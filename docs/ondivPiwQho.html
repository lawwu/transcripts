<html><head><title>Lesson 12: Deep Learning Part 2 2018 - Generative Adversarial Networks (GANs)</title>
<style>
    body {
        font-family: Arial, sans-serif;
        margin: 0;
        padding: 0;
        background-color: #f4f4f4;
        color: #333;
    }
    .container {
        width: 95%;  /* Increased width to use more space */
        margin: auto;
        overflow: auto;  /* Added to handle overflow by adding a scrollbar if necessary */
    }
    h2, h3 {
        color: #333;
        text-align: center;
    }
    a {
        color: #0000FF;  /* Traditional blue color for links */
        text-decoration: none;
    }
    a:hover {
        text-decoration: underline;
    }
    img {
        display: block;
        margin: auto;
        max-width: 100%;
    }
    .c {
        margin: 10px 0;
    }
    .s, .t {
        display: inline-block;
        margin-right: 5px;
    }
    .max-width {
        max-width: 800px;
        margin: auto;
        padding-left: 20px;
    }
    table {
        width: 100%;
        border-collapse: collapse;
    }
    th, td {
        border: 1px solid #ddd;
        padding: 8px;
        text-align: left;  /* Ensure text alignment is consistent */
    }
    tr:nth-child(even) {
        background-color: #f2f2f2;
    }
    tr:nth-child(odd) {
        background-color: #e6e6e6;
    }
</style>

    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-69VLBMTTP0"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-69VLBMTTP0');
    </script>
    </head><body><div class='container'><a href="index.html">back to index</a><h2>Lesson 12: Deep Learning Part 2 2018 - Generative Adversarial Networks (GANs)</h2><a href="https://www.youtube.com/watch?v=ondivPiwQho"><img src="https://i.ytimg.com/vi_webp/ondivPiwQho/maxresdefault.webp" style="width:50%;"></a><div><br></div><h3>Chapters</h3><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=0">0:0</a> Introduction<br><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=65">1:5</a> Christine Payne<br><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=436">7:16</a> Darknet<br><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=535">8:55</a> Basic Skills<br><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=663">11:3</a> Architecture<br><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=710">11:50</a> Basic Architecture<br><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=878">14:38</a> Res Blocks<br><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=1006">16:46</a> Number of Channels<br><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=1103">18:23</a> InPlace<br><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=1270">21:10</a> Padding<br><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=1333">22:13</a> One by One Con<br><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=1560">26:0</a> Wide Residual Networks<br><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=1784">29:44</a> SelfNormalising<br><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=1888">31:28</a> Group Layers<br><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=2245">37:25</a> Adaptive Average Pooling<br><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=2813">46:53</a> Strides<br><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=2906">48:26</a> GANs<br><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=3291">54:51</a> Generating Pictures<br><br><div style="text-align: left;"><a href="./ondivPiwQho.html">Whisper Transcript</a> | <a href="./transcript_ondivPiwQho.html">Transcript Only Page</a></div><br><div style="max-width: 800px;"><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=0" target="_blank">00:00:00.000</a></span> | <span class="t">So, we're going to be talking about GANs today.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=5" target="_blank">00:00:05.760</a></span> | <span class="t">Who has heard of GANs?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=7" target="_blank">00:00:07.920</a></span> | <span class="t">Yeah, most of you.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=11" target="_blank">00:00:11.520</a></span> | <span class="t">Very hot technology, but definitely deserving to be in the cutting-edge deep learning part</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=20" target="_blank">00:00:20.640</a></span> | <span class="t">of the course, because they're not quite proven to be necessarily useful for anything, but</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=28" target="_blank">00:00:28.320</a></span> | <span class="t">they're nearly there.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=29" target="_blank">00:00:29.680</a></span> | <span class="t">They're definitely going to get there, and we're going to focus on the things where they're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=35" target="_blank">00:00:35.360</a></span> | <span class="t">definitely going to be useful in practice.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=38" target="_blank">00:00:38.400</a></span> | <span class="t">There are a number of areas where they may turn out to be useful in practice, but we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=41" target="_blank">00:00:41.600</a></span> | <span class="t">don't know yet.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=42" target="_blank">00:00:42.880</a></span> | <span class="t">So I think the area that we're going to be useful in practice is the kind of thing you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=48" target="_blank">00:00:48.400</a></span> | <span class="t">see on the left here, which is, for example, turning drawings into rendered pictures.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=54" target="_blank">00:00:54.960</a></span> | <span class="t">This comes from a paper that just came out two days ago.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=59" target="_blank">00:00:59.480</a></span> | <span class="t">So there's a very active research going on right now.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=65" target="_blank">00:01:05.560</a></span> | <span class="t">Before we get there, though, let's talk about some interesting stuff from the last class.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=72" target="_blank">00:01:12.400</a></span> | <span class="t">This is an interesting thing that one of our diversity fellows, Christine Payne, did.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=77" target="_blank">00:01:17.800</a></span> | <span class="t">Christine has a master's in medicine from Stanford, and so she obviously had an interest</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=84" target="_blank">00:01:24.000</a></span> | <span class="t">in thinking what would it look like if we built a language model of medicine.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=90" target="_blank">00:01:30.800</a></span> | <span class="t">One of the things that we briefly touched on back in lesson 4 but didn't really talk</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=95" target="_blank">00:01:35.560</a></span> | <span class="t">much about last time is this idea that you can actually seed a generative language model,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=101" target="_blank">00:01:41.720</a></span> | <span class="t">which basically means you've trained a language model on some corpus, and then you're going</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=106" target="_blank">00:01:46.040</a></span> | <span class="t">to generate some text from that language model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=109" target="_blank">00:01:49.520</a></span> | <span class="t">And so you can start off by feeding it a few words to basically say here's the first few</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=115" target="_blank">00:01:55.360</a></span> | <span class="t">words to create the hidden state in the language model, and then generate from there, please.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=121" target="_blank">00:02:01.000</a></span> | <span class="t">And so Christine did something clever, which was to kind of pick a -- was to seed it with</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=126" target="_blank">00:02:06.920</a></span> | <span class="t">a question and then repeat the question three times, Christine, three times, and then let</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=132" target="_blank">00:02:12.920</a></span> | <span class="t">it generate from there.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=135" target="_blank">00:02:15.760</a></span> | <span class="t">And so she fed a language model lots of different medical texts, and then fed it this question,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=141" target="_blank">00:02:21.360</a></span> | <span class="t">what is the prevalence of malaria, and the model said in the US about 10% of the population</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=147" target="_blank">00:02:27.640</a></span> | <span class="t">has the virus, but only about 1% is infected with the virus, about 50 to 80 million are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=152" target="_blank">00:02:32.440</a></span> | <span class="t">infected.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=153" target="_blank">00:02:33.440</a></span> | <span class="t">She said what's the treatment for ectopic pregnancy, and it said it's a safe and safe</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=158" target="_blank">00:02:38.240</a></span> | <span class="t">treatment for women with a history of symptoms that may have a significant impact on clinical</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=161" target="_blank">00:02:41.720</a></span> | <span class="t">response, most important factor is development of management of ectopic pregnancy, etc.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=166" target="_blank">00:02:46.720</a></span> | <span class="t">And so what I find interesting about this is it's pretty close to being a -- to me as</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=176" target="_blank">00:02:56.000</a></span> | <span class="t">somebody who doesn't have a master's in medicine from Stanford, pretty close to being a believable</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=180" target="_blank">00:03:00.600</a></span> | <span class="t">answer to the question, but it really has no bearing on reality whatsoever, and I kind</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=186" target="_blank">00:03:06.920</a></span> | <span class="t">of think it's an interesting kind of ethical and user experience quandary.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=193" target="_blank">00:03:13.560</a></span> | <span class="t">So actually, I'm involved also in a company called Doc.ai that's trying to basically -- or</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=200" target="_blank">00:03:20.480</a></span> | <span class="t">doing a number of things, but in the end provide an app for doctors and patients which can</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=205" target="_blank">00:03:25.600</a></span> | <span class="t">help create a conversational user interface around helping them with their medical issues.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=211" target="_blank">00:03:31.520</a></span> | <span class="t">And I've been continually saying to the software engineers on that team, please don't try to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=217" target="_blank">00:03:37.640</a></span> | <span class="t">create a generative model using like an LSTM or something because they're going to be really</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=223" target="_blank">00:03:43.520</a></span> | <span class="t">good at creating bad advice that sounds impressive, kind of like political pundits or tenured professors,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=235" target="_blank">00:03:55.320</a></span> | <span class="t">people who can say bullshit with great authority.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=243" target="_blank">00:04:03.400</a></span> | <span class="t">So I thought it was a really interesting experiment, and great to see what our diversity fellows</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=252" target="_blank">00:04:12.000</a></span> | <span class="t">are doing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=253" target="_blank">00:04:13.000</a></span> | <span class="t">I mean, this is why we have this program.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=255" target="_blank">00:04:15.680</a></span> | <span class="t">I suppose I shouldn't just say master's in medicine, actually a Juilliard trained classical</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=261" target="_blank">00:04:21.080</a></span> | <span class="t">musician or actually also a Princeton valedictorian in physics, so also a high performance computing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=267" target="_blank">00:04:27.400</a></span> | <span class="t">expert.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=268" target="_blank">00:04:28.400</a></span> | <span class="t">Yeah, okay, so she does a bit of everything.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=271" target="_blank">00:04:31.120</a></span> | <span class="t">So yeah, really impressive group of people and great to see such exciting kind of ideas</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=276" target="_blank">00:04:36.440</a></span> | <span class="t">coming out.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=277" target="_blank">00:04:37.440</a></span> | <span class="t">And if you're wondering, you know, I've done some interesting experiments, should I let</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=284" target="_blank">00:04:44.160</a></span> | <span class="t">people know about it?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=286" target="_blank">00:04:46.800</a></span> | <span class="t">Well, Christine mentioned this on the forum, I went on to mention it on Twitter, to which</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=292" target="_blank">00:04:52.920</a></span> | <span class="t">I got this response, you're looking for a job, you may be wondering who Xavier Maricain is,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=299" target="_blank">00:04:59.080</a></span> | <span class="t">well he is the founder of a hot new medical AI startup, he was previously the head of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=305" target="_blank">00:05:05.400</a></span> | <span class="t">engineering at Quora, before that he was the guy at Netflix who ran the data science team</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=310" target="_blank">00:05:10.960</a></span> | <span class="t">and built their recommender systems, so this is what happens if you do something cool,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=317" target="_blank">00:05:17.160</a></span> | <span class="t">let people know about it and get noticed by awesome people like Xavier.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=326" target="_blank">00:05:26.520</a></span> | <span class="t">So let's talk about sci-fi 10.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=332" target="_blank">00:05:32.520</a></span> | <span class="t">And the reason I'm going to talk about sci-fi 10 is that we're going to be looking at some</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=339" target="_blank">00:05:39.560</a></span> | <span class="t">more bare-bones PyTorch stuff today to build these generative adversarial models, there's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=347" target="_blank">00:05:47.040</a></span> | <span class="t">no really fast AI support to speak of at all for GANs at the moment, I'm sure there will</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=353" target="_blank">00:05:53.320</a></span> | <span class="t">be soon enough, but currently there isn't, so we're going to be building a lot of models</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=356" target="_blank">00:05:56.200</a></span> | <span class="t">from scratch.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=357" target="_blank">00:05:57.200</a></span> | <span class="t">It's been a while since we've done serious model building, a little bit of model building</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=363" target="_blank">00:06:03.240</a></span> | <span class="t">I guess for our bounding box stuff, but really all the interesting stuff there was the loss</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=369" target="_blank">00:06:09.840</a></span> | <span class="t">function.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=370" target="_blank">00:06:10.840</a></span> | <span class="t">So we looked at sci-fi 10 in the part 1 of the course and we built something which was</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=375" target="_blank">00:06:15.080</a></span> | <span class="t">getting about 85% accuracy and I can't remember, a couple of hours to train.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=381" target="_blank">00:06:21.800</a></span> | <span class="t">Interestingly there's a competition going on now to see who can actually train sci-fi</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=385" target="_blank">00:06:25.880</a></span> | <span class="t">10 the fastest, going through this Stanford/Dawn bench and currently, so the goal is to get</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=391" target="_blank">00:06:31.720</a></span> | <span class="t">it to train to 94% accuracy.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=394" target="_blank">00:06:34.160</a></span> | <span class="t">So it'd be interesting to see if we can build an architecture that can get to 94% accuracy</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=399" target="_blank">00:06:39.760</a></span> | <span class="t">because that's a lot better than our previous attempt and so hopefully in doing so we'll</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=404" target="_blank">00:06:44.600</a></span> | <span class="t">learn something about creating good architectures.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=407" target="_blank">00:06:47.720</a></span> | <span class="t">That will be then useful for looking at these GANs today, but I think also it's useful because</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=416" target="_blank">00:06:56.460</a></span> | <span class="t">I've been looking much more deeply into the last few years' papers about different kinds</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=422" target="_blank">00:07:02.840</a></span> | <span class="t">of CNN architectures and realized that a lot of the insights in those papers are not being</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=428" target="_blank">00:07:08.060</a></span> | <span class="t">widely leveraged and clearly not widely understood.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=431" target="_blank">00:07:11.560</a></span> | <span class="t">So I want to show you what happens if we can leverage some of that understanding.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=437" target="_blank">00:07:17.200</a></span> | <span class="t">So I've got this notebook called sci-fi 10 darknet.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=443" target="_blank">00:07:23.200</a></span> | <span class="t">That's because the architecture we're going to look at is really very close to the darknet</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=448" target="_blank">00:07:28.600</a></span> | <span class="t">architecture.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=449" target="_blank">00:07:29.600</a></span> | <span class="t">But you'll see in the process that the darknet architecture has not the whole YOLO version</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=454" target="_blank">00:07:34.920</a></span> | <span class="t">3 end-to-end thing, but just the part of it that they pre-trained on ImageNet to do classification.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=461" target="_blank">00:07:41.520</a></span> | <span class="t">It's almost like the most generic simple architecture almost you could come up with.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=468" target="_blank">00:07:48.160</a></span> | <span class="t">And so it's a really great starting point for experiments.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=472" target="_blank">00:07:52.360</a></span> | <span class="t">So we're going to call it darknet, but it's not quite darknet and you can fiddle around</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=476" target="_blank">00:07:56.240</a></span> | <span class="t">with it to create things that definitely aren't darknet.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=478" target="_blank">00:07:58.840</a></span> | <span class="t">It's really just the basis of nearly any modern ResNet-based architecture.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=486" target="_blank">00:08:06.480</a></span> | <span class="t">So sci-fi 10, remember, is a fairly small dataset.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=491" target="_blank">00:08:11.080</a></span> | <span class="t">The images are only 32x32 in size.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=494" target="_blank">00:08:14.400</a></span> | <span class="t">And I think it's a really great dataset to work with because you can train it relatively</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=501" target="_blank">00:08:21.360</a></span> | <span class="t">quickly, unlike ImageNet.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=503" target="_blank">00:08:23.280</a></span> | <span class="t">It's a relatively small amount of data, unlike ImageNet, and it's actually quite hard to recognize</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=508" target="_blank">00:08:28.040</a></span> | <span class="t">the images because 32x32 is kind of too small to easily see what's going on.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=512" target="_blank">00:08:32.840</a></span> | <span class="t">So it's somewhat challenging.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=515" target="_blank">00:08:35.440</a></span> | <span class="t">So I think it's a really underappreciated dataset because it's old, and who at DeepMind</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=522" target="_blank">00:08:42.400</a></span> | <span class="t">or OpenAI wants to work with a small old dataset when they could use their entire server room</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=528" target="_blank">00:08:48.740</a></span> | <span class="t">to process something much bigger.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=530" target="_blank">00:08:50.440</a></span> | <span class="t">But to me, I think this is a really great dataset to focus on.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=536" target="_blank">00:08:56.640</a></span> | <span class="t">So we'll go ahead and import our usual stuff, and we're going to try and build a network</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=544" target="_blank">00:09:04.160</a></span> | <span class="t">from scratch to train this with.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=548" target="_blank">00:09:08.760</a></span> | <span class="t">One thing that I think is a really good exercise for anybody who's not 100% confident with</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=554" target="_blank">00:09:14.120</a></span> | <span class="t">their kind of broadcasting and PyTorch and so forth basic skills is figure out how I</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=561" target="_blank">00:09:21.400</a></span> | <span class="t">came up with these numbers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=564" target="_blank">00:09:24.240</a></span> | <span class="t">So these numbers are the averages for each channel and the standard deviations for each</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=568" target="_blank">00:09:28.880</a></span> | <span class="t">channel in SciFiTet.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=570" target="_blank">00:09:30.680</a></span> | <span class="t">So try and as a bit of a homework, just make sure you can recreate those numbers and see</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=575" target="_blank">00:09:35.480</a></span> | <span class="t">if you can do it in no more than a couple of lines of code, you know, no loops.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=582" target="_blank">00:09:42.960</a></span> | <span class="t">Ideally you want to do it in one go if you can.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=589" target="_blank">00:09:49.160</a></span> | <span class="t">Because these are fairly small, we can use a larger batch size than usual, 256, and the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=594" target="_blank">00:09:54.160</a></span> | <span class="t">size of these images is 32.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=598" target="_blank">00:09:58.940</a></span> | <span class="t">Transformations - normally we have this standard set of side-on transformations we use for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=605" target="_blank">00:10:05.440</a></span> | <span class="t">photos of normal objects.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=607" target="_blank">00:10:07.640</a></span> | <span class="t">We're not going to use that here though because these images are so small that trying to rotate</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=611" target="_blank">00:10:11.520</a></span> | <span class="t">a 32x32 image a bit is going to introduce a lot of blocking kind of distortions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=619" target="_blank">00:10:19.000</a></span> | <span class="t">So the kind of standard transforms that people tend to use is a random horizontal flip, and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=625" target="_blank">00:10:25.040</a></span> | <span class="t">then we add size divided by 8, so 4 pixels of padding on each side.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=632" target="_blank">00:10:32.120</a></span> | <span class="t">And one thing which I find works really well is by default FastAI doesn't add black padding,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=637" target="_blank">00:10:37.080</a></span> | <span class="t">which basically every other library does.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=639" target="_blank">00:10:39.080</a></span> | <span class="t">We actually take the last 4 pixels of the existing photo and flip it and reflect it,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=644" target="_blank">00:10:44.680</a></span> | <span class="t">and we find that we get much better results by using this reflection padding by default.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=651" target="_blank">00:10:51.400</a></span> | <span class="t">So now that we've got a 36x36 image, this set of transforms in training will randomly</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=658" target="_blank">00:10:58.160</a></span> | <span class="t">pick a 32x32 crop.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=660" target="_blank">00:11:00.240</a></span> | <span class="t">So we get a little bit of variation, but not heaps.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=663" target="_blank">00:11:03.320</a></span> | <span class="t">Alright, so we can use our normal from paths to grab our data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=667" target="_blank">00:11:07.400</a></span> | <span class="t">So we now need an architecture.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=670" target="_blank">00:11:10.360</a></span> | <span class="t">And what we're going to do is create an architecture which fits in one screen.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=678" target="_blank">00:11:18.080</a></span> | <span class="t">So this is from scratch, as you can see, I'm using the predefined com2d, batch norm2d,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=687" target="_blank">00:11:27.280</a></span> | <span class="t">leaky value modules, but I'm not using any blocks or anything, they're all being defined.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=696" target="_blank">00:11:36.040</a></span> | <span class="t">So the entire thing is here on one screen.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=697" target="_blank">00:11:37.840</a></span> | <span class="t">So if you're ever wondering can I understand a modern good quality architecture, absolutely.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=705" target="_blank">00:11:45.560</a></span> | <span class="t">Let's study this one.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=708" target="_blank">00:11:48.480</a></span> | <span class="t">So my basic starting point with an architecture is to say it's a stacked bunch of layers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=717" target="_blank">00:11:57.960</a></span> | <span class="t">And generally speaking there's going to be some kind of hierarchy of layers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=720" target="_blank">00:12:00.680</a></span> | <span class="t">So at the very bottom level there's things like a convolutional layer and a batch norm</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=724" target="_blank">00:12:04.280</a></span> | <span class="t">layer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=725" target="_blank">00:12:05.280</a></span> | <span class="t">So if you're thinking anytime you have a convolution, you're probably going to have some standard</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=730" target="_blank">00:12:10.800</a></span> | <span class="t">sequence and normally it's going to be conv, batch norm, then a nonlinear activation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=737" target="_blank">00:12:17.720</a></span> | <span class="t">So I try to start right from the top by saying, okay, what are my basic units going to be?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=745" target="_blank">00:12:25.600</a></span> | <span class="t">And so by defining it here, that way I don't have to worry about trying to keep everything</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=754" target="_blank">00:12:34.520</a></span> | <span class="t">consistent and it's going to make everything a lot simpler.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=757" target="_blank">00:12:37.040</a></span> | <span class="t">So here's my conv layer, and so anytime I say conv layer, I mean conv, batch norm, relu.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=763" target="_blank">00:12:43.880</a></span> | <span class="t">Now I'm not quite saying relu, I'm saying leaky relu, and I think we've briefly mentioned</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=773" target="_blank">00:12:53.280</a></span> | <span class="t">it before, but the basic idea is that normally a relu looks like that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=786" target="_blank">00:13:06.800</a></span> | <span class="t">Hopefully you all know that now.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=790" target="_blank">00:13:10.740</a></span> | <span class="t">A leaky relu looks like that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=798" target="_blank">00:13:18.740</a></span> | <span class="t">So this part, as before, has a gradient of 1, and this part has a gradient of, it can</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=803" target="_blank">00:13:23.400</a></span> | <span class="t">vary, but something around 0.1 or 0.01 is common.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=808" target="_blank">00:13:28.640</a></span> | <span class="t">And the idea behind it is that when you're in this negative zone here, you don't end</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=814" target="_blank">00:13:34.380</a></span> | <span class="t">up with a 0 gradient, which makes it very hard to update it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=819" target="_blank">00:13:39.080</a></span> | <span class="t">In practice, people have found leaky relu more useful on smaller datasets and less useful</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=825" target="_blank">00:13:45.480</a></span> | <span class="t">on big datasets, but it's interesting that for the YOLO version 3 paper, they did use</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=829" target="_blank">00:13:49.720</a></span> | <span class="t">a leaky relu and got great performance from it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=833" target="_blank">00:13:53.080</a></span> | <span class="t">So it rarely makes things worse, and it often makes things better.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=837" target="_blank">00:13:57.320</a></span> | <span class="t">So it's probably not bad if you need to create your own architecture to make that your default</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=842" target="_blank">00:14:02.400</a></span> | <span class="t">go-to is to use leaky relu.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=847" target="_blank">00:14:07.560</a></span> | <span class="t">You'll notice I don't define a PyTorch module here, I just go ahead and go sequential.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=853" target="_blank">00:14:13.640</a></span> | <span class="t">This is something that if you read other people's PyTorch code, it's really underutilized.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=859" target="_blank">00:14:19.480</a></span> | <span class="t">People tend to write everything as a PyTorch module with an init and a forward.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=864" target="_blank">00:14:24.040</a></span> | <span class="t">But if the thing you want is just a sequence of things one after the other, it's much more</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=869" target="_blank">00:14:29.240</a></span> | <span class="t">concise and easy to understand to just make it a sequential.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=872" target="_blank">00:14:32.640</a></span> | <span class="t">So I've just got a simple plain function that just returns a sequential model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=878" target="_blank">00:14:38.700</a></span> | <span class="t">So I mentioned that there's generally a number of hierarchies of units in most modern networks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=889" target="_blank">00:14:49.960</a></span> | <span class="t">And I think we know now that the next level in this unit hierarchy for ResNets is the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=901" target="_blank">00:15:01.640</a></span> | <span class="t">res block or the residual block, I call it here a res layer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=910" target="_blank">00:15:10.520</a></span> | <span class="t">And back when we last did scifi 10, I oversimplified this, I cheated a little bit.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=918" target="_blank">00:15:18.560</a></span> | <span class="t">We had x coming in, and we put that through a conv, and then we added it back up to x</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=927" target="_blank">00:15:27.400</a></span> | <span class="t">to go out.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=930" target="_blank">00:15:30.720</a></span> | <span class="t">So in general, we've got your output is equal to your input plus some function of your input.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=945" target="_blank">00:15:45.080</a></span> | <span class="t">And the thing we did last year was we made f was a 2D conv.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=952" target="_blank">00:15:52.240</a></span> | <span class="t">And actually, in the real res block, there's actually two of them.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=965" target="_blank">00:16:05.040</a></span> | <span class="t">So it's actually conv of conv of x.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=974" target="_blank">00:16:14.480</a></span> | <span class="t">And when I say conv, I'm using this as a shortcut for our conv layer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=984" target="_blank">00:16:24.800</a></span> | <span class="t">So you can see here, I've created two convs, and here it is.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=988" target="_blank">00:16:28.680</a></span> | <span class="t">I take my x, put it through the first conv, put it through the second conv, and add it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=993" target="_blank">00:16:33.100</a></span> | <span class="t">back up to my input again to get my basic res block.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=1000" target="_blank">00:16:40.000</a></span> | <span class="t">So, one interesting insight here is what are the number of channels in these convolutions?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=1019" target="_blank">00:16:59.960</a></span> | <span class="t">So we've got coming in some number of input filters.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=1029" target="_blank">00:17:09.040</a></span> | <span class="t">The way that the darknet folks set things up is they said we're going to make every one</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=1033" target="_blank">00:17:13.320</a></span> | <span class="t">of these res layers spit out the same number of channels that came in.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=1038" target="_blank">00:17:18.840</a></span> | <span class="t">And I kind of like that, that's why I used it here, because it makes life simpler.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=1043" target="_blank">00:17:23.120</a></span> | <span class="t">And so what they did is they said let's have the first conv have the number of channels,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=1049" target="_blank">00:17:29.120</a></span> | <span class="t">and then the second conv double it again.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=1051" target="_blank">00:17:31.480</a></span> | <span class="t">So ni goes to ni/2, and then ni/2 goes to ni.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=1056" target="_blank">00:17:36.180</a></span> | <span class="t">So you've kind of got this funneling thing where if you've got like 64 channels coming</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=1062" target="_blank">00:17:42.720</a></span> | <span class="t">in, it kind of gets squished down with a first conv down to 32 channels, and then taken back</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=1069" target="_blank">00:17:49.280</a></span> | <span class="t">up again to 64 channels coming out.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=1073" target="_blank">00:17:53.040</a></span> | <span class="t">Yes, Rachel?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=1076" target="_blank">00:17:56.000</a></span> | <span class="t">Why is inplace equals true in the leaky value?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=1079" target="_blank">00:17:59.000</a></span> | <span class="t">Oh, thanks for asking.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=1081" target="_blank">00:18:01.560</a></span> | <span class="t">A lot of people forget this or don't know about it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=1085" target="_blank">00:18:05.640</a></span> | <span class="t">But this is a really important memory technique.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=1091" target="_blank">00:18:11.120</a></span> | <span class="t">If you think about it, this conv layer is like the lowest level thing, so pretty much</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=1095" target="_blank">00:18:15.360</a></span> | <span class="t">everything in our resnet once it's all put together is going to be conv layers, conv layers,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=1101" target="_blank">00:18:21.760</a></span> | <span class="t">conv layers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=1103" target="_blank">00:18:23.680</a></span> | <span class="t">If you don't have inplace equals true, it's going to create a whole separate piece of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=1109" target="_blank">00:18:29.800</a></span> | <span class="t">memory for the output of the value.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=1114" target="_blank">00:18:34.720</a></span> | <span class="t">So like it's going to allocate a whole bunch of memory that's totally unnecessary.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=1119" target="_blank">00:18:39.280</a></span> | <span class="t">And actually, since I wrote this, I came up with another idea the other day, which I'll</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=1125" target="_blank">00:18:45.800</a></span> | <span class="t">now implement, which is you can do the same thing for the res layer, rather than going</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=1130" target="_blank">00:18:50.280</a></span> | <span class="t">-- let's just reorder this to say x plus that -- you can actually do the same thing here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=1141" target="_blank">00:19:01.360</a></span> | <span class="t">Hopefully some of you might remember that in PyTorch, pretty much every function has</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=1146" target="_blank">00:19:06.400</a></span> | <span class="t">an underscore suffix version which says do that inplace.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=1151" target="_blank">00:19:11.160</a></span> | <span class="t">So plus, there's also an add, and so that's add inplace.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=1158" target="_blank">00:19:18.680</a></span> | <span class="t">And so that's now suddenly reduced my memory there as well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=1164" target="_blank">00:19:24.640</a></span> | <span class="t">So these are really handy little tricks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=1166" target="_blank">00:19:26.920</a></span> | <span class="t">And I actually forgot the inplace equals true at first for this, and I literally was having</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=1171" target="_blank">00:19:31.000</a></span> | <span class="t">to decrease my batch size to much lower amounts than I knew should be possible, and it was</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=1174" target="_blank">00:19:34.720</a></span> | <span class="t">driving me crazy, and then I realized that that was missing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=1179" target="_blank">00:19:39.560</a></span> | <span class="t">You can also do that with dropout, by the way, if you have dropout.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=1182" target="_blank">00:19:42.880</a></span> | <span class="t">So dropout and all the activation functions you can do inplace, and then generally any</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=1190" target="_blank">00:19:50.280</a></span> | <span class="t">arithmetic operation you can do inplace as well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=1194" target="_blank">00:19:54.360</a></span> | <span class="t">Why is bias usually in ResNet set to false in the conv layer?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=1202" target="_blank">00:20:02.400</a></span> | <span class="t">If you're watching the video, pause now and see if you can figure this out, because this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=1208" target="_blank">00:20:08.080</a></span> | <span class="t">is a really interesting question.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=1210" target="_blank">00:20:10.280</a></span> | <span class="t">Why don't we need bias?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=1212" target="_blank">00:20:12.240</a></span> | <span class="t">So I'll wait for you to pause.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=1215" target="_blank">00:20:15.060</a></span> | <span class="t">Welcome back.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=1216" target="_blank">00:20:16.060</a></span> | <span class="t">So if you've figured it out, here's the thing, immediately after the conv is a batch norm.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=1224" target="_blank">00:20:24.000</a></span> | <span class="t">And remember batch norm has two learnable parameters for each activation, the kind of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=1231" target="_blank">00:20:31.280</a></span> | <span class="t">the thing you multiply by and the thing you add.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=1234" target="_blank">00:20:34.800</a></span> | <span class="t">So if we had bias here to add, and then we add another thing here, we're adding two things</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=1241" target="_blank">00:20:41.120</a></span> | <span class="t">which is totally pointless, like that's two weights where one would do.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=1244" target="_blank">00:20:44.440</a></span> | <span class="t">So if you have a batch norm after a conv, then you can either say in the batch norm,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=1251" target="_blank">00:20:51.240</a></span> | <span class="t">don't include the add bit there please, or easier is just to say don't include the bias</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=1255" target="_blank">00:20:55.920</a></span> | <span class="t">in the conv.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=1260" target="_blank">00:21:00.200</a></span> | <span class="t">There's no particular harm, but again, it's going to take more memory because that's more</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=1264" target="_blank">00:21:04.860</a></span> | <span class="t">gradients that it has to keep track of.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=1268" target="_blank">00:21:08.920</a></span> | <span class="t">So best to avoid.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=1272" target="_blank">00:21:12.400</a></span> | <span class="t">Also another thing, a little trick, is most people's conv layers have padding as a parameter,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=1279" target="_blank">00:21:19.320</a></span> | <span class="t">but generally speaking you should be able to calculate the padding easily enough.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=1283" target="_blank">00:21:23.600</a></span> | <span class="t">And I see people try to implement special same padding modules and all kinds of stuff</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=1289" target="_blank">00:21:29.760</a></span> | <span class="t">like that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=1290" target="_blank">00:21:30.760</a></span> | <span class="t">But if you've got a stride 1, and you've got a kernel size of 3, then obviously that's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=1304" target="_blank">00:21:44.000</a></span> | <span class="t">going to overlap by one unit on each side, so we want padding of 1.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=1310" target="_blank">00:21:50.680</a></span> | <span class="t">Whereas if it's stride 1, then we don't need any padding.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=1314" target="_blank">00:21:54.480</a></span> | <span class="t">So in general, padding of kernel size integer divided by 2 is what you need.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=1320" target="_blank">00:22:00.640</a></span> | <span class="t">There's some tweaks sometimes, but in this case this works perfectly well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=1325" target="_blank">00:22:05.400</a></span> | <span class="t">So again, trying to simplify my code by having the computer calculate stuff for me rather</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=1330" target="_blank">00:22:10.760</a></span> | <span class="t">than me having to do it myself.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=1335" target="_blank">00:22:15.120</a></span> | <span class="t">Another thing here with the two conv layers, we have this idea of a bottleneck, this idea</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=1341" target="_blank">00:22:21.240</a></span> | <span class="t">of reducing the channels and then increasing them again, is also what kernel size we use.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=1346" target="_blank">00:22:26.320</a></span> | <span class="t">So here is a 1x1 conv, and this is again something you might want to pause the video now and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=1352" target="_blank">00:22:32.000</a></span> | <span class="t">think about what's a 1x1 conv really?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=1356" target="_blank">00:22:36.060</a></span> | <span class="t">What actually happens in a 1x1 conv?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=1362" target="_blank">00:22:42.920</a></span> | <span class="t">So if we've got a little 4x4 grid here, and of course there's a filter or channels axis</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=1375" target="_blank">00:22:55.200</a></span> | <span class="t">as well, maybe that's like 32, and we're going to do a 1x1 conv.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=1381" target="_blank">00:23:01.160</a></span> | <span class="t">So what's the kernel for a 1x1 conv going to look like?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=1386" target="_blank">00:23:06.640</a></span> | <span class="t">It's going to be 1 by 32.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=1394" target="_blank">00:23:14.760</a></span> | <span class="t">So remember when we talk about the kernel size, we never mention that last piece, but</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=1400" target="_blank">00:23:20.360</a></span> | <span class="t">let's say it's 1x1 by 32 because that's part of the filters in and filters out.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=1404" target="_blank">00:23:24.840</a></span> | <span class="t">So in other words then, what happens is this one thing gets placed first of all here on</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=1411" target="_blank">00:23:31.480</a></span> | <span class="t">the first cell, and we basically get a dot product of that 32 deep bit with this 32 bit</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=1419" target="_blank">00:23:39.320</a></span> | <span class="t">deep bit, and that's going to give us our first output.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=1427" target="_blank">00:23:47.920</a></span> | <span class="t">And then we're going to take that 32 bit bit and put it with the second one to get the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=1431" target="_blank">00:23:51.040</a></span> | <span class="t">second output.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=1432" target="_blank">00:23:52.040</a></span> | <span class="t">So it's basically going to be a bunch of little dot products for each point in the grid.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=1441" target="_blank">00:24:01.640</a></span> | <span class="t">So what it basically is then is basically something which is allowing us to kind of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=1453" target="_blank">00:24:13.960</a></span> | <span class="t">change the dimensionality in whatever way we want in the channel dimension.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=1463" target="_blank">00:24:23.300</a></span> | <span class="t">And so that would be one of our filters.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=1468" target="_blank">00:24:28.760</a></span> | <span class="t">And so in this case we're creating ni divided by 2 of these, so we're going to have ni divided</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=1475" target="_blank">00:24:35.920</a></span> | <span class="t">by 2 of these dot products, all with different weighted averages of the input channels.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=1482" target="_blank">00:24:42.240</a></span> | <span class="t">So it basically lets us, with very little computation, add this additional step of calculations</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=1492" target="_blank">00:24:52.640</a></span> | <span class="t">and non-linearities.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=1495" target="_blank">00:24:55.720</a></span> | <span class="t">So that's a cool trick, this idea of taking advantage of these 1x1 comms, creating this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=1501" target="_blank">00:25:01.200</a></span> | <span class="t">bottleneck and then pulling it out again with 3x3 comms.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=1505" target="_blank">00:25:05.280</a></span> | <span class="t">So that's actually going to take advantage of the 2D nature of the input properly.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=1512" target="_blank">00:25:12.160</a></span> | <span class="t">The 1x1 comm doesn't take advantage of that at all.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=1517" target="_blank">00:25:17.760</a></span> | <span class="t">So these two lines of code, there's not much in it, but it's a really great test of your</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=1524" target="_blank">00:25:24.760</a></span> | <span class="t">understanding and kind of your intuition about what's going on.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=1529" target="_blank">00:25:29.160</a></span> | <span class="t">Why is it that a 1x1 comm going from ni to ni over 2 channels, followed by a 3x3 comm</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=1536" target="_blank">00:25:36.440</a></span> | <span class="t">going from ni over 2 to ni channels? Why does it work? Why do the tensor ranks line up? Why</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=1542" target="_blank">00:25:42.800</a></span> | <span class="t">do the dimensions all line up nicely? Why is it a good idea? What's it really doing? It's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=1549" target="_blank">00:25:49.280</a></span> | <span class="t">a really good thing to fiddle around with, maybe create some small ones in Jupyter Notebook,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=1555" target="_blank">00:25:55.280</a></span> | <span class="t">run them yourself, see what inputs and outputs come in and out. Really get a feel for that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=1561" target="_blank">00:26:01.360</a></span> | <span class="t">Once you've done so, you can then play around with different things. One of the really unappreciated</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=1573" target="_blank">00:26:13.480</a></span> | <span class="t">papers is this one, Wide Residual Networks. It's really quite a simple paper, but what</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=1585" target="_blank">00:26:25.200</a></span> | <span class="t">they do is they basically fiddle around with these two lines of code. And what they do</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=1593" target="_blank">00:26:33.360</a></span> | <span class="t">is they say, well what if this wasn't divided by 2, but what if it was times 2? That would</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=1600" target="_blank">00:26:40.600</a></span> | <span class="t">be totally allowable. That's going to line up nicely. Or what if we had another comm3</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=1612" target="_blank">00:26:52.120</a></span> | <span class="t">after this, and so this was actually ni over 2 to ni over 2, and then this is ni over 2.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=1621" target="_blank">00:27:01.760</a></span> | <span class="t">Again that's going to work, right? Kernel size 1, 3, 1, going to half the number of kernels,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=1627" target="_blank">00:27:07.680</a></span> | <span class="t">leave it at half and then double it again at the end. And so they come up with this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=1631" target="_blank">00:27:11.360</a></span> | <span class="t">kind of simple notation for basically defining what this can look like. And then they show</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=1639" target="_blank">00:27:19.680</a></span> | <span class="t">lots of experiments. And basically what they show is that this approach of bottlenecking,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=1650" target="_blank">00:27:30.000</a></span> | <span class="t">of decreasing the number of channels, which is almost universal in resnets, is probably</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=1655" target="_blank">00:27:35.480</a></span> | <span class="t">not a good idea. In fact from the experiment, it's definitely not a good idea. Because what</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=1659" target="_blank">00:27:39.640</a></span> | <span class="t">happens is it lets you create really deep networks. The guys who created resnets got</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=1665" target="_blank">00:27:45.360</a></span> | <span class="t">particularly famous creating a 1,001-layer network. But the thing about 1,001 layers is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=1671" target="_blank">00:27:51.480</a></span> | <span class="t">you can't calculate layer 2 until you finish layer 1. You can't calculate layer 3 until</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=1676" target="_blank">00:27:56.600</a></span> | <span class="t">you finish layer 2. So it's sequential. GPUs don't like sequential. So what they showed</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=1683" target="_blank">00:28:03.280</a></span> | <span class="t">is that if you have less layers, but with more calculations per layer, and so one easy</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=1690" target="_blank">00:28:10.920</a></span> | <span class="t">way to do that would be to remove the /2. No other changes. Like try this at home. Try</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=1697" target="_blank">00:28:17.960</a></span> | <span class="t">running sci-fi and see what happens. Or maybe even multiply it by 2 or fiddle around. And</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=1704" target="_blank">00:28:24.760</a></span> | <span class="t">that basically lets your GPU do more work. And it's very interesting because the vast</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=1709" target="_blank">00:28:29.320</a></span> | <span class="t">majority of papers that talk about performance of different architectures never actually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=1714" target="_blank">00:28:34.760</a></span> | <span class="t">time how long it takes to run a batch through it. They literally say this one requires x</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=1722" target="_blank">00:28:42.960</a></span> | <span class="t">number of floating-point operations per batch, but then they never actually bother to run</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=1728" target="_blank">00:28:48.160</a></span> | <span class="t">the damn thing like a proper experimentalist and find out whether it's faster or slower.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=1733" target="_blank">00:28:53.000</a></span> | <span class="t">And so a lot of the architectures that are really famous now turn out to be slowest molasses</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=1739" target="_blank">00:28:59.440</a></span> | <span class="t">and take craploads of memory and just totally useless because the researchers never actually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=1746" target="_blank">00:29:06.200</a></span> | <span class="t">bother to see whether they're fast and to actually see whether they fit in RAM with</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=1749" target="_blank">00:29:09.880</a></span> | <span class="t">normal batch sizes. So the wide resnet paper is unusual in that it actually times how long</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=1757" target="_blank">00:29:17.280</a></span> | <span class="t">it takes, as does the YOLO version 3 paper, which made the same insight. I'm not sure</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=1762" target="_blank">00:29:22.560</a></span> | <span class="t">they might have missed the wide resnets paper because the YOLO version 3 paper came to a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=1767" target="_blank">00:29:27.000</a></span> | <span class="t">lot of the same conclusions, but I'm not even sure they cited the wide resnets paper, so</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=1772" target="_blank">00:29:32.120</a></span> | <span class="t">they might not be aware that all that work's been done. But they're both great to see people</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=1778" target="_blank">00:29:38.640</a></span> | <span class="t">actually timing things and noticing what actually makes sense.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=1783" target="_blank">00:29:43.280</a></span> | <span class="t">Yes, Rich?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=1785" target="_blank">00:29:45.720</a></span> | <span class="t">Cellu looked really hot in the paper which came out, but I noticed that you don't use</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=1789" target="_blank">00:29:49.240</a></span> | <span class="t">it. What's your opinion on Cellu?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=1792" target="_blank">00:29:52.600</a></span> | <span class="t">So Cellu is something largely for fully connected layers which allows you to get rid of batch</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=1799" target="_blank">00:29:59.840</a></span> | <span class="t">norm, and the basic idea is that if you use this different activation function, it's kind</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=1806" target="_blank">00:30:06.040</a></span> | <span class="t">of self-normalizing. That's what the S in Cellu stands for. So self-normalizing means that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=1812" target="_blank">00:30:12.440</a></span> | <span class="t">it will always remain at a unit standard deviation and zero mean, and therefore you don't need</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=1816" target="_blank">00:30:16.760</a></span> | <span class="t">that batch norm. It hasn't really gone anywhere, and the reason it hasn't really gone anywhere</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=1823" target="_blank">00:30:23.040</a></span> | <span class="t">is because it's incredibly finicky. You have to use a very specific initialization, otherwise</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=1828" target="_blank">00:30:28.680</a></span> | <span class="t">it doesn't start with exactly the right standard deviation of mean. It's very hard to use it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=1835" target="_blank">00:30:35.680</a></span> | <span class="t">with things like embeddings. If you do, then you have to use a particular kind of embedding</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=1840" target="_blank">00:30:40.320</a></span> | <span class="t">initialization which doesn't necessarily actually make sense for embeddings.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=1846" target="_blank">00:30:46.280</a></span> | <span class="t">You do all this work very hard to get it right, and if you do finally get it right, what's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=1852" target="_blank">00:30:52.040</a></span> | <span class="t">the point where you've managed to get rid of some batch norm layers which weren't really</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=1856" target="_blank">00:30:56.160</a></span> | <span class="t">hurting you anyway. It's interesting because that paper, that Cellu paper, I think one</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=1861" target="_blank">00:31:01.360</a></span> | <span class="t">of the reasons people noticed it, or in my experience the main reason people noticed</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=1865" target="_blank">00:31:05.120</a></span> | <span class="t">it was because it was created by the inventor of LSTMs, and also it had a huge mathematical</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=1870" target="_blank">00:31:10.800</a></span> | <span class="t">appendix and people were like "Lots of maths from a famous guy, this must be great!" But</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=1877" target="_blank">00:31:17.480</a></span> | <span class="t">in practice I don't see anybody using it to get any state-of-the-art results or win any</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=1883" target="_blank">00:31:23.880</a></span> | <span class="t">competitions or anything like that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=1890" target="_blank">00:31:30.240</a></span> | <span class="t">This is some of the tiniest bits of code we've seen, but there's so much here and it's fascinating</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=1894" target="_blank">00:31:34.080</a></span> | <span class="t">to play with. Now we've got this block which is built on this block, and then we're going</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=1900" target="_blank">00:31:40.280</a></span> | <span class="t">to create another block on top of that block. We're going to call this a group layer, and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=1907" target="_blank">00:31:47.680</a></span> | <span class="t">it's going to contain a bunch of res layers. A group layer is going to have some number</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=1915" target="_blank">00:31:55.680</a></span> | <span class="t">of channels or filters coming in, and what we're going to do is we're going to double</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=1924" target="_blank">00:32:04.360</a></span> | <span class="t">the number of channels coming in by just using a standard conv layer. Optionally, we'll halve</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=1931" target="_blank">00:32:11.960</a></span> | <span class="t">the grid size by using a stride of 2, and then we're going to do a whole bunch of res blocks,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=1940" target="_blank">00:32:20.600</a></span> | <span class="t">a whole bunch of res layers. We can pick how many. That could be 2 or 3 or 8. Because remember,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=1946" target="_blank">00:32:26.560</a></span> | <span class="t">these res layers don't change the grid size and they don't change the number of channels.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=1951" target="_blank">00:32:31.840</a></span> | <span class="t">You can add as many as you like, anywhere you like, without causing any problems. It's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=1957" target="_blank">00:32:37.200</a></span> | <span class="t">just going to use more computation and more RAM, but there's no reason other than that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=1962" target="_blank">00:32:42.600</a></span> | <span class="t">you can't add as many as you like. A group layer, therefore, is going to end up doubling</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=1969" target="_blank">00:32:49.720</a></span> | <span class="t">the number of channels because it's this initial convolution which doubles the number of channels.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=1978" target="_blank">00:32:58.560</a></span> | <span class="t">And depending on what we pass in a stride, it may also halve the grid size if we put</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=1983" target="_blank">00:33:03.560</a></span> | <span class="t">stride=2. And then we can do a whole bunch of res block computations as many as we like.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=1993" target="_blank">00:33:13.960</a></span> | <span class="t">So then to define our dark net, or whatever we want to call this thing, we're just going</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=2001" target="_blank">00:33:21.240</a></span> | <span class="t">to pass in something that looks like this. And what this says is, create 5 group layers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=2010" target="_blank">00:33:30.400</a></span> | <span class="t">The first one will contain 1 of these extra res layers. The second will contain 2, then</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=2016" target="_blank">00:33:36.400</a></span> | <span class="t">4, then 6, then 3. And I want you to start with 32 filters.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=2027" target="_blank">00:33:47.560</a></span> | <span class="t">So the first one of these res layers will contain 32 filters, and there will just be</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=2037" target="_blank">00:33:57.100</a></span> | <span class="t">one extra res layer. The second one is going to double the number of filters because that's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=2043" target="_blank">00:34:03.280</a></span> | <span class="t">what we do. Each time we have a new group layer, we double the number. So the second</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=2046" target="_blank">00:34:06.600</a></span> | <span class="t">one will have 64, then 128, then 256, then 512, and then that will be it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=2054" target="_blank">00:34:14.660</a></span> | <span class="t">So nearly all of the network is going to be those bunches of layers. And remember, every</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=2060" target="_blank">00:34:20.840</a></span> | <span class="t">one of those group layers also has one convolution of the start. And so then all we have is before</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=2069" target="_blank">00:34:29.360</a></span> | <span class="t">that all happens, we're going to have one convolutional layer at the very start, and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=2075" target="_blank">00:34:35.640</a></span> | <span class="t">at the very end we're going to do our standard adaptive average pooling, flatten, and a linear</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=2081" target="_blank">00:34:41.360</a></span> | <span class="t">layer to create the number of classes out at the end.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=2085" target="_blank">00:34:45.060</a></span> | <span class="t">So one convolution at the end, adaptive pooling, and one linear layer at the other end, and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=2091" target="_blank">00:34:51.480</a></span> | <span class="t">then in the middle, these group layers, each one consisting of a convolutional layer followed</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=2097" target="_blank">00:34:57.680</a></span> | <span class="t">by n number of res layers. And that's it. Again, I think we've mentioned this a few</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=2104" target="_blank">00:35:04.840</a></span> | <span class="t">times, but I'm yet to see any code out there, any examples, anything anywhere that uses</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=2114" target="_blank">00:35:14.200</a></span> | <span class="t">adaptive average pooling. Everyone I've seen writes it like this, and then bits a particular</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=2121" target="_blank">00:35:21.240</a></span> | <span class="t">number here, which means that it's now tied to a particular image size, which definitely</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=2126" target="_blank">00:35:26.280</a></span> | <span class="t">isn't what you want. So most people, even the top researchers I speak to, most of them</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=2131" target="_blank">00:35:31.640</a></span> | <span class="t">are still under the impression that a specific architecture is tied to a specific size, and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=2138" target="_blank">00:35:38.900</a></span> | <span class="t">that's a huge problem when people think that because it really limits their ability to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=2144" target="_blank">00:35:44.520</a></span> | <span class="t">use smaller sizes to kind of kickstart their modeling or to use smaller sizes for doing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=2148" target="_blank">00:35:48.840</a></span> | <span class="t">experiments and stuff like that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=2151" target="_blank">00:35:51.840</a></span> | <span class="t">Again, you'll notice I'm using sequential here, but a nice way to create architectures</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=2158" target="_blank">00:35:58.240</a></span> | <span class="t">is to start out by creating a list. In this case, this is a list with just one conv layer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=2162" target="_blank">00:36:02.040</a></span> | <span class="t">in, and then my function here, make_group_layer, it just returns another list. So then I can</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=2168" target="_blank">00:36:08.920</a></span> | <span class="t">just go plus equals, appending that list to the previous list, and then I can go plus equals</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=2174" target="_blank">00:36:14.600</a></span> | <span class="t">to append this bunch of things to that list, and then finally sequential of all those layers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=2180" target="_blank">00:36:20.360</a></span> | <span class="t">So that's a very nice thing. So now my forward is just self.layers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=2185" target="_blank">00:36:25.360</a></span> | <span class="t">So this is a nice kind of picture of how to make your architectures as simple as possible.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=2192" target="_blank">00:36:32.720</a></span> | <span class="t">So you can now go ahead and create this, and as I say, you can fiddle around. You could</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=2198" target="_blank">00:36:38.520</a></span> | <span class="t">even parameterize this to make it a number that you pass in here, to pass in different</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=2203" target="_blank">00:36:43.720</a></span> | <span class="t">numbers so it's not 2, maybe it's times 2 instead. You could pass in things that change</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=2208" target="_blank">00:36:48.920</a></span> | <span class="t">the kernel size or change the number of conv layers, fiddle around with it, and maybe you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=2213" target="_blank">00:36:53.880</a></span> | <span class="t">can create something -- I've actually got a version of this which I'm about to run for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=2218" target="_blank">00:36:58.600</a></span> | <span class="t">you -- which kind of implements all of the different parameters that's in that wide ResNet</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=2224" target="_blank">00:37:04.760</a></span> | <span class="t">paper, so I could fiddle around to see what worked well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=2229" target="_blank">00:37:09.220</a></span> | <span class="t">So once we've got that, we can use conv_learner from model_data to take our pytorch_model module</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=2235" target="_blank">00:37:15.560</a></span> | <span class="t">and the model_data object and turn them into a learner, give it a criterion, add some metrics</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=2241" target="_blank">00:37:21.600</a></span> | <span class="t">if we like, and then we can call fit and away we go.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=2246" target="_blank">00:37:26.480</a></span> | <span class="t">Could you please explain adaptive average pooling? How does setting to one work?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=2251" target="_blank">00:37:31.560</a></span> | <span class="t">Sure. Before I do, since we've only got a certain amount of time in this class, I do</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=2265" target="_blank">00:37:45.160</a></span> | <span class="t">want to see how we go with this simple network against these state-of-the-art results. So</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=2274" target="_blank">00:37:54.120</a></span> | <span class="t">to make life a little easier, we can start it running now and see how it looks later.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=2279" target="_blank">00:37:59.240</a></span> | <span class="t">So I've got the command ready to go. So we've basically taken all that stuff and put it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=2285" target="_blank">00:38:05.160</a></span> | <span class="t">into a simple little Python script, and I've modified some of those parameters I mentioned</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=2290" target="_blank">00:38:10.280</a></span> | <span class="t">to create something I've called a WRN22 network, which doesn't officially exist, but it's got</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=2295" target="_blank">00:38:15.080</a></span> | <span class="t">a bunch of changes to the parameters we talked about based on my experiments.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=2300" target="_blank">00:38:20.280</a></span> | <span class="t">We're going to use the new Leslie Smith one-cycle thing. So there's quite a bunch of cool stuff</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=2306" target="_blank">00:38:26.560</a></span> | <span class="t">here. So the one-cycle implementation was done by our student, Sylvain Gugge, the trained</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=2315" target="_blank">00:38:35.640</a></span> | <span class="t">sci-fi experiments were largely done by Brett Coons, and stuff like getting the half-position</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=2322" target="_blank">00:38:42.040</a></span> | <span class="t">floating-point implementation integrated into fast.ai was done by Andrew Shaw. So it's been</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=2329" target="_blank">00:38:49.120</a></span> | <span class="t">a cool bunch of different student projects coming together to allow us to run this. So</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=2335" target="_blank">00:38:55.240</a></span> | <span class="t">this is going to run actually on an AWS, Amazon AWS P3, which has eight GPUs. The P3 has these</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=2344" target="_blank">00:39:04.280</a></span> | <span class="t">newer Volta architecture GPUs, which actually have special support for half-position floating</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=2350" target="_blank">00:39:10.440</a></span> | <span class="t">point. Fast.ai is the first library I know of to actually integrate the Volta-optimized</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=2358" target="_blank">00:39:18.280</a></span> | <span class="t">half-position floating point into the library, so we can just go learn.half now and get that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=2363" target="_blank">00:39:23.600</a></span> | <span class="t">support automatically. And it's also the first one to integrate one-cycle, so these are the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=2370" target="_blank">00:39:30.160</a></span> | <span class="t">parameters for the one-cycle. So we can go ahead and get this running. So what this actually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=2376" target="_blank">00:39:36.840</a></span> | <span class="t">does is it's using PyTorch's multi-GPU support. Since there are eight GPUs, it's actually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=2383" target="_blank">00:39:43.800</a></span> | <span class="t">going to fire off eight separate Python processes, and each one's going to train on a little</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=2389" target="_blank">00:39:49.640</a></span> | <span class="t">bit, and then at the end it's going to pass the gradient updates back to the master process</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=2396" target="_blank">00:39:56.760</a></span> | <span class="t">that's going to integrate them all together. So you'll see, here they are, lots of progress</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=2404" target="_blank">00:40:04.600</a></span> | <span class="t">bars all pop up together. And you can see it's training three or four seconds when you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=2412" target="_blank">00:40:12.800</a></span> | <span class="t">do it this way. When I was training earlier, I was getting about 30 seconds per epoch. So</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=2426" target="_blank">00:40:26.240</a></span> | <span class="t">doing it this way, we can kind of train things like 10 times faster or so, which is pretty</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=2432" target="_blank">00:40:32.440</a></span> | <span class="t">cool.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=2433" target="_blank">00:40:33.440</a></span> | <span class="t">Okay, so we'll leave that running. So you were asking about adaptive average pooling,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=2438" target="_blank">00:40:38.740</a></span> | <span class="t">and I think specifically what's the number 1 doing? So normally when we're doing average</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=2449" target="_blank">00:40:49.960</a></span> | <span class="t">pooling, let's say we've got 4x4. Let's say we did average pooling 2, 2. Then that creates</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=2466" target="_blank">00:41:06.440</a></span> | <span class="t">a 2x2 area and takes the average of those 4, and then we can pass in the stride. So if</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=2482" target="_blank">00:41:22.200</a></span> | <span class="t">we said stride 1, then the next one is we would look at this block of 2x2 and take that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=2487" target="_blank">00:41:27.480</a></span> | <span class="t">average, and so forth. So that's what a normal 2x2 average pooling would be.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=2495" target="_blank">00:41:35.320</a></span> | <span class="t">And so in that case, if we didn't have any padding, that would spit out a 3x3, because</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=2502" target="_blank">00:41:42.640</a></span> | <span class="t">it's 2 here, 2 here, 2 here. And if we added padding, we can make it 4x4. So if we wanted</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=2512" target="_blank">00:41:52.680</a></span> | <span class="t">to spit out something, we didn't want 3x3, what if we wanted 1x1? Then we could say average</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=2519" target="_blank">00:41:59.480</a></span> | <span class="t">pool 4, 4. And so that's going to do 4, 4, and average the whole lot. And that would spit</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=2533" target="_blank">00:42:13.320</a></span> | <span class="t">out 1x1.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=2537" target="_blank">00:42:17.360</a></span> | <span class="t">But that's just one way to do it. Rather than saying the size of the pooling filter, why</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=2545" target="_blank">00:42:25.800</a></span> | <span class="t">don't we instead say, I don't care what the size of the input grid is, I always want 1x1.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=2552" target="_blank">00:42:32.880</a></span> | <span class="t">So that's where then you say "adaptive average pool", and now you don't say what's the size</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=2561" target="_blank">00:42:41.320</a></span> | <span class="t">of the pooling filter, you instead say what's the size of the output I want. And so I want</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=2565" target="_blank">00:42:45.920</a></span> | <span class="t">something that's 1x1. And if you only put a single int, it assumes you mean 1x1. So in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=2572" target="_blank">00:42:52.320</a></span> | <span class="t">this case, adaptive average pooling 1 with a 4x4 grid coming in is the same as average</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=2580" target="_blank">00:43:00.200</a></span> | <span class="t">pooling 4, 4. If it was a 7x7 grid coming in, it would be the same as 7, 7.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=2586" target="_blank">00:43:06.880</a></span> | <span class="t">So it's the same operation, it's just expressing it in a way that says regardless of the input,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=2591" target="_blank">00:43:11.500</a></span> | <span class="t">I want something of that size to output.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=2606" target="_blank">00:43:26.840</a></span> | <span class="t">We got to 94, and it took 3 minutes and 11 seconds, and the previous state-of-the-art</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=2614" target="_blank">00:43:34.120</a></span> | <span class="t">was 1 hour and 7 minutes. So was it worth fiddling around with those parameters and learning</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=2620" target="_blank">00:43:40.060</a></span> | <span class="t">a little bit about how these architectures actually work and not just using what came</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=2623" target="_blank">00:43:43.280</a></span> | <span class="t">out of the box? Well, holy shit, we just used a publicly available instance. We used a spot</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=2629" target="_blank">00:43:49.760</a></span> | <span class="t">instance so that cost us $8 per hour for 3 minutes. It cost us a few cents to train this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=2640" target="_blank">00:44:00.800</a></span> | <span class="t">from scratch 20 times faster than anybody's ever done it before.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=2646" target="_blank">00:44:06.960</a></span> | <span class="t">So that's like the most crazy state-of-the-art result we've ever seen, but this one just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=2652" target="_blank">00:44:12.680</a></span> | <span class="t">blew it out of the water. This is partly thanks to just fiddling around with those parameters</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=2661" target="_blank">00:44:21.440</a></span> | <span class="t">of the architecture. Mainly, frankly, about using Leslie Smith's one-cycle thing and Zulma's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=2668" target="_blank">00:44:28.360</a></span> | <span class="t">implementation of that. Remember, not only a reminder of what that's doing, it's basically</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=2676" target="_blank">00:44:36.040</a></span> | <span class="t">saying this is batches, and this is learning rate. It creates an upward path that's equally</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=2690" target="_blank">00:44:50.360</a></span> | <span class="t">long as the downward path, so it's a true C-L-R, triangular, cyclical learning rate.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=2697" target="_blank">00:44:57.520</a></span> | <span class="t">As per usual, you can pick the ratio between those two numbers. So x divided by y in this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=2706" target="_blank">00:45:06.720</a></span> | <span class="t">case is the number that you get to pick. In this case, we picked 50, so we started out</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=2716" target="_blank">00:45:16.520</a></span> | <span class="t">with a much smaller one here. And then it's got this cool idea which is you get to say</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=2722" target="_blank">00:45:22.360</a></span> | <span class="t">what percentage of your epochs then is spent going from the bottom of this down all the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=2728" target="_blank">00:45:28.120</a></span> | <span class="t">way down pretty much to zero. That's what this second number here is. So 15% of the batches</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=2734" target="_blank">00:45:34.720</a></span> | <span class="t">is spent going from the bottom of our triangle even further.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=2742" target="_blank">00:45:42.720</a></span> | <span class="t">So importantly though, that's not the only thing one cycle does. We also have momentum,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=2750" target="_blank">00:45:50.960</a></span> | <span class="t">and momentum goes from 0.95 to 0.85 like this. In other words, when the learning rate is really</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=2768" target="_blank">00:46:08.040</a></span> | <span class="t">low, we use a lot of momentum, and when the learning rate is really high, we use very</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=2771" target="_blank">00:46:11.720</a></span> | <span class="t">little momentum, which makes a lot of sense. But until Leslie Smith showed this in that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=2776" target="_blank">00:46:16.160</a></span> | <span class="t">paper, I've never seen anybody do it before, so it's a really cool trick.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=2783" target="_blank">00:46:23.520</a></span> | <span class="t">You can now use that by using the useCLRbeta parameter in fast.ai, and you should be able</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=2790" target="_blank">00:46:30.840</a></span> | <span class="t">to basically replicate this state-of-the-art result. You can use it on your own computer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=2796" target="_blank">00:46:36.280</a></span> | <span class="t">or your paper space. Obviously the only thing you won't get is the multi-GPU piece, but</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=2800" target="_blank">00:46:40.920</a></span> | <span class="t">that makes it a bit easier to train. So on a single GPU, you should be able to beat this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=2810" target="_blank">00:46:50.440</a></span> | <span class="t">on a single GPU.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=2813" target="_blank">00:46:53.560</a></span> | <span class="t">Make group layer contains stride=2, so this means stride is 1 for layer 1 and 2 for everything</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=2820" target="_blank">00:47:00.360</a></span> | <span class="t">else. What's the logic behind it? Usually the strides I've seen are odd.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=2828" target="_blank">00:47:08.920</a></span> | <span class="t">Strides are either 1 or 2, I think you're thinking of kernel sizes. So stride=2 means</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=2834" target="_blank">00:47:14.280</a></span> | <span class="t">that I jump 2 across, and so a stride of 2 means that you halve your grid size. I think</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=2840" target="_blank">00:47:20.000</a></span> | <span class="t">you might have got confused between stride and kernel size there. If we have a stride</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=2847" target="_blank">00:47:27.120</a></span> | <span class="t">of 1, the grid size doesn't change. If we have a stride of 2, then it does. In this case,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=2855" target="_blank">00:47:35.140</a></span> | <span class="t">this is for sci-fi 10. 32x32 is small, and we don't get to halve the grid size very often,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=2862" target="_blank">00:47:42.100</a></span> | <span class="t">because pretty quickly we're going to run out of cells. That's why the first layer has</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=2870" target="_blank">00:47:50.960</a></span> | <span class="t">a stride of 1, so we don't decrease the grid size straight away, basically. It's kind of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=2879" target="_blank">00:47:59.400</a></span> | <span class="t">a nice way of doing it, because that's why we have a low number here, so we can start</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=2885" target="_blank">00:48:05.520</a></span> | <span class="t">out with not too much computation on the big grid, and then we can gradually do more and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=2892" target="_blank">00:48:12.120</a></span> | <span class="t">more computation as the grids get smaller and smaller. Because the smaller grid the computation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=2897" target="_blank">00:48:17.800</a></span> | <span class="t">will take less time. I think so that we can do all of our scanning</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=2910" target="_blank">00:48:30.340</a></span> | <span class="t">in one go. Let's take a slightly early break and come back at 7.30.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=2930" target="_blank">00:48:50.400</a></span> | <span class="t">So we're going to talk about generative adversarial networks, also known as GANs, and specifically</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=2937" target="_blank">00:48:57.280</a></span> | <span class="t">we're going to focus on the Wasserstein GAN paper, which included some guy called Sumith</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=2944" target="_blank">00:49:04.400</a></span> | <span class="t">Chintala, who went on to create some piece of software called HiTorch. The Wasserstein</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=2951" target="_blank">00:49:11.440</a></span> | <span class="t">GAN was heavily influenced by the - so I'm just going to call this WGAN, that's the time</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=2955" target="_blank">00:49:15.840</a></span> | <span class="t">- the DC GAN, or deep convolutional generative adversarial networks paper, which also Sumith</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=2962" target="_blank">00:49:22.320</a></span> | <span class="t">was involved with. It's a really interesting paper to read. A lot of it looks like this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=2979" target="_blank">00:49:39.240</a></span> | <span class="t">The good news is you can skip those bits, because there's also a bit that looks like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=2985" target="_blank">00:49:45.360</a></span> | <span class="t">this which says do these things. Now I will say though that a lot of papers have a theoretical</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=2995" target="_blank">00:49:55.500</a></span> | <span class="t">section which seems to be there entirely to get past the reviewer's need for theory. That's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=3003" target="_blank">00:50:03.220</a></span> | <span class="t">not true of the WGAN paper. The theory bit is actually really interesting. You don't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=3008" target="_blank">00:50:08.060</a></span> | <span class="t">need to know it to use it, but if you want to learn about some cool ideas and see the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=3014" target="_blank">00:50:14.600</a></span> | <span class="t">thinking behind why this particular algorithm, it's absolutely fascinating. Before this paper</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=3022" target="_blank">00:50:22.720</a></span> | <span class="t">came out, I didn't know literally I knew nobody who had studied the math that it's based on,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=3028" target="_blank">00:50:28.760</a></span> | <span class="t">so everybody had to learn the math it was based on. The paper does a pretty good job</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=3033" target="_blank">00:50:33.520</a></span> | <span class="t">of laying out all the pieces. You'll have to do a bunch of reading yourself. If you're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=3039" target="_blank">00:50:39.000</a></span> | <span class="t">interested in digging into the deeper math behind some paper to see what it's like to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=3046" target="_blank">00:50:46.240</a></span> | <span class="t">study it, I would pick this one. Because at the end of that theory section, you'll come</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=3051" target="_blank">00:50:51.520</a></span> | <span class="t">away saying, okay, I can see now why they made this algorithm the way it is. And then</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=3061" target="_blank">00:51:01.600</a></span> | <span class="t">having come up with that idea, the other thing is often these theoretical sections are very</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=3065" target="_blank">00:51:05.560</a></span> | <span class="t">clearly added after they come up with the algorithm. They'll come up with the algorithm</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=3069" target="_blank">00:51:09.020</a></span> | <span class="t">based on intuition and experiments, and then later on post-hoc justify it. Whereas this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=3074" target="_blank">00:51:14.280</a></span> | <span class="t">one you can clearly see it's like, okay, let's actually think about what's going on in GANs</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=3079" target="_blank">00:51:19.720</a></span> | <span class="t">and think about what they need to do and then come up with the algorithm.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=3084" target="_blank">00:51:24.280</a></span> | <span class="t">So the basic idea of a GAN is it's a generative model. So it's something that is going to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=3091" target="_blank">00:51:31.880</a></span> | <span class="t">create sentences or create images. It's going to generate stuff. And it's going to try and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=3102" target="_blank">00:51:42.400</a></span> | <span class="t">create stuff which is very hard to tell the difference between generated stuff and real</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=3109" target="_blank">00:51:49.480</a></span> | <span class="t">stuff. So a generative model could be used to face-swap a video, a very well-known controversial</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=3118" target="_blank">00:51:58.600</a></span> | <span class="t">thing of deep fakes and fake pornography and stuff happening at the moment. It could be</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=3124" target="_blank">00:52:04.360</a></span> | <span class="t">used to fake somebody's voice. It could be used to fake the answer to a medical question.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=3133" target="_blank">00:52:13.640</a></span> | <span class="t">But in that case, it's not really a fake. It could be a generative answer to a medical</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=3138" target="_blank">00:52:18.080</a></span> | <span class="t">question that's actually a good answer. So you're generating language. You could generate</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=3143" target="_blank">00:52:23.200</a></span> | <span class="t">a caption to an image, for example. So generative models have lots of interesting applications.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=3155" target="_blank">00:52:35.920</a></span> | <span class="t">But generally speaking, they need to be good enough that, for example, if you're using</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=3161" target="_blank">00:52:41.240</a></span> | <span class="t">it to automatically create a new scene for Carrie Fisher in the next Star Wars movies</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=3168" target="_blank">00:52:48.640</a></span> | <span class="t">and she's not around to play that part anymore, you want to try and generate an image of her</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=3174" target="_blank">00:52:54.580</a></span> | <span class="t">that looks the same, then it has to fool the Star Wars audience into thinking that doesn't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=3180" target="_blank">00:53:00.400</a></span> | <span class="t">look like some weird Carrie Fisher, that looks like the real Carrie Fisher. Or if you're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=3185" target="_blank">00:53:05.680</a></span> | <span class="t">trying to generate an answer to a medical question, you want to generate English that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=3190" target="_blank">00:53:10.680</a></span> | <span class="t">reads nicely and clearly and sounds authoritative and meaningful. So the idea of a generative</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=3199" target="_blank">00:53:19.320</a></span> | <span class="t">adversarial network is we're going to create not just a generative model to create, say,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=3207" target="_blank">00:53:27.140</a></span> | <span class="t">the generated image, but a second model that's going to try to pick which ones are real and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=3213" target="_blank">00:53:33.600</a></span> | <span class="t">which ones are generated. We're going to call them fake. So which ones are real and which</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=3218" target="_blank">00:53:38.360</a></span> | <span class="t">ones are fake? So we've got a generator that's going to create our fake content and a discriminator</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=3225" target="_blank">00:53:45.500</a></span> | <span class="t">that's going to try to get good at recognizing which ones are real and which ones are fake.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=3230" target="_blank">00:53:50.400</a></span> | <span class="t">So there's going to be two models. And then there's going to be adversarial, meaning the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=3233" target="_blank">00:53:53.960</a></span> | <span class="t">generator is going to try to keep getting better at fooling the discriminator into thinking</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=3239" target="_blank">00:53:59.580</a></span> | <span class="t">that fake is real, and the discriminator is going to try to keep getting better at discriminating</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=3244" target="_blank">00:54:04.320</a></span> | <span class="t">between the real and the fake. And they're going to go head-to-head, like that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=3249" target="_blank">00:54:09.640</a></span> | <span class="t">And it's basically as easy as I just described. It really is. We're just going to build two</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=3256" target="_blank">00:54:16.640</a></span> | <span class="t">models in PyTorch. We're going to create a training loop that first of all says the loss</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=3262" target="_blank">00:54:22.440</a></span> | <span class="t">function for the discriminator is can you tell the difference between real and fake,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=3266" target="_blank">00:54:26.400</a></span> | <span class="t">and then update the weights of that. And then we're going to create a loss function for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=3269" target="_blank">00:54:29.880</a></span> | <span class="t">the generator, which is going to say can you generate something which pulls the discriminator</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=3274" target="_blank">00:54:34.560</a></span> | <span class="t">and update the weights from that loss. And we're going to look through that a few times</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=3278" target="_blank">00:54:38.960</a></span> | <span class="t">and see what happens.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=3280" target="_blank">00:54:40.840</a></span> | <span class="t">And so let's come back to the pseudocode here of the algorithm and let's read the real code</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=3287" target="_blank">00:54:47.760</a></span> | <span class="t">first.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=3292" target="_blank">00:54:52.560</a></span> | <span class="t">So there's lots of different things you can do with GANs. And we're going to do something</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=3297" target="_blank">00:54:57.640</a></span> | <span class="t">that's kind of boring but easy to understand, and it's kind of cool that it's even possible.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=3304" target="_blank">00:55:04.040</a></span> | <span class="t">We're just going to generate some pictures from nothing. We're just going to get it to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=3309" target="_blank">00:55:09.040</a></span> | <span class="t">draw some pictures. And specifically we're going to get it to draw pictures of bedrooms.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=3315" target="_blank">00:55:15.440</a></span> | <span class="t">You'll find if you hopefully get a chance to play around with this during the week with</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=3319" target="_blank">00:55:19.640</a></span> | <span class="t">your own datasets, if you pick a dataset that's very varied, like ImageNet, and then get a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=3326" target="_blank">00:55:26.040</a></span> | <span class="t">GAN to try and create ImageNet pictures, it tends not to do so well because it's not really</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=3332" target="_blank">00:55:32.720</a></span> | <span class="t">clear enough what you want a picture of.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=3335" target="_blank">00:55:35.640</a></span> | <span class="t">So it's better to give it, for example, there's a dataset called CelebA, which is pictures</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=3340" target="_blank">00:55:40.400</a></span> | <span class="t">of celebrity faces. That works great with GANs. You create really clear celebrity faces</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=3346" target="_blank">00:55:46.280</a></span> | <span class="t">that don't actually exist. The bedroom dataset, also a good one. Lots of pictures of the same</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=3351" target="_blank">00:55:51.560</a></span> | <span class="t">kind of thing. So that's just a suggestion.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=3355" target="_blank">00:55:55.660</a></span> | <span class="t">So there's something called the lsun_scene_classification_dataset. You can download it using these steps.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=3366" target="_blank">00:56:06.600</a></span> | <span class="t">It's pretty huge. So I've actually created a Kaggle dataset of a 20% sample. So unless</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=3373" target="_blank">00:56:13.320</a></span> | <span class="t">you're really excited about generating bedroom images, you might prefer to grab the 20% sample.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=3380" target="_blank">00:56:20.940</a></span> | <span class="t">So then we do the normal steps of creating some different paths. In this case, as we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=3387" target="_blank">00:56:27.320</a></span> | <span class="t">do before, I find it much easier to go the CSV route when it comes to handling our data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=3394" target="_blank">00:56:34.320</a></span> | <span class="t">So I just generate a CSV with the list of files that we want and a fake label that's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=3401" target="_blank">00:56:41.040</a></span> | <span class="t">zero because we don't really have labels for these at all.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=3405" target="_blank">00:56:45.120</a></span> | <span class="t">So I actually create two CSV files, one that contains everything in that bedroom dataset</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=3411" target="_blank">00:56:51.720</a></span> | <span class="t">and one that just contains a random 10%. It's just nice to do that because then I can most</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=3417" target="_blank">00:56:57.840</a></span> | <span class="t">of the time use the sample when I'm experimenting. Because there's well over a million files,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=3424" target="_blank">00:57:04.680</a></span> | <span class="t">even just reading in the list takes a while.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=3431" target="_blank">00:57:11.480</a></span> | <span class="t">So this will look pretty familiar. So here's a conv block. This is before I realized that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=3438" target="_blank">00:57:18.640</a></span> | <span class="t">sequential models are much better. So if you compare this to my previous conv block with</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=3443" target="_blank">00:57:23.320</a></span> | <span class="t">a sequential model, there's just a lot more lines of code here. But it does the same thing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=3450" target="_blank">00:57:30.240</a></span> | <span class="t">of doing conv value batch norm.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=3456" target="_blank">00:57:36.440</a></span> | <span class="t">And we calculate our padding, and here's a bias pulse. So this is the same as before</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=3460" target="_blank">00:57:40.360</a></span> | <span class="t">basically, but with a little bit more code.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=3468" target="_blank">00:57:48.520</a></span> | <span class="t">So the first thing we're going to do is build a discriminator. So a discriminator is going</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=3473" target="_blank">00:57:53.480</a></span> | <span class="t">to receive as input an image, and it's going to spit out a number. And the number is meant</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=3482" target="_blank">00:58:02.120</a></span> | <span class="t">to be lower if it thinks this image is real. Of course, what does it do for a lower number</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=3491" target="_blank">00:58:11.120</a></span> | <span class="t">thing doesn't appear in the architecture, that will be in the loss function. So all</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=3495" target="_blank">00:58:15.000</a></span> | <span class="t">we have to do is create something that takes an image and spits out a number.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=3503" target="_blank">00:58:23.560</a></span> | <span class="t">So a lot of this code is borrowed from the original authors of the paper, so some of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=3514" target="_blank">00:58:34.200</a></span> | <span class="t">the naming scheme and stuff is different to what we're used to. So sorry about that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=3523" target="_blank">00:58:43.600</a></span> | <span class="t">But I've tried to make it look at least somewhat familiar. I probably should have renamed things</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=3526" target="_blank">00:58:46.800</a></span> | <span class="t">a little bit. But it looks very similar to actually what we had before. We start out</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=3530" target="_blank">00:58:50.800</a></span> | <span class="t">with a convolution, so remember conv block is conv-relievational.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=3537" target="_blank">00:58:57.980</a></span> | <span class="t">And then we have a bunch of extra conv layers. This is not going to use a residual. It looks</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=3544" target="_blank">00:59:04.720</a></span> | <span class="t">very similar to before, a bunch of extra layers, but these are going to be conv layers rather</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=3548" target="_blank">00:59:08.280</a></span> | <span class="t">than res layers. And then at the end, we need to append enough stride 2 conv layers that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=3562" target="_blank">00:59:22.120</a></span> | <span class="t">we decrease the grid size down to be no bigger than 4x4. So it's going to keep using stride</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=3569" target="_blank">00:59:29.920</a></span> | <span class="t">2, divide the size by 2, stride 2, divide by size by 2, until our grid size is no bigger</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=3576" target="_blank">00:59:36.020</a></span> | <span class="t">than 4. So this is quite a nice way of creating as many layers as you need in a network to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=3582" target="_blank">00:59:42.240</a></span> | <span class="t">handle arbitrary sized images and turn them into a fixed known grid size.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=3586" target="_blank">00:59:46.960</a></span> | <span class="t">Yes, Rachel? Does a GAN need a lot more data than say dogs</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=3591" target="_blank">00:59:51.600</a></span> | <span class="t">versus cats or NLP, or is it comparable? Honestly, I'm kind of embarrassed to say</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=3598" target="_blank">00:59:58.880</a></span> | <span class="t">I am not an expert practitioner in GANs. The stuff I teach in part 1 is stuff I'm happy</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=3609" target="_blank">01:00:09.120</a></span> | <span class="t">to say I know the best way to do these things and so I can show you state-of-the-art results</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=3615" target="_blank">01:00:15.520</a></span> | <span class="t">like I just did with sci-fi 10 with the help of some of my students, of course. I'm not</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=3621" target="_blank">01:00:21.680</a></span> | <span class="t">there at all with GANs. So I'm not quite sure how much you need. In general, it seems you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=3629" target="_blank">01:00:29.760</a></span> | <span class="t">need quite a lot. But remember, the only reason we didn't need too much in dogs and cats is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=3635" target="_blank">01:00:35.920</a></span> | <span class="t">because we had a pre-trained model, and could we leverage pre-trained GAN models and fine-tune</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=3640" target="_blank">01:00:40.880</a></span> | <span class="t">them? Probably. I don't think anybody's done it as far as I know. That could be a really</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=3648" target="_blank">01:00:48.000</a></span> | <span class="t">interesting thing for people to kind of think about and experiment with. Maybe people have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=3652" target="_blank">01:00:52.120</a></span> | <span class="t">done it and there's some literature there I haven't come across. So I'm somewhat familiar</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=3657" target="_blank">01:00:57.120</a></span> | <span class="t">with the main pieces of literature in GANs, but I don't know all of it. So maybe I've</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=3663" target="_blank">01:01:03.040</a></span> | <span class="t">missed something about transfer learning in GANs, but that would be the trick to not needing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=3666" target="_blank">01:01:06.880</a></span> | <span class="t">too much data. So it's the huge speed-up combination of one cycle learning rate and momentum annealing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=3674" target="_blank">01:01:14.560</a></span> | <span class="t">plus the 8 GPU parallel training and the half precision. Is that only possible to do the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=3680" target="_blank">01:01:20.360</a></span> | <span class="t">half-precision calculation with consumer GPU? Another question, why is the calculation 8</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=3686" target="_blank">01:01:26.760</a></span> | <span class="t">times faster from single to half-precision while from double to single is only 2 times</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=3691" target="_blank">01:01:31.280</a></span> | <span class="t">faster?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=3692" target="_blank">01:01:32.280</a></span> | <span class="t">Okay, so the sci-fi 10 result, it's not 8 times faster from single to half. It's about</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=3699" target="_blank">01:01:39.160</a></span> | <span class="t">2 or 3 times as fast from single to half. The Nvidia claims about the flops performance</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=3706" target="_blank">01:01:46.400</a></span> | <span class="t">of the tensor cores are academically correct but in practice meaningless because it really</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=3714" target="_blank">01:01:54.000</a></span> | <span class="t">depends on what cores you need for what pieces. So about 2 or 3x improvement for half. So</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=3722" target="_blank">01:02:02.640</a></span> | <span class="t">the half-precision helps a bit, the extra GPU helps a bit, the one cycle helps an enormous</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=3730" target="_blank">01:02:10.720</a></span> | <span class="t">amount. Then another key piece was the playing around with the parameters that I told you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=3736" target="_blank">01:02:16.240</a></span> | <span class="t">about. So reading the wide resnet paper carefully, identifying the kinds of things that they</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=3743" target="_blank">01:02:23.040</a></span> | <span class="t">found there, and then writing a version of the architecture you just saw that made it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=3749" target="_blank">01:02:29.040</a></span> | <span class="t">really easy for me to fiddle around with parameters. Staying up all night trying every possible</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=3757" target="_blank">01:02:37.520</a></span> | <span class="t">combination of different kernel sizes and numbers of kernels and numbers of layer groups</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=3763" target="_blank">01:02:43.760</a></span> | <span class="t">and size of layer groups. Remember we did a bottleneck but actually we tended to focus</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=3771" target="_blank">01:02:51.560</a></span> | <span class="t">not on bottlenecks but instead on widening. So we actually like things that increase the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=3775" target="_blank">01:02:55.760</a></span> | <span class="t">size and then decrease it because it takes better advantage of the GPU. So all those</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=3781" target="_blank">01:03:01.000</a></span> | <span class="t">things combined together. I'd say the one cycle was perhaps the most critical but every</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=3787" target="_blank">01:03:07.840</a></span> | <span class="t">one of those resulted in a big speedup. That's why we were able to get this 30x improvement</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=3793" target="_blank">01:03:13.400</a></span> | <span class="t">over the state of the art. And we got some ideas for other things like after this Dawn</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=3804" target="_blank">01:03:24.000</a></span> | <span class="t">Bench finishes. Maybe we'll try and go even further and see if we can beat one minute</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=3808" target="_blank">01:03:28.880</a></span> | <span class="t">one day. That'll be fun.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=3817" target="_blank">01:03:37.480</a></span> | <span class="t">So here's our discriminator. The important thing to remember about an architecture is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=3822" target="_blank">01:03:42.080</a></span> | <span class="t">it doesn't do anything other than have some input tensor size and rank and some output</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=3828" target="_blank">01:03:48.080</a></span> | <span class="t">tensor size and rank. You see the last com here has one channel. This is a bit different</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=3835" target="_blank">01:03:55.840</a></span> | <span class="t">to what we're used to, because normally our last thing is a linear block. But our last</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=3840" target="_blank">01:04:00.960</a></span> | <span class="t">thing here is a com block. And it's only got one channel but it's got a grid size of something</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=3848" target="_blank">01:04:08.240</a></span> | <span class="t">around 4x4. So we're going to spit out a 4x4 by 1 tensor.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=3857" target="_blank">01:04:17.120</a></span> | <span class="t">So what we then do is we then take the mean of that. So it goes from 4x4 by 1 to the scalar.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=3867" target="_blank">01:04:27.980</a></span> | <span class="t">So this is kind of like the ultimate adaptive average pooling, because we've got something</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=3872" target="_blank">01:04:32.200</a></span> | <span class="t">with just one channel, we take the mean. So this is a bit different. Normally we first</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=3877" target="_blank">01:04:37.120</a></span> | <span class="t">do average pooling and then we put it through a fully connected layer to get our one thing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=3882" target="_blank">01:04:42.000</a></span> | <span class="t">out. In this case though we're getting one channel out and then taking the mean of that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=3888" target="_blank">01:04:48.720</a></span> | <span class="t">I haven't fiddled around with why did we do it that way, what would instead happen if</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=3893" target="_blank">01:04:53.160</a></span> | <span class="t">we did the usual average pooling followed by a fully connected layer. Would it work better?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=3898" target="_blank">01:04:58.560</a></span> | <span class="t">Would it not? I don't know. I rather suspect it would work better if we did it the normal</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=3904" target="_blank">01:05:04.960</a></span> | <span class="t">way, but I haven't tried it and I don't really have a good enough intuition to know whether</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=3910" target="_blank">01:05:10.400</a></span> | <span class="t">I'm missing something. It would be an interesting experiment to try. If somebody wants to stick</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=3914" target="_blank">01:05:14.640</a></span> | <span class="t">an adaptive average pooling layer here and a fully connected layer afterwards with a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=3917" target="_blank">01:05:17.880</a></span> | <span class="t">single output, it should keep working. It should do something. The loss will go down to see</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=3925" target="_blank">01:05:25.000</a></span> | <span class="t">whether it works.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=3927" target="_blank">01:05:27.320</a></span> | <span class="t">So that's the discriminator. There's going to be a training loop. Let's assume we've</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=3931" target="_blank">01:05:31.640</a></span> | <span class="t">already got a generator. Somebody says, "Okay Jeremy, here's a generator, it generates bedrooms.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=3937" target="_blank">01:05:37.760</a></span> | <span class="t">I want you to build a model that can figure out which ones are real and which ones aren't.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=3941" target="_blank">01:05:41.160</a></span> | <span class="t">So I'm going to take the data set and I'm going to basically label a bunch of images</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=3945" target="_blank">01:05:45.680</a></span> | <span class="t">which are fake bedrooms from the generator and a bunch of images of real bedrooms from</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=3950" target="_blank">01:05:50.040</a></span> | <span class="t">my else-on data set to stick a 1 or a 0 in each one and then I'll try to get the discriminator</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=3956" target="_blank">01:05:56.080</a></span> | <span class="t">to tell the difference. So that's going to be simple enough.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=3964" target="_blank">01:06:04.000</a></span> | <span class="t">But I haven't been given a generator, I need to build one. So a generator, and we haven't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=3969" target="_blank">01:06:09.880</a></span> | <span class="t">talked about the loss function yet. We're just going to assume there's some loss function</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=3973" target="_blank">01:06:13.400</a></span> | <span class="t">that does this thing. So a generator is also an architecture which doesn't do anything</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=3979" target="_blank">01:06:19.920</a></span> | <span class="t">by itself until we have a loss function and data. But what are the ranks and sizes of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=3985" target="_blank">01:06:25.560</a></span> | <span class="t">the tensors? The input to the generator is going to be a vector of random numbers. In</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=3994" target="_blank">01:06:34.480</a></span> | <span class="t">the paper, they call that the prior. It's going to be a vector of random numbers. How</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=3998" target="_blank">01:06:38.440</a></span> | <span class="t">big? I don't know. Some big. 64, 128. And the idea is that a different bunch of random numbers</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=4006" target="_blank">01:06:46.880</a></span> | <span class="t">will generate a different bedroom. So our generator has to take as input a vector, and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=4021" target="_blank">01:07:01.320</a></span> | <span class="t">it's going to take that vector, so here's our input, and it's going to stick it through,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=4026" target="_blank">01:07:06.200</a></span> | <span class="t">in this case a sequential model. And the sequential model is going to take that vector and it's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=4031" target="_blank">01:07:11.160</a></span> | <span class="t">going to turn it into a rank 4 tensor, or if we take off the batch bit, a rank 3 tensor,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=4046" target="_blank">01:07:26.520</a></span> | <span class="t">height by width by 3. So you can see at the end here, our final step here, NC, number of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=4060" target="_blank">01:07:40.440</a></span> | <span class="t">channels. So I think that's going to have to end up being 3 because we're going to create</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=4063" target="_blank">01:07:43.560</a></span> | <span class="t">a 3-channel image of some size.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=4068" target="_blank">01:07:48.800</a></span> | <span class="t">In com-block-forward, is there a reason why BatchNorm comes after ReLU, i.e. self.batchnorm.relu?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=4077" target="_blank">01:07:57.760</a></span> | <span class="t">No, there's not. It's just what they had in the code I borrowed from, I think.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=4085" target="_blank">01:08:05.240</a></span> | <span class="t">So again, unless my intuition about GANs is all wrong and for some reason needs to be</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=4097" target="_blank">01:08:17.280</a></span> | <span class="t">different to what I'm used to, I would normally expect to go ReLU then BatchNorm. This is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=4109" target="_blank">01:08:29.200</a></span> | <span class="t">actually the order that makes more sense to me. But I think the order I had in the darknet</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=4115" target="_blank">01:08:35.680</a></span> | <span class="t">was what they used in the darknet paper. Everybody seems to have a different order of these things.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=4125" target="_blank">01:08:45.200</a></span> | <span class="t">And in fact, most people for sci-fi 10 have a different order again, which is they actually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=4132" target="_blank">01:08:52.220</a></span> | <span class="t">go bn, then ReLU, then conv, which is kind of a quirky way of thinking about it. But</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=4142" target="_blank">01:09:02.160</a></span> | <span class="t">it turns out that often for residual blocks that works better. That's called a pre-activation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=4147" target="_blank">01:09:07.920</a></span> | <span class="t">resnet. So if you Google for pre-activation resnet, you can see that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=4153" target="_blank">01:09:13.520</a></span> | <span class="t">So yeah, there's not so much papers but more blog posts out there where people have experimented</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=4159" target="_blank">01:09:19.120</a></span> | <span class="t">with different orders of those things. And yeah, it seems to depend a lot on what specific</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=4165" target="_blank">01:09:25.200</a></span> | <span class="t">data set it is and what you're doing with, although in general the difference in performance</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=4169" target="_blank">01:09:29.940</a></span> | <span class="t">is small enough you won't care unless it's for a competition.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=4176" target="_blank">01:09:36.960</a></span> | <span class="t">So the generator needs to start with a vector and end up with a rank 3 tensor. We don't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=4185" target="_blank">01:09:45.040</a></span> | <span class="t">really know how to do that yet, so how do we do that? How do we start with a vector</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=4190" target="_blank">01:09:50.520</a></span> | <span class="t">and turn it into a rank 3 tensor?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=4192" target="_blank">01:09:52.880</a></span> | <span class="t">We need to use something called a deconvolution. And a deconvolution is, or as they call it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=4202" target="_blank">01:10:02.920</a></span> | <span class="t">in PyTorch, a transposed convolution. Same thing, different name. And so a deconvolution</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=4213" target="_blank">01:10:13.360</a></span> | <span class="t">is something which, rather than decreasing the grid size, it increases the grid size.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=4222" target="_blank">01:10:22.920</a></span> | <span class="t">So as with all things, it's easiest to see in an Excel spreadsheet.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=4228" target="_blank">01:10:28.780</a></span> | <span class="t">So here's a convolution. We start with a 4x4 grid cell with a single channel, a single filter.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=4238" target="_blank">01:10:38.240</a></span> | <span class="t">And let's put it through a 3x3 kernel again with a single output. So we've got a single</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=4246" target="_blank">01:10:46.820</a></span> | <span class="t">channel in, a single filter kernel. And so if we don't add any padding, we're going to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=4253" target="_blank">01:10:53.400</a></span> | <span class="t">end up with 2x2, because that 3x3 can go in 1, 2, 3, 4 places. It can go in one of two</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=4261" target="_blank">01:11:01.480</a></span> | <span class="t">places across and one of two places down if there's no padding.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=4266" target="_blank">01:11:06.880</a></span> | <span class="t">So there's our convolution. Remember the convolution is just the sum of the product of the kernel</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=4274" target="_blank">01:11:14.960</a></span> | <span class="t">and the appropriate grid cell. So there's our standard 3x3 on one channel, one filter.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=4285" target="_blank">01:11:25.440</a></span> | <span class="t">So the idea now is I want to go the opposite direction. I want to start with my 2x2, and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=4294" target="_blank">01:11:34.320</a></span> | <span class="t">I want to create a 4x4. And specifically, I want to create the same 4x4 that I started</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=4301" target="_blank">01:11:41.040</a></span> | <span class="t">with. And I want to do that by using a convolution.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=4305" target="_blank">01:11:45.840</a></span> | <span class="t">So how would I do that? Well, if I have a 3x3 convolution, then if I want to create</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=4311" target="_blank">01:11:51.200</a></span> | <span class="t">a 4x4 output, I'm going to need to create this much padding. Because with this much</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=4321" target="_blank">01:12:01.340</a></span> | <span class="t">padding, I'm going to end up with 1, 2, 3, 4 by 1, 2, 3, 4. You see why that is? So this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=4331" target="_blank">01:12:11.180</a></span> | <span class="t">filter can go in any one of four places across and four places up and down.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=4338" target="_blank">01:12:18.380</a></span> | <span class="t">So let's say my convolutional filter was just a bunch of zeros, then I can calculate my</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=4343" target="_blank">01:12:23.960</a></span> | <span class="t">error for each cell just by taking this attraction, and then I can get the sum of absolute values,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=4352" target="_blank">01:12:32.920</a></span> | <span class="t">the L1 loss, by just summing up the absolute values of those errors.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=4358" target="_blank">01:12:38.300</a></span> | <span class="t">So now I could use optimization. So in Excel, that's called Solver to do a gradient descent.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=4368" target="_blank">01:12:48.900</a></span> | <span class="t">So I'm going to set that cell equal to a minimum, and I'll try and reduce my loss by changing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=4376" target="_blank">01:12:56.380</a></span> | <span class="t">my filter, and I'll go Solve. And you can see it's come up with a filter such that 15.7</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=4385" target="_blank">01:13:05.420</a></span> | <span class="t">compared to 16, 17 is right, 17.8, 18, 19, so it's not perfect. And in general, you can't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=4392" target="_blank">01:13:12.540</a></span> | <span class="t">assume that a deconvolution can exactly create the exact thing that you want, because there's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=4401" target="_blank">01:13:21.220</a></span> | <span class="t">just not enough. There's only 9 things here, and there's 16 things you're trying to create.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=4406" target="_blank">01:13:26.500</a></span> | <span class="t">But it's made a pretty good attempt. So this is what a deconvolution looks like, a stride</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=4414" target="_blank">01:13:34.140</a></span> | <span class="t">1 3x3 deconvolution on a 2x2 grid cell input. How difficult is it to create a discriminator</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=4426" target="_blank">01:13:46.060</a></span> | <span class="t">to identify fake news versus real news? Well, you don't need anything special, that's just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=4433" target="_blank">01:13:53.220</a></span> | <span class="t">a classifier. So you would just use the NLP classifier from previous to previous class</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=4440" target="_blank">01:14:00.780</a></span> | <span class="t">and lesson 4. In that case, there's no generative piece, right? So you just need a dataset that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=4450" target="_blank">01:14:10.860</a></span> | <span class="t">says these are the things that we believe are fake news, and these are the things we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=4453" target="_blank">01:14:13.780</a></span> | <span class="t">consider to be real news. And it should actually work very well. To the best of my knowledge,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=4462" target="_blank">01:14:22.740</a></span> | <span class="t">if you try it, you should get as good a result as anybody else has got, whether it's good</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=4467" target="_blank">01:14:27.900</a></span> | <span class="t">enough to be useful to practice, I don't know. Oh, I was going to say that it's very hard</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=4472" target="_blank">01:14:32.580</a></span> | <span class="t">using the technique you've described. Very hard. There's not a good solution that does</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=4481" target="_blank">01:14:41.300</a></span> | <span class="t">that. Well, but I don't think anybody in our course has tried, and nobody else outside</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=4486" target="_blank">01:14:46.700</a></span> | <span class="t">our course knows of this technique. So there's been, as we've learned, we've just had a very</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=4493" target="_blank">01:14:53.500</a></span> | <span class="t">significant jump in NLP classification capabilities. Obviously the best you could do at this stage</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=4504" target="_blank">01:15:04.940</a></span> | <span class="t">would be to generate a triage that says these things look pretty sketchy based on how they're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=4513" target="_blank">01:15:13.340</a></span> | <span class="t">written and some human could go and fact check them. An NLP classifier and RNN can't fact</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=4520" target="_blank">01:15:20.680</a></span> | <span class="t">check things, but it could recognize like, oh, these are written in that kind of highly</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=4529" target="_blank">01:15:29.820</a></span> | <span class="t">popularized style which often fake news is written in, and so maybe these ones are worth</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=4534" target="_blank">01:15:34.540</a></span> | <span class="t">paying attention to. I think that would probably be the best you could hope for without drawing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=4541" target="_blank">01:15:41.460</a></span> | <span class="t">on some kind of external data sources.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=4544" target="_blank">01:15:44.380</a></span> | <span class="t">But it's important to remember that a discriminator is basically just a classifier and you don't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=4551" target="_blank">01:15:51.460</a></span> | <span class="t">need any special techniques beyond what we've already learnt to do NLP classification.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=4561" target="_blank">01:16:01.360</a></span> | <span class="t">So to do that kind of deconvolution in PyTorch, just say com_transport is 2D, and in the normal</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=4568" target="_blank">01:16:08.780</a></span> | <span class="t">way you say the number of input channels, the number of output channels, the kernel size,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=4574" target="_blank">01:16:14.500</a></span> | <span class="t">the stride, the padding, the bias, so these parameters are all the same. And the reason</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=4579" target="_blank">01:16:19.340</a></span> | <span class="t">it's called a com_transpose is because actually it turns out that this is the same as the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=4584" target="_blank">01:16:24.860</a></span> | <span class="t">calculation of the gradient of convolution. So this is a really nice example back on the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=4596" target="_blank">01:16:36.140</a></span> | <span class="t">old Theano website that comes from a really nice paper which actually shows you some visualizations.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=4602" target="_blank">01:16:42.740</a></span> | <span class="t">So this is actually the one we just saw of doing a 2x2 deconvolution. If there's a stride</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=4608" target="_blank">01:16:48.580</a></span> | <span class="t">2, then you don't just have padding around the outside, but you actually have to put</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=4612" target="_blank">01:16:52.460</a></span> | <span class="t">padding in the middle as well. They're not actually quite implemented this way because</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=4618" target="_blank">01:16:58.620</a></span> | <span class="t">this is slow to do. In practice they implement them a different way, but it all happens behind</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=4623" target="_blank">01:17:03.900</a></span> | <span class="t">the scenes, we don't have to worry about it. We've talked about this convolution arithmetic</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=4630" target="_blank">01:17:10.700</a></span> | <span class="t">tutorial before, and if you're still not comfortable with convolutions and in order to get comfortable</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=4636" target="_blank">01:17:16.580</a></span> | <span class="t">with deconvolutions, this is a great site to go to. If you want to see the paper, just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=4642" target="_blank">01:17:22.420</a></span> | <span class="t">Google for convolution arithmetic, that'll be the first thing that comes up. Let's do</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=4647" target="_blank">01:17:27.700</a></span> | <span class="t">it now so you know you've found it. Here it is. And so that Theano tutorial actually comes</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=4658" target="_blank">01:17:38.580</a></span> | <span class="t">from this paper. But the paper doesn't have the animated gifs.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=4668" target="_blank">01:17:48.700</a></span> | <span class="t">So it's interesting then. A deconv block looks identical to a conv block, except it's got</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=4673" target="_blank">01:17:53.000</a></span> | <span class="t">the word transpose written here. We just go conv-related batch norm as before, it's got</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=4678" target="_blank">01:17:58.220</a></span> | <span class="t">input filters, output filters. The only difference is that stride 2 means that the grid size</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=4686" target="_blank">01:18:06.580</a></span> | <span class="t">will double rather than half.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=4691" target="_blank">01:18:11.140</a></span> | <span class="t">Both nn_conf_transpose_2D and nn.upsample seem to do the same thing, i.e. expand grid size,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=4698" target="_blank">01:18:18.700</a></span> | <span class="t">height and width from the previous layer. Can we say that conv_transpose_2D is always better</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=4703" target="_blank">01:18:23.860</a></span> | <span class="t">than upsample, since upsample is merely resizing and filling unknowns by zeros or interpolation?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=4710" target="_blank">01:18:30.980</a></span> | <span class="t">No, you can't. So there's a fantastic interactive paper on distill.pub called Deconvolution</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=4732" target="_blank">01:18:52.340</a></span> | <span class="t">But the good news is everybody else does it. If you have a look here, can you see these</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=4741" target="_blank">01:19:01.460</a></span> | <span class="t">checkerboard artifacts? It's all like dark blue, light blue, dark blue, light blue. So</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=4747" target="_blank">01:19:07.620</a></span> | <span class="t">these are all from actual papers, right? Basically they noticed every one of these papers with</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=4753" target="_blank">01:19:13.860</a></span> | <span class="t">generative models has these checkerboard artifacts. And what they realized is it's because when</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=4760" target="_blank">01:19:20.820</a></span> | <span class="t">you have a stride 2 convolution of size 3 kernel, they overlap. And so you basically get like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=4770" target="_blank">01:19:30.580</a></span> | <span class="t">some pixels get twice as much, some grid cells get twice as much activation. And so even</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=4778" target="_blank">01:19:38.340</a></span> | <span class="t">if you start with random weights, you end up with a checkerboard artifact. So you can</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=4784" target="_blank">01:19:44.780</a></span> | <span class="t">kind of see it here. And so the deeper you get, the worse it gets. Their advice is actually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=4798" target="_blank">01:19:58.060</a></span> | <span class="t">less direct from it than it ought to be. I found that for most generative models, upsampling</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=4803" target="_blank">01:20:03.620</a></span> | <span class="t">is better. So if you do nn.upsample, then all it does is it's basically doing cooling.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=4813" target="_blank">01:20:13.300</a></span> | <span class="t">But it's kind of the opposite of cooling. It says let's replace this one pixel or this one</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=4820" target="_blank">01:20:20.100</a></span> | <span class="t">grid cell with 4, 2x2. And there's a number of ways to upsample. One is just to copy</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=4826" target="_blank">01:20:26.180</a></span> | <span class="t">it across to those 4. Another is to use bilinear or bicubic interpolation. There are various</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=4832" target="_blank">01:20:32.260</a></span> | <span class="t">techniques to try and create a smooth upsampled version, and you can pretty much choose any</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=4837" target="_blank">01:20:37.500</a></span> | <span class="t">of them in PyTorch. So if you do a 2x2 upsample and then a regular stride 1 3x3 conv, that's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=4848" target="_blank">01:20:48.180</a></span> | <span class="t">like another way of doing the same kind of thing as a conv transpose. It's doubling the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=4855" target="_blank">01:20:55.660</a></span> | <span class="t">grid size and doing some convolutional arithmetic on it. And I found for generative models it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=4864" target="_blank">01:21:04.020</a></span> | <span class="t">pretty much always works better. And in that distillator publication, they kind of indicate</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=4871" target="_blank">01:21:11.260</a></span> | <span class="t">that maybe that's a good approach, but they don't just come out and say just do this,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=4875" target="_blank">01:21:15.080</a></span> | <span class="t">whereas I would just say just do this. Having said that, for GANs, I haven't had that much</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=4881" target="_blank">01:21:21.700</a></span> | <span class="t">success with it yet, and I think it probably requires some tweaking to get it to work.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=4886" target="_blank">01:21:26.540</a></span> | <span class="t">I'm sure some people have got it to work. The issue I think is that in the early stages,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=4893" target="_blank">01:21:33.980</a></span> | <span class="t">it doesn't create enough noise. I had a version actually where I tried to do it with an upsample,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=4907" target="_blank">01:21:47.140</a></span> | <span class="t">and you could kind of see that the noise didn't look very noisy. So anyway, it's an interesting</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=4913" target="_blank">01:21:53.420</a></span> | <span class="t">version. But next week when we look at style transfer and super resolution and stuff, I</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=4918" target="_blank">01:21:58.660</a></span> | <span class="t">think you'll see an end-up sample really comes into its own.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=4925" target="_blank">01:22:05.100</a></span> | <span class="t">So the generator, we can now basically start with a vector. We can decide and say, okay,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=4930" target="_blank">01:22:10.340</a></span> | <span class="t">let's not think of it as a vector, but actually it's a 1x1 grid cell, and then we can turn</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=4934" target="_blank">01:22:14.120</a></span> | <span class="t">it into a 4x4 and an 8x8 and so forth. And so that's why we have to make sure it's a suitable</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=4940" target="_blank">01:22:20.860</a></span> | <span class="t">multiple so that we can actually create something of the right size. And so you can see it's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=4946" target="_blank">01:22:26.500</a></span> | <span class="t">doing the exact opposite as before, right? It's making the cell size smaller and smaller</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=4951" target="_blank">01:22:31.340</a></span> | <span class="t">by 2 at a time, as long as it can, until it gets to half the size that we want. And then</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=4968" target="_blank">01:22:48.340</a></span> | <span class="t">finally we add one more on at the end -- sorry, we add n more on at the end with no stride,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=4978" target="_blank">01:22:58.100</a></span> | <span class="t">and then we add one more com transpose to finally get to the size that we wanted, and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=4986" target="_blank">01:23:06.020</a></span> | <span class="t">we're done. Finally, we put that through a than, and that's going to force us to be in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=4993" target="_blank">01:23:13.100</a></span> | <span class="t">the 0-to-1 range, because of course we don't want to spit out arbitrary size pixel values.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=5004" target="_blank">01:23:24.860</a></span> | <span class="t">So we've got a generator architecture which spits out an image of some given size with</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=5009" target="_blank">01:23:29.580</a></span> | <span class="t">the correct number of channels and with values between 0 and 1.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=5019" target="_blank">01:23:39.420</a></span> | <span class="t">So at this point we can now create our ModelData object. These things take a while to train,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=5027" target="_blank">01:23:47.700</a></span> | <span class="t">so I just made it 128x128, so this is just a convenient way to make it a bit faster. And</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=5038" target="_blank">01:23:58.380</a></span> | <span class="t">that's going to be the size of the import, but then we're going to use transformations</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=5041" target="_blank">01:24:01.180</a></span> | <span class="t">to turn it into 64x64. There's been more recent advances which have attempted to really increase</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=5050" target="_blank">01:24:10.060</a></span> | <span class="t">this up to high resolution sizes, but they still tend to require either a batch size</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=5055" target="_blank">01:24:15.060</a></span> | <span class="t">of 1 or lots and lots of GPUs or whatever. We're trying to do things that we can do on</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=5061" target="_blank">01:24:21.740</a></span> | <span class="t">single consumer GPUs here. So here's an example of one of the 64x64 bedrooms.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=5071" target="_blank">01:24:31.260</a></span> | <span class="t">So we're going to do pretty much everything manually, so let's go ahead and create our</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=5076" target="_blank">01:24:36.740</a></span> | <span class="t">two models, our generator and our discriminator. And as you can see, the DCGAN, so in other</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=5084" target="_blank">01:24:44.460</a></span> | <span class="t">words they're the same modules that were appeared in this paper. So if you're interested in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=5092" target="_blank">01:24:52.380</a></span> | <span class="t">reading the papers, it's well worth going back and looking at the DCGAN paper to see</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=5098" target="_blank">01:24:58.740</a></span> | <span class="t">what these architectures are, because it's assumed that when you read the Wasserstein</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=5102" target="_blank">01:25:02.340</a></span> | <span class="t">GAN paper that you already know that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=5107" target="_blank">01:25:07.820</a></span> | <span class="t">Shouldn't we use a sigmoid if we want values between 0 and 1?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=5113" target="_blank">01:25:13.460</a></span> | <span class="t">I always forget which one's which. So sigmoid is 0 to 1, than is 1 to -1. I think what will</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=5127" target="_blank">01:25:27.780</a></span> | <span class="t">happen is -- I'm going to have to check that. I vaguely remember thinking about this when</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=5134" target="_blank">01:25:34.860</a></span> | <span class="t">I was writing this notebook and realizing that 1 to -1 made sense for some reason, but</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=5139" target="_blank">01:25:39.540</a></span> | <span class="t">I can't remember what that reason was now. So let me get back to you about that during</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=5143" target="_blank">01:25:43.900</a></span> | <span class="t">the week and remind me if I forget.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=5146" target="_blank">01:25:46.980</a></span> | <span class="t">Good question, thank you.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=5150" target="_blank">01:25:50.180</a></span> | <span class="t">So we've got our generator and our discriminator. So we need a function that returns a prior</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=5156" target="_blank">01:25:56.060</a></span> | <span class="t">vector, so a bunch of noise. So we do that by creating a bunch of zeros. nz is the size</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=5165" target="_blank">01:26:05.020</a></span> | <span class="t">of z, so very often in our code if you see a mysterious letter, it's because that's the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=5170" target="_blank">01:26:10.260</a></span> | <span class="t">letter they used in the paper. So z is the size of our noise vector.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=5176" target="_blank">01:26:16.980</a></span> | <span class="t">So there's the size of our noise vector, and then we use a normal distribution to generate</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=5182" target="_blank">01:26:22.340</a></span> | <span class="t">random numbers inside that. And that needs to be a variable because it's going to be</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=5186" target="_blank">01:26:26.840</a></span> | <span class="t">participating in the gradient updates.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=5192" target="_blank">01:26:32.780</a></span> | <span class="t">So here's an example of creating some noise, and so here are four different pieces of noise.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=5200" target="_blank">01:26:40.060</a></span> | <span class="t">So we need an optimizer in order to update our gradients. In the Wasserstein GAN paper,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=5211" target="_blank">01:26:51.480</a></span> | <span class="t">they told us to use rmsprop. So that's fine. So when you see this thing saying do an rmsprop</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=5216" target="_blank">01:26:56.820</a></span> | <span class="t">update in a paper, that's nice. We can just do an rmsprop update with pytorch. And they</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=5225" target="_blank">01:27:05.140</a></span> | <span class="t">suggested a learning rate of 5e-neg-5. I think I found 1e-neg-4 seemed to work, so I just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=5232" target="_blank">01:27:12.260</a></span> | <span class="t">made it a bit bigger.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=5234" target="_blank">01:27:14.820</a></span> | <span class="t">So now we need a training loop. And so this is the thing that's going to implement this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=5238" target="_blank">01:27:18.820</a></span> | <span class="t">algorithm. So a training loop is going to go through some number of epochs that we get</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=5246" target="_blank">01:27:26.780</a></span> | <span class="t">to pick, so that's going to be a parameter. And so remember, when you do everything manually,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=5253" target="_blank">01:27:33.860</a></span> | <span class="t">you've got to remember all the manual steps to do. So one is that you have to set your</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=5257" target="_blank">01:27:37.700</a></span> | <span class="t">modules into training mode when you're training them, and into evaluation mode when you're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=5263" target="_blank">01:27:43.340</a></span> | <span class="t">evaluating them. Because in training mode, batch norm updates happen, and dropout happens.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=5269" target="_blank">01:27:49.940</a></span> | <span class="t">In evaluation mode, those two things get turned off. That's basically the difference. So put</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=5274" target="_blank">01:27:54.860</a></span> | <span class="t">it into training mode. We're going to grab an iterator from our training data loader.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=5281" target="_blank">01:28:01.900</a></span> | <span class="t">We're going to see how many steps we have to go through, and then we'll use TQDM to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=5288" target="_blank">01:28:08.020</a></span> | <span class="t">give us a progress bar, and then we're going to go through that many steps.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=5294" target="_blank">01:28:14.060</a></span> | <span class="t">So the first step of this algorithm is to update the discriminator. So in this one -- they</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=5317" target="_blank">01:28:37.060</a></span> | <span class="t">don't call it a discriminator, they call it a critic. So w are the weights of the critic.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=5323" target="_blank">01:28:43.380</a></span> | <span class="t">So the first step is to train our critic a little bit, and then we're going to train</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=5328" target="_blank">01:28:48.660</a></span> | <span class="t">our generator a little bit, and then we're going to go back to the top of the loop. So</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=5333" target="_blank">01:28:53.500</a></span> | <span class="t">we've got a while loop on the outside, so here's our while loop on the outside, and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=5338" target="_blank">01:28:58.060</a></span> | <span class="t">then inside that there's another loop for the critic, and so here's our little loop</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=5342" target="_blank">01:29:02.440</a></span> | <span class="t">inside that for the critic. We call it a discriminator.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=5347" target="_blank">01:29:07.060</a></span> | <span class="t">So what we're going to do now is we've got a generator, and at the moment it's random.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=5353" target="_blank">01:29:13.660</a></span> | <span class="t">So our generator is going to generate stuff that looks something like this, and so we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=5359" target="_blank">01:29:19.360</a></span> | <span class="t">need to first of all teach our discriminator to tell the difference between that and a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=5364" target="_blank">01:29:24.060</a></span> | <span class="t">bedroom. It shouldn't be too hard, you would hope. So we just do it in basically the usual</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=5371" target="_blank">01:29:31.420</a></span> | <span class="t">way, but there's a few little tweaks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=5374" target="_blank">01:29:34.780</a></span> | <span class="t">So first of all, we're going to grab a mini-batch of real bedroom photos, so we can just grab</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=5382" target="_blank">01:29:42.060</a></span> | <span class="t">the next batch from our iterator, turn it into a variable. Then we're going to calculate</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=5394" target="_blank">01:29:54.580</a></span> | <span class="t">the loss for that. So this is going to be, how much does the discriminator think this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=5408" target="_blank">01:30:08.220</a></span> | <span class="t">looks fake? And then we're going to create some fake images, and to do that we'll create</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=5416" target="_blank">01:30:16.240</a></span> | <span class="t">some random noise, and we'll stick it through our generator, which at this stage is just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=5420" target="_blank">01:30:20.940</a></span> | <span class="t">a bunch of random weights, and that's going to create a mini-batch of fake images. And</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=5427" target="_blank">01:30:27.060</a></span> | <span class="t">so then we'll put that through the same discriminator module as before to get the loss for that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=5434" target="_blank">01:30:34.780</a></span> | <span class="t">So how fake do the fake ones look? Remember when you do everything manually, you have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=5439" target="_blank">01:30:39.900</a></span> | <span class="t">to zero the gradients in your loop, and if you've forgotten about that, go back to the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=5445" target="_blank">01:30:45.780</a></span> | <span class="t">Part 1 lesson where we do everything from scratch. So now finally, the total discriminator</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=5452" target="_blank">01:30:52.820</a></span> | <span class="t">loss is equal to the real loss minus the fake loss. And so you can see that here. They don't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=5463" target="_blank">01:31:03.140</a></span> | <span class="t">talk about the loss, they actually just talk about what are the gradient updates. So this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=5468" target="_blank">01:31:08.140</a></span> | <span class="t">here is the symbol for get the gradients. So inside here is the loss. And try to learn</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=5476" target="_blank">01:31:16.860</a></span> | <span class="t">to throw away in your head all of the boring stuff. So when you see sum over m divided</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=5482" target="_blank">01:31:22.780</a></span> | <span class="t">by m, that means take the average. So just throw that away and replace it with np.mean</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=5487" target="_blank">01:31:27.820</a></span> | <span class="t">in your head. There's another np.mean. So you want to get quick at being able to see these</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=5493" target="_blank">01:31:33.180</a></span> | <span class="t">common idioms. So anytime you see 1 over m, sum over m, you go, okay, np.mean. So we're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=5500" target="_blank">01:31:40.060</a></span> | <span class="t">taking the mean of, and we're taking the mean of, so that's all fine.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=5505" target="_blank">01:31:45.580</a></span> | <span class="t">x_i, what's x_i? It looks like it's x to the power of i, but it's not. The math notation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=5512" target="_blank">01:31:52.100</a></span> | <span class="t">is very overloaded. They showed us here what x_i is, and it's a set of m samples from a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=5521" target="_blank">01:32:01.420</a></span> | <span class="t">batch of the real data. So in other words, this is a mini-batch. So when you see something</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=5526" target="_blank">01:32:06.940</a></span> | <span class="t">saying sample, it means just grab a row, grab a row, grab a row, and you can see here grab</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=5532" target="_blank">01:32:12.180</a></span> | <span class="t">at m times, and we'll call the first row x, parenthesis 1, the second row x, parenthesis</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=5537" target="_blank">01:32:17.980</a></span> | <span class="t">2. One of the annoying things about math notation is the way that we index into arrays is everybody</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=5548" target="_blank">01:32:28.500</a></span> | <span class="t">uses different approaches, subscripts, superscripts, things in brackets, combinations, commas, square</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=5553" target="_blank">01:32:33.700</a></span> | <span class="t">brackets, whatever. So you've just got to look in the paper and be like, okay, at some point</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=5559" target="_blank">01:32:39.300</a></span> | <span class="t">they're going to say take the i-th row from this matrix or the i-th image in this batch,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=5565" target="_blank">01:32:45.220</a></span> | <span class="t">how are they going to do it? In this case, it's a superscript in parenthesis.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=5571" target="_blank">01:32:51.020</a></span> | <span class="t">So that's all sample means, and curly brackets means it's just a set of them. This little</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=5576" target="_blank">01:32:56.420</a></span> | <span class="t">squiggle followed by something here means according to some probability distribution.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=5584" target="_blank">01:33:04.580</a></span> | <span class="t">And so in this case, and very very often in papers, it simply means, hey, you've got a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=5589" target="_blank">01:33:09.420</a></span> | <span class="t">bunch of data, grab a bit from it at random. So that's the probability distribution of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=5597" target="_blank">01:33:17.380</a></span> | <span class="t">the data you have is the data you have. So this says grab m things at random from your</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=5604" target="_blank">01:33:24.620</a></span> | <span class="t">prior samples, and so that means in other words call create_noise to create m random vectors.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=5622" target="_blank">01:33:42.620</a></span> | <span class="t">So now we've got m real images. Each one gets put through our discriminator. We've got m</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=5634" target="_blank">01:33:54.380</a></span> | <span class="t">bits of noise. Each one gets put through our generator to create m generated images. Each</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=5643" target="_blank">01:34:03.500</a></span> | <span class="t">one of those gets put through, look, f(w), that's the same thing, so each one of those</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=5647" target="_blank">01:34:07.460</a></span> | <span class="t">gets put through our discriminator to try and figure out whether they're fake or not.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=5651" target="_blank">01:34:11.820</a></span> | <span class="t">And so then it's this, minus this, and the mean of that, and then finally get the gradient</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=5658" target="_blank">01:34:18.060</a></span> | <span class="t">of that in order to figure out how to use rmsprop to update our weights using some learning</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=5665" target="_blank">01:34:25.260</a></span> | <span class="t">weight.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=5667" target="_blank">01:34:27.180</a></span> | <span class="t">So in PyTorch, we don't have to worry about getting the gradients. We can just specify</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=5674" target="_blank">01:34:34.660</a></span> | <span class="t">the loss bit, and then just say loss.backward, discriminator optimizer.step.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=5682" target="_blank">01:34:42.140</a></span> | <span class="t">Now there's one key step, which is that we have to keep all of our weights, which are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=5696" target="_blank">01:34:56.660</a></span> | <span class="t">the parameters in a PyTorch module, in this small range between -0.01 and 0.01. Why? Because</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=5707" target="_blank">01:35:07.540</a></span> | <span class="t">the mathematical assumptions that make this algorithm work only apply in like a small</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=5715" target="_blank">01:35:15.620</a></span> | <span class="t">ball. I think it's kind of interesting to understand the math of why that's the case,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=5723" target="_blank">01:35:23.220</a></span> | <span class="t">but it's very specific to this one paper, and understanding it won't help you understand</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=5728" target="_blank">01:35:28.420</a></span> | <span class="t">any other paper. So only study it if you're interested. I think it's nicely explained,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=5734" target="_blank">01:35:34.140</a></span> | <span class="t">I think it's fun, but it won't be information that you'll reuse elsewhere unless you get</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=5740" target="_blank">01:35:40.620</a></span> | <span class="t">super into GANs.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=5742" target="_blank">01:35:42.380</a></span> | <span class="t">I'll also mention, after the paper came out, an improved Frostenstein GAN came out that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=5747" target="_blank">01:35:47.900</a></span> | <span class="t">said there are better ways to ensure that your weight space is in this type ball, which</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=5754" target="_blank">01:35:54.380</a></span> | <span class="t">was basically to penalize gradients that are too high. So nowadays there are slightly different</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=5762" target="_blank">01:36:02.060</a></span> | <span class="t">ways to do this. Anyway, that's why this line of code there is kind of the key contribution.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=5768" target="_blank">01:36:08.720</a></span> | <span class="t">This one line of code actually is the one line of code you add to make it a Frostenstein</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=5773" target="_blank">01:36:13.100</a></span> | <span class="t">GAN. But the work was all in knowing that that's the thing you can do that makes everything</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=5779" target="_blank">01:36:19.700</a></span> | <span class="t">work better.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=5780" target="_blank">01:36:20.700</a></span> | <span class="t">At the end of this, we've got a discriminator that can recognize it in real bedrooms and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=5785" target="_blank">01:36:25.580</a></span> | <span class="t">now totally random crappy generated images. So let's now try and create some better images.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=5793" target="_blank">01:36:33.160</a></span> | <span class="t">So now set trainable discriminator to false, set trainable to true, zero out the gradients</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=5800" target="_blank">01:36:40.380</a></span> | <span class="t">of the generator.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=5802" target="_blank">01:36:42.740</a></span> | <span class="t">And now our loss again is fw, that's the discriminator of the generator applied to some more random</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=5817" target="_blank">01:36:57.380</a></span> | <span class="t">noise. So here's our random noise, here's our generator, and here's our discriminator.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=5829" target="_blank">01:37:09.260</a></span> | <span class="t">I think I can remove that now because I think I've put it inside the discriminator but I</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=5836" target="_blank">01:37:16.300</a></span> | <span class="t">won't change it now because it's going to confuse me. So it's exactly the same as before</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=5842" target="_blank">01:37:22.540</a></span> | <span class="t">where we did generator on the noise and then pass that to discriminator, but this time</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=5848" target="_blank">01:37:28.140</a></span> | <span class="t">the thing that's trainable is the generator, not the discriminator. So in other words,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=5852" target="_blank">01:37:32.580</a></span> | <span class="t">in this pseudocode, the thing they update is theta, which is the generator's parameters</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=5860" target="_blank">01:37:40.900</a></span> | <span class="t">rather than w, which is the discriminator's parameters.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=5865" target="_blank">01:37:45.860</a></span> | <span class="t">And so hopefully you'll see now that this w down here is telling you these are the parameters</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=5872" target="_blank">01:37:52.740</a></span> | <span class="t">of the discriminator, this theta down here is telling you these are the parameters of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=5882" target="_blank">01:38:02.420</a></span> | <span class="t">the generator.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=5883" target="_blank">01:38:03.420</a></span> | <span class="t">And again, it's not a universal mathematical notation, it's a thing they're doing in this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=5890" target="_blank">01:38:10.740</a></span> | <span class="t">particular paper, but it's kind of nice when you see some suffix like that, try to think</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=5898" target="_blank">01:38:18.180</a></span> | <span class="t">about what it's telling you.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=5901" target="_blank">01:38:21.780</a></span> | <span class="t">So we take some noise, generate some images, try and figure out if they're fake or real,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=5908" target="_blank">01:38:28.500</a></span> | <span class="t">and use that to get gradients with respect to the generator, as opposed to earlier we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=5915" target="_blank">01:38:35.420</a></span> | <span class="t">got them with respect to the discriminator, and use that to update their weights with</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=5920" target="_blank">01:38:40.020</a></span> | <span class="t">our MSProp with an alpha learning rate.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=5927" target="_blank">01:38:47.980</a></span> | <span class="t">You'll see that it's kind of unfair that the discriminator is getting trained n critic</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=5935" target="_blank">01:38:55.700</a></span> | <span class="t">times, which they set to 5, for every time that we train the generator once.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=5944" target="_blank">01:39:04.700</a></span> | <span class="t">And the paper talks a bit about this, but the basic idea is there's no point making</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=5949" target="_blank">01:39:09.500</a></span> | <span class="t">the generator better if the discriminator doesn't know how to discriminate yet.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=5955" target="_blank">01:39:15.020</a></span> | <span class="t">So that's why we've got this while loop.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=5958" target="_blank">01:39:18.460</a></span> | <span class="t">And here's that 5, and actually something which was added in the later paper is the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=5968" target="_blank">01:39:28.880</a></span> | <span class="t">idea that from time to time, and a bunch of times at the start, you should do more steps</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=5979" target="_blank">01:39:39.060</a></span> | <span class="t">of the discriminator.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=5980" target="_blank">01:39:40.060</a></span> | <span class="t">So make sure that the discriminator is pretty capable from time to time.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=5986" target="_blank">01:39:46.420</a></span> | <span class="t">So do a bunch of epochs of training the discriminator a bunch of times to get better at telling</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=5991" target="_blank">01:39:51.900</a></span> | <span class="t">the difference between real and fake, and then do one step with making the generator</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=5996" target="_blank">01:39:56.860</a></span> | <span class="t">being better at generating, and that is an epoch.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=6001" target="_blank">01:40:01.940</a></span> | <span class="t">And so let's train that for one epoch, and then let's create some noise so we can generate</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=6011" target="_blank">01:40:11.620</a></span> | <span class="t">some examples.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=6016" target="_blank">01:40:16.020</a></span> | <span class="t">So we're going to do that later.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=6017" target="_blank">01:40:17.020</a></span> | <span class="t">Let's first of all decrease the learning rate by 10 and do one more pass.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=6020" target="_blank">01:40:20.900</a></span> | <span class="t">So we've now done two epochs, and now let's use our noise to pass it to our generator,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=6030" target="_blank">01:40:30.540</a></span> | <span class="t">and then put it through our denormalization to turn it back into something we can see,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=6037" target="_blank">01:40:37.580</a></span> | <span class="t">and then plot it, and we have some bedrooms.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=6043" target="_blank">01:40:43.620</a></span> | <span class="t">It's not real bedrooms, and some of them don't look particularly like bedrooms, but some</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=6046" target="_blank">01:40:46.940</a></span> | <span class="t">of them look a lot like bedrooms.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=6049" target="_blank">01:40:49.540</a></span> | <span class="t">So that's the idea, that's a GAN.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=6053" target="_blank">01:40:53.620</a></span> | <span class="t">And I think the best way to think about a GAN is it's like an underlying technology</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=6061" target="_blank">01:41:01.020</a></span> | <span class="t">that you'll probably never use like this, but you'll use in lots of interesting ways.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=6068" target="_blank">01:41:08.820</a></span> | <span class="t">For example, we're going to use it to create now a CycleGAN, and we're going to use the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=6080" target="_blank">01:41:20.900</a></span> | <span class="t">CycleGAN to turn horses into zebras.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=6088" target="_blank">01:41:28.040</a></span> | <span class="t">You could also use it to turn Monet prints into photos, or to turn photos of Yosemite</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=6093" target="_blank">01:41:33.020</a></span> | <span class="t">in summer into winter.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=6096" target="_blank">01:41:36.200</a></span> | <span class="t">So it's going to be pretty, yes, Rachel?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=6098" target="_blank">01:41:38.860</a></span> | <span class="t">Two questions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=6099" target="_blank">01:41:39.860</a></span> | <span class="t">One, is there any reason for using RMS props, specifically as the optimizer as opposed to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=6105" target="_blank">01:41:45.820</a></span> | <span class="t">Adam?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=6106" target="_blank">01:41:46.820</a></span> | <span class="t">I don't remember it being explicitly discussed in the paper, I don't know if it's just experimental</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=6112" target="_blank">01:41:52.740</a></span> | <span class="t">or the theoretical reason.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=6114" target="_blank">01:41:54.220</a></span> | <span class="t">Have a look in the paper and see what it says, I don't recall.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=6117" target="_blank">01:41:57.900</a></span> | <span class="t">And which could be a reasonable way of detecting overfitting while training, or evaluating</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=6122" target="_blank">01:42:02.420</a></span> | <span class="t">the performance of one of these GAN models once we're done training?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=6126" target="_blank">01:42:06.060</a></span> | <span class="t">In other words, how does the notion of training validation test sets translate to GANs?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=6135" target="_blank">01:42:15.340</a></span> | <span class="t">That's an awesome question.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=6138" target="_blank">01:42:18.740</a></span> | <span class="t">And there's a lot of people who make jokes about how GANs is the one field where you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=6144" target="_blank">01:42:24.420</a></span> | <span class="t">don't need a test set, and people take advantage of that by making stuff up and saying it looks</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=6150" target="_blank">01:42:30.620</a></span> | <span class="t">great.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=6153" target="_blank">01:42:33.060</a></span> | <span class="t">There are some pretty famous problems with GANs.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=6156" target="_blank">01:42:36.420</a></span> | <span class="t">One of the famous problems with GANs is called mode collapse.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=6160" target="_blank">01:42:40.060</a></span> | <span class="t">And mode collapse happens where you look at your bedrooms and it turns out that there's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=6164" target="_blank">01:42:44.900</a></span> | <span class="t">basically only three kinds of bedrooms that every possible noise vector mapped to, and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=6170" target="_blank">01:42:50.660</a></span> | <span class="t">you look at your gallery and it turns out they're all just the same thing, or there's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=6174" target="_blank">01:42:54.620</a></span> | <span class="t">just three different things.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=6176" target="_blank">01:42:56.980</a></span> | <span class="t">Mode collapse is easy to see if you collapse down to a small number of modes, like three</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=6181" target="_blank">01:43:01.700</a></span> | <span class="t">or four.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=6182" target="_blank">01:43:02.700</a></span> | <span class="t">But what if you have a mode collapse down to 10,000 modes, so there's only 10,000 possible</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=6188" target="_blank">01:43:08.300</a></span> | <span class="t">bedrooms that all of your noise vectors collapse to?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=6192" target="_blank">01:43:12.700</a></span> | <span class="t">You wouldn't be able to see it here, because it's pretty unlikely you would have two identical</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=6196" target="_blank">01:43:16.060</a></span> | <span class="t">bedrooms out of 10,000.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=6198" target="_blank">01:43:18.460</a></span> | <span class="t">Or what if every one of these bedrooms is basically a direct copy of one of the -- it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=6204" target="_blank">01:43:24.980</a></span> | <span class="t">basically memorized some input.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=6209" target="_blank">01:43:29.900</a></span> | <span class="t">Could that be happening?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=6211" target="_blank">01:43:31.680</a></span> | <span class="t">And the truth is most papers don't do a good job or sometimes any job of checking those</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=6219" target="_blank">01:43:39.260</a></span> | <span class="t">things.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=6222" target="_blank">01:43:42.440</a></span> | <span class="t">So the question of how do we evaluate GANs, and even the point of maybe we should actually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=6230" target="_blank">01:43:50.100</a></span> | <span class="t">evaluate GANs properly is something that is not widely enough understood even now.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=6239" target="_blank">01:43:59.780</a></span> | <span class="t">And some people are trying to really push.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=6242" target="_blank">01:44:02.460</a></span> | <span class="t">So Ian Goodfellow, who a lot of you will know because he came and spoke here at a lot of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=6249" target="_blank">01:44:09.540</a></span> | <span class="t">the book club meetings last year, and of course was the first author on the most famous deep</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=6255" target="_blank">01:44:15.540</a></span> | <span class="t">learning book.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=6256" target="_blank">01:44:16.540</a></span> | <span class="t">He's the inventor of GANs, and he's been sending a continuous stream of tweets reminding people</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=6264" target="_blank">01:44:24.900</a></span> | <span class="t">about the importance of testing GANs properly.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=6270" target="_blank">01:44:30.500</a></span> | <span class="t">So if you see a paper that claims exceptional GAN results, then this is definitely something</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=6277" target="_blank">01:44:37.100</a></span> | <span class="t">to look at.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=6278" target="_blank">01:44:38.800</a></span> | <span class="t">Have they talked about mode collapse?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=6280" target="_blank">01:44:40.380</a></span> | <span class="t">Have they talked about memorization?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=6287" target="_blank">01:44:47.100</a></span> | <span class="t">So this is going to be really straightforward because it's just a neural net.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=6291" target="_blank">01:44:51.260</a></span> | <span class="t">So all we're going to do is we're going to create an input containing lots of zebra photos,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=6298" target="_blank">01:44:58.780</a></span> | <span class="t">and with each one we'll pair it with an equivalent horse photo, and we'll just train a neural</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=6306" target="_blank">01:45:06.660</a></span> | <span class="t">net that goes from one to the other.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=6308" target="_blank">01:45:08.300</a></span> | <span class="t">Or you can do the same thing for every Monet painting, create a dataset containing the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=6313" target="_blank">01:45:13.060</a></span> | <span class="t">photo of the place.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=6315" target="_blank">01:45:15.020</a></span> | <span class="t">Oh wait, that's not possible because the places that Monet painted aren't there anymore, and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=6320" target="_blank">01:45:20.900</a></span> | <span class="t">there aren't exact zebra versions of horses.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=6323" target="_blank">01:45:23.700</a></span> | <span class="t">And oh wait, how the hell is this going to work?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=6327" target="_blank">01:45:27.920</a></span> | <span class="t">This seems to break everything we know about what neural nets can do and how they do them.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=6332" target="_blank">01:45:32.980</a></span> | <span class="t">Alright Rachel, you're going to ask me a question, just spoil our whole train of thought.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=6336" target="_blank">01:45:36.940</a></span> | <span class="t">Come on, better be good.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=6338" target="_blank">01:45:38.500</a></span> | <span class="t">Can GANs be used for data augmentation?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=6341" target="_blank">01:45:41.380</a></span> | <span class="t">Yeah, absolutely.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=6343" target="_blank">01:45:43.140</a></span> | <span class="t">You can use a GAN for data augmentation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=6345" target="_blank">01:45:45.540</a></span> | <span class="t">Should you?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=6347" target="_blank">01:45:47.740</a></span> | <span class="t">I don't know.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=6349" target="_blank">01:45:49.660</a></span> | <span class="t">There are some papers that try to do semi-supervised learning with GANs.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=6353" target="_blank">01:45:53.620</a></span> | <span class="t">I haven't found any that are particularly compelling, showing state-of-the-art results on really</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=6360" target="_blank">01:46:00.340</a></span> | <span class="t">interesting datasets that have been widely studied.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=6364" target="_blank">01:46:04.940</a></span> | <span class="t">I'm a little skeptical.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=6368" target="_blank">01:46:08.100</a></span> | <span class="t">The reason I'm a little skeptical is because in my experience, if you train a model with</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=6372" target="_blank">01:46:12.660</a></span> | <span class="t">synthetic data, the neural net will become fantastically good at recognizing the specific</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=6380" target="_blank">01:46:20.020</a></span> | <span class="t">problems of your synthetic data, and that will end up what it's learning from.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=6386" target="_blank">01:46:26.820</a></span> | <span class="t">And there are lots of other ways of doing semi-supervised models which do work well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=6392" target="_blank">01:46:32.340</a></span> | <span class="t">There are some places that it can work.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=6394" target="_blank">01:46:34.260</a></span> | <span class="t">For example, you might remember Otavio Good who created that fantastic visualization in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=6399" target="_blank">01:46:39.540</a></span> | <span class="t">Part 1 of the Zooming ConvNet where he kind of showed a letter going through MNIST.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=6405" target="_blank">01:46:45.740</a></span> | <span class="t">He at least at that time was the number one autonomous remote-controlled car guy in autonomous</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=6416" target="_blank">01:46:56.220</a></span> | <span class="t">remote-controlled car competitions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=6418" target="_blank">01:46:58.420</a></span> | <span class="t">And he trained his model using synthetically augmented data where he basically talked real</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=6426" target="_blank">01:47:06.040</a></span> | <span class="t">videos of a car driving around a circuit and added fake people and fake other cars and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=6433" target="_blank">01:47:13.860</a></span> | <span class="t">stuff like that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=6435" target="_blank">01:47:15.020</a></span> | <span class="t">And I think that worked well because he's kind of a genius and because I think he had</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=6442" target="_blank">01:47:22.660</a></span> | <span class="t">a well-defined subset that he had to work in.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=6452" target="_blank">01:47:32.820</a></span> | <span class="t">But in general it's really hard to use synthetic data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=6456" target="_blank">01:47:36.620</a></span> | <span class="t">I've tried using synthetic data in models for decades now, obviously not GANs because</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=6462" target="_blank">01:47:42.220</a></span> | <span class="t">they're pretty new, but in general it's very hard to do.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=6466" target="_blank">01:47:46.980</a></span> | <span class="t">Very interesting research question.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=6473" target="_blank">01:47:53.380</a></span> | <span class="t">So somehow these folks at Berkeley created a model that can turn a horse into a zebra</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=6483" target="_blank">01:48:03.700</a></span> | <span class="t">despite not having any photos unless they went out there and painted horses and took</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=6488" target="_blank">01:48:08.820</a></span> | <span class="t">before and after shots, but I believe they did it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=6494" target="_blank">01:48:14.860</a></span> | <span class="t">So how the hell did they do this?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=6498" target="_blank">01:48:18.840</a></span> | <span class="t">It's kind of genius.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=6504" target="_blank">01:48:24.300</a></span> | <span class="t">I will say the person I know who's doing the most interesting practice of CycleGAN right</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=6511" target="_blank">01:48:31.020</a></span> | <span class="t">now is one of our students, Helena Sarin.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=6515" target="_blank">01:48:35.780</a></span> | <span class="t">She's the only artist I know of who is a CycleGAN artist.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=6521" target="_blank">01:48:41.220</a></span> | <span class="t">Here's an example I love.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=6522" target="_blank">01:48:42.700</a></span> | <span class="t">She created this little doodle in the top left, and then trained a CycleGAN to turn</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=6529" target="_blank">01:48:49.140</a></span> | <span class="t">it into this beautiful painting in the bottom right.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=6534" target="_blank">01:48:54.220</a></span> | <span class="t">Here are some more of her amazing works.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=6538" target="_blank">01:48:58.860</a></span> | <span class="t">I think it's really interesting, I mentioned at the start of this class that GANs are in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=6544" target="_blank">01:49:04.500</a></span> | <span class="t">the category of stuff that's not there yet, but it's nearly there, and in this case there's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=6552" target="_blank">01:49:12.140</a></span> | <span class="t">at least one person in the world now who's creating beautiful and extraordinary artworks</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=6556" target="_blank">01:49:16.840</a></span> | <span class="t">using GANs, and there's lots of specifically CycleGANs, and there's actually at least</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=6562" target="_blank">01:49:22.660</a></span> | <span class="t">maybe a dozen people I know of who are just doing interesting creative work with neural</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=6567" target="_blank">01:49:27.420</a></span> | <span class="t">nets more generally, and the field of creative AI is going to expand dramatically.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=6573" target="_blank">01:49:33.300</a></span> | <span class="t">I think it's interesting with Helena, I don't know her personally, but from what I understand</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=6578" target="_blank">01:49:38.700</a></span> | <span class="t">of her background, she's a software developer, it's her full-time job, and an artist as her</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=6585" target="_blank">01:49:45.420</a></span> | <span class="t">hobby, and she's kind of started combining these two by saying, "Gosh, I wonder what</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=6590" target="_blank">01:49:50.380</a></span> | <span class="t">this particular tool could bring to my art?"</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=6593" target="_blank">01:49:53.660</a></span> | <span class="t">And so if you follow her Twitter account, we'll make sure we add it on the wiki.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=6597" target="_blank">01:49:57.540</a></span> | <span class="t">If somebody can find it, it's Helena Sarin.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=6603" target="_blank">01:50:03.020</a></span> | <span class="t">She basically posts a new work almost every day, and they're always pretty amazing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=6611" target="_blank">01:50:11.820</a></span> | <span class="t">So here's the basic trick, and this is from the CycleGAN paper.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=6618" target="_blank">01:50:18.620</a></span> | <span class="t">We're going to have two images, assuming we're doing this with images, but the key thing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=6627" target="_blank">01:50:27.140</a></span> | <span class="t">is they're not paired images. We don't have a data set of horses and the equivalent zebras.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=6634" target="_blank">01:50:34.620</a></span> | <span class="t">We've got a bunch of horses, a bunch of zebras.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=6638" target="_blank">01:50:38.460</a></span> | <span class="t">Grab one horse, grab one zebra.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=6641" target="_blank">01:50:41.780</a></span> | <span class="t">We've now got an X, let's say X is horse, and Y is zebra.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=6647" target="_blank">01:50:47.060</a></span> | <span class="t">We're going to train a generator, and what they call here a mapping function, that turns</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=6652" target="_blank">01:50:52.940</a></span> | <span class="t">horse into zebra, we'll call that mapping function G, and we'll create one mapping function,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=6658" target="_blank">01:50:58.900</a></span> | <span class="t">generator, that turns a zebra into a horse, and we'll call that F.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=6664" target="_blank">01:51:04.140</a></span> | <span class="t">We'll create a discriminator, just like we did before, which is going to get as good</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=6669" target="_blank">01:51:09.660</a></span> | <span class="t">as possible at recognizing real from fake horses, so that'll be DX, and then another</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=6676" target="_blank">01:51:16.500</a></span> | <span class="t">discriminator which is going to be as good as possible and recognizing real from fake</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=6680" target="_blank">01:51:20.820</a></span> | <span class="t">zebras, we'll call that DY.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=6684" target="_blank">01:51:24.740</a></span> | <span class="t">So that's kind of our starting point, but then the key thing to making this work, we're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=6691" target="_blank">01:51:31.700</a></span> | <span class="t">kind of generating a loss function here, right? Here's one bit of the loss function, here's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=6694" target="_blank">01:51:34.620</a></span> | <span class="t">the second bit of the loss function. We're going to create something called cycle consistency</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=6699" target="_blank">01:51:39.060</a></span> | <span class="t">loss which says after you turn your horse into a zebra with your G generator and check</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=6707" target="_blank">01:51:47.900</a></span> | <span class="t">whether or not I can recognize that it's real. I keep forgetting which one's horse and which</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=6714" target="_blank">01:51:54.420</a></span> | <span class="t">one's zebra, I apologize if I get my X's and Y's backwards.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=6717" target="_blank">01:51:57.700</a></span> | <span class="t">I turn my horse into a zebra, and then I'm going to try and turn that zebra back into</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=6723" target="_blank">01:52:03.080</a></span> | <span class="t">the same horse that I started with. So then I'm going to have another function that's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=6729" target="_blank">01:52:09.240</a></span> | <span class="t">going to check whether this horse, which I've generated knowing nothing about X, generated</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=6739" target="_blank">01:52:19.500</a></span> | <span class="t">entirely from this zebra, is similar to the original horse or not.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=6744" target="_blank">01:52:24.980</a></span> | <span class="t">So the idea would be if your generated zebra doesn't look anything like your original horse,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=6752" target="_blank">01:52:32.420</a></span> | <span class="t">you've got no chance of turning it back into the original horse. So a loss, which compares</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=6758" target="_blank">01:52:38.340</a></span> | <span class="t">X hat to X, is going to be really bad unless you can go into Y and back out again. And</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=6766" target="_blank">01:52:46.140</a></span> | <span class="t">you're probably only going to be able to do that if you're able to create a zebra that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=6770" target="_blank">01:52:50.540</a></span> | <span class="t">looks like the original horse so that you know what the original horse looked like.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=6775" target="_blank">01:52:55.400</a></span> | <span class="t">And vice versa. Take your zebra, turn it into a fake horse, and then try and turn it back</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=6784" target="_blank">01:53:04.880</a></span> | <span class="t">into the original zebra and check that it looks like the original. So notice here, this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=6790" target="_blank">01:53:10.100</a></span> | <span class="t">F is our zebra to horse. This G is our horse to zebra. So the G and the F are kind of doing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=6799" target="_blank">01:53:19.260</a></span> | <span class="t">two things. They're both turning the original horse into the zebra and then turning the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=6805" target="_blank">01:53:25.740</a></span> | <span class="t">zebra back into the original horse. So notice that there's only two generators. There isn't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=6811" target="_blank">01:53:31.780</a></span> | <span class="t">a separate generator for the reverse mapping. You have to use the same generator that was</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=6816" target="_blank">01:53:36.980</a></span> | <span class="t">used for the original mapping. So this is the cycle consistency loss. And I just think</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=6822" target="_blank">01:53:42.420</a></span> | <span class="t">this is genius. The idea that this is a thing that could be even possible, honestly when</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=6831" target="_blank">01:53:51.620</a></span> | <span class="t">this came out, it just never occurred to me as a thing that I could even try and solve.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=6836" target="_blank">01:53:56.540</a></span> | <span class="t">It seems so obviously impossible. And then the idea that you can solve it like this,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=6840" target="_blank">01:54:00.860</a></span> | <span class="t">I just think it's so damn smart.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=6845" target="_blank">01:54:05.940</a></span> | <span class="t">So it's good to look at the equations in this paper because they're written pretty simply.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=6856" target="_blank">01:54:16.660</a></span> | <span class="t">It's not like some of the stuff in the Wasserstein-Gahn paper which is like lots of theoretical proofs</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=6863" target="_blank">01:54:23.140</a></span> | <span class="t">and whatever else. In this case, they're just equations that just lay out what's going on.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=6868" target="_blank">01:54:28.500</a></span> | <span class="t">And you really want to get to a point where you can read them and understand them. So let's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=6872" target="_blank">01:54:32.500</a></span> | <span class="t">kind of start talking through them.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=6875" target="_blank">01:54:35.040</a></span> | <span class="t">So we've got a horse and a zebra. So for some mapping function G, which is our horse to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=6888" target="_blank">01:54:48.500</a></span> | <span class="t">zebra mapping function, then there's a GAN loss, which is the bit we're already familiar</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=6894" target="_blank">01:54:54.580</a></span> | <span class="t">with. It says I've got a horse, a zebra, a fake zebra recognizer, and a horse to zebra</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=6903" target="_blank">01:55:03.060</a></span> | <span class="t">generator. And the loss is what we saw before. It's our ability to draw one zebra out of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=6914" target="_blank">01:55:14.220</a></span> | <span class="t">our zebras and recognize whether it's real or fake. And then take a horse and turn it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=6929" target="_blank">01:55:29.700</a></span> | <span class="t">into a zebra and recognize whether that's real or fake. And then you can then do one</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=6937" target="_blank">01:55:37.300</a></span> | <span class="t">minus the other. In this case, they've got a log in there. The log's not terribly important.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=6943" target="_blank">01:55:43.060</a></span> | <span class="t">So this is the thing we just saw. So that's why we did Wasserstein GAN first. This is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=6947" target="_blank">01:55:47.740</a></span> | <span class="t">just a standard GAN loss in math form.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=6952" target="_blank">01:55:52.200</a></span> | <span class="t">Did you have a question, Rachel?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=6954" target="_blank">01:55:54.780</a></span> | <span class="t">All of this sounds awfully like translating in one language to another than back to the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=6958" target="_blank">01:55:58.580</a></span> | <span class="t">original. Have GANs or any equivalent been tried in translation?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=6964" target="_blank">01:56:04.460</a></span> | <span class="t">Not that I know of. There's this unsupervised machine translation which does kind of do</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=6984" target="_blank">01:56:24.020</a></span> | <span class="t">something like this, but I haven't looked at it closely enough to know if it's nearly</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=6989" target="_blank">01:56:29.820</a></span> | <span class="t">identical or if it's just vaguely similar.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=6995" target="_blank">01:56:35.020</a></span> | <span class="t">So to kind of back up to what I do know, normally with translation you require this kind of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=7000" target="_blank">01:56:40.340</a></span> | <span class="t">paired input. You require parallel texts. This is the French translation of this English</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=7005" target="_blank">01:56:45.140</a></span> | <span class="t">sentence.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=7007" target="_blank">01:56:47.820</a></span> | <span class="t">I do know there's been a couple of recent papers that show the ability to create good</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=7013" target="_blank">01:56:53.060</a></span> | <span class="t">quality translation models without paired data. I haven't implemented them and I don't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=7020" target="_blank">01:57:00.860</a></span> | <span class="t">understand anything, I haven't implemented them, but they may well be doing the same</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=7024" target="_blank">01:57:04.820</a></span> | <span class="t">basic idea. We'll look at it during the week and get back to you.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=7035" target="_blank">01:57:15.980</a></span> | <span class="t">So we've got our GAN loss. The next piece is the cycle consistency loss. So the basic</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=7042" target="_blank">01:57:22.180</a></span> | <span class="t">idea here is that we start with our horse, use our zebra generator on that to create</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=7048" target="_blank">01:57:28.980</a></span> | <span class="t">a zebra, use our horse generator on that to create a horse, and then compare that to the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=7054" target="_blank">01:57:34.580</a></span> | <span class="t">original horse. And this double lines with a 1, we've seen this before, this is the L1</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=7061" target="_blank">01:57:41.500</a></span> | <span class="t">loss. So this is the sum of the absolute value of differences.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=7065" target="_blank">01:57:45.580</a></span> | <span class="t">Or else if this was a 2, it would be the L2 loss, or the 2 norm, which would be the sum</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=7071" target="_blank">01:57:51.900</a></span> | <span class="t">of the square root of it, actually.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=7077" target="_blank">01:57:57.480</a></span> | <span class="t">And again, we now know this squiggle idea, which is from our horses, grab a horse. So</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=7087" target="_blank">01:58:07.540</a></span> | <span class="t">this is what we mean by sample from a distribution. There's all kinds of distributions, but most</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=7092" target="_blank">01:58:12.380</a></span> | <span class="t">commonly in these papers we're using in empirical distribution. In other words, we've got some</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=7097" target="_blank">01:58:17.540</a></span> | <span class="t">rows of data, grab a row.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=7100" target="_blank">01:58:20.060</a></span> | <span class="t">So when you see this thing, squiggle, other thing, this thing here, when it says pdata,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=7107" target="_blank">01:58:27.340</a></span> | <span class="t">that means grab something from the data, and we're going to call that thing x. So from</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=7113" target="_blank">01:58:33.700</a></span> | <span class="t">our horse's pictures, grab a horse, turn it into a zebra, turn it back into a horse, compare</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=7119" target="_blank">01:58:39.740</a></span> | <span class="t">it to the original, and sum up the absolute values. Do that for horse to zebra, do it for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=7124" target="_blank">01:58:44.760</a></span> | <span class="t">zebra to horse as well, add the two together, and that is our cycle consistency loss.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=7136" target="_blank">01:58:56.420</a></span> | <span class="t">So now we get our loss function, and the whole loss function depends on our horse generator,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=7143" target="_blank">01:59:03.460</a></span> | <span class="t">our zebra generator, our horse recognizer, our zebra recognizer discriminator, and we're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=7149" target="_blank">01:59:09.340</a></span> | <span class="t">going to add up the GAN loss for recognizing horses, the GAN loss for recognizing zebras,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=7157" target="_blank">01:59:17.980</a></span> | <span class="t">and the cycle consistency loss for our two generators.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=7163" target="_blank">01:59:23.580</a></span> | <span class="t">And then we've got a lambda here, which hopefully we're kind of used to this idea now, that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=7167" target="_blank">01:59:27.620</a></span> | <span class="t">is when you've got two different kinds of loss, you chuck in a parameter there, you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=7172" target="_blank">01:59:32.580</a></span> | <span class="t">can multiply them by so they're about the same scale. We did a similar thing with our</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=7178" target="_blank">01:59:38.100</a></span> | <span class="t">bounding box loss compared to our classifier loss when we did that localization stuff.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=7189" target="_blank">01:59:49.140</a></span> | <span class="t">So then we're going to try to, for this loss function, maximize the capability of the discriminators</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=7196" target="_blank">01:59:56.100</a></span> | <span class="t">that are discriminating whilst minimizing that for the generators. So the generators</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=7204" target="_blank">02:00:04.700</a></span> | <span class="t">and the discriminators are going to be facing off against each other.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=7208" target="_blank">02:00:08.880</a></span> | <span class="t">So when you see this min-max thing in papers, you'll see it a lot. It basically means this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=7215" target="_blank">02:00:15.500</a></span> | <span class="t">idea that in your training loop, one thing is trying to make something better, the other</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=7220" target="_blank">02:00:20.180</a></span> | <span class="t">is trying to make something worse, and there's lots of ways to do it, but most commonly you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=7224" target="_blank">02:00:24.700</a></span> | <span class="t">will alternate between the two. And you'll often see this just referred to in math papers</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=7229" target="_blank">02:00:29.820</a></span> | <span class="t">as min-max. So when you see min-max, you should immediately think, okay, adversarial training.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=7242" target="_blank">02:00:42.320</a></span> | <span class="t">So let's look at the code. We probably won't be able to finish this today, but we're going</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=7249" target="_blank">02:00:49.020</a></span> | <span class="t">to do something almost unheard of, which is I started looking at somebody else's code,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=7256" target="_blank">02:00:56.660</a></span> | <span class="t">and I was not so disgusted that I threw the whole thing away and did it myself. I actually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=7261" target="_blank">02:01:01.060</a></span> | <span class="t">said I quite like this. I like it enough I'm going to show it to my students.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=7267" target="_blank">02:01:07.140</a></span> | <span class="t">So this is where the code comes from. So this is one of the people that created the original</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=7277" target="_blank">02:01:17.340</a></span> | <span class="t">code for CycleGANs, and they've created a PyTorch version. I had to clean it up a little</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=7289" target="_blank">02:01:29.660</a></span> | <span class="t">bit, but it's actually pretty damn good. I think the first time I found code that I didn't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=7297" target="_blank">02:01:37.740</a></span> | <span class="t">feel the need to rewrite from scratch before I showed it to you.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=7304" target="_blank">02:01:44.340</a></span> | <span class="t">And so the cool thing about this is one of the reasons I like doing it this way, like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=7309" target="_blank">02:01:49.140</a></span> | <span class="t">finally finding something that's not awful, is that you're now going to get to see almost</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=7315" target="_blank">02:01:55.940</a></span> | <span class="t">all the bits of fast.ai, or all the relevant bits of fast.ai, written in a different way</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=7320" target="_blank">02:02:00.980</a></span> | <span class="t">than somebody else. And so you're going to get to see how they do data sets, and data</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=7326" target="_blank">02:02:06.140</a></span> | <span class="t">loaders, and models, and training loops, and so forth. So you'll find there's a Segan directory,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=7337" target="_blank">02:02:17.860</a></span> | <span class="t">which is basically nearly this, with some cleanups which I hope to submit as a PR sometime.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=7346" target="_blank">02:02:26.740</a></span> | <span class="t">It was written in a way that unfortunately made it a bit over-connected to how they were</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=7350" target="_blank">02:02:30.260</a></span> | <span class="t">using it as a script. I cleaned it up a little bit so I could use it as a module, but other</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=7355" target="_blank">02:02:35.100</a></span> | <span class="t">than that it's pretty similar. So Segan is basically their code copied from their GitHub</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=7364" target="_blank">02:02:44.540</a></span> | <span class="t">repo with some minor changes. So the way the Segan mini library has been set up is that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=7374" target="_blank">02:02:54.220</a></span> | <span class="t">the configuration options they're assuming are being passed in to a script. So they've</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=7379" target="_blank">02:02:59.580</a></span> | <span class="t">got this train options parser method, and so you can see I'm basically passing in an</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=7386" target="_blank">02:03:06.780</a></span> | <span class="t">array of script options. Where's my data? How many threads do I want to drop out? How many</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=7394" target="_blank">02:03:14.780</a></span> | <span class="t">iterations? What am I going to call this model? Which GPU do I want to write it on? So that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=7402" target="_blank">02:03:22.460</a></span> | <span class="t">might just be an opt object, which you can then see what it contains. You'll see it contains</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=7412" target="_blank">02:03:32.580</a></span> | <span class="t">some things I didn't mention, and that's because it's got defaults for everything else that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=7416" target="_blank">02:03:36.780</a></span> | <span class="t">I didn't mention.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=7419" target="_blank">02:03:39.540</a></span> | <span class="t">So rather than using fast.ai stuff, we're going to use Segan stuff. So the first thing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=7426" target="_blank">02:03:46.820</a></span> | <span class="t">we're going to need is a data loader. And so this is also a great opportunity for you again</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=7432" target="_blank">02:03:52.620</a></span> | <span class="t">to practice your ability to navigate through code with your editor or IDE of choice. So</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=7441" target="_blank">02:04:01.060</a></span> | <span class="t">we're going to start with create data loader. So you should be able to go find symbol or</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=7446" target="_blank">02:04:06.940</a></span> | <span class="t">in vim tag to jump straight to create data loader, and we can see that's creating a custom</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=7454" target="_blank">02:04:14.260</a></span> | <span class="t">dataset loader, and then we can see custom dataset loader is a base data loader. So basically</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=7466" target="_blank">02:04:26.180</a></span> | <span class="t">we can see that it's going to use a standard PyTorch data loader. So that's good. And so</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=7472" target="_blank">02:04:32.540</a></span> | <span class="t">we know if you're going to use a standard PyTorch data loader, you have to pass it a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=7476" target="_blank">02:04:36.540</a></span> | <span class="t">dataset. And we know that a dataset is something that contains a length and an indexer. So</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=7483" target="_blank">02:04:43.900</a></span> | <span class="t">presumably when we look at create dataset, it's going to do that. Here is create dataset.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=7489" target="_blank">02:04:49.980</a></span> | <span class="t">So this library actually does more than just CycleGAN. It handles both aligned and unaligned</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=7495" target="_blank">02:04:55.660</a></span> | <span class="t">image pairs. We know that our image pairs are unaligned. So we've got an unaligned dataset.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=7502" target="_blank">02:05:02.300</a></span> | <span class="t">Okay, here it is. And as expected, it has a getItem and a length. Good. And so obviously</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=7513" target="_blank">02:05:13.260</a></span> | <span class="t">the length is just whatever. So A and B is our horses and zebras. We've got two sets.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=7521" target="_blank">02:05:21.820</a></span> | <span class="t">So whichever one is longer is the length of the data loader. And so getItem is just going</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=7526" target="_blank">02:05:26.620</a></span> | <span class="t">to go ahead and randomly grab something from each of our two horses and zebras, open them</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=7536" target="_blank">02:05:36.620</a></span> | <span class="t">up with Pillow or PIL, run them through some transformations, and then we could either</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=7543" target="_blank">02:05:43.260</a></span> | <span class="t">be turning horses into zebras or zebras into horses, so there's some direction, and then</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=7548" target="_blank">02:05:48.260</a></span> | <span class="t">it will just go ahead and return our horse and our zebra and our path to the horse and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=7553" target="_blank">02:05:53.980</a></span> | <span class="t">the path to zebra. So hopefully you can kind of see that this is looking pretty similar</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=7559" target="_blank">02:05:59.980</a></span> | <span class="t">to the kind of stuff that FastAI does. FastAI obviously does quite a lot more when it comes</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=7566" target="_blank">02:06:06.860</a></span> | <span class="t">to transforms and performance and stuff like this. But remember, this is like research</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=7572" target="_blank">02:06:12.380</a></span> | <span class="t">code for this one thing. It's pretty cool that they did all this work.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=7577" target="_blank">02:06:17.900</a></span> | <span class="t">So we've got a data loader, so we can go and load our data into it, and so that will tell</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=7584" target="_blank">02:06:24.860</a></span> | <span class="t">us how many minibatches are in it. That's the length of the data loader in PyTorch.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=7591" target="_blank">02:06:31.140</a></span> | <span class="t">Next step, we've got a data loader is to create a model. So you can go tag for create_model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=7603" target="_blank">02:06:43.660</a></span> | <span class="t">There it is. Same idea, we've got different kinds of models, so we're going to be doing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=7608" target="_blank">02:06:48.220</a></span> | <span class="t">a CycleGAN. So here's our CycleGAN model. So there's quite a lot of stuff in a CycleGAN</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=7615" target="_blank">02:06:55.180</a></span> | <span class="t">model, so let's go through and find out what's going to be used. But basically at this stage,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=7624" target="_blank">02:07:04.540</a></span> | <span class="t">we've just called initializer. So when we initialize it, you can see it's going to go through and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=7631" target="_blank">02:07:11.540</a></span> | <span class="t">it's going to define two generators, which is not surprising, a generator for our horses</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=7637" target="_blank">02:07:17.480</a></span> | <span class="t">and a generator for our zebras. There's some way for it to generate a pool of fake data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=7651" target="_blank">02:07:31.940</a></span> | <span class="t">And then here we're going to grab our GAN loss, and as we talked about, our cycle consistency</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=7659" target="_blank">02:07:39.140</a></span> | <span class="t">loss is an L1 loss. That's interesting, they're going to use ADAM. So obviously for CycleGANs,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=7668" target="_blank">02:07:48.780</a></span> | <span class="t">they found ADAM works pretty well. And so then we're going to have an optimizer for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=7674" target="_blank">02:07:54.020</a></span> | <span class="t">our horse discriminator, an optimizer for our zebra discriminator, and an optimizer for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=7681" target="_blank">02:08:01.500</a></span> | <span class="t">our generator. The optimizer for the generator is going to contain the parameters both for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=7689" target="_blank">02:08:09.880</a></span> | <span class="t">the horse generator and the zebra generator all in one place. So the initializer is going</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=7697" target="_blank">02:08:17.380</a></span> | <span class="t">to set up all of the different networks and loss functions we need, and they're all going</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=7701" target="_blank">02:08:21.100</a></span> | <span class="t">to be stored inside this model. And so then it prints out and shows us exactly the PyTorch</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=7710" target="_blank">02:08:30.940</a></span> | <span class="t">bottles we have. And so it's interesting to see that they're using ResNets. And so you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=7716" target="_blank">02:08:36.100</a></span> | <span class="t">can see the ResNets look pretty familiar. We've got conv_batch_norm_rail_u, conv_batch_norm.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=7725" target="_blank">02:08:45.980</a></span> | <span class="t">So instance_norm is just the same as batch_norm, basically, but it applies it to one image</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=7732" target="_blank">02:08:52.240</a></span> | <span class="t">at a time. The difference isn't particularly important. And you can see they're doing reflection</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=7740" target="_blank">02:09:00.940</a></span> | <span class="t">padding just like we are. You can kind of see when you try to build everything from</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=7748" target="_blank">02:09:08.620</a></span> | <span class="t">scratch like this, it is a lot of work. And you can kind of get the nice little things</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=7756" target="_blank">02:09:16.740</a></span> | <span class="t">that fast.ai does automatically for you. You kind of have to do all of them by hand and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=7763" target="_blank">02:09:23.140</a></span> | <span class="t">only end up with a subset of them. So over time, hopefully soon, we'll get all of this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=7769" target="_blank">02:09:29.300</a></span> | <span class="t">GAN stuff into fast.ai and it'll be nice and easy.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=7774" target="_blank">02:09:34.140</a></span> | <span class="t">So we've got our model, and remember the model contains the loss functions, it contains the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=7778" target="_blank">02:09:38.820</a></span> | <span class="t">generators, it contains the discriminators, all in one convenient place. So I've gone</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=7783" target="_blank">02:09:43.260</a></span> | <span class="t">ahead and kind of copied and pasted and slightly refactored the training loop from the code</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=7790" target="_blank">02:09:50.580</a></span> | <span class="t">so that we can run it inside the notebook.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=7793" target="_blank">02:09:53.860</a></span> | <span class="t">So this is a lot pretty familiar, right? It's a loop to go through each epoch, and a loop</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=7798" target="_blank">02:09:58.980</a></span> | <span class="t">to go through the data. Before we did this, we set up our -- this is actually not a PyTorch</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=7808" target="_blank">02:10:08.940</a></span> | <span class="t">dataset, I think this is what they used slightly confusingly to talk about their combined,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=7815" target="_blank">02:10:15.660</a></span> | <span class="t">what we would call a model data object, I guess, or the data that they need. We'll go through</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=7821" target="_blank">02:10:21.060</a></span> | <span class="t">that with TQDM to get a progress bar, and so now we can go through and see what happens</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=7826" target="_blank">02:10:26.860</a></span> | <span class="t">in the model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=7828" target="_blank">02:10:28.740</a></span> | <span class="t">So set input. So it's kind of a different approach to what we do in fast.ai. It's kind</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=7842" target="_blank">02:10:42.540</a></span> | <span class="t">of neat, it's quite specific to CycleGANs, but basically internally inside this model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=7848" target="_blank">02:10:48.140</a></span> | <span class="t">is this idea that we're going to go into our data and grab -- we're either going horse</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=7855" target="_blank">02:10:55.880</a></span> | <span class="t">to zebra or zebra to horse, depending on which way we go. A is either the horse or the zebra,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=7862" target="_blank">02:11:02.140</a></span> | <span class="t">and vice versa, and if necessary, put it on the appropriate GPU and then grab the appropriate</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=7869" target="_blank">02:11:09.460</a></span> | <span class="t">path.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=7871" target="_blank">02:11:11.500</a></span> | <span class="t">So the model now has a mini-batch of horses and a mini-batch of zebras, and so now we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=7880" target="_blank">02:11:20.500</a></span> | <span class="t">optimize the parameters.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=7891" target="_blank">02:11:31.300</a></span> | <span class="t">So it's kind of nice to see it like this. You can see each step. First of all, try to optimize</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=7902" target="_blank">02:11:42.000</a></span> | <span class="t">the generators, then try to optimize the horse discriminator, then try to optimize the zebra</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=7908" target="_blank">02:11:48.460</a></span> | <span class="t">discriminator.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=7909" target="_blank">02:11:49.460</a></span> | <span class="t">0 grad is part of PyTorch. Step is part of PyTorch. So the interesting bit is the actual</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=7917" target="_blank">02:11:57.820</a></span> | <span class="t">thing which does the backpropagation on the generator.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=7924" target="_blank">02:12:04.620</a></span> | <span class="t">So here it is.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=7927" target="_blank">02:12:07.900</a></span> | <span class="t">And let's jump to the key pieces. There's all the bits, all the formulas that we basically</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=7932" target="_blank">02:12:12.300</a></span> | <span class="t">just saw from the paper. So let's take a horse and generate a zebra. So we've now got a fake</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=7945" target="_blank">02:12:25.580</a></span> | <span class="t">zebra. And let's now use the discriminator to see if we can tell whether it's fake or</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=7950" target="_blank">02:12:30.140</a></span> | <span class="t">not. And then let's pop that into our loss function, which we set up earlier to see if</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=7964" target="_blank">02:12:44.060</a></span> | <span class="t">we can basically get a loss function based on that prediction.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=7971" target="_blank">02:12:51.420</a></span> | <span class="t">Then let's do the same thing to do the GAN loss. So go in the opposite direction, and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=7977" target="_blank">02:12:57.960</a></span> | <span class="t">then we need to use the opposite discriminator, and then put that through the loss function</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=7983" target="_blank">02:13:03.580</a></span> | <span class="t">again.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=7985" target="_blank">02:13:05.100</a></span> | <span class="t">And then let's do the cycle-consistency loss. So again, we take our fake, which we created</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=7992" target="_blank">02:13:12.700</a></span> | <span class="t">up here, and try and turn it back again into the original. And then let's use that cycle-consistency</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=8003" target="_blank">02:13:23.820</a></span> | <span class="t">loss function we created earlier to compare it to the real original.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=8009" target="_blank">02:13:29.040</a></span> | <span class="t">And here's that lambda. So there's some weight that we used, and that was set up, actually.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=8016" target="_blank">02:13:36.420</a></span> | <span class="t">We just used the default that I suggested in their options. And then do the same for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=8020" target="_blank">02:13:40.740</a></span> | <span class="t">the opposite direction, and then add them all together. Do the backward step, and that's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=8029" target="_blank">02:13:49.940</a></span> | <span class="t">it. So we can then do the same thing for the first discriminator.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=8037" target="_blank">02:13:57.980</a></span> | <span class="t">And since basically all the work's been done now, there's much less to do here. So I won't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=8050" target="_blank">02:14:10.540</a></span> | <span class="t">step all through it, but it's basically the same basic stuff that we've already seen.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=8057" target="_blank">02:14:17.300</a></span> | <span class="t">So optimized parameters basically is calculating the losses and doing the optimizer step from</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=8065" target="_blank">02:14:25.460</a></span> | <span class="t">time to time, save and print out some results. And then from time to time, update the learning</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=8073" target="_blank">02:14:33.260</a></span> | <span class="t">rate, so they've got some learning rate annealing built in here as well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=8077" target="_blank">02:14:37.980</a></span> | <span class="t">It isn't very exciting, but we can take a look at it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=8089" target="_blank">02:14:49.540</a></span> | <span class="t">So they've basically got some kind of fast AI, they've got this idea of schedulers which</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=8094" target="_blank">02:14:54.700</a></span> | <span class="t">you can then use to update your learning rates. So I think for those of you who are interested</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=8101" target="_blank">02:15:01.380</a></span> | <span class="t">in better understanding deep learning APIs, or interested in contributing more to fast</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=8108" target="_blank">02:15:08.900</a></span> | <span class="t">AI, or interested in creating your own version of some of this stuff in some different backend,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=8115" target="_blank">02:15:15.940</a></span> | <span class="t">it's cool to look at a second kind of API that covers some subset of some of the similar</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=8121" target="_blank">02:15:21.620</a></span> | <span class="t">things to get a sense of how are they solving some of these problems, and what are the similarities</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=8126" target="_blank">02:15:26.740</a></span> | <span class="t">and what are the differences.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=8130" target="_blank">02:15:30.420</a></span> | <span class="t">So we train that for a little while, and then we can just grab a few examples, and here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=8139" target="_blank">02:15:39.240</a></span> | <span class="t">we have them. So here are our horses, here they are as zebras, and here they are back</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=8145" target="_blank">02:15:45.820</a></span> | <span class="t">as horses again. Here's a zebra, into a horse, back on a zebra, it's kind of thrown away</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=8151" target="_blank">02:15:51.180</a></span> | <span class="t">its head for some reason, but not so much it could get it back again. This is a really</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=8157" target="_blank">02:15:57.140</a></span> | <span class="t">interesting one, like this is obviously not what zebras look like, but it's going to be</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=8160" target="_blank">02:16:00.620</a></span> | <span class="t">a zebra version of that horse. It's also interesting to see its failure situations, I guess it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=8165" target="_blank">02:16:05.940</a></span> | <span class="t">doesn't very often see basically just an eyeball, it has no idea how to do that one. So some</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=8173" target="_blank">02:16:13.020</a></span> | <span class="t">of them don't work very well, this one's done a pretty good job. This one's interesting,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=8178" target="_blank">02:16:18.260</a></span> | <span class="t">it's done a good job of that one and that one, but for some reason the one in the middle</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=8181" target="_blank">02:16:21.140</a></span> | <span class="t">didn't get a go. This one's a really weird shape, but it's done a reasonable job of it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=8187" target="_blank">02:16:27.980</a></span> | <span class="t">This one looks good, this one's pretty sloppy, again the fork just ahead, it's not bad. So</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=8197" target="_blank">02:16:37.060</a></span> | <span class="t">it took me like 24 hours to train it even that far, so it's kind of slow. And I know</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=8205" target="_blank">02:16:45.020</a></span> | <span class="t">Helena is constantly complaining on Twitter about how long these things take, I don't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=8209" target="_blank">02:16:49.620</a></span> | <span class="t">know how she's so productive with them. So I will mention one more thing that just came</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=8216" target="_blank">02:16:56.980</a></span> | <span class="t">out yesterday, which is there's now a multimodal image-to-image translation of unpaired, and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=8225" target="_blank">02:17:05.220</a></span> | <span class="t">so you can basically now create different cats, for instance, from this dog. So this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=8233" target="_blank">02:17:13.500</a></span> | <span class="t">is basically not just creating one example of the output that you want, but creating</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=8238" target="_blank">02:17:18.980</a></span> | <span class="t">a multimodal one. So here's a house cat to big cat, and here's a big cat to house cat,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=8246" target="_blank">02:17:26.060</a></span> | <span class="t">this is the paper. So this came out like yesterday or the day before, I think. I think it's pretty</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=8251" target="_blank">02:17:31.980</a></span> | <span class="t">amazing cat and a dog. So you can kind of see how this technology is developing, and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=8257" target="_blank">02:17:37.940</a></span> | <span class="t">I think there's so many opportunities to maybe do this with music, or speech, or writing,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=8265" target="_blank">02:17:45.740</a></span> | <span class="t">or to create tools for artists, or whatever. Alright, thanks everybody, and see you next</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=8271" target="_blank">02:17:51.100</a></span> | <span class="t">week.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ondivPiwQho&t=8271" target="_blank">02:17:51.300</a></span> | <span class="t">(audience applauds)</span></div></div></body></html>