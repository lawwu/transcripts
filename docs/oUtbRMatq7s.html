<html><head><title>AGI: (gets close), Humans: ‘Who Gets to Own it?’</title>
<style>
    body {
        font-family: Arial, sans-serif;
        margin: 0;
        padding: 0;
        background-color: #f4f4f4;
        color: #333;
    }
    .container {
        width: 95%;  /* Increased width to use more space */
        margin: auto;
        overflow: auto;  /* Added to handle overflow by adding a scrollbar if necessary */
    }
    h2, h3 {
        color: #333;
        text-align: center;
    }
    a {
        color: #0000FF;  /* Traditional blue color for links */
        text-decoration: none;
    }
    a:hover {
        text-decoration: underline;
    }
    img {
        display: block;
        margin: auto;
        max-width: 100%;
    }
    .c {
        margin: 10px 0;
    }
    .s, .t {
        display: inline-block;
        margin-right: 5px;
    }
    .max-width {
        max-width: 800px;
        margin: auto;
        padding-left: 20px;
    }
    table {
        width: 100%;
        border-collapse: collapse;
    }
    th, td {
        border: 1px solid #ddd;
        padding: 8px;
        text-align: left;  /* Ensure text alignment is consistent */
    }
    tr:nth-child(even) {
        background-color: #f2f2f2;
    }
    tr:nth-child(odd) {
        background-color: #e6e6e6;
    }
</style>

    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-69VLBMTTP0"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-69VLBMTTP0');
    </script>
    </head><body><div class='container'><a href="index.html">back to index</a><h2>AGI: (gets close), Humans: ‘Who Gets to Own it?’</h2><a href="https://www.youtube.com/watch?v=oUtbRMatq7s"><img src="https://i.ytimg.com/vi/oUtbRMatq7s/maxresdefault.jpg" style="width:50%;"></a><div><br></div><h3>Chapters</h3><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=0">0:0</a> Intro<br><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=97">1:37</a> AGI Inches Closer<br><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=266">4:26</a> ‘Super-Exponential’<br><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=358">5:58</a> Musk Bid<br><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=454">7:34</a> Luxury Goods and Land<br><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=545">9:5</a> ‘Benefits All Humanity’<br><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=772">12:52</a> ‘National Security’<br><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=861">14:21</a> s1<br><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=1233">20:33</a> Final thoughts<br><br><div style="text-align: left;"><a href="./oUtbRMatq7s.html">Whisper Transcript</a> | <a href="./transcript_oUtbRMatq7s.html">Transcript Only Page</a></div><br><div style="max-width: 800px;"><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=0" target="_blank">00:00:00.000</a></span> | <span class="t">The world may be waking up to the fact that intelligence will be automated sooner than</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=5" target="_blank">00:00:05.680</a></span> | <span class="t">anyone could have imagined a few years ago, but it is still sleeping when it comes to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=11" target="_blank">00:00:11.280</a></span> | <span class="t">who gets the spoils. Just today, the Vice President of America said that AI will never</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=17" target="_blank">00:00:17.120</a></span> | <span class="t">replace workers and only boost productivity. Then again, Sam Altman, CEO of OpenAI, wrote</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=23" target="_blank">00:00:23.520</a></span> | <span class="t">just yesterday that he could see labor losing its power to capital. And Rand, the famous</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=30" target="_blank">00:00:30.080</a></span> | <span class="t">think tank, put out a paper just the other day that said that the world isn't ready</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=34" target="_blank">00:00:34.200</a></span> | <span class="t">for the "job losses and societal unrest" that it thinks might accompany a more general</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=40" target="_blank">00:00:40.320</a></span> | <span class="t">artificial intelligence. But even if labor does lose, capital can't decide who gets</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=45" target="_blank">00:00:45.840</a></span> | <span class="t">the money. Just today, Musk and co. challenged Sam Altman and Microsoft for control of OpenAI</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=53" target="_blank">00:00:53.500</a></span> | <span class="t">itself. And of course, there are always papers like this one from Stanford suggesting that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=58" target="_blank">00:00:58.720</a></span> | <span class="t">the reasoning enhancements needed to bring a model to frontier capability are achievable</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=63" target="_blank">00:01:03.960</a></span> | <span class="t">for just $20, which makes me think you guys can afford AGI after all. Meanwhile, Dario</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=69" target="_blank">00:01:09.600</a></span> | <span class="t">Amadei, CEO of Anthropic, makers of Claude, says that time is running out to control the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=75" target="_blank">00:01:15.400</a></span> | <span class="t">AGI itself. "I just think that when the day inevitably comes that we must confront</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=80" target="_blank">00:01:20.920</a></span> | <span class="t">the full automation of intelligence. I just hope we are a little more unified, let's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=86" target="_blank">00:01:26.600</a></span> | <span class="t">say, than we are now." There is too much to cover as always, so let's just cut it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=90" target="_blank">00:01:30.880</a></span> | <span class="t">down to the 7 most interesting developments, using the Sam Altman essay as the jumping</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=96" target="_blank">00:01:36.280</a></span> | <span class="t">off point for each. First off, he gives his 5th or maybe 15th different definition for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=102" target="_blank">00:01:42.440</a></span> | <span class="t">AGI, but this time it's "We mean it to be a system that can tackle increasingly</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=107" target="_blank">00:01:47.640</a></span> | <span class="t">complex problems at human level in many fields." Well, under that definition, we are getting</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=113" target="_blank">00:01:53.880</a></span> | <span class="t">awfully close. Take coding, where we heard in December that the O3 model was the 175th</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=121" target="_blank">00:02:01.400</a></span> | <span class="t">highest ranked coder in CodeForce's ELO. Now, that might not mean much to many people,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=126" target="_blank">00:02:06.680</a></span> | <span class="t">but just yesterday in Japan, Sam Altman said they now have internally the 50th highest</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=132" target="_blank">00:02:12.120</a></span> | <span class="t">scoring competitor. We're clearly well beyond imitation learning. These systems O1, O3,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=137" target="_blank">00:02:17.480</a></span> | <span class="t">O4, they're not copying those top 50 competitors saying coding. They are trying things out</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=142" target="_blank">00:02:22.440</a></span> | <span class="t">themselves and teaching themselves through reinforcement learning what works. We are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=146" target="_blank">00:02:26.440</a></span> | <span class="t">not capped at the human level and that applies to way more than just coding. I've been</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=150" target="_blank">00:02:30.580</a></span> | <span class="t">using deep research from OpenAI on the pro tier this week to at least suggest diagnoses</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=157" target="_blank">00:02:37.420</a></span> | <span class="t">for a relative and a doctor I know said that it found things that she wouldn't have thought</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=163" target="_blank">00:02:43.960</a></span> | <span class="t">of. Of course, it does hallucinate fairly frequently, but it also thinks of things you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=168" target="_blank">00:02:48.040</a></span> | <span class="t">might not have thought of. And remember, this is O3 searching maybe 20 sources. What about</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=173" target="_blank">00:02:53.960</a></span> | <span class="t">O5 searching 500? And you might say, well, knowing stuff is cool, but why color workers</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=179" target="_blank">00:02:59.360</a></span> | <span class="t">actually take actions on their computers? Well, Karina Nguyen from OpenAI has this to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=185" target="_blank">00:03:05.760</a></span> | <span class="t">say. On tasks, they're saturating all the benchmarks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=189" target="_blank">00:03:09.260</a></span> | <span class="t">And post-training itself is not hitting the wall. Basically, we went from like raw data</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=195" target="_blank">00:03:15.620</a></span> | <span class="t">sets from pre-trained models to infinite amount of tasks that you can teach the model in the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=203" target="_blank">00:03:23.760</a></span> | <span class="t">post-training world via reinforcement learning. So any task, for example, like how to search</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=210" target="_blank">00:03:30.700</a></span> | <span class="t">the web, how to use the computer, how to write, well, like all sorts of tasks that you like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=217" target="_blank">00:03:37.900</a></span> | <span class="t">trying to teach the model, all the different skills. And that's why we think like there's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=222" target="_blank">00:03:42.340</a></span> | <span class="t">no data wall or whatever, because there will be infinite amount of tasks. And that's how</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=228" target="_blank">00:03:48.340</a></span> | <span class="t">the model becomes extremely super intelligent. And VR actually getting saturated in all benchmarks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=234" target="_blank">00:03:54.740</a></span> | <span class="t">So I think the bottleneck is actually in evaluations.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=237" target="_blank">00:03:57.860</a></span> | <span class="t">And there's a reason I can believe that even though their current operator system, only</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=241" target="_blank">00:04:01.900</a></span> | <span class="t">available on Pro for $200 a month, is quite jank. It's because tasks like buying something</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=247" target="_blank">00:04:07.680</a></span> | <span class="t">online or filling out a spreadsheet are mostly verifiable. And whenever you hear verifiable</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=252" target="_blank">00:04:12.780</a></span> | <span class="t">or checkable, think ready to be absolutely eaten by reinforcement learning. Just like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=258" target="_blank">00:04:18.060</a></span> | <span class="t">domains like code, where you can see the impact of enhanced reinforcement learning from 01</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=263" target="_blank">00:04:23.980</a></span> | <span class="t">preview to 03. Next is the investment that must go in to make all of this happen. And</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=268" target="_blank">00:04:28.740</a></span> | <span class="t">Sam Altman had this to say later on in the essay, "The scaling laws that predict intelligence</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=274" target="_blank">00:04:34.060</a></span> | <span class="t">improvements have been accurate over many orders of magnitude. Give or take the intelligence</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=279" target="_blank">00:04:39.260</a></span> | <span class="t">of an AI model roughly equals the log of the resources used to train and run it." So think</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=283" target="_blank">00:04:43.980</a></span> | <span class="t">of that as 10xing the resources you put in to get one incremental step forward in intelligence.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=290" target="_blank">00:04:50.500</a></span> | <span class="t">Doesn't sound super impressive until you read the third point. And I agree with this point.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=294" target="_blank">00:04:54.700</a></span> | <span class="t">The socioeconomic value of linearly increasing intelligence, each increment, is super exponential.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=301" target="_blank">00:05:01.140</a></span> | <span class="t">In short, if someone could somehow double the intelligence of 03, it wouldn't be worth</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=306" target="_blank">00:05:06.020</a></span> | <span class="t">4x more to me, and I think to many people, it would be worth way, way more than that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=310" target="_blank">00:05:10.460</a></span> | <span class="t">It would be super exponential. He goes on, "A consequence of this is that we see no reason</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=315" target="_blank">00:05:15.820</a></span> | <span class="t">for the exponentially increasing investment to stop in the near future." In other words,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=320" target="_blank">00:05:20.340</a></span> | <span class="t">if AI will always pay you back tenfold for what you invest in it, why ever stop investing?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=326" target="_blank">00:05:26.820</a></span> | <span class="t">Many forget this, but less than two years ago, Sam Altman himself said that his grand</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=331" target="_blank">00:05:31.060</a></span> | <span class="t">idea is that OpenAI will capture much of the world's wealth through the creation of AGI,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=336" target="_blank">00:05:36.780</a></span> | <span class="t">and then redistribute it to the people. We're talking figures like not just 100 billion,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=341" target="_blank">00:05:41.700</a></span> | <span class="t">but a trillion, or even 100 trillion. That's coming from him. Only adds, if AGI does create</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=347" target="_blank">00:05:47.140</a></span> | <span class="t">all that wealth, he's not sure how the company will redistribute it. To give you a sense</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=351" target="_blank">00:05:51.260</a></span> | <span class="t">of scale, as you head towards 100 trillion, you're talking about the scale of the entire</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=356" target="_blank">00:05:56.460</a></span> | <span class="t">labor force of the planet. And that, of course, brings us to others who don't want him to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=361" target="_blank">00:06:01.980</a></span> | <span class="t">have that control, or maybe want that control for themselves. As you may have heard about,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=367" target="_blank">00:06:07.500</a></span> | <span class="t">Elon Musk has bid almost 100 billion for OpenAI, or at least it's a bid for the non-profit</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=374" target="_blank">00:06:14.200</a></span> | <span class="t">which currently controls OpenAI. To save you reading half a dozen reports, essentially</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=379" target="_blank">00:06:19.500</a></span> | <span class="t">it looks like Sam Altman and OpenAI have valued that non-profit's stake in OpenAI at around</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=386" target="_blank">00:06:26.380</a></span> | <span class="t">$40 billion. That leaves plenty of equity left for Microsoft and OpenAI itself, including</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=392" target="_blank">00:06:32.380</a></span> | <span class="t">its employees. However, if Musk and others have valued that stake at $100 billion, then</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=399" target="_blank">00:06:39.380</a></span> | <span class="t">it might be very difficult in court for Altman and co. to say it's worth only $40 billion.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=405" target="_blank">00:06:45.820</a></span> | <span class="t">So even if they reject, as it seems like they have done, Musk's offer, it forces them</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=411" target="_blank">00:06:51.180</a></span> | <span class="t">to potentially dilute the stake owned by Microsoft and the employees. Altman said to the employees</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=417" target="_blank">00:06:57.380</a></span> | <span class="t">at OpenAI that these are just tactics to try and weaken us because we're making great</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=422" target="_blank">00:07:02.300</a></span> | <span class="t">progress. The non-profit behind OpenAI could also reject the offer because it thinks that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=427" target="_blank">00:07:07.780</a></span> | <span class="t">AGI wouldn't be safe in the hands of Musk. At this point, I just can't resist doing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=432" target="_blank">00:07:12.480</a></span> | <span class="t">a quick plug for a mini documentary I released on my Patreon just yesterday. It actually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=438" target="_blank">00:07:18.100</a></span> | <span class="t">covers the origin stories of DeepMind, OpenAI, the tussle with Musk and Anthropic and how</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=444" target="_blank">00:07:24.300</a></span> | <span class="t">the founding vision of each of those AGI labs went awry. This time, by the way, I used a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=449" target="_blank">00:07:29.780</a></span> | <span class="t">professional video editor and the early reviews seemed to be good. All the shenanigans that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=454" target="_blank">00:07:34.820</a></span> | <span class="t">are going on with the non-profit at OpenAI seem worthy of an entire video on their own.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=461" target="_blank">00:07:41.260</a></span> | <span class="t">So for now, I'm going to move on to the next point.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=464" target="_blank">00:07:44.060</a></span> | <span class="t">Sam Altman predicted that with the advent of AGI, the price of many goods will eventually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=469" target="_blank">00:07:49.300</a></span> | <span class="t">fall dramatically. It seems like one way to assuage people who lose their job or see their</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=474" target="_blank">00:07:54.700</a></span> | <span class="t">wages drop is that, well, at least your TV is cheaper. But he did say the price of luxury</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=480" target="_blank">00:08:00.460</a></span> | <span class="t">goods and land may rise even more dramatically. Now, I don't know what you think, but I live</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=487" target="_blank">00:08:07.380</a></span> | <span class="t">in London and the price of land is already pretty dramatic. So who knows what it will</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=493" target="_blank">00:08:13.100</a></span> | <span class="t">be after AGI. But just on that luxury goods point, I think Sam Altman might have one particular</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=499" target="_blank">00:08:19.340</a></span> | <span class="t">luxury good in mind. Yesterday in London, Sam Altman was asked about their hardware</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=504" target="_blank">00:08:24.860</a></span> | <span class="t">device designed in part by Johnny Ive from Apple. And he said, it's incredible. It really</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=511" target="_blank">00:08:31.360</a></span> | <span class="t">is. I'm proud of it. And it's just a year away. Yes, by the way, I did apply to be at</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=516" target="_blank">00:08:36.380</a></span> | <span class="t">that event, but you had to have certain org IDs, which I didn't. One thing that might</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=520" target="_blank">00:08:40.960</a></span> | <span class="t">not be a luxury device are smaller language models. In leaked audio of that same event,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=527" target="_blank">00:08:47.760</a></span> | <span class="t">he apparently said, well, one idea would be we put out O3 and then open source O3 mini.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=533" target="_blank">00:08:53.420</a></span> | <span class="t">We put out O4 and open source O4 mini. He added, this is not a decision, but directionally</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=539" target="_blank">00:08:59.900</a></span> | <span class="t">you could imagine us saying this. Take all of that for what it is worth.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=544" target="_blank">00:09:04.620</a></span> | <span class="t">The next jumping off point comes in the first sentence actually of this essay, which is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=549" target="_blank">00:09:09.740</a></span> | <span class="t">that the mission of OpenAI is to ensure that AGI benefits all of humanity. Not that they</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=555" target="_blank">00:09:15.640</a></span> | <span class="t">make AGI, that they make an AGI that benefits all of humanity. Now, originally when they</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=560" target="_blank">00:09:20.680</a></span> | <span class="t">were founded, which I covered in the documentary, the charter was that they make AGI that benefits</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=566" target="_blank">00:09:26.200</a></span> | <span class="t">all of humanity unencumbered by the need for a financial return. But that last bit's gone,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=571" target="_blank">00:09:31.540</a></span> | <span class="t">but we still have that it benefits all of humanity. Not most of humanity, by the way,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=575" target="_blank">00:09:35.940</a></span> | <span class="t">benefits all of humanity. I really don't know how they are going to achieve that when they</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=581" target="_blank">00:09:41.660</a></span> | <span class="t">themselves admit that the vast majority of human labor might soon become redundant. Even</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=586" target="_blank">00:09:46.980</a></span> | <span class="t">if they somehow got implemented a benevolent policy in the US to make sure that everyone</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=593" target="_blank">00:09:53.140</a></span> | <span class="t">was looked after, how could you ensure that for other nations?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=596" target="_blank">00:09:56.420</a></span> | <span class="t">After watching Yoshua Bengio, one of the godfathers of AI, and I'll show you the clip in a second,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=601" target="_blank">00:10:01.220</a></span> | <span class="t">I did have this thought. It seems to me if a nation got to AGI or super intelligence</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=606" target="_blank">00:10:06.380</a></span> | <span class="t">one month, three months, six months before another one, it's not the most likely that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=611" target="_blank">00:10:11.500</a></span> | <span class="t">they would use that advantage to just wipe out other nations. I think more likely would</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=616" target="_blank">00:10:16.860</a></span> | <span class="t">be to wipe out the economies of other nations. The US might automate the economy of say China</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=623" target="_blank">00:10:23.460</a></span> | <span class="t">or China, the US, and then take that wealth and distribute it amongst its people. And</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=628" target="_blank">00:10:28.580</a></span> | <span class="t">Yoshua Bengio thinks that that might even apply at the level of companies.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=632" target="_blank">00:10:32.500</a></span> | <span class="t">I can see from the declarations that are made and, you know, what, you know, logically these</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=637" target="_blank">00:10:37.540</a></span> | <span class="t">people would do is that the people who control these systems, like say open AI potentially,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=644" target="_blank">00:10:44.780</a></span> | <span class="t">they're not going to continue just selling the access to their AI. They're going to give</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=650" target="_blank">00:10:50.980</a></span> | <span class="t">access to, you know, a lower grade AI. They're going to keep the really powerful ones for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=655" target="_blank">00:10:55.940</a></span> | <span class="t">themselves and they're going to build companies that are going to compete with the non-AI,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=661" target="_blank">00:11:01.100</a></span> | <span class="t">you know, systems that exist. And they're going to basically wipe out the economies</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=665" target="_blank">00:11:05.360</a></span> | <span class="t">of all the other countries which don't have these superintelligent systems. So it's, you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=673" target="_blank">00:11:13.160</a></span> | <span class="t">know, you say it's, you wrote it's not existential, but I think it is existential for countries</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=678" target="_blank">00:11:18.660</a></span> | <span class="t">who don't build up to this kind of level of AI. And it's an emergency because it's going</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=686" target="_blank">00:11:26.340</a></span> | <span class="t">to take at least several years, even with the coalition of the willing to bridge that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=692" target="_blank">00:11:32.900</a></span> | <span class="t">And just very quickly, I can't help, because he mentioned competitor companies to mention</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=698" target="_blank">00:11:38.000</a></span> | <span class="t">Gemini 2 Pro and Flash from Google, new models from Google DeepMind. There's also of course</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=703" target="_blank">00:11:43.720</a></span> | <span class="t">Gemini Thinking, which replicates the kind of reasoning traces of say O3 Mini or DeepSeek</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=708" target="_blank">00:11:48.720</a></span> | <span class="t">R1. Now straight off the benchmark results of these models are decent, but not stratospheric.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=715" target="_blank">00:11:55.000</a></span> | <span class="t">For the most part, we're not talking O3 or DeepSeek R1 levels. On SimpleBench we're rate</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=719" target="_blank">00:11:59.480</a></span> | <span class="t">limited, but it seems like the scores of both the Thinking Mode and Gemini 2 Pro will gravitate</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=725" target="_blank">00:12:05.520</a></span> | <span class="t">around the same level as the "Gemini Experimental 1206". But I will say this, I know it's kind</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=731" target="_blank">00:12:11.280</a></span> | <span class="t">of niche. Gemini is amazing at quickly reading vast amounts of PDFs and other files. No,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=738" target="_blank">00:12:18.760</a></span> | <span class="t">it's transcription accuracy of audio and I've tested isn't going to be at the level of say</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=743" target="_blank">00:12:23.200</a></span> | <span class="t">Assembly AI and no, it's coding is no O3 and it's "deep research" button is no deep research,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=750" target="_blank">00:12:30.080</a></span> | <span class="t">but the Gemini series are great at extracting text from files and they are incredibly cheap.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=756" target="_blank">00:12:36.040</a></span> | <span class="t">So I'm quite impressed. And I do suspect as Chachapiti just recently overtook Twitter to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=761" target="_blank">00:12:41.200</a></span> | <span class="t">become the sixth most visited site and slowly starts closing in on Google, that Google will</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=766" target="_blank">00:12:46.600</a></span> | <span class="t">invest more and more and more to ensure that Gemini 3 is state of the art. Next, Ullman</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=772" target="_blank">00:12:52.400</a></span> | <span class="t">wrote about a likely path that he sees is AI being used by authoritarian governments</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=777" target="_blank">00:12:57.400</a></span> | <span class="t">to control their population through mass surveillance and loss of autonomy. And that remark brings</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=783" target="_blank">00:13:03.060</a></span> | <span class="t">me to the RAND paper that for some reason I read in full, because they're worried by</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=788" target="_blank">00:13:08.400</a></span> | <span class="t">not just mass surveillance by authoritarian dictatorships, but other threats to quote</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=793" target="_blank">00:13:13.640</a></span> | <span class="t">national security. Wonder weapons, systemic shifts in power, kind of talked about that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=798" target="_blank">00:13:18.560</a></span> | <span class="t">earlier with say China automating the economy of the US, non-experts in power to develop</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=803" target="_blank">00:13:23.520</a></span> | <span class="t">weapons of mass destruction, artificial entities with agency, think O6 kind of coming alive</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=809" target="_blank">00:13:29.160</a></span> | <span class="t">and instability. This is RAND again, which has been around for over 75 years and is not</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=815" target="_blank">00:13:35.160</a></span> | <span class="t">known for dramatic statements. Again, I would ask though that if the US does a quote large</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=820" target="_blank">00:13:40.280</a></span> | <span class="t">national effort to ensure that they obtain a decisive AI enabled wonder weapon before</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=826" target="_blank">00:13:46.240</a></span> | <span class="t">China, say three months before, six months before, then what? Are you really going to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=830" target="_blank">00:13:50.080</a></span> | <span class="t">use it to then disable the tech sector of China? For me, the real admission comes towards</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=835" target="_blank">00:13:55.800</a></span> | <span class="t">the end of this paper where they say the US is not well positioned to realise the ambitious</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=842" target="_blank">00:14:02.160</a></span> | <span class="t">economic benefits of AGI without widespread unemployment and accompanying societal unrest.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=848" target="_blank">00:14:08.580</a></span> | <span class="t">And I still remember the days when Ullman used to say in interviews, it's just around</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=852" target="_blank">00:14:12.280</a></span> | <span class="t">two years ago, he said stuff like, if AGI produces the kind of inequality that he thinks</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=857" target="_blank">00:14:17.960</a></span> | <span class="t">it will, people won't take it anymore. Let's now though, get to some signs that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=862" target="_blank">00:14:22.440</a></span> | <span class="t">AGI might not even be controlled by countries or even companies. For less than $50 worth</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=869" target="_blank">00:14:29.260</a></span> | <span class="t">of compute time, of course, not counting research time, but for around apparently $20 worth</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=874" target="_blank">00:14:34.400</a></span> | <span class="t">of compute time, affordable for all of you guys, Stanford produced S1. Now, yes, of course,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=880" target="_blank">00:14:40.360</a></span> | <span class="t">they did utilise an open weight base model, QUEN 2.5, 32 billion parameters in struct,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=886" target="_blank">00:14:46.100</a></span> | <span class="t">but the headline is with just a thousand questions worth of data, they could bring that tiny</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=892" target="_blank">00:14:52.360</a></span> | <span class="t">model to being competitive with O1. This is in science, GPQA and competition level mathematics.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=899" target="_blank">00:14:59.840</a></span> | <span class="t">The key methodology was, well, whenever the model wanted to stop, they forced it to continue</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=905" target="_blank">00:15:05.520</a></span> | <span class="t">by adding weight, literally the token weight, multiple times to the model's generation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=911" target="_blank">00:15:11.520</a></span> | <span class="t">when it tried to end. Imagine you sitting in an exam and every time</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=914" target="_blank">00:15:14.560</a></span> | <span class="t">you think you've come to an answer and you're ready to write it down, a voice in your head</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=918" target="_blank">00:15:18.880</a></span> | <span class="t">says, wait, that's kind of what happened until the student or you had taken a set amount</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=925" target="_blank">00:15:25.240</a></span> | <span class="t">of time on the problem. Appropriately then, this is called test time scaling, scaling</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=930" target="_blank">00:15:30.640</a></span> | <span class="t">up the amount of tokens spent to answer each question. I've reviewed the questions, by</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=935" target="_blank">00:15:35.520</a></span> | <span class="t">the way, in the math 500 benchmark, and they are tough. So to get 95%, at least the hard</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=941" target="_blank">00:15:41.000</a></span> | <span class="t">ones, the level five ones are, so to get 95% in that is impressive. Likewise, of course,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=945" target="_blank">00:15:45.840</a></span> | <span class="t">to get beyond 60% in GPQA diamond, which roughly matches the level of PhDs in those domains.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=952" target="_blank">00:15:52.920</a></span> | <span class="t">To recap, this is an off the shelf open weights model trained with just a thousand questions</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=958" target="_blank">00:15:58.000</a></span> | <span class="t">and reasoning traces. There were some famed professors in this Stanford team and their</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=962" target="_blank">00:16:02.760</a></span> | <span class="t">goal, by the way, was to replicate this chart on the right, which came in September from</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=967" target="_blank">00:16:07.920</a></span> | <span class="t">OpenAI. Now we kind of already know that the more pre-training you do and post-training</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=972" target="_blank">00:16:12.640</a></span> | <span class="t">with reinforcement learning you do, the better the performance will be. But what about time</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=977" target="_blank">00:16:17.460</a></span> | <span class="t">taken to actually answer questions, test time compute? That's the chart they wanted to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=982" target="_blank">00:16:22.040</a></span> | <span class="t">replicate. Going back to the S1 paper, they say, despite the large number of O1 replication</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=986" target="_blank">00:16:26.760</a></span> | <span class="t">attempts, none have openly replicated a clear test time scaling behavior and look how they</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=992" target="_blank">00:16:32.520</a></span> | <span class="t">have done so. I'm going to simplify their approach a little bit because it's the finding</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=996" target="_blank">00:16:36.560</a></span> | <span class="t">that I'm more interested in, but essentially they sourced 59,000 tough questions. Physics</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=1002" target="_blank">00:16:42.640</a></span> | <span class="t">Olympiads, astronomy, competition level mathematics, and AGI eval. I remember covering that paper</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=1007" target="_blank">00:16:47.800</a></span> | <span class="t">like almost two years ago on this channel. They got Gemini thinking, the one that outputs</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=1012" target="_blank">00:16:52.160</a></span> | <span class="t">thinking tokens like DeepSeek R1 does to generate reasoning traces and answers for each of those</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=1017" target="_blank">00:16:57.840</a></span> | <span class="t">59,000 examples. Now they could have just trained on all of those examples, but that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=1024" target="_blank">00:17:04.120</a></span> | <span class="t">did not offer substantial gains over just picking a thousand of them. Just a thousand</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=1028" target="_blank">00:17:08.860</a></span> | <span class="t">examples in say your domain to get a small model to be a true reasoner. Then of course</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=1034" target="_blank">00:17:14.200</a></span> | <span class="t">get it to think for a while with that weight trick. How to filter down from 59,000 examples</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=1039" target="_blank">00:17:19.360</a></span> | <span class="t">to 1,000 by the way. First decontaminate, you don't want any questions that you're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=1043" target="_blank">00:17:23.520</a></span> | <span class="t">going to use to then test the model of course. Remove examples that rely on images that aren't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=1048" target="_blank">00:17:28.600</a></span> | <span class="t">found in the question, for example, and other formatting stuff. But more interestingly,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=1054" target="_blank">00:17:34.040</a></span> | <span class="t">difficulty and diversity. This is the kind of diversity that even JD Vance would get</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=1058" target="_blank">00:17:38.320</a></span> | <span class="t">behind. On difficulty, they got smaller models to try those questions. And if those smaller</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=1062" target="_blank">00:17:42.880</a></span> | <span class="t">models got the questions right, they excluded them. They must be too easy. On diversity,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=1068" target="_blank">00:17:48.000</a></span> | <span class="t">they wanted to cover as many topics as possible from mathematics and science, for example.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=1073" target="_blank">00:17:53.960</a></span> | <span class="t">They ended up with around 20 questions from 50 different domains. They then fine-tuned</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=1079" target="_blank">00:17:59.120</a></span> | <span class="t">that base model on those a thousand examples with the reasoning traces from Gemini. And</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=1083" target="_blank">00:18:03.360</a></span> | <span class="t">if you're wondering about DeepSeek R1, they fine-tuned with 800,000 examples. Actually,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=1089" target="_blank">00:18:09.760</a></span> | <span class="t">you can see that in this chart on the right here. Again, it wasn't just about fine-tuning</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=1094" target="_blank">00:18:14.360</a></span> | <span class="t">each time the model would try to stop. They said wait sometimes two, four, or six times</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=1100" target="_blank">00:18:20.440</a></span> | <span class="t">to keep boosting performance. Basically, it forces the model to check its own output and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=1105" target="_blank">00:18:25.200</a></span> | <span class="t">see if it can improve it. Notice weight is fairly neutral. You're not telling the model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=1109" target="_blank">00:18:29.200</a></span> | <span class="t">that it's wrong. You're saying, wait, maybe do we need to check that? They also tried</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=1113" target="_blank">00:18:33.160</a></span> | <span class="t">scaling up majority voting or self-consistency, and it didn't quite have the same slope. Suffice</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=1118" target="_blank">00:18:38.980</a></span> | <span class="t">to say though, if anyone watching is in any confusion, getting these kinds of scores in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=1123" target="_blank">00:18:43.440</a></span> | <span class="t">GPQA, Google Proof Question and Answer, and competition level mathematics, it's insane.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=1129" target="_blank">00:18:49.400</a></span> | <span class="t">Incredibly impressive. Of course, if you took this same model and tested it in a different</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=1133" target="_blank">00:18:53.400</a></span> | <span class="t">domain, it would likely perform relatively poorly. Also, side note, when they say open</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=1137" target="_blank">00:18:57.960</a></span> | <span class="t">data, they mean those thousand examples that they fine-tuned the base model on. The actual</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=1142" target="_blank">00:19:02.800</a></span> | <span class="t">base model doesn't have open data. So it's not truly open data. As in, we don't know</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=1147" target="_blank">00:19:07.440</a></span> | <span class="t">everything that went into the base model. Everything that Quen 2.5, 32 billion parameters,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=1152" target="_blank">00:19:12.920</a></span> | <span class="t">was trained on. Interestingly, they would have gone further, but the actual context</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=1157" target="_blank">00:19:17.000</a></span> | <span class="t">window of the underlying language model constrains it. And Karpathy, in his excellent Chatterbitty</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=1162" target="_blank">00:19:22.560</a></span> | <span class="t">video this week, talked about how it's an open research question about how to extend</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=1167" target="_blank">00:19:27.800</a></span> | <span class="t">the context window suitably at the frontier. It's a three and a half hour video, but it's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=1171" target="_blank">00:19:31.920</a></span> | <span class="t">a definite recommend from me. Actually, speaking of Karpathy, his reaction to this very paper</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=1176" target="_blank">00:19:36.880</a></span> | <span class="t">was "cute idea, reminds me of let's think step-by-step trick. That's where you told</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=1181" target="_blank">00:19:41.960</a></span> | <span class="t">the model to think step-by-step so it spent more tokens to reason first before giving</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=1186" target="_blank">00:19:46.160</a></span> | <span class="t">you an answer. Here, by saying wait, we're forcing the model to think for longer. Both</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=1190" target="_blank">00:19:50.320</a></span> | <span class="t">lean, he said, on the language prior to steer the thoughts." And speaking of spending</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=1194" target="_blank">00:19:54.240</a></span> | <span class="t">your time well by watching a Karpathy video, I would argue you can spend your money pretty</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=1199" target="_blank">00:19:59.680</a></span> | <span class="t">well by researching which, say, charity to give to through GiveWell. They are the sponsors</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=1205" target="_blank">00:20:05.480</a></span> | <span class="t">of this video, but I've actually been using them for, I think, 13 years. They have incredibly</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=1210" target="_blank">00:20:10.780</a></span> | <span class="t">rigorous methodology, backed by 60,000+ hours of research each year on which charities save</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=1217" target="_blank">00:20:17.800</a></span> | <span class="t">the most lives, essentially. The one that I've gone for, for actually all of those</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=1222" target="_blank">00:20:22.000</a></span> | <span class="t">13 years, is the Against Malaria Foundation, I think started in the UK. Anyway, do check</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=1226" target="_blank">00:20:26.520</a></span> | <span class="t">out GiveWell, the links are in the description, and you can even put in where you first heard</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=1231" target="_blank">00:20:31.080</a></span> | <span class="t">of them. So obviously, you could put, say, AI Explained. But alas, we are drawing to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=1235" target="_blank">00:20:35.040</a></span> | <span class="t">the end, so I've got one more point from the Sam Wallman essay that I wanted to get</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=1238" target="_blank">00:20:38.600</a></span> | <span class="t">to. In previous essays, he's talked about the value of labour going to zero. Now he</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=1242" target="_blank">00:20:42.720</a></span> | <span class="t">just talks about the balance of power between capital and labour getting messed up. But</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=1247" target="_blank">00:20:47.120</a></span> | <span class="t">interestingly, he adds, this may require early intervention. Now, OpenAI have funded studies</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=1252" target="_blank">00:20:52.320</a></span> | <span class="t">into UBI with, let's say, mixed results, so it's interesting he doesn't specifically</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=1256" target="_blank">00:20:56.860</a></span> | <span class="t">advocate for universal basic income. He just talks about early intervention, then talks</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=1260" target="_blank">00:21:00.920</a></span> | <span class="t">about compute budgets and being open to strange-sounding ideas. But I would say, if AGI is coming in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=1266" target="_blank">00:21:06.400</a></span> | <span class="t">two to five years, then the quote "early intervention" would have to happen, say,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=1270" target="_blank">00:21:10.480</a></span> | <span class="t">now? I must confess, though, at this stage, that I feel like we desperately need preparation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=1275" target="_blank">00:21:15.880</a></span> | <span class="t">for what's coming, but it's quite hard to actually specifically say what I'm advocating</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=1280" target="_blank">00:21:20.360</a></span> | <span class="t">the preparation be. Then we get renewed calls just today from the CEO of Anthropic, Dario</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=1285" target="_blank">00:21:25.160</a></span> | <span class="t">Amadei, about how AI will become a country of geniuses in a data centre, possibly by</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=1290" target="_blank">00:21:30.400</a></span> | <span class="t">2026 or 2027, and almost certainly no later than 2030. He said that governments are not</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=1296" target="_blank">00:21:36.800</a></span> | <span class="t">doing enough to hold the big AI labs to account and measure risks and, at the next international</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=1303" target="_blank">00:21:43.600</a></span> | <span class="t">summit – there was one just this week – we should not repeat this missed opportunity.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=1308" target="_blank">00:21:48.080</a></span> | <span class="t">These issues should be at the top of the agenda. The advance of AI presents major new global</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=1313" target="_blank">00:21:53.200</a></span> | <span class="t">challenges. We must move faster and with greater clarity to confront them. I mean, I'm sold</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=1318" target="_blank">00:21:58.760</a></span> | <span class="t">and I think many of you are, that change is coming very rapidly and sooner than the vast</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=1324" target="_blank">00:22:04.360</a></span> | <span class="t">majority of people on the planet think. The question for me that I'll have to reflect</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=1328" target="_blank">00:22:08.120</a></span> | <span class="t">on is, well, what are we going to do about it? Let me know what you think in the comments</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=oUtbRMatq7s&t=1332" target="_blank">00:22:12.560</a></span> | <span class="t">but above all, thank you so much for watching to the end and have a wonderful day.</span></div></div></body></html>