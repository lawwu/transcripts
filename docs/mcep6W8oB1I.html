<html><head><title>Stanford CS25: V3 I Recipe for Training Helpful Chatbots</title>
<style>
    body {
        font-family: Arial, sans-serif;
        margin: 0;
        padding: 0;
        background-color: #f4f4f4;
        color: #333;
    }
    .container {
        width: 95%;  /* Increased width to use more space */
        margin: auto;
        overflow: auto;  /* Added to handle overflow by adding a scrollbar if necessary */
    }
    h2, h3 {
        color: #333;
        text-align: center;
    }
    a {
        color: #0000FF;  /* Traditional blue color for links */
        text-decoration: none;
    }
    a:hover {
        text-decoration: underline;
    }
    img {
        display: block;
        margin: auto;
        max-width: 100%;
    }
    .c {
        margin: 10px 0;
    }
    .s, .t {
        display: inline-block;
        margin-right: 5px;
    }
    .max-width {
        max-width: 800px;
        margin: auto;
        padding-left: 20px;
    }
    table {
        width: 100%;
        border-collapse: collapse;
    }
    th, td {
        border: 1px solid #ddd;
        padding: 8px;
        text-align: left;  /* Ensure text alignment is consistent */
    }
    tr:nth-child(even) {
        background-color: #f2f2f2;
    }
    tr:nth-child(odd) {
        background-color: #e6e6e6;
    }
</style>

    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-69VLBMTTP0"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-69VLBMTTP0');
    </script>
    </head><body><div class='container'><a href="index.html">back to index</a><h2>Stanford CS25: V3 I Recipe for Training Helpful Chatbots</h2><a href="https://www.youtube.com/watch?v=mcep6W8oB1I"><img src="https://i.ytimg.com/vi/mcep6W8oB1I/maxresdefault.jpg" style="width:50%;"></a><div><br></div><div style="text-align: left;"><a href="./mcep6W8oB1I.html">Whisper Transcript</a> | <a href="./transcript_mcep6W8oB1I.html">Transcript Only Page</a></div><br><div style="max-width: 800px;"><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=0" target="_blank">00:00:00.000</a></span> | <span class="t">>> Hello, everyone. Today we have Nezni from Hugging Face, who is working on AI safety</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=13" target="_blank">00:00:13.960</a></span> | <span class="t">and alignment using reinforcement learning with human feedback. She's an expert in the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=20" target="_blank">00:00:20.000</a></span> | <span class="t">space of large language models and their evaluation. Before Hugging Face, she led a team of researchers</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=29" target="_blank">00:00:29.480</a></span> | <span class="t">at Salesforce focused on building robust natural language generation systems based on LLMs,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=36" target="_blank">00:00:36.880</a></span> | <span class="t">and she got her Ph.D. at UT Austin in computer science. So, everyone, welcome.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=45" target="_blank">00:00:45.000</a></span> | <span class="t">>> Thanks for having me. So, the title of my talk today is recipes for training helpful</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=53" target="_blank">00:00:53.880</a></span> | <span class="t">chatbots. So, here's the introduction. I was part of this team called the H4 at Hugging</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=60" target="_blank">00:01:00.800</a></span> | <span class="t">Face, and today I'll walk you through what we built, how we decided on what we need for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=67" target="_blank">00:01:07.360</a></span> | <span class="t">building that. And so, essentially, what we wanted to build and the goal of the team and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=71" target="_blank">00:01:11.200</a></span> | <span class="t">the project since earlier this year was to figure out a recipe for H4, which stands for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=77" target="_blank">00:01:17.400</a></span> | <span class="t">helpful, harmless, honest, and huggy because it's Hugging Face chatbot. And so, the ingredients</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=83" target="_blank">00:01:23.920</a></span> | <span class="t">essentially were to figure out what kind of data sets do we need for supervised trine</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=88" target="_blank">00:01:28.800</a></span> | <span class="t">tuning and RLHF. And we wanted to not worry about pre-training. Instead, take an open</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=96" target="_blank">00:01:36.000</a></span> | <span class="t">source pre-trained model and recreate the secret sauce of alignment on it. And the procedure</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=101" target="_blank">00:01:41.440</a></span> | <span class="t">that we wanted to follow and replicate on open source is this figure that I'm pretty</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=106" target="_blank">00:01:46.560</a></span> | <span class="t">sure most of you are familiar with at this point. It's from this instruct GPD paper from</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=110" target="_blank">00:01:50.960</a></span> | <span class="t">OpenAI, which shows three steps. I'm going to go into a bit more detail on this because</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=118" target="_blank">00:01:58.160</a></span> | <span class="t">this slide is much smaller. But this is what the outline of the talk looks like. I'll be</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=123" target="_blank">00:02:03.360</a></span> | <span class="t">getting the detail of how did we decide what kind of data, how much data, and all the details</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=128" target="_blank">00:02:08.760</a></span> | <span class="t">of the data for supervised fine tuning. Then similarly for RLHF. Then I'm going to talk</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=134" target="_blank">00:02:14.640</a></span> | <span class="t">about distillation of language model alignment. Then experiments with different helpfulness</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=141" target="_blank">00:02:21.080</a></span> | <span class="t">recipes. Finally, talk about evaluation of these models and quirks of using GPD 4 as</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=147" target="_blank">00:02:27.080</a></span> | <span class="t">an evaluator.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=148" target="_blank">00:02:28.840</a></span> | <span class="t">Okay, so this is kind of like, you know, what overall recipe that instruct GPD paper from</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=154" target="_blank">00:02:34.680</a></span> | <span class="t">OpenAI put forward as, you know, the steps for training a chatbot. So, the first step</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=160" target="_blank">00:02:40.720</a></span> | <span class="t">over here is to do supervised fine tuning. Essentially, like, you know, you're doing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=164" target="_blank">00:02:44.920</a></span> | <span class="t">fine tuning with human instruction demonstration data. So, the input and the output are both</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=170" target="_blank">00:02:50.440</a></span> | <span class="t">given by humans. The step two is, like, you know, the input is given by a human. The output</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=175" target="_blank">00:02:55.760</a></span> | <span class="t">comes from models. And then the human just rates thumbs up, thumbs down, or ranks them.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=181" target="_blank">00:03:01.080</a></span> | <span class="t">And then you train a reward model, which is essentially just a classifier. And then the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=184" target="_blank">00:03:04.600</a></span> | <span class="t">final step three is doing fine tuning using that reward model with reinforcement learning.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=190" target="_blank">00:03:10.840</a></span> | <span class="t">And so, the way I'm looking at it, like, step one is more for, like, you know, making a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=195" target="_blank">00:03:15.060</a></span> | <span class="t">model into a helpful chatbot. And the steps two and three are essentially trying to add</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=200" target="_blank">00:03:20.080</a></span> | <span class="t">those guardrails in place for harmlessness. So, let's get started with talking about helpfulness.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=206" target="_blank">00:03:26.360</a></span> | <span class="t">And most of my talk today will be focused on the step one. So, let's start diving deeper</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=214" target="_blank">00:03:34.240</a></span> | <span class="t">into this. And let's start with the data set. Like, how do we decide what we need for doing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=219" target="_blank">00:03:39.760</a></span> | <span class="t">the supervised fine tuning? So, like, the data set for helpfulness for supervised fine</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=225" target="_blank">00:03:45.160</a></span> | <span class="t">tuning looks somewhat like this. This is from the self-instruct paper, if you're aware of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=230" target="_blank">00:03:50.320</a></span> | <span class="t">that from end of last year. So, you have something that we call as a task, which then has an</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=235" target="_blank">00:03:55.560</a></span> | <span class="t">instruction, which is essentially a request by a user asking the model to, like, fulfill</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=240" target="_blank">00:04:00.840</a></span> | <span class="t">or, like, give a response to a certain task. And that is followed by input and output.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=246" target="_blank">00:04:06.920</a></span> | <span class="t">The input in this case is optional. It could just be part of the instruction. And then</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=251" target="_blank">00:04:11.760</a></span> | <span class="t">the output is the expected output that the model should generate. But while we are doing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=256" target="_blank">00:04:16.320</a></span> | <span class="t">this training, the human provides the expected output that the model would have generated</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=261" target="_blank">00:04:21.240</a></span> | <span class="t">in the actual test case. And so, here the input and the output are called instance or</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=267" target="_blank">00:04:27.000</a></span> | <span class="t">demonstration or completion. And that's why this is called instruction demonstration.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=272" target="_blank">00:04:32.840</a></span> | <span class="t">So, this is kind of, like, just a high level landscape of what these data sets for instruction</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=279" target="_blank">00:04:39.720</a></span> | <span class="t">demonstration look like. And you must have, you know, been familiar with at least some</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=284" target="_blank">00:04:44.200</a></span> | <span class="t">of these. And, like, you know, the way I'm trying to put this is on this line where on</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=290" target="_blank">00:04:50.120</a></span> | <span class="t">one side I'm showing data sets that were generated using models or more powerful language models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=296" target="_blank">00:04:56.880</a></span> | <span class="t">And so, they're more synthetic data sets. On the right, I'm showing, like, human written</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=301" target="_blank">00:05:01.120</a></span> | <span class="t">data sets. And so, these are data sets that the human wrote the input as well as the expected</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=308" target="_blank">00:05:08.280</a></span> | <span class="t">output.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=309" target="_blank">00:05:09.280</a></span> | <span class="t">And so, examples of these are, like, you know, so the search instruct is the data that we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=313" target="_blank">00:05:13.280</a></span> | <span class="t">at Hugging Face H4, you know, contracted with search, this company that basically had contracts</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=320" target="_blank">00:05:20.820</a></span> | <span class="t">with annotators that were writing the inputs and outputs. But we had to give them all the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=325" target="_blank">00:05:25.240</a></span> | <span class="t">specifications of what kind of data we need. And then you must have heard of, like, you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=329" target="_blank">00:05:29.680</a></span> | <span class="t">know, obviously Open Assistant is this other community wide effort where people contributed</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=333" target="_blank">00:05:33.960</a></span> | <span class="t">manually writing inputs and outputs. Similarly with Dolly. And then on the other end, you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=339" target="_blank">00:05:39.240</a></span> | <span class="t">can see, like, you know, the self instruct data set. I'm going to, like, dive into some</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=342" target="_blank">00:05:42.920</a></span> | <span class="t">of these. How are these synthetic data sets created for helpfulness or for supervised</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=348" target="_blank">00:05:48.520</a></span> | <span class="t">fine tuning?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=349" target="_blank">00:05:49.520</a></span> | <span class="t">So, one of the examples of how the synthetic data is created is in the self instruct paper,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=356" target="_blank">00:05:56.520</a></span> | <span class="t">which is called bootstrapping the data. So, in this case, they start with 175 C task.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=362" target="_blank">00:06:02.680</a></span> | <span class="t">That is, you know, a 175, like, a very small data set of examples where the manually written</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=368" target="_blank">00:06:08.400</a></span> | <span class="t">inputs and outputs from humans, those are added to a task pool. Then a language model,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=373" target="_blank">00:06:13.480</a></span> | <span class="t">like, you know, basically you bootstrap by giving that to the language model in a few</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=377" target="_blank">00:06:17.960</a></span> | <span class="t">short settings and ask it to generate more data like that. And then you have another</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=383" target="_blank">00:06:23.200</a></span> | <span class="t">language model that does this task classification. Like, you know, what kind of task is this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=388" target="_blank">00:06:28.800</a></span> | <span class="t">sample or the example belonging to? And finally, it also does this more fine grained classification</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=394" target="_blank">00:06:34.880</a></span> | <span class="t">as to, like, you know, does it have, you know, output first or does it require input first</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=399" target="_blank">00:06:39.360</a></span> | <span class="t">and so on? And because this is synthetic data and created in this, like, a very scalable</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=403" target="_blank">00:06:43.760</a></span> | <span class="t">way, you also have to do a lot of filtering to make sure that it is very high quality.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=409" target="_blank">00:06:49.560</a></span> | <span class="t">So, another way of generating this kind of synthetic data is what UltraChat did. And</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=415" target="_blank">00:06:55.840</a></span> | <span class="t">in this case, they had, like, a human in the loop process. So, a human would, like, you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=420" target="_blank">00:07:00.480</a></span> | <span class="t">know, look up, like, either, you know, search Wikipedia or something and then come up with,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=426" target="_blank">00:07:06.400</a></span> | <span class="t">you know, topics that they want to generate data for. And then, you know, ask the model,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=431" target="_blank">00:07:11.640</a></span> | <span class="t">like, provide it with the required material that would be needed for, you know, coming</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=436" target="_blank">00:07:16.240</a></span> | <span class="t">up with, say, question answering or summarization or any of these specific tasks. And then give</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=441" target="_blank">00:07:21.320</a></span> | <span class="t">it to a more powerful model, like, chat GPD or GPD4. In this case, it was chat GPD. And</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=446" target="_blank">00:07:26.040</a></span> | <span class="t">then, oh, actually, GPD4. And then you kind of, like, you know, keep doing these loops</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=450" target="_blank">00:07:30.520</a></span> | <span class="t">of, like, you know, giving the material to the model and say, like, come up with questions</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=454" target="_blank">00:07:34.480</a></span> | <span class="t">and answers on this particular task using all this material. And then, you know, then</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=459" target="_blank">00:07:39.120</a></span> | <span class="t">the human looks at it and then keeps querying it and refining it more and more. So, this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=463" target="_blank">00:07:43.560</a></span> | <span class="t">is another way of creating synthetic data. Obviously, this has a human sitting there</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=467" target="_blank">00:07:47.640</a></span> | <span class="t">and doing a lot more filtering in the process. Then there's another one, which is, like,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=473" target="_blank">00:07:53.120</a></span> | <span class="t">even less human involved, which is role playing. And this is the camel dataset. In this case,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=479" target="_blank">00:07:59.080</a></span> | <span class="t">all that the human does is, like, come up with an idea of what task or what, you know,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=485" target="_blank">00:08:05.280</a></span> | <span class="t">level they want. So, at a high level, it would be, like, develop a trading bot for the stock</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=489" target="_blank">00:08:09.400</a></span> | <span class="t">market. And there would be two LLMs. One would be role playing as an AI assistant. The other</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=495" target="_blank">00:08:15.680</a></span> | <span class="t">would be role playing as an AI user. And then they basically just specify the task and,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=500" target="_blank">00:08:20.760</a></span> | <span class="t">like, let these two bots chat with each other and create a conversation dataset, which is,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=505" target="_blank">00:08:25.760</a></span> | <span class="t">again, like, a synthetic dataset for supervised fine tuning.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=512" target="_blank">00:08:32.200</a></span> | <span class="t">So this is kind of, like, you know, just going back to this, you know, landscape. It looks</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=515" target="_blank">00:08:35.920</a></span> | <span class="t">like, you know, people have been very creative. And how do we get, you know, very high quality</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=520" target="_blank">00:08:40.920</a></span> | <span class="t">data quickly without spending a lot of money? And because humans are inefficient and expensive.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=526" target="_blank">00:08:46.920</a></span> | <span class="t">And so, these are, like, you know, some examples that we looked at. But on the other hand,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=530" target="_blank">00:08:50.440</a></span> | <span class="t">we also cannot, like, you know, underestimate how good quality, like, the manually created</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=535" target="_blank">00:08:55.640</a></span> | <span class="t">datasets are. And so, we at Hugging Face decided to, like, you know, go with everything, like,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=541" target="_blank">00:09:01.840</a></span> | <span class="t">very manual and, like, you know, have humans do both the input and output. Also go figure</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=546" target="_blank">00:09:06.080</a></span> | <span class="t">out, like, what are the, you know, essential documents or, you know, other material they</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=550" target="_blank">00:09:10.760</a></span> | <span class="t">need for coming up with creating this dataset. But when we started doing that, we were earlier</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=557" target="_blank">00:09:17.000</a></span> | <span class="t">in the year. So, this is back in January or February of this year. And this is what the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=561" target="_blank">00:09:21.000</a></span> | <span class="t">landscape looked like at that time. And so, there was very little datasets available.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=566" target="_blank">00:09:26.080</a></span> | <span class="t">A lot of these were mostly synthetically created. So, we wanted to, like, you know, kind of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=571" target="_blank">00:09:31.640</a></span> | <span class="t">leverage what was existing out there. But we also had to make some really important</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=575" target="_blank">00:09:35.440</a></span> | <span class="t">decisions because we were going to, like, pay money and make sure that the data that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=579" target="_blank">00:09:39.160</a></span> | <span class="t">we collect is actually useful for building the model and, you know, the applications</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=583" target="_blank">00:09:43.520</a></span> | <span class="t">that are built on top of it. So, these are the learnings that we had from the past papers</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=589" target="_blank">00:09:49.200</a></span> | <span class="t">that were, you know, creating these supervised fine-tuned datasets. We knew that the dataset</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=593" target="_blank">00:09:53.800</a></span> | <span class="t">has to be in the range of tens of thousands of examples. So, this is from the self-instruct</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=598" target="_blank">00:09:58.840</a></span> | <span class="t">dataset. And we also knew that, you know, these models that are trained on this dataset</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=604" target="_blank">00:10:04.720</a></span> | <span class="t">show diminishing returns after just a few thousand high-quality instructions. So, you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=610" target="_blank">00:10:10.040</a></span> | <span class="t">don't need a lot. And then it saturates very quickly. So, these are the two findings that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=614" target="_blank">00:10:14.080</a></span> | <span class="t">we had when we started to, like, go collect datasets for supervised fine-tuning.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=620" target="_blank">00:10:20.400</a></span> | <span class="t">But we also had to give some very fine-grained specifications on what we want for our dataset.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=626" target="_blank">00:10:26.000</a></span> | <span class="t">In particular, we had to decide what is the task distribution we want for the data that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=629" target="_blank">00:10:29.880</a></span> | <span class="t">we are collecting. I mean, we know it's tens of thousands, but how many thousands of what</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=634" target="_blank">00:10:34.160</a></span> | <span class="t">task, right? The length distribution, like, you know, should the prompt have a certain</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=639" target="_blank">00:10:39.040</a></span> | <span class="t">dimension? Is that even an important factor? And one thing is that we wanted we had decided</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=644" target="_blank">00:10:44.080</a></span> | <span class="t">that we want to make it high-quality and human-written, but then there were, like, options on that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=648" target="_blank">00:10:48.800</a></span> | <span class="t">as well. We could go with external vendors, like SERT, Scale AI, AWS, Ground Truth, and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=654" target="_blank">00:10:54.400</a></span> | <span class="t">so on. Or we could hire our own contractors from Upwork and MTurk. So, those were, like,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=659" target="_blank">00:10:59.560</a></span> | <span class="t">decisions that we had to make. So, let's look at each of these one by one.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=664" target="_blank">00:11:04.040</a></span> | <span class="t">So, because we were recreating this InstructGPT recipe for this helpful chatbot, we wanted</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=670" target="_blank">00:11:10.960</a></span> | <span class="t">to, like, you know, take inspiration from their task distribution. So, on the left,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=674" target="_blank">00:11:14.840</a></span> | <span class="t">I'm showing, like, the task distribution that InstructGPT did for OpenAI did for the InstructGPT</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=680" target="_blank">00:11:20.600</a></span> | <span class="t">paper. As you can see, that generation is, like, you know, the majority of it, followed</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=684" target="_blank">00:11:24.960</a></span> | <span class="t">by some, you know, some of these open-ended tasks and brainstorming tasks and so on. And</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=689" target="_blank">00:11:29.760</a></span> | <span class="t">these are examples of, like, what prompts of each of those look like. So, we decided</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=694" target="_blank">00:11:34.640</a></span> | <span class="t">to, like, you know, just go with that. But instead, you must have noticed that there's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=698" target="_blank">00:11:38.120</a></span> | <span class="t">this category called "other" in the table. And we obviously don't know what that was.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=703" target="_blank">00:11:43.400</a></span> | <span class="t">But so, we decided to replace that with "code." So, essentially, it would be, like, debugging,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=708" target="_blank">00:11:48.020</a></span> | <span class="t">asking clarification questions about the code. So, it's like code plus natural language.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=712" target="_blank">00:11:52.480</a></span> | <span class="t">So, this is what our final distribution looked like.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=717" target="_blank">00:11:57.680</a></span> | <span class="t">The second question was the length distribution. So, we also had to, like, you know, figure</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=721" target="_blank">00:12:01.840</a></span> | <span class="t">out, like, you know, how important is the length? And should we, like, you know, have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=725" target="_blank">00:12:05.240</a></span> | <span class="t">a certain length distribution that we ask these companies to collect data for us? So,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=730" target="_blank">00:12:10.400</a></span> | <span class="t">we did a pilot study with SERT, ScaleAI, and AWS SageMaker Ground Truth, which is more</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=735" target="_blank">00:12:15.400</a></span> | <span class="t">like a managed service. So, it's very different from MTurk. And they have very high-quality</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=739" target="_blank">00:12:19.520</a></span> | <span class="t">humans, like, basically writing these examples. And so, I wanted to, like, just highlight</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=747" target="_blank">00:12:27.040</a></span> | <span class="t">that, you know, this or the first two rows here show what the instruct GPD length distribution</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=752" target="_blank">00:12:32.800</a></span> | <span class="t">looks like. And as you can see, this is obviously the full data set. This is more like pilot.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=756" target="_blank">00:12:36.480</a></span> | <span class="t">So, like, the counts are much smaller. But you can see, like, the maximum is 2048. And</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=762" target="_blank">00:12:42.360</a></span> | <span class="t">as you know, like, that was, like, the standard context size in the beginning of the year.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=767" target="_blank">00:12:47.240</a></span> | <span class="t">And then, you know, there is obviously, like, even the mean and, you know, that much. It's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=770" target="_blank">00:12:50.440</a></span> | <span class="t">not, like, basically, it's more or less, you know, in the range. But if you look at, you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=775" target="_blank">00:12:55.080</a></span> | <span class="t">know, these examples from SERT, AWS, ScaleAI, there's very high variance. So, for example,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=780" target="_blank">00:13:00.880</a></span> | <span class="t">AWS SageMaker, the maximum prompt length is 1036. But then, like, you know, the mean is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=786" target="_blank">00:13:06.200</a></span> | <span class="t">just 54. And on the other hand, with SERT, the maximum length is 500. But then the mean</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=793" target="_blank">00:13:13.160</a></span> | <span class="t">is much, like, you know, 104. So, it's, like, more in the range of what we would expect</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=797" target="_blank">00:13:17.800</a></span> | <span class="t">from, like, you know, this difference in instruct GPD. And similarly, with ScaleAI, we found</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=802" target="_blank">00:13:22.760</a></span> | <span class="t">that, you know, the prompts were just very, very short. And so, just based on this, we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=808" target="_blank">00:13:28.920</a></span> | <span class="t">said that, you know, okay, we should probably just go with search. Because, you know, that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=812" target="_blank">00:13:32.560</a></span> | <span class="t">seems like something that is more, you know, in the range of not very high variance.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=818" target="_blank">00:13:38.840</a></span> | <span class="t">So, we ended up collecting 10,000 instruction demonstration pairs from search. And this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=824" target="_blank">00:13:44.840</a></span> | <span class="t">is what the task distribution looked like. So, this very much follows the task distribution</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=829" target="_blank">00:13:49.280</a></span> | <span class="t">instruct GPD, except for the coding part, which was, like, the other category over there.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=834" target="_blank">00:13:54.640</a></span> | <span class="t">And these are the number of examples we collected for each of these tasks. And year over year,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=839" target="_blank">00:13:59.720</a></span> | <span class="t">I'm showing, like, you know, the average length for each of these task categories. And one</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=844" target="_blank">00:14:04.160</a></span> | <span class="t">thing I wanted to highlight was, which was very surprising to me, is that the chat is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=848" target="_blank">00:14:08.160</a></span> | <span class="t">actually one of the shortest prompt length categories. But for OpenAI, that is actually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=854" target="_blank">00:14:14.520</a></span> | <span class="t">one of the longest prompt length categories. So, which was very interesting. And so, obviously,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=859" target="_blank">00:14:19.560</a></span> | <span class="t">like, you know, at that time, we did not think much about it. But when we started training</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=864" target="_blank">00:14:24.360</a></span> | <span class="t">models and started looking at the evaluation results, we were kind of, like, you know,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=868" target="_blank">00:14:28.600</a></span> | <span class="t">if we had to go back and change things, how would we change that? And so, these were,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=873" target="_blank">00:14:33.000</a></span> | <span class="t">like, things that we started, you know, looking at more carefully after we had already collected</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=877" target="_blank">00:14:37.720</a></span> | <span class="t">the data set. So, here are examples of what that data set looked like. You know, classification,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=886" target="_blank">00:14:46.520</a></span> | <span class="t">generation, brainstorming. I'm sure you all must have seen at least some of these kind</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=891" target="_blank">00:14:51.480</a></span> | <span class="t">of examples of instruction demonstration data sets. So, it's very much, like, it has everything</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=896" target="_blank">00:14:56.000</a></span> | <span class="t">that you can expect from, like, NLP kind of tasks, but also more open-ended chatty tasks</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=902" target="_blank">00:15:02.800</a></span> | <span class="t">as well. Okay. So, here are, like, some details about the task force that was used by search</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=913" target="_blank">00:15:13.600</a></span> | <span class="t">to generate this data set. We requested a U.S.-based task force mainly because, like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=918" target="_blank">00:15:18.920</a></span> | <span class="t">I said, we just wanted to replicate what InstructGVD was doing. And based on Anthropic and OpenAI's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=924" target="_blank">00:15:24.720</a></span> | <span class="t">paper, it seemed like they preferred going with the U.S.-based task force. The gender</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=929" target="_blank">00:15:29.880</a></span> | <span class="t">was equally divided, and the age range was also very, you know, it was, like, a big range</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=936" target="_blank">00:15:36.520</a></span> | <span class="t">going all the way from 19 to 62. And then people had, like, you know, educational background</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=942" target="_blank">00:15:42.480</a></span> | <span class="t">ranges from technical degree to Ph.D. So, Ph.D. was mainly for tasks like math, coding,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=947" target="_blank">00:15:47.120</a></span> | <span class="t">and so on. Okay. So, now I wanted to, like, switch gears a little bit and talk about this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=955" target="_blank">00:15:55.760</a></span> | <span class="t">data set that we collected for RLHF or for human preferences before I get into, like,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=962" target="_blank">00:16:02.000</a></span> | <span class="t">you know, the experiments we ran with this supervised fine-tuning data set and what results</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=965" target="_blank">00:16:05.960</a></span> | <span class="t">we got. So, again, over here, while we were collecting human reference data set, we had</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=972" target="_blank">00:16:12.320</a></span> | <span class="t">to come up with what are the specifications of these data sets. So, again, just to, like,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=977" target="_blank">00:16:17.360</a></span> | <span class="t">contrast this with how is it different from SFD, the SFD data set, both the input and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=982" target="_blank">00:16:22.200</a></span> | <span class="t">the output are written by humans. In this case, the human writes the input. The output</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=986" target="_blank">00:16:26.940</a></span> | <span class="t">comes from models, which is responses, but then the human just ranks or rates them on</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=991" target="_blank">00:16:31.960</a></span> | <span class="t">a certain scale. So, yeah, essentially, we had to decide, like, what is the task distribution</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=998" target="_blank">00:16:38.240</a></span> | <span class="t">looks like for RLHF data? Is it going to be same as supervised fine-tuning? What about</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1004" target="_blank">00:16:44.440</a></span> | <span class="t">the length distribution? And should we do, like, single turn versus multi-turn? So, in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1009" target="_blank">00:16:49.040</a></span> | <span class="t">struct GPT, it was mainly single turn. So, if we are trying to replicate in struct GPT,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1013" target="_blank">00:16:53.720</a></span> | <span class="t">we would have to go with single turn. But if we are trying to replicate something like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1017" target="_blank">00:16:57.120</a></span> | <span class="t">chat GPT, it would have to be, like, a multi-turn dialogue. And then we had to also, like, you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1022" target="_blank">00:17:02.680</a></span> | <span class="t">know, decide on these dimensions of, like, helpfulness, honesty, and harmlessness. So,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1027" target="_blank">00:17:07.760</a></span> | <span class="t">these are, like, the HHH that Entropiq follows, like, OpenAI puts it as helpfulness, truthfulness,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1033" target="_blank">00:17:13.400</a></span> | <span class="t">and harmlessness. And then also we had to decide, like, you know, are they going to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1036" target="_blank">00:17:16.880</a></span> | <span class="t">rate each of the responses individually? Or are they going to rank them? And what are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1041" target="_blank">00:17:21.320</a></span> | <span class="t">the implications of, like, you know, us deciding one way or the other?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1046" target="_blank">00:17:26.320</a></span> | <span class="t">So, we started by doing pilot study again. So, we took 300 from the self-instruct data</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1054" target="_blank">00:17:34.160</a></span> | <span class="t">set, the data set that was released end of last year. And then, you know, gave it generated</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1059" target="_blank">00:17:39.800</a></span> | <span class="t">model responses from our models and then gave it to data vendors to, like, rate the responses</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1065" target="_blank">00:17:45.320</a></span> | <span class="t">of the models. And we used this Entropiq template on the left, which is essentially asking the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1071" target="_blank">00:17:51.480</a></span> | <span class="t">human choose the most helpful and honest response. And then, you know, these are the responses</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1075" target="_blank">00:17:55.800</a></span> | <span class="t">from, like, model A and model B. And this is a scale, which is also working as, like,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1081" target="_blank">00:18:01.320</a></span> | <span class="t">sort of a ranking thing in the sense that one to four is, like, decreasingly model A</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1086" target="_blank">00:18:06.760</a></span> | <span class="t">and five to eight is increasingly model B.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1092" target="_blank">00:18:12.320</a></span> | <span class="t">And also, like, you know, one other thing we had to decide about is, like, how much</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1096" target="_blank">00:18:16.100</a></span> | <span class="t">data should we collect? And so, again, this is from the InstructGPD paper. And as you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1101" target="_blank">00:18:21.000</a></span> | <span class="t">can see, like, you know, they have, like, the train and validation splits for each of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1105" target="_blank">00:18:25.200</a></span> | <span class="t">the three steps, which are the SFD, training the reward model, and the PPO. And this one</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1110" target="_blank">00:18:30.240</a></span> | <span class="t">is in the order of tens of thousands. And, like, overall, this combined, which is, like,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1115" target="_blank">00:18:35.000</a></span> | <span class="t">you know, this process of RLHF comes up to about 100,000.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1120" target="_blank">00:18:40.120</a></span> | <span class="t">Great. Okay. So, then once we got this pilot study data back, we sat down and we wanted</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1129" target="_blank">00:18:49.040</a></span> | <span class="t">to also, like, you know, so I looked at it manually, and I felt that I did not agree</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1133" target="_blank">00:18:53.640</a></span> | <span class="t">with most of the answers that, you know, the annotators from each of these companies were</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1138" target="_blank">00:18:58.200</a></span> | <span class="t">providing. And so, I was kind of, like, you know, I don't think this is high quality at</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1142" target="_blank">00:19:02.600</a></span> | <span class="t">all. So, what I decided, like, you know, I told my team, let's go and, like, you know,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1146" target="_blank">00:19:06.880</a></span> | <span class="t">rate it within ourselves. And then, you know, we basically rated, like, about 100 examples</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1152" target="_blank">00:19:12.240</a></span> | <span class="t">or so. And we followed, like, a similar template of, like, one to four and five to eight. And</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1157" target="_blank">00:19:17.560</a></span> | <span class="t">it basically the output, like, you know, the takeaway was that even we did not agree amongst</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1162" target="_blank">00:19:22.280</a></span> | <span class="t">each other. So, essentially, like, our models earlier in the year was so bad, you were essentially</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1167" target="_blank">00:19:27.440</a></span> | <span class="t">breaking ties, like, arbitrarily. Like, you know, you're deciding between, like, should</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1171" target="_blank">00:19:31.640</a></span> | <span class="t">it be, like, you know, three versus, like, seven or something like that. So, if they're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1175" target="_blank">00:19:35.360</a></span> | <span class="t">equally bad, it's hard to, like, decide which one is better, right? And so, we were kind</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1180" target="_blank">00:19:40.000</a></span> | <span class="t">of, like, breaking some of these ties arbitrarily. And so, as you can see, like, you know, there</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1184" target="_blank">00:19:44.120</a></span> | <span class="t">was barely any, like, you know, agreement or correlation among our outputs. And then,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1188" target="_blank">00:19:48.760</a></span> | <span class="t">you know, when I aggregated that, and, you know, looked at, you know, how well do we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1192" target="_blank">00:19:52.480</a></span> | <span class="t">correlate with, like, for example, search and scale. And so, we decided, like, you know,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1197" target="_blank">00:19:57.000</a></span> | <span class="t">with AI, we had, like, more, like, the maximum overlap was with scale compared to, like,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1203" target="_blank">00:20:03.680</a></span> | <span class="t">say, search. Okay. So, we ended up collecting 20,000 dialogues. So, we decided to go with</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1209" target="_blank">00:20:09.880</a></span> | <span class="t">multi-turn. And so, because it was multi-turn, you would have, like, 20,000 overall dialogues,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1216" target="_blank">00:20:16.560</a></span> | <span class="t">but the number of prompts would be 80,000. So, there would be each dialogue would have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1219" target="_blank">00:20:19.840</a></span> | <span class="t">about four turns on an average. So, like, you know, a human would prompt it, the model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1224" target="_blank">00:20:24.280</a></span> | <span class="t">would respond, a human would, like, rate the response, and then, you know, ask the follow-up</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1229" target="_blank">00:20:29.320</a></span> | <span class="t">question. And then, again, the model would, like, you know, generate two responses, and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1232" target="_blank">00:20:32.760</a></span> | <span class="t">that is how it would go on. And so, the task distribution we decided to follow was a little</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1239" target="_blank">00:20:39.360</a></span> | <span class="t">bit different from what we had for supervised fine tuning. And the reason behind that was</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1244" target="_blank">00:20:44.640</a></span> | <span class="t">that we wanted to focus more on tasks that were, like, factual, so that, you know, essentially,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1251" target="_blank">00:20:51.520</a></span> | <span class="t">this is more about making the model learn, like, between positive and negative signals.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1255" target="_blank">00:20:55.800</a></span> | <span class="t">So, making the model, like, discriminate between, like, you know, what is factual, what is not,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1260" target="_blank">00:21:00.200</a></span> | <span class="t">what is helpful, what is not, and what is harmless and what is not. And, like, you know,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1264" target="_blank">00:21:04.920</a></span> | <span class="t">for example, tasks like generation and brainstorming, there's no one correct answer. Like, you know,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1269" target="_blank">00:21:09.480</a></span> | <span class="t">everyone can come up with, like, different lists or recipes, and, you know, it's hard</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1273" target="_blank">00:21:13.440</a></span> | <span class="t">to say, is this the best answer? Is this the most helpful answer? But if you ask, like,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1277" target="_blank">00:21:17.200</a></span> | <span class="t">a factual question, it's, like, very clear what is correct and what is not. So, that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1282" target="_blank">00:21:22.080</a></span> | <span class="t">was kind of, like, our reasoning behind doing this. And so, this is a task distribution</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1286" target="_blank">00:21:26.120</a></span> | <span class="t">that we came up with for collecting the human preference dataset.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1291" target="_blank">00:21:31.680</a></span> | <span class="t">Also about the length, because we are doing this in a multi-turn setting, and so we wanted</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1295" target="_blank">00:21:35.840</a></span> | <span class="t">to make sure, like, you know, the entire dialogue could fit into, like, the context line of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1300" target="_blank">00:21:40.000</a></span> | <span class="t">the models, we have decided to, like, you know, ask them to keep the overall dialogue</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1304" target="_blank">00:21:44.080</a></span> | <span class="t">to be shorter than 2048 tokens. And then it was multi-turn with an average of four turns</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1311" target="_blank">00:21:51.080</a></span> | <span class="t">per dialogue. Then, obviously, we had to also select on the dimension of, like, whether</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1315" target="_blank">00:21:55.880</a></span> | <span class="t">we are going for, like, helpful over harmless or, you know, honesty. So, we followed this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1321" target="_blank">00:22:01.800</a></span> | <span class="t">instructions from this OpenAI guidelines. I'm not sure if I can pull this up. That would</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1326" target="_blank">00:22:06.240</a></span> | <span class="t">be nice. Okay. Great. But, yeah, so, OpenAI has this document which is public of, like,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1336" target="_blank">00:22:16.400</a></span> | <span class="t">labeling instructions that they shared with their annotators. And so, they have, obviously,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1341" target="_blank">00:22:21.360</a></span> | <span class="t">like I said, they have helpful, truthful, and harmless, but then they also have this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1345" target="_blank">00:22:25.320</a></span> | <span class="t">thing how do I scroll down? Okay. So, they have definitions on what do they mean by helpfulness,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1352" target="_blank">00:22:32.440</a></span> | <span class="t">what do they mean by truthfulness, and what do they mean by harmlessness. So, in our case,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1357" target="_blank">00:22:37.120</a></span> | <span class="t">because our models were not as good, we decided to focus on helpfulness and truthfulness.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1362" target="_blank">00:22:42.620</a></span> | <span class="t">And when they had to break ties, OpenAI says that, you know, choose truthfulness over helpfulness</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1368" target="_blank">00:22:48.840</a></span> | <span class="t">over your so, like, let me see that. Yeah. So, they wanted to, like, prioritize harmlessness</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1387" target="_blank">00:23:07.000</a></span> | <span class="t">and truthfulness over helpfulness, but we went the other way around. We said we wanted</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1390" target="_blank">00:23:10.920</a></span> | <span class="t">to, like, prioritize helpfulness over honesty or harmlessness. I mean, we weren't even focusing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1396" target="_blank">00:23:16.720</a></span> | <span class="t">on harmlessness, because we just wanted to get our model to a certain capabilities before</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1401" target="_blank">00:23:21.120</a></span> | <span class="t">we start thinking about that. But, yeah, this is really a very good document and, like,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1406" target="_blank">00:23:26.840</a></span> | <span class="t">you know, defines what should the annotator be looking at and how do they decide when</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1412" target="_blank">00:23:32.040</a></span> | <span class="t">the model responses are very close, how do they break those ties. And for, like, you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1417" target="_blank">00:23:37.680</a></span> | <span class="t">know, deciding between what kind of template should we use for collecting these annotations,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1422" target="_blank">00:23:42.680</a></span> | <span class="t">we started off with the entropic template that I showed a few slides earlier, which</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1425" target="_blank">00:23:45.960</a></span> | <span class="t">was on a scale of one to eight, but essentially ranking between these two models. And then,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1430" target="_blank">00:23:50.720</a></span> | <span class="t">you know, Lama2 came out while we were in this iterative process. And our iterative</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1434" target="_blank">00:23:54.960</a></span> | <span class="t">process was essentially we used to give an endpoint to the vendor, and then the, you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1439" target="_blank">00:23:59.520</a></span> | <span class="t">know, basically the annotators that they had in the managed task force would prompt these</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1443" target="_blank">00:24:03.880</a></span> | <span class="t">endpoints. The model would generate two responses. They would, you know, follow the instructions</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1450" target="_blank">00:24:10.680</a></span> | <span class="t">and, you know, give the ranking for each of those instruction each of those model responses.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1455" target="_blank">00:24:15.800</a></span> | <span class="t">And then, you know, again, like, follow up with the second prompt and the conversation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1458" target="_blank">00:24:18.680</a></span> | <span class="t">would go on. And then they would give us the data at the end of that week. We would fine</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1462" target="_blank">00:24:22.600</a></span> | <span class="t">tune our model on that data so that the model now is hopefully better. And then we give,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1467" target="_blank">00:24:27.920</a></span> | <span class="t">like, a better endpoint to them for the next week to continue this process. So it's, like,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1472" target="_blank">00:24:32.160</a></span> | <span class="t">very iterative. And, like, you know, they have to adapt to, like, model getting better</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1476" target="_blank">00:24:36.320</a></span> | <span class="t">week by week. So, yeah, basically, but, like, you know, we decided to switch to I think</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1481" target="_blank">00:24:41.240</a></span> | <span class="t">for one or two weeks we collected entropics, use entropic scale for collecting data set.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1487" target="_blank">00:24:47.840</a></span> | <span class="t">But then Lama 2 came out and their results showed that, you know, clearly that, you know,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1492" target="_blank">00:24:52.080</a></span> | <span class="t">they were using this much more easier scale of just 1 to 4. So they were, like, you know,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1497" target="_blank">00:24:57.440</a></span> | <span class="t">choosing which one is a better response between the two responses and then seeing how much</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1502" target="_blank">00:25:02.140</a></span> | <span class="t">better it is. So is it, like, significantly better or is it only slightly better? And</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1506" target="_blank">00:25:06.920</a></span> | <span class="t">so that was the ranking of, like, scale 1 to 4. So here are examples of data that we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1513" target="_blank">00:25:13.280</a></span> | <span class="t">collected. So on the left, you can see that it is asking about, like, you know, basically</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1519" target="_blank">00:25:19.920</a></span> | <span class="t">human is prompting with a question and then the bot generates a response. So this is the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1524" target="_blank">00:25:24.480</a></span> | <span class="t">response that the human chose at this turn. And then the human, you know, follows up with</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1528" target="_blank">00:25:28.680</a></span> | <span class="t">the second prompt. And then this is the bot response that was chosen by this human. And</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1533" target="_blank">00:25:33.480</a></span> | <span class="t">this is the rejected bot response. And this is giving the response margin of 3, which</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1537" target="_blank">00:25:37.760</a></span> | <span class="t">is saying that they are quite a bit different. So 4 is, like, very different and 1 being</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1541" target="_blank">00:25:41.880</a></span> | <span class="t">very slightly different. And then here on the right-hand side is more about sort of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1547" target="_blank">00:25:47.200</a></span> | <span class="t">generation brainstorming kind of example where the human is asking, like, can you write a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1552" target="_blank">00:25:52.580</a></span> | <span class="t">text message wishing your husband a happy anniversary? And then the bot writes something.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1557" target="_blank">00:25:57.760</a></span> | <span class="t">I guess my thing messed up the emojis. But, you know, then the human follows up with saying,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1563" target="_blank">00:26:03.640</a></span> | <span class="t">hey, you missed this important detail, which is, you know, they have been married for eight</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1567" target="_blank">00:26:07.320</a></span> | <span class="t">years. And so this is a chosen bot response. This is the rejected one that the human chose</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1572" target="_blank">00:26:12.360</a></span> | <span class="t">between those two. And as you can see, they are quite good. So the response margin is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1577" target="_blank">00:26:17.920</a></span> | <span class="t">just 1. So they're, like, just slightly different. Okay. Sounds good. So now I'm going to, like,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1586" target="_blank">00:26:26.680</a></span> | <span class="t">talk about this another recipe that we tried, which is, you know, using synthetic data set</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1592" target="_blank">00:26:32.080</a></span> | <span class="t">essentially for distillation of AI alignment, which is basically the paper that we released</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1597" target="_blank">00:26:37.680</a></span> | <span class="t">last week called Zephyr, and which was, like, a 7 billion parameter model, which actually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1603" target="_blank">00:26:43.160</a></span> | <span class="t">beat Chad GPT. And this builds on top of the Mistral model. But I just wanted to, like,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1609" target="_blank">00:26:49.280</a></span> | <span class="t">you know, yeah, just, you know, basically we recreated some of the steps that were there</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1612" target="_blank">00:26:52.640</a></span> | <span class="t">on the instruct GPT paper, but now with using synthetic data set. And so the first one is,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1618" target="_blank">00:26:58.920</a></span> | <span class="t">like, you know, you are basically, like, using a data set. In this case, we use Ultra Chat.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1623" target="_blank">00:27:03.800</a></span> | <span class="t">So this is a data set I showed a few slides earlier for supervised fine tuning, wherein,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1627" target="_blank">00:27:07.680</a></span> | <span class="t">like, a human was brainstorming and, like, gathering the material, and then, like, you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1632" target="_blank">00:27:12.280</a></span> | <span class="t">know, chatting with this GPT-4 model to, like, generate multiple different, you know, outputs</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1638" target="_blank">00:27:18.000</a></span> | <span class="t">for the instruction. And then, you know, this is how we collect that data set, which is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1641" target="_blank">00:27:21.920</a></span> | <span class="t">called the Ultra Chat. And then we use that for fine tuning our model. And then the second</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1647" target="_blank">00:27:27.500</a></span> | <span class="t">step is the response generation AI ranking. So in this case, also, like, you know, we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1653" target="_blank">00:27:33.320</a></span> | <span class="t">used Ultra Feedback, which is a data set that was released. And the way this data set was</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1659" target="_blank">00:27:39.280</a></span> | <span class="t">constructed was that, you know, they asked, basically, like, you know, took some prompts</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1664" target="_blank">00:27:44.440</a></span> | <span class="t">from, like, shared GPT and some of these different data sets of SFT that were already out there.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1669" target="_blank">00:27:49.920</a></span> | <span class="t">And then they gave it to four different models, like, four different powerful models, like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1673" target="_blank">00:27:53.800</a></span> | <span class="t">Palm 2, Cloud 2, GPT-4, and so on. And then they asked this GPT-4 to, like, rank each</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1681" target="_blank">00:28:01.440</a></span> | <span class="t">of those four responses. And then, so, like, you know, the one that is the best is the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1685" target="_blank">00:28:05.800</a></span> | <span class="t">one that GPT-4 ranks as the highest. So each of these are scored individually on a scale</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1689" target="_blank">00:28:09.840</a></span> | <span class="t">of 1 to 10. And the one that gets the maximum score is, like, the best response. And then</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1696" target="_blank">00:28:16.760</a></span> | <span class="t">finally, we did something called DPO, which you might have been aware of because it came</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1701" target="_blank">00:28:21.520</a></span> | <span class="t">out of Stanford. It's, like, this kind of alternative to RLHF, which is, like, doing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1706" target="_blank">00:28:26.320</a></span> | <span class="t">this direct preference optimization. And so instead of, like, you know, basically doing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1711" target="_blank">00:28:31.720</a></span> | <span class="t">this iterative process of fine-tuning, you directly, like, optimize on, like, the chosen</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1715" target="_blank">00:28:35.960</a></span> | <span class="t">one. So we just take that and then fine-tune our model directly on that chosen response.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1722" target="_blank">00:28:42.600</a></span> | <span class="t">And the other one that we are using is, like, a random response from these other three responses.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1727" target="_blank">00:28:47.920</a></span> | <span class="t">Okay. So I'm going to talk a little bit about experiments and evaluation for each of these</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1734" target="_blank">00:28:54.960</a></span> | <span class="t">recipes. One is collecting everything with, like, humans involved. And the second one</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1740" target="_blank">00:29:00.000</a></span> | <span class="t">is everything which is synthetic. But then before I discuss evaluation, I wanted to talk</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1745" target="_blank">00:29:05.160</a></span> | <span class="t">about, like, what are the benchmarks that we are evaluating on and how good are these</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1749" target="_blank">00:29:09.040</a></span> | <span class="t">benchmarks for evaluating chatbots. And to think about evaluation, we need to first think</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1754" target="_blank">00:29:14.520</a></span> | <span class="t">about how are we training these models. So, like, today, all the models that are trained</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1759" target="_blank">00:29:19.240</a></span> | <span class="t">are, like, more or less have these four ways of learning. The first one is pre-training</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1763" target="_blank">00:29:23.640</a></span> | <span class="t">the language model. Essentially, you're predicting the next token. And examples of these are,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1768" target="_blank">00:29:28.080</a></span> | <span class="t">like, GPT-3, OPT, and so, like, the foundation models. The second type of learning is in-context</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1774" target="_blank">00:29:34.280</a></span> | <span class="t">learning or the prompt-based learning. In this case, you're, like, just giving a new</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1778" target="_blank">00:29:38.800</a></span> | <span class="t">kind of task in the context of the model and then, you know, ask it to, like, you know,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1783" target="_blank">00:29:43.480</a></span> | <span class="t">do that on new examples. So, like, if you wanted to write a poem, for example, for GPT-3,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1788" target="_blank">00:29:48.160</a></span> | <span class="t">you would have written that in the context and then it would have generated a new poem</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1791" target="_blank">00:29:51.880</a></span> | <span class="t">on some other topic. The third type of learning is the supervised fine tuning, which was kind</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1799" target="_blank">00:29:59.760</a></span> | <span class="t">of, like, the first step of training a chatbot. In this case, you're, like, fine tuning on</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1804" target="_blank">00:30:04.760</a></span> | <span class="t">the instruction following data and then you want these language models, which are just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1808" target="_blank">00:30:08.840</a></span> | <span class="t">pre-trained to predict the next token to become chatty and to, like, generate open-ended responses.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1814" target="_blank">00:30:14.760</a></span> | <span class="t">And then, finally, the fourth one is reinforcement learning from human feedback, which is nudging</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1819" target="_blank">00:30:19.480</a></span> | <span class="t">the language model towards the values you desire. And examples include llama to chat</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1824" target="_blank">00:30:24.040</a></span> | <span class="t">from meta. So, the first two steps are, you know, we have a lot of benchmarks for these</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1833" target="_blank">00:30:33.060</a></span> | <span class="t">two types of training. Like, Sanford Helm is an example of that. Or the Google Big Bench</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1837" target="_blank">00:30:37.840</a></span> | <span class="t">or even open LLM leaderboard. But for these two types of learning, which is supervised</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1845" target="_blank">00:30:45.440</a></span> | <span class="t">fine tuning and reinforcement learning from human feedback, which are parts of, like,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1849" target="_blank">00:30:49.160</a></span> | <span class="t">this recipe for training a chatbot, there's, you know, not a lot of leaderboards or evaluation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1854" target="_blank">00:30:54.380</a></span> | <span class="t">benchmarks available. But there are some available. And I wanted to, like, you know, just highlight</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1858" target="_blank">00:30:58.340</a></span> | <span class="t">some of those. So, like, yeah, this is essentially, like, the steps three and four here match</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1864" target="_blank">00:31:04.220</a></span> | <span class="t">to, like, you know, the step one over here, which is helpfulness, and then steps two and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1868" target="_blank">00:31:08.440</a></span> | <span class="t">three over here, which is, like, you know, nudging the model towards being more harmless.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1873" target="_blank">00:31:13.560</a></span> | <span class="t">So, if you had to, you know, evaluate the chatbot for each of these steps, you would</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1879" target="_blank">00:31:19.840</a></span> | <span class="t">have to think about how do you evaluate instruction following or chattiness. You would have to,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1884" target="_blank">00:31:24.800</a></span> | <span class="t">you know, think about how do you evaluate the reward model, which is essentially a classifier.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1889" target="_blank">00:31:29.420</a></span> | <span class="t">And then finally think about, you know, how do you evaluate for harmlessness, which is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1893" target="_blank">00:31:33.320</a></span> | <span class="t">by red feeling or adversely prompting the language model. So, for the first step, you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1899" target="_blank">00:31:39.480</a></span> | <span class="t">would have to see, like, does the model generate useful responses on the topic? And are they</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1903" target="_blank">00:31:43.440</a></span> | <span class="t">open ended? And one example of a prompt that you would try to evaluate the model would</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1907" target="_blank">00:31:47.880</a></span> | <span class="t">be to, like, say, brainstorm a list of the New Year's resolution. And so, examples of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1914" target="_blank">00:31:54.080</a></span> | <span class="t">benchmarks and evaluation boards that are looking at this sort of, like, supervised</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1919" target="_blank">00:31:59.360</a></span> | <span class="t">fine tuning is, like, Hugging Faces, a leaderboard with ELO ratings. So, ELO is this metric that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1925" target="_blank">00:32:05.300</a></span> | <span class="t">is used in chess, which is, like, you know, you're pairing one player against the other,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1929" target="_blank">00:32:09.480</a></span> | <span class="t">and you want to, like, rank these players when they have, like, these tournaments against</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1933" target="_blank">00:32:13.160</a></span> | <span class="t">each other. And so, in a similar sense, we are, you know, taking these chatbots and then,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1940" target="_blank">00:32:20.080</a></span> | <span class="t">you know, putting them in a pairwise setting. And then we partnered with ScaleAI, and they</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1945" target="_blank">00:32:25.000</a></span> | <span class="t">provided humans to, like, annotate which response is better. And we did that for every single</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1950" target="_blank">00:32:30.360</a></span> | <span class="t">combination. So, like, it was NC2, where N is the number of prompts we are looking at.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1955" target="_blank">00:32:35.480</a></span> | <span class="t">And so, we generate NC2 combinations, and we rate each of them. And so, these are the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1960" target="_blank">00:32:40.640</a></span> | <span class="t">ELO ratings that we get out of it. And on this column here shows that what is the rating</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1967" target="_blank">00:32:47.600</a></span> | <span class="t">you would get if you would have used GPD 4 as a proxy for humans? So, instead of, like,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1972" target="_blank">00:32:52.880</a></span> | <span class="t">humans sitting and rating each of those, you're asking, like, you know, GPD 4 to select which</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1977" target="_blank">00:32:57.120</a></span> | <span class="t">is a better response. Yeah. And so, this is basically the first table you're showing if</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1982" target="_blank">00:33:02.680</a></span> | <span class="t">you allow ties in the sense sorry, if there was no tie allowed. And this table you're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1987" target="_blank">00:33:07.320</a></span> | <span class="t">showing that if ties were allowed. Another example is, you know, this leaderboard from</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=1995" target="_blank">00:33:15.480</a></span> | <span class="t">Stanford, which is Alpaca Eval leaderboard, and they're doing something very similar in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2000" target="_blank">00:33:20.440</a></span> | <span class="t">the sense that they have GPD 4 and Claude as an evaluator, and they are doing, like,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2005" target="_blank">00:33:25.720</a></span> | <span class="t">a pairwise evaluation of these models, chatbot models, and they're reporting the win rate</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2012" target="_blank">00:33:32.040</a></span> | <span class="t">of, you know, which model wins against the other one. There's also the LMSIS leaderboard</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2018" target="_blank">00:33:38.840</a></span> | <span class="t">from Berkeley, which has this thing called the chatbot arena, which is essentially like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2023" target="_blank">00:33:43.120</a></span> | <span class="t">a publicly crowdsourced leaderboard, wherein you can, like, go chat, like, you know, chat</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2028" target="_blank">00:33:48.040</a></span> | <span class="t">with any of their models, and then give them rating to, like, which one was more helpful</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2031" target="_blank">00:33:51.880</a></span> | <span class="t">and which one was better. And so, this, again, has, like, a leaderboard of ELO ratings, because</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2036" target="_blank">00:33:56.640</a></span> | <span class="t">this is done in a pairwise setting. There's another benchmark from LMSIS, which is called</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2043" target="_blank">00:34:03.960</a></span> | <span class="t">the empty bench or the multi-turn bench, a benchmark. And this is the first ever multi-turn</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2049" target="_blank">00:34:09.360</a></span> | <span class="t">dialogue benchmark that is evaluating chatbots. And so, it has, there are just, like, 80 examples</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2055" target="_blank">00:34:15.440</a></span> | <span class="t">in this across, like, a bunch of categories. But essentially, what, the way it works is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2060" target="_blank">00:34:20.320</a></span> | <span class="t">that the first turn or the first prompt from the benchmark is prompted to the model. Then</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2067" target="_blank">00:34:27.360</a></span> | <span class="t">GPD 4 is asked to score on a score of 1 to 10. How good is the model's response? And</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2073" target="_blank">00:34:33.560</a></span> | <span class="t">then, you know, it is followed up by another prompt, which is, like, you know, the multi-turn</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2078" target="_blank">00:34:38.000</a></span> | <span class="t">prompt, which is, like, related to the question, but it might not be related to the model's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2082" target="_blank">00:34:42.560</a></span> | <span class="t">responses, because, you know, this is already constructed, and they always, like, follow</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2085" target="_blank">00:34:45.960</a></span> | <span class="t">up with the same response to every part. And then, again, GPD 4 evaluates how good was</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2091" target="_blank">00:34:51.600</a></span> | <span class="t">the second turn of the response. So, this is, like, the consolidated leaderboard from</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2097" target="_blank">00:34:57.600</a></span> | <span class="t">LMSIS, showing both the arena ELO rating, as well as empty bench scores. So, these are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2103" target="_blank">00:35:03.400</a></span> | <span class="t">scores that are aggregated across all the 80 examples, and this is GPD score scoring</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2108" target="_blank">00:35:08.880</a></span> | <span class="t">from, like, 1 to 10, essentially. Cool. So, I think the second step that we wanted to,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2116" target="_blank">00:35:16.040</a></span> | <span class="t">like, look at in our evaluating a chatbot chart was, like, you know, think about how</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2120" target="_blank">00:35:20.800</a></span> | <span class="t">do you evaluate a reward model. So, when you have these human preference data set collected,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2125" target="_blank">00:35:25.840</a></span> | <span class="t">and you train this reward model, which is essentially a classifier, to discriminate</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2129" target="_blank">00:35:29.680</a></span> | <span class="t">between, like, you know, truthful and untruthful response, or, like, you know, can it rank</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2133" target="_blank">00:35:33.840</a></span> | <span class="t">helpful response higher than the less helpful responses? And, you know, there's literally</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2139" target="_blank">00:35:39.280</a></span> | <span class="t">no open source data leaderboard available for evaluating these, like, preference model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2144" target="_blank">00:35:44.840</a></span> | <span class="t">or the reward models. But internally at Hugging Face, we have our own data set for evaluating,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2150" target="_blank">00:35:50.660</a></span> | <span class="t">so that we know that as we are adding more human preference data, our models are actually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2155" target="_blank">00:35:55.520</a></span> | <span class="t">getting better. So, this is essentially we are evaluating on these open source data sets,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2162" target="_blank">00:36:02.200</a></span> | <span class="t">which is the Anthropic Helpful data set, the Open Assistant data set, the Stanford's Human</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2167" target="_blank">00:36:07.520</a></span> | <span class="t">Preference data set, and also the Learning to Summarize data sets from the very first</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2171" target="_blank">00:36:11.960</a></span> | <span class="t">paper from OpenAI, which was looking at Learning to Summarize. And so, this is, like, you know,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2178" target="_blank">00:36:18.600</a></span> | <span class="t">basically seeing that, you know, how good is our reward model. And then, finally, the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2183" target="_blank">00:36:23.280</a></span> | <span class="t">third type of evaluation is red teaming. And so, in this case, you want to craft a prompt</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2188" target="_blank">00:36:28.720</a></span> | <span class="t">in a way that could surface model vulnerabilities and emerging capabilities. And for example,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2194" target="_blank">00:36:34.720</a></span> | <span class="t">if you're asking, like, how do I plan a prank robbery is a model, actually, like, you know,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2199" target="_blank">00:36:39.120</a></span> | <span class="t">helping you with that and trying to elicit undesired behavior from the model. And unfortunately,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2204" target="_blank">00:36:44.720</a></span> | <span class="t">actually, there's no leader open source leaderboard available for this thing. There's just one</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2209" target="_blank">00:36:49.280</a></span> | <span class="t">data set from Anthropic, which has all the three included, which is the it actually has</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2213" target="_blank">00:36:53.840</a></span> | <span class="t">both helpfulness and harmlessness. It's the edge data set from Anthropic. And that's the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2218" target="_blank">00:36:58.720</a></span> | <span class="t">only open source data set available for red teaming. But there's no leaderboard available</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2224" target="_blank">00:37:04.080</a></span> | <span class="t">for red teaming. And so, this was, like, a blog that I wrote earlier in the year, saying,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2228" target="_blank">00:37:08.080</a></span> | <span class="t">like, you know, highlighting this gap and saying that, you know, putting out an announcement</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2232" target="_blank">00:37:12.320</a></span> | <span class="t">saying, like, we should get together and build a data set for red teaming. And if you had</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2236" target="_blank">00:37:16.160</a></span> | <span class="t">heard of, like, the DEF CON red teaming design challenge, and, you know, basically crowdsourcing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2240" target="_blank">00:37:20.900</a></span> | <span class="t">some of these red teaming work kind of came out of that. Okay. So, now I'm going to get</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2246" target="_blank">00:37:26.600</a></span> | <span class="t">into now that we have discussed evaluation and benchmarks and leaderboards, I'm going</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2250" target="_blank">00:37:30.600</a></span> | <span class="t">to talk about results and what did they look like on each of and some of these benchmarks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2255" target="_blank">00:37:35.160</a></span> | <span class="t">So, here I'm showing the results for this Lama 213 billion on the open LLM leaderboard</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2262" target="_blank">00:37:42.840</a></span> | <span class="t">from Hugging Face. And in this case, I was using the data set that we collected from</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2268" target="_blank">00:37:48.120</a></span> | <span class="t">search that was a 10,000 instruction demonstration data. And I hear on this, you know, these</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2273" target="_blank">00:37:53.400</a></span> | <span class="t">are basically the four data sets, which are, like, NLP focused data sets that we have as</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2278" target="_blank">00:37:58.480</a></span> | <span class="t">part of open LLM leaderboard, which are the Arc Challenge, the Hendrix, Hellaswag, and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2283" target="_blank">00:38:03.200</a></span> | <span class="t">Truthful QA. And you're, like, you know, this is how well our model does. And all of this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2289" target="_blank">00:38:09.760</a></span> | <span class="t">is essentially accuracy. And this is the Lima paper or the Lima model, which is less is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2294" target="_blank">00:38:14.300</a></span> | <span class="t">more for alignment that came from meta. And they just used 1,000 examples of high quality</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2299" target="_blank">00:38:19.240</a></span> | <span class="t">instructions and showed that you can get a very good chatbot by just using 1,000 examples.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2304" target="_blank">00:38:24.760</a></span> | <span class="t">And this is, like, you know, taking the longest example from Open Assistant and just choosing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2308" target="_blank">00:38:28.480</a></span> | <span class="t">the top 500 of them. And so, we found that our model does slightly better than, you know,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2314" target="_blank">00:38:34.320</a></span> | <span class="t">each both of, like, Lama and Open Assistant, except for in Truthful QA, where we found</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2319" target="_blank">00:38:39.760</a></span> | <span class="t">that the Lima and Open Assistant did better than us. And similarly, like, actually, like,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2325" target="_blank">00:38:45.760</a></span> | <span class="t">in Empty Bench, we found, like, you know, the opposite was true. So, this is, like,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2329" target="_blank">00:38:49.680</a></span> | <span class="t">you know, Empty Bench is remember that LLMSys had, like, you know, turn zero and turn one.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2334" target="_blank">00:38:54.360</a></span> | <span class="t">And then so, this is reporting the first response. This is, like, GPD 4 is essentially scoring</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2338" target="_blank">00:38:58.720</a></span> | <span class="t">on a score of 1 to 10, how good these models are on the first dialogue turn and the second</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2344" target="_blank">00:39:04.880</a></span> | <span class="t">dialogue turn and the average score. And so, actually, this is kind of more counterintuitive</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2350" target="_blank">00:39:10.960</a></span> | <span class="t">to what we found on this automatic evals is that actually the Empty Bench says that, you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2355" target="_blank">00:39:15.600</a></span> | <span class="t">know, our the data that our model trained on the data that we collected from search</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2360" target="_blank">00:39:20.160</a></span> | <span class="t">is not very good. And in fact, Lima and Open Assistant, which are, like, a fraction of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2364" target="_blank">00:39:24.520</a></span> | <span class="t">the size of the data we had are much better. So, this was kind of surprising. And then</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2371" target="_blank">00:39:31.800</a></span> | <span class="t">I looked into, like, you know, let me look at is the length a factor in this? And it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2376" target="_blank">00:39:36.520</a></span> | <span class="t">does seem like, you know, like, the data I was looking at each of those and then, you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2380" target="_blank">00:39:40.240</a></span> | <span class="t">know, looked at the average length of the prompts in each of those. And it seems like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2383" target="_blank">00:39:43.960</a></span> | <span class="t">there is a very wide range. For example, like, our data set, the average length was just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2388" target="_blank">00:39:48.600</a></span> | <span class="t">211 of these prompts, while Lima is, like, double of that and Open Assistant is almost</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2393" target="_blank">00:39:53.520</a></span> | <span class="t">double of that. So, then I did this experiment where I wanted to check, like, if I controlled</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2402" target="_blank">00:40:02.760</a></span> | <span class="t">for the size of the data, but then, you know, let the length be varied, the prompt length,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2407" target="_blank">00:40:07.960</a></span> | <span class="t">does that affect the performance? So, in particular, like, I think I highlighted this before is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2412" target="_blank">00:40:12.520</a></span> | <span class="t">that our chat category was, like, really short. And so, it actually found that, you know,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2417" target="_blank">00:40:17.600</a></span> | <span class="t">like, length did not really affect that much, except for this truthful QA data set. Even</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2423" target="_blank">00:40:23.880</a></span> | <span class="t">for this Hellas swag, even though it looks small, it's actually just in the third digit.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2428" target="_blank">00:40:28.620</a></span> | <span class="t">And over here, you can see, like, the actual difference only made on truthful QA, which</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2432" target="_blank">00:40:32.140</a></span> | <span class="t">actually preferred models that were generating longer responses. But on the other hand, the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2439" target="_blank">00:40:39.320</a></span> | <span class="t">empty bench score was, again, not intuitive, not aligning or correlated with what we found</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2444" target="_blank">00:40:44.080</a></span> | <span class="t">with these automatic metrics and evaluations, in the sense that GPT-4 actually did not prefer,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2450" target="_blank">00:40:50.600</a></span> | <span class="t">like, longer responses. And so, this was, like, you know, a little bit counterintuitive.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2455" target="_blank">00:40:55.640</a></span> | <span class="t">And so, need to, like, dig more into, like, what's going on over here. But, you know,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2460" target="_blank">00:41:00.440</a></span> | <span class="t">it actually found that, you know, like, shorter responses were better than, you know, longer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2465" target="_blank">00:41:05.220</a></span> | <span class="t">responses. Although there was, like, not much of a very much of a difference.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2470" target="_blank">00:41:10.120</a></span> | <span class="t">So, the other experiment and evaluation we did is that just removing amounts of data</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2475" target="_blank">00:41:15.840</a></span> | <span class="t">and seeing, like, if you incrementally add more data, how does that affect performance?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2480" target="_blank">00:41:20.860</a></span> | <span class="t">And this is, again, on that open LLM leaderboard from Hugging Face, which is looking at some</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2486" target="_blank">00:41:26.620</a></span> | <span class="t">of these standard NLP benchmarks and reporting accuracy. And so, this is, like, starting</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2492" target="_blank">00:41:32.200</a></span> | <span class="t">with just 10% of all the data we collected from search. And as you can see, like, you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2497" target="_blank">00:41:37.160</a></span> | <span class="t">know, in all these benchmarks, actually, like, it saturates very quickly. And in some of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2501" target="_blank">00:41:41.720</a></span> | <span class="t">them, you actually get, like, you know, you basically lose performance if you keep adding</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2506" target="_blank">00:41:46.120</a></span> | <span class="t">data. And so, this is kind of aligning with when I started, when we started collecting</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2510" target="_blank">00:41:50.520</a></span> | <span class="t">data, we had this diminishing return plot, wherein you said that if you have just very</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2514" target="_blank">00:41:54.920</a></span> | <span class="t">few thousand examples of very high quality instruction following data set, that's good</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2520" target="_blank">00:42:00.040</a></span> | <span class="t">enough. And then your performance saturates or plateaus very quickly after that. And so,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2526" target="_blank">00:42:06.040</a></span> | <span class="t">that is kind of what we got as well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2529" target="_blank">00:42:09.160</a></span> | <span class="t">Similarly, I think this is where one place where Empty Bench actually correlated with</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2536" target="_blank">00:42:16.440</a></span> | <span class="t">the automated metrics is that GPT-4 also, like, you know, showed that, you know, after,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2542" target="_blank">00:42:22.880</a></span> | <span class="t">like, about 4,000 examples, it was basically very barely any gain in performance, actually,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2548" target="_blank">00:42:28.800</a></span> | <span class="t">decreasing performance on the with the model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2553" target="_blank">00:42:33.040</a></span> | <span class="t">Okay, great. So, that was all the results on using, like, these human curated very high</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2560" target="_blank">00:42:40.440</a></span> | <span class="t">quality data set. What about, like, results from distillation from these synthetic data</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2566" target="_blank">00:42:46.000</a></span> | <span class="t">sets? In particular, we use UltraChat for supervised fine tuning and UltraFeedback for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2571" target="_blank">00:42:51.560</a></span> | <span class="t">DPO. And so, these are the results. So, this is, like, basically just work that was released</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2577" target="_blank">00:42:57.520</a></span> | <span class="t">last week. We haven't yet released the code and the data set, which we are going to do</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2581" target="_blank">00:43:01.960</a></span> | <span class="t">this week. And so, here I'm highlighting that Zephyr is the model we released. We built,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2586" target="_blank">00:43:06.560</a></span> | <span class="t">we used Mistral as the foundation model, and then fine tuned it using UltraChat and then</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2592" target="_blank">00:43:12.800</a></span> | <span class="t">did DPO on UltraFeedback. And as you can see that it actually beats chat GPT on this Alpaca</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2598" target="_blank">00:43:18.400</a></span> | <span class="t">eval leaderboard.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2599" target="_blank">00:43:19.400</a></span> | <span class="t">Also, it is, like, the best in the, in all the open, at least it's, like, it beats most</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2610" target="_blank">00:43:30.920</a></span> | <span class="t">of the 13 billion parameter models. And it's, like, quite competitive to cloud to, again,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2618" target="_blank">00:43:38.920</a></span> | <span class="t">on the Alpaca eval leaderboard. So, this is the model which has both SFD and DPO. So,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2626" target="_blank">00:43:46.880</a></span> | <span class="t">we did an ablation on how good or how useful is, like, you know, SFD and how useful is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2632" target="_blank">00:43:52.720</a></span> | <span class="t">DPO, because there's this two-step process. It's, like, first you fine tune on instruction</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2636" target="_blank">00:43:56.960</a></span> | <span class="t">demonstration, then you fine tune on human preferences. And so, this is the first row</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2642" target="_blank">00:44:02.280</a></span> | <span class="t">over here is showing what if you directly did DPO on UltraFeedback and did not do the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2647" target="_blank">00:44:07.640</a></span> | <span class="t">supervised fine tuning. And you actually saw that that's really bad. So, that doesn't work</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2651" target="_blank">00:44:11.720</a></span> | <span class="t">at all. And then the second one is saying that what if you just did supervised fine</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2656" target="_blank">00:44:16.600</a></span> | <span class="t">tuning and did not do DPO. And so, this actually, which is, like, the first step, and this actually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2661" target="_blank">00:44:21.480</a></span> | <span class="t">works decently well. And it's, like, you know, basically getting you to, like, 80 or 90%</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2665" target="_blank">00:44:25.840</a></span> | <span class="t">of the overall performance. And finally, this is doing, like, supervised fine tuning on</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2671" target="_blank">00:44:31.080</a></span> | <span class="t">the human preference data. So, you take this row and do another round of supervised fine</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2675" target="_blank">00:44:35.440</a></span> | <span class="t">tuning, but on this data of human preferences. So, you remember you had, like, the chosen</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2679" target="_blank">00:44:39.800</a></span> | <span class="t">and the rejected. So, you give all the dialogue history, and then the expected completion</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2684" target="_blank">00:44:44.800</a></span> | <span class="t">is the chosen dialogue response. So, in this case, you're not really doing that discriminative</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2689" target="_blank">00:44:49.000</a></span> | <span class="t">thing. You're still doing the SFD process, but you're just, you know, like, using that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2693" target="_blank">00:44:53.240</a></span> | <span class="t">in a smart using the data set in a smart way so that it follows a template of what supervised</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2698" target="_blank">00:44:58.160</a></span> | <span class="t">fine tuning does. And then that, as well, we found that, you know, wasn't very helpful.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2703" target="_blank">00:45:03.000</a></span> | <span class="t">So, the best recipe, obviously, is DPO plus SFD. So, you know, doing SFD first on the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2709" target="_blank">00:45:09.280</a></span> | <span class="t">UltraChat, and then DPO on the UltraFeedback. Both of these data sets are synthetic. And</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2714" target="_blank">00:45:14.880</a></span> | <span class="t">then, you know, it's, like, only slightly better than just doing SFD.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2720" target="_blank">00:45:20.040</a></span> | <span class="t">Okay. So, I'm getting to this final section of my talk, which is essentially looking at,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2727" target="_blank">00:45:27.120</a></span> | <span class="t">you know, so, we have seen a lot of these evaluation and benchmarks and leaderboards,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2731" target="_blank">00:45:31.760</a></span> | <span class="t">and many of them are starting to adopt these powerful models, like Cloud2 and GPD4, and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2737" target="_blank">00:45:37.120</a></span> | <span class="t">are using as proxy for humans in evaluation. And so, what are the quirks associated with</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2741" target="_blank">00:45:41.880</a></span> | <span class="t">doing that, and are there things that we should, like, be, like, you know, considering when</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2745" target="_blank">00:45:45.720</a></span> | <span class="t">we are doing this at a very large scale? So, when we did that, when we used GPD4 as</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2751" target="_blank">00:45:51.920</a></span> | <span class="t">an evaluator, we found that it actually has a positional bias. And so, in particular,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2757" target="_blank">00:45:57.440</a></span> | <span class="t">it is predisposed to generating a rating of 1 in a preference collection setting. And</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2763" target="_blank">00:46:03.080</a></span> | <span class="t">so, like, you know, this chart over here shows, like, the average rating for model responses</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2769" target="_blank">00:46:09.040</a></span> | <span class="t">across, like, the entire data set. And on the right, on the other hand, humans are more</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2773" target="_blank">00:46:13.440</a></span> | <span class="t">or less uniform. And so, you expect that, you know, this distribution seems much more</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2777" target="_blank">00:46:17.960</a></span> | <span class="t">better than this distribution, which is skewed to the right.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2782" target="_blank">00:46:22.440</a></span> | <span class="t">So, then what we did is that we prompted GPD4 to say that, hey, you have this left bias,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2788" target="_blank">00:46:28.560</a></span> | <span class="t">and you always generate this rating of 1, you know, be aware of this bias, and then</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2793" target="_blank">00:46:33.160</a></span> | <span class="t">you tell it to debias itself, it actually flips the bias in the opposite direction.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2798" target="_blank">00:46:38.000</a></span> | <span class="t">So, then it starts, like, it is more self-aware in the sense that it knows that, you know,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2802" target="_blank">00:46:42.400</a></span> | <span class="t">it has this bias, and now it starts generating more ratings of 5 and 6. And the one way of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2807" target="_blank">00:46:47.440</a></span> | <span class="t">getting rid of this is that we kind of make sure that each response is equally likely</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2811" target="_blank">00:46:51.720</a></span> | <span class="t">to be in right and left position. So, that kind of dilutes, like, this bias that it has</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2816" target="_blank">00:46:56.320</a></span> | <span class="t">to each of these positions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2820" target="_blank">00:47:00.440</a></span> | <span class="t">And then, you know, we found that actually, like, prompting GPD4 to generate scores, so</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2825" target="_blank">00:47:05.080</a></span> | <span class="t">asking it to score, like, each response individually, like, Empty Bench does. And then instead of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2830" target="_blank">00:47:10.040</a></span> | <span class="t">ranking, but in a pairwise setting, we actually found that that alleviates the problem a little</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2834" target="_blank">00:47:14.200</a></span> | <span class="t">bit, but does not completely get rid of the problem.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2838" target="_blank">00:47:18.080</a></span> | <span class="t">We also found evidence of doping between training and evaluation. So, in particular, we found</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2844" target="_blank">00:47:24.840</a></span> | <span class="t">that GPD4 prefers models that were trained on GPD4's data. So, these, all these models</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2851" target="_blank">00:47:31.200</a></span> | <span class="t">here were trained on data that was bootstrapped using GPD4. And, you know, so it prefers that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2857" target="_blank">00:47:37.640</a></span> | <span class="t">over humans who are, like, more factual, much more higher quality, but they might be very</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2863" target="_blank">00:47:43.080</a></span> | <span class="t">succinct and to the point. So, this is one thing that, you know, we should be aware of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2867" target="_blank">00:47:47.840</a></span> | <span class="t">when we are using GPD4 as an evaluator.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2871" target="_blank">00:47:51.240</a></span> | <span class="t">The other thing is that, you know, it also, like, conquers with findings from these other</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2875" target="_blank">00:47:55.040</a></span> | <span class="t">papers, which is that GPD4 prefers models with higher diversity. So, that is number</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2880" target="_blank">00:48:00.580</a></span> | <span class="t">of unique tokens in the response and the longer responses. So, if you have, like, this list</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2885" target="_blank">00:48:05.480</a></span> | <span class="t">of list kind of response, just like chat GPD does, GPD4 is, like, predisposed to rating</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2891" target="_blank">00:48:11.440</a></span> | <span class="t">that higher compared to a model that does not generate that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2894" target="_blank">00:48:14.720</a></span> | <span class="t">We also found that GPD4 has poor correlation with humans on low entropy tasks, such as</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2903" target="_blank">00:48:23.000</a></span> | <span class="t">math coding and reasoning. So, remember that leaderboard I showed you where we had compared,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2907" target="_blank">00:48:27.240</a></span> | <span class="t">like, how does GPD4 ELO rating compare to humans? And then we dive deeper into, like,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2913" target="_blank">00:48:33.120</a></span> | <span class="t">how does that compare on each of these different task distribution and categories? And so,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2917" target="_blank">00:48:37.400</a></span> | <span class="t">this is what it looks like. So, it seems like, you know, it says lower correlation with humans</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2922" target="_blank">00:48:42.640</a></span> | <span class="t">on some of these more factual, like, you know, kind of, like, expecting one correct answer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2928" target="_blank">00:48:48.160</a></span> | <span class="t">And they actually highly correlated with humans on these more high entropy tasks where you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2933" target="_blank">00:48:53.400</a></span> | <span class="t">got, like, brainstorming and creative generation, which was kind of unintuitive and counterintuitive</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2938" target="_blank">00:48:58.200</a></span> | <span class="t">because you could have so many different ways of coming up with, like, you know, a recipe</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2943" target="_blank">00:49:03.280</a></span> | <span class="t">or a list of something. But that's where, like, the rating of GPD4 and humans are more</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2948" target="_blank">00:49:08.160</a></span> | <span class="t">correlated.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2950" target="_blank">00:49:10.120</a></span> | <span class="t">Okay. So, the final thing is takeaways. So, there's a bunch of this. But let's try to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2957" target="_blank">00:49:17.680</a></span> | <span class="t">break it down. Essentially, like, you know, we discussed, like, how do we come up with</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2961" target="_blank">00:49:21.520</a></span> | <span class="t">steps for data curation for supervised fine tuning and RLHF? And it involves, like, several</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2967" target="_blank">00:49:27.160</a></span> | <span class="t">critical factors, such as how much data do you need to collect? What is the length of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2971" target="_blank">00:49:31.480</a></span> | <span class="t">the prompts and the distribution of those length? The task distribution? And what is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2976" target="_blank">00:49:36.880</a></span> | <span class="t">the role of humans? Like, you know, do you need synthetic data? Do you need completely</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2980" target="_blank">00:49:40.400</a></span> | <span class="t">manually curated or something in the middle? And we looked at, like, there are many tools</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2984" target="_blank">00:49:44.880</a></span> | <span class="t">for, like, efficient fine tuning of open source LLMs. From the SFD results, we found that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2991" target="_blank">00:49:51.160</a></span> | <span class="t">truthful QA was the main differentiating benchmark for these automated eval metrics. And then</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=2997" target="_blank">00:49:57.680</a></span> | <span class="t">we found that empty bench scores were actually not correlated with these automated metrics.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=3002" target="_blank">00:50:02.680</a></span> | <span class="t">And so, it was more sort of, you know, only on, like, some of these models, we found that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=3008" target="_blank">00:50:08.360</a></span> | <span class="t">they were correlated. For the distillation results, which is from the Zephyr 7D, where</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=3013" target="_blank">00:50:13.560</a></span> | <span class="t">we are, like, fine tuning on synthetic data, we found that the SFD on AI generated data</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=3019" target="_blank">00:50:19.520</a></span> | <span class="t">and the DPO or distillation of DPO on AI feedback data actually beats chat GPD, even though</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=3025" target="_blank">00:50:25.680</a></span> | <span class="t">the model is just 7 billion parameter. And then we found that, you know, benchmarking</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=3030" target="_blank">00:50:30.600</a></span> | <span class="t">gap in assessing RLHF models in particular, that we don't have benchmarks for assessing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=3037" target="_blank">00:50:37.080</a></span> | <span class="t">reward models. And we also don't have open source benchmarks for evaluating red teaming</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=3042" target="_blank">00:50:42.320</a></span> | <span class="t">and model vulnerabilities. Then finally, we'd like, you know, dive deeper into, like, you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=3047" target="_blank">00:50:47.480</a></span> | <span class="t">know, looking at quirks of using GPT-4 or some of these powerful LLMs as an evaluator.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=3053" target="_blank">00:50:53.560</a></span> | <span class="t">And some of them were, like, you know, they prefer models trained on GPT-4-like data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=3057" target="_blank">00:50:57.980</a></span> | <span class="t">It has, like, a left positional bias. And then it has high correlation with humans on</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=3062" target="_blank">00:51:02.960</a></span> | <span class="t">creative tasks compared to, like, coding or reasoning tasks. And my work has been covered</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=3069" target="_blank">00:51:09.640</a></span> | <span class="t">on the New York Times article cover, which talks about the secret ingredient of alignment,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=3075" target="_blank">00:51:15.200</a></span> | <span class="t">which is for chat GPD, which is alignment. I'm also part of the United Nations Advisory</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=3080" target="_blank">00:51:20.000</a></span> | <span class="t">Board that was announced last week. So, really humbled to be part of that. Here are some</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=3084" target="_blank">00:51:24.760</a></span> | <span class="t">blog posts. You know, basically, like, yeah, we kind of, like, did not publish a whole</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=3090" target="_blank">00:51:30.440</a></span> | <span class="t">lot this year. But we wrote a bunch of blog posts highlighting what we are releasing and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=3095" target="_blank">00:51:35.080</a></span> | <span class="t">working on. And also, like, you know, some of these are part of the talk that I just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=3099" target="_blank">00:51:39.960</a></span> | <span class="t">discussed. And this is part of the Edge 4 team. I'm grateful to be part of this. And</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=3107" target="_blank">00:51:47.440</a></span> | <span class="t">thanks for listening.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=3112" target="_blank">00:51:52.560</a></span> | <span class="t">When you get alternating responses from the products, do you select really high temperatures</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=3134" target="_blank">00:52:14.440</a></span> | <span class="t">or do you keep it pretty close to the temperature that's also told in the final product?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=3139" target="_blank">00:52:19.680</a></span> | <span class="t">Yeah. So, we did, like, you know, basically chose, like, you know, we tried experimenting</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=3145" target="_blank">00:52:25.400</a></span> | <span class="t">with different temperatures. But then we actually found that just using different sampling strategy</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=3151" target="_blank">00:52:31.660</a></span> | <span class="t">worked better. So, like, you know, using a different value of P and then K and some combination</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=3156" target="_blank">00:52:36.600</a></span> | <span class="t">of that as opposed to just, like, relying on temperature.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=3184" target="_blank">00:53:04.760</a></span> | <span class="t">Yeah. So, I think for Red Teaming at scale, there's actually a paper that came out recently</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=3200" target="_blank">00:53:20.760</a></span> | <span class="t">called GPD Fuzzer that actually, like, you know, bootstraps and uses these powerful LLMs</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=3207" target="_blank">00:53:27.280</a></span> | <span class="t">to jailbreak other LLMs. And also, there was a DeepMind paper, I think, actually, like,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=3210" target="_blank">00:53:30.840</a></span> | <span class="t">one and a half to almost two years ago that was Red Teaming large language models with</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=3215" target="_blank">00:53:35.600</a></span> | <span class="t">large language models. So, how do you, like, Red Team and evaluate a language model by</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=3219" target="_blank">00:53:39.840</a></span> | <span class="t">using another powerful language model? And so, I think that is kind of the way to go</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=3224" target="_blank">00:53:44.440</a></span> | <span class="t">in terms of scale. And so, what was the second question?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=3231" target="_blank">00:53:51.240</a></span> | <span class="t">Yeah. So, I think one thing is this idea of, like, emerging capabilities, which is essentially,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=3249" target="_blank">00:54:09.480</a></span> | <span class="t">like, as you scale up, and which is a trend that we are seeing, like, you know, as we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=3253" target="_blank">00:54:13.280</a></span> | <span class="t">are scaling up, there are things that these models do or, like, you know, capabilities</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=3257" target="_blank">00:54:17.720</a></span> | <span class="t">that emerge that were not there in the smaller models. I think examples are chain of thought</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=3261" target="_blank">00:54:21.780</a></span> | <span class="t">reasoning, which, you know, GPT-2 or GPT was not capable of doing it. And as we scale up,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=3267" target="_blank">00:54:27.880</a></span> | <span class="t">and the other example is this few short prompting that we first saw in GPT-3, as in, like, you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=3272" target="_blank">00:54:32.880</a></span> | <span class="t">could give it a completely new task and not update its parameters in any way, but just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=3277" target="_blank">00:54:37.760</a></span> | <span class="t">put it as part of the prompt. And then, you know, now it just learns the task, and then</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=3281" target="_blank">00:54:41.960</a></span> | <span class="t">it can do it on n number of examples, right? And so, like, labeling and all these things</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=3287" target="_blank">00:54:47.200</a></span> | <span class="t">started coming up, like using GPT-3 as a labeler and all that, when we kind of, like, discovered</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=3292" target="_blank">00:54:52.480</a></span> | <span class="t">that thing. So, I think, essentially, like, you know, the other example is, like, manipulation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=3296" target="_blank">00:54:56.840</a></span> | <span class="t">I don't think any open source models are capable of that yet, but I know, like, Anthropic and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=3302" target="_blank">00:55:02.560</a></span> | <span class="t">OpenAI, these companies are focusing on, like, you know, deception and manipulation, because</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=3307" target="_blank">00:55:07.320</a></span> | <span class="t">when you start, like, you know, chatting with these models, you start, like, you know, treating</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=3312" target="_blank">00:55:12.440</a></span> | <span class="t">them as a companion, especially, like, if you have, like, character AI kind of a thing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=3316" target="_blank">00:55:16.800</a></span> | <span class="t">where, you know, you might try confiding in them, start confiding in them, sharing information</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=3321" target="_blank">00:55:21.160</a></span> | <span class="t">that you probably shouldn't, and then they can use it against you, maybe. Like, you know,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=3326" target="_blank">00:55:26.000</a></span> | <span class="t">an example of that is, like, I think recently we saw that GPT-4 actually manipulated someone</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=3331" target="_blank">00:55:31.060</a></span> | <span class="t">to, like, read the capture to it in some way and, like, tell it what the capture reads.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=3335" target="_blank">00:55:35.440</a></span> | <span class="t">And so, that's a really concrete example of manipulation. And so, it seems like now these</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=3341" target="_blank">00:55:41.480</a></span> | <span class="t">models are capable of that. I don't think open source models are there yet, but these</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=3346" target="_blank">00:55:46.760</a></span> | <span class="t">are, like, just, like, you know, things that come out and, like, vulnerabilities that would</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=3350" target="_blank">00:55:50.840</a></span> | <span class="t">surface when you do it at D9.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=3355" target="_blank">00:55:55.840</a></span> | <span class="t">Yeah. So, I would say, like, it was, it's less about, like, you know, it's more about</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=3385" target="_blank">00:56:25.720</a></span> | <span class="t">open sourcing a data set that is crafted to kind of elicit this behavior. It's more about</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=3392" target="_blank">00:56:32.160</a></span> | <span class="t">the kind of harms that we should be thinking about. So, it's more about, like, you know,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=3396" target="_blank">00:56:36.920</a></span> | <span class="t">hallucinating or plagiarism, manipulation, you know, trying to leak PII information,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=3402" target="_blank">00:56:42.720</a></span> | <span class="t">people's credit card, SSN, things like that. It's more about, like, thinking about these</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=3406" target="_blank">00:56:46.560</a></span> | <span class="t">different dimensions and giving concrete examples of how these models can, you know, elicit</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=3412" target="_blank">00:56:52.280</a></span> | <span class="t">this behavior. But I think what you are trying to, like, talk about is that, you know, what</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=3417" target="_blank">00:56:57.120</a></span> | <span class="t">if we gave them concrete ways, like, concrete prompts on how you jailbreak, and then they</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=3421" target="_blank">00:57:01.320</a></span> | <span class="t">can go and try to do that. I think first thing is, like, you know, while we are doing this,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=3425" target="_blank">00:57:05.600</a></span> | <span class="t">we would have evaluated our models, and we would then start thinking about guardrails</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=3429" target="_blank">00:57:09.160</a></span> | <span class="t">and safety ourselves. And if, indeed, like, you know, the data set is so good that we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=3433" target="_blank">00:57:13.600</a></span> | <span class="t">can say that a lot of these powerful models are failing on that, then obviously you don't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=3437" target="_blank">00:57:17.160</a></span> | <span class="t">open source it instantly, but you actually think about what is the best way to put it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=3441" target="_blank">00:57:21.240</a></span> | <span class="t">out there by first securing the model and making sure that it does not, like, you know,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=3446" target="_blank">00:57:26.040</a></span> | <span class="t">basically does not elicit that kind of behavior, and then sharing it while you have already,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=3451" target="_blank">00:57:31.200</a></span> | <span class="t">you know, kind of crossed that bridge and being like, yeah, my model is safeguarded</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=3454" target="_blank">00:57:34.760</a></span> | <span class="t">against that. So it's more like, yeah, a process of a gradient of things that you need to do.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=3461" target="_blank">00:57:41.240</a></span> | <span class="t">Yeah, so you're talking about, like, when you're using synthetic data bootstrap on,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=3491" target="_blank">00:58:11.160</a></span> | <span class="t">on other language models, have you seen, like, collapse of, like, some kind of, like, mode</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=3495" target="_blank">00:58:15.800</a></span> | <span class="t">collapse or something like that? So, actually, so far, it's been, like, clear that these</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=3502" target="_blank">00:58:22.280</a></span> | <span class="t">are good, like, these, these actually turn, like, you know, regular chatbots and, like,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=3506" target="_blank">00:58:26.760</a></span> | <span class="t">regular language models into chatbots, and which are as good as the experience that you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=3510" target="_blank">00:58:30.600</a></span> | <span class="t">get by chatting with chat GPD. But although, like, you know, like, the kind of the quirks</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=3515" target="_blank">00:58:35.000</a></span> | <span class="t">that I raised, which is, like, you know, when you have these models, and then you, like,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=3518" target="_blank">00:58:38.320</a></span> | <span class="t">now put them on a benchmark, and then you see that suddenly, it's like 90%, it might</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=3522" target="_blank">00:58:42.320</a></span> | <span class="t">just be because you use the model that was the evaluator to generate the data and then</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=3526" target="_blank">00:58:46.640</a></span> | <span class="t">create this model and that in turn, like this doping thing, right. And so that is one thing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=3531" target="_blank">00:58:51.160</a></span> | <span class="t">that was, that is important to think about. The other thing is, what was I gonna say?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=3538" target="_blank">00:58:58.960</a></span> | <span class="t">I forgot. Yeah, the other thing is like about the licensing part, which is kind of not related</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=3557" target="_blank">00:59:17.880</a></span> | <span class="t">to what you were asking, but essentially, like, you know, there was this kind of like,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=3562" target="_blank">00:59:22.040</a></span> | <span class="t">you cannot, like, we could open, we cannot open source and commercially, so it's like,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=3566" target="_blank">00:59:26.440</a></span> | <span class="t">you know, still restrictive license. And you cannot use it for building and selling</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=3571" target="_blank">00:59:31.640</a></span> | <span class="t">applications down the line. But then it's still like good as like a research artifact.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=3577" target="_blank">00:59:37.360</a></span> | <span class="t">And so I think I like we would have seen these kind of collapses happen if it was allowed</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=3582" target="_blank">00:59:42.840</a></span> | <span class="t">to use these commercially. And then people would have been like, oh, but like, actually,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=3586" target="_blank">00:59:46.520</a></span> | <span class="t">recently, we did see like, so there's this company called Daxter, which use it, which</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=3590" target="_blank">00:59:50.880</a></span> | <span class="t">was using GPT for for summarization, they replaced it with the open source model called</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=3595" target="_blank">00:59:55.220</a></span> | <span class="t">Mistral. And they said that their customers haven't complained. And, you know, they're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=3600" target="_blank">01:00:00.200</a></span> | <span class="t">saving a ton of money, and it just seems to work fine. And they are like, you know, it's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=3604" target="_blank">01:00:04.720</a></span> | <span class="t">just as good. And so, but not not that I'm saying that Mistral is trained on any of the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=3609" target="_blank">01:00:09.840</a></span> | <span class="t">synthetic data, but it's just an example of, like things that would become very clear by</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=3614" target="_blank">01:00:14.400</a></span> | <span class="t">doing this sort of A/B testing where you like replace this model by another one and see</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=3618" target="_blank">01:00:18.720</a></span> | <span class="t">how that affects those things.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=3626" target="_blank">01:00:26.060</a></span> | <span class="t">I have a question on zoom.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=3629" target="_blank">01:00:29.320</a></span> | <span class="t">Yes.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=3631" target="_blank">01:00:31.440</a></span> | <span class="t">It's, it seems like another access you might be checked GPT on is on cost. So I wondered</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=3640" target="_blank">01:00:40.740</a></span> | <span class="t">why one of what your total budget was, or your total cost was to to produce your model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=3645" target="_blank">01:00:45.360</a></span> | <span class="t">that beat them.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=3646" target="_blank">01:00:46.360</a></span> | <span class="t">Oh, so the Zephyr 7B was just four hours of training on 16 A100. So that's less than $50,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=3655" target="_blank">01:00:55.800</a></span> | <span class="t">I guess. Because we use a synthetic data set, which was already open source, which is ultra</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=3662" target="_blank">01:01:02.360</a></span> | <span class="t">chat and ultra feedback. But the cost associated</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=3667" target="_blank">01:01:07.520</a></span> | <span class="t">with the overall cost, all the people and everything. Yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=3671" target="_blank">01:01:11.760</a></span> | <span class="t">I see. Okay. So all the people and everything in the sense that there were no, I guess like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=3676" target="_blank">01:01:16.720</a></span> | <span class="t">ultra chat probably might have reported some cost and ultra feedback, but they are mostly</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=3682" target="_blank">01:01:22.000</a></span> | <span class="t">synthetic synthetically created with very little human intervention. And so they might,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=3688" target="_blank">01:01:28.960</a></span> | <span class="t">I don't know if they report that I haven't looked into that. But I would say it was still</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=3693" target="_blank">01:01:33.100</a></span> | <span class="t">much more cost efficient than what we spent on buying data from search and scale AI. And</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=3698" target="_blank">01:01:38.480</a></span> | <span class="t">we spend about half a million buying about 20,000 prompts of human preferences, the 20,000</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=3705" target="_blank">01:01:45.160</a></span> | <span class="t">dialogue, and about 10,000 instruction demonstration data. So that was quite a bit.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=3715" target="_blank">01:01:55.200</a></span> | <span class="t">I'm curious about is the scale that you use for evaluating the bias for GPT-4. So I was</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=3730" target="_blank">01:02:10.360</a></span> | <span class="t">like one seven on the slide. Yeah. Oh, so yeah, this was the entropic scale. Like remember</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=3745" target="_blank">01:02:25.600</a></span> | <span class="t">that like one, two, four is decreasingly A and five to eight is increasingly B. Yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=3750" target="_blank">01:02:30.560</a></span> | <span class="t">And I was giving the model to the last student. Yes, exactly. Yeah. And these types of evaluations,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=3760" target="_blank">01:02:40.440</a></span> | <span class="t">how sensitive to the prompt do you find the evaluators to placing you in the library saying</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=3766" target="_blank">01:02:46.600</a></span> | <span class="t">that it has the account for this left bias and the right bias, what's stopping you from</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=3774" target="_blank">01:02:54.000</a></span> | <span class="t">saying the distribution should be uniform, the distribution should be normal, and just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=3779" target="_blank">01:02:59.160</a></span> | <span class="t">kind of iteratively to see how like what those should be. Yeah. Yeah. I think that's a good</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=3784" target="_blank">01:03:04.840</a></span> | <span class="t">point in the sense like we did not study as to what were the certain tasks or prompts</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=3789" target="_blank">01:03:09.960</a></span> | <span class="t">that were putting off GPT-4 to like, you know, generate this kind of bias. Although I would</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=3796" target="_blank">01:03:16.120</a></span> | <span class="t">say that, you know, this was also observed by LNCIS and it's part of the findings as</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=3802" target="_blank">01:03:22.040</a></span> | <span class="t">well. But yeah, so the LNCIS paper also has that. But it will be interesting, like it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=3810" target="_blank">01:03:30.320</a></span> | <span class="t">will be surprising if it generates this on like very long prompts or prompts from like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=3815" target="_blank">01:03:35.320</a></span> | <span class="t">math or something, which are just hard to kind of like evaluate when they're like too</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=3819" target="_blank">01:03:39.640</a></span> | <span class="t">responsive, which at least as a human, like when I see like a bunch of code, like, you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=3824" target="_blank">01:03:44.520</a></span> | <span class="t">know, on this side and this side, and then it's very hard to say, and both of them are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=3827" target="_blank">01:03:47.480</a></span> | <span class="t">trying to do the same thing, but a very different approach. It's very hard to evaluate them.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=3832" target="_blank">01:03:52.520</a></span> | <span class="t">Right. And so, yeah, we haven't looked into that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=3836" target="_blank">01:03:56.360</a></span> | <span class="t">Perhaps another thing is, do you think forwarded matters, like which output you give to GPT-4</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=3849" target="_blank">01:04:09.440</a></span> | <span class="t">first?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=3850" target="_blank">01:04:10.440</a></span> | <span class="t">Yeah, I mean, that was basically the takeaway was that, you know, so it's interesting because</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=3855" target="_blank">01:04:15.760</a></span> | <span class="t">humans usually have recency bias, which is essentially the last thing that you read is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=3860" target="_blank">01:04:20.080</a></span> | <span class="t">the thing that you remember. And so you would just, you know, try to like, you know, choose</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=3863" target="_blank">01:04:23.880</a></span> | <span class="t">that more, you know, you're just inclined to do that. And GPT-4 actually had a left</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=3867" target="_blank">01:04:27.720</a></span> | <span class="t">bias. So the thing that it first saw in some sense, and I think some, like, I think LNCIS</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=3872" target="_blank">01:04:32.760</a></span> | <span class="t">was the one that proposed because it has this left to right training, maybe that's why it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=3877" target="_blank">01:04:37.080</a></span> | <span class="t">has that kind of a bias. But yeah, so I think the way we elevated that was that, you know,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=3884" target="_blank">01:04:44.120</a></span> | <span class="t">having every model's output be equally likely to be on the left and the right hand side.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=3888" target="_blank">01:04:48.720</a></span> | <span class="t">So if like, we're doing Alpaca and Vicuna, then instead of just doing Alpaca on left</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=3893" target="_blank">01:04:53.240</a></span> | <span class="t">and Vicuna on right, we would just randomly like switch them. And so both of them are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=3897" target="_blank">01:04:57.120</a></span> | <span class="t">likely to occur in both these positions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=3901" target="_blank">01:05:01.960</a></span> | <span class="t">And you still saw the left bias?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=3905" target="_blank">01:05:05.280</a></span> | <span class="t">If you just ask it to like rate it on a scale of 1 to 5, yes. But if you say that, you know,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=3910" target="_blank">01:05:10.280</a></span> | <span class="t">hey, you have this bias and make it try to make it aware of it, then it flips and it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=3914" target="_blank">01:05:14.520</a></span> | <span class="t">generates something like that. So yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=3940" target="_blank">01:05:40.120</a></span> | <span class="t">Is there other approaches where you kind of, you prompt the model by shuffling the prompts</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=3946" target="_blank">01:05:46.160</a></span> | <span class="t">and then you have to kind of de-bias or de-bias the results of it?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=3955" target="_blank">01:05:55.600</a></span> | <span class="t">By shuffling the prompts, you mean like-</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=3957" target="_blank">01:05:57.080</a></span> | <span class="t">Shuffle the order of how you put in the new recipes?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=3965" target="_blank">01:06:05.760</a></span> | <span class="t">Yeah. So that's what we did is that, you know, we would like, you know, randomly shuffle</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=3971" target="_blank">01:06:11.240</a></span> | <span class="t">the left and the right. And then so each model, so like, so basically like you have, you create</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=3977" target="_blank">01:06:17.080</a></span> | <span class="t">NC2 combinations. Suppose you want to evaluate three models on 10 prompts. So you'll have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=3983" target="_blank">01:06:23.200</a></span> | <span class="t">10 C2 combinations. I mean, N is the number of prompts, sorry, the number of models. And</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=3989" target="_blank">01:06:29.040</a></span> | <span class="t">then you would like, you know, basically like generate like, so this would be a total data</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=3993" target="_blank">01:06:33.080</a></span> | <span class="t">set. So like, you know, you would have generated 10 responses from each of these models and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=3997" target="_blank">01:06:37.080</a></span> | <span class="t">then put them together in this three C2 setting. And then so like, that will be like a combination</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=4003" target="_blank">01:06:43.360</a></span> | <span class="t">of each of these. And then you make sure that every time the, like the models on the left</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=4008" target="_blank">01:06:48.040</a></span> | <span class="t">are equally likely to also occur on the right. So if you are doing like model one and then</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=4012" target="_blank">01:06:52.680</a></span> | <span class="t">model two, then you also make sure like you also do model two and then model one on a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=4041" target="_blank">01:07:21.520</a></span> | <span class="t">scale of one to 10. Okay. Sure. Sorry. Should I keep the zoom on? Thank you. Yes. Yes. Yes.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=4069" target="_blank">01:07:49.360</a></span> | <span class="t">So I mean, just to see if I understand this correctly. So on the reinforcement learning</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=4078" target="_blank">01:07:58.120</a></span> | <span class="t">community, first you build a reward model. And then that reward model, I take text input</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=4082" target="_blank">01:08:02.840</a></span> | <span class="t">and then humans give it scores. The supervised problem, we are trying to predict from the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=4086" target="_blank">01:08:06.600</a></span> | <span class="t">sketch the score. And then I have the reward model. I will add a set of points to reinforcement</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=4093" target="_blank">01:08:13.600</a></span> | <span class="t">learning, take a set of points. Sometimes I have the next token, which is the end of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=4098" target="_blank">01:08:18.000</a></span> | <span class="t">statement token. And I pump that through the reward model and then reward optimize on this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=4102" target="_blank">01:08:22.000</a></span> | <span class="t">Yes. And that's how, it's very sparse rewards, right? I only have rewards at the very end.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=4106" target="_blank">01:08:26.400</a></span> | <span class="t">But that's how it works. Yes, exactly. And so you have to, it's very sample inefficient</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=4111" target="_blank">01:08:31.240</a></span> | <span class="t">because I keep doing this again and again. And then that's why you need a hundred thousand</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=4115" target="_blank">01:08:35.600</a></span> | <span class="t">examples for doing Arul-Acha, but only 10,000 possible. That's kind of the info. Okay, great.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=4121" target="_blank">01:08:41.240</a></span> | <span class="t">Thanks so much. Very interesting talk. Thank you.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=4123" target="_blank">01:08:43.120</a></span> | <span class="t">Thank you very much.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=4124" target="_blank">01:08:44.120</a></span> | <span class="t">Thank you.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=4125" target="_blank">01:08:45.120</a></span> | <span class="t">Thank you.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=4125" target="_blank">01:08:45.120</a></span> | <span class="t">you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mcep6W8oB1I&t=4127" target="_blank">01:08:47.180</a></span> | <span class="t">[BLANK_AUDIO]</span></div></div></body></html>