<html><head><title>o3 - wow</title>
<style>
    body {
        font-family: Arial, sans-serif;
        margin: 0;
        padding: 0;
        background-color: #f4f4f4;
        color: #333;
    }
    .container {
        width: 95%;  /* Increased width to use more space */
        margin: auto;
        overflow: auto;  /* Added to handle overflow by adding a scrollbar if necessary */
    }
    h2, h3 {
        color: #333;
        text-align: center;
    }
    a {
        color: #0000FF;  /* Traditional blue color for links */
        text-decoration: none;
    }
    a:hover {
        text-decoration: underline;
    }
    img {
        display: block;
        margin: auto;
        max-width: 100%;
    }
    .c {
        margin: 10px 0;
    }
    .s, .t {
        display: inline-block;
        margin-right: 5px;
    }
    .max-width {
        max-width: 800px;
        margin: auto;
        padding-left: 20px;
    }
    table {
        width: 100%;
        border-collapse: collapse;
    }
    th, td {
        border: 1px solid #ddd;
        padding: 8px;
        text-align: left;  /* Ensure text alignment is consistent */
    }
    tr:nth-child(even) {
        background-color: #f2f2f2;
    }
    tr:nth-child(odd) {
        background-color: #e6e6e6;
    }
</style>

    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-69VLBMTTP0"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-69VLBMTTP0');
    </script>
    </head><body><div class='container'><a href="index.html">back to index</a><h2>o3 - wow</h2><a href="https://www.youtube.com/watch?v=YAgIh4aFawU"><img src="https://i.ytimg.com/vi_webp/YAgIh4aFawU/maxresdefault.webp" style="width:50%;"></a><div><br></div><h3>Chapters</h3><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=0">0:0</a> Introduction<br><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=79">1:19</a> What is o3?<br><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=198">3:18</a> FrontierMath<br><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=315">5:15</a> o4, o5<br><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=363">6:3</a> GPQA<br><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=384">6:24</a> Coding, Codeforces + SWE-verified, AlphaCode 2<br><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=493">8:13</a> 1st Caveat<br><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=543">9:3</a> Compositionality?<br><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=616">10:16</a> SimpleBench?<br><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=791">13:11</a> ARC-AGI, Chollet<br><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=1225">20:25</a> Safety Implicaitons<br><br><div style="text-align: left;"><a href="./YAgIh4aFawU.html">Whisper Transcript</a> | <a href="./transcript_YAgIh4aFawU.html">Transcript Only Page</a></div><br><div style="max-width: 800px;"><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=0" target="_blank">00:00:00.000</a></span> | <span class="t">The model announced tonight by OpenAI, called O3, could well be the final refutation that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=8" target="_blank">00:00:08.200</a></span> | <span class="t">artificial intelligence was hitting a wall. OpenAI, it seems, have not so much as surmounted</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=15" target="_blank">00:00:15.100</a></span> | <span class="t">that wall, they have supplied evidence that the wall did not in fact exist. The real news</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=20" target="_blank">00:00:20.220</a></span> | <span class="t">of tonight isn't, for me, that O3 just crushed benchmarks designed to stand for decades.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=28" target="_blank">00:00:28.180</a></span> | <span class="t">Estimates that OpenAI have shown that anything you can benchmark, the O-series of models</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=33" target="_blank">00:00:33.680</a></span> | <span class="t">can eventually beat. Let me invite you to think of any challenge. If that challenge</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=39" target="_blank">00:00:39.340</a></span> | <span class="t">is ultimately susceptible to reasoning, and if the reasoning steps are represented anywhere</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=44" target="_blank">00:00:44.580</a></span> | <span class="t">in the training data, the O-series of models will eventually crush that challenge. Yes,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=50" target="_blank">00:00:50.400</a></span> | <span class="t">it might have cost O3, or OpenAI, $350,000 in thinking time to beat some of these benchmarks,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=58" target="_blank">00:00:58.380</a></span> | <span class="t">but costs alone will not hold the tide at bay for long. Yes, I'll give the caveats,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=63" target="_blank">00:01:03.620</a></span> | <span class="t">I always do, and there are quite a few. But I must admit, and I will admit, that this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=68" target="_blank">00:01:08.540</a></span> | <span class="t">is a monumental day in AI, and pretty much everyone listening should adjust their timelines.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=75" target="_blank">00:01:15.740</a></span> | <span class="t">Before we get to the absolutely crazy benchmark scores, what actually is O3? What did they</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=81" target="_blank">00:01:21.440</a></span> | <span class="t">do? Well, I've given more detail on the O-series of models in previous videos on this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=86" target="_blank">00:01:26.980</a></span> | <span class="t">channel but let me give you a 30 second summary. OpenAI get the base model to generate hundreds</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=92" target="_blank">00:01:32.700</a></span> | <span class="t">or potentially thousands of candidate solutions, following long chains of thought, to get to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=97" target="_blank">00:01:37.940</a></span> | <span class="t">an answer. A verifier model, likely based on the same base model, then reviews those</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=103" target="_blank">00:01:43.000</a></span> | <span class="t">answers and ranks them, looking for classic calculation mistakes or reasoning mistakes.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=108" target="_blank">00:01:48.300</a></span> | <span class="t">That verifier model, of course, is trained on thousands of correct reasoning steps. But</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=112" target="_blank">00:01:52.940</a></span> | <span class="t">here's the kicker, in scientific domains like mathematics and coding, you can know</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=117" target="_blank">00:01:57.420</a></span> | <span class="t">what the correct answer is. So when the system generates a correct set of reasoning steps,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=123" target="_blank">00:02:03.260</a></span> | <span class="t">steps that lead to the correct verified answer, then the model as a whole can be fine-tuned</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=128" target="_blank">00:02:08.860</a></span> | <span class="t">on those correct steps. This fundamentally shifts us from predicting the next word to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=133" target="_blank">00:02:13.520</a></span> | <span class="t">predicting the series of tokens that will lead to an objectively correct answer. That</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=138" target="_blank">00:02:18.740</a></span> | <span class="t">fine-tuning on just the correct answers can be classed as reinforcement learning.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=143" target="_blank">00:02:23.500</a></span> | <span class="t">So what then is O3? Well, more of the same. As one researcher at OpenAI told us tonight,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=150" target="_blank">00:02:30.220</a></span> | <span class="t">O3 is powered by further scaling up reinforcement learning beyond O1. No special ingredient</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=156" target="_blank">00:02:36.700</a></span> | <span class="t">added to O1, it seems. No secret source. No wall. And that's why I said in the intro,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=162" target="_blank">00:02:42.900</a></span> | <span class="t">if you can benchmark it, the O series of models can eventually beat it. What I don't want</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=167" target="_blank">00:02:47.820</a></span> | <span class="t">to imply, though, is that this leap forward with O3 was entirely predictable. Yes, I talked</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=173" target="_blank">00:02:53.380</a></span> | <span class="t">about AI being on an exponential in my first video of this year, and I even referenced</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=179" target="_blank">00:02:59.940</a></span> | <span class="t">verifiers and inference time compute. That's the fancy term for thinking longer and generating</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=185" target="_blank">00:03:05.100</a></span> | <span class="t">more candidate solutions. But I am in pretty good company in not predicting this much of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=190" target="_blank">00:03:10.700</a></span> | <span class="t">a leap this soon. Let's briefly start with frontier math and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=194" target="_blank">00:03:14.660</a></span> | <span class="t">how did O3 do? This is considered today the toughest mathematical</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=198" target="_blank">00:03:18.380</a></span> | <span class="t">benchmark out there. This is a data set that consists of novel, unpublished, and also very</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=204" target="_blank">00:03:24.100</a></span> | <span class="t">hard. These are extremely hard.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=205" target="_blank">00:03:25.500</a></span> | <span class="t">Yeah, very, very hard problems. Even in terms of analysis, you know, it would take professional</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=208" target="_blank">00:03:28.980</a></span> | <span class="t">mathematicians hours or even days to solve one of these problems. And today all offerings</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=216" target="_blank">00:03:36.060</a></span> | <span class="t">out there have less than 2% accuracy on this benchmark. And we're seeing with O3, in aggressive</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=221" target="_blank">00:03:41.820</a></span> | <span class="t">test time settings, we're able to get over 25%. Yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=225" target="_blank">00:03:45.780</a></span> | <span class="t">They didn't say this in the announcement tonight, but the darker part of the bar, the smaller</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=230" target="_blank">00:03:50.060</a></span> | <span class="t">part is the model getting it right with only one attempt. The lighter part of the bar is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=235" target="_blank">00:03:55.340</a></span> | <span class="t">when the model gave lots of different solutions, but the one that came up the most often, the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=240" target="_blank">00:04:00.820</a></span> | <span class="t">consensus answer was the correct answer. We'll get to time and cost in a moment, but those</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=245" target="_blank">00:04:05.420</a></span> | <span class="t">details aside, the achievement of 25% is monumental. Here's what Terence Tao said at the beginning</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=252" target="_blank">00:04:12.580</a></span> | <span class="t">of November. These questions are extremely challenging. He's arguably the smartest</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=257" target="_blank">00:04:17.220</a></span> | <span class="t">guy in the world, by the way. I think that in the near term, basically the only way to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=261" target="_blank">00:04:21.780</a></span> | <span class="t">solve them, short of having a real domain expert in the area, is by a combination of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=266" target="_blank">00:04:26.400</a></span> | <span class="t">a semi-expert, like a grad student in a related field, paired with some combination of a modern</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=271" target="_blank">00:04:31.780</a></span> | <span class="t">AI and lots of other algebra packages. Given that O3 doesn't rely on algebra packages,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=278" target="_blank">00:04:38.340</a></span> | <span class="t">he's basically saying that O3 must be a real domain expert in mathematics. Summing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=283" target="_blank">00:04:43.540</a></span> | <span class="t">up, Terence Tao said that this benchmark would resist AIs for several years at least. Sam</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=289" target="_blank">00:04:49.900</a></span> | <span class="t">Altman seemed to imply that they were releasing the full O3 perhaps in February or at least</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=295" target="_blank">00:04:55.220</a></span> | <span class="t">the first quarter of next year. And that implies to me at least that they didn't just bust</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=299" target="_blank">00:04:59.740</a></span> | <span class="t">every single GPU on the planet to get this score, but could never serve it realistically</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=305" target="_blank">00:05:05.100</a></span> | <span class="t">to the public. Or to phrase things another way, we are not at the limits of the compute</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=309" target="_blank">00:05:09.620</a></span> | <span class="t">we even have available today. The next generation, O4, could be with us by quarter two of next</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=315" target="_blank">00:05:15.700</a></span> | <span class="t">year. O5 by quarter three. Here's what another top OpenAI researcher said "O3 is very performant.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=322" target="_blank">00:05:22.860</a></span> | <span class="t">More importantly, progress from O1 to O3 was only three months, which shows how fast progress</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=329" target="_blank">00:05:29.060</a></span> | <span class="t">will be in the new paradigm of reinforcement learning on chain of thought to scale inference</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=334" target="_blank">00:05:34.180</a></span> | <span class="t">compute." Way faster than the pre-training paradigm of a new model every one to two years.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=339" target="_blank">00:05:39.500</a></span> | <span class="t">We may never get GPT-5, but get AGI anyway. Of course, safety testing may well end up</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=345" target="_blank">00:05:45.660</a></span> | <span class="t">delaying the release to the public of these new generations of models. And so there might</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=349" target="_blank">00:05:49.980</a></span> | <span class="t">end up being an increasingly wide gap between what the frontier labs have available to use</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=355" target="_blank">00:05:55.500</a></span> | <span class="t">themselves and what the public has. What about Google proof graduate level science questions?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=361" target="_blank">00:06:01.380</a></span> | <span class="t">And as one OpenAI researcher put it, "Take a moment of silence for that benchmark. It</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=365" target="_blank">00:06:05.700</a></span> | <span class="t">was born in November of 2023 and died just a year later." Why RIP GPQA? Well, O3 gets</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=373" target="_blank">00:06:13.380</a></span> | <span class="t">87.7 percent. Benchmarks are being crushed almost as quickly as they can be created.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=381" target="_blank">00:06:21.020</a></span> | <span class="t">Then there's competitive coding where O3 establishes itself as the 175th highest scoring</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=387" target="_blank">00:06:27.820</a></span> | <span class="t">global competitor. Better at this coding competition than 99.95 percent of humans. Now you might</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=394" target="_blank">00:06:34.260</a></span> | <span class="t">say that's competition coding. That's not real software engineering. But then we had</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=398" target="_blank">00:06:38.380</a></span> | <span class="t">SWE Bench verified. That benchmark tests real issues faced by real software engineers. The</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=404" target="_blank">00:06:44.060</a></span> | <span class="t">verified part refers to the fact that the benchmark was combed for only genuine questions</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=408" target="_blank">00:06:48.660</a></span> | <span class="t">with real clear answers. Claude 3.5 SONNET gets 49 percent. O3 71.7 percent. As foreseen,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=417" target="_blank">00:06:57.660</a></span> | <span class="t">you could argue by the CEO of Anthropic, the creators of Claude.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=423" target="_blank">00:07:03.300</a></span> | <span class="t">The latest model we released, SONNET 3.5, the new or updated version, it gets something</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=429" target="_blank">00:07:09.580</a></span> | <span class="t">like 50 percent on SWE Bench. And SWE Bench is an example of a bunch of professional,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=434" target="_blank">00:07:14.940</a></span> | <span class="t">real-world software engineering tasks. At the beginning of the year, I think the state</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=440" target="_blank">00:07:20.220</a></span> | <span class="t">of the art was three or four percent. So in 10 months, we've gone from three percent to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=445" target="_blank">00:07:25.540</a></span> | <span class="t">50 percent on this task. And I think in another year, we'll probably be at 90 percent. I mean,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=449" target="_blank">00:07:29.900</a></span> | <span class="t">I don't know, but it might even be less than that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=453" target="_blank">00:07:33.380</a></span> | <span class="t">Before you ask, by the way, yes, these were unseen programming competitions. This isn't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=458" target="_blank">00:07:38.100</a></span> | <span class="t">data contamination. Again, if you can benchmark it, the O series of models will eventually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=464" target="_blank">00:07:44.540</a></span> | <span class="t">or imminently beat it. Interestingly, if you were following the channel closely, you might</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=469" target="_blank">00:07:49.540</a></span> | <span class="t">have guessed that this was coming in Codeforces as of this time last year. Google produced</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=474" target="_blank">00:07:54.900</a></span> | <span class="t">AlphaCode 2, which in certain parts of the Codeforces competition outperformed 99.5 percent</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=481" target="_blank">00:08:01.260</a></span> | <span class="t">of competition participants. And they went on prophetically, "We find that performance</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=485" target="_blank">00:08:05.980</a></span> | <span class="t">increases roughly log linearly with more samples."</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=489" target="_blank">00:08:09.420</a></span> | <span class="t">Yes, of course, I'm going to get to Arc AGI, but I just want to throw in my first</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=493" target="_blank">00:08:13.180</a></span> | <span class="t">quick caveat. What happens if you can't benchmark it, or at least it's harder to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=497" target="_blank">00:08:17.740</a></span> | <span class="t">benchmark or the field isn't as susceptible to reasoning steps? How about personal writing,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=503" target="_blank">00:08:23.740</a></span> | <span class="t">for example? Well, as OpenAI admitted back in September, the O series of models starting</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=508" target="_blank">00:08:28.780</a></span> | <span class="t">with O1 preview is not preferred on some natural language tasks, suggesting that it's not</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=514" target="_blank">00:08:34.180</a></span> | <span class="t">well suited for all use cases. Again then, think of a task. Is there an objectively correct</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=520" target="_blank">00:08:40.500</a></span> | <span class="t">answer to that task? The O series will likely soon beat it. As O3 proved tonight, that's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=527" target="_blank">00:08:47.340</a></span> | <span class="t">regardless of how difficult that task is. Is the correctness of the answer or the quality</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=532" target="_blank">00:08:52.780</a></span> | <span class="t">of the output more a matter of taste, however? Well, that might take longer to beat.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=537" target="_blank">00:08:57.780</a></span> | <span class="t">What about core reasoning, though? Out of distribution generalization? What I started</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=542" target="_blank">00:09:02.720</a></span> | <span class="t">this channel to cover back at the beginning of last year. Forgetting about cost or latency</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=547" target="_blank">00:09:07.740</a></span> | <span class="t">for a moment, what we all want to know is how intrinsically intelligent are these models?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=552" target="_blank">00:09:12.260</a></span> | <span class="t">That will dictate everything else, and I will raise that question through three examples</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=557" target="_blank">00:09:17.500</a></span> | <span class="t">to end the video. The first is compositionality, which came in a famous paper in Nature published</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=564" target="_blank">00:09:24.140</a></span> | <span class="t">last year. Essentially, you test models by making up a language full of concepts like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=570" target="_blank">00:09:30.100</a></span> | <span class="t">between, or double, or colours, and see if they can compose those concepts into a correct</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=576" target="_blank">00:09:36.620</a></span> | <span class="t">answer. The concepts are abstract enough that they would of course never have been seen</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=581" target="_blank">00:09:41.520</a></span> | <span class="t">in the training data. The original GPT-4 flopped hard at this challenge in the paper in Nature,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=587" target="_blank">00:09:47.460</a></span> | <span class="t">and O1 Pro mode gets close, but still can't do it. After thinking for 9 minutes, it successfully</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=595" target="_blank">00:09:55.460</a></span> | <span class="t">translates "who" as "double", but doesn't quite understand "moreau". It thinks it's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=602" target="_blank">00:10:02.180</a></span> | <span class="t">something about symmetry, but doesn't grasp that it means between. Will O3 master compositionality?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=608" target="_blank">00:10:08.940</a></span> | <span class="t">I can't answer that question because I can't yet test it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=612" target="_blank">00:10:12.260</a></span> | <span class="t">Next is of course my own benchmark called SimpleBench. This video was originally meant</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=617" target="_blank">00:10:17.020</a></span> | <span class="t">to be a summary of the 12 days, I was going to show off VO2 and talk about Gemini 2.0</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=622" target="_blank">00:10:22.700</a></span> | <span class="t">Flash Thinking Experimental from Google. The thinking, this time in visible chains of thought,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=628" target="_blank">00:10:28.300</a></span> | <span class="t">is reminiscent then of the O series of models. On the 3 runs we've done so far, it scores</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=633" target="_blank">00:10:33.460</a></span> | <span class="t">around 25%, which is great for such a small model as Flash, but isn't quite as good</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=639" target="_blank">00:10:39.320</a></span> | <span class="t">as even their own model, Gemini Experimental 1206. For this particular day of shipmas,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=645" target="_blank">00:10:45.580</a></span> | <span class="t">we are though putting Google to one side because OpenAI have produced O3.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=650" target="_blank">00:10:50.300</a></span> | <span class="t">So here's what I'm looking out for in O3 to see whether it would crush SimpleBench.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=656" target="_blank">00:10:56.140</a></span> | <span class="t">Essentially it needs to master spatial reasoning. Now you can pause and read the question yourself,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=661" target="_blank">00:11:01.900</a></span> | <span class="t">but I helpfully supplied O1 Pro mode with this visual as well. And without even reading</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=667" target="_blank">00:11:07.100</a></span> | <span class="t">the question, what would you say would happen to this glove if it fell off of the bike?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=672" target="_blank">00:11:12.980</a></span> | <span class="t">And let's say I also supplied you with the speed of the river. Well you might well say</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=677" target="_blank">00:11:17.140</a></span> | <span class="t">to me, thanks for all of those details, but honestly the glove is just going to fall onto</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=681" target="_blank">00:11:21.540</a></span> | <span class="t">the road. O1 doesn't even consider that possibility, and never does, because spatial</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=687" target="_blank">00:11:27.820</a></span> | <span class="t">data isn't really in its training data, nor is sophisticated social reasoning data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=693" target="_blank">00:11:33.380</a></span> | <span class="t">Wait, let me caveat that, of course we don't know what is in the training data, I just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=698" target="_blank">00:11:38.140</a></span> | <span class="t">suspect it's not in the training data of O1 at least. Likely not in O3, but we don't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=703" target="_blank">00:11:43.460</a></span> | <span class="t">know. Is the base model for O3 Orion or what would have been GPT 4.5, GPT 5? OpenAI never</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=709" target="_blank">00:11:49.900</a></span> | <span class="t">mentioned a shift in what the base model was, but they haven't denied it either. Someone</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=714" target="_blank">00:11:54.860</a></span> | <span class="t">could make the argument that O3 is so good at something like physics that it can intuit</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=720" target="_blank">00:12:00.300</a></span> | <span class="t">for itself what would happen in spatial reasoning scenarios. Maybe, but we'd have to test it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=726" target="_blank">00:12:06.180</a></span> | <span class="t">What I do have to remind myself though, with simple bench and spatial reasoning more generally,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=731" target="_blank">00:12:11.540</a></span> | <span class="t">is it doesn't strike me perhaps as a fundamental limitation for the model going forward. As</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=736" target="_blank">00:12:16.700</a></span> | <span class="t">I said right in the start of the intro to this video, OpenAI have fundamentally with</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=741" target="_blank">00:12:21.420</a></span> | <span class="t">O3 demonstrated the extent of a generalizable approach to solving things. In other words,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=747" target="_blank">00:12:27.100</a></span> | <span class="t">with enough spatial reasoning data, and good spatial reasoning benchmarks, and some more</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=752" target="_blank">00:12:32.220</a></span> | <span class="t">of that scaled up reinforcement learning, I think models would get great at this too.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=756" target="_blank">00:12:36.700</a></span> | <span class="t">And frankly, even if benchmarks like simple bench can last a little bit longer because</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=761" target="_blank">00:12:41.340</a></span> | <span class="t">of a paucity of spatial reasoning data, or text based spatial reasoning data not being</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=766" target="_blank">00:12:46.300</a></span> | <span class="t">enough, you have simulators like Genesis that can model physics and give models like O3</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=774" target="_blank">00:12:54.140</a></span> | <span class="t">almost infinite training data of lifelike simulations. You could almost imagine O3 or</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=779" target="_blank">00:12:59.500</a></span> | <span class="t">O4 being unsure of an answer, spinning up a simulation, spotting what would happen and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=785" target="_blank">00:13:05.180</a></span> | <span class="t">then outputting the answer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=786" target="_blank">00:13:06.740</a></span> | <span class="t">And now at last, what about Arc AGI? I made an entire video not that long ago about how</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=792" target="_blank">00:13:12.940</a></span> | <span class="t">this particular challenge created by Francois Chalet was a necessary but not sufficient</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=798" target="_blank">00:13:18.660</a></span> | <span class="t">condition for AGI. The reason why O3 beating this benchmark is so significant is because</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=805" target="_blank">00:13:25.180</a></span> | <span class="t">each example is supposed to be a novel test. A challenge, in other words, that's deliberately</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=811" target="_blank">00:13:31.100</a></span> | <span class="t">designed not to be in any training data, past or present. Beating it therefore has to involve</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=817" target="_blank">00:13:37.940</a></span> | <span class="t">at least a certain level of reasoning.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=820" target="_blank">00:13:40.420</a></span> | <span class="t">In case you're wondering by the way, I think reasoning is actually a spectrum. I define</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=825" target="_blank">00:13:45.140</a></span> | <span class="t">it as deriving efficient functions and composite functions. LLMs therefore always have done</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=832" target="_blank">00:13:52.040</a></span> | <span class="t">a form of reasoning, it's just that their functions that they derive are not particularly</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=836" target="_blank">00:13:56.980</a></span> | <span class="t">efficient. More like convoluted interpolations. Humans tend to spot things quicker, have more</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=842" target="_blank">00:14:02.620</a></span> | <span class="t">meta rules of thumb. And with these more meta rules of thumb, we can generalise better and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=848" target="_blank">00:14:08.920</a></span> | <span class="t">solve challenges that we haven't seen before more efficiently. Hence why many humans can</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=853" target="_blank">00:14:13.620</a></span> | <span class="t">see what has occurred to get from input 1 to output 1, input 2 to output 2. GPT-4 couldn't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=861" target="_blank">00:14:21.740</a></span> | <span class="t">and even O1 couldn't really. And for these specific examples, even O3 can't. Yes, it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=868" target="_blank">00:14:28.820</a></span> | <span class="t">might surprise you, there are still questions that aren't crazy hard that O3 can't get</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=874" target="_blank">00:14:34.620</a></span> | <span class="t">right. Nevertheless, O3, when given maximal compute, what I've calculated it at being</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=880" target="_blank">00:14:40.860</a></span> | <span class="t">350 grand's worth, gets 88%. And here's what the author of that benchmark said. "This</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=888" target="_blank">00:14:48.580</a></span> | <span class="t">isn't just brute force. Yes, it's very expensive, but these capabilities are new</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=894" target="_blank">00:14:54.120</a></span> | <span class="t">territory and they demand serious scientific attention. We believe, he said, it represents</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=900" target="_blank">00:15:00.020</a></span> | <span class="t">a significant breakthrough in getting AI to adapt to novel tasks. Reinforced again and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=906" target="_blank">00:15:06.180</a></span> | <span class="t">again with those chains of thought or reasoning steps that led it to correct answers, O3 has</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=911" target="_blank">00:15:11.260</a></span> | <span class="t">gotten pretty good at deriving efficient functions." In other words, it reasons pretty well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=917" target="_blank">00:15:17.220</a></span> | <span class="t">Now Chalet has often mentioned in the past that many of his smart friends scored around</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=922" target="_blank">00:15:22.620</a></span> | <span class="t">98% in Arc AGI. But a fairly recent paper from September showed that when an exhaustive</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=930" target="_blank">00:15:30.360</a></span> | <span class="t">study was done on average human performance, it was 64.2% on the public evaluation set.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=938" target="_blank">00:15:38.140</a></span> | <span class="t">Chalet himself predicted two and a half years ago that there wouldn't be a "pure" transformer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=944" target="_blank">00:15:44.020</a></span> | <span class="t">based model that gets greater than 50% on previously unseen Arc tasks within a time</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=949" target="_blank">00:15:49.780</a></span> | <span class="t">limit of five years. Again, I want to give you a couple of quick</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=953" target="_blank">00:15:53.020</a></span> | <span class="t">caveats before we get to his assessment of whether O3 is AGI. One OpenAI researcher admitted</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=960" target="_blank">00:16:00.240</a></span> | <span class="t">that it took 16 hours to get O3 to get 87.5% with an increase rate of 3.5% an hour to get</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=968" target="_blank">00:16:08.580</a></span> | <span class="t">to solved. And another caveat, this time from his public statement on O3. OpenAI apparently</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=975" target="_blank">00:16:15.340</a></span> | <span class="t">requested that they didn't publish the high compute costs involved in getting that high</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=980" target="_blank">00:16:20.300</a></span> | <span class="t">score. But they kind of did anyway, saying the amount of compute was roughly 172x the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=987" target="_blank">00:16:27.180</a></span> | <span class="t">low compute configuration. If the low compute high efficiency retail cost was $2,000, by</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=994" target="_blank">00:16:34.100</a></span> | <span class="t">my calculation, that's around $350,000 to get the 87.5%. If your day job is solving</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=1001" target="_blank">00:16:41.740</a></span> | <span class="t">Arc AGI challenges and you're paid less than $350,000 a year, you're safe just for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=1007" target="_blank">00:16:47.700</a></span> | <span class="t">now. And of course, if you're crazy worried by cost, there's always O3 mini, which gets</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=1012" target="_blank">00:16:52.720</a></span> | <span class="t">close to the performance of O3 for a fraction of the cost. But more seriously, he said later</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=1017" target="_blank">00:16:57.580</a></span> | <span class="t">in the statement, but cost performance will likely improve quite dramatically over the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=1022" target="_blank">00:17:02.420</a></span> | <span class="t">next few months and years. So you should plan for these capabilities to become competitive</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=1027" target="_blank">00:17:07.900</a></span> | <span class="t">with human work within a fairly short timeline. The challenge was always to get models to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=1033" target="_blank">00:17:13.940</a></span> | <span class="t">reason. The costs and latency came second. Those can drop later with more GPUs, Moore's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=1040" target="_blank">00:17:20.420</a></span> | <span class="t">law and algorithmic efficiency. It's the crushing of these challenges that was the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=1045" target="_blank">00:17:25.620</a></span> | <span class="t">hard part. Cost is not a barrier that's going to last long. Now, Shillay does go on</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=1050" target="_blank">00:17:30.100</a></span> | <span class="t">to say that O3 still fails on some very easy tasks. And you might argue that that Arc challenge</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=1056" target="_blank">00:17:36.180</a></span> | <span class="t">I showed just earlier was such an example. The blocks move essentially in the direction</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=1061" target="_blank">00:17:41.540</a></span> | <span class="t">of the lines that protrude out of them. And he mentions that he's crafting a so-called</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=1066" target="_blank">00:17:46.580</a></span> | <span class="t">Arc AGI 2 benchmark that he thinks will still pose a significant challenge to O3, potentially</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=1073" target="_blank">00:17:53.080</a></span> | <span class="t">reducing its score to under 30%. Sounds like he's almost already tested it. He goes on,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=1078" target="_blank">00:17:58.340</a></span> | <span class="t">"Even at high compute, while a smart human would still be able to score over 95% with</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=1083" target="_blank">00:18:03.740</a></span> | <span class="t">no training." Notice that's smart human rather than average human though. And also</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=1088" target="_blank">00:18:08.180</a></span> | <span class="t">it's kind of like O3 is under 30%, but what about O4, O5? What if even O6 is released</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=1094" target="_blank">00:18:14.980</a></span> | <span class="t">before the end of 2025? That's maybe why Mike Knoop, the funder of the Arc $1 million</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=1101" target="_blank">00:18:21.860</a></span> | <span class="t">prize, says, "We want AGI benchmarks that can endure many years. I do not expect V2</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=1108" target="_blank">00:18:28.020</a></span> | <span class="t">will." And so, cryptically, he says, "We're also starting turning attention to V3, which</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=1113" target="_blank">00:18:33.340</a></span> | <span class="t">will be very different." That sets up the crucial definition then of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=1117" target="_blank">00:18:37.420</a></span> | <span class="t">what counts as AGI. Is it still not AGI as long as there's any benchmark that the average</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=1123" target="_blank">00:18:43.780</a></span> | <span class="t">human can outperform a model at? Shillay's position, at least as of tonight, is that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=1128" target="_blank">00:18:48.660</a></span> | <span class="t">he doesn't believe that O3 is AGI. The reason? Because it's still feasible to create unsaturated,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=1135" target="_blank">00:18:55.700</a></span> | <span class="t">not crushed, interesting benchmarks that are easy for humans yet impossible for AI, without</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=1141" target="_blank">00:19:01.700</a></span> | <span class="t">involving specialist knowledge. In sum, we will have AGI when creating such evals becomes</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=1147" target="_blank">00:19:07.980</a></span> | <span class="t">outright impossible. The question is, is that a fair marker? Does it have to be impossible</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=1153" target="_blank">00:19:13.900</a></span> | <span class="t">to create such a benchmark? One that humans can beat easily, yet is impossible for AI?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=1159" target="_blank">00:19:19.780</a></span> | <span class="t">Or should the definition of AGI be when it's harder to create a benchmark that's easier</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=1166" target="_blank">00:19:26.260</a></span> | <span class="t">for humans than it is for AI? In a way, that seems like a fairer definition, such that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=1171" target="_blank">00:19:31.800</a></span> | <span class="t">there isn't just a single benchmark out there that's holding out and the rest have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=1176" target="_blank">00:19:36.220</a></span> | <span class="t">fallen, and we're still saying not AGI. That of course leaves the question of is it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=1180" target="_blank">00:19:40.740</a></span> | <span class="t">harder to create a benchmark that O3 can't solve and yet is easy for humans? Do we consider</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=1185" target="_blank">00:19:45.620</a></span> | <span class="t">different modalities? Can it spot the lack of realism in certain AI generated videos?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=1191" target="_blank">00:19:51.020</a></span> | <span class="t">What kind of benchmarks are allowed or are not allowed? What about benchmarks where we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=1195" target="_blank">00:19:55.220</a></span> | <span class="t">factor in how quickly challenges are solved? I alas can't provide a satisfying answer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=1201" target="_blank">00:20:01.100</a></span> | <span class="t">for those of you who want a simple yes/no AGI or not. What I can do though is shine</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=1207" target="_blank">00:20:07.200</a></span> | <span class="t">a light on the significance of this achievement. Again, it's not about particular benchmarks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=1212" target="_blank">00:20:12.660</a></span> | <span class="t">It's about an approach that can be used again and again on whatever benchmark you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=1217" target="_blank">00:20:17.380</a></span> | <span class="t">create and to whatever scale you can pay for. It's almost like they've shown that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=1221" target="_blank">00:20:21.940</a></span> | <span class="t">they can defeat the very concept of a benchmark. Yes, of course I read the paper released tonight</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=1227" target="_blank">00:20:27.500</a></span> | <span class="t">by OpenAI on deliberative alignment. Essentially, they use these same reasoning techniques to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=1232" target="_blank">00:20:32.500</a></span> | <span class="t">get the models to be great at refusing harmful requests while also not over-refusing innocent</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=1238" target="_blank">00:20:38.540</a></span> | <span class="t">ones. Noam Brown, who is one of the research leads for O1, said that frontier math result</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=1245" target="_blank">00:20:45.100</a></span> | <span class="t">actually had safety implications. He said even if LLMs are dumb in some ways, and of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=1250" target="_blank">00:20:50.300</a></span> | <span class="t">course I can't yet test O3 on SimpleBench, nor even O1, they haven't yet given me API</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=1255" target="_blank">00:20:55.800</a></span> | <span class="t">access. He went on "Saturating evals, like frontier math, suggests AI is surpassing top</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=1262" target="_blank">00:21:02.220</a></span> | <span class="t">human intelligence in certain domains." The first implication of that, he said, is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=1266" target="_blank">00:21:06.920</a></span> | <span class="t">that we may see a broad acceleration in scientific research. But then he went on "This also</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=1271" target="_blank">00:21:11.920</a></span> | <span class="t">means that AI safety topics, like scalable oversight, may soon stop being hypothetical.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=1278" target="_blank">00:21:18.280</a></span> | <span class="t">Research in these domains needs to be a priority for the field." Scalable oversight, in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=1283" target="_blank">00:21:23.000</a></span> | <span class="t">a ridiculous nutshell, is answering the question of how essentially a dumber model, or dumber</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=1289" target="_blank">00:21:29.120</a></span> | <span class="t">human, can still have oversight over a smarter model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=1292" target="_blank">00:21:32.440</a></span> | <span class="t">This then is one of the co-creators of O3 saying we really need to start focusing on</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=1298" target="_blank">00:21:38.640</a></span> | <span class="t">safety. It's perhaps then more credible when OpenAI researchers like John Holman say</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=1303" target="_blank">00:21:43.600</a></span> | <span class="t">this, "When Sam and us researchers say AGI is coming, we aren't doing it to sell you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=1308" target="_blank">00:21:48.720</a></span> | <span class="t">Kool-Aid, a $2,000 subscription, or to trick you to invest in our next round. It's actually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=1314" target="_blank">00:21:54.880</a></span> | <span class="t">coming." Whatever you've made of O3 tonight, let me</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=1317" target="_blank">00:21:57.400</a></span> | <span class="t">know in the comments, I personally can't wait to test it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=1321" target="_blank">00:22:01.020</a></span> | <span class="t">This has been a big night in AI, and thank you so much for joining me on it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=1325" target="_blank">00:22:05.640</a></span> | <span class="t">As always, we'd love to see you over on Patreon, where I'll be continuing the discussion</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=1330" target="_blank">00:22:10.360</a></span> | <span class="t">and actually fairly soon releasing a mini-documentary on the fateful year 2015 when OpenAI started.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YAgIh4aFawU&t=1337" target="_blank">00:22:17.080</a></span> | <span class="t">But regardless, wherever you are, have a wonderful day.</span></div></div></body></html>