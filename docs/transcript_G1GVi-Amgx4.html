<html><head><title>What's Happening Inside Claude? – Dario Amodei (Anthropic CEO)</title>
<style>
    body {
        font-family: Arial, sans-serif;
        margin: 0;
        padding: 0;
        background-color: #f4f4f4;
        color: #333;
    }
    .container {
        width: 95%;  /* Increased width to use more space */
        margin: auto;
        overflow: auto;  /* Added to handle overflow by adding a scrollbar if necessary */
    }
    h2, h3 {
        color: #333;
        text-align: center;
    }
    a {
        color: #0000FF;  /* Traditional blue color for links */
        text-decoration: none;
    }
    a:hover {
        text-decoration: underline;
    }
    img {
        display: block;
        margin: auto;
        max-width: 100%;
    }
    .c {
        margin: 10px 0;
    }
    .s, .t {
        display: inline-block;
        margin-right: 5px;
    }
    .max-width {
        max-width: 800px;
        margin: auto;
        padding-left: 20px;
    }
    table {
        width: 100%;
        border-collapse: collapse;
    }
    th, td {
        border: 1px solid #ddd;
        padding: 8px;
        text-align: left;  /* Ensure text alignment is consistent */
    }
    tr:nth-child(even) {
        background-color: #f2f2f2;
    }
    tr:nth-child(odd) {
        background-color: #e6e6e6;
    }
</style>

    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-69VLBMTTP0"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-69VLBMTTP0');
    </script>
    </head><body><div class='container'><a href="index.html">Back to Index</a><h2>What's Happening Inside Claude? – Dario Amodei (Anthropic CEO)</h2><a href="https://www.youtube.com/watch?v=G1GVi-Amgx4" target="_blank"><img src="https://i.ytimg.com/vi_webp/G1GVi-Amgx4/maxresdefault.webp" style="width:50%;"></a><div><br></div><h3>Transcript</h3><div class='max-width'><p>I don't know if like, there's this circuit that's weak and getting stronger. I don't know if it's something that works, but not very well, like, I think we don't know. And these are some of the questions we're trying to answer with mechanistic interpretability. If you had to put it in terms of human psychology, what is the change that is happening?</p><p>Are we creating new drives, new goals, new thoughts? How is the model is changing in terms of psychology when I think all those terms are kind of like inadequate for you know, describing what's it's not clear how useful they are as abstractions for humans, either. I think we don't have the language to describe what's going on.</p><p>I'd love to look inside and say, and kind of actually know what we're talking about, instead of, you know, what basically making up words, which is what which is what I do, what you're doing, asking this question, where, you know, we should, we should just be honest, we really have very little idea what we're what we're talking about.</p><p>So, you know, it would be great to say, well, what we actually mean by that is, you know, this circuit within here turns, you know, turns on, and, you know, and, you know, after we've trained the model, then, you know, this circuit is no longer operative or weaker. And that would love to be able to say, again, we're going to take a lot of work to be able to do that.</p><p>mechanistically, what is alignment? Is it that you're locking in the model into a benevolent character? Are you disabling deceptive circuits and procedures like what concretely is happening? Yeah, when you align a model, I think as with most things, you know, when we actually train a model to be aligned, we don't know what happens inside the model, right?</p><p>There are different ways of training it to be aligned. But I think we don't really know what happens. I mean, I think for some of the current methods, I think all the current methods that involve some kind of fine tuning, of course, have the property that the underlying knowledge and abilities that we might be worried about, don't don't disappear.</p><p>It's just, you know, the model is just taught not to output them. I don't know if that's a fatal flaw or if, you know, or if that's just the way things have to be. I think this problem would be much easier if you had an oracle that could just scan a model and say, like, okay, I know this model is aligned, I know what it will do in every situation, then the problem would be much easier.</p><p>And I think the closest thing we have to that is something like mechanistic interpretability. It's not anywhere near up to the task yet. But mechanistic interpretability is the only thing that even in principle, is the thing where it's like, it's more like an X ray of the model than a modification of the model, right?</p><p>It's more like an assessment than an intervention. I don't know what's going on inside mechanistically. And I think that's the whole point of mechanistic interpretability, to really understand what's going on inside the models at the level of individual circuits. I think what we're hoping for in the end is not that we'll understand every detail.</p><p>But again, I would give like the X ray or the MRI analogy that like, we can be in a position where we can look at the broad features of the model and say, like, is this a model whose internal state and plans are very different from what it externally represents itself to do, right?</p><p>Is this a model where we're uncomfortable that, you know, far too much of its computational power is, you know, is devoted to doing what looked like fairly destructive and manipulative things. And I give an analogy like to humans. So it's actually possible to, you know, to look at an MRI of someone and predict above random chance, whether they're a psychopath.</p><p>There was actually a story a few years back about a neuroscientist who was studying this, and he looked at his own scan and discovered that he was a psychopath. And then everyone, everyone in his life was like, no, no, that's just obvious. Like, you're, you're a complete asshole. You must be a psychopath.</p><p>And he was totally, totally unaware of this. The basic idea that, you know, that there can be these macro features that like, like psychopath is probably a good analogy for it, right? They're like, you know, this is what we would be afraid of model that's kind of like, charming on the surface, very goal oriented, and you know, very dark on the inside.</p><p>Do you think that cloud has conscious experience? How likely do you think that is? This is another of these questions that just seems very unsettled and uncertain. Conscious is again, one of these words that I suspect it will like, not end up having a, a well defined, but yeah, but, but that, yeah, well, I suspect that's, that's, that's the spectrum, right?</p><p>So I don't know if we, if we, if we discover like that, you know, that I should care about, let's say we discover that I should care about Claude's experience as much as I should care about like a dog or a monkey or something. Yeah, I would be, I would be kind of, kind of worried.</p><p>I don't know if their experience is positive or negative. Unsettlingly, I also don't know, like, I wouldn't know if any intervention that we made was more likely to make Claude, you know, have a positive versus negative experience versus not having one. If there's an area that is helpful with this, it's maybe mechanistic interpretability, because I think of it as neuroscience for models.</p><p>And so it's possible that we could, we could shed some, shed some light on this, although, you know, it's not, it's not a straightforward, factual</p></div></div></body></html>