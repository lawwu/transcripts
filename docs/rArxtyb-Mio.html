<html><head><title>o3 breaks (some) records, but AI becomes pay-to-win</title>
<style>
    body {
        font-family: Arial, sans-serif;
        margin: 0;
        padding: 0;
        background-color: #f4f4f4;
        color: #333;
    }
    .container {
        width: 95%;  /* Increased width to use more space */
        margin: auto;
        overflow: auto;  /* Added to handle overflow by adding a scrollbar if necessary */
    }
    h2, h3 {
        color: #333;
        text-align: center;
    }
    a {
        color: #0000FF;  /* Traditional blue color for links */
        text-decoration: none;
    }
    a:hover {
        text-decoration: underline;
    }
    img {
        display: block;
        margin: auto;
        max-width: 100%;
    }
    .c {
        margin: 10px 0;
    }
    .s, .t {
        display: inline-block;
        margin-right: 5px;
    }
    .max-width {
        max-width: 800px;
        margin: auto;
        padding-left: 20px;
    }
    table {
        width: 100%;
        border-collapse: collapse;
    }
    th, td {
        border: 1px solid #ddd;
        padding: 8px;
        text-align: left;  /* Ensure text alignment is consistent */
    }
    tr:nth-child(even) {
        background-color: #f2f2f2;
    }
    tr:nth-child(odd) {
        background-color: #e6e6e6;
    }
</style>

    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-69VLBMTTP0"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-69VLBMTTP0');
    </script>
    </head><body><div class='container'><a href="index.html">back to index</a><h2>o3 breaks (some) records, but AI becomes pay-to-win</h2><a href="https://www.youtube.com/watch?v=rArxtyb-Mio"><img src="https://i.ytimg.com/vi/rArxtyb-Mio/maxresdefault.jpg" style="width:50%;"></a><div><br></div><h3>Chapters</h3><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=0">0:0</a> Introduction<br><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=33">0:33</a> FictionLiveBench<br><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=97">1:37</a> PHYBench<br><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=134">2:14</a> SimpleBench<br><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=174">2:54</a> Virology Capabilities Test<br><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=193">3:13</a> Mathematics Performance<br><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=269">4:29</a> Vision Benchmarks<br><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=343">5:43</a> V* and how o3 works<br><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=404">6:44</a> Revenue and costs for you<br><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=534">8:54</a> Expensive RL and trade-offs<br><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=580">9:40</a> How to spend the OOMs<br><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=807">13:27</a> Gray Swan Arena<br><br><div style="text-align: left;"><a href="./rArxtyb-Mio.html">Whisper Transcript</a> | <a href="./transcript_rArxtyb-Mio.html">Transcript Only Page</a></div><br><div style="max-width: 800px;"><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=0" target="_blank">00:00:00.000</a></span> | <span class="t">This video is about rapid progress in AI, progress that might soon be a little less</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=5" target="_blank">00:00:05.660</a></span> | <span class="t">US-centric, with news of a veteran OpenAI researcher being denied a green card.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=12" target="_blank">00:00:12.320</a></span> | <span class="t">But it's been just a single-digit number of days since the release of O3, the latest model from</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=18" target="_blank">00:00:18.260</a></span> | <span class="t">OpenAI, and it has broken some records, and in turn raised yet more questions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=23" target="_blank">00:00:23.800</a></span> | <span class="t">So in no particular order, and drawing on a half dozen papers, here are four updates on</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=30" target="_blank">00:00:30.000</a></span> | <span class="t">the state of play at the bleeding edge of AI.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=32" target="_blank">00:00:32.520</a></span> | <span class="t">Now just before we get to how much money these models will make for companies like OpenAI</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=36" target="_blank">00:00:36.700</a></span> | <span class="t">and Google, and how much money they will cost you, which model is actually the best at the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=42" target="_blank">00:00:42.160</a></span> | <span class="t">moment?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=42" target="_blank">00:00:42.400</a></span> | <span class="t">Well, that's actually really hard to say, because it depends heavily on your use case and the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=48" target="_blank">00:00:48.100</a></span> | <span class="t">benchmark that you look at.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=49" target="_blank">00:00:49.420</a></span> | <span class="t">At the moment, the two clear contenders for me would be O3 and Gemini 2.5 Pro, and I covered</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=56" target="_blank">00:00:56.020</a></span> | <span class="t">how they were neck and neck in some of the most famous benchmarks in the video I released</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=60" target="_blank">00:01:00.420</a></span> | <span class="t">on the night of O3's release.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=62" target="_blank">00:01:02.220</a></span> | <span class="t">But since then, we've arguably got some more interesting benchmark results.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=65" target="_blank">00:01:05.840</a></span> | <span class="t">Take the piecing together of puzzles within long works of fiction, up to say around 100,000</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=72" target="_blank">00:01:12.340</a></span> | <span class="t">words.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=72" target="_blank">00:01:12.740</a></span> | <span class="t">I honestly expected Gemini 2.5 Pro to keep its lead, in that it could piece together those</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=78" target="_blank">00:01:18.020</a></span> | <span class="t">puzzles, even at various lengths through to the longest texts.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=81" target="_blank">00:01:21.620</a></span> | <span class="t">After all, long context is Gemini's speciality.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=84" target="_blank">00:01:24.740</a></span> | <span class="t">But no, O3 takes the lead at almost every length of text.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=89" target="_blank">00:01:29.760</a></span> | <span class="t">If you know that there's a clue in chapter 3 that pertains to chapter 16, then O3 is the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=95" target="_blank">00:01:35.900</a></span> | <span class="t">model for you.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=96" target="_blank">00:01:36.480</a></span> | <span class="t">Who cares about that, some of you will say.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=98" target="_blank">00:01:38.300</a></span> | <span class="t">What about physics and spatial reasoning?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=100" target="_blank">00:01:40.260</a></span> | <span class="t">Well, here is a brand new benchmark from less than 72 hours ago, and we can compare those</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=106" target="_blank">00:01:46.200</a></span> | <span class="t">top two contenders.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=107" target="_blank">00:01:47.040</a></span> | <span class="t">We have Gemini 2.5 Pro in the lead, followed by O3 High.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=111" target="_blank">00:01:51.880</a></span> | <span class="t">And bear in mind that Gemini 2.5 Pro is four times cheaper than O3.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=117" target="_blank">00:01:57.320</a></span> | <span class="t">Notice though for reference that human expert accuracy on this benchmark still far exceeds</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=122" target="_blank">00:02:02.700</a></span> | <span class="t">the best model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=123" target="_blank">00:02:03.540</a></span> | <span class="t">Imagine you had to learn about all sorts of realistic physical interactions, predominantly</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=127" target="_blank">00:02:07.960</a></span> | <span class="t">through reading text, not experiencing the world.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=131" target="_blank">00:02:11.040</a></span> | <span class="t">You would probably have the same problems.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=133" target="_blank">00:02:13.900</a></span> | <span class="t">And honestly, this explains much of the discrepancy between the top two models and the human baseline</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=139" target="_blank">00:02:19.960</a></span> | <span class="t">on my own benchmark, Simple Bench.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=141" target="_blank">00:02:21.740</a></span> | <span class="t">Those two models are starting to see through all the tricks on my benchmark, but they're still</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=145" target="_blank">00:02:25.440</a></span> | <span class="t">failing quite badly on spatial reasoning.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=147" target="_blank">00:02:27.680</a></span> | <span class="t">This isn't a question from Simple Bench or the physics benchmark, but it illustrates</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=151" target="_blank">00:02:31.200</a></span> | <span class="t">the point that if, for example, you put your right palm on your left shoulder and then loop</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=156" target="_blank">00:02:36.020</a></span> | <span class="t">your left arm through the gap between your right arm and your chest, well, you're probably</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=161" target="_blank">00:02:41.280</a></span> | <span class="t">following, but models have no idea what's going on.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=164" target="_blank">00:02:44.080</a></span> | <span class="t">It's not in their training data and they can't really visualize what's happening.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=167" target="_blank">00:02:47.140</a></span> | <span class="t">I will come back to this example later though, because soon with tools, I could see them</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=171" target="_blank">00:02:51.640</a></span> | <span class="t">getting this question right.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=172" target="_blank">00:02:52.680</a></span> | <span class="t">Speaking of getting questions right, we learned that O3 beats out Gemini 2.5 Pro on a test</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=178" target="_blank">00:02:58.300</a></span> | <span class="t">of troubleshooting complex virology lab protocols.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=182" target="_blank">00:03:02.060</a></span> | <span class="t">O3, you will be glad to know, gets a 94th percentile score.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=187" target="_blank">00:03:07.160</a></span> | <span class="t">This is, of course, a text-based exam and isn't the same as actually conducting those protocols</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=191" target="_blank">00:03:11.680</a></span> | <span class="t">in the lab.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=192" target="_blank">00:03:12.340</a></span> | <span class="t">You might notice I'm balancing things out because now for a benchmark in which Gemini 2.5 Pro</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=197" target="_blank">00:03:17.300</a></span> | <span class="t">exceeds the performance of O3, competition mathematics.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=201" target="_blank">00:03:21.000</a></span> | <span class="t">Now, you may have heard on the Grapevine, the O3 and O4 Mini actually got state-of-the-art</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=206" target="_blank">00:03:26.480</a></span> | <span class="t">scores on AIM 2025.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=208" target="_blank">00:03:28.400</a></span> | <span class="t">That is a high school maths competition.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=211" target="_blank">00:03:31.000</a></span> | <span class="t">Without tools, both models got around 90%, but with tools, they got over 99%.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=216" target="_blank">00:03:36.580</a></span> | <span class="t">What you may not know is that AIM is just one of the tests used to qualify for US AMO.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=223" target="_blank">00:03:43.000</a></span> | <span class="t">That is a significantly harder proof-based maths test.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=226" target="_blank">00:03:46.420</a></span> | <span class="t">Notice all of these are high school tests though, which is very different from professional</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=230" target="_blank">00:03:50.500</a></span> | <span class="t">mathematics.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=231" target="_blank">00:03:51.500</a></span> | <span class="t">Anyway, on the US AMO, you can see here that we have O3 on high settings, getting around</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=237" target="_blank">00:03:57.820</a></span> | <span class="t">22% right compared to 24% for Gemini 2.5.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=242" target="_blank">00:04:02.060</a></span> | <span class="t">Again, four times cheaper for Gemini.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=244" target="_blank">00:04:04.160</a></span> | <span class="t">What's perhaps more interesting is that the US AMO is only a qualifier for the hardest high</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=250" target="_blank">00:04:10.440</a></span> | <span class="t">school math competition.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=251" target="_blank">00:04:11.400</a></span> | <span class="t">That's the International Math Olympiad.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=253" target="_blank">00:04:13.400</a></span> | <span class="t">And Google has a system, alpha proof, that got a silver medal in that competition.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=259" target="_blank">00:04:19.880</a></span> | <span class="t">Now, I've done other videos on alpha proof, but I would predict that in this year's competition</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=264" target="_blank">00:04:24.960</a></span> | <span class="t">in July, I suspect Google might get gold.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=268" target="_blank">00:04:28.000</a></span> | <span class="t">Back to some more down-to-earth domains though.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=270" target="_blank">00:04:30.520</a></span> | <span class="t">What about simple visual challenges like this one?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=273" target="_blank">00:04:33.080</a></span> | <span class="t">Given an image, can the model answer, is the squirrel climbing up the fence?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=277" target="_blank">00:04:37.500</a></span> | <span class="t">Or is the squirrel climbing down the fence with these two images?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=280" target="_blank">00:04:40.560</a></span> | <span class="t">Are these two dogs significantly different in size, as another question.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=284" target="_blank">00:04:44.460</a></span> | <span class="t">This benchmark is called Natural Bench.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=287" target="_blank">00:04:47.080</a></span> | <span class="t">And you probably guessed, because I'm alternating in performance, O3 actually scores better than</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=292" target="_blank">00:04:52.380</a></span> | <span class="t">Gemini 2.5.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=293" target="_blank">00:04:53.560</a></span> | <span class="t">Both, of course, still well behind human performance.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=296" target="_blank">00:04:56.980</a></span> | <span class="t">Despite that first impression, it's actually Gemini 2.5 Pro that scores better at geoguessing,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=302" target="_blank">00:05:02.560</a></span> | <span class="t">being given a random street view and knowing which country and location within that country</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=308" target="_blank">00:05:08.120</a></span> | <span class="t">you're looking at.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=309" target="_blank">00:05:09.120</a></span> | <span class="t">In fact, the difference is quite stark, with 2.5 Pro way exceeding O3 High.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=314" target="_blank">00:05:14.240</a></span> | <span class="t">Now I think of it, probably not too surprising given Google's ownership of Google Maps, Google</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=318" target="_blank">00:05:18.400</a></span> | <span class="t">Earth, and of course, YouTube.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=319" target="_blank">00:05:19.920</a></span> | <span class="t">And Waymo.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=320" target="_blank">00:05:20.920</a></span> | <span class="t">Last benchmark, I promise, but how about visual puzzles?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=324" target="_blank">00:05:24.360</a></span> | <span class="t">Which kite has the longest string?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=327" target="_blank">00:05:27.080</a></span> | <span class="t">Here the answer is C.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=328" target="_blank">00:05:28.840</a></span> | <span class="t">And overall, on the visual puzzles benchmark, we have Gemini 2.5 Pro even underperforming</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=334" target="_blank">00:05:34.680</a></span> | <span class="t">O1, let alone O3.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=336" target="_blank">00:05:36.580</a></span> | <span class="t">Both, of course, still well behind the average human, let alone an expert human.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=341" target="_blank">00:05:41.900</a></span> | <span class="t">Now allow me, if you will, 30 more seconds before we get to the question of money, because</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=346" target="_blank">00:05:46.060</a></span> | <span class="t">OpenAI basically gave away the VSTAR method they use to improve so much in vision.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=352" target="_blank">00:05:52.120</a></span> | <span class="t">You may have noticed how O3 seems to zoom in to answer a question, but what's the executive</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=357" target="_blank">00:05:57.280</a></span> | <span class="t">summary of VSTAR?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=358" target="_blank">00:05:58.600</a></span> | <span class="t">Essentially, the model gets overwhelmed by a high-resolution image.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=362" target="_blank">00:06:02.600</a></span> | <span class="t">So what the method does is it uses a multimodal LM to guess at what part of the image is going</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=369" target="_blank">00:06:09.640</a></span> | <span class="t">to be most relevant to the question.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=371" target="_blank">00:06:11.320</a></span> | <span class="t">That part of the image is then cropped, added to the visual working memory, the context of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=376" target="_blank">00:06:16.360</a></span> | <span class="t">the model, along with the original image, and submitted with the question.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=380" target="_blank">00:06:20.040</a></span> | <span class="t">You can see that in action when I gave O3 this "Where's Wally?" or Americans say "Where's Waldo?" image.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=385" target="_blank">00:06:25.960</a></span> | <span class="t">The language model speculates that Waldo tends to show up in places like a top vantage point or a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=391" target="_blank">00:06:31.320</a></span> | <span class="t">walkway. So it decides to crop that area. Now I will say, in keeping with the other benchmarks we saw,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=397" target="_blank">00:06:37.000</a></span> | <span class="t">it wasn't actually able to find Waldo, and I was, although it took me about three minutes, I'll be</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=402" target="_blank">00:06:42.120</a></span> | <span class="t">honest. Okay, those are the state-of-the-art models in AI. But where is this all heading? Well, to $174</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=408" target="_blank">00:06:48.280</a></span> | <span class="t">billion of revenue for OpenAI in 2030, according to themselves. In a moment, I'll touch on what that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=414" target="_blank">00:06:54.760</a></span> | <span class="t">means for you in terms of price, but actually on that prediction seems pretty reasonable to me.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=419" target="_blank">00:06:59.480</a></span> | <span class="t">Even though in 2024 they made just $4 billion, I could see that growing extremely rapidly. I would</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=424" target="_blank">00:07:04.760</a></span> | <span class="t">note though, that even with the biggest figures being far less than 1% of the value of white-collar</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=430" target="_blank">00:07:10.600</a></span> | <span class="t">labor globally, someone would have to be spectacularly wrong. Either as I suspect we won't get a country of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=437" target="_blank">00:07:17.400</a></span> | <span class="t">geniuses in a data center in 2026-2027, or these figures are spectacular underestimates. Here then</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=445" target="_blank">00:07:25.000</a></span> | <span class="t">are some of my very summarized thoughts about why I think AI is becoming, maybe has already become,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=451" target="_blank">00:07:31.160</a></span> | <span class="t">pay to win. Or another way of putting that, why me or you might have to pay more and more and more to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=456" target="_blank">00:07:36.280</a></span> | <span class="t">stay at the cutting edge of AI. We got news just the other day that Google is planning their own</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=461" target="_blank">00:07:41.240</a></span> | <span class="t">premium plus and premium pro tiers. Probably on the order of $100, $200 a month,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=466" target="_blank">00:07:46.840</a></span> | <span class="t">just like OpenAI and very recently Anthropic as well. Now think about it, if AGI or Superintelligence</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=472" target="_blank">00:07:52.760</a></span> | <span class="t">was quote, one simple trick away, one algorithmic tweak or a quick little scale up of RL, well then</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=479" target="_blank">00:07:59.160</a></span> | <span class="t">these companies incentives would be to get that AGI out as soon as possible to everyone, safety</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=485" target="_blank">00:08:05.080</a></span> | <span class="t">permitting. Capture market share as they all tend to want to do, gain monopolies, and then further down</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=490" target="_blank">00:08:10.680</a></span> | <span class="t">the road charge for access to that AGI. If on the other hand performance can be bought through sheer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=496" target="_blank">00:08:16.280</a></span> | <span class="t">scaling up of compute, then someone is going to have to pay for that compute, namely you. Yes,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=501" target="_blank">00:08:21.960</a></span> | <span class="t">we've had some quick gains going from 01 to 03 and even 04 mini, but as the CEO of Anthropic said,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=508" target="_blank">00:08:28.200</a></span> | <span class="t">that post-training or reasoning through reinforcement learning is soon going to be at the cost of billions</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=513" target="_blank">00:08:33.720</a></span> | <span class="t">and billions of dollars. And nor is post-training magic. It can't actually create reasoning paths not</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=518" target="_blank">00:08:38.760</a></span> | <span class="t">found in the original base model. That's according to a very new paper out of Xinhua University. If you're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=524" target="_blank">00:08:44.120</a></span> | <span class="t">interested in my deep dive on that paper and the previous one you just saw, I've just put up a 20 minute</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=529" target="_blank">00:08:49.800</a></span> | <span class="t">on my Patreon. Thank you as ever to everyone who supports the channel via Patreon. Now as the former</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=534" target="_blank">00:08:54.840</a></span> | <span class="t">chief research officer at OpenAI said, that doesn't mean that there isn't lots of low-hanging fruit in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=539" target="_blank">00:08:59.880</a></span> | <span class="t">reasoning or post-training. But he nevertheless predicts that soon reasoning will quote "catch up" to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=545" target="_blank">00:09:05.800</a></span> | <span class="t">pre-training in the sense of providing log linear returns. As in you have to put 10 times the investment to get</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=551" target="_blank">00:09:11.320</a></span> | <span class="t">one increment more of progress. Also bear in mind that Sam Altman recently called OpenAI a product</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=556" target="_blank">00:09:16.840</a></span> | <span class="t">company as much as a model company. It's a little bit like they're kind of taking their eye off the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=561" target="_blank">00:09:21.800</a></span> | <span class="t">AGI ball and focusing more on dollar returned per compute spend. These companies only have so many GPUs</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=568" target="_blank">00:09:28.840</a></span> | <span class="t">and TPUs to go around. Every time researchers are tempted toward a bigger base model or more post-training,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=574" target="_blank">00:09:34.840</a></span> | <span class="t">Sam Altman has to judge that against rate limits for new users, new feature launches and latency. I know</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=580" target="_blank">00:09:40.920</a></span> | <span class="t">this research from Epoch AI was mainly focused on scaling up training runs or pre-training the base</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=587" target="_blank">00:09:47.000</a></span> | <span class="t">models, but very broadly speaking it predicted by 2030 having say a hundred thousand times the effective</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=593" target="_blank">00:09:53.800</a></span> | <span class="t">compute as was used in 2022 for the training of GPT-4. Even if hypothetically by 2030 we had five orders</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=602" target="_blank">00:10:02.200</a></span> | <span class="t">of magnitude more compute than we have say today, think of all the competing demands on that compute</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=607" target="_blank">00:10:07.560</a></span> | <span class="t">OpenAI would have if they're to achieve a hundred and seventy four billion dollars of revenue. Their models</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=612" target="_blank">00:10:12.680</a></span> | <span class="t">by parameter count might be a thousand times bigger on average by then as compared to now. Most free users</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=619" target="_blank">00:10:19.160</a></span> | <span class="t">until very recently were using around an eight billion parameter model GPT-40 mini. But even if free users</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=625" target="_blank">00:10:25.560</a></span> | <span class="t">are now getting used to models the size of GPT-40, GPT-4.5 is around 20 trillion parameters. Some say</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=631" target="_blank">00:10:31.880</a></span> | <span class="t">12 trillion but either way roughly two orders of magnitude more than GPT-40. Of course by then</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=636" target="_blank">00:10:36.760</a></span> | <span class="t">power users like me won't be using GPT-4.5 but probably GPT-5 or 6, 10 or 100 times bigger. Then</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=643" target="_blank">00:10:43.720</a></span> | <span class="t">there's the user base and even though OpenAI are serving 600 million monthly active users, by five</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=650" target="_blank">00:10:50.040</a></span> | <span class="t">years from now there might be six billion smartphone users. Google with Gemini recently quadrupled its</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=655" target="_blank">00:10:55.240</a></span> | <span class="t">user base in just a few months up to 350 million monthly active users. But that could easily 2x, 3x, 4x.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=662" target="_blank">00:11:02.040</a></span> | <span class="t">That takes compute and this is all before we get to models thinking for longer. Then there's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=666" target="_blank">00:11:06.440</a></span> | <span class="t">latency. Deep research is amazing but it takes an average of say five to ten minutes. You can imagine</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=671" target="_blank">00:11:11.640</a></span> | <span class="t">spending an order of magnitude more compute to bring that down to say five seconds. Also don't forget</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=676" target="_blank">00:11:16.680</a></span> | <span class="t">there's usage per user. In this 2027 or 2030 scenario of AGI everyone is of course going to be using these</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=684" target="_blank">00:11:24.280</a></span> | <span class="t">chatbots way more than they are now. That's another 10x and that's all before we get to things like text to image,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=690" target="_blank">00:11:30.440</a></span> | <span class="t">text to video with Sora. All of which is a long way of saying that I could imagine 12 orders of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=695" target="_blank">00:11:35.000</a></span> | <span class="t">magnitude of effective compute being utilized by companies like OpenAI. That includes things like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=700" target="_blank">00:11:40.120</a></span> | <span class="t">not just more chips but more efficient chips and better algorithms. Five orders of magnitude by 2030</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=705" target="_blank">00:11:45.640</a></span> | <span class="t">wouldn't be nearly enough. If you notice none of that actually precludes there being a proto-AGI in the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=712" target="_blank">00:11:52.440</a></span> | <span class="t">coming few years. Albeit a very expensive one. Here's what a senior staff member at OpenAI said</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=718" target="_blank">00:11:58.040</a></span> | <span class="t">just a few days ago. OpenAI, he said, has defined AGI as "a highly autonomous system that can outperform</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=724" target="_blank">00:12:04.840</a></span> | <span class="t">humans at most economically valuable work. We definitely aren't there yet, far from it." You might have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=730" target="_blank">00:12:10.440</a></span> | <span class="t">deduced the same with some of the benchmarks earlier in this video. But he goes on, "The AGI vibes are very real</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=736" target="_blank">00:12:16.920</a></span> | <span class="t">to me." Especially the way that O3 dynamically uses tools as part of its chain of thought. Again he says</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=742" target="_blank">00:12:22.680</a></span> | <span class="t">that does not mean we've achieved AGI now. In fact it's a hill that he would die on that we have in fact</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=748" target="_blank">00:12:28.840</a></span> | <span class="t">not. He ends though, and I agree with this, that things will go slow until they go fast, really fast.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=754" target="_blank">00:12:34.840</a></span> | <span class="t">Things feel fast today, but I think we're actually still accelerating, and we will actually start to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=759" target="_blank">00:12:39.880</a></span> | <span class="t">go even faster. If you're willing to spend the money, Francois Chalet, a famous AI researcher said,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=764" target="_blank">00:12:44.760</a></span> | <span class="t">going from cents per query up to tens of thousands of dollars per query, you can go from zero fluid</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=770" target="_blank">00:12:50.440</a></span> | <span class="t">intelligence to near human level fluid intelligence. After all, we're getting things like Anthropic's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=775" target="_blank">00:12:55.240</a></span> | <span class="t">Model Context Protocol, where models now have a shared language to call tools of all types. And we know</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=781" target="_blank">00:13:01.320</a></span> | <span class="t">that tool calling was part of the reinforcement learning training of O3. So how long is it before</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=787" target="_blank">00:13:07.000</a></span> | <span class="t">O3, which arguably fails on anatomy questions like this, can call on open source software like OpenSim,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=793" target="_blank">00:13:13.960</a></span> | <span class="t">and run a simulation. Enter the relevant parameters and run the code like they do with Code Interpreter,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=799" target="_blank">00:13:19.080</a></span> | <span class="t">watching the resultant simulation. Soon almost any software could be sucked into the orbit of these</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=804" target="_blank">00:13:24.600</a></span> | <span class="t">models training regimes. Now I will grant you that presents all sorts of security problems that will</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=810" target="_blank">00:13:30.440</a></span> | <span class="t">have to be solved first. Which is why I'm going to introduce you to the sponsors of this video,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=814" target="_blank">00:13:34.760</a></span> | <span class="t">Grace One. And you may be able to see out of the corner of your eye, a $60,000 competition that's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=821" target="_blank">00:13:41.560</a></span> | <span class="t">in progress, wherein you, you don't even have to be a professional researcher, can try to use image</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=826" target="_blank">00:13:46.840</a></span> | <span class="t">inputs to jailbreak leading vision enabled AI models. I think it's pretty insane that you can be paid to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=832" target="_blank">00:13:52.840</a></span> | <span class="t">exploit these vulnerabilities, and yet at the same time be boosting AI safety and security. These are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=838" target="_blank">00:13:58.760</a></span> | <span class="t">incredibly legit competitions with public leaderboards monitored by OpenAI, Anthropic,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=843" target="_blank">00:14:03.400</a></span> | <span class="t">and Google DeepMind. So wouldn't it be pretty epic if the winners of this competition turned out to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=847" target="_blank">00:14:07.800</a></span> | <span class="t">have used my unique link, which you can find in the description. I will completely take full credit for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=853" target="_blank">00:14:13.160</a></span> | <span class="t">your win and bask in the resultant glory. Of course, feel free to weigh in in the comments what you think</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=859" target="_blank">00:14:19.080</a></span> | <span class="t">about the new story that's currently going viral online. No doubt it's crazy times we live in,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=864" target="_blank">00:14:24.760</a></span> | <span class="t">but thank you guys so much for watching to the end. I will never not be grateful for your viewership,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rArxtyb-Mio&t=871" target="_blank">00:14:31.240</a></span> | <span class="t">so have an absolutely wonderful day.</span></div></div></body></html>