<html><head><title>Surfacing Semantic Orthogonality Across Model Safety Benchmarks — Jonathan Bennion</title>
<style>
    body {
        font-family: Arial, sans-serif;
        margin: 0;
        padding: 0;
        background-color: #f4f4f4;
        color: #333;
    }
    .container {
        width: 95%;  /* Increased width to use more space */
        margin: auto;
        overflow: auto;  /* Added to handle overflow by adding a scrollbar if necessary */
    }
    h2, h3 {
        color: #333;
        text-align: center;
    }
    a {
        color: #0000FF;  /* Traditional blue color for links */
        text-decoration: none;
    }
    a:hover {
        text-decoration: underline;
    }
    img {
        display: block;
        margin: auto;
        max-width: 100%;
    }
    .c {
        margin: 10px 0;
    }
    .s, .t {
        display: inline-block;
        margin-right: 5px;
    }
    .max-width {
        max-width: 800px;
        margin: auto;
        padding-left: 20px;
    }
    table {
        width: 100%;
        border-collapse: collapse;
    }
    th, td {
        border: 1px solid #ddd;
        padding: 8px;
        text-align: left;  /* Ensure text alignment is consistent */
    }
    tr:nth-child(even) {
        background-color: #f2f2f2;
    }
    tr:nth-child(odd) {
        background-color: #e6e6e6;
    }
</style>

    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-69VLBMTTP0"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-69VLBMTTP0');
    </script>
    </head><body><div class='container'><a href="index.html">back to index</a><h2>Surfacing Semantic Orthogonality Across Model Safety Benchmarks — Jonathan Bennion</h2><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg"><img src="https://i.ytimg.com/vi_webp/jqyWZ19d1hg/maxresdefault.webp" style="width:50%;"></a><div><br></div><div style="text-align: left;"><a href="./jqyWZ19d1hg.html">Whisper Transcript</a> | <a href="./transcript_jqyWZ19d1hg.html">Transcript Only Page</a></div><br><div style="max-width: 800px;"><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=0" target="_blank">00:00:00.240</a></span> | <span class="t">Thank you for the introduction and thanks to the International Advanced Natural Language</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=3" target="_blank">00:00:03.920</a></span> | <span class="t">Processing Conference for organizing this. And thanks as well for allowing this talk to start</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=9" target="_blank">00:00:09.600</a></span> | <span class="t">and kick off the conference. I appreciate it. You guys have done a great job. In terms of the topic,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=17" target="_blank">00:00:17.680</a></span> | <span class="t">I do have to make sure that we understand the contextual background behind this topic</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=26" target="_blank">00:00:26.400</a></span> | <span class="t">today in recent events over the last few weeks and months. So I'm going to take a few minutes before</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=31" target="_blank">00:00:31.840</a></span> | <span class="t">getting into the paper to make sure that for those of you that are outside of the bounds of not only</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=39" target="_blank">00:00:39.360</a></span> | <span class="t">just NLP but also maybe working on NLP in another industry or aspect, I think it's important that we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=47" target="_blank">00:00:47.280</a></span> | <span class="t">know what this paper is discussing. And so first of all, the papers about AI safety benchmarks and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=58" target="_blank">00:00:58.400</a></span> | <span class="t">artificial intelligence, I'm assuming people listening and watching are familiar with AI safety.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=67" target="_blank">00:01:07.680</a></span> | <span class="t">I assume people are also relatively familiar with in terms of what they've read, although there's many</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=73" target="_blank">00:01:13.040</a></span> | <span class="t">different meanings for that. Benchmarks, I'm not sure if people are incredibly familiar with benchmarks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=79" target="_blank">00:01:19.360</a></span> | <span class="t">But what benchmarks are, they're question and answer data sets, prompts and response data sets that are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=85" target="_blank">00:01:25.600</a></span> | <span class="t">used to -- there's a few other formats as well -- but that are used to measure LLMs. They've been controversial</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=92" target="_blank">00:01:32.080</a></span> | <span class="t">in the past because of their incomplete nature and a lot of the shortcomings that they have in measuring</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=98" target="_blank">00:01:38.800</a></span> | <span class="t">everything that people expect when we measure LLMs. So there's a hype versus reality for each of these</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=107" target="_blank">00:01:47.600</a></span> | <span class="t">terms in this topic. And I want to make sure that we understand the hype versus reality for each of these</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=115" target="_blank">00:01:55.040</a></span> | <span class="t">terms so that way we can understand what the topic is, and then I'll be getting into the paper.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=123" target="_blank">00:02:03.040</a></span> | <span class="t">So artificial intelligence, the hype, has reached fever pitch. This was last month where the former</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=133" target="_blank">00:02:13.920</a></span> | <span class="t">Google CEO was warning that AI is about to explode and take over humans, when in reality it was announced</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=142" target="_blank">00:02:22.160</a></span> | <span class="t">as well this week that Meta is delaying the rollout of its flagship AI model. There's a lot of issues. If you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=147" target="_blank">00:02:27.840</a></span> | <span class="t">see the bottom paragraph here, there's a lot of companies that are having a hard time getting past</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=153" target="_blank">00:02:33.120</a></span> | <span class="t">the advances from Transformers. This is something that a lot of developers have known about for the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=158" target="_blank">00:02:38.160</a></span> | <span class="t">last few years. But this is the reality versus the hype. In terms of AI safety, again, there's many different</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=165" target="_blank">00:02:45.440</a></span> | <span class="t">definitions of AI safety. There's hype. This is one aspect of AI safety. If you think of AI as contributing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=173" target="_blank">00:02:53.120</a></span> | <span class="t">something good, will AI replace doctors? How could AI be bad if it can replace doctors and prevent</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=178" target="_blank">00:02:58.960</a></span> | <span class="t">some things? Can it add to more well-being feeling from psychologists? Well, there's reality there</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=189" target="_blank">00:03:09.760</a></span> | <span class="t">in that obviously, as a lot of us have read about over the last few years, AI doctors are all over social</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=196" target="_blank">00:03:16.560</a></span> | <span class="t">media spreading fake claims, and it gets worse and worse. And there's a lot of efforts to prevent what's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=203" target="_blank">00:03:23.280</a></span> | <span class="t">happening as a result of artificial intelligence, which seems to be where a lot of the harms are in terms of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=211" target="_blank">00:03:31.600</a></span> | <span class="t">the psychological effects of using AI, the psychological effects of AI being accessible to people. Benchmarks,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=220" target="_blank">00:03:40.240</a></span> | <span class="t">there's also a hype versus reality. As we know, we hear every model coming out, what the score might be</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=229" target="_blank">00:03:49.040</a></span> | <span class="t">in terms of some predominant benchmark that's best in class. For example, this is actually a little over a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=238" target="_blank">00:03:58.000</a></span> | <span class="t">month prior to now. Chris Cox at Meta talking about Llama 4 being great and releasing all these metrics.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=245" target="_blank">00:04:05.040</a></span> | <span class="t">Reality is this particular model that he's talking about was optimized. In other words, it was given the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=253" target="_blank">00:04:13.040</a></span> | <span class="t">answers to the tests. So if it's not straightforward, I think we're moving into a place where hype could be a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=263" target="_blank">00:04:23.360</a></span> | <span class="t">little more than it is now. And reality could be a little bit more severe in terms of contrast than it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=269" target="_blank">00:04:29.600</a></span> | <span class="t">is now. This paper is about reality. AI is going to be around for the time being. No matter where it is in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=280" target="_blank">00:04:40.720</a></span> | <span class="t">the hype cycle, it'll be visible or not visible, but there's no way to escape it. In terms of AI safety, there's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=288" target="_blank">00:04:48.320</a></span> | <span class="t">always going to be some harms that we want to prevent. In terms of benchmarks, there's always going to be a need to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=292" target="_blank">00:04:52.880</a></span> | <span class="t">measure. So this paper is about AI safety benchmarks. Again, it's introduced – thank you for introducing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=300" target="_blank">00:05:00.240</a></span> | <span class="t">me, but I want to thank my co-authors here. I'm Jonathan Bennion. Shona Ghosh from NVIDIA</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=307" target="_blank">00:05:07.840</a></span> | <span class="t">has – Nantik Singh and Nuha Dzeri have all contributed a lot of thoughts going into this paper that I think that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=319" target="_blank">00:05:19.360</a></span> | <span class="t">they should be recognized as well. So I'm excited to present. So in terms of choosing the benchmarks that we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=328" target="_blank">00:05:28.480</a></span> | <span class="t">analyzed, again, we're looking at AI safety benchmarks. No other paper, by the way, has looked at the semantic</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=336" target="_blank">00:05:36.720</a></span> | <span class="t">extent and area that's covered by AI safety benchmarks as far as we know. So how do we choose the benchmarks</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=348" target="_blank">00:05:48.720</a></span> | <span class="t">that we did choose to analyze? Basically, if we go back the last two years, we see between five and ten</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=358" target="_blank">00:05:58.880</a></span> | <span class="t">benchmarks actually released for open source research for AI safety. Again, each of these are reflecting</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=365" target="_blank">00:06:05.920</a></span> | <span class="t">some of the values that people have. Some of these are reflecting the actual use cases that it targets.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=376" target="_blank">00:06:16.320</a></span> | <span class="t">Some of these change over time. It really depends on the definition of harm. And so it's an exciting</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=384" target="_blank">00:06:24.080</a></span> | <span class="t">place to be in terms of measuring safety. But a lot of these datasets are also private. So we looked at</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=391" target="_blank">00:06:31.680</a></span> | <span class="t">the benchmarks that are open source and filtered it only to those that had enough rows for us to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=399" target="_blank">00:06:39.040</a></span> | <span class="t">measure in terms of sample size and not whittle everything down. Some of these benchmarks. There's two</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=406" target="_blank">00:06:46.480</a></span> | <span class="t">others that were considered for the paper, but they became too small after filtering out for first turn</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=415" target="_blank">00:06:55.360</a></span> | <span class="t">only, filter only first turn prompts. And then we also filtered on only the prompts that were flagged as</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=423" target="_blank">00:07:03.840</a></span> | <span class="t">harmful. Some flat, some prompts right now are flagged for not harmful because of the nature of how these</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=430" target="_blank">00:07:10.880</a></span> | <span class="t">are used to either, again, to these, these, these benchmarks are used to measure LLMs, LLM systems,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=436" target="_blank">00:07:16.320</a></span> | <span class="t">or fine tune a model on a behavior that, that you want, that's a little bit more desired and more aware</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=443" target="_blank">00:07:23.440</a></span> | <span class="t">of these, these, this ground truth that's defined here in these datasets for measuring harm. I want to get</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=450" target="_blank">00:07:30.400</a></span> | <span class="t">into the methodology. This is the bulk of the paper. Basically, we appended the benchmarks into one dataset</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=458" target="_blank">00:07:38.720</a></span> | <span class="t">for solid findings, had to clean the data by examining statistical sample size for, from each,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=465" target="_blank">00:07:45.600</a></span> | <span class="t">and then also had to clean the data by removing duplicates and taking out outliers when we look at</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=474" target="_blank">00:07:54.240</a></span> | <span class="t">outliers of the total dataset at that point. And the outliers actually in this case were prompt length,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=481" target="_blank">00:08:01.200</a></span> | <span class="t">which doesn't perfectly correlate to the embedding vectors, but we'll get into this in a second.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=487" target="_blank">00:08:07.760</a></span> | <span class="t">Steps three, four, and five here were iterative with variants to find the best and most optimized</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=496" target="_blank">00:08:16.800</a></span> | <span class="t">unsupervised learning clusters that were developed to, to, to, to, to figure out harms across all of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=503" target="_blank">00:08:23.200</a></span> | <span class="t">these datasets, or at least clusters of, of, of, of meaning, um, which are presumed to be harms.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=508" target="_blank">00:08:28.640</a></span> | <span class="t">So, uh, so after using an embedding model that was tested for, um, um, for best fit, we'll, we'll get</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=518" target="_blank">00:08:38.240</a></span> | <span class="t">into that in a second. Uh, there was, uh, a few different, uh, dimensionality reduction techniques</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=524" target="_blank">00:08:44.880</a></span> | <span class="t">that, that we looked at. And then, uh, each of those had hyperparameters and values for those</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=529" target="_blank">00:08:49.200</a></span> | <span class="t">hyperparameters in grid search. And then, uh, there's multiple distance metrics that could always be,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=533" target="_blank">00:08:53.760</a></span> | <span class="t">be used, uh, in, in, in, in clustering. And so I'll get into that, uh, as well in this presentation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=539" target="_blank">00:08:59.280</a></span> | <span class="t">and just doing a quick time check because I'm gonna have to, uh, go through this. I, anyways,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=544" target="_blank">00:09:04.240</a></span> | <span class="t">so then, uh, with, um, uh, clusters, once the clusters were developed, uh, to an optimal, uh,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=551" target="_blank">00:09:11.280</a></span> | <span class="t">separation by silhouette score, uh, then we took the, uh, the prompt values that were at each centroid</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=558" target="_blank">00:09:18.320</a></span> | <span class="t">that were at each edge. There's four edges. And, uh, this is again, all according to past research</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=563" target="_blank">00:09:23.120</a></span> | <span class="t">that's done this in the past, but this has just never been done in this capacity. Uh, and so then, uh,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=569" target="_blank">00:09:29.680</a></span> | <span class="t">each of those prompts were then, uh, using, uh, inference to another LLM, multiple LLMs actually,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=576" target="_blank">00:09:36.320</a></span> | <span class="t">to corroborate and find the category labeling, labeling behind that, that centroid. And then,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=581" target="_blank">00:09:41.520</a></span> | <span class="t">uh, we ended up with, uh, what's gonna be on the next slide. We also identified more bias that,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=587" target="_blank">00:09:47.040</a></span> | <span class="t">that could be seeping into that process, but this is the result, uh, the clustered results by,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=592" target="_blank">00:09:52.960</a></span> | <span class="t">by benchmark. Uh, you can see each color here represents a benchmark that I was just talking about.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=597" target="_blank">00:09:57.440</a></span> | <span class="t">Each of these benchmark benchmarks might've over-indexed, uh, on a different area, but again,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=602" target="_blank">00:10:02.240</a></span> | <span class="t">this is using, uh, k-means clustering after you, we'll, we'll get into the, the process here and how</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=607" target="_blank">00:10:07.280</a></span> | <span class="t">I optimized, uh, by this is kind of an interesting method. Once everything is clustered in aggregate and,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=614" target="_blank">00:10:14.960</a></span> | <span class="t">and, and after everything is, uh, appended into one dataset, uh, to see where these benchmarks,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=622" target="_blank">00:10:22.320</a></span> | <span class="t">uh, over-index, you can see the, uh, each one of these dots here is a prompt. And, uh, the x and y</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=630" target="_blank">00:10:30.000</a></span> | <span class="t">axis here are just dimensions. When I say just dimensions, they're highly normalized from a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=634" target="_blank">00:10:34.160</a></span> | <span class="t">high dimensional space, but you can think of these as semantic space. Uh, the closer they are together,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=639" target="_blank">00:10:39.600</a></span> | <span class="t">the more, um, common they are, the further away, uh, the, the more breadth and, and semantic meaning and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=646" target="_blank">00:10:46.240</a></span> | <span class="t">coverage, uh, is, is, is, uh, uh, highlighted. So again, the, the point of this, this paper was to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=654" target="_blank">00:10:54.320</a></span> | <span class="t">show what's happened in the past, also show where people can research further and show, uh, what areas</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=660" target="_blank">00:11:00.240</a></span> | <span class="t">might, uh, have not had as much research as in terms of the breadth, uh, that, uh, they could have, um,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=666" target="_blank">00:11:06.640</a></span> | <span class="t">and, and this is a great means to evaluate as well, uh, because this shows you, uh, what is inside of,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=675" target="_blank">00:11:15.040</a></span> | <span class="t">of either, you know, an LLM benchmark or whatever you want to measure and, and it doesn't add those</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=680" target="_blank">00:11:20.080</a></span> | <span class="t">compounds of using blue and rouge scores. Um, again, the harm categories we, we found, uh, in this case,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=686" target="_blank">00:11:26.080</a></span> | <span class="t">controlled substances, suicide and self-harm, guns, illegal weapons, criminal planning, confessions,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=694" target="_blank">00:11:34.560</a></span> | <span class="t">hate, which actually included identity hate according to inference, and PII and privacy.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=701" target="_blank">00:11:41.280</a></span> | <span class="t">Um, so the bulk of the paper gets into variants that are used to optimize for the distance here in the,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=709" target="_blank">00:11:49.280</a></span> | <span class="t">in the clusters, and this process could be reused. It could be also, uh, refined, but the framework is,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=715" target="_blank">00:11:55.760</a></span> | <span class="t">is where the paper, um, I think, uh, has, has, has made advances in, in terms of what the framework</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=722" target="_blank">00:12:02.880</a></span> | <span class="t">could be to optimize for any benchmarks that are around a similar topic in semantic space.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=730" target="_blank">00:12:10.400</a></span> | <span class="t">So, um, just to clarify this, this slide, uh, used more than one embedding model, used more than</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=740" target="_blank">00:12:20.160</a></span> | <span class="t">one distance metric, used more than one means to have a dimensionality reduction, and then, uh,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=746" target="_blank">00:12:26.400</a></span> | <span class="t">optimized for hyperparameters that were found by past research to be, uh, the most impactful,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=751" target="_blank">00:12:31.440</a></span> | <span class="t">and then, uh, optimized for those values from those hyperparameters, which, you know, could have been a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=757" target="_blank">00:12:37.520</a></span> | <span class="t">lot of compute, and then, um, more, ideally more than one evaluation metric. You can see a reference to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=763" target="_blank">00:12:43.600</a></span> | <span class="t">BERT score at the bottom. Tried that. Uh, everything was ultimately optimized for silhouette score in order to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=771" target="_blank">00:12:51.280</a></span> | <span class="t">optimize for the, the, the, the distance and the separation of each, each cluster. But BERT score,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=777" target="_blank">00:12:57.200</a></span> | <span class="t">I thought, or the hypothesis was that BERT score would actually tell you in terms of tokens, uh, the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=785" target="_blank">00:13:05.440</a></span> | <span class="t">difference between one cluster and the next. BERT score, the, the results actually came back like 1.0 for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=790" target="_blank">00:13:10.000</a></span> | <span class="t">every cluster. And, uh, turns out BERT score is actually not the best metric to use because for, for,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=795" target="_blank">00:13:15.760</a></span> | <span class="t">for, uh, data sets that have the same topic or a similar topic, like AI safety,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=801" target="_blank">00:13:21.520</a></span> | <span class="t">or adversarial, uh, uh, data sets like, like, like, like AI safety data sets, um, where you fine tune a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=808" target="_blank">00:13:28.320</a></span> | <span class="t">model based on what not to do. Um, uh, BERT score didn't, didn't, didn't work here. And so that the,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=815" target="_blank">00:13:35.920</a></span> | <span class="t">the secondary metric used here was, uh, performance, performance time. So, so we optimized for the best</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=821" target="_blank">00:13:41.840</a></span> | <span class="t">silhouette score, and then of the best silhouette scores that were in the same confidence interval,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=826" target="_blank">00:13:46.960</a></span> | <span class="t">uh, we're able to find that the most performant, uh, in terms of performance to scale.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=831" target="_blank">00:13:51.120</a></span> | <span class="t">So, uh, sample size presumptions, um, this is, these are what went into the sample size calculation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=838" target="_blank">00:13:58.160</a></span> | <span class="t">Why are we doing this? Because the theory for, uh, why we want to do this is to, uh, query and look at</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=847" target="_blank">00:14:07.200</a></span> | <span class="t">the differences of, uh, over-indexing in a certain cluster from each benchmark. Um, you can see here,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=852" target="_blank">00:14:12.880</a></span> | <span class="t">I hope you can see my screen where, where I'm highlighting, the maximum clusters we had to assume was</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=856" target="_blank">00:14:16.640</a></span> | <span class="t">15. Um, obviously we didn't get 15, but going into it, uh, we had to presume that because the,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=863" target="_blank">00:14:23.920</a></span> | <span class="t">the most recent paper had a taxonomy listing, uh, between 12 and 13, adding 10 percent to that,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=869" target="_blank">00:14:29.520</a></span> | <span class="t">according to past research, because we, we would have had, uh, in theory, more, uh, clusters, um,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=875" target="_blank">00:14:35.760</a></span> | <span class="t">or at least more semantic space covered by looking at more than one dataset. So, um, we had to presume</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=881" target="_blank">00:14:41.520</a></span> | <span class="t">something, and so that was rationale to presume 15. Uh, significance level, because it was 15 clusters,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=888" target="_blank">00:14:48.160</a></span> | <span class="t">and we wanted to look at this by each benchmark, 15 split, you know, five split by 15. Uh, the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=895" target="_blank">00:14:55.200</a></span> | <span class="t">significance level, to be safe, dropped to 0.15. Um, and the effect size is large because, uh, according</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=904" target="_blank">00:15:04.800</a></span> | <span class="t">to past research, there's been, uh, a citation here in the paper that stated that it wouldn't matter</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=912" target="_blank">00:15:12.320</a></span> | <span class="t">the results that we'd find in terms of a benchmark having a slightly different, uh, over indexing for,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=917" target="_blank">00:15:17.680</a></span> | <span class="t">uh, each harm category. It wouldn't matter unless effect size is 0.5 at least. So I thought, okay,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=922" target="_blank">00:15:22.960</a></span> | <span class="t">that's fine. That's rationale to, to use a high effect size here. Um, um, didn't know what we'd get,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=928" target="_blank">00:15:28.960</a></span> | <span class="t">uh, because this, this was never really done in this capacity in terms of prompts. Uh, anyways,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=936" target="_blank">00:15:36.080</a></span> | <span class="t">with this calculation, uh, ended up with a minimum required sample size per benchmark of 1,635,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=942" target="_blank">00:15:42.400</a></span> | <span class="t">and with a total sample size across all benchmarks of 8,175. Uh, outlier removal, uh, did this again</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=950" target="_blank">00:15:50.080</a></span> | <span class="t">for the whole entire dataset, uh, used compared IQR method and z-score method. Uh, counterintuitively,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=955" target="_blank">00:15:55.760</a></span> | <span class="t">the z-score method actually, uh, was looser and allowed for actually more prompts here, uh,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=961" target="_blank">00:16:01.040</a></span> | <span class="t">that, you know, could be considered an outlier if we're using our IQR method. What was interesting</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=965" target="_blank">00:16:05.920</a></span> | <span class="t">was because this is so right skewed, uh, this is not a normal distribution. This is extremely right skewed,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=972" target="_blank">00:16:12.000</a></span> | <span class="t">uh, in terms of prompt length. Uh, the z-score actually looked at the standard deviation as it does</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=980" target="_blank">00:16:20.000</a></span> | <span class="t">and removed less because the standard deviation was so large here. So not only are there long</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=985" target="_blank">00:16:25.440</a></span> | <span class="t">prompts, there's just a lot of standard deviation amongst those long, long prompts, which was great</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=990" target="_blank">00:16:30.640</a></span> | <span class="t">because the, these prompts here turned out to be, uh, relatively valuable and showing up in, in a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=996" target="_blank">00:16:36.080</a></span> | <span class="t">semantic space that, that it was kind of of its own. So that said, um, this, this, this worked, uh, in terms</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=1002" target="_blank">00:16:42.960</a></span> | <span class="t">of the, the result, uh, still right skewed, but, uh, better if you, especially with the magnitude, uh, down</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=1009" target="_blank">00:16:49.680</a></span> | <span class="t">there, uh, uh, quite a bit better, uh, but still right skewed, uh, there's gonna be the next three</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=1017" target="_blank">00:16:57.040</a></span> | <span class="t">slides. I'm gonna talk about the variance and then I'm gonna talk about the results. Um, so the variance,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=1023" target="_blank">00:17:03.520</a></span> | <span class="t">uh, again, that I iterated through, uh, the, um, embedding models, uh, there had to be some rationale</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=1031" target="_blank">00:17:11.840</a></span> | <span class="t">there, uh, in terms of what embedding model to use. Uh, mini LM is something that we, uh, started using</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=1039" target="_blank">00:17:19.680</a></span> | <span class="t">because of its scalability. Uh, it produces high quality embedding values for each, each prompt.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=1045" target="_blank">00:17:25.920</a></span> | <span class="t">For those of you that are unfamiliar, um, it's, uh, it'll just take a prompt and assign a semantic,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=1052" target="_blank">00:17:32.240</a></span> | <span class="t">uh, vectorized, very high dimensional, uh, value. It's a mini, mini LM, not only does a high quality</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=1060" target="_blank">00:17:40.000</a></span> | <span class="t">embedding value, but also, uh, performs some reduction of, of, of dimensions. And I'll get</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=1065" target="_blank">00:17:45.600</a></span> | <span class="t">into why we even go, go through the, the hassle of, uh, reducing, uh, dimensionality on the next,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=1071" target="_blank">00:17:51.360</a></span> | <span class="t">the next step. But then there's also an efficient memory usage. It's, it's really small and it's,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=1075" target="_blank">00:17:55.440</a></span> | <span class="t">it's, uh, been used in a lot of research, uh, especially of the same kind for, for looking at prompts</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=1080" target="_blank">00:18:00.080</a></span> | <span class="t">and semantic space. MP net gets into using more memory. It excels at contextual and sequential</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=1085" target="_blank">00:18:05.600</a></span> | <span class="t">encoding, uh, higher memory usage. So it's the next step up, even though they're both small and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=1090" target="_blank">00:18:10.480</a></span> | <span class="t">comparable. I wanted to see the direction it would go. Um, both are 512 tokens. This isn't on the paper,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=1096" target="_blank">00:18:16.240</a></span> | <span class="t">so I added a note down below just to clarify for those of you listening, um, that, uh, there's,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=1101" target="_blank">00:18:21.920</a></span> | <span class="t">there's memory differences and they're relatively substantial. It's one difference. So we wanted to see</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=1107" target="_blank">00:18:27.680</a></span> | <span class="t">if there was a difference at all and, and using these, um, embedding models as they became more</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=1112" target="_blank">00:18:32.480</a></span> | <span class="t">sophisticated, um, for reducing dimensionality further, which is important to do with, uh, there's,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=1120" target="_blank">00:18:40.560</a></span> | <span class="t">there's some research that suggests, um, even though we lose more information, uh, we still, uh, in order</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=1128" target="_blank">00:18:48.320</a></span> | <span class="t">to cluster, uh, need something here, uh, to allow us to have manageable values that we're clustering on.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=1137" target="_blank">00:18:57.040</a></span> | <span class="t">So TSNE, uh, preserves local structure but struggles with global relationships that actually, in this case,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=1144" target="_blank">00:19:04.080</a></span> | <span class="t">could be useful. UMAP, uh, preserves both local and global structure while scaling efficiently. Different</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=1151" target="_blank">00:19:11.600</a></span> | <span class="t">hyperparameters for each. Uh, for TSNE, we had to draw on past research, um, so prioritize perplexity and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=1159" target="_blank">00:19:19.520</a></span> | <span class="t">learning rate. For UMAP, uh, again, had to draw upon past research that was most impactful for, for a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=1164" target="_blank">00:19:24.640</a></span> | <span class="t">similar use case and looked at n-neighbors and, and min-dist. The, uh, Euclidean distance is something that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=1171" target="_blank">00:19:31.360</a></span> | <span class="t">is kind of a common, uh, default to use. Uh, works well in low dimensional spaces, doesn't work well when you get into</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=1179" target="_blank">00:19:39.120</a></span> | <span class="t">high dimensions, uh, because the differences are, are, are too profound. Um, so Mahalanobis is something</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=1186" target="_blank">00:19:46.320</a></span> | <span class="t">else that we looked at to compare. It incorporates an, an inverse, uh, covariance matrix, uh, to account for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=1194" target="_blank">00:19:54.000</a></span> | <span class="t">dimensional correlations. And I was really excited about the Mahalanobis distance. The research in the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=1202" target="_blank">00:20:02.000</a></span> | <span class="t">past suggests that it could be one of the best metrics to look at because it accounts for dimensional</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=1206" target="_blank">00:20:06.400</a></span> | <span class="t">correlations, which you would presume would be extremely interesting. Um, it didn't, uh, in the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=1212" target="_blank">00:20:12.560</a></span> | <span class="t">results, we're looking at the top eight out of 16 different combinations here. Uh, there's 16. You think</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=1217" target="_blank">00:20:17.760</a></span> | <span class="t">there might have been more, but, uh, the, uh, for grid search, I had to, uh, whittle, uh, some of the values</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=1225" target="_blank">00:20:25.440</a></span> | <span class="t">down in order to, uh, uh, have this performance. And, uh, if you look at the top eight of the, the cluster optimization results,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=1233" target="_blank">00:20:33.680</a></span> | <span class="t">again, by, uh, silhouette score, you can see that there's some overlap visually in the confidence interval.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=1238" target="_blank">00:20:38.880</a></span> | <span class="t">And among that overlap, you see the second one from the top, um, mini LM, Euclidean, uh, UMAP, uh, uh,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=1247" target="_blank">00:20:47.520</a></span> | <span class="t">the end of the 30 min dist is 0.1. So, um, this is also, you could look at the efficiency, which is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=1255" target="_blank">00:20:55.280</a></span> | <span class="t">normal and normalized, uh, in terms of, uh, seconds in terms of time processing time. And this makes more</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=1261" target="_blank">00:21:01.360</a></span> | <span class="t">sense to scale. If everything's in the same comfort or within the same confidence range. Um, so, uh, number</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=1268" target="_blank">00:21:08.160</a></span> | <span class="t">of clustered clusters was reviewed for diligence, um, because that was important because also counterintuitive,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=1275" target="_blank">00:21:15.600</a></span> | <span class="t">we expected more because the taxonomies were getting large. There's a lot more semantic space,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=1281" target="_blank">00:21:21.040</a></span> | <span class="t">a lot more harms that were covered. It was counterintuitive to get, uh, six.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=1284" target="_blank">00:21:24.880</a></span> | <span class="t">Uh, elbow method actually suggests between five and six. Silhouette analysis suggested six. Uh, there's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=1293" target="_blank">00:21:33.840</a></span> | <span class="t">research that suggests that if you're between two values to use the one that makes the most sense to you.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=1298" target="_blank">00:21:38.560</a></span> | <span class="t">So we use six. Um, this influenced prompt values and centroids, um, excuse me, the, the inference, uh,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=1306" target="_blank">00:21:46.640</a></span> | <span class="t">uh, that, that we gave to the, the, the prompt values, uh, at the centroids, uh, were influenced by,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=1314" target="_blank">00:21:54.000</a></span> | <span class="t">um, LLMs, but they didn't, there was not much variance here at all. Uh, there might have been a plural</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=1319" target="_blank">00:21:59.040</a></span> | <span class="t">word, uh, versus a singular word if you move across, uh, model families and into the next model family for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=1325" target="_blank">00:22:05.920</a></span> | <span class="t">inference. So this is, these are the, the, uh, the, the clusters that developed from, from these</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=1330" target="_blank">00:22:10.560</a></span> | <span class="t">benchmarks and insights here, I'm getting down to the end of this, uh, talk and then I'm going to be</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=1336" target="_blank">00:22:16.560</a></span> | <span class="t">opening up for questions, but I want to emphasize, uh, the insights and then what we learned here in the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=1341" target="_blank">00:22:21.120</a></span> | <span class="t">insights, if you know, the sparsity and variant breadth, like I, uh, mentioned before, um, the hate and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=1347" target="_blank">00:22:27.120</a></span> | <span class="t">identity hate category, it's very focused, uh, it could be more, more, but then actually there's a,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=1353" target="_blank">00:22:33.360</a></span> | <span class="t">there's a, a tangent there on, uh, uh, the inability for, uh, LLMs to capture hate speech right now,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=1362" target="_blank">00:22:42.240</a></span> | <span class="t">currently, uh, and that's a criticism of a lot of, uh, AI tools, uh, it should be better, right? Well,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=1368" target="_blank">00:22:48.480</a></span> | <span class="t">this is because we don't have as much ground truth and this, this, this highlights that. Also, uh, there is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=1373" target="_blank">00:22:53.840</a></span> | <span class="t">anthropomorphism that is happening quite often and a lot of other harms that are happening</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=1378" target="_blank">00:22:58.400</a></span> | <span class="t">psychologically to people using AI that, that are not, uh, evident here. Um, it's not that they're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=1384" target="_blank">00:23:04.000</a></span> | <span class="t">debated, they're, they're, they're harms, they're just not, not explored. So this allows you to pivot</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=1390" target="_blank">00:23:10.080</a></span> | <span class="t">and go, okay, these are harms that we looked at in the past. What else can we look at in order to,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=1394" target="_blank">00:23:14.320</a></span> | <span class="t">I don't want to be fear-mongering, um, but there are, like I said in the beginning of the talk,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=1400" target="_blank">00:23:20.960</a></span> | <span class="t">uh, there are, uh, harms that will happen from AI use. Uh, one, exacerbation of suicide and self-harm.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=1410" target="_blank">00:23:30.160</a></span> | <span class="t">In other words, if someone's using an AI tool and they're thinking about self-harm and suicide,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=1415" target="_blank">00:23:35.520</a></span> | <span class="t">it could exacerbate that, um, through, uh, sycopency. And I think we all know, are aware of that, um, uh,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=1424" target="_blank">00:23:44.240</a></span> | <span class="t">but some people are not, and some people are, um, possibly, uh, more susceptible to this than others.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=1431" target="_blank">00:23:51.120</a></span> | <span class="t">So, so, uh, there's always going to be some harms with, with usage, not that AI is causing those per</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=1437" target="_blank">00:23:57.440</a></span> | <span class="t">se, it's the usage. And so, uh, this is something that, um, we thought was interesting. In terms of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=1442" target="_blank">00:24:02.800</a></span> | <span class="t">looking at the bias in clusters, there's still the bias in clusters that exist. If you look at the prompt,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=1446" target="_blank">00:24:06.240</a></span> | <span class="t">the distribution of prompt links by benchmark, different, uh, and that's all I'm going to say</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=1450" target="_blank">00:24:10.080</a></span> | <span class="t">about that, um, because we're almost out of time when I talk about the limitations and then the, uh,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=1454" target="_blank">00:24:14.960</a></span> | <span class="t">takeaways. Limitations, obviously there's, there's, uh, methodological, methodological limitations here,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=1460" target="_blank">00:24:20.480</a></span> | <span class="t">uh, could have increased the sample size, for example, uh, dimensionality reduction loses information.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=1466" target="_blank">00:24:26.400</a></span> | <span class="t">There's bias actually inherent in the embeddings models that we're trying to get out.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=1469" target="_blank">00:24:29.360</a></span> | <span class="t">Uh, um, choosing the benchmarks, this is only five. I mean, I generalize because there's a lot of private</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=1474" target="_blank">00:24:34.640</a></span> | <span class="t">benchmarks. Um, equal benchmark weighting presumes that people are using this equally</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=1480" target="_blank">00:24:40.000</a></span> | <span class="t">they may not, uh, human biases that are inherent in research, implicit Western views in our research,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=1485" target="_blank">00:24:45.360</a></span> | <span class="t">um, in terms of the past harm as well. And, uh, the author's technical backgrounds, including myself,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=1492" target="_blank">00:24:52.320</a></span> | <span class="t">uh, um, because of the technical background, we might not have been thinking about harms that are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=1497" target="_blank">00:24:57.440</a></span> | <span class="t">actually, um, something that might be more of a priority that, that we might not have seen, not have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=1502" target="_blank">00:25:02.000</a></span> | <span class="t">seen, uh, future research directions, um, could include harm benchmarks for more, more cultural contexts.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=1508" target="_blank">00:25:08.480</a></span> | <span class="t">Um, there could be more exploration of prompt response relationships, because this is only</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=1512" target="_blank">00:25:12.720</a></span> | <span class="t">looking at the prompts intended to look at the prompts, prompt response relationships,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=1516" target="_blank">00:25:16.560</a></span> | <span class="t">but ran out of time and space in the paper. And then, um, if you were to apply this methodology</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=1522" target="_blank">00:25:22.400</a></span> | <span class="t">framework to domain specific data sets, um, and investigate differences this way, this, this is a,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=1528" target="_blank">00:25:28.000</a></span> | <span class="t">an evaluation method that is, uh, uh, uh, solid because it shows you what, what, what's in the data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=1535" target="_blank">00:25:35.360</a></span> | <span class="t">Top four conclusions, last slide. Uh, there are six primary harm categories that we identified</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=1542" target="_blank">00:25:42.160</a></span> | <span class="t">with varying coverage and breadth from each benchmark. Uh, semantic coverage gaps, as you've seen,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=1547" target="_blank">00:25:47.280</a></span> | <span class="t">exist across recent benchmarks and will over time as we change the definition for harms. Uh, the third,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=1553" target="_blank">00:25:53.440</a></span> | <span class="t">uh, was that we've found optimal clustering configuration framework for this particular use</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=1558" target="_blank">00:25:58.640</a></span> | <span class="t">case. And, um, this could be scaled for, for use in other benchmarks of similar topical use or, uh,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=1565" target="_blank">00:26:05.680</a></span> | <span class="t">other LLM applications of other similar, similar topical use. Uh, again, it shows you amongst a collection of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=1573" target="_blank">00:26:13.040</a></span> | <span class="t">things of similar topics, how something might over index and under index fourth, uh, plotting semantic</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=1579" target="_blank">00:26:19.760</a></span> | <span class="t">space. Um, again, this is a, uh, transparent evaluation approach that, uh, allows for more action and more</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=1585" target="_blank">00:26:25.360</a></span> | <span class="t">insight than the stereotypical region blue scores, which are binomial, uh, related to precision and recall</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jqyWZ19d1hg&t=1591" target="_blank">00:26:31.840</a></span> | <span class="t">that we're biased on using. So this allows you to, to have more insights. Thank you very much. Uh, we're</span></div></div></body></html>