<html><head><title>Lesson 7: Practical Deep Learning for Coders</title>
<style>
    body {
        font-family: Arial, sans-serif;
        margin: 0;
        padding: 0;
        background-color: #f4f4f4;
        color: #333;
    }
    .container {
        width: 95%;  /* Increased width to use more space */
        margin: auto;
        overflow: auto;  /* Added to handle overflow by adding a scrollbar if necessary */
    }
    h2, h3 {
        color: #333;
        text-align: center;
    }
    a {
        color: #0000FF;  /* Traditional blue color for links */
        text-decoration: none;
    }
    a:hover {
        text-decoration: underline;
    }
    img {
        display: block;
        margin: auto;
        max-width: 100%;
    }
    .c {
        margin: 10px 0;
    }
    .s, .t {
        display: inline-block;
        margin-right: 5px;
    }
    .max-width {
        max-width: 800px;
        margin: auto;
        padding-left: 20px;
    }
    table {
        width: 100%;
        border-collapse: collapse;
    }
    th, td {
        border: 1px solid #ddd;
        padding: 8px;
        text-align: left;  /* Ensure text alignment is consistent */
    }
    tr:nth-child(even) {
        background-color: #f2f2f2;
    }
    tr:nth-child(odd) {
        background-color: #e6e6e6;
    }
</style>

    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-69VLBMTTP0"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-69VLBMTTP0');
    </script>
    </head><body><div class='container'><a href="index.html">back to index</a><h2>Lesson 7: Practical Deep Learning for Coders</h2><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY"><img src="https://i.ytimg.com/vi_webp/Q0z-l2KRYFY/sddefault.webp" style="width:50%;"></a><div><br></div><div style="text-align: left;"><a href="./Q0z-l2KRYFY.html">Whisper Transcript</a> | <a href="./transcript_Q0z-l2KRYFY.html">Transcript Only Page</a></div><br><div style="max-width: 800px;"><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=0" target="_blank">00:00:00.000</a></span> | <span class="t">This is week 7 of 7, although in a sense it's week 7 of 14.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=9" target="_blank">00:00:09.380</a></span> | <span class="t">No pressure and no commitment, but how many of you are thinking you might want to come</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=14" target="_blank">00:00:14.880</a></span> | <span class="t">back for part 2 next year?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=17" target="_blank">00:00:17.100</a></span> | <span class="t">That's great.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=18" target="_blank">00:00:18.100</a></span> | <span class="t">When we started this, I thought if 1 in 5 people come back for part 2, I'd be happy.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=26" target="_blank">00:00:26.200</a></span> | <span class="t">So that's the best thing I've ever seen, thank you so much.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=31" target="_blank">00:00:31.140</a></span> | <span class="t">In that case, that's perfect because today I'm going to show you, and I think you'll</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=39" target="_blank">00:00:39.480</a></span> | <span class="t">be surprised and maybe a little overwhelmed, at what you can do with this little set of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=45" target="_blank">00:00:45.260</a></span> | <span class="t">tools you've learned already.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=47" target="_blank">00:00:47.600</a></span> | <span class="t">So this is going to be part 1 of this lesson, it's going to be a whirlwind tour of a bunch</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=55" target="_blank">00:00:55.720</a></span> | <span class="t">of different architectures, and different architectures are not just different because</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=60" target="_blank">00:01:00.840</a></span> | <span class="t">some of them will be better at doing what they're doing, but some of them will be doing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=65" target="_blank">00:01:05.680</a></span> | <span class="t">different things.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=67" target="_blank">00:01:07.880</a></span> | <span class="t">And I want to set your expectations and say that looking at an architecture and understanding</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=77" target="_blank">00:01:17.040</a></span> | <span class="t">how it does what it does is something that took me quite a few weeks to just get an intuitive</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=82" target="_blank">00:01:22.280</a></span> | <span class="t">feel for it, so don't feel bad, because as you'll see, it's like unprogrammed, it's like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=88" target="_blank">00:01:28.920</a></span> | <span class="t">we're going to describe something we would think would be great if the model knew how</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=94" target="_blank">00:01:34.040</a></span> | <span class="t">to do it, and then we'll say fit, and suddenly the model knows how to do it, and we'll look</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=98" target="_blank">00:01:38.920</a></span> | <span class="t">at it and decide how they're going to do that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=102" target="_blank">00:01:42.720</a></span> | <span class="t">The other thing I want to mention is, having said that, everything we're about to see uses</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=107" target="_blank">00:01:47.920</a></span> | <span class="t">only the things we've done. In fact, in the first half we're only going to use CNNs. There's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=113" target="_blank">00:01:53.360</a></span> | <span class="t">going to be no cropping of images, there's going to be no filtering, there's going to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=118" target="_blank">00:01:58.760</a></span> | <span class="t">be nothing hand-tuned, it's just going to be a bunch of convolutional ordains, but we're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=124" target="_blank">00:02:04.920</a></span> | <span class="t">going to put them together in some interesting ways.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=130" target="_blank">00:02:10.720</a></span> | <span class="t">So let me start with one of the most important developments of the last year or two, which</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=139" target="_blank">00:02:19.720</a></span> | <span class="t">is called ResNet. ResNet won the 2015 ImageNet competition. I was delighted that it won it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=149" target="_blank">00:02:29.240</a></span> | <span class="t">because it's an incredibly simple and intuitively understandable concept, and it's very simple</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=157" target="_blank">00:02:37.440</a></span> | <span class="t">to implement. In fact, what I would like to do is to show you.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=169" target="_blank">00:02:49.200</a></span> | <span class="t">So let me describe as best as I can how ResNet works. In fact, before I describe how it works,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=177" target="_blank">00:02:57.460</a></span> | <span class="t">I will show you why you should care that it works. So let's for now just put aside the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=184" target="_blank">00:03:04.080</a></span> | <span class="t">idea that there's a thing called ResNet. It's another architecture, a lot like VGG, that's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=188" target="_blank">00:03:08.580</a></span> | <span class="t">used for image classification or other CNN type things. It's actually broader than just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=195" target="_blank">00:03:15.840</a></span> | <span class="t">image classification. And we use it just the same way as we use the VGG-16 class you're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=200" target="_blank">00:03:20.080</a></span> | <span class="t">familiar with. We just say create something in ResNet, and again there's different size</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=209" target="_blank">00:03:29.080</a></span> | <span class="t">of ResNet. I'm going to use 50 because it's the smallest one and it works super well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=214" target="_blank">00:03:34.640</a></span> | <span class="t">I've started adding a parameter to my versions of these networks. I've added it to the new</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=220" target="_blank">00:03:40.240</a></span> | <span class="t">VGG as well, which is include_top. It's actually the same as the Keras author who started doing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=225" target="_blank">00:03:45.960</a></span> | <span class="t">his models. Basically the idea is that if you say include_top = false, you don't have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=232" target="_blank">00:03:52.360</a></span> | <span class="t">to go model.pop afterwards to remove the layers if you want to fine-tune. Include_top = false</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=238" target="_blank">00:03:58.280</a></span> | <span class="t">means only include the convolutional layers basically, and I'm going to stick my own final</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=247" target="_blank">00:04:07.640</a></span> | <span class="t">classification layers on top of that. So when I do this, it's not going to give me the last</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=254" target="_blank">00:04:14.080</a></span> | <span class="t">few layers. Maybe the best way to explain that is to show you when I create this network,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=264" target="_blank">00:04:24.320</a></span> | <span class="t">I've got this thing at the end that says if include_top, and if so then we add the last</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=269" target="_blank">00:04:29.760</a></span> | <span class="t">few layers with this last dense fully connected layer that makes it just image net things</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=273" target="_blank">00:04:33.860</a></span> | <span class="t">that's from your thousand categories. If we're not include_top, then don't add these additional</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=278" target="_blank">00:04:38.400</a></span> | <span class="t">layers. So this is just a thing which means you can load in a model which is specifically</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=285" target="_blank">00:04:45.700</a></span> | <span class="t">designed for fine-tuning. It's a little shortcut. And as you'll see shortly, it has some really</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=290" target="_blank">00:04:50.160</a></span> | <span class="t">helpful properties. We're in the Cats and Dogs competition here. The winner of the Cats and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=298" target="_blank">00:04:58.600</a></span> | <span class="t">Dogs competition had an accuracy of 0.985 on the private leaderboard and 0.989 on the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=304" target="_blank">00:05:04.840</a></span> | <span class="t">private leaderboard. We use this ResNet model in the same way as usual. We grab our batches,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=311" target="_blank">00:05:11.560</a></span> | <span class="t">we can pre-compute some features. And in fact, every single CNN model I'm going to show you,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=317" target="_blank">00:05:17.600</a></span> | <span class="t">we're always going to pre-compute the convolutional features. So everything we see today will</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=322" target="_blank">00:05:22.040</a></span> | <span class="t">be things you can do without retraining any of the convolutional layers. So you'll see</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=326" target="_blank">00:05:26.720</a></span> | <span class="t">pretty much everything I train will train in a small number of seconds. And that's because</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=332" target="_blank">00:05:32.160</a></span> | <span class="t">in my experience when you're working with photos, it's almost never helpful to retrain</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=337" target="_blank">00:05:37.560</a></span> | <span class="t">the convolutional layers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=340" target="_blank">00:05:40.640</a></span> | <span class="t">So we can stick something on top of our ResNet in the usual way. And we can say go ahead</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=350" target="_blank">00:05:50.760</a></span> | <span class="t">and compile and fit it. And in 48 seconds, it's created a model with a 0.986 accuracy,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=359" target="_blank">00:05:59.840</a></span> | <span class="t">which is the winner of the private leaderboard or the second winner of the private leaderboard.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=365" target="_blank">00:06:05.380</a></span> | <span class="t">So that's pretty impressive. I'm going to show you how this works in a moment. ResNet's actually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=372" target="_blank">00:06:12.740</a></span> | <span class="t">designed to not be used with a standard bunch of dense layers, but it's designed to be used</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=378" target="_blank">00:06:18.400</a></span> | <span class="t">with something called a global average pooling layer, which I'm about to describe to you.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=383" target="_blank">00:06:23.340</a></span> | <span class="t">So for now, let me just show you what happens if instead of the previous model, I use this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=387" target="_blank">00:06:27.160</a></span> | <span class="t">model, which has 3 layers, and compile and fit it, I get 0.9875 in 3 seconds. In fact,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=400" target="_blank">00:06:40.400</a></span> | <span class="t">I can even tell it that I don't want to use 224x224 images but I want to use 400x400 images.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=410" target="_blank">00:06:50.740</a></span> | <span class="t">And if I do that, and then I get batches, I say I want to create 400x400 images, and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=418" target="_blank">00:06:58.220</a></span> | <span class="t">create those features, compile and fit, I get 99.3. So this is kind of off the charts</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=426" target="_blank">00:07:06.040</a></span> | <span class="t">to go from somewhere around 98.5 to 99.3, we're reducing the amount of error by 3rd to 1/2.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=435" target="_blank">00:07:15.780</a></span> | <span class="t">So this is why you should be interested in ResNet. It's incredibly accurate. We're using</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=442" target="_blank">00:07:22.260</a></span> | <span class="t">it for the thing it's best at, which was originally, this ResNet was trained on ImageNet and the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=450" target="_blank">00:07:30.540</a></span> | <span class="t">Dogs and Cats competition looks a lot like ImageNet images. They're single pictures of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=455" target="_blank">00:07:35.420</a></span> | <span class="t">a single thing that's kind of reasonably large in the picture, they're not very big images</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=460" target="_blank">00:07:40.020</a></span> | <span class="t">on the whole. So this is something which this ResNet approach is particularly good for.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=467" target="_blank">00:07:47.180</a></span> | <span class="t">So I do actually want to show you how it works, because I think it's fascinating and awesome.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=471" target="_blank">00:07:51.920</a></span> | <span class="t">And I'm going to stick to the same approach that we've used so far when we've talked about</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=478" target="_blank">00:07:58.300</a></span> | <span class="t">architectures, which is that we have any shape represents a matrix of activations, and any</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=494" target="_blank">00:08:14.100</a></span> | <span class="t">arrow represents a layer operation. So that is a convolution or a dense layer with an activation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=501" target="_blank">00:08:21.300</a></span> | <span class="t">function. ResNet looks a lot like VGG. So I've mentioned that there's some part of the model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=512" target="_blank">00:08:32.340</a></span> | <span class="t">down here that we're not going to worry about too much. We're kind of halfway through the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=517" target="_blank">00:08:37.020</a></span> | <span class="t">model and there's some hidden activation layer that we've got too. With VGG, the approach</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=526" target="_blank">00:08:46.020</a></span> | <span class="t">is generally to go, the layers are basically a 3x3 conv, that gives you some activations,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=535" target="_blank">00:08:55.540</a></span> | <span class="t">another 3x3 conv, that gives you some activations, another 3x3 conv, that gives you some activations,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=541" target="_blank">00:09:01.220</a></span> | <span class="t">and then from time to time, it also does a max pulling. So each of these is representing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=549" target="_blank">00:09:09.220</a></span> | <span class="t">a conv layer. ResNet looks a lot like this. In fact, it has exactly that path, which is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=558" target="_blank">00:09:18.820</a></span> | <span class="t">a bunch of conv and values on top of each other. But it does something else, which is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=565" target="_blank">00:09:25.980</a></span> | <span class="t">this bit that comes out, and remember, when we have two arrows coming into a shape, that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=578" target="_blank">00:09:38.220</a></span> | <span class="t">means we're adding things.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=580" target="_blank">00:09:40.100</a></span> | <span class="t">You'll notice here, in fact, there's no shapes anywhere on the way here. In fact, this arrow</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=589" target="_blank">00:09:49.940</a></span> | <span class="t">does not represent a conv, it does not represent a dense layer, it actually represents identity.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=596" target="_blank">00:09:56.060</a></span> | <span class="t">In other words, we do nothing at all. And this whole thing here is called a ResNet block.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=608" target="_blank">00:10:08.700</a></span> | <span class="t">And so ResNet, basically if we represented a ResNet block as a square, ResNet is just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=613" target="_blank">00:10:13.460</a></span> | <span class="t">a whole bunch of these blocks basically stacked on top of each other. And then there's an</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=619" target="_blank">00:10:19.300</a></span> | <span class="t">input which is the input data, and then the output, of course it's yet.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=626" target="_blank">00:10:26.980</a></span> | <span class="t">Another way of looking at this is just to look at the code. I think the code is nice</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=632" target="_blank">00:10:32.500</a></span> | <span class="t">and kind of intuitive to understand. Let's take a look at this thing, they call it an</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=641" target="_blank">00:10:41.140</a></span> | <span class="t">identity block. So here's the code for what I just described, it's here. You might notice</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=649" target="_blank">00:10:49.180</a></span> | <span class="t">that everything I just selected here looks like a totally standard VGG block. I've got</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=655" target="_blank">00:10:55.660</a></span> | <span class="t">a conv2d, a batch normalization, and an activation function. I guess it looks like our improved</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=662" target="_blank">00:11:02.740</a></span> | <span class="t">VGG because it's got batch normalization. Another conv2d, another batch norm, but then this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=672" target="_blank">00:11:12.580</a></span> | <span class="t">is the magic that makes it ResNet, this single line of code. And it does something incredibly</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=677" target="_blank">00:11:17.340</a></span> | <span class="t">simple. It takes the result, all those 3 convolutions, and it adds it to our original input.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=689" target="_blank">00:11:29.100</a></span> | <span class="t">So normally, we have the output of some block is equal to a convolution of some input to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=710" target="_blank">00:11:50.500</a></span> | <span class="t">that block. But we're doing something different. We're saying the output to a block, so let's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=720" target="_blank">00:12:00.500</a></span> | <span class="t">call this "hidden state at time t + 1" is equal to the convolutions of hidden state</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=728" target="_blank">00:12:08.380</a></span> | <span class="t">at time t plus the hidden state at time t. That is the magic which makes it ResNet.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=739" target="_blank">00:12:19.860</a></span> | <span class="t">So why is it that that can give us this huge improvement in the state of the art in such</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=748" target="_blank">00:12:28.820</a></span> | <span class="t">a short period of time? And this is actually interestingly something that is somewhat controversial.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=758" target="_blank">00:12:38.020</a></span> | <span class="t">The authors of this paper that originally developed this describe it a number of ways.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=765" target="_blank">00:12:45.060</a></span> | <span class="t">They basically gave 2 main reasons. The first is they claim that you can create much deeper</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=770" target="_blank">00:12:50.700</a></span> | <span class="t">networks this way, because when you're backpropagating the weights, backpropagating through an identity</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=777" target="_blank">00:12:57.060</a></span> | <span class="t">is easy. You're never going to have an explosion of gradients or an explosion of activations.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=783" target="_blank">00:13:03.940</a></span> | <span class="t">And indeed, this did turn out to be true. The authors created a ResNet with over a thousand</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=790" target="_blank">00:13:10.860</a></span> | <span class="t">layers and got very good results. But it also turned out to be a bit of a red herring. A</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=798" target="_blank">00:13:18.420</a></span> | <span class="t">few months ago, some other folks created a ResNet which was not at all deep. It had like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=805" target="_blank">00:13:25.500</a></span> | <span class="t">40 or 50 layers, but instead it's very wide and had a lot of activations. And that did</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=810" target="_blank">00:13:30.460</a></span> | <span class="t">even better. So it's one of these funny things that seems even the original authors might</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=816" target="_blank">00:13:36.020</a></span> | <span class="t">have been wrong about why they built what they built.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=819" target="_blank">00:13:39.140</a></span> | <span class="t">The second reason why they built what they built seems to have stood the test of time,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=824" target="_blank">00:13:44.180</a></span> | <span class="t">which is that if we take this equation and rejig it, let's subtract that from both sides.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=831" target="_blank">00:13:51.180</a></span> | <span class="t">And that gives us h(t) + 1 - h(t). So the hidden activations at the next time period</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=839" target="_blank">00:13:59.620</a></span> | <span class="t">minus the hidden activations the previous time period equals (and I'm going to replace</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=844" target="_blank">00:14:04.380</a></span> | <span class="t">all this with R for ResNet block) a convolution of convolution of convolution applied to the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=853" target="_blank">00:14:13.740</a></span> | <span class="t">previous hidden state.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=855" target="_blank">00:14:15.460</a></span> | <span class="t">When you write it like that, it might make you realize something, which is all of the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=866" target="_blank">00:14:26.420</a></span> | <span class="t">weights we're learning are here. So we're learning a bunch of weights which allow us</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=871" target="_blank">00:14:31.740</a></span> | <span class="t">to make our previous guess as to the predictions a little bit better. We're basically saying</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=880" target="_blank">00:14:40.140</a></span> | <span class="t">let's take the previous predictions we've got, however we got to them, and try and build</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=884" target="_blank">00:14:44.980</a></span> | <span class="t">a set of things which makes them a little bit better.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=887" target="_blank">00:14:47.980</a></span> | <span class="t">In statistics, this thing is called the residual. The residual is the difference between the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=893" target="_blank">00:14:53.420</a></span> | <span class="t">thing you're trying to predict and your actions. So what we basically did here was they did</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=901" target="_blank">00:15:01.700</a></span> | <span class="t">design an architecture which without us having to do anything special automatically learns</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=907" target="_blank">00:15:07.740</a></span> | <span class="t">how to model the residuals. It learns how to build a bunch of layers which continually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=912" target="_blank">00:15:12.420</a></span> | <span class="t">slightly improve the previous answer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=914" target="_blank">00:15:14.780</a></span> | <span class="t">For those of you who have more of a machine learning background, you would recognize this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=920" target="_blank">00:15:20.420</a></span> | <span class="t">as essentially being boosting. Boosting refers to the idea of having a bunch of models where</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=928" target="_blank">00:15:28.420</a></span> | <span class="t">each model tries to predict the errors of the previous model. If you have a whole chain</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=933" target="_blank">00:15:33.240</a></span> | <span class="t">of those, you can then predict the errors on top of the errors, and add them all together,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=938" target="_blank">00:15:38.460</a></span> | <span class="t">and boosting is a way of getting much improved ensembles.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=943" target="_blank">00:15:43.780</a></span> | <span class="t">So this ResNet is not manually doing boosting, it's not manually doing anything. It's just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=950" target="_blank">00:15:50.300</a></span> | <span class="t">this single one extra line of code. It's all in the architecture.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=958" target="_blank">00:15:58.660</a></span> | <span class="t">A question about dimensionality. I would have assumed that by the time we were close to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=964" target="_blank">00:16:04.980</a></span> | <span class="t">output, the dimensions would be so different that element-wise addition wouldn't be possible</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=969" target="_blank">00:16:09.960</a></span> | <span class="t">between the last layer and the first layer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=971" target="_blank">00:16:11.980</a></span> | <span class="t">It's important to note that this input tensor is the input tensor to the block. So you'll</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=979" target="_blank">00:16:19.940</a></span> | <span class="t">see there's no max pooling inside here, so the dimensionality remains constant throughout</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=987" target="_blank">00:16:27.820</a></span> | <span class="t">all of these lines of code, so we can add them up. And then we can do our strides or</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=992" target="_blank">00:16:32.580</a></span> | <span class="t">max pooling, and then we do another identity block. So we're only adding that to the input</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=997" target="_blank">00:16:37.780</a></span> | <span class="t">of the block, not the input of the original image.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=1000" target="_blank">00:16:40.900</a></span> | <span class="t">And that's what we want. We want to say the input to each block is our best prediction</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=1007" target="_blank">00:16:47.820</a></span> | <span class="t">so far is effectively what it's doing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=1010" target="_blank">00:16:50.740</a></span> | <span class="t">Then qualitatively, how does this compare to dropout?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=1013" target="_blank">00:16:53.780</a></span> | <span class="t">In some ways, in most ways, it's unrelated to dropout. And indeed you can add dropout</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=1022" target="_blank">00:17:02.180</a></span> | <span class="t">to ResNet. At the end of a ResNet block, after this merge, you can add dropout. So ResNet</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=1029" target="_blank">00:17:09.420</a></span> | <span class="t">is not a regularization technique per se. Having said that, it does seem to have excellent</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=1037" target="_blank">00:17:17.580</a></span> | <span class="t">generalization characteristics, and if memory serves correctly, I just searched this entire</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=1044" target="_blank">00:17:24.180</a></span> | <span class="t">code base for dropout, and it didn't appear. So the image network didn't use any dropout,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=1049" target="_blank">00:17:29.140</a></span> | <span class="t">they didn't find it as necessary. But this is very problem-dependent. If you have only</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=1054" target="_blank">00:17:34.900</a></span> | <span class="t">a small amount of data, you may well need dropout. And I explained another reason that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=1060" target="_blank">00:17:40.700</a></span> | <span class="t">we don't need dropout for this in just a moment.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=1063" target="_blank">00:17:43.580</a></span> | <span class="t">In fact, I'll do that right now, which is, remember what I did here at the end was I</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=1071" target="_blank">00:17:51.180</a></span> | <span class="t">created a model which had a special kind of layer called a global average boolean layer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=1080" target="_blank">00:18:00.140</a></span> | <span class="t">This is the next key thing I teach you about today. It's a really important concept, it's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=1084" target="_blank">00:18:04.900</a></span> | <span class="t">going to come up a couple more times during today's class.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=1089" target="_blank">00:18:09.820</a></span> | <span class="t">Let's describe what this is. It's actually very simple. Here is the output of the pre-computed</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=1103" target="_blank">00:18:23.460</a></span> | <span class="t">resume. On the 224x224, the pre-computed residual blocks give us a 13x13 output with 2048.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=1129" target="_blank">00:18:49.100</a></span> | <span class="t">One way of thinking about this would be to say, well, each of these 13x13 blocks could</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=1137" target="_blank">00:18:57.180</a></span> | <span class="t">potentially try to say how catty or how doggy edge one of those 13 blocks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=1143" target="_blank">00:19:03.940</a></span> | <span class="t">And so rather than max pooling, which is take the maximum of that grid, we could do average</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=1150" target="_blank">00:19:10.980</a></span> | <span class="t">pooling. Across those 13x13 areas, what is the average amount of doggyness in each one,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=1160" target="_blank">00:19:20.100</a></span> | <span class="t">what is the average amount of cattyness in each one?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=1165" target="_blank">00:19:25.300</a></span> | <span class="t">And that's actually what global average pooling does. What global average pooling does is it's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=1169" target="_blank">00:19:29.980</a></span> | <span class="t">identical to average pooling 13x13 because the input to it is 13x13. So in other words,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=1189" target="_blank">00:19:49.060</a></span> | <span class="t">whatever the input to a global average pooling layer is, it will take all of the x and all</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=1195" target="_blank">00:19:55.020</a></span> | <span class="t">of the y coordinates and just take the average for every one of these 2048 georges.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=1202" target="_blank">00:20:02.960</a></span> | <span class="t">So let's take a look here. So what this is doing is it's taking an input of 2048 by 13x13</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=1217" target="_blank">00:20:17.860</a></span> | <span class="t">and it's going to return an output which is just a single vector of 2048. And that vector</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=1224" target="_blank">00:20:24.460</a></span> | <span class="t">is, on average, how much does this whole image have of each of those 2048 features.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=1233" target="_blank">00:20:33.740</a></span> | <span class="t">And because ResNet was originally trained with global average pooling 2D, so you can</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=1239" target="_blank">00:20:39.900</a></span> | <span class="t">see that this is the ResNet code. In fact, it's 7x7. So this was actually written before</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=1257" target="_blank">00:20:57.740</a></span> | <span class="t">the global average pooling 2D layer existed, so they just did it manually, they just put</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=1262" target="_blank">00:21:02.660</a></span> | <span class="t">an average pooling 7x7 here. So because ResNet was trained originally with this layer here,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=1276" target="_blank">00:21:16.300</a></span> | <span class="t">that means that it was trained such that the last identity block was basically creating</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=1282" target="_blank">00:21:22.180</a></span> | <span class="t">features that were designed to be average together. And so that means that when we used</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=1288" target="_blank">00:21:28.720</a></span> | <span class="t">this tiny little architecture, we got the best results because that was how ResNet was</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=1295" target="_blank">00:21:35.700</a></span> | <span class="t">originally designed to be used.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=1298" target="_blank">00:21:38.220</a></span> | <span class="t">If you had a wider network without the input fed forward to the output activation, couldn't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=1303" target="_blank">00:21:43.500</a></span> | <span class="t">you get the same result? The extra activations in the wider network could pass the input</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=1308" target="_blank">00:21:48.620</a></span> | <span class="t">all the way through all the layers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=1310" target="_blank">00:21:50.740</a></span> | <span class="t">Well, you can in theory have convolutional filters that don't do anything, but the point</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=1323" target="_blank">00:22:03.620</a></span> | <span class="t">is having to learn that is learning lots and lots of filters designed to learn that. And</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=1331" target="_blank">00:22:11.260</a></span> | <span class="t">so maybe the best way I can describe this is everything I'm telling you about architectures</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=1338" target="_blank">00:22:18.180</a></span> | <span class="t">is in some ways irrelevant. You could create nothing but dense layers at every level of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=1343" target="_blank">00:22:23.900</a></span> | <span class="t">your model. And dense layers have every input connected to every output, so every architecture</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=1351" target="_blank">00:22:31.660</a></span> | <span class="t">I'm telling you about is just a simplified version of that, we're just deleting some</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=1356" target="_blank">00:22:36.540</a></span> | <span class="t">of those.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=1359" target="_blank">00:22:39.220</a></span> | <span class="t">But it's really helpful to do that. It's really helpful to help our SGD optimizer by giving</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=1367" target="_blank">00:22:47.660</a></span> | <span class="t">it, by making it so that the default thing it can do is the thing we want. So yes, in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=1374" target="_blank">00:22:54.460</a></span> | <span class="t">theory, a convNet or a native fully connected net could learn to do the same thing that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=1379" target="_blank">00:22:59.540</a></span> | <span class="t">ResNet does. In practice, it would take a lot of parameters for it to do so, and time to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=1388" target="_blank">00:23:08.180</a></span> | <span class="t">do so, and so this is why we care about architectures. In practice, having a good architecture makes</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=1394" target="_blank">00:23:14.980</a></span> | <span class="t">a huge difference. That's a good question, very good question.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=1402" target="_blank">00:23:22.180</a></span> | <span class="t">Another question, would it be fair to say that if VGG was trained with average pooling,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=1407" target="_blank">00:23:27.340</a></span> | <span class="t">it would yield better results?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=1409" target="_blank">00:23:29.500</a></span> | <span class="t">I'm not sure, so let's talk about that a little bit. One of the reasons, or maybe the main</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=1418" target="_blank">00:23:38.900</a></span> | <span class="t">reason that ResNet didn't need to drop out is because we're using global average pooling,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=1424" target="_blank">00:23:44.940</a></span> | <span class="t">there's a hell of a lot less parameters in this model. Remember, the vast majority of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=1431" target="_blank">00:23:51.940</a></span> | <span class="t">the parameters in the model are in the dense layers, because if you've got 'm' inputs and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=1436" target="_blank">00:23:56.700</a></span> | <span class="t">'m' outputs, you have 'n' times 'm' connections.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=1440" target="_blank">00:24:00.560</a></span> | <span class="t">So in VGG, I can't quite remember, but that first dense layer has something like 300 million</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=1446" target="_blank">00:24:06.780</a></span> | <span class="t">inputs, because it had every possible feature of the convolutional layer by each of the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=1456" target="_blank">00:24:16.060</a></span> | <span class="t">3, by each convolutional layer by every one of the 4,006 outputs, so it just created a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=1461" target="_blank">00:24:21.020</a></span> | <span class="t">lot of features and made it very easy to fit.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=1465" target="_blank">00:24:25.540</a></span> | <span class="t">With global average pooling and indeed not having any dense layers, we have a lot less</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=1471" target="_blank">00:24:31.460</a></span> | <span class="t">parameters, so it's going to generalize better. It also generalizes better because we're treating</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=1477" target="_blank">00:24:37.420</a></span> | <span class="t">every one of those 7x7 or 13x13 areas in the same way. We're saying how doggy or catty</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=1486" target="_blank">00:24:46.540</a></span> | <span class="t">are each of these, we're just averaging them. It turns out that these global average pooling</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=1493" target="_blank">00:24:53.760</a></span> | <span class="t">layer models do seem to generalize very well, and we're going to be seeing more of that in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=1498" target="_blank">00:24:58.260</a></span> | <span class="t">a moment.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=1499" target="_blank">00:24:59.260</a></span> | <span class="t">Why do we use global average pooling instead of max pooling?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=1504" target="_blank">00:25:04.620</a></span> | <span class="t">You wouldn't want to max pool over, well, it depends. You can try both. In this case, the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=1531" target="_blank">00:25:31.920</a></span> | <span class="t">same thing is the same thing. The same thing is the same thing. On the other hand, the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=1545" target="_blank">00:25:45.800</a></span> | <span class="t">fisheries competition, the fish is generally a very small part of each image. So maybe in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=1552" target="_blank">00:25:52.780</a></span> | <span class="t">the fisheries competition you should use a global max pooling layer, give it a try and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=1558" target="_blank">00:25:58.620</a></span> | <span class="t">tell us how it goes. Because in that case, you actually don't care about all the parts</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=1562" target="_blank">00:26:02.700</a></span> | <span class="t">of the image, which have nothing to do with fish. So that would be a very interesting thing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=1568" target="_blank">00:26:08.460</a></span> | <span class="t">to try.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=1571" target="_blank">00:26:11.900</a></span> | <span class="t">ResNet is very powerful, but it has not been studied much at all for transfer learning.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=1586" target="_blank">00:26:26.540</a></span> | <span class="t">This is not to say it won't work well for transfer learning, I just literally haven't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=1590" target="_blank">00:26:30.740</a></span> | <span class="t">found a single paper yet where somebody has analyzed its effectiveness for transfer learning.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=1597" target="_blank">00:26:37.580</a></span> | <span class="t">And to me, 99.9999% of what you will work on will be transfer learning. Because if you're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=1604" target="_blank">00:26:44.700</a></span> | <span class="t">not using transfer learning, it means you're looking at a data set that is so different</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=1608" target="_blank">00:26:48.180</a></span> | <span class="t">to anything that anybody has looked at before that none of the pictures in any model was</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=1612" target="_blank">00:26:52.420</a></span> | <span class="t">remotely helpful for you, which is going to be rare.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=1622" target="_blank">00:27:02.220</a></span> | <span class="t">Particularly all of the work I've seen on transfer learning, both in terms of capital winners</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=1627" target="_blank">00:27:07.180</a></span> | <span class="t">and in terms of papers, uses VGG. And I think one of the reasons for that is, as we talked</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=1632" target="_blank">00:27:12.620</a></span> | <span class="t">about in lesson 1, the VGG architecture really is designed to create layers of gradually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=1643" target="_blank">00:27:23.980</a></span> | <span class="t">increasing semantic complexity. All the work I've seen on visualizing layers tends to use</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=1650" target="_blank">00:27:30.980</a></span> | <span class="t">VGG or something similar to that as well, like that Matt Seiler stuff we saw, or those</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=1655" target="_blank">00:27:35.260</a></span> | <span class="t">Joseph Nusinski videos we saw. And so we've seen how the VGG network, those kinds of networks,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=1662" target="_blank">00:27:42.540</a></span> | <span class="t">create gradually more complex representations, which is exactly what we want to transfer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=1668" target="_blank">00:27:48.660</a></span> | <span class="t">Because let's just say, how different is this new domain to the previous domain, and then</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=1675" target="_blank">00:27:55.580</a></span> | <span class="t">we can pick a layer far enough back, we can try a few that the features seem to work well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=1683" target="_blank">00:28:03.260</a></span> | <span class="t">So for that reason, we're going to go back to looking at VGG for the rest of these architectures.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=1689" target="_blank">00:28:09.980</a></span> | <span class="t">And I'm going to look at the fisheries competition. The fisheries competition is actually very</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=1697" target="_blank">00:28:17.300</a></span> | <span class="t">interesting. The pictures are from a dozen boats, and each one of these boats has a fixed</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=1706" target="_blank">00:28:26.940</a></span> | <span class="t">camera, and they can do daytime and nighttime shots. And so every picture has the same basic</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=1715" target="_blank">00:28:35.540</a></span> | <span class="t">shape and structure for each of the 12 boats, because it's a fixed camera. And then somewhere</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=1720" target="_blank">00:28:40.500</a></span> | <span class="t">in there, most of the time, there's one or more fish. And your job is to say what kind</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=1725" target="_blank">00:28:45.340</a></span> | <span class="t">of fish is it? The fish are pretty small.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=1731" target="_blank">00:28:51.020</a></span> | <span class="t">And so one of the things that makes this interesting is that this is the kind of somewhat weird,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=1738" target="_blank">00:28:58.540</a></span> | <span class="t">kind of complex, different thing to ImageNet, which is exactly the kind of stuff that you're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=1744" target="_blank">00:29:04.260</a></span> | <span class="t">going to have to deal with any time you're doing some kind of computer vision problem</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=1748" target="_blank">00:29:08.180</a></span> | <span class="t">or any kind of CNN problem. It's very likely that the thing you're doing won't be quite</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=1752" target="_blank">00:29:12.980</a></span> | <span class="t">the same as what other academics have been looking at. So trying to figure out how to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=1756" target="_blank">00:29:16.300</a></span> | <span class="t">do a good job of the fisheries competition is a great example.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=1763" target="_blank">00:29:23.080</a></span> | <span class="t">So when I started on the fisheries competition, I just did the usual thing, which was to create</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=1766" target="_blank">00:29:26.580</a></span> | <span class="t">a VGG-16 model, fine-tuned it to have just 8 outputs, because we had to say which of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=1772" target="_blank">00:29:32.260</a></span> | <span class="t">8 types of fish do we see in it. And then I, as per usual, pre-computed the convolutional</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=1781" target="_blank">00:29:41.740</a></span> | <span class="t">layers using the pre-trained VGG network, and then everything after that I just used</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=1786" target="_blank">00:29:46.760</a></span> | <span class="t">those pre-computed convolutional layers. And as per usual, the first thing I did was to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=1791" target="_blank">00:29:51.380</a></span> | <span class="t">stick a few dense layers on top and see how that goes.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=1796" target="_blank">00:29:56.740</a></span> | <span class="t">So the nice thing about this is you can see each epoch takes less than a second to run.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=1802" target="_blank">00:30:02.340</a></span> | <span class="t">So when people talk about needing lots of data or lots of time, it's not really true</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=1808" target="_blank">00:30:08.140</a></span> | <span class="t">because for most stuff you do in real life, you're only using pre-computed convolutional</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=1812" target="_blank">00:30:12.260</a></span> | <span class="t">features. And in our validation set, we get an accuracy of 96.2%, a percentage loss of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=1820" target="_blank">00:30:20.420</a></span> | <span class="t">0.18. That's pretty good, which seems to be recognising the fish pretty well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=1828" target="_blank">00:30:28.060</a></span> | <span class="t">But here's the problem. There is all kinds of data leakage going on, and this is one</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=1835" target="_blank">00:30:35.380</a></span> | <span class="t">of the most important concepts to understand when it comes to building any kind of model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=1845" target="_blank">00:30:45.020</a></span> | <span class="t">or any kind of machine learning project leakage.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=1851" target="_blank">00:30:51.780</a></span> | <span class="t">There was a paper, I think it actually won the KDD Best Paper Award a couple of years</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=1857" target="_blank">00:30:57.420</a></span> | <span class="t">ago from Claudia Prerich and some of her colleagues, which studied data leakage. Data leakage occurs</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=1865" target="_blank">00:31:05.500</a></span> | <span class="t">when something about the target you're trying to predict is encoded in the things that you're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=1872" target="_blank">00:31:12.980</a></span> | <span class="t">predicting with, but that information is either not going to be available or it won't be helpful</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=1879" target="_blank">00:31:19.140</a></span> | <span class="t">in practice when you're going to use the model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=1882" target="_blank">00:31:22.740</a></span> | <span class="t">For example, in the fisheries competition, different boats fish in different parts of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=1889" target="_blank">00:31:29.380</a></span> | <span class="t">the sea. Different parts of the sea have different fish in them, and so in the fisheries competition,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=1896" target="_blank">00:31:36.820</a></span> | <span class="t">if you just use something representing which boat did the image come from, you can get</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=1903" target="_blank">00:31:43.340</a></span> | <span class="t">a pretty good, accurate validation set result. What I mean by that, for example, is here's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=1912" target="_blank">00:31:52.060</a></span> | <span class="t">something which is very cheeky. This is a list of the size of each photo, along with</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=1920" target="_blank">00:32:00.780</a></span> | <span class="t">how many times that appears. You can see it's gone through every photo and opened it using</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=1928" target="_blank">00:32:08.020</a></span> | <span class="t">PIL, which is the Python imaging library, and greater the size. You can see that there's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=1933" target="_blank">00:32:13.540</a></span> | <span class="t">basically a small number of sizes that appear.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=1936" target="_blank">00:32:16.580</a></span> | <span class="t">It turns out that if you create a simple linear model that says any image of size 1192 x 670,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=1947" target="_blank">00:32:27.080</a></span> | <span class="t">what kind of fish is that? Anything with 1280 x 720, what kind of fish is that? You get</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=1951" target="_blank">00:32:31.700</a></span> | <span class="t">a pretty accurate model because these are the different ships. The different ships have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=1957" target="_blank">00:32:37.820</a></span> | <span class="t">different cameras and different cameras have different resolutions. This isn't helpful</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=1961" target="_blank">00:32:41.860</a></span> | <span class="t">in practice because what the fisheries people actually wanted to do was to use this to find</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=1966" target="_blank">00:32:46.460</a></span> | <span class="t">out when people are illegally or accidentally overfishing or fishing in the wrong way. So</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=1974" target="_blank">00:32:54.060</a></span> | <span class="t">if they're bringing up dolphins or something, they wouldn't know about it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=1978" target="_blank">00:32:58.260</a></span> | <span class="t">So any model that says I know what kind of fish this is because I know what the boat</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=1982" target="_blank">00:33:02.500</a></span> | <span class="t">is is entirely useless. So this is an example of leakage. In this particular paper I mentioned,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=1994" target="_blank">00:33:14.260</a></span> | <span class="t">the authors looked at machine learning competitions and discovered that over 50% of them had some</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=2000" target="_blank">00:33:20.300</a></span> | <span class="t">kind of data leakage. I spoke to Claudia after she presented that paper, and I asked her</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=2008" target="_blank">00:33:28.500</a></span> | <span class="t">if she thought that regular machine learning projects in inside companies would have more</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=2013" target="_blank">00:33:33.700</a></span> | <span class="t">or less leakage than that, and she said a lot more. In competitions, people have tried</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=2024" target="_blank">00:33:44.100</a></span> | <span class="t">really hard to clean up the data ahead of time because they know that lots and lots of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=2027" target="_blank">00:33:47.140</a></span> | <span class="t">people are going to be looking at it. And if there is leakage, you're almost certain</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=2030" target="_blank">00:33:50.900</a></span> | <span class="t">that somebody's going to find it because it's a competition. Whereas if you have leakage</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=2035" target="_blank">00:33:55.260</a></span> | <span class="t">in your data set, it's very likely you won't even know about it until you try to put the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=2040" target="_blank">00:34:00.580</a></span> | <span class="t">model into production and discover that it doesn't work as well as you thought it would.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=2044" target="_blank">00:34:04.820</a></span> | <span class="t">Oh, and I was just going to add that it might not even help you in the competition if your</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=2051" target="_blank">00:34:11.460</a></span> | <span class="t">test set is brand new boats that weren't in your training set.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=2057" target="_blank">00:34:17.940</a></span> | <span class="t">So let's talk about that. So trying to win a Kaggle competition and trying to do a good</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=2068" target="_blank">00:34:28.580</a></span> | <span class="t">job is somewhat independent. So when I'm working on Kaggle, I focus on trying to win a Kaggle</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=2074" target="_blank">00:34:34.740</a></span> | <span class="t">competition. I have a clear metric and I try to optimize the metric. And sometimes that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=2079" target="_blank">00:34:39.620</a></span> | <span class="t">means finding leakage and taking advantage of it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=2083" target="_blank">00:34:43.220</a></span> | <span class="t">So in this case, step number 1 for me in the fisheries competition was to say, "Can I take</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=2088" target="_blank">00:34:48.580</a></span> | <span class="t">advantage of this leakage?" I want to be very clear. This is the exact opposite of what</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=2093" target="_blank">00:34:53.820</a></span> | <span class="t">you would want to do if you were actually trying to help the fisheries people create</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=2097" target="_blank">00:34:57.060</a></span> | <span class="t">a good model. Having said that, there's $150,000 at stake and I could donate that to the Fred</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=2102" target="_blank">00:35:02.660</a></span> | <span class="t">Hollis Foundation and get lots of people their site back. So winning this would be good.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=2108" target="_blank">00:35:08.020</a></span> | <span class="t">So let me show you how I try to take advantage of this leakage, which is totally legal in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=2113" target="_blank">00:35:13.660</a></span> | <span class="t">a Kaggle competition and see what happened. And then I'll talk more about Rachel's issue</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=2121" target="_blank">00:35:21.160</a></span> | <span class="t">after that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=2122" target="_blank">00:35:22.260</a></span> | <span class="t">So the first thing I did was I made a list for every file of how big it was and what</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=2127" target="_blank">00:35:27.380</a></span> | <span class="t">the image dimensions were. And I did that for the validation of the training set. I</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=2133" target="_blank">00:35:33.180</a></span> | <span class="t">normalized them by subtracting the main, divided by the standard deviation. And then I created</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=2138" target="_blank">00:35:38.260</a></span> | <span class="t">an almost exact copy of the previous model I showed you, this one. But this time, rather</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=2145" target="_blank">00:35:45.820</a></span> | <span class="t">than using the sequential API, I used the functional API. But other than that, this is almost identical.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=2152" target="_blank">00:35:52.620</a></span> | <span class="t">The only difference is in this line, what I've done is I've taken not just the input which</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=2163" target="_blank">00:36:03.700</a></span> | <span class="t">is the output of the last convolutional layer of my BGG model, but I have a second input.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=2171" target="_blank">00:36:11.300</a></span> | <span class="t">And the second input is what size image is it. I should mention I have one-hot encoded</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=2182" target="_blank">00:36:22.420</a></span> | <span class="t">those image sizes, so they're treated as categories.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=2187" target="_blank">00:36:27.660</a></span> | <span class="t">So I now have an additional input. One is the output of the BGG convolutional layer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=2193" target="_blank">00:36:33.620</a></span> | <span class="t">One is the one-hot encoded image size. I batch-monolized that, obviously. And then right at the very</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=2201" target="_blank">00:36:41.660</a></span> | <span class="t">last step, I can catenate the two together. So my model is basically a standard last few</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=2211" target="_blank">00:36:51.740</a></span> | <span class="t">layers of BGG model, so three dense layers. And then I have my input, and then I have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=2224" target="_blank">00:37:04.180</a></span> | <span class="t">another input. It ended up being something I think I catenated, and that creates an output.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=2233" target="_blank">00:37:13.900</a></span> | <span class="t">So what this can do now is that the last dense layer can learn to combine the image features</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=2242" target="_blank">00:37:22.340</a></span> | <span class="t">along with this metadata. This is useful for all kinds of things other than taking advantage</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=2249" target="_blank">00:37:29.860</a></span> | <span class="t">in a dastardly way of linkage. For example, if you were doing a collaborative free model,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=2256" target="_blank">00:37:36.740</a></span> | <span class="t">you might have information about the user, such as their age, their gender, their favorite</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=2264" target="_blank">00:37:44.300</a></span> | <span class="t">genres, and they asked for a survey. This is how you incorporate that kind of metadata</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=2271" target="_blank">00:37:51.020</a></span> | <span class="t">into a standard neural layer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=2275" target="_blank">00:37:55.820</a></span> | <span class="t">So I batch the two together and run it. Initially it's looking encouraging. If we go back and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=2282" target="_blank">00:38:02.580</a></span> | <span class="t">look at the standard model, we've got 0.84, 0.94, 0.95. This multi-input model is a little</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=2294" target="_blank">00:38:14.300</a></span> | <span class="t">better, 0.86, 0.95, 0.96. So that's encouraging. But interestingly, the model without using</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=2305" target="_blank">00:38:25.420</a></span> | <span class="t">the leakage gets somewhere around 96.5, 97.5, maybe 98. It's kind of all over the place,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=2314" target="_blank">00:38:34.860</a></span> | <span class="t">which isn't a great sign, but let's say somewhere around 97, 97.5. This multi-input model, on</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=2322" target="_blank">00:38:42.420</a></span> | <span class="t">the other hand, does not get better than that. It's best is also around 97.5. Why is that?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=2332" target="_blank">00:38:52.820</a></span> | <span class="t">This is very common when people try and utilize metadata in deep learning models. It often</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=2338" target="_blank">00:38:58.420</a></span> | <span class="t">turns out that the main thing you're looking at, in this case the image, already encodes</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=2344" target="_blank">00:39:04.100</a></span> | <span class="t">everything that your metadata has anyway. In this case, yeah, the size of the image</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=2348" target="_blank">00:39:08.980</a></span> | <span class="t">tells us what bode comes from, but you can't just look at the picture and see what bode</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=2352" target="_blank">00:39:12.020</a></span> | <span class="t">comes from. So by the later epochs, the convolutional model has learnt already to figure out what</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=2357" target="_blank">00:39:17.340</a></span> | <span class="t">bode comes from, so the linkage actually turned out not to be helpful anyway.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=2362" target="_blank">00:39:22.740</a></span> | <span class="t">So it's amazing how often people assume they need to find metadata and incorporate it into</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=2371" target="_blank">00:39:31.920</a></span> | <span class="t">their model, and how often it turns out to be a waste of time. Because the raw, real</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=2377" target="_blank">00:39:37.820</a></span> | <span class="t">data or the audio or the pictures or the language or whatever turns out to encode all of that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=2384" target="_blank">00:39:44.540</a></span> | <span class="t">in it. Finally, I wanted to go back to what Rachel was talking about, which is what would</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=2394" target="_blank">00:39:54.380</a></span> | <span class="t">have happened if this did work. Let's say that actually this gave us a much better validation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=2400" target="_blank">00:40:00.380</a></span> | <span class="t">result than the non-linkage model. If I then submitted it to Kaggle and my leaderboard</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=2407" target="_blank">00:40:07.740</a></span> | <span class="t">result was great, that would tell me that I have found leakage, that the Kaggle competition</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=2413" target="_blank">00:40:13.980</a></span> | <span class="t">administrators didn't, and I'm possibly not aware of any competition. Having said that,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=2420" target="_blank">00:40:20.140</a></span> | <span class="t">the Kaggle competition administrators first and foremost try to avoid leakage, and indeed</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=2426" target="_blank">00:40:26.860</a></span> | <span class="t">if you do try and submit this to the leaderboard, you'll find it doesn't do that great. I haven't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=2433" target="_blank">00:40:33.260</a></span> | <span class="t">really looked into it yet, but somehow the competition administrators have simplified</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=2438" target="_blank">00:40:38.540</a></span> | <span class="t">some attempt to remove the leakage. The kind of ways that we did that when I was at Kaggle</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=2445" target="_blank">00:40:45.020</a></span> | <span class="t">would be to do things like some kind of stratified sampling where it would say there's way more</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=2450" target="_blank">00:40:50.300</a></span> | <span class="t">alcohol from this ship than this ship. Let's enforce that every ship has to have the same</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=2456" target="_blank">00:40:56.700</a></span> | <span class="t">number, same kind of fish, or something like that. But honestly, it's a very difficult</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=2466" target="_blank">00:41:06.620</a></span> | <span class="t">thing to do, and this impacts a lot more than just machine learning competitions. Every one</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=2471" target="_blank">00:41:11.820</a></span> | <span class="t">of your real-world projects, you're going to have to think long and hard about how can</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=2477" target="_blank">00:41:17.020</a></span> | <span class="t">you replicate real-world conditions in your test set. Maybe the best example I can come</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=2483" target="_blank">00:41:23.740</a></span> | <span class="t">up with is when you put your model into production, it will probably be a few months after you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=2489" target="_blank">00:41:29.980</a></span> | <span class="t">grabbed the data and trained it. How much has the world changed? Therefore, wouldn't it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=2496" target="_blank">00:41:36.780</a></span> | <span class="t">be great if instead you could create a test set that had data from a few months later</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=2501" target="_blank">00:41:41.820</a></span> | <span class="t">that you're trying to set? And again, you're really trying to replicate the situation that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=2508" target="_blank">00:41:48.140</a></span> | <span class="t">you actually have when you put your model into production.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=2511" target="_blank">00:41:51.420</a></span> | <span class="t">Two questions. One is just a note that they're releasing another test set later on in the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=2517" target="_blank">00:41:57.340</a></span> | <span class="t">fishery competition. Question, did you do two classifications, one for the boats and one</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=2524" target="_blank">00:42:04.060</a></span> | <span class="t">for the fish? Is that a waste of time?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=2528" target="_blank">00:42:08.900</a></span> | <span class="t">I have two inputs, not two outputs. My input is the one hot encoded size of the image,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=2537" target="_blank">00:42:17.980</a></span> | <span class="t">which I assumed is a proxy for the boat ID. Some discussion on the Kaggle forum suggested</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=2546" target="_blank">00:42:26.220</a></span> | <span class="t">that's a really small assumption. We're going to look at multi-output in a moment. In fact,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=2552" target="_blank">00:42:32.620</a></span> | <span class="t">we're going to do it now.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=2559" target="_blank">00:42:39.660</a></span> | <span class="t">Another question, can you find a good way of isolating the fish on the images and then</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=2564" target="_blank">00:42:44.420</a></span> | <span class="t">do the classification on that?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=2566" target="_blank">00:42:46.860</a></span> | <span class="t">Let's do that now, shall we? This is my lunch. All right, multi-output. There's a lot of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=2586" target="_blank">00:43:06.420</a></span> | <span class="t">nice things about our Kaggle competitions are structured, and one of the things I really</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=2589" target="_blank">00:43:09.820</a></span> | <span class="t">like is that in most of them you can create or find your own data sources as long as you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=2597" target="_blank">00:43:17.580</a></span> | <span class="t">share them with the community. So one of the people in the fisheries competition has gone</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=2602" target="_blank">00:43:22.500</a></span> | <span class="t">through and by hand put a little square around every fish, which is called annotating the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=2609" target="_blank">00:43:29.500</a></span> | <span class="t">dataset. Specifically, this kind of annotation is called a bounding box. The bounding box</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=2616" target="_blank">00:43:36.060</a></span> | <span class="t">is a box in which your object only is. Because of the rules of Kaggle, you had to make that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=2622" target="_blank">00:43:42.860</a></span> | <span class="t">available to everybody in the Kaggle community, which he provided a link on the Kaggle forum.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=2628" target="_blank">00:43:48.580</a></span> | <span class="t">So I'm going to go ahead and download those. There are a bunch of JSON files that basically</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=2632" target="_blank">00:43:52.460</a></span> | <span class="t">look like this. So for each image, for each fish in that image, it had the height, width,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=2638" target="_blank">00:43:58.540</a></span> | <span class="t">and x and y. So the details of the code don't matter too much, but I basically just went</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=2644" target="_blank">00:44:04.620</a></span> | <span class="t">and found the largest fish in each image and created a list of them. So I've got now my</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=2654" target="_blank">00:44:14.580</a></span> | <span class="t">training bounding boxes and my validation bounding boxes. For things that didn't have a fish,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=2659" target="_blank">00:44:19.260</a></span> | <span class="t">I just had 0, 0, 0, 0. This is my empty bounding box here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=2665" target="_blank">00:44:25.060</a></span> | <span class="t">So as always, when I want to understand new data, the first thing to do is to look at</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=2668" target="_blank">00:44:28.900</a></span> | <span class="t">it. When we're doing computer vision problems, it's very easy to look at data because it's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=2672" target="_blank">00:44:32.420</a></span> | <span class="t">pictures. So I went ahead and created this little show bounding box thing, and I tried</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=2678" target="_blank">00:44:38.980</a></span> | <span class="t">it on an image, and here is the fish, and here is the bounding box.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=2684" target="_blank">00:44:44.660</a></span> | <span class="t">There are two questions, although I didn't know if you wanted to get to a good stopping</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=2690" target="_blank">00:44:50.300</a></span> | <span class="t">point on your thought. One is, adding metadata, is that not useful for both CNNs and RNNs</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=2698" target="_blank">00:44:58.940</a></span> | <span class="t">or just for CNNs? And the other one is, VGG required images all the same size and training.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=2708" target="_blank">00:45:08.300</a></span> | <span class="t">In the fisheries case, are there different sized images being used for training and how</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=2713" target="_blank">00:45:13.220</a></span> | <span class="t">do you train a model on images with different dimensions?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=2716" target="_blank">00:45:16.740</a></span> | <span class="t">Regarding whether metadata is useful for RNNs or CNNs, it's got nothing to do with the architecture.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=2728" target="_blank">00:45:28.580</a></span> | <span class="t">It's entirely about the semantics of the data. If your text or audio or whatever unstructured</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=2734" target="_blank">00:45:34.940</a></span> | <span class="t">data in some way kind of encodes the same information that is in the metadata, the metadata</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=2741" target="_blank">00:45:41.220</a></span> | <span class="t">is unlikely to be helpful. For example, in the Netflix prize, in the early stages of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=2747" target="_blank">00:45:47.260</a></span> | <span class="t">the competition, people found that it was helpful to link to IMDb and bring in information</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=2753" target="_blank">00:45:53.500</a></span> | <span class="t">about the movies. In later stages, they found it wasn't. The reason why is because in later</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=2759" target="_blank">00:45:59.500</a></span> | <span class="t">stages they had figured out how to extrapolate from the ratings themselves, they basically</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=2766" target="_blank">00:46:06.580</a></span> | <span class="t">contained implicitly all the same information.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=2772" target="_blank">00:46:12.180</a></span> | <span class="t">How do we deal with different sized images? I'm about to show you some tricks, but so</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=2777" target="_blank">00:46:17.780</a></span> | <span class="t">far throughout this course, we have always resized everything to 224x224. Whenever you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=2785" target="_blank">00:46:25.140</a></span> | <span class="t">use get matches, I default to resizing into 224x224 because that's what ImageNet did,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=2791" target="_blank">00:46:31.260</a></span> | <span class="t">with the exception that in my previous ResNet model, I showed you resizing to 400x400 instead.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=2799" target="_blank">00:46:39.740</a></span> | <span class="t">So far, and in fact everything we're doing this year, we're going to resize everything</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=2806" target="_blank">00:46:46.200</a></span> | <span class="t">to be the same size.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=2809" target="_blank">00:46:49.220</a></span> | <span class="t">So I had a question about the 400x400, is that because there are two different ResNet</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=2816" target="_blank">00:46:56.620</a></span> | <span class="t">models?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=2817" target="_blank">00:46:57.620</a></span> | <span class="t">Two different ResNet models? No, it's not. I'll show you how that happened in a moment.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=2823" target="_blank">00:47:03.020</a></span> | <span class="t">We're going to get to that. It's kind of a little sneak peek at what we're coming to.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=2830" target="_blank">00:47:10.700</a></span> | <span class="t">So now that we've got these bounding boxes, here is a complexity, both a practical one</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=2837" target="_blank">00:47:17.140</a></span> | <span class="t">and a kaggle one. The kaggle complexity is the rules say you're not allowed to manually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=2841" target="_blank">00:47:21.660</a></span> | <span class="t">annotate the test set, so we can't put bounding boxes on the test set. So if, for example,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=2846" target="_blank">00:47:26.780</a></span> | <span class="t">we want to go through and crop out just the fish in every image and just train on them,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=2853" target="_blank">00:47:33.340</a></span> | <span class="t">this is not enough to do that because we can't do that on the test set because we don't have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=2857" target="_blank">00:47:37.860</a></span> | <span class="t">bounding boxes.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=2858" target="_blank">00:47:38.860</a></span> | <span class="t">The practical meaning of this is in practice, they're trying to create an automatic warning</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=2864" target="_blank">00:47:44.580</a></span> | <span class="t">system to let them know if somebody is taking the wrong kind of fish, they don't want to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=2870" target="_blank">00:47:50.260</a></span> | <span class="t">have somebody drawing a box in every one. So what we're going to do is build a model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=2876" target="_blank">00:47:56.620</a></span> | <span class="t">that can find these bounding boxes automatically. And how do we do that? It may surprise you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=2882" target="_blank">00:48:02.140</a></span> | <span class="t">to know we use exactly the same techniques that we've always used. Here is the exact</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=2888" target="_blank">00:48:08.220</a></span> | <span class="t">same model again. This time, as well as having something at the end which has 8 softmax outputs,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=2897" target="_blank">00:48:17.900</a></span> | <span class="t">we also have something which has 4 linear outputs, i.e. 4 outputs with no activation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=2904" target="_blank">00:48:24.500</a></span> | <span class="t">function. What this is saying, and then what we're going to do is when we train this model,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=2911" target="_blank">00:48:31.140</a></span> | <span class="t">we now have 2 outputs, so when we compile it, we're going to say this model has 2 outputs.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=2917" target="_blank">00:48:37.700</a></span> | <span class="t">One is the 4 outputs with no activation function, one is the 8 softmax. When I compile it, the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=2926" target="_blank">00:48:46.060</a></span> | <span class="t">first of those I want you to optimize for mean squared error, and the second of those</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=2930" target="_blank">00:48:50.820</a></span> | <span class="t">I want you to optimize for cross entropy loss. And the first of them I want you to multiply</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=2936" target="_blank">00:48:56.940</a></span> | <span class="t">the loss by 0.001 because the mean squared error of finding the location of an image</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=2944" target="_blank">00:49:04.700</a></span> | <span class="t">is going to be a much bigger number than the categorical cross entropy, so it's making</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=2948" target="_blank">00:49:08.620</a></span> | <span class="t">them about the same size. And then when you train it, I want you to use the bounding boxes</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=2954" target="_blank">00:49:14.500</a></span> | <span class="t">as the labels for the first output and the fish types as the labels for the second output.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=2962" target="_blank">00:49:22.260</a></span> | <span class="t">And so what this is going to have to do is it's going to have to figure out how to come</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=2965" target="_blank">00:49:25.260</a></span> | <span class="t">up with a bunch of dense layers which is capable of doing these 2 things simultaneously. So</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=2972" target="_blank">00:49:32.500</a></span> | <span class="t">in other words, we now have something that looks like this, 2 outputs, 1 input. And notice</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=2996" target="_blank">00:49:56.820</a></span> | <span class="t">that the 2 outputs, you don't have to do it this way, but in the way I've got it, the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=3001" target="_blank">00:50:01.460</a></span> | <span class="t">outputs both come out, both are just their own dense layer. It would be possible to do</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=3009" target="_blank">00:50:09.980</a></span> | <span class="t">it like this instead. That is to say, each of the 2 outputs could have 2 dense layers</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=3030" target="_blank">00:50:30.460</a></span> | <span class="t">of their own before. In this case though, we're going to talk about the pros and cons.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=3036" target="_blank">00:50:36.820</a></span> | <span class="t">Both of my last layers are both going to have to use the same set of features to generate</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=3042" target="_blank">00:50:42.940</a></span> | <span class="t">both the bounding boxes and the fish classes. So let's have this go. We'll just go fit as</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=3050" target="_blank">00:50:50.540</a></span> | <span class="t">usual, but now that we have 2 outputs, we get a lot more information. We get the bounding</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=3056" target="_blank">00:50:56.020</a></span> | <span class="t">box loss, we get the fishy classification loss, we get the total loss, which is equal</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=3064" target="_blank">00:51:04.060</a></span> | <span class="t">to 0.001 x bounding box, because you can see this is over 1000 times bigger than this,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=3069" target="_blank">00:51:09.020</a></span> | <span class="t">so you can see why I've got 0.001. So that's the 2 added together with that way. Then we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=3075" target="_blank">00:51:15.660</a></span> | <span class="t">get the validation loss, total bounding box loss, and the validation classification loss.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=3083" target="_blank">00:51:23.520</a></span> | <span class="t">So here is something pretty interesting. The first thing I want to point out is that after</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=3087" target="_blank">00:51:27.380</a></span> | <span class="t">I thin it a little bit, we actually get a much better accuracy. Now maybe this is counter-intuitive,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=3098" target="_blank">00:51:38.020</a></span> | <span class="t">because we're now saying our model has exactly the same capacity as before. Our previous</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=3103" target="_blank">00:51:43.100</a></span> | <span class="t">dense layer is of size 512. And before, that last layer only had to do one thing, which</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=3109" target="_blank">00:51:49.060</a></span> | <span class="t">is to tell us what kind of fish it was. Now it has to do 2 things. It has to tell us where</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=3113" target="_blank">00:51:53.580</a></span> | <span class="t">the fish is and what kind of fish it is. But yet it's still done better. Why is it done</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=3121" target="_blank">00:52:01.540</a></span> | <span class="t">better? Well the reason it's done better is because by telling it we want you to use those</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=3126" target="_blank">00:52:06.300</a></span> | <span class="t">features to figure out where the fish is, we've given it a hint about what to look for.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=3132" target="_blank">00:52:12.540</a></span> | <span class="t">We've really given it more information about what to work on. So interestingly, even if</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=3137" target="_blank">00:52:17.860</a></span> | <span class="t">we didn't use the bounding box for anything else, and just threw it away at this point,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=3142" target="_blank">00:52:22.300</a></span> | <span class="t">we already have a much better model. And do you notice also the model is much more stable</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=3146" target="_blank">00:52:26.860</a></span> | <span class="t">- 97.8, 98, 98, 98.2 - before our loss was all over the place. So by having multiple</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=3154" target="_blank">00:52:34.840</a></span> | <span class="t">outputs, we've created a much more stable, resilient and accurate classification model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=3162" target="_blank">00:52:42.900</a></span> | <span class="t">And we also have bounding boxes. The best way to look at how accurate the bounding boxes</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=3169" target="_blank">00:52:49.980</a></span> | <span class="t">are is to look at a picture.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=3173" target="_blank">00:52:53.460</a></span> | <span class="t">So I do a prediction for the first 10 validation examples. Support to use the validation set</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=3180" target="_blank">00:53:00.500</a></span> | <span class="t">anytime you're looking at how good your model is. This time I slightly increased the function</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=3187" target="_blank">00:53:07.740</a></span> | <span class="t">to show the bounding boxes to now create a yellow box for my prediction and a default</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=3193" target="_blank">00:53:13.180</a></span> | <span class="t">red box for my actual. So I just want to make it very clear here. We haven't done anything</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=3203" target="_blank">00:53:23.300</a></span> | <span class="t">clever. We didn't do anything to program this. We just said there is an output which we have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=3213" target="_blank">00:53:33.540</a></span> | <span class="t">for outputs that has no activation function. And I want you to use mean squared error to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=3221" target="_blank">00:53:41.100</a></span> | <span class="t">find a set of weights that would optimize those weights such that the bounding boxes</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=3226" target="_blank">00:53:46.860</a></span> | <span class="t">and your predictions are as close as possible. And somehow it has done that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=3235" target="_blank">00:53:55.740</a></span> | <span class="t">So that is to say, very often if you're trying to get a neural net to do something, your</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=3243" target="_blank">00:54:03.380</a></span> | <span class="t">first step before you create some complex programming heuristic thing is just ask the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=3248" target="_blank">00:54:08.900</a></span> | <span class="t">neural net to do it, and very often it does.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=3253" target="_blank">00:54:13.180</a></span> | <span class="t">Why do both in the same fitting instead of training the boxes first and feeding that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=3258" target="_blank">00:54:18.780</a></span> | <span class="t">as input to recognize fishes?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=3260" target="_blank">00:54:20.900</a></span> | <span class="t">Well, we can, right? But the first thing I want to point out is even then I would still</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=3266" target="_blank">00:54:26.220</a></span> | <span class="t">have the first stage do both at the same time because the more compatible tasks you can</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=3272" target="_blank">00:54:32.860</a></span> | <span class="t">give it, so like where is the fish and what kind of fish it is, the more it can create</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=3278" target="_blank">00:54:38.540</a></span> | <span class="t">an internal representation that is as appropriate as possible.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=3283" target="_blank">00:54:43.780</a></span> | <span class="t">Now if you now want to go away over the next couple of weeks and crop out these fish and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=3290" target="_blank">00:54:50.580</a></span> | <span class="t">create the second model, I can almost guarantee you will get into the top ten of this competition.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=3300" target="_blank">00:55:00.800</a></span> | <span class="t">And the reason I can almost guarantee that is because there was quite a similar competition</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=3303" target="_blank">00:55:03.740</a></span> | <span class="t">on Kaggle last year, or maybe earlier this year, which was trying to identify particular</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=3311" target="_blank">00:55:11.140</a></span> | <span class="t">whales and literally saying which individual whale is it, and all of the top three in that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=3320" target="_blank">00:55:20.580</a></span> | <span class="t">competition did some kind of bounding box prediction and some kind of cropping and then</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=3324" target="_blank">00:55:24.620</a></span> | <span class="t">modeled a second layer on the cropping features.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=3328" target="_blank">00:55:28.300</a></span> | <span class="t">Are the four bounding box outputs the vertical and horizontal size of the box and the two</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=3333" target="_blank">00:55:33.820</a></span> | <span class="t">coordinates for its center?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=3335" target="_blank">00:55:35.980</a></span> | <span class="t">It's whatever we were given, which was not quite that, it was the height, width, x and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=3343" target="_blank">00:55:43.100</a></span> | <span class="t">y.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=3344" target="_blank">00:55:44.100</a></span> | <span class="t">So how many of the people in this Kaggle competition are using this sort of model? And if you came</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=3356" target="_blank">00:55:56.980</a></span> | <span class="t">up with this with a bit of tinkering, do you think that you would actually stay in the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=3365" target="_blank">00:56:05.700</a></span> | <span class="t">top ten or would this just be sort of like an obvious thing that people would tend to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=3370" target="_blank">00:56:10.700</a></span> | <span class="t">do, and so your ranking would basically drop over time as everyone else incorporates this?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=3377" target="_blank">00:56:17.980</a></span> | <span class="t">So I'm going to show you a few techniques that I used this week, a few techniques I</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=3391" target="_blank">00:56:31.420</a></span> | <span class="t">used this week, but they're all very basic, they're very normal. We're at a point now</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=3398" target="_blank">00:56:38.620</a></span> | <span class="t">in this $150,000 competition where over 500 people have entered, and I am currently 20th.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=3407" target="_blank">00:56:47.420</a></span> | <span class="t">So no, the stuff that you're learning in this course is not at all well known. There's never</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=3415" target="_blank">00:56:55.180</a></span> | <span class="t">been an applied learning course before. So the people who are above me in the competition</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=3421" target="_blank">00:57:01.420</a></span> | <span class="t">are people who have figured these things out over time and read lots of papers and studied</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=3429" target="_blank">00:57:09.420</a></span> | <span class="t">and whatever else.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=3430" target="_blank">00:57:10.420</a></span> | <span class="t">So I definitely think that people in this course, particularly if somebody teamed up</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=3435" target="_blank">00:57:15.420</a></span> | <span class="t">together would have a very good chance of winning this competition because it's a perfect fit</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=3441" target="_blank">00:57:21.340</a></span> | <span class="t">for everything we've been talking about, and particularly you can collaborate on the forums</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=3446" target="_blank">00:57:26.020</a></span> | <span class="t">and stuff like that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=3449" target="_blank">00:57:29.420</a></span> | <span class="t">I should mention, I haven't done any cropping yet. This is just using the whole image, which</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=3456" target="_blank">00:57:36.140</a></span> | <span class="t">is clearly not the right way to tackle this. I was actually intentionally trying not to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=3462" target="_blank">00:57:42.780</a></span> | <span class="t">do too well because I'm going to have to release this to everybody on the Kaggle forum and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=3468" target="_blank">00:57:48.860</a></span> | <span class="t">say I've done this and here's a notebook because it's $150,000. I didn't want to say here's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=3474" target="_blank">00:57:54.540</a></span> | <span class="t">a way to get in the top 10 because that's not fair to everybody else.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=3478" target="_blank">00:57:58.540</a></span> | <span class="t">So I think to answer your question, by the end of the competition, to win one of these</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=3484" target="_blank">00:58:04.420</a></span> | <span class="t">things, you've got to do everything right at every point. Every time you fail, you have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=3490" target="_blank">00:58:10.380</a></span> | <span class="t">to keep trying again. Tenacity is part of winning these things. I know from experience</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=3494" target="_blank">00:58:14.740</a></span> | <span class="t">the feeling of being on top of the leaderboard and waking up the next day and finding that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=3499" target="_blank">00:58:19.140</a></span> | <span class="t">five people have passed you. But the thing is, you then know they have found something</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=3505" target="_blank">00:58:25.060</a></span> | <span class="t">that is there and you haven't found it. That's part of what makes competing in the Kaggle</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=3509" target="_blank">00:58:29.780</a></span> | <span class="t">competition so different to doing academic papers or looking at old Kaggle competitions</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=3515" target="_blank">00:58:35.780</a></span> | <span class="t">that are long gone. It's a really great test of your own processes and your own grit. What</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=3525" target="_blank">00:58:45.740</a></span> | <span class="t">you'll probably find yourself doing is repeatedly fucking around with hyperparameters and minor</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=3533" target="_blank">00:58:53.020</a></span> | <span class="t">architectural details because it's just so addictive until eventually you go away and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=3538" target="_blank">00:58:58.300</a></span> | <span class="t">go 'okay, what's a totally different way of thinking about this problem?'</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=3543" target="_blank">00:59:03.340</a></span> | <span class="t">So I hope some of you will consider seriously investing in putting an hour a day into a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=3550" target="_blank">00:59:10.700</a></span> | <span class="t">competition because I learned far more doing that than everything else I've ever done in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=3556" target="_blank">00:59:16.660</a></span> | <span class="t">machine learning. It's totally different to just playing around. And after it, it's something</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=3565" target="_blank">00:59:25.660</a></span> | <span class="t">that every real-world project I've done is greatly better than that experience.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=3572" target="_blank">00:59:32.660</a></span> | <span class="t">To give you a sense of this, here's number 6. I can't even see that fish, but it's done</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=3586" target="_blank">00:59:46.260</a></span> | <span class="t">a pretty good job. And I think maybe it kind of knows that people tend to float around</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=3592" target="_blank">00:59:52.220</a></span> | <span class="t">where the fish is or something, because it's pretty hard to see. As you can see, this is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=3595" target="_blank">00:59:55.860</a></span> | <span class="t">just a 224x224 image. So this model is doing a pretty great job, and the amount of time</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=3602" target="_blank">01:00:02.780</a></span> | <span class="t">we took to train was under 10 seconds.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=3606" target="_blank">01:00:06.340</a></span> | <span class="t">I've got a section here on data augmentation. Before we look at finding things without manually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=3632" target="_blank">01:00:32.180</a></span> | <span class="t">annotating bounding boxes, I'd like to talk more about different size images.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=3636" target="_blank">01:00:36.660</a></span> | <span class="t">So let's talk about sizes. Let's specifically talk about in which situations is our model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=3646" target="_blank">01:00:46.300</a></span> | <span class="t">going to be sensitive to the size of the input, like a pre-trained model with pre-trained weights.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=3656" target="_blank">01:00:56.020</a></span> | <span class="t">And it's all about what are these layer operations exactly? If it's a dense layer, then there's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=3665" target="_blank">01:01:05.420</a></span> | <span class="t">a weight going from every input to every output. And so if you have a different sized input,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=3674" target="_blank">01:01:14.420</a></span> | <span class="t">then that's not going to work at all, because the weight matrix for your dense layer is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=3679" target="_blank">01:01:19.020</a></span> | <span class="t">just simply of the wrong size. Who knows what it should do. What if it's a convolutional</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=3686" target="_blank">01:01:26.700</a></span> | <span class="t">layer? If it's a convolutional layer, then we have a little set of weights for each 3x3</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=3697" target="_blank">01:01:37.260</a></span> | <span class="t">block for each different feature, and then that 3x3 block is going to be slid over to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=3702" target="_blank">01:01:42.060</a></span> | <span class="t">create the outputs. If the image is bigger, it doesn't change the number of weights. It</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=3709" target="_blank">01:01:49.820</a></span> | <span class="t">just means that block is going to be slid around more, and the output will be bigger.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=3716" target="_blank">01:01:56.300</a></span> | <span class="t">A max pooling layer doesn't have any weights. A batch normalization layer simply cares about</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=3723" target="_blank">01:02:03.340</a></span> | <span class="t">the number of weights of the previous layer. So really, when you think about it, the only</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=3728" target="_blank">01:02:08.700</a></span> | <span class="t">layer that really cares about what size your input is is a dense layer. And remember that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=3734" target="_blank">01:02:14.820</a></span> | <span class="t">with VGG, nearly all of the layers are convolutional layers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=3740" target="_blank">01:02:20.300</a></span> | <span class="t">So that's why it is that we can say not only include top = false, we can say not only include</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=3750" target="_blank">01:02:30.260</a></span> | <span class="t">top = false, but we can also choose what size we want. So if you look at my new version</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=3761" target="_blank">01:02:41.780</a></span> | <span class="t">of the VGG model, I've actually got something here that says if size is not equal to 224</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=3771" target="_blank">01:02:51.740</a></span> | <span class="t">then don't try to add the fully connected blocks at all, just return that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=3786" target="_blank">01:03:06.400</a></span> | <span class="t">So in other words, if we cut off whatever our architecture is before any dense layers</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=3792" target="_blank">01:03:12.940</a></span> | <span class="t">happen, then we're going to be able to use it on any size input to at least create those</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=3799" target="_blank">01:03:19.380</a></span> | <span class="t">convolutional features.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=3810" target="_blank">01:03:30.380</a></span> | <span class="t">There's no particular reason it has to be fixed. A dense layer has to be fixed because</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=3815" target="_blank">01:03:35.380</a></span> | <span class="t">a dense layer has a specific weight matrix. And the input to that weight matrix generally</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=3821" target="_blank">01:03:41.000</a></span> | <span class="t">is the flattened out version of the previous convolutional layer, and the size of that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=3826" target="_blank">01:03:46.660</a></span> | <span class="t">depends on the size of the image. But the convolutional weight matrix simply depends</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=3833" target="_blank">01:03:53.280</a></span> | <span class="t">on the filter size, not on the image size.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=3838" target="_blank">01:03:58.540</a></span> | <span class="t">So let's try it. And specifically we're going to try building something called a fully convolutional</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=3846" target="_blank">01:04:06.220</a></span> | <span class="t">net, which is going to have no dense layers at all. So the input, as usual, will be the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=3852" target="_blank">01:04:12.780</a></span> | <span class="t">output of the last VGG convolutional layer. But this time, when we create our VGG 16 model,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=3871" target="_blank">01:04:31.660</a></span> | <span class="t">we're going to tell it we want it to be 640 by 360.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=3875" target="_blank">01:04:35.980</a></span> | <span class="t">Now be careful here. When we talk about matrices, we talk about rows by columns. When we talk</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=3882" target="_blank">01:04:42.880</a></span> | <span class="t">about images, we talk about columns by rows. So a 640 by 360 image is a 360 by 640 matrix.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=3892" target="_blank">01:04:52.700</a></span> | <span class="t">I mention this because I screwed it up. But I knew I screwed it up because I always draw</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=3897" target="_blank">01:04:57.100</a></span> | <span class="t">pictures. So when I drew the picture and saw this little squashed boat, I knew that I'd</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=3903" target="_blank">01:05:03.340</a></span> | <span class="t">screwed it up.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=3906" target="_blank">01:05:06.180</a></span> | <span class="t">This is the exact same VGG-16 network we've been using since I added batch norm. So nothing's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=3916" target="_blank">01:05:16.540</a></span> | <span class="t">been changed other than this one piece of code I just showed you which says you can</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=3921" target="_blank">01:05:21.740</a></span> | <span class="t">use different sizes, and if you do, don't add the fully connected layers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=3931" target="_blank">01:05:31.380</a></span> | <span class="t">So now that I've got this VGG model which is expecting a 640 by 360 input, I can then</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=3940" target="_blank">01:05:40.980</a></span> | <span class="t">add to it my top layers. And this time, my top layers are going to get in an input which</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=3949" target="_blank">01:05:49.380</a></span> | <span class="t">is of size 22 by 40. So normally, our VGG's final layer is 14 by 14, or if you include</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=3959" target="_blank">01:05:59.460</a></span> | <span class="t">the final max pooling, it's 7 by 7. In this case, it's 22 by 40, and that's because we've</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=3967" target="_blank">01:06:07.180</a></span> | <span class="t">told it we're not going to pass it a 224 by 224, we're going to pass it a 640 by 360.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=3973" target="_blank">01:06:13.540</a></span> | <span class="t">So this is what happens. We end up with a different output shape. So if we now try to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=3978" target="_blank">01:06:18.540</a></span> | <span class="t">pass that to the same dense layer we used before, it wouldn't work, so it would be the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=3981" target="_blank">01:06:21.900</a></span> | <span class="t">wrong size. But we're actually going to do something very different anyway, we're not</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=3986" target="_blank">01:06:26.620</a></span> | <span class="t">going to use any pre-trained fully connected weights. We're instead going to have, in fact,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=3994" target="_blank">01:06:34.220</a></span> | <span class="t">no dense layers at all. Instead, we're going to go conv.maxpool, conv.maxpool, conv.maxpool,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=4004" target="_blank">01:06:44.780</a></span> | <span class="t">global average pooling.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=4007" target="_blank">01:06:47.100</a></span> | <span class="t">So the best way to look at that is to see what's happening to our shape. So it goes</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=4013" target="_blank">01:06:53.900</a></span> | <span class="t">in 22 by 40 until the max pooling, 11 by 20 until the max pooling, 5 by 10. And then because</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=4021" target="_blank">01:07:01.340</a></span> | <span class="t">this is rectangular, the last max pooling I did a 1,2 shape, so that gives me a square</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=4027" target="_blank">01:07:07.860</a></span> | <span class="t">result, so 5 by 5.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=4032" target="_blank">01:07:12.740</a></span> | <span class="t">Then I do a convolutional layer in which I have just 8 filters. And remember, there are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=4039" target="_blank">01:07:19.380</a></span> | <span class="t">8 types of fish. There are no other weights after this. And in fact, even the dropout</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=4045" target="_blank">01:07:25.020</a></span> | <span class="t">is not doing anything because I've set my p value to 0. So ignore that dropout layer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=4051" target="_blank">01:07:31.220</a></span> | <span class="t">So we're going straight from a convolutional layer, which is going to be grid size 5 by</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=4055" target="_blank">01:07:35.700</a></span> | <span class="t">5, and have 8 filters, and then we're going to average across the 5 by 5, and that's going</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=4062" target="_blank">01:07:42.580</a></span> | <span class="t">to give us something of size 8.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=4067" target="_blank">01:07:47.780</a></span> | <span class="t">So if we now say, please train this model, and please try and make these 8 things equal</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=4073" target="_blank">01:07:53.420</a></span> | <span class="t">to the classes of fish. Now you have to think backwards. How would it do that? If it was</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=4079" target="_blank">01:07:59.940</a></span> | <span class="t">to do that for us, and it will because it's going to use SGD, what would it have to do?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=4085" target="_blank">01:08:05.940</a></span> | <span class="t">Well it has no ability to use any weights to get to this point, so it has to do everything</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=4093" target="_blank">01:08:13.300</a></span> | <span class="t">by the time it gets to this point. Which means this convolution2D layer is going to have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=4098" target="_blank">01:08:18.380</a></span> | <span class="t">to have in each of its 5 grid areas something saying, how fishy is that area? Because that's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=4104" target="_blank">01:08:24.260</a></span> | <span class="t">all it can do. After that, all it can do is to average them together.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=4108" target="_blank">01:08:28.860</a></span> | <span class="t">So we haven't done anything specifically to calculate it that way, we just created an</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=4113" target="_blank">01:08:33.900</a></span> | <span class="t">architecture that has to do that. Now my feeling is that ought to work pretty well because</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=4118" target="_blank">01:08:38.940</a></span> | <span class="t">as we saw in that earlier picture, the fish only appears in one little spot. And indeed</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=4124" target="_blank">01:08:44.260</a></span> | <span class="t">as we discussed earlier, maybe even a global max pooling could even be better.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=4130" target="_blank">01:08:50.500</a></span> | <span class="t">So let's try this. We can fit it as per usual, and you can see here even without using bounding</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=4136" target="_blank">01:08:56.140</a></span> | <span class="t">boxes, we've got a pretty stable and pretty good result in about 30 seconds, 97.6.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=4145" target="_blank">01:09:05.420</a></span> | <span class="t">When I then tried this on the Kaggle leaderboard, I got a much better result. In fact to show</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=4152" target="_blank">01:09:12.100</a></span> | <span class="t">you my submissions, the 20th place was me just averaging together 4 different models,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=4165" target="_blank">01:09:25.300</a></span> | <span class="t">4 of the models that I'm showing you today. But this one on its own was 0.986, which would</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=4182" target="_blank">01:09:42.100</a></span> | <span class="t">be 20 seconds. So this model on its own would get its 20 second position. And no data augmentation,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=4195" target="_blank">01:09:55.820</a></span> | <span class="t">no pseudo-labeling, we're not using the validation set to help us, which you should when you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=4201" target="_blank">01:10:01.460</a></span> | <span class="t">do your final Kaggle entry.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=4205" target="_blank">01:10:05.060</a></span> | <span class="t">So you can get 20 second position with this very simple approach, which is to use a slightly</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=4210" target="_blank">01:10:10.420</a></span> | <span class="t">larger image and use a fully convolutional network. There's something else cool about</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=4216" target="_blank">01:10:16.220</a></span> | <span class="t">this fully convolutional network, which can get us into 20 second position. And that is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=4221" target="_blank">01:10:21.060</a></span> | <span class="t">that we can actually look at the output of this layer, and remember it's 5x5.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=4229" target="_blank">01:10:29.340</a></span> | <span class="t">How are you using VGG?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=4240" target="_blank">01:10:40.620</a></span> | <span class="t">VGG, as always before, is the input to this model. So I first of all calculated every</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=4247" target="_blank">01:10:47.060</a></span> | <span class="t">single model I'm showing you today, I pre-computed the output of the last convolutional layer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=4252" target="_blank">01:10:52.020</a></span> | <span class="t">in VGG.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=4260" target="_blank">01:11:00.180</a></span> | <span class="t">So I go get data, and I say I want to get a 360, 640 sized data, and so that gives me</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=4268" target="_blank">01:11:08.100</a></span> | <span class="t">my image, and then I -- this is data augmentation which I'm not doing at the moment, I then</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=4279" target="_blank">01:11:19.580</a></span> | <span class="t">create my model, pop off the last layer, because I don't want the last max pooling layer, so</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=4285" target="_blank">01:11:25.780</a></span> | <span class="t">that's the size, and then call predict to get the features from that last layer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=4297" target="_blank">01:11:37.960</a></span> | <span class="t">So it's what we always do, it's just the only difference is that we passed 360, 640 to our</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=4304" target="_blank">01:11:44.140</a></span> | <span class="t">constructor for the model, and we passed 360, 640 to the get data command.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=4313" target="_blank">01:11:53.500</a></span> | <span class="t">I'm always skipping that bit, but everything I'm showing you today is taking as input the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=4325" target="_blank">01:12:05.220</a></span> | <span class="t">last convolutional layer from VGG.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=4335" target="_blank">01:12:15.580</a></span> | <span class="t">A couple of reasons why. The first because the authors of the paper which created the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=4340" target="_blank">01:12:20.060</a></span> | <span class="t">fully convolutional net found that it worked pretty well. The global average pooling 2D</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=4347" target="_blank">01:12:27.500</a></span> | <span class="t">layer has been discussed, turns out to have excellent generalization characteristics.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=4351" target="_blank">01:12:31.100</a></span> | <span class="t">So you'll notice here we have no dropout, and yet we're in 22nd place on the leaderboard</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=4357" target="_blank">01:12:37.180</a></span> | <span class="t">without even beginning to try.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=4362" target="_blank">01:12:42.380</a></span> | <span class="t">And then the final reason is the thing I'm about to show you, which is that we basically</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=4366" target="_blank">01:12:46.700</a></span> | <span class="t">have maintained a sense of kind of x-y coordinates all the way through, which means that we can</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=4377" target="_blank">01:12:57.100</a></span> | <span class="t">actually now visualize this last layer. And I want to do that before I take the next question.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=4385" target="_blank">01:13:05.380</a></span> | <span class="t">So I can say, let's create a function which takes our model's input as input and our fourth</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=4394" target="_blank">01:13:14.060</a></span> | <span class="t">from last layer as output, that is that convolutional layer that I showed you.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=4399" target="_blank">01:13:19.740</a></span> | <span class="t">And then I'm going to take that and I'm going to pass into it the features of my first validation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=4408" target="_blank">01:13:28.780</a></span> | <span class="t">image and draw a picture of it for this picture, and here is my picture. And so you can see</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=4418" target="_blank">01:13:38.900</a></span> | <span class="t">it's done exactly what we thought it would do, which is it's had to figure out that there's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=4422" target="_blank">01:13:42.380</a></span> | <span class="t">a fishy bit here. So these fully convolutional networks have a nice side effect, which is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=4431" target="_blank">01:13:51.900</a></span> | <span class="t">that they allow us to find whereabouts the interesting parts are.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=4436" target="_blank">01:13:56.940</a></span> | <span class="t">The default parameters for max pooling are 2,2, so it's taking each 2x2 square and replacing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=4453" target="_blank">01:14:13.820</a></span> | <span class="t">it with the largest value in that 2x2 square. So this is not the most high-res heat map</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=4461" target="_blank">01:14:21.300</a></span> | <span class="t">we've ever seen. So the obvious thing to make it all more high-res would be to remove all</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=4466" target="_blank">01:14:26.460</a></span> | <span class="t">the max pooling layers. So here's exactly the same thing as before, but I've removed</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=4471" target="_blank">01:14:31.500</a></span> | <span class="t">all the max pooling layers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=4474" target="_blank">01:14:34.060</a></span> | <span class="t">So that means that my model now remains at 22x40 all the way through, everything else</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=4481" target="_blank">01:14:41.220</a></span> | <span class="t">is the same. And that indeed does not give quite as accurate a result, we get 95.2 rather</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=4490" target="_blank">01:14:50.540</a></span> | <span class="t">than 97.6. On the other hand, we do have a much higher resolution grid, so if we now</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=4501" target="_blank">01:15:01.020</a></span> | <span class="t">do exactly the same thing to create the heat map, and the other thing we're going to do</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=4506" target="_blank">01:15:06.140</a></span> | <span class="t">is resize the heat map to 360x640, and by default, this resize command will try and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=4513" target="_blank">01:15:13.300</a></span> | <span class="t">interpolate. So it's going to replace big pixels with interpolated small pixels.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=4520" target="_blank">01:15:20.420</a></span> | <span class="t">And that gives us, for this image, this answer, which is much more interesting. And so now</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=4528" target="_blank">01:15:28.780</a></span> | <span class="t">we can stick one on top of the other, like so. And this tells us a lot. It tells us that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=4538" target="_blank">01:15:38.340</a></span> | <span class="t">on the whole, this is doing a good job of saying the thing that mattered, the fishy</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=4542" target="_blank">01:15:42.860</a></span> | <span class="t">thing, the albacore thing specifically, because we're asking here for the albacore plus. Remember,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=4550" target="_blank">01:15:50.140</a></span> | <span class="t">the layer, that layer of the model is 8x22x40, so we have to ask how much like albacore is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=4559" target="_blank">01:15:59.820</a></span> | <span class="t">each of those areas, or how much like shark is each of those areas.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=4563" target="_blank">01:16:03.460</a></span> | <span class="t">So when we called this function, it returned basically a heat map for every type of fish,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=4573" target="_blank">01:16:13.620</a></span> | <span class="t">and so we can pass in 0 for albacore, or here's a cool one. Class number 4 is nofish. So one</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=4583" target="_blank">01:16:23.940</a></span> | <span class="t">of the classes you have to predict in this competition is nofish. So we could say, tell</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=4588" target="_blank">01:16:28.540</a></span> | <span class="t">us how much each part of this picture looks like the nofish class. What happens is if</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=4594" target="_blank">01:16:34.860</a></span> | <span class="t">you look at the nofish version, it's basically the exact opposite of this. You get a big</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=4599" target="_blank">01:16:39.620</a></span> | <span class="t">blue spot here, and pink or round it. The other thing I wanted to point out here is these</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=4608" target="_blank">01:16:48.380</a></span> | <span class="t">areas of pinkishness that are not where the fish is. This is telling me that our model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=4614" target="_blank">01:16:54.500</a></span> | <span class="t">is not currently just looking for fish. It's also looking, if we look at this pink here,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=4621" target="_blank">01:17:01.100</a></span> | <span class="t">it's looking for particular characteristics of the boat.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=4626" target="_blank">01:17:06.860</a></span> | <span class="t">So this is suggesting to me that since it's not all concentrated on the fish, I do think</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=4632" target="_blank">01:17:12.740</a></span> | <span class="t">that there's some data leakage still coming through.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=4637" target="_blank">01:17:17.180</a></span> | <span class="t">I think we know everything about why it's working. We have set up a model where we've</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=4657" target="_blank">01:17:37.700</a></span> | <span class="t">said we want you to predict each of the 8 fish classes. We have set it up such that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=4668" target="_blank">01:17:48.860</a></span> | <span class="t">the last layer simply averages the answers from the previous layer. The previous layer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=4675" target="_blank">01:17:55.300</a></span> | <span class="t">we have set up so it has the 8 classes we need. So that's obviously the only way you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=4680" target="_blank">01:18:00.500</a></span> | <span class="t">can average and get the right number of classes. We know that SGD is a general optimization</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=4687" target="_blank">01:18:07.780</a></span> | <span class="t">approach which will find a set of parameters which solves the problem that you give it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=4693" target="_blank">01:18:13.620</a></span> | <span class="t">and we've given it that problem.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=4695" target="_blank">01:18:15.740</a></span> | <span class="t">So really, when you think of it that way, unless it failed to train, which it could</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=4703" target="_blank">01:18:23.500</a></span> | <span class="t">for all kinds of reasons, unless it failed to train, it could only get a decent answer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=4711" target="_blank">01:18:31.360</a></span> | <span class="t">if it solved it in this way. If it actually looked at each area and figured out how fishy</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=4715" target="_blank">01:18:35.940</a></span> | <span class="t">it is.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=4716" target="_blank">01:18:36.940</a></span> | <span class="t">We're not doing attention models in this part of the course, per se. I would say for now,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=4731" target="_blank">01:18:51.940</a></span> | <span class="t">the simple attention model that I would do would be to find the largest area of the heat</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=4738" target="_blank">01:18:58.980</a></span> | <span class="t">mat and crop that, and maybe compare that to the bounding boxes and make sure they look</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=4745" target="_blank">01:19:05.860</a></span> | <span class="t">about the same and those that don't, you might want to hand fix. And if you hand fix them,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=4750" target="_blank">01:19:10.860</a></span> | <span class="t">you have to give that back to the Kaggle community of course because that's hand labeling.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=4757" target="_blank">01:19:17.700</a></span> | <span class="t">And honestly, that's the state of the art. In terms of who wins the money in Kaggle,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=4765" target="_blank">01:19:25.540</a></span> | <span class="t">that's how the Kaggle winners have won these kinds of competitions is by having a two-stage</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=4771" target="_blank">01:19:31.220</a></span> | <span class="t">pipeline where first of all they find the thing of interest and then they zoom into</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=4775" target="_blank">01:19:35.380</a></span> | <span class="t">it and then they do a model on that thing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=4780" target="_blank">01:19:40.220</a></span> | <span class="t">Actually the other thing that you might want to do is to orient the fish so that the tail</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=4787" target="_blank">01:19:47.420</a></span> | <span class="t">is kind of in the same place and the head is in the same place. Make it as easy as possible</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=4792" target="_blank">01:19:52.100</a></span> | <span class="t">basically for your consonant to do what it needs to do.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=4803" target="_blank">01:20:03.020</a></span> | <span class="t">You guys might have heard of another architecture called Inception. A combination of Inception</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=4809" target="_blank">01:20:09.580</a></span> | <span class="t">plus ResNet won this year's ImageNet competition. And I want to give you a very quick hint as</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=4821" target="_blank">01:20:21.300</a></span> | <span class="t">to how it works. I have built the world's tiniest little Inception network here in this screen.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=4831" target="_blank">01:20:31.700</a></span> | <span class="t">One of the reasons I want to show it to you is because it actually uses the same technique</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=4836" target="_blank">01:20:36.060</a></span> | <span class="t">that we heard from Ben Bowles that he used. Do you remember in his language model, Quid,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=4842" target="_blank">01:20:42.940</a></span> | <span class="t">Ben used a trick where he had multiple different convolution filter sizes and ran all of them</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=4849" target="_blank">01:20:49.680</a></span> | <span class="t">and concatenated them together? That's actually what the Inception network does.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=4869" target="_blank">01:21:09.880</a></span> | <span class="t">To align the head and tail, the easiest way would be to hand annotate the head and hand</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=4874" target="_blank">01:21:14.300</a></span> | <span class="t">annotate the tail. That was what was done in the whale competition.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=4890" target="_blank">01:21:30.540</a></span> | <span class="t">Hand labeling always has errors, and indeed there are quite a few people in the forum</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=4895" target="_blank">01:21:35.340</a></span> | <span class="t">who have various bounding boxes that they don't think are correct. It's great to have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=4899" target="_blank">01:21:39.780</a></span> | <span class="t">an automatic approach which ought to give about the same answer as the hand approach,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=4904" target="_blank">01:21:44.740</a></span> | <span class="t">and you can then compare the two and use the best of both worlds.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=4910" target="_blank">01:21:50.460</a></span> | <span class="t">And in general, this idea of combining human intelligence and machine intelligence seems</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=4915" target="_blank">01:21:55.640</a></span> | <span class="t">to be a great approach, particularly early on. You can do that for the first few bounding</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=4921" target="_blank">01:22:01.140</a></span> | <span class="t">boxes to improve your bounding box model and then use that to gradually make the model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=4931" target="_blank">01:22:11.380</a></span> | <span class="t">have to ask you less and less for your input.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=4960" target="_blank">01:22:40.080</a></span> | <span class="t">The heatmap you don't need to. The heatmap was just visualizing one of the layers of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=4970" target="_blank">01:22:50.700</a></span> | <span class="t">the network. We didn't use the bounding boxes, we didn't do anything special. It's just a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=4976" target="_blank">01:22:56.620</a></span> | <span class="t">side effect of this kind of model. You can visualize the last convolutional layer and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=4982" target="_blank">01:23:02.460</a></span> | <span class="t">in doing so we'll give you a heatmap.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=4994" target="_blank">01:23:14.820</a></span> | <span class="t">There's so many ways of interpreting neural nets, and one of them is to draw pictures</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=4999" target="_blank">01:23:19.160</a></span> | <span class="t">of the intermediate activations. You can also draw pictures of the intermediate gradients.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=5004" target="_blank">01:23:24.520</a></span> | <span class="t">There's all kinds of things you can draw pictures of.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=5018" target="_blank">01:23:38.300</a></span> | <span class="t">The Inception network is going to use this trick where we're going to use multiple different</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=5036" target="_blank">01:23:56.120</a></span> | <span class="t">convolutional filter sizes. Just like in ResNet, there's this idea of a ResNet block which is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=5050" target="_blank">01:24:10.520</a></span> | <span class="t">repeated again and again. In the Inception network, there's an Inception block which</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=5054" target="_blank">01:24:14.620</a></span> | <span class="t">is repeated again and again. I've created a version of one here. I have one thing which</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=5062" target="_blank">01:24:22.400</a></span> | <span class="t">takes my input and does a 1x1 convolution. I've got one thing that takes the input and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=5067" target="_blank">01:24:27.320</a></span> | <span class="t">does a 5x5 convolution. I've got one thing that takes the input and does 2 3x3 convolutions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=5073" target="_blank">01:24:33.560</a></span> | <span class="t">I've got one thing that takes the input and just average pulls it. And then we concatenate</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=5079" target="_blank">01:24:39.000</a></span> | <span class="t">them all together.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=5080" target="_blank">01:24:40.640</a></span> | <span class="t">So what this is doing is each Inception block is basically able to look for things at various</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=5086" target="_blank">01:24:46.560</a></span> | <span class="t">different scales and create a single feature map at the end which adds all those things</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=5092" target="_blank">01:24:52.600</a></span> | <span class="t">together.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=5094" target="_blank">01:24:54.600</a></span> | <span class="t">So once I've defined that, I can create a model that just goes Inception block, Inception</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=5098" target="_blank">01:24:58.760</a></span> | <span class="t">block, Inception block, Comm2D, global average pulling 2D, output. I haven't managed to get</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=5105" target="_blank">01:25:05.600</a></span> | <span class="t">this to work terribly well yet. I've got the same kind of results. I haven't actually tried</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=5111" target="_blank">01:25:11.840</a></span> | <span class="t">submitting this to Kaggle. Part of the purpose of this is to give you guys a sense of the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=5123" target="_blank">01:25:23.040</a></span> | <span class="t">kinds of things we'll be doing next year. This idea of we've built the basic pieces</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=5128" target="_blank">01:25:28.920</a></span> | <span class="t">now of convolutions, fully connected layers, activation functions, SGD, and really from</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=5138" target="_blank">01:25:38.800</a></span> | <span class="t">here, deep learning is putting these pieces together. What are the ways people have learned</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=5143" target="_blank">01:25:43.400</a></span> | <span class="t">about putting these things together in ways that solve problems as well as possible?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=5150" target="_blank">01:25:50.200</a></span> | <span class="t">And so the Inception network is one of these ways. And the other thing I wanted to do was</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=5154" target="_blank">01:25:54.000</a></span> | <span class="t">to give you plenty of things to think about over the next couple of months and play with.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=5158" target="_blank">01:25:58.840</a></span> | <span class="t">So hopefully this notebook is going to be full of things you can experiment with and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=5163" target="_blank">01:26:03.800</a></span> | <span class="t">maybe even try submitting some Kaggle results.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=5170" target="_blank">01:26:10.240</a></span> | <span class="t">I guess the warnings about the Inception network are a bit similar to the warnings about the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=5173" target="_blank">01:26:13.440</a></span> | <span class="t">ResNet network. Like ResNet, the Inception network is available, actually Keras. I haven't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=5180" target="_blank">01:26:20.440</a></span> | <span class="t">converted one to my standard approach, but Keras has an Inception network that you can</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=5185" target="_blank">01:26:25.960</a></span> | <span class="t">download and use. It hasn't been well-studied in terms of its transfer learning capabilities.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=5196" target="_blank">01:26:36.040</a></span> | <span class="t">Again I haven't seen people who have won Kaggle competitions using transfer learning of Inception</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=5202" target="_blank">01:26:42.160</a></span> | <span class="t">network, so it's just a little bit less well-studied. But like ResNet, the combination of Inception</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=5210" target="_blank">01:26:50.120</a></span> | <span class="t">plus ResNet is the most recent image network. So if you are looking to really start with</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=5216" target="_blank">01:26:56.760</a></span> | <span class="t">the most predictive model, this is where you would want to start.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=5222" target="_blank">01:27:02.600</a></span> | <span class="t">So I want to finish off on a very different note, which is looking at RNNs. I've spent</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=5236" target="_blank">01:27:16.840</a></span> | <span class="t">much more time on CNNs than RNNs. The reason is that this course is really all about being</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=5243" target="_blank">01:27:23.200</a></span> | <span class="t">pragmatic. It's about teaching you the stuff that works, and in the vast majority of areas</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=5249" target="_blank">01:27:29.080</a></span> | <span class="t">where I see people using deep learning to solve their problems, they're using CNNs.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=5258" target="_blank">01:27:38.520</a></span> | <span class="t">Having said that, some of the most challenging problems are now being solved with RNNs like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=5265" target="_blank">01:27:45.160</a></span> | <span class="t">speech recognition and language translation. So when you use Google Translate now, you're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=5271" target="_blank">01:27:51.000</a></span> | <span class="t">using RNNs. My suspicion is you're going to come across these kinds of problems a lot</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=5278" target="_blank">01:27:58.120</a></span> | <span class="t">less often, but I also suspect that in a business context, a very common kind of problem is a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=5286" target="_blank">01:28:06.400</a></span> | <span class="t">time series problem, like looking at the time series of click events on your website or</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=5293" target="_blank">01:28:13.080</a></span> | <span class="t">e-commerce transactions or logistics or whatever.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=5300" target="_blank">01:28:20.000</a></span> | <span class="t">These sequence-to-sequence RNNs we've been looking at, which we've been using to create</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=5305" target="_blank">01:28:25.240</a></span> | <span class="t">Nietzschean philosophy, are identical to the ones you would use to analyze a sequence of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=5311" target="_blank">01:28:31.680</a></span> | <span class="t">e-commerce transactions and try to find anomalies.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=5315" target="_blank">01:28:35.400</a></span> | <span class="t">So I think CNNs are more practically important for most people in most organizations right</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=5323" target="_blank">01:28:43.320</a></span> | <span class="t">now, but RNNs also have a lot of opportunities, and of course we'll also be looking at them</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=5330" target="_blank">01:28:50.880</a></span> | <span class="t">when it comes to attentional models next year, which is figuring out in a really big image</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=5336" target="_blank">01:28:56.360</a></span> | <span class="t">which part should we look at next.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=5338" target="_blank">01:28:58.200</a></span> | <span class="t">Question - Does Inception have the merge characteristic?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=5345" target="_blank">01:29:05.040</a></span> | <span class="t">The Inception merge is a concat rather than that, which is the same as what we saw when</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=5349" target="_blank">01:29:09.720</a></span> | <span class="t">we looked at Ben Bowles' quid NLP model. We're taking multiple convolution filter sizes and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=5360" target="_blank">01:29:20.160</a></span> | <span class="t">we're sticking them next to each other. So that feature basically contains information</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=5367" target="_blank">01:29:27.240</a></span> | <span class="t">about 5x5 features and 3x3 features and 1x1 features.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=5372" target="_blank">01:29:32.920</a></span> | <span class="t">And so when you add them together, you lose that information. ResNet does that for a very</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=5377" target="_blank">01:29:37.800</a></span> | <span class="t">specific reason, which is we want to cause at all our residuals. In Inception, we don't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=5383" target="_blank">01:29:43.600</a></span> | <span class="t">want that. Inception, we want to keep them all in the feature space.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=5395" target="_blank">01:29:55.280</a></span> | <span class="t">The other reason I wanted to look at RNNs is that last week we looked at building an</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=5402" target="_blank">01:30:02.600</a></span> | <span class="t">RNN nearly from scratch in Theano. And I say nearly from scratch because there was one</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=5409" target="_blank">01:30:09.460</a></span> | <span class="t">key step which it did for us, which was the gradients. Really understanding how the gradients</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=5419" target="_blank">01:30:19.040</a></span> | <span class="t">are calculated is not something you would probably ever have to do by hand, but I think</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=5425" target="_blank">01:30:25.600</a></span> | <span class="t">it can be very helpful to your intuition of training neural networks to be able to trace</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=5432" target="_blank">01:30:32.280</a></span> | <span class="t">it through.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=5433" target="_blank">01:30:33.280</a></span> | <span class="t">And so for that reason, this is kind of the one time in this course over this year and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=5437" target="_blank">01:30:37.640</a></span> | <span class="t">next year's course where we're going to really go through and actually calculate the gradients</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=5442" target="_blank">01:30:42.840</a></span> | <span class="t">ourselves. So here is a recurrent neural network in pure Python. And the reason I'm doing a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=5449" target="_blank">01:30:49.720</a></span> | <span class="t">recurrent neural network in pure Python is this is kind of the hardest. RNNs are the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=5454" target="_blank">01:30:54.200</a></span> | <span class="t">hardest thing to get your head around backpropagating gradients. So if you look at this and study</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=5460" target="_blank">01:31:00.720</a></span> | <span class="t">this and step through this over the next couple of months, you will really be able to get</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=5464" target="_blank">01:31:04.720</a></span> | <span class="t">a great understanding of what a neural net is really doing. There's going to be no magic</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=5469" target="_blank">01:31:09.160</a></span> | <span class="t">or mystery because this whole thing is going to be every line of code, something that you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=5473" target="_blank">01:31:13.600</a></span> | <span class="t">can see and play with.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=5475" target="_blank">01:31:15.560</a></span> | <span class="t">So if we're going to do it all ourselves, we have to write everything ourselves. So</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=5481" target="_blank">01:31:21.560</a></span> | <span class="t">if we want a sigmoid function, we have to write the sigmoid function. Any time we write</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=5485" target="_blank">01:31:25.680</a></span> | <span class="t">any function, we also have to create this derivative. So I'm going to use this approach</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=5491" target="_blank">01:31:31.520</a></span> | <span class="t">where _d is the derivative function. So I'm going to have relu and the derivative of relu.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=5500" target="_blank">01:31:40.280</a></span> | <span class="t">And I'll just kind of check myself as I go along that they look reasonable. The Euclidean</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=5505" target="_blank">01:31:45.040</a></span> | <span class="t">distance and the derivative of the Euclidean distance.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=5510" target="_blank">01:31:50.520</a></span> | <span class="t">The cross entropy and the derivative of the cross entropy. And note here that I am clipping</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=5516" target="_blank">01:31:56.560</a></span> | <span class="t">my predictions because if you have zeros or ones there, you're going to get infinities</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=5522" target="_blank">01:32:02.860</a></span> | <span class="t">and it destroys everything.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=5524" target="_blank">01:32:04.800</a></span> | <span class="t">So you have to be careful of this. This did actually happen. I didn't have this Euclidean</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=5528" target="_blank">01:32:08.800</a></span> | <span class="t">at first and I was starting to get infinities and this is necessary. My softmax is the derivative</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=5535" target="_blank">01:32:15.560</a></span> | <span class="t">of softmax.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=5538" target="_blank">01:32:18.560</a></span> | <span class="t">So then I basically go through and I double check that the answers I get with my versions</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=5542" target="_blank">01:32:22.200</a></span> | <span class="t">are the same as the answers I get with the theana versions to make sure they're all correct</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=5546" target="_blank">01:32:26.680</a></span> | <span class="t">and they all seem to be fine.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=5552" target="_blank">01:32:32.160</a></span> | <span class="t">So I am going to use as my activation function relu, which means the derivative is relu derivative</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=5557" target="_blank">01:32:37.800</a></span> | <span class="t">and my loss function is cross entropy derivative. I also have to write my own scan. So you guys</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=5566" target="_blank">01:32:46.120</a></span> | <span class="t">remember scan. Scan is this thing where we go through a sequence one step at a time,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=5571" target="_blank">01:32:51.560</a></span> | <span class="t">calling a function on each element of the sequence. And each time the function is going to get</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=5576" target="_blank">01:32:56.040</a></span> | <span class="t">two things, it's going to get the next element of the sequence as well as the previous result</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=5581" target="_blank">01:33:01.200</a></span> | <span class="t">of the call.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=5582" target="_blank">01:33:02.640</a></span> | <span class="t">So for example, scan of add two things together on the integers from 0 to 5 is going to give</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=5592" target="_blank">01:33:12.560</a></span> | <span class="t">us the cumulative sum. And remember the reason we do this is because GPUs don't know how to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=5599" target="_blank">01:33:19.560</a></span> | <span class="t">do loops, so our theano version used a scan. And I wanted to make this as close to the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=5604" target="_blank">01:33:24.000</a></span> | <span class="t">theano version as possible.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=5606" target="_blank">01:33:26.320</a></span> | <span class="t">In theano, scan is not implemented like this with a for loop. In theano, they use a very</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=5611" target="_blank">01:33:31.840</a></span> | <span class="t">clever approach which basically creates a tree where it does a whole lot of the things</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=5616" target="_blank">01:33:36.320</a></span> | <span class="t">kind of simultaneously and gradually combines them together. Next year we may even look</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=5621" target="_blank">01:33:41.840</a></span> | <span class="t">at how that works if anybody's interested.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=5627" target="_blank">01:33:47.040</a></span> | <span class="t">So in order to create our Nietzschean philosophy, we need an input and an output. So we have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=5633" target="_blank">01:33:53.560</a></span> | <span class="t">the eight character sequences, one hot encoded for our inputs, and the eight character sequences</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=5641" target="_blank">01:34:01.600</a></span> | <span class="t">moved across by one, one hot encoded for our outputs. And we've got our vocab size, which</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=5648" target="_blank">01:34:08.040</a></span> | <span class="t">is 86 characters. So here's our input and output shapes, 75,000 phrases, each one has</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=5656" target="_blank">01:34:16.880</a></span> | <span class="t">eight characters in, and each of those eight characters is a one-hot encoded vector of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=5660" target="_blank">01:34:20.360</a></span> | <span class="t">size 86.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=5664" target="_blank">01:34:24.440</a></span> | <span class="t">So we first of all need to do the forward pass. So the forward pass is to scan through</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=5674" target="_blank">01:34:34.400</a></span> | <span class="t">all of the characters in the nth phrase, the input and output, calling some function. And</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=5682" target="_blank">01:34:42.160</a></span> | <span class="t">so here is the forward pass. And this is basically identical to what we saw in theano. In theano,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=5687" target="_blank">01:34:47.720</a></span> | <span class="t">we had to lay out the forward pass as well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=5690" target="_blank">01:34:50.000</a></span> | <span class="t">So to create the hidden state, we have to take the dot product of x with its weight</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=5695" target="_blank">01:34:55.120</a></span> | <span class="t">matrix and the dot product of the hidden with its weight matrix, and then we have to put</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=5700" target="_blank">01:35:00.760</a></span> | <span class="t">all that through the activation function. And then to create the predictions, we have to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=5706" target="_blank">01:35:06.360</a></span> | <span class="t">take the dot product of the hidden with its weight matrix and then put that through softmax.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=5715" target="_blank">01:35:15.240</a></span> | <span class="t">And so we have to make sure we keep track of all of the state that it needs, so at the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=5718" target="_blank">01:35:18.880</a></span> | <span class="t">end we will return the loss, the pre-hidden and pre-pred, because we're going to use them</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=5731" target="_blank">01:35:31.120</a></span> | <span class="t">each time we go through. In the back prop, we'll be using those. We need to know the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=5736" target="_blank">01:35:36.800</a></span> | <span class="t">hidden state, of course, we have to keep track of that because we're going to be using it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=5740" target="_blank">01:35:40.720</a></span> | <span class="t">the next time through the RNN. And of course, we're going to need our actual predictions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=5746" target="_blank">01:35:46.960</a></span> | <span class="t">So that's the forward pass, very similar to the other one. The backward pass is the bit</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=5752" target="_blank">01:35:52.560</a></span> | <span class="t">I wanted to show you, and I want to show you how I think about it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=5764" target="_blank">01:36:04.360</a></span> | <span class="t">This is how I think about it. All of my arrows, I've reversed their direction. And the reason</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=5770" target="_blank">01:36:10.480</a></span> | <span class="t">for that is that when we create a derivative, we're really saying how does the input change,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=5776" target="_blank">01:36:16.720</a></span> | <span class="t">how does a change in the input impact the output? And to do that, we have to use the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=5781" target="_blank">01:36:21.560</a></span> | <span class="t">chain rule, we have to go back from the end all the way back to the start.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=5785" target="_blank">01:36:25.920</a></span> | <span class="t">So this is our output last hidden layer activation matrix. This is our loss, which is adding together</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=5797" target="_blank">01:36:37.360</a></span> | <span class="t">all of the losses of each of the characters. If we want the derivative of the loss with</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=5803" target="_blank">01:36:43.280</a></span> | <span class="t">respect to this hidden activation, we would have to take the derivative of the loss with</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=5807" target="_blank">01:36:47.560</a></span> | <span class="t">respect to this output activation and multiply it by the derivative of this output activation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=5813" target="_blank">01:36:53.520</a></span> | <span class="t">with respect to this hidden activation. We have to then multiply them together because</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=5818" target="_blank">01:36:58.280</a></span> | <span class="t">that's the chain rule. The chain rule basically tells you to go from some function of some</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=5826" target="_blank">01:37:06.960</a></span> | <span class="t">other function of x, the derivative is the product of those functions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=5837" target="_blank">01:37:17.640</a></span> | <span class="t">So I find it really helpful to literally draw the arrows. So let's draw the arrow from the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=5844" target="_blank">01:37:24.160</a></span> | <span class="t">loss function to each of the outputs as well. And so to calculate the derivatives, we basically</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=5852" target="_blank">01:37:32.280</a></span> | <span class="t">have to go through and undo each of those steps. In order to figure out how that input</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=5859" target="_blank">01:37:39.560</a></span> | <span class="t">would change that output, we have to basically undo it. We have to go back along the arrow</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=5864" target="_blank">01:37:44.640</a></span> | <span class="t">in the opposite direction.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=5866" target="_blank">01:37:46.680</a></span> | <span class="t">So how do we get from the loss to the output? So to do that, we need the derivative of the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=5875" target="_blank">01:37:55.720</a></span> | <span class="t">loss function. If we're going to go back to the activation function, we're going to need</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=5882" target="_blank">01:38:02.880</a></span> | <span class="t">the derivative of the activation function as well. So you can see it here. This is a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=5888" target="_blank">01:38:08.280</a></span> | <span class="t">single backward pass. We grab one of our inputs, one of our outputs, and then we go backwards</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=5898" target="_blank">01:38:18.560</a></span> | <span class="t">through each one, each of the 8 characters from the end to the start. So grab our input</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=5903" target="_blank">01:38:23.840</a></span> | <span class="t">character and our output character, and the first thing you want is the derivative of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=5909" target="_blank">01:38:29.960</a></span> | <span class="t">pre-pred. Remember pre-pred was the prediction prior to putting it through the softmax. So</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=5918" target="_blank">01:38:38.800</a></span> | <span class="t">that was the bit I just showed you. It's the derivative of the softmax times the derivative</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=5925" target="_blank">01:38:45.360</a></span> | <span class="t">of the loss.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=5927" target="_blank">01:38:47.320</a></span> | <span class="t">So the derivative of the loss is going to get us from here back to here, and then derivative</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=5933" target="_blank">01:38:53.600</a></span> | <span class="t">of the softmax gets us from here back to the other side of the activation function. That</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=5939" target="_blank">01:38:59.520</a></span> | <span class="t">basically gets us to here. So that's what that gets us to. So we want to keep going</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=5949" target="_blank">01:39:09.920</a></span> | <span class="t">further, which is we want to get back to the other side of the hidden. We want to get all</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=5955" target="_blank">01:39:15.360</a></span> | <span class="t">the way over now to here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=5965" target="_blank">01:39:25.320</a></span> | <span class="t">For those of you that haven't done vector calculus, which I'm sure is many of you, just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=5970" target="_blank">01:39:30.360</a></span> | <span class="t">take my word for it. The derivative of a matrix multiplication is the multiplication with</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=5977" target="_blank">01:39:37.480</a></span> | <span class="t">the transpose of that matrix. So in order to take the derivative of the pre-hidden times</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=5985" target="_blank">01:39:45.920</a></span> | <span class="t">its weights, we simply take it by the transpose of its weights. So this is the derivative</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=5993" target="_blank">01:39:53.720</a></span> | <span class="t">of that part.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=5995" target="_blank">01:39:55.880</a></span> | <span class="t">And remember the hidden, we've actually got 2 arrows coming back out of it, and also we've</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=6002" target="_blank">01:40:02.160</a></span> | <span class="t">got 2 arrows coming into it. So we're going to have to add together that derivative and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=6009" target="_blank">01:40:09.080</a></span> | <span class="t">that derivative.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=6010" target="_blank">01:40:10.860</a></span> | <span class="t">So here is the second part. So there it is with respect to the outputs, and there it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=6016" target="_blank">01:40:16.920</a></span> | <span class="t">is with respect to the hidden. And then finally, we have to undo the activation function. So</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=6024" target="_blank">01:40:24.080</a></span> | <span class="t">multiply it by the derivative of the activation function. So that's the chain rule that gets</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=6028" target="_blank">01:40:28.880</a></span> | <span class="t">us all the way back to here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=6034" target="_blank">01:40:34.480</a></span> | <span class="t">So now that we've got those two pieces of information, we can update our weights. So</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=6041" target="_blank">01:40:41.160</a></span> | <span class="t">we can now say for the blue line, what are these weights now going to equal? So we basically</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=6048" target="_blank">01:40:48.800</a></span> | <span class="t">have to take the derivative that we got to at this point, which we called dprered. We</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=6056" target="_blank">01:40:56.080</a></span> | <span class="t">have to multiply by our learning rate, which we're calling alpha. And then we have to undo</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=6062" target="_blank">01:41:02.960</a></span> | <span class="t">the multiplication by the hidden state to get the derivative with respect to the weights.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=6068" target="_blank">01:41:08.360</a></span> | <span class="t">And I created this little columnify function to do that. So it's turning a vector into</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=6074" target="_blank">01:41:14.200</a></span> | <span class="t">a column, so essentially taking its transpose if you like.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=6077" target="_blank">01:41:17.720</a></span> | <span class="t">So that gives me my new output weights. My new hidden weights are basically the same</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=6083" target="_blank">01:41:23.040</a></span> | <span class="t">thing. It's the learning rate times the derivative that we just calculated, and then we have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=6089" target="_blank">01:41:29.240</a></span> | <span class="t">to undo its weights and our new input weights, again at the learning rate, times the pre-hidden</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=6096" target="_blank">01:41:36.280</a></span> | <span class="t">times the columnify version of x.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=6100" target="_blank">01:41:40.080</a></span> | <span class="t">So I'll go through that very quickly. The details aren't important, but if you're interested</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=6105" target="_blank">01:41:45.720</a></span> | <span class="t">it might be fun to look at it over the Christmas break or the next few days. Because you can</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=6112" target="_blank">01:41:52.120</a></span> | <span class="t">see in this here is all of the steps necessary to do that through an RNN, which is also why</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=6121" target="_blank">01:42:01.960</a></span> | <span class="t">we would never want to do this by hand again.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=6124" target="_blank">01:42:04.600</a></span> | <span class="t">So when I wrote this code, luckily I did it before I got my code. You can see I've written</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=6133" target="_blank">01:42:13.040</a></span> | <span class="t">after every one the dimensions of each matrix and vector because it just makes your head</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=6137" target="_blank">01:42:17.200</a></span> | <span class="t">hurt. So thank God, Theano does this for us. But I think it's useful to see it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=6147" target="_blank">01:42:27.640</a></span> | <span class="t">So finally, I now just have to create my initial weight matrices, which are normally distributed</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=6154" target="_blank">01:42:34.360</a></span> | <span class="t">matrices where these normal distribution, I'm going to use the square root of 2 divided</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=6159" target="_blank">01:42:39.120</a></span> | <span class="t">by the number of inputs because that's that Glauro thing, ditto for my y matrix, and remember</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=6165" target="_blank">01:42:45.000</a></span> | <span class="t">for my hidden matrix for a simple RNN, we will use the identity matrix to initialize</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=6171" target="_blank">01:42:51.040</a></span> | <span class="t">it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=6177" target="_blank">01:42:57.880</a></span> | <span class="t">We haven't got to that bit yet, so it depends how we use this. At this stage all we've done</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=6182" target="_blank">01:43:02.600</a></span> | <span class="t">is we've defined the matrices and we've defined the transitions. And whether we maintain state</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=6189" target="_blank">01:43:09.000</a></span> | <span class="t">will depend entirely on what we do next, which is the loop. So here is our loop. In our loop</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=6196" target="_blank">01:43:16.440</a></span> | <span class="t">we're going to go through a bunch of examples, we should really go through all of them, but</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=6199" target="_blank">01:43:19.480</a></span> | <span class="t">I was too lazy to wait. Run one forward step, and then one backward step, and then from</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=6210" target="_blank">01:43:30.120</a></span> | <span class="t">time to time print out how we're getting along.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=6214" target="_blank">01:43:34.960</a></span> | <span class="t">So in this case, the forward step is passing to scan the initial state is a whole bunch</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=6226" target="_blank">01:43:46.400</a></span> | <span class="t">of zeros. So currently this is resetting the state, it's not doing it statefully. If you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=6235" target="_blank">01:43:55.360</a></span> | <span class="t">wanted to do it statefully, it would be pretty easy to change. You would have to have the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=6239" target="_blank">01:43:59.800</a></span> | <span class="t">final state returned by this and keep track of it and then feed it back the next time</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=6245" target="_blank">01:44:05.040</a></span> | <span class="t">through the loop.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=6246" target="_blank">01:44:06.040</a></span> | <span class="t">If you're interested, maybe you could try that. Having said that, you probably won't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=6249" target="_blank">01:44:09.680</a></span> | <span class="t">get great results because remember that when you do things statefully, you're much more</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=6254" target="_blank">01:44:14.240</a></span> | <span class="t">likely to have gradients and activations explode unless you do a GIU or an LSTM. So my guess</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=6262" target="_blank">01:44:22.320</a></span> | <span class="t">is it probably won't work very well. So that was a very quick fly-through and really more</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=6273" target="_blank">01:44:33.320</a></span> | <span class="t">showing you around the code so that if you're interested, you can check it out.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=6279" target="_blank">01:44:39.880</a></span> | <span class="t">What I really wanted to do was get onto this more interesting type of RNN, which is actually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=6287" target="_blank">01:44:47.640</a></span> | <span class="t">two interesting types of RNN called Long Short-Term Memory and Gated Recurrent Unit. Many of you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=6297" target="_blank">01:44:57.120</a></span> | <span class="t">will have heard of the one on the left, LSTM.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=6311" target="_blank">01:45:11.120</a></span> | <span class="t">For stateful RNNs, you can't exactly have minivatches because you're doing one at a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=6318" target="_blank">01:45:18.480</a></span> | <span class="t">time. In our case, we were going through it in order. Using minivatches is a great way</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=6329" target="_blank">01:45:29.520</a></span> | <span class="t">to parallelize things on the GPU and make things run faster, but we have to be careful</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=6335" target="_blank">01:45:35.640</a></span> | <span class="t">about how you're thinking about state.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=6341" target="_blank">01:45:41.400</a></span> | <span class="t">So LSTMs a lot of you will have heard about because they've been pretty popular over the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=6344" target="_blank">01:45:44.840</a></span> | <span class="t">last couple of years for all kinds of cool stuff that Google does. On the right, however,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=6351" target="_blank">01:45:51.000</a></span> | <span class="t">is the GRU, which is simpler and better than the LSTM. So I'm not going to talk about the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=6359" target="_blank">01:45:59.720</a></span> | <span class="t">LSTM, I'm going to talk about the GRU. They're both techniques for building your recurrent</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=6366" target="_blank">01:46:06.640</a></span> | <span class="t">neural network where your gradients are much less likely to explode.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=6372" target="_blank">01:46:12.360</a></span> | <span class="t">They're another great interesting example of a clever architecture, but it's just going</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=6379" target="_blank">01:46:19.440</a></span> | <span class="t">to be more of using the same ideas that we've seen again and again.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=6385" target="_blank">01:46:25.600</a></span> | <span class="t">What we have here on the right-hand side is this box. It's basically zooming into what's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=6397" target="_blank">01:46:37.320</a></span> | <span class="t">going on inside one of these circles in a GRU. So normally in our standard RNN, what's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=6403" target="_blank">01:46:43.560</a></span> | <span class="t">going on in here is pretty simple, which is we do a multiplication by this WH weight matrix</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=6409" target="_blank">01:46:49.080</a></span> | <span class="t">and stick it through an activation function, and we grab our input, do it by a multiplication</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=6414" target="_blank">01:46:54.520</a></span> | <span class="t">by weight matrix and grab its, and do it through its activation function, and we add the two</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=6421" target="_blank">01:47:01.240</a></span> | <span class="t">together.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=6422" target="_blank">01:47:02.240</a></span> | <span class="t">At GRU, though, it's going to do something more complex. We still have the input coming</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=6426" target="_blank">01:47:06.720</a></span> | <span class="t">in and the output going out, so that's what these arrows are. They're representing our</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=6431" target="_blank">01:47:11.360</a></span> | <span class="t">new input character and our prediction. But what's going on in the middle is more complex.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=6438" target="_blank">01:47:18.360</a></span> | <span class="t">We still have our hidden state, just like before. But in a normal RNN, the hidden state</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=6447" target="_blank">01:47:27.720</a></span> | <span class="t">each time simply updates itself. It just goes through a weight matrix and an activation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=6455" target="_blank">01:47:35.400</a></span> | <span class="t">function and updates itself.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=6459" target="_blank">01:47:39.560</a></span> | <span class="t">But in this case, you can see that the loop looks like it's going back to come direct</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=6463" target="_blank">01:47:43.640</a></span> | <span class="t">with self, but then there's this gate here. So it's actually not just a self-loop, there's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=6472" target="_blank">01:47:52.520</a></span> | <span class="t">something more complicated. So in order to understand what's going on, we're going to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=6475" target="_blank">01:47:55.600</a></span> | <span class="t">have to follow across to the right hand side.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=6478" target="_blank">01:47:58.880</a></span> | <span class="t">So on the right hand side, you can see that the hidden state is going to go through another</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=6483" target="_blank">01:48:03.440</a></span> | <span class="t">gate. So what's a gate? A gate is simply a little mini-neural network which is going</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=6495" target="_blank">01:48:15.000</a></span> | <span class="t">to output a bunch of numbers between 0 and 1, which we're going to multiply by its input.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=6502" target="_blank">01:48:22.080</a></span> | <span class="t">In this particular one, the R stands for reset. And so the numbers between 0 and 1, if they</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=6509" target="_blank">01:48:29.880</a></span> | <span class="t">were all 0, then the thing coming out of the reset gate would be just a big bunch of 0's.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=6515" target="_blank">01:48:35.560</a></span> | <span class="t">In other words, it would allow this network to forget the hidden state. Or it could be</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=6522" target="_blank">01:48:42.960</a></span> | <span class="t">a big bunch of 1's which would allow the network to remember all of the hidden state. Do we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=6531" target="_blank">01:48:51.400</a></span> | <span class="t">want it to remember or forget? We don't know, which is why we implement this gate using</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=6537" target="_blank">01:48:57.200</a></span> | <span class="t">a little neural network. And this little neural network is going to have two inputs, which</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=6542" target="_blank">01:49:02.840</a></span> | <span class="t">is the input to the gate, the input to the GIU unit, and the current hidden state.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=6551" target="_blank">01:49:11.240</a></span> | <span class="t">And so it's going to learn a set of weights that it's going to use to decide when to forget.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=6558" target="_blank">01:49:18.400</a></span> | <span class="t">So it's now got the ability to forget what it knows. And that's what the reset gate does.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=6565" target="_blank">01:49:25.200</a></span> | <span class="t">So assuming that the reset gate has at least some non-zero entries, which it most surely</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=6570" target="_blank">01:49:30.160</a></span> | <span class="t">will most of the time, then whatever comes through we're going to call h_tilde, or in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=6575" target="_blank">01:49:35.440</a></span> | <span class="t">my code I call it h_new. So this is the new value of the hidden state after being reset.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=6587" target="_blank">01:49:47.220</a></span> | <span class="t">And so then finally, that goes up to this top bit here. The original hidden state goes</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=6593" target="_blank">01:49:53.200</a></span> | <span class="t">up to this top bit here. And then there's a gate which decides how much of each one should</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=6600" target="_blank">01:50:00.020</a></span> | <span class="t">we have. So this is an update gate. This update gate is going to decide if it's 1, we'll take</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=6612" target="_blank">01:50:12.160</a></span> | <span class="t">more from this side. If it's 0, we'll take more from this side. And again, that's implemented</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=6617" target="_blank">01:50:17.360</a></span> | <span class="t">as a little neural network. I think the easiest way to understand this is probably to look</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=6623" target="_blank">01:50:23.380</a></span> | <span class="t">at the code. So I have implemented this in Theano. You can use a GIU in Keras by simply</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=6630" target="_blank">01:50:30.200</a></span> | <span class="t">replacing the words simple RNN with GIU. So you don't really need to know this to use</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=6636" target="_blank">01:50:36.040</a></span> | <span class="t">it, and you get pretty good results. But here's what it looks like when implemented. We don't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=6647" target="_blank">01:50:47.560</a></span> | <span class="t">just have a hidden input weight matrix and an output weight matrix anymore, we also have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=6654" target="_blank">01:50:54.240</a></span> | <span class="t">a hidden input weight matrix for our little reset gate, and for our update gate.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=6664" target="_blank">01:51:04.400</a></span> | <span class="t">So here is the definition of a gate. A gate is something which takes its inputs, its hidden</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=6670" target="_blank">01:51:10.080</a></span> | <span class="t">state, its hidden state weights, its input weights, and its biases. It does a dot product</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=6677" target="_blank">01:51:17.940</a></span> | <span class="t">of the x with w_x, a dot product of h with w_h, and adds the biases and sticks to its</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=6683" target="_blank">01:51:23.180</a></span> | <span class="t">true or single action. So that's what I meant by a mini-neuronet. It's hardly a neuronet,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=6688" target="_blank">01:51:28.880</a></span> | <span class="t">it's just got one layer. So that's the definition of the reset gate and the update gate.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=6697" target="_blank">01:51:37.920</a></span> | <span class="t">And so in our step function, this is the thing that runs each time on the scan, it looks</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=6705" target="_blank">01:51:45.320</a></span> | <span class="t">exactly the same as what we looked at last week. The output equals the hidden state times</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=6711" target="_blank">01:51:51.600</a></span> | <span class="t">the hidden weight matrix plus the hidden biases. The new hidden state equals our inputs times</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=6721" target="_blank">01:52:01.520</a></span> | <span class="t">its weights and the hidden state times its weights plus the biases, but this time the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=6727" target="_blank">01:52:07.440</a></span> | <span class="t">hidden weights are multiplied by the reset gate. And the reset gate is just a little</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=6735" target="_blank">01:52:15.320</a></span> | <span class="t">neural net. So now that we have h new, our actual new hidden state is equal to that times</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=6746" target="_blank">01:52:26.960</a></span> | <span class="t">1 minus the update gate plus our previous hidden state times the update gate. So you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=6752" target="_blank">01:52:32.560</a></span> | <span class="t">can see that update plus 1 minus update will add to 1. So you can see why it's been drawn</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=6761" target="_blank">01:52:41.560</a></span> | <span class="t">like so, which is that this can really be anywhere at either end or somewhere in between.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=6769" target="_blank">01:52:49.040</a></span> | <span class="t">So the update gate decides how much is h new going to replace the new hidden state with.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=6779" target="_blank">01:52:59.560</a></span> | <span class="t">So actually, although people tend to talk about LSTMs and GRUs as being pretty complex,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=6784" target="_blank">01:53:04.640</a></span> | <span class="t">it really wasn't that hard to write. The key outcome of this though is that because we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=6794" target="_blank">01:53:14.000</a></span> | <span class="t">now have these reset and update gates, is that it has the ability to learn these special</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=6799" target="_blank">01:53:19.580</a></span> | <span class="t">sets of weights to make sure that it throws away state when that's a good idea, or to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=6807" target="_blank">01:53:27.120</a></span> | <span class="t">ignore state when that's a good idea. And so these extra degrees of freedom allow SGD</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=6813" target="_blank">01:53:33.480</a></span> | <span class="t">to find better answers, basically.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=6817" target="_blank">01:53:37.120</a></span> | <span class="t">And so again, this is one of these things where we're coming up with architectures which</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=6822" target="_blank">01:53:42.600</a></span> | <span class="t">just try to make it easier for the optimizer to come up with good answers. Everything after</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=6829" target="_blank">01:53:49.000</a></span> | <span class="t">this is identical to what we looked at last week. That goes into the scan function, to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=6833" target="_blank">01:53:53.240</a></span> | <span class="t">calculate the loss, we calculate the gradients, we do the SGD updates, and we chuck it into</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=6840" target="_blank">01:54:00.480</a></span> | <span class="t">the scan function.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=6843" target="_blank">01:54:03.920</a></span> | <span class="t">So I think really the main reason I wanted to do all that today was to show you the backdrop</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=6854" target="_blank">01:54:14.480</a></span> | <span class="t">example. I know some learning styles are more detail oriented as well, and so I think some</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=6862" target="_blank">01:54:22.200</a></span> | <span class="t">of you hopefully will have found that helpful. Any time you find yourself wondering how the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=6869" target="_blank">01:54:29.360</a></span> | <span class="t">hell did this neural network do this, you can come back to this piece of code and that's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=6876" target="_blank">01:54:36.180</a></span> | <span class="t">all it did. That's all that's going on.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=6880" target="_blank">01:54:40.280</a></span> | <span class="t">That's one way of thinking about it. Where you really get successful with neural nets</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=6884" target="_blank">01:54:44.520</a></span> | <span class="t">though is when you go to a whole other level and you don't think of it at that level anymore,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=6889" target="_blank">01:54:49.320</a></span> | <span class="t">but instead you start thinking, if I'm an optimizer and I'm given an architecture like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=6896" target="_blank">01:54:56.240</a></span> | <span class="t">this, what would I have to do in order to optimize it?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=6901" target="_blank">01:55:01.200</a></span> | <span class="t">And once you start thinking like that, then you can start thinking in this kind of like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=6906" target="_blank">01:55:06.920</a></span> | <span class="t">upside down way that is necessary to come up with good architectures. You can start</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=6912" target="_blank">01:55:12.600</a></span> | <span class="t">to understand why it is that this convolution layer followed by this average pooling layer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=6920" target="_blank">01:55:20.200</a></span> | <span class="t">gives the answers that it does. Why does it work? You get that real intuition for what's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=6925" target="_blank">01:55:25.000</a></span> | <span class="t">going to work for your problem.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=6926" target="_blank">01:55:26.700</a></span> | <span class="t">So there's two ways, two levels at which you need to think about neural nets. The sooner</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=6936" target="_blank">01:55:36.560</a></span> | <span class="t">you can think of it at this super high level, I feel like the sooner you'll do well with</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=6940" target="_blank">01:55:40.680</a></span> | <span class="t">them. One of the best ways to do that is to, over the next couple of weeks, run this FISH</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=6948" target="_blank">01:55:48.640</a></span> | <span class="t">notebook yourself and screw around with it a lot. Make sure that you know how to do</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=6954" target="_blank">01:55:54.960</a></span> | <span class="t">these things that I did where I actually create a little function that allows me to spit out</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=6963" target="_blank">01:56:03.680</a></span> | <span class="t">the output of any of the layers and visualize it. Make sure you kind of know how to inspect</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=6969" target="_blank">01:56:09.000</a></span> | <span class="t">it and really look at the inputs and outputs. I think that's the best way to get an intuition.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=6978" target="_blank">01:56:18.400</a></span> | <span class="t">So this was kind of like, particularly the first half of this class was a bit of a preview</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=6985" target="_blank">01:56:25.160</a></span> | <span class="t">of next year. In the first 6 weeks, you learn all the pieces. And then today, we very rapidly</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=6993" target="_blank">01:56:33.320</a></span> | <span class="t">tried putting those pieces together in a thousand different ways and saw what happened. There's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=7000" target="_blank">01:56:40.640</a></span> | <span class="t">a million more ways that we know of, and probably a billion more ways we don't know of. So knowing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=7007" target="_blank">01:56:47.680</a></span> | <span class="t">this little set of tools, convolutions, fully connected layers, activation functions, SGD,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=7018" target="_blank">01:56:58.280</a></span> | <span class="t">you're now able to be an architect, create these architectures. Keras' functional API</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=7025" target="_blank">01:57:05.800</a></span> | <span class="t">makes it ridiculously easy. I created all of the architectures you see today, this week,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=7033" target="_blank">01:57:13.760</a></span> | <span class="t">while I was sick and my baby wasn't sleeping. My brain was not even working, that's how</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=7038" target="_blank">01:57:18.960</a></span> | <span class="t">easy Keras makes this. It takes a few weeks to build your comfort level up, but hopefully</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=7051" target="_blank">01:57:31.000</a></span> | <span class="t">you can try that. And most importantly, over the next few weeks, as Rachel and I, maybe</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=7059" target="_blank">01:57:39.240</a></span> | <span class="t">with some of your help, start to develop the MOOC, you guys can stay talking on the forums</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=7066" target="_blank">01:57:46.880</a></span> | <span class="t">about keep working through whatever problems you're interested in. Whether it be the projects</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=7072" target="_blank">01:57:52.080</a></span> | <span class="t">that you want to apply these things to in your own organizations or your personal passion</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=7076" target="_blank">01:57:56.240</a></span> | <span class="t">projects or if you want to try and win a competition or two. Rachel and I are still going to be</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=7082" target="_blank">01:58:02.880</a></span> | <span class="t">on the forums. And then in a few weeks time, when the MOOC goes online, hopefully there's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=7091" target="_blank">01:58:11.000</a></span> | <span class="t">going to be thousands of people joining this community. So we'll be like the seed. So I</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=7098" target="_blank">01:58:18.640</a></span> | <span class="t">really hope you guys will stay a part of it and help. Can you imagine that first day when</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=7106" target="_blank">01:58:26.680</a></span> | <span class="t">half the people still think that a python is a snake and don't know how to connect to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=7113" target="_blank">01:58:33.280</a></span> | <span class="t">an AWS instance? You'll all be able to say, read the wiki, here's the page, oh yeah, I</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=7119" target="_blank">01:58:39.200</a></span> | <span class="t">had that problem too. And hopefully our goal here is to create a new generation of deep</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=7126" target="_blank">01:58:46.560</a></span> | <span class="t">learning practitioners, people who have useful problems that they're trying to solve and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=7134" target="_blank">01:58:54.000</a></span> | <span class="t">can use this tool to solve them, rather than create more and more exclusive, heavily mathematical</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=7143" target="_blank">01:59:03.880</a></span> | <span class="t">content that's designed to put people off. So that's our hope. That's really why we're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=7151" target="_blank">01:59:11.040</a></span> | <span class="t">doing this. Rachel, anything else that we should add before we wrap up?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=7158" target="_blank">01:59:18.280</a></span> | <span class="t">Okay, well thank you so much. It really has been a genuine pleasure and I'm so happy to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=7164" target="_blank">01:59:24.840</a></span> | <span class="t">hear that most of you are going to see you again next year. You guys obviously will get</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=7172" target="_blank">01:59:32.560</a></span> | <span class="t">first dibs on places for next year's course. If the MOOC successful, next year's course</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=7179" target="_blank">01:59:39.400</a></span> | <span class="t">could be quite popular, so I do suggest that you do nonetheless get your applications in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=7184" target="_blank">01:59:44.680</a></span> | <span class="t">not too late. They'll certainly go through with priority.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=7190" target="_blank">01:59:50.680</a></span> | <span class="t">Be aware if you're not already, we don't send email much, really the forums is our main</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=7199" target="_blank">01:59:59.840</a></span> | <span class="t">way to communicate and Slack to some extent. So if you want to see what's going on, that's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=7204" target="_blank">02:00:04.840</a></span> | <span class="t">the places to look. And of course, our wiki is the knowledge base that we're creating</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=7211" target="_blank">02:00:11.520</a></span> | <span class="t">for everybody. So anytime you see something missing on the wiki or something you think</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=7215" target="_blank">02:00:15.000</a></span> | <span class="t">could be improved, edit it. Even if you're not sure if you're saying the right thing,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=7219" target="_blank">02:00:19.320</a></span> | <span class="t">you can add a little comment after it's saying "I'm not sure if this is correct." The next</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=7222" target="_blank">02:00:22.440</a></span> | <span class="t">person coming along will help you.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=7225" target="_blank">02:00:25.200</a></span> | <span class="t">Thanks so much everybody. I hope you all have a great vacation season.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Q0z-l2KRYFY&t=7229" target="_blank">02:00:29.280</a></span> | <span class="t">[applause]</span></div></div></body></html>