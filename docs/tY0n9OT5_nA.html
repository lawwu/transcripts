<html><head><title>Lesson 11: Deep Learning Part 2 2018 - Neural Translation</title>
<style>
    body {
        font-family: Arial, sans-serif;
        margin: 0;
        padding: 0;
        background-color: #f4f4f4;
        color: #333;
    }
    .container {
        width: 95%;  /* Increased width to use more space */
        margin: auto;
        overflow: auto;  /* Added to handle overflow by adding a scrollbar if necessary */
    }
    h2, h3 {
        color: #333;
        text-align: center;
    }
    a {
        color: #0000FF;  /* Traditional blue color for links */
        text-decoration: none;
    }
    a:hover {
        text-decoration: underline;
    }
    img {
        display: block;
        margin: auto;
        max-width: 100%;
    }
    .c {
        margin: 10px 0;
    }
    .s, .t {
        display: inline-block;
        margin-right: 5px;
    }
    .max-width {
        max-width: 800px;
        margin: auto;
        padding-left: 20px;
    }
    table {
        width: 100%;
        border-collapse: collapse;
    }
    th, td {
        border: 1px solid #ddd;
        padding: 8px;
        text-align: left;  /* Ensure text alignment is consistent */
    }
    tr:nth-child(even) {
        background-color: #f2f2f2;
    }
    tr:nth-child(odd) {
        background-color: #e6e6e6;
    }
</style>

    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-69VLBMTTP0"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-69VLBMTTP0');
    </script>
    </head><body><div class='container'><a href="index.html">back to index</a><h2>Lesson 11: Deep Learning Part 2 2018 - Neural Translation</h2><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA"><img src="https://i.ytimg.com/vi_webp/tY0n9OT5_nA/maxresdefault.webp" style="width:50%;"></a><div><br></div><h3>Chapters</h3><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=0">0:0</a> Super Convergence<br><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=118">1:58</a> One Cycle<br><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=237">3:57</a> Our Cube Flow<br><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=341">5:41</a> Neural Translation<br><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=584">9:44</a> Code<br><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=812">13:32</a> Basic Approach<br><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1098">18:18</a> RNN Review<br><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1170">19:30</a> Refactoring<br><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1299">21:39</a> Stacking<br><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1357">22:37</a> Training<br><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1488">24:48</a> Tokenizing<br><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1573">26:13</a> Processing<br><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1614">26:54</a> Partition<br><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1639">27:19</a> Intention Layer<br><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1946">32:26</a> Industry Marker<br><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2053">34:13</a> Fast Text<br><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2154">35:54</a> Python Dictionary<br><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2591">43:11</a> Data Loader<br><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2895">48:15</a> NCoder<br><br><div style="text-align: left;"><a href="./tY0n9OT5_nA.html">Whisper Transcript</a> | <a href="./transcript_tY0n9OT5_nA.html">Transcript Only Page</a></div><br><div style="max-width: 800px;"><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=0" target="_blank">00:00:00.000</a></span> | <span class="t">I want to start pointing out a couple of the many cool things that happened this week.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7" target="_blank">00:00:07.040</a></span> | <span class="t">One thing that I'm really excited about is we briefly talked about how Leslie Smith has</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=12" target="_blank">00:00:12.780</a></span> | <span class="t">a new paper out, and basically the paper takes these previous two key papers, cyclical learning</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=22" target="_blank">00:00:22.120</a></span> | <span class="t">rates and superconvergence, and builds on them with a number of experiments to show</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=30" target="_blank">00:00:30.120</a></span> | <span class="t">how you can achieve superconvergence.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=33" target="_blank">00:00:33.220</a></span> | <span class="t">Superconvergence lets you train models 5 times faster than previous stepwise approaches.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=41" target="_blank">00:00:41.840</a></span> | <span class="t">It's not 5 times faster than CLR, but it's faster than CLR as well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=46" target="_blank">00:00:46.440</a></span> | <span class="t">The key is that superconvergence lets you get up to massively high learning rates, somewhere</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=55" target="_blank">00:00:55.620</a></span> | <span class="t">between 1 and 3, which is quite amazing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=60" target="_blank">00:01:00.640</a></span> | <span class="t">So the interesting thing about superconvergence is that you actually train at those very high</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=70" target="_blank">00:01:10.400</a></span> | <span class="t">learning rates for quite a large percentage of your epochs, and during that time the loss</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=76" target="_blank">00:01:16.000</a></span> | <span class="t">doesn't really improve very much, but the trick is it's doing a lot of searching through</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=82" target="_blank">00:01:22.240</a></span> | <span class="t">the space to find really generalizable areas, it seems.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=88" target="_blank">00:01:28.200</a></span> | <span class="t">We kind of had a lot of what we needed in fastAI to achieve this, but we're missing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=92" target="_blank">00:01:32.160</a></span> | <span class="t">a couple of bits, and so Sylvan Gugo has done an amazing job of fleshing out the pieces</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=98" target="_blank">00:01:38.180</a></span> | <span class="t">that we're missing, and then confirming that he has actually achieved superconvergence</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=104" target="_blank">00:01:44.320</a></span> | <span class="t">on training on sci-fi 10.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=106" target="_blank">00:01:46.000</a></span> | <span class="t">I think this is the first time that this has been done that I've heard of outside of Leslie</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=110" target="_blank">00:01:50.320</a></span> | <span class="t">Smith himself.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=111" target="_blank">00:01:51.320</a></span> | <span class="t">He's got a great blog post up now on 1Cycle, which is what Leslie Smith called this approach.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=119" target="_blank">00:01:59.200</a></span> | <span class="t">And this is actually, it turns out, what 1Cycle looks like.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=123" target="_blank">00:02:03.520</a></span> | <span class="t">It's a single cyclical learning rate, but the key difference here is that the going up bit</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=131" target="_blank">00:02:11.400</a></span> | <span class="t">is the same length as the going down bit, so you go up really slowly.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=136" target="_blank">00:02:16.080</a></span> | <span class="t">And then at the end, for like a tenth of the time, you then have this little bit where</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=140" target="_blank">00:02:20.240</a></span> | <span class="t">you go down even further.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=143" target="_blank">00:02:23.760</a></span> | <span class="t">And it's interesting, obviously this is a very easy thing to show, a very easy thing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=147" target="_blank">00:02:27.240</a></span> | <span class="t">to explain.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=149" target="_blank">00:02:29.240</a></span> | <span class="t">Sylvan has added it to fastAI under the temporarily, it's called useCLRbeta by the time you watch</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=157" target="_blank">00:02:37.160</a></span> | <span class="t">this on the video, it'll probably be called 1Cycle or something like that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=163" target="_blank">00:02:43.600</a></span> | <span class="t">But you can use this right now.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=165" target="_blank">00:02:45.920</a></span> | <span class="t">So that's one key piece to getting these massively high learning rates.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=169" target="_blank">00:02:49.780</a></span> | <span class="t">And he shows a number of experiments when you do that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=172" target="_blank">00:02:52.200</a></span> | <span class="t">A second key piece is that as you do this to the learning rate, you do this to the momentum.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=179" target="_blank">00:02:59.080</a></span> | <span class="t">So when the learning rate's low, it's fine to have a high momentum.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=182" target="_blank">00:03:02.480</a></span> | <span class="t">But when the learning rate gets up really high, your momentum needs to be quite a bit</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=189" target="_blank">00:03:09.640</a></span> | <span class="t">lower.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=190" target="_blank">00:03:10.960</a></span> | <span class="t">So this is also part of what he's added to the library is this cyclical momentum.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=196" target="_blank">00:03:16.040</a></span> | <span class="t">And so with these two things, you can train for about the fifth of the number of epochs</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=201" target="_blank">00:03:21.640</a></span> | <span class="t">with a stepwise learning rate schedule.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=204" target="_blank">00:03:24.800</a></span> | <span class="t">Then you can drop your weight decay down by about two orders of magnitude.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=208" target="_blank">00:03:28.720</a></span> | <span class="t">You can often remove most or all of your dropout, and so you end up with something that's trained</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=214" target="_blank">00:03:34.160</a></span> | <span class="t">faster and generalizes better.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=217" target="_blank">00:03:37.600</a></span> | <span class="t">And it actually turns out that Sylvan got quite a bit better accuracy than Leslie Smith's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=221" target="_blank">00:03:41.880</a></span> | <span class="t">paper.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=222" target="_blank">00:03:42.880</a></span> | <span class="t">His guess, I was pleased to see, is because our data augmentation defaults are better</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=228" target="_blank">00:03:48.040</a></span> | <span class="t">than Leslie's.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=229" target="_blank">00:03:49.040</a></span> | <span class="t">I hope that's true.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=231" target="_blank">00:03:51.280</a></span> | <span class="t">So check that out.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=232" target="_blank">00:03:52.280</a></span> | <span class="t">As I say, there's been so many cool things this week, I'm just going to pick two.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=239" target="_blank">00:03:59.600</a></span> | <span class="t">Hamill Hussain works at GitHub.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=243" target="_blank">00:04:03.320</a></span> | <span class="t">I just really like this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=245" target="_blank">00:04:05.320</a></span> | <span class="t">There's a fairly new project called Kubeflow, which is basically TensorFlow for Kubernetes.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=251" target="_blank">00:04:11.960</a></span> | <span class="t">Hamill wrote a very nice article about magical sequence-to-sequence models, building data</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=259" target="_blank">00:04:19.800</a></span> | <span class="t">products on that, using Kubernetes to kind of put that in production and so forth.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=269" target="_blank">00:04:29.320</a></span> | <span class="t">He said that the Google Kubeflow team created a demo based on what he wrote earlier this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=274" target="_blank">00:04:34.560</a></span> | <span class="t">year, directly based on the skills alone in class AI, and I will be presenting this technique</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=280" target="_blank">00:04:40.080</a></span> | <span class="t">at KDD.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=281" target="_blank">00:04:41.080</a></span> | <span class="t">KDD is one of the top academic conferences, so I wanted to share this as a motivation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=287" target="_blank">00:04:47.120</a></span> | <span class="t">for folks to blog, which I think is a great point.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=291" target="_blank">00:04:51.760</a></span> | <span class="t">Nobody who goes out and writes a blog thinks that none of us really think our blog is actually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=298" target="_blank">00:04:58.120</a></span> | <span class="t">going to be very good, probably nobody's going to read it, and then when people actually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=302" target="_blank">00:05:02.440</a></span> | <span class="t">do like it and read it, it's like with great surprise, you just go, oh, it's actually something</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=306" target="_blank">00:05:06.680</a></span> | <span class="t">people were interested to read.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=309" target="_blank">00:05:09.840</a></span> | <span class="t">So here is the tool where you can summarize GitHub issues using this tool, which is now</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=316" target="_blank">00:05:16.000</a></span> | <span class="t">hosted by Google on the kubeflow.org domain.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=319" target="_blank">00:05:19.560</a></span> | <span class="t">So I think that's a great story if Hamill didn't put his work out there, none of this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=326" target="_blank">00:05:26.440</a></span> | <span class="t">would have happened, and you can check out his post that made it all happen as well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=336" target="_blank">00:05:36.440</a></span> | <span class="t">So talking of the magic of sequence-to-sequence models, let's build one.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=344" target="_blank">00:05:44.600</a></span> | <span class="t">So we're going to be specifically working on machine translation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=351" target="_blank">00:05:51.980</a></span> | <span class="t">So machine translation is something that's been around for a long time, but specifically</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=358" target="_blank">00:05:58.040</a></span> | <span class="t">we're going to look at a code called neural translation, which is using neural networks</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=362" target="_blank">00:06:02.040</a></span> | <span class="t">for translation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=364" target="_blank">00:06:04.920</a></span> | <span class="t">That wasn't really a thing in any kind of meaningful way until a couple of years ago.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=373" target="_blank">00:06:13.320</a></span> | <span class="t">And so thanks to Chris Manning from Stanford for the next three slides.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=379" target="_blank">00:06:19.000</a></span> | <span class="t">In 2015, Chris pointed out that neural machine translation first appeared properly, and it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=385" target="_blank">00:06:25.000</a></span> | <span class="t">was pretty crappy compared to the statistical machine translation approaches that used kind</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=388" target="_blank">00:06:28.840</a></span> | <span class="t">of classic feature engineering and standard MLP kind of approaches of lots of stemming</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=395" target="_blank">00:06:35.360</a></span> | <span class="t">and fiddling around with work frequencies and n-grams and lots of stuff.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=402" target="_blank">00:06:42.000</a></span> | <span class="t">A year later, it was better than everything else.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=406" target="_blank">00:06:46.040</a></span> | <span class="t">This is on a metric called Blue, we're not going to discuss the metric because it's not</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=409" target="_blank">00:06:49.200</a></span> | <span class="t">a very good metric and it's not very interesting, but it's what everybody uses.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=413" target="_blank">00:06:53.200</a></span> | <span class="t">So that was Blue as of when Chris did this slide.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=417" target="_blank">00:06:57.320</a></span> | <span class="t">As of now, it's about up here, it's about 30.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=422" target="_blank">00:07:02.800</a></span> | <span class="t">So we're kind of seeing machine translation starting down the path that we saw starting</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=430" target="_blank">00:07:10.560</a></span> | <span class="t">computer vision object classification in 2012, I guess, which is we kind of just surpassed</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=437" target="_blank">00:07:17.640</a></span> | <span class="t">the state-of-the-art and now we're zipping past it at a great rate.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=444" target="_blank">00:07:24.160</a></span> | <span class="t">It's very unlikely that anybody watching this is actually going to build a machine translation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=450" target="_blank">00:07:30.840</a></span> | <span class="t">model because you can go to translate.google.com and use theirs and it works quite well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=457" target="_blank">00:07:37.260</a></span> | <span class="t">So why are we learning about machine translation?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=460" target="_blank">00:07:40.120</a></span> | <span class="t">The reason we're learning about machine translation is that the general idea of taking some kind</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=464" target="_blank">00:07:44.480</a></span> | <span class="t">of input, like a sentence in French, and transforming it into some other kind of output of arbitrary</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=472" target="_blank">00:07:52.200</a></span> | <span class="t">length such as a sentence in English is a really useful thing to do.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=479" target="_blank">00:07:59.080</a></span> | <span class="t">For example, the thing that we just saw that Hamill did takes GitHub issues and turns them</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=485" target="_blank">00:08:05.840</a></span> | <span class="t">into summaries.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=488" target="_blank">00:08:08.240</a></span> | <span class="t">Another example is taking videos and turning them into descriptions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=499" target="_blank">00:08:19.720</a></span> | <span class="t">Basically anything where you're spitting out kind of an arbitrary sized output, very often</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=504" target="_blank">00:08:24.400</a></span> | <span class="t">that's a sentence, so maybe taking a CT scan and spitting out a radiology report, this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=510" target="_blank">00:08:30.760</a></span> | <span class="t">is where you can use sequence-to-sequence learning.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=517" target="_blank">00:08:37.200</a></span> | <span class="t">So the important thing about a neural machine translation, there's more slides from Chris,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=525" target="_blank">00:08:45.200</a></span> | <span class="t">and generally sequence-to-sequence models is that there's no fussing around with heuristics</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=533" target="_blank">00:08:53.520</a></span> | <span class="t">and hacky feature engineering or whatever, it's end-to-end training.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=538" target="_blank">00:08:58.720</a></span> | <span class="t">We're able to build these distributed representations which are shared by lots of concepts within</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=543" target="_blank">00:09:03.920</a></span> | <span class="t">a single network, we're able to use long-term state in the RNN, so use a lot more context</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=550" target="_blank">00:09:10.640</a></span> | <span class="t">than kind of n-gram type approaches, and in the end the text we're generating uses an</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=555" target="_blank">00:09:15.560</a></span> | <span class="t">RNN as well so we can build something that's more fluid.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=559" target="_blank">00:09:19.240</a></span> | <span class="t">We're going to use a bidirectional LSTM with a tension, well actually we're going to use</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=566" target="_blank">00:09:26.000</a></span> | <span class="t">a bidirectional GRU with a tension but basically the same thing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=570" target="_blank">00:09:30.120</a></span> | <span class="t">So you already know about bidirectional recurrent neural networks and a tension we're going</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=574" target="_blank">00:09:34.600</a></span> | <span class="t">to add on top today.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=576" target="_blank">00:09:36.240</a></span> | <span class="t">These general ideas you can use for lots of other things as well as Chris points out on</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=581" target="_blank">00:09:41.400</a></span> | <span class="t">this slide.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=585" target="_blank">00:09:45.560</a></span> | <span class="t">So let's jump into the code which is in the translate notebook, funnily enough.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=603" target="_blank">00:10:03.960</a></span> | <span class="t">And so we're going to try to translate French into English.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=609" target="_blank">00:10:09.840</a></span> | <span class="t">And so the basic idea is that we're going to try and make this look as much like a standard</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=618" target="_blank">00:10:18.120</a></span> | <span class="t">neural network approach as possible.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=621" target="_blank">00:10:21.080</a></span> | <span class="t">So we're going to need three things, you all remember the three things, data, a suitable</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=629" target="_blank">00:10:29.040</a></span> | <span class="t">architecture and a suitable loss function.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=633" target="_blank">00:10:33.400</a></span> | <span class="t">Once you've got those three things, you run fit.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=635" target="_blank">00:10:35.720</a></span> | <span class="t">And all things going well, you end up with something that solves your problem.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=641" target="_blank">00:10:41.920</a></span> | <span class="t">So data, we generally need x y pairs because we need something which we can feed it into</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=650" target="_blank">00:10:50.160</a></span> | <span class="t">the loss function and say I took my x value which was my French sentence and the loss</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=658" target="_blank">00:10:58.920</a></span> | <span class="t">function says it was meant to generate this English sentence and then you had your predictions</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=665" target="_blank">00:11:05.560</a></span> | <span class="t">which you would then compare and see how good it is.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=668" target="_blank">00:11:08.740</a></span> | <span class="t">So therefore we need lots of these tuples of French sentences with their equivalent</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=674" target="_blank">00:11:14.840</a></span> | <span class="t">English sentence.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=676" target="_blank">00:11:16.560</a></span> | <span class="t">That's called a parallel corpus.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=678" target="_blank">00:11:18.840</a></span> | <span class="t">Obviously this is harder to find than a corpus for a language model, because for a language</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=683" target="_blank">00:11:23.480</a></span> | <span class="t">model we just need text in some language.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=689" target="_blank">00:11:29.640</a></span> | <span class="t">For any living language of which the people that use that language, like use computers,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=697" target="_blank">00:11:37.480</a></span> | <span class="t">there will be a few gigabytes at least of text floating around the internet for you to grab.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=702" target="_blank">00:11:42.600</a></span> | <span class="t">So building a language model is only challenging corpus-wise for ancient languages, one of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=709" target="_blank">00:11:49.840</a></span> | <span class="t">our students is trying to do a Sanskrit one for example at the moment, but that's very</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=714" target="_blank">00:11:54.720</a></span> | <span class="t">rarely a problem.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=716" target="_blank">00:11:56.720</a></span> | <span class="t">For translation there are actually some pretty good parallel corpuses available for European</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=722" target="_blank">00:12:02.600</a></span> | <span class="t">languages.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=723" target="_blank">00:12:03.600</a></span> | <span class="t">The European Parliament basically has every sentence in every European language.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=728" target="_blank">00:12:08.960</a></span> | <span class="t">Anything that goes through the UN is translated to lots of languages.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=734" target="_blank">00:12:14.320</a></span> | <span class="t">For French through English we have a particularly nice thing which is pretty much any semi-official</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=741" target="_blank">00:12:21.400</a></span> | <span class="t">Canadian website, we'll have a French version and an English version.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=747" target="_blank">00:12:27.600</a></span> | <span class="t">This chap Chris Callison-Burch did a cool thing which is basically to try to transform French</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=752" target="_blank">00:12:32.400</a></span> | <span class="t">URLs into English URLs by replacing -fr with -en and hoping that that retrieves the equivalent</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=759" target="_blank">00:12:39.200</a></span> | <span class="t">document and then did that for lots and lots of websites and ended up creating a huge corpus</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=767" target="_blank">00:12:47.640</a></span> | <span class="t">based on millions of web pages.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=769" target="_blank">00:12:49.400</a></span> | <span class="t">So French to English we have this particularly nice resource.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=774" target="_blank">00:12:54.400</a></span> | <span class="t">So we're going to start out by talking about how to create the data, then we'll look at</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=777" target="_blank">00:12:57.520</a></span> | <span class="t">the architecture, and then we'll look at the loss function.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=780" target="_blank">00:13:00.320</a></span> | <span class="t">And so for bounding boxes all of the interesting stuff was in the loss function, but for neural</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=788" target="_blank">00:13:08.680</a></span> | <span class="t">translation all of the interesting stuff is going to be in the architecture.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=794" target="_blank">00:13:14.140</a></span> | <span class="t">So let's zip through this pretty quickly.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=797" target="_blank">00:13:17.720</a></span> | <span class="t">One of the things I want you to think about particularly is what are the relationships</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=802" target="_blank">00:13:22.360</a></span> | <span class="t">and similarities in terms of the task we're doing and how we do it between language modeling</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=807" target="_blank">00:13:27.680</a></span> | <span class="t">versus neural translation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=814" target="_blank">00:13:34.040</a></span> | <span class="t">So the basic approach here is that we're going to take a sentence, so in this case the example</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=821" target="_blank">00:13:41.520</a></span> | <span class="t">is English to German, and this slide's from Stephen Meridy, we steal everything we can</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=827" target="_blank">00:13:47.440</a></span> | <span class="t">from Stephen.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=829" target="_blank">00:13:49.680</a></span> | <span class="t">We start with some sentence in English, and the first step is to do basically the exact</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=834" target="_blank">00:13:54.640</a></span> | <span class="t">same thing we do in a language model, which is to chuck it through an RNN.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=840" target="_blank">00:14:00.200</a></span> | <span class="t">Now with our language model, actually let's not even think about the language model, let's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=847" target="_blank">00:14:07.360</a></span> | <span class="t">start even easier, the classification model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=850" target="_blank">00:14:10.160</a></span> | <span class="t">So something that turns this sentence into positive or negative sentiment.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=856" target="_blank">00:14:16.760</a></span> | <span class="t">We had a decoder, something which basically took the RNN output, and from our paper we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=872" target="_blank">00:14:32.440</a></span> | <span class="t">grabbed three things.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=873" target="_blank">00:14:33.440</a></span> | <span class="t">We took a max pool over all of the time steps, we took a mean pool over all the time steps,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=878" target="_blank">00:14:38.760</a></span> | <span class="t">and we took the value of the RNN at the last time step, stuck all those together, and put</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=884" target="_blank">00:14:44.160</a></span> | <span class="t">it through a linear layer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=886" target="_blank">00:14:46.920</a></span> | <span class="t">Most people don't do that in most NLP stuff, I think it's something we invented.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=894" target="_blank">00:14:54.040</a></span> | <span class="t">People pretty much always use the last time step, so all the stuff we'll be talking about</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=898" target="_blank">00:14:58.160</a></span> | <span class="t">today uses the last time step.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=901" target="_blank">00:15:01.320</a></span> | <span class="t">So we start out by chucking this sentence through an RNN, and out of it comes some state.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=909" target="_blank">00:15:09.480</a></span> | <span class="t">So some state meaning some hidden state, some vector that represents the output of an RNN</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=916" target="_blank">00:15:16.680</a></span> | <span class="t">that has encoded that sentence.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=918" target="_blank">00:15:18.840</a></span> | <span class="t">You'll see the word that Stephen used here was encoder.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=923" target="_blank">00:15:23.040</a></span> | <span class="t">We've tended to use the word backbone.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=925" target="_blank">00:15:25.640</a></span> | <span class="t">So like when we've talked about adding a custom head to an existing model, like the existing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=931" target="_blank">00:15:31.280</a></span> | <span class="t">pre-trained ImageNet model, for example, we say that's our backbone, and then we stick</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=935" target="_blank">00:15:35.480</a></span> | <span class="t">on top of it some head that does the task we want.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=939" target="_blank">00:15:39.620</a></span> | <span class="t">In sequence-to-sequence learning, they use the word encoder.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=944" target="_blank">00:15:44.640</a></span> | <span class="t">But basically it's the same thing, it's some piece of a neural network architecture that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=949" target="_blank">00:15:49.120</a></span> | <span class="t">takes the input and turns it into some representation which we can then stick a few more layers</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=956" target="_blank">00:15:56.240</a></span> | <span class="t">on top of to grab something out of it, such as we did for the classifier where we stuck</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=963" target="_blank">00:16:03.040</a></span> | <span class="t">a linear layer on top of it to turn it into a sentiment, positive or negative.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=971" target="_blank">00:16:11.800</a></span> | <span class="t">So this time, though, we have something that's a little bit harder than just getting sentiment,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=980" target="_blank">00:16:20.320</a></span> | <span class="t">which is I want to turn this state not into a positive or negative sentiment, but into</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=984" target="_blank">00:16:24.800</a></span> | <span class="t">a sequence of tokens, where that sequence of tokens is the German sentence that we want.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=992" target="_blank">00:16:32.640</a></span> | <span class="t">So this is sounding more like the language model than the classifier, because the language</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=997" target="_blank">00:16:37.720</a></span> | <span class="t">model had multiple tokens for every input word, there was an output word, but the language</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1003" target="_blank">00:16:43.360</a></span> | <span class="t">model was also much easier because the number of tokens in the language model output was</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1010" target="_blank">00:16:50.600</a></span> | <span class="t">the same length as the number of tokens in the language model input.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1014" target="_blank">00:16:54.040</a></span> | <span class="t">And not only were they the same length, they exactly matched up.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1018" target="_blank">00:16:58.000</a></span> | <span class="t">Like after word 1 comes word 2, after word 2 comes word 3 and so forth.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1024" target="_blank">00:17:04.040</a></span> | <span class="t">But for translating language, you don't necessarily know that the word 'he' will be translated</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1031" target="_blank">00:17:11.860</a></span> | <span class="t">as the first word in the output, and that 'loved' will be the second word in the output.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1035" target="_blank">00:17:15.640</a></span> | <span class="t">In this particular case, unfortunately, they are the same.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1038" target="_blank">00:17:18.960</a></span> | <span class="t">But very often the subject-object order will be different, or there will be some extra</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1044" target="_blank">00:17:24.480</a></span> | <span class="t">words inserted, or some pronouns will need to add some gendered article to it, or whatever.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1051" target="_blank">00:17:31.600</a></span> | <span class="t">So this is the key issue we're going to have to deal with is the fact that we have an arbitrary</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1057" target="_blank">00:17:37.280</a></span> | <span class="t">length output where the tokens in the output do not correspond to the same order of specific</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1064" target="_blank">00:17:44.640</a></span> | <span class="t">tokens in the input.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1068" target="_blank">00:17:48.000</a></span> | <span class="t">So the general idea is the same, use an RNN to encode the input, turns it into some hidden</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1073" target="_blank">00:17:53.880</a></span> | <span class="t">state and then this is the new thing we're going to learn is generating a sequence output.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1080" target="_blank">00:18:00.480</a></span> | <span class="t">So we already know sequence to class, that's IMDB classifier, we already know sequence</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1088" target="_blank">00:18:08.060</a></span> | <span class="t">to equal length sequence where it corresponds to the same items, that's the language model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1093" target="_blank">00:18:13.800</a></span> | <span class="t">for example, but we don't know yet how to do a general-purpose sequence to sequence,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1098" target="_blank">00:18:18.440</a></span> | <span class="t">so that's the new thing today.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1101" target="_blank">00:18:21.240</a></span> | <span class="t">Very little of this will make sense unless you really understand lesson 6, how an RNN</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1109" target="_blank">00:18:29.920</a></span> | <span class="t">works.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1111" target="_blank">00:18:31.320</a></span> | <span class="t">So if some of this lesson doesn't make sense to you and you find yourself wondering what</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1116" target="_blank">00:18:36.520</a></span> | <span class="t">does he mean by 'hidden state' exactly, how's that working, go back and rewatch lesson 6</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1122" target="_blank">00:18:42.960</a></span> | <span class="t">to give you a very quick review, we learned that an RNN at its heart is a standard fully</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1131" target="_blank">00:18:51.000</a></span> | <span class="t">connected network, so here's one with one, two, three, four layers, takes an input and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1137" target="_blank">00:18:57.520</a></span> | <span class="t">puts it through four layers, but then at the second layer it can just concatenate in the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1144" target="_blank">00:19:04.200</a></span> | <span class="t">second input, third layer concatenate in the third input, but we actually wrote this in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1148" target="_blank">00:19:08.520</a></span> | <span class="t">Python as just literally a four-layer neural network, there was nothing else we used other</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1155" target="_blank">00:19:15.560</a></span> | <span class="t">than linear layers and values.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1160" target="_blank">00:19:20.480</a></span> | <span class="t">We used the same weight matrix every time an input came in, we used the same matrix</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1164" target="_blank">00:19:24.200</a></span> | <span class="t">every time we went from one of these states to the next, and that's why these arrows are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1168" target="_blank">00:19:28.440</a></span> | <span class="t">the same color, and so we can redraw that previous thing like this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1174" target="_blank">00:19:34.960</a></span> | <span class="t">And so not only did we redraw it, but we took four lines of linear linear linear linear code</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1183" target="_blank">00:19:43.520</a></span> | <span class="t">in PyTorch and we replaced it with a for loop.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1190" target="_blank">00:19:50.400</a></span> | <span class="t">So remember we had something that did exactly the same thing as this, but it just had four</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1195" target="_blank">00:19:55.680</a></span> | <span class="t">lines of code saying linear linear linear linear, and we literally replaced it with</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1201" target="_blank">00:20:01.880</a></span> | <span class="t">a for loop because that's nice to refactor.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1205" target="_blank">00:20:05.380</a></span> | <span class="t">So literally that refactoring, which doesn't change any of the math, any of the ideas,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1212" target="_blank">00:20:12.120</a></span> | <span class="t">any of the outputs, that refactoring is an RNN, it's turning a bunch of separate lines</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1218" target="_blank">00:20:18.880</a></span> | <span class="t">in the code into a Python folder.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1222" target="_blank">00:20:22.760</a></span> | <span class="t">And so that's how we can draw it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1226" target="_blank">00:20:26.680</a></span> | <span class="t">We could take the output so that it's not outside the loop and put it inside the loop,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1232" target="_blank">00:20:32.720</a></span> | <span class="t">like so.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1234" target="_blank">00:20:34.500</a></span> | <span class="t">And if we do that, we're now going to generate a separate output for every input.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1244" target="_blank">00:20:44.240</a></span> | <span class="t">So in this case, this particular one here, the hidden state gets replaced each time and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1249" target="_blank">00:20:49.960</a></span> | <span class="t">we end up just spitting out the final hidden state.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1252" target="_blank">00:20:52.880</a></span> | <span class="t">So this one is this example, but if instead we had something that said h's dot append</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1262" target="_blank">00:21:02.200</a></span> | <span class="t">h and returned h's at the end, that would be this picture.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1268" target="_blank">00:21:08.120</a></span> | <span class="t">And so go back and relook at that notebook if this is unclear.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1270" target="_blank">00:21:10.680</a></span> | <span class="t">I think the main thing to remember is when we say hidden state, we're referring to a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1275" target="_blank">00:21:15.520</a></span> | <span class="t">vector.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1277" target="_blank">00:21:17.480</a></span> | <span class="t">See here, here's the vector, h equals torch.zeros nhidden.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1284" target="_blank">00:21:24.880</a></span> | <span class="t">Now of course it's a vector for each thing in the mini-batch, so it's a matrix.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1289" target="_blank">00:21:29.720</a></span> | <span class="t">But generally when I speak about these things, I ignore the mini-batch piece and treat it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1294" target="_blank">00:21:34.080</a></span> | <span class="t">with just a single item.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1295" target="_blank">00:21:35.680</a></span> | <span class="t">So it's just a vector of this length.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1302" target="_blank">00:21:42.040</a></span> | <span class="t">We also learned that you can stack these layers on top of each other.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1305" target="_blank">00:21:45.840</a></span> | <span class="t">So rather than this first RNN spitting out output, there could just spit out inputs into</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1311" target="_blank">00:21:51.160</a></span> | <span class="t">a second RNN.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1313" target="_blank">00:21:53.440</a></span> | <span class="t">And if you're thinking at this point, "I think I understand this, but I'm not quite sure,"</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1320" target="_blank">00:22:00.320</a></span> | <span class="t">if you're anything like me, that means you don't understand this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1324" target="_blank">00:22:04.160</a></span> | <span class="t">And the only way you know and that you actually understand it is to go and write this from</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1329" target="_blank">00:22:09.320</a></span> | <span class="t">scratch in PyTorch or NumPy.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1332" target="_blank">00:22:12.520</a></span> | <span class="t">And if you can't do that, then you don't understand it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1336" target="_blank">00:22:16.080</a></span> | <span class="t">You can go back and rewatch Lesson 6 and check out the notebook and copy some of the ideas</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1340" target="_blank">00:22:20.960</a></span> | <span class="t">until it's really important that you can write that from scratch.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1344" target="_blank">00:22:24.680</a></span> | <span class="t">It's less than a screen of code.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1348" target="_blank">00:22:28.400</a></span> | <span class="t">So you want to make sure you create a two-layer RNN.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1354" target="_blank">00:22:34.120</a></span> | <span class="t">And this is what it looks like if you unroll it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1358" target="_blank">00:22:38.840</a></span> | <span class="t">So that's the goal, is to get to a point that we first of all have these X, Y pairs of sentences,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1365" target="_blank">00:22:45.840</a></span> | <span class="t">and we're going to do French to English.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1368" target="_blank">00:22:48.360</a></span> | <span class="t">So we're going to start by downloading this dataset, and training a translation model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1375" target="_blank">00:22:55.840</a></span> | <span class="t">takes a long time.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1379" target="_blank">00:22:59.080</a></span> | <span class="t">Google's translation model has 8 layers of RNN stacked on top of each other.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1383" target="_blank">00:23:03.920</a></span> | <span class="t">There's no conceptual difference between 8 layers and 2 layers, it's just like if you're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1389" target="_blank">00:23:09.680</a></span> | <span class="t">Google and you have more GPUs or TPUs and you know what to do with, then you're fine</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1393" target="_blank">00:23:13.360</a></span> | <span class="t">doing that, whereas in our case it's pretty likely that the kind of sequence-to-sequence</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1397" target="_blank">00:23:17.640</a></span> | <span class="t">models we're building are not going to require that level of computation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1401" target="_blank">00:23:21.880</a></span> | <span class="t">So to keep things simple, let's do a cut-down thing where rather than learning how to translate</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1408" target="_blank">00:23:28.000</a></span> | <span class="t">French into English for any sentence, let's learn to translate French questions into English</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1413" target="_blank">00:23:33.440</a></span> | <span class="t">questions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1414" target="_blank">00:23:34.440</a></span> | <span class="t">And specifically questions that start with what, where, which, when.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1418" target="_blank">00:23:38.280</a></span> | <span class="t">So you can see here I've got a regex that looks for things that start with wh and end</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1422" target="_blank">00:23:42.160</a></span> | <span class="t">with a question mark.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1423" target="_blank">00:23:43.160</a></span> | <span class="t">So I just go through the corpus, open up each of the two files, each line is one parallel</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1429" target="_blank">00:23:49.120</a></span> | <span class="t">text, zip them together, grab the English question, the French question, and check whether they</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1434" target="_blank">00:23:54.440</a></span> | <span class="t">match the regular expressions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1437" target="_blank">00:23:57.760</a></span> | <span class="t">Dump that out as a pickle so that I don't have to do it again.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1440" target="_blank">00:24:00.880</a></span> | <span class="t">And so we now have 52,000 sentences, and here are some examples of those sentence pairs.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1449" target="_blank">00:24:09.480</a></span> | <span class="t">One nice thing about this is that what, who, where type questions tend to be fairly short,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1455" target="_blank">00:24:15.280</a></span> | <span class="t">which is nice.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1457" target="_blank">00:24:17.960</a></span> | <span class="t">But I would say the idea that we could learn from scratch with no previous understanding</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1464" target="_blank">00:24:24.160</a></span> | <span class="t">of the idea of language, let alone of English or of French, that we could create something</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1468" target="_blank">00:24:28.840</a></span> | <span class="t">that can translate one to the other for any arbitrary question with only 50,000 sentences,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1474" target="_blank">00:24:34.880</a></span> | <span class="t">sounds like a ludicrously difficult thing to ask this to do.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1479" target="_blank">00:24:39.840</a></span> | <span class="t">So I would be impressed if we could make any progress whatsoever.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1483" target="_blank">00:24:43.480</a></span> | <span class="t">This is very little data to do a very complex exercise.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1489" target="_blank">00:24:49.400</a></span> | <span class="t">So this contains the tuples of French and English.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1492" target="_blank">00:24:52.840</a></span> | <span class="t">You can use this handy idiom to split them apart into a list of English questions and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1497" target="_blank">00:24:57.520</a></span> | <span class="t">a list of French questions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1499" target="_blank">00:24:59.560</a></span> | <span class="t">And then we tokenize the English questions and we tokenize the French questions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1505" target="_blank">00:25:05.200</a></span> | <span class="t">So remember that just means splitting them up into separate words or word-like things.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1512" target="_blank">00:25:12.440</a></span> | <span class="t">By default, the tokenizer that we have here, and remember this is a wrapper around the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1517" target="_blank">00:25:17.880</a></span> | <span class="t">spacey tokenizer, which is a fantastic tokenizer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1522" target="_blank">00:25:22.120</a></span> | <span class="t">This wrapper by default assumes English, so to ask for French, you just add an extra</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1527" target="_blank">00:25:27.240</a></span> | <span class="t">parameter.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1528" target="_blank">00:25:28.240</a></span> | <span class="t">The first time you do this, you'll get an error saying that you don't have the spacey</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1531" target="_blank">00:25:31.600</a></span> | <span class="t">French model installed, and you can google to get the command something python -m spacey</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1537" target="_blank">00:25:37.600</a></span> | <span class="t">download French or something like that to grab the French model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1544" target="_blank">00:25:44.480</a></span> | <span class="t">I don't think any of you are going to have RAM problems here because this is not particularly</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1548" target="_blank">00:25:48.440</a></span> | <span class="t">big corpus, but I know that some of you were trying to train new language models during</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1553" target="_blank">00:25:53.080</a></span> | <span class="t">the week and were having RAM problems.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1555" target="_blank">00:25:55.280</a></span> | <span class="t">If you do, it's worth knowing what these functions are actually doing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1559" target="_blank">00:25:59.420</a></span> | <span class="t">So for example, these ones here is processing every sentence across multiple processes.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1565" target="_blank">00:26:05.560</a></span> | <span class="t">And remember, fastai code is designed to be pretty easy to read, so here's the three lines</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1577" target="_blank">00:26:17.200</a></span> | <span class="t">of code to process all MP, find out how many CPUs you have, divide by two, because normally</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1583" target="_blank">00:26:23.200</a></span> | <span class="t">with hyperthreading they don't actually all work in parallel, then in parallel run this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1591" target="_blank">00:26:31.440</a></span> | <span class="t">process function.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1592" target="_blank">00:26:32.720</a></span> | <span class="t">So that's going to spit out a whole separate Python process for every CPU you have.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1597" target="_blank">00:26:37.720</a></span> | <span class="t">If you have a lot of cores, a lot of Python processes, everyone's going to load all this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1602" target="_blank">00:26:42.580</a></span> | <span class="t">data in and that can potentially use up all your RAM.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1606" target="_blank">00:26:46.720</a></span> | <span class="t">So you could replace that with just proc all rather than proc all MP to use less RAM.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1615" target="_blank">00:26:55.080</a></span> | <span class="t">Or you could just use less cores.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1618" target="_blank">00:26:58.400</a></span> | <span class="t">So at the moment we're calling this function partition by cores, which calls partition</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1624" target="_blank">00:27:04.920</a></span> | <span class="t">on a list and asks to split it into a number of equal length things according to how many</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1630" target="_blank">00:27:10.920</a></span> | <span class="t">CPUs you have, so you could replace that by splitting it into a smaller list and run it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1636" target="_blank">00:27:16.680</a></span> | <span class="t">on less things.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1638" target="_blank">00:27:18.880</a></span> | <span class="t">Yes, Rachel.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1641" target="_blank">00:27:21.440</a></span> | <span class="t">Was an attention layer tried in the language model?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1643" target="_blank">00:27:23.920</a></span> | <span class="t">Do you think it would be a good idea to try and add one?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1647" target="_blank">00:27:27.640</a></span> | <span class="t">We haven't learned about attention yet, so let's ask about things that we have got to,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1651" target="_blank">00:27:31.720</a></span> | <span class="t">not things we haven't.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1654" target="_blank">00:27:34.360</a></span> | <span class="t">The short answer is no, I haven't tried it properly, yes, you should try it because it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1660" target="_blank">00:27:40.280</a></span> | <span class="t">might help.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1661" target="_blank">00:27:41.280</a></span> | <span class="t">In general, there's going to be a lot of things that we cover today, which if you've done</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1666" target="_blank">00:27:46.360</a></span> | <span class="t">some sequence-to-sequence stuff before, you'll want to know about something we haven't covered</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1670" target="_blank">00:27:50.480</a></span> | <span class="t">yet.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1671" target="_blank">00:27:51.480</a></span> | <span class="t">I'm going to cover all the sequence-to-sequence things.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1673" target="_blank">00:27:53.480</a></span> | <span class="t">So at the end of this, if I haven't covered the thing you wanted to know about, please</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1677" target="_blank">00:27:57.080</a></span> | <span class="t">ask me then.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1678" target="_blank">00:27:58.600</a></span> | <span class="t">If you ask me before, I'll be answering something based on something I'm about to teach you.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1685" target="_blank">00:28:05.160</a></span> | <span class="t">So having tokenized the English and French, you can see how it gets split out.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1690" target="_blank">00:28:10.320</a></span> | <span class="t">You can see that tokenization for French is quite different looking because French loves</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1695" target="_blank">00:28:15.080</a></span> | <span class="t">their apostrophes and their hyphens and stuff.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1697" target="_blank">00:28:17.920</a></span> | <span class="t">So if you try to use an English tokenizer for a French sentence, you're going to get</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1701" target="_blank">00:28:21.240</a></span> | <span class="t">a pretty crappy outcome.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1705" target="_blank">00:28:25.040</a></span> | <span class="t">So I don't find you need to know heaps of NLP ideas to use deep learning for NLP, but</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1711" target="_blank">00:28:31.240</a></span> | <span class="t">just some basic stuff like use the right tokenizer if your language is important.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1718" target="_blank">00:28:38.040</a></span> | <span class="t">And so some of the students this week in our study group have been trying to build language</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1722" target="_blank">00:28:42.080</a></span> | <span class="t">models for Chinese, for instance, which of course doesn't really have the concept of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1728" target="_blank">00:28:48.400</a></span> | <span class="t">a tokenizer in the same way.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1730" target="_blank">00:28:50.440</a></span> | <span class="t">So we've been starting to look at, briefly mentioned last week, this Google thing called</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1735" target="_blank">00:28:55.040</a></span> | <span class="t">sentence piece, which basically splits things into arbitrary subword units.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1741" target="_blank">00:29:01.020</a></span> | <span class="t">And so when I say tokenize, if you're using a language that doesn't have spaces in, you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1746" target="_blank">00:29:06.800</a></span> | <span class="t">should probably be checking out sentence piece or some other similar subword unit thing instead.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1753" target="_blank">00:29:13.800</a></span> | <span class="t">And hopefully in the next week or two we'll be able to report back with some early results</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1757" target="_blank">00:29:17.720</a></span> | <span class="t">of these experiments with Chinese.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1765" target="_blank">00:29:25.680</a></span> | <span class="t">So having tokenized it, we'll save that to disk.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1767" target="_blank">00:29:27.880</a></span> | <span class="t">And then remember the next step after we create tokens is to turn them into numbers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1773" target="_blank">00:29:33.120</a></span> | <span class="t">And to turn them into numbers, we have two steps.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1775" target="_blank">00:29:35.240</a></span> | <span class="t">The first is to get a list of all of the words that appear, and then we turn every word into</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1780" target="_blank">00:29:40.920</a></span> | <span class="t">the index into that list.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1784" target="_blank">00:29:44.560</a></span> | <span class="t">If there are more than 40,000 words that appear, then let's cut it off there so it doesn't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1788" target="_blank">00:29:48.880</a></span> | <span class="t">get too crazy.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1791" target="_blank">00:29:51.240</a></span> | <span class="t">And we insert a few extra tokens for beginning of stream, padding, end of stream, and unknown.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1800" target="_blank">00:30:00.880</a></span> | <span class="t">So if we try to look up something that wasn't in the 40,000 most common, then we use a default</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1806" target="_blank">00:30:06.600</a></span> | <span class="t">dict to return 3, which is unknown.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1811" target="_blank">00:30:11.600</a></span> | <span class="t">So now we can go ahead and turn every token into an id by putting it through the string</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1817" target="_blank">00:30:17.200</a></span> | <span class="t">to integer dictionary we just created.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1820" target="_blank">00:30:20.840</a></span> | <span class="t">And then at the end of that, let's add the number 2, which is end of stream.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1825" target="_blank">00:30:25.720</a></span> | <span class="t">And you'll see the code you see here is the code I write when I'm iterating and experimenting.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1832" target="_blank">00:30:32.880</a></span> | <span class="t">Because 99% of the code I write when I'm iterating and experimenting turns out to be totally</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1838" target="_blank">00:30:38.440</a></span> | <span class="t">wrong or stupid or embarrassing and you don't get to see it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1842" target="_blank">00:30:42.640</a></span> | <span class="t">But there's no point refactoring that and making it beautiful when I'm writing it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1849" target="_blank">00:30:49.320</a></span> | <span class="t">So I was wanting you to see all the little shortcuts I have.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1852" target="_blank">00:30:52.560</a></span> | <span class="t">So rather than doing this properly and having some constant or something for end of stream</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1857" target="_blank">00:30:57.560</a></span> | <span class="t">marker and using it, when I'm prototyping, I just do the easy stuff.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1864" target="_blank">00:31:04.680</a></span> | <span class="t">Not so much that I end up with broken code, but I try to find some mid-ground between</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1874" target="_blank">00:31:14.760</a></span> | <span class="t">beautiful code and code that works.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1877" target="_blank">00:31:17.760</a></span> | <span class="t">I just heard him mention that we divide them of CPUs by 2 because with hyperthreading we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1884" target="_blank">00:31:24.760</a></span> | <span class="t">don't get to speed up using all the hyperthreaded cores.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1887" target="_blank">00:31:27.800</a></span> | <span class="t">Is this based on practical experience or is there some underlying reason why we wouldn't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1891" target="_blank">00:31:31.640</a></span> | <span class="t">get additional speed up?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1893" target="_blank">00:31:33.040</a></span> | <span class="t">Yeah, it's just practical experience.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1895" target="_blank">00:31:35.560</a></span> | <span class="t">And it's like not all things kind of seem like this, but I definitely noticed with tokenization</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1901" target="_blank">00:31:41.720</a></span> | <span class="t">hyperthreading seems to slow things down a little bit.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1905" target="_blank">00:31:45.000</a></span> | <span class="t">Also if I use all the cores, often I want to do something else at the same time, like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1911" target="_blank">00:31:51.600</a></span> | <span class="t">generally run some interactive notebook and I don't have any spare room to do that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1917" target="_blank">00:31:57.080</a></span> | <span class="t">It's a minor issue.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1923" target="_blank">00:32:03.120</a></span> | <span class="t">So now for our English and our French, we can grab our list of IDs.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1927" target="_blank">00:32:07.800</a></span> | <span class="t">And when we do that, of course, we need to make sure that we also store the vocabulary.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1931" target="_blank">00:32:11.640</a></span> | <span class="t">There's no point having IDs if we don't know what the number 5 represents.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1935" target="_blank">00:32:15.840</a></span> | <span class="t">There's no point having a number 5.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1937" target="_blank">00:32:17.600</a></span> | <span class="t">So that's our vocabulary, the string, and the reverse mapping, string to int, that we can</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1942" target="_blank">00:32:22.800</a></span> | <span class="t">use to convert more cores in the future.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1948" target="_blank">00:32:28.320</a></span> | <span class="t">So just to confirm it's working, we can go through each ID, convert the int to a string</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1953" target="_blank">00:32:33.440</a></span> | <span class="t">and spit that out, and there we have our thing back, now with an end-to-stream marker at</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1958" target="_blank">00:32:38.000</a></span> | <span class="t">the end.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1959" target="_blank">00:32:39.560</a></span> | <span class="t">Our English vocab is 17,000, our French vocab is 25,000.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1964" target="_blank">00:32:44.880</a></span> | <span class="t">So this is not too complex a vocab that we're dealing with, which is nice to know.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1974" target="_blank">00:32:54.840</a></span> | <span class="t">So we spent a lot of time on the forums during the week discussing how pointless word vectors</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1981" target="_blank">00:33:01.060</a></span> | <span class="t">are and how you should stop getting so excited about them, we're now going to use them.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1986" target="_blank">00:33:06.440</a></span> | <span class="t">Why is that?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1987" target="_blank">00:33:07.760</a></span> | <span class="t">Basically, all the stuff we've been learning about using language models and pre-trained</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1993" target="_blank">00:33:13.440</a></span> | <span class="t">proper models rather than pre-trained linear single layers, which is what word vectors</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=1998" target="_blank">00:33:18.240</a></span> | <span class="t">are, I think applies equally well to sequence-to-sequence, but I haven't tried it yet.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2005" target="_blank">00:33:25.580</a></span> | <span class="t">So Sebastian and I are starting to look at that, slightly distracted by preparing this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2011" target="_blank">00:33:31.560</a></span> | <span class="t">class at the moment, but after this class is done.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2014" target="_blank">00:33:34.080</a></span> | <span class="t">So there's a whole thing, for anybody interested in creating some genuinely new, highly publishable</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2021" target="_blank">00:33:41.120</a></span> | <span class="t">results, the entire area of sequence-to-sequence with pre-trained language models hasn't been</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2028" target="_blank">00:33:48.160</a></span> | <span class="t">touched yet, and I strongly believe it's going to be just as good as classification stuff.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2034" target="_blank">00:33:54.800</a></span> | <span class="t">And if you work on this and you get to the point where you have something that's looking</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2040" target="_blank">00:34:00.400</a></span> | <span class="t">exciting and you want help publishing it, I'm very happy to help co-author papers on</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2047" target="_blank">00:34:07.740</a></span> | <span class="t">stuff that's looking good.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2049" target="_blank">00:34:09.980</a></span> | <span class="t">So feel free to reach out if and when you have some interesting results.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2055" target="_blank">00:34:15.040</a></span> | <span class="t">So at this stage, we don't have any of that, so we're going to use very little fast.ai</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2062" target="_blank">00:34:22.600</a></span> | <span class="t">actually, and very little in terms of fast.ai ideas.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2067" target="_blank">00:34:27.300</a></span> | <span class="t">So all we've got is word vectors.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2071" target="_blank">00:34:31.360</a></span> | <span class="t">Anyway, so let's at least use decent word vectors.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2073" target="_blank">00:34:33.880</a></span> | <span class="t">So Word2vec is very old word vectors.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2076" target="_blank">00:34:36.880</a></span> | <span class="t">There are better word vectors now, and fast text is a pretty good source of word vectors.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2082" target="_blank">00:34:42.000</a></span> | <span class="t">There's hundreds of languages available for them, your language is likely to be represented.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2087" target="_blank">00:34:47.100</a></span> | <span class="t">So to grab them, you can click on this link, download word vectors for a language that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2092" target="_blank">00:34:52.080</a></span> | <span class="t">you're interested in, install the fast text Python library.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2101" target="_blank">00:35:01.080</a></span> | <span class="t">It's not available on PyPy, but here's a handy trick.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2104" target="_blank">00:35:04.720</a></span> | <span class="t">If there is a GitHub repo that has a setup.py in it and a requirements.txt in it, you can</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2112" target="_blank">00:35:12.760</a></span> | <span class="t">just chuck git+ at the start and then stick that in your pip install and it works.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2119" target="_blank">00:35:19.400</a></span> | <span class="t">Hardly anybody seems to know this, and if you go to the fast text repo, they won't tell</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2124" target="_blank">00:35:24.840</a></span> | <span class="t">you this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2125" target="_blank">00:35:25.840</a></span> | <span class="t">They'll say you have to download it and CD into it and blah blah blah, but you don't,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2128" target="_blank">00:35:28.480</a></span> | <span class="t">you can just run that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2130" target="_blank">00:35:30.960</a></span> | <span class="t">You can also use for the fast.ai library, by the way.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2133" target="_blank">00:35:33.640</a></span> | <span class="t">If you want to pip install the latest version of fast.ai, you can totally do this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2139" target="_blank">00:35:39.080</a></span> | <span class="t">So you grab the library, import it, load the model, so here's my English model, and here's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2145" target="_blank">00:35:45.000</a></span> | <span class="t">my French model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2147" target="_blank">00:35:47.040</a></span> | <span class="t">You'll see there's a text version and a binary version, the binary version's a bit faster,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2150" target="_blank">00:35:50.640</a></span> | <span class="t">we're going to use that, the text version's also a bit buggy.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2155" target="_blank">00:35:55.560</a></span> | <span class="t">And then I'm going to convert it into a standard Python dictionary to make it a bit easier</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2159" target="_blank">00:35:59.680</a></span> | <span class="t">to work with, so this is just going to go through each word with a dictionary comprehension</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2163" target="_blank">00:36:03.740</a></span> | <span class="t">and save it as a pickled dictionary.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2167" target="_blank">00:36:07.800</a></span> | <span class="t">So now we've got our pickled dictionary.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2171" target="_blank">00:36:11.440</a></span> | <span class="t">We can go ahead and look up a word, for example, comma, and that will return a vector.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2177" target="_blank">00:36:17.640</a></span> | <span class="t">The length of that vector is the dimensionality of this set of word vectors, so in this case</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2182" target="_blank">00:36:22.600</a></span> | <span class="t">we've got 300-dimensional English and French word vectors.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2191" target="_blank">00:36:31.960</a></span> | <span class="t">For reasons that you'll see in a moment, I also want to find out what the mean of my</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2195" target="_blank">00:36:35.680</a></span> | <span class="t">vectors are and the standard deviation of my vectors are.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2198" target="_blank">00:36:38.680</a></span> | <span class="t">So the mean's about zero and the standard deviation is about 0.3.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2209" target="_blank">00:36:49.040</a></span> | <span class="t">Often corpus's have a pretty long-tailed distribution of sequence length, and it's the longest sequences</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2217" target="_blank">00:36:57.960</a></span> | <span class="t">that kind of tend to overwhelm how long things take and how much memory is used and stuff</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2222" target="_blank">00:37:02.880</a></span> | <span class="t">like that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2224" target="_blank">00:37:04.380</a></span> | <span class="t">So I'm going to grab, in this case, the 99th and 97th percentile of the English and French</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2231" target="_blank">00:37:11.960</a></span> | <span class="t">and truncate them to that amount.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2236" target="_blank">00:37:16.320</a></span> | <span class="t">Originally I was using the 90th percentile, so these are poorly named variables, so apologies</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2241" target="_blank">00:37:21.800</a></span> | <span class="t">for that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2242" target="_blank">00:37:22.800</a></span> | <span class="t">So that's just truncating them.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2245" target="_blank">00:37:25.200</a></span> | <span class="t">So we're nearly there.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2246" target="_blank">00:37:26.320</a></span> | <span class="t">We've got our tokenized, numericalized English and French dataset.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2253" target="_blank">00:37:33.900</a></span> | <span class="t">We've got some word vectors.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2256" target="_blank">00:37:36.980</a></span> | <span class="t">So now we need to get it ready for PyTorch.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2259" target="_blank">00:37:39.880</a></span> | <span class="t">So PyTorch expects a dataset object, and hopefully by now you all can tell me that a dataset</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2267" target="_blank">00:37:47.720</a></span> | <span class="t">object requires two things, a length and an indexer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2273" target="_blank">00:37:53.280</a></span> | <span class="t">So I started out writing this, and I was like, "Okay, I need a sector-sect dataset."</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2276" target="_blank">00:37:56.320</a></span> | <span class="t">I started out writing it, and I thought, "Okay, we're going to have to pass it our x's and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2279" target="_blank">00:37:59.920</a></span> | <span class="t">our y's and store them away, and then my indexer is going to need to return a numpy array of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2286" target="_blank">00:38:06.960</a></span> | <span class="t">the x's at that point and a numpy array of the y's at that point, and oh, that's it."</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2293" target="_blank">00:38:13.120</a></span> | <span class="t">So then after I wrote this, I realized I haven't really written a sector-sect dataset, I've</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2297" target="_blank">00:38:17.120</a></span> | <span class="t">just written a totally generic dataset.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2300" target="_blank">00:38:20.240</a></span> | <span class="t">So here's the simplest possible dataset that works for any pair of arrays.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2306" target="_blank">00:38:26.500</a></span> | <span class="t">So it's now poorly named, it's much more general than a sector-sect dataset, but that's what</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2311" target="_blank">00:38:31.480</a></span> | <span class="t">I needed it for.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2313" target="_blank">00:38:33.600</a></span> | <span class="t">This a function, remember we've got v for variables, t for tensors, a for arrays.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2319" target="_blank">00:38:39.800</a></span> | <span class="t">So this basically goes through each of the things you pass it, if it's not already a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2323" target="_blank">00:38:43.400</a></span> | <span class="t">numpy array, it converts it into a numpy array and returns back a tuple of all of the things</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2329" target="_blank">00:38:49.120</a></span> | <span class="t">that you passed it, which are now guaranteed to be numpy arrays.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2332" target="_blank">00:38:52.460</a></span> | <span class="t">So that's AVT3 very handy little functions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2340" target="_blank">00:39:00.000</a></span> | <span class="t">So that's it, that's our dataset.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2344" target="_blank">00:39:04.640</a></span> | <span class="t">So now we need to grab our English and French IDs and get a training set and a validation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2352" target="_blank">00:39:12.360</a></span> | <span class="t">set.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2353" target="_blank">00:39:13.360</a></span> | <span class="t">And so one of the things which is pretty disappointing about a lot of code out there on the internet</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2358" target="_blank">00:39:18.800</a></span> | <span class="t">is that they don't follow some simple best practices.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2362" target="_blank">00:39:22.240</a></span> | <span class="t">For example, if you go to the PyTorch website, they have an example section for sequence-to-sequence</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2369" target="_blank">00:39:29.760</a></span> | <span class="t">translation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2371" target="_blank">00:39:31.120</a></span> | <span class="t">Their example does not have a separate validation set.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2373" target="_blank">00:39:33.840</a></span> | <span class="t">I tried it, training according to their settings, and tested it with a validation set and it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2379" target="_blank">00:39:39.080</a></span> | <span class="t">turned out that it overfit massively.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2381" target="_blank">00:39:41.800</a></span> | <span class="t">So this is not just a theoretical problem, the actual PyTorch repo has the actual official</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2387" target="_blank">00:39:47.720</a></span> | <span class="t">sequence-to-sequence translation example, which does not check for overfitting and overfits</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2392" target="_blank">00:39:52.200</a></span> | <span class="t">horribly.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2394" target="_blank">00:39:54.200</a></span> | <span class="t">Also it fails to use minibatches, so it actually fails to utilize any of the efficiency of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2400" target="_blank">00:40:00.120</a></span> | <span class="t">PyTorch whatsoever.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2403" target="_blank">00:40:03.120</a></span> | <span class="t">Even if you find code in the official PyTorch repo, don't assume it's any good at all.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2409" target="_blank">00:40:09.400</a></span> | <span class="t">The other thing you'll notice is that pretty much every other sequence-to-sequence model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2416" target="_blank">00:40:16.640</a></span> | <span class="t">I've found in PyTorch anywhere on the internet has clearly copied from that shitty PyTorch</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2422" target="_blank">00:40:22.220</a></span> | <span class="t">repo because it's all the same variable names, it has the same problems, it has the same</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2427" target="_blank">00:40:27.080</a></span> | <span class="t">mistakes.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2428" target="_blank">00:40:28.400</a></span> | <span class="t">Like another example, nearly every PyTorch convolutional neural network I've found does</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2433" target="_blank">00:40:33.480</a></span> | <span class="t">not use an adaptive pooling layer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2436" target="_blank">00:40:36.120</a></span> | <span class="t">So in other words, the final layer is always like average_pool(7,7).</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2441" target="_blank">00:40:41.880</a></span> | <span class="t">So they assume that the previous layer is 7x7, and if you use any other size input you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2447" target="_blank">00:40:47.840</a></span> | <span class="t">get an exception.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2449" target="_blank">00:40:49.200</a></span> | <span class="t">And therefore nearly everybody I've spoken to that uses PyTorch thinks that there is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2453" target="_blank">00:40:53.000</a></span> | <span class="t">a fundamental limitation of CNNs that they are tied to the input size.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2456" target="_blank">00:40:56.960</a></span> | <span class="t">And that has not been true since VGG.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2460" target="_blank">00:41:00.240</a></span> | <span class="t">So every time we grab a new model and stick it in the fastai repo, I have to go in, search</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2464" target="_blank">00:41:04.680</a></span> | <span class="t">for pool and add adaptive to the start and replace the 7 with a 1, and now it works on</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2470" target="_blank">00:41:10.400</a></span> | <span class="t">any sized object.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2472" target="_blank">00:41:12.400</a></span> | <span class="t">So just be careful, it's still early days, and believe it or not, even though most of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2478" target="_blank">00:41:18.280</a></span> | <span class="t">you have only started in the last year your deep learning journey, you know quite a lot</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2484" target="_blank">00:41:24.040</a></span> | <span class="t">more about a lot of the more important practical aspects than the vast majority of people that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2488" target="_blank">00:41:28.520</a></span> | <span class="t">are publishing and writing stuff in official repos.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2492" target="_blank">00:41:32.520</a></span> | <span class="t">So you kind of need to have a little more self-confidence than you might expect when</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2497" target="_blank">00:41:37.760</a></span> | <span class="t">it comes to reading other people's code.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2499" target="_blank">00:41:39.120</a></span> | <span class="t">If you find yourself thinking that looks odd, it's not necessarily you, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2503" target="_blank">00:41:43.960</a></span> | <span class="t">It might well be them.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2509" target="_blank">00:41:49.880</a></span> | <span class="t">So I would say like at least 90% of deep learning code that I start looking at turns out to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2519" target="_blank">00:41:59.400</a></span> | <span class="t">have like deathly serious problems that make it completely unusable for anything.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2527" target="_blank">00:42:07.960</a></span> | <span class="t">And so I've been telling people that I've been working with recently, if a repo you're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2533" target="_blank">00:42:13.920</a></span> | <span class="t">looking at doesn't have a section on it saying here's the test we did where we got the same</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2538" target="_blank">00:42:18.080</a></span> | <span class="t">results as the paper that this is meant to be implementing, that almost certainly means</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2541" target="_blank">00:42:21.960</a></span> | <span class="t">they haven't got the same results as the paper they're implementing, they probably haven't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2544" target="_blank">00:42:24.720</a></span> | <span class="t">even checked.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2545" target="_blank">00:42:25.720</a></span> | <span class="t">And if you run it, it definitely won't get those results because it's hard to get things</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2551" target="_blank">00:42:31.080</a></span> | <span class="t">right the first time.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2552" target="_blank">00:42:32.080</a></span> | <span class="t">It probably takes me 12 goes, probably takes normal smarter people than me 6 goes, but</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2558" target="_blank">00:42:38.000</a></span> | <span class="t">if they haven't tested it once, it almost certainly won't work.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2563" target="_blank">00:42:43.680</a></span> | <span class="t">So there's our sequence data set.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2565" target="_blank">00:42:45.400</a></span> | <span class="t">Let's get the training and validation sets.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2568" target="_blank">00:42:48.100</a></span> | <span class="t">Here's an easy way to do that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2569" target="_blank">00:42:49.100</a></span> | <span class="t">Grab a bunch of random numbers, one for each row of your data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2572" target="_blank">00:42:52.680</a></span> | <span class="t">See if they're bigger than 0.1 or not.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2575" target="_blank">00:42:55.800</a></span> | <span class="t">That gets you a list of balls.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2577" target="_blank">00:42:57.820</a></span> | <span class="t">Index into your array with that list of balls to grab a training set.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2581" target="_blank">00:43:01.520</a></span> | <span class="t">Index into that array with the opposite of that list of balls to get your validation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2585" target="_blank">00:43:05.080</a></span> | <span class="t">set.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2586" target="_blank">00:43:06.080</a></span> | <span class="t">There's lots of ways of doing it, I just like to do different ways to see a few approaches.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2592" target="_blank">00:43:12.960</a></span> | <span class="t">So now we can create our data set with our X's and our Y's, French and English.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2597" target="_blank">00:43:17.880</a></span> | <span class="t">If you want to translate instead English to French, switch these two around and you're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2603" target="_blank">00:43:23.000</a></span> | <span class="t">done.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2604" target="_blank">00:43:24.000</a></span> | <span class="t">Now we need to create data loaders.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2606" target="_blank">00:43:26.720</a></span> | <span class="t">We can just grab our data loader and pass in our data set and batch size.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2615" target="_blank">00:43:35.240</a></span> | <span class="t">We actually have to transpose the arrays.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2618" target="_blank">00:43:38.160</a></span> | <span class="t">I'm not going to go into the details about why, we can talk about it during the week</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2621" target="_blank">00:43:41.840</a></span> | <span class="t">if you're interested, but have a think about why we might need to transpose their orientation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2629" target="_blank">00:43:49.160</a></span> | <span class="t">But there's a few more things I want to do.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2631" target="_blank">00:43:51.120</a></span> | <span class="t">One is that since we've already done all the pre-processing, there's no point spawning</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2635" target="_blank">00:43:55.560</a></span> | <span class="t">off multiple workers to do augmentation or whatever because there's no work to do.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2640" target="_blank">00:44:00.680</a></span> | <span class="t">So making num workers equals 1 will save you some time.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2644" target="_blank">00:44:04.880</a></span> | <span class="t">We have to tell it what our padding index is, that's actually pretty important because</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2650" target="_blank">00:44:10.320</a></span> | <span class="t">what's going to happen is that we've got different length sentences and fastai will just automatically</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2659" target="_blank">00:44:19.160</a></span> | <span class="t">stick them together and pad the shorter ones so that they'll end up equal length.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2664" target="_blank">00:44:24.520</a></span> | <span class="t">Because remember a tensor has to be rectangular.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2671" target="_blank">00:44:31.560</a></span> | <span class="t">In the decoder in particular, I actually want my padding to be at the end, not at the start.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2678" target="_blank">00:44:38.840</a></span> | <span class="t">For a classifier, I want the padding at the start because I want that final token to represent</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2684" target="_blank">00:44:44.800</a></span> | <span class="t">the last word of the movie review.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2687" target="_blank">00:44:47.840</a></span> | <span class="t">But in the decoder, as you'll see, it's going to work out a bit better to have padding at</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2691" target="_blank">00:44:51.640</a></span> | <span class="t">the end.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2692" target="_blank">00:44:52.640</a></span> | <span class="t">And then finally, since we've got sentences of different lengths coming in and they all</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2699" target="_blank">00:44:59.000</a></span> | <span class="t">have to be put together in a mini-batch to be the same size by padding, we would much</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2704" target="_blank">00:45:04.080</a></span> | <span class="t">prefer that the sentences in a mini-batch are of similar sizes already because otherwise</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2710" target="_blank">00:45:10.160</a></span> | <span class="t">it's going to be as long as the longest sentence and that's going to end up wasting time and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2714" target="_blank">00:45:14.440</a></span> | <span class="t">memory.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2716" target="_blank">00:45:16.280</a></span> | <span class="t">So therefore I'm going to use the sampler trick that we learned last time which is the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2720" target="_blank">00:45:20.640</a></span> | <span class="t">validation set.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2722" target="_blank">00:45:22.280</a></span> | <span class="t">We're going to ask it to sort everything by length first.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2727" target="_blank">00:45:27.360</a></span> | <span class="t">And then for the training set, we're going to ask it to randomize the order of things</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2732" target="_blank">00:45:32.440</a></span> | <span class="t">but to roughly make it so that things of similar length are about in the same spot.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2737" target="_blank">00:45:37.440</a></span> | <span class="t">So we've got our sort_sampler and our sort_ish_sampler.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2741" target="_blank">00:45:41.960</a></span> | <span class="t">And then at that point, we can create a model_data object.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2745" target="_blank">00:45:45.480</a></span> | <span class="t">For a model_data object, it really does one thing which is it says I have a training set</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2750" target="_blank">00:45:50.600</a></span> | <span class="t">and a validation set and an optional test set and sticks them into a single object.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2755" target="_blank">00:45:55.480</a></span> | <span class="t">We also have a path so that it has somewhere to store temporary files, models, stuff like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2760" target="_blank">00:46:00.400</a></span> | <span class="t">that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2761" target="_blank">00:46:01.400</a></span> | <span class="t">So we're not using fast.ai for very much at all in this example, just a minimal set to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2769" target="_blank">00:46:09.520</a></span> | <span class="t">show you how to get your model_data object.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2776" target="_blank">00:46:16.280</a></span> | <span class="t">In the end, once you've got a model_data object, you can then create a learner and you can</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2780" target="_blank">00:46:20.380</a></span> | <span class="t">then call fit.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2782" target="_blank">00:46:22.080</a></span> | <span class="t">So that's a minimal amount of fast.ai stuff here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2788" target="_blank">00:46:28.440</a></span> | <span class="t">This is a standard PyTorch compatible dataset.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2792" target="_blank">00:46:32.600</a></span> | <span class="t">This is a standard PyTorch compatible data loader.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2794" target="_blank">00:46:34.840</a></span> | <span class="t">Behind the scenes, it's actually using the fast.ai version because I do need to do this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2799" target="_blank">00:46:39.360</a></span> | <span class="t">automatic padding for convenience.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2800" target="_blank">00:46:40.960</a></span> | <span class="t">So there's a few tweaks in our version that are a bit faster and a bit more convenient.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2806" target="_blank">00:46:46.880</a></span> | <span class="t">The fast.ai samplers we're using, but there's not too much going on here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2812" target="_blank">00:46:52.480</a></span> | <span class="t">So now we've got our model_data object.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2815" target="_blank">00:46:55.160</a></span> | <span class="t">We can basically tick off number one.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2819" target="_blank">00:46:59.800</a></span> | <span class="t">So as I said, most of the work is in the architecture.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2824" target="_blank">00:47:04.060</a></span> | <span class="t">And so the architecture is going to take our sequence of tokens.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2834" target="_blank">00:47:14.420</a></span> | <span class="t">It's going to spit them into an encoder, or in computer vision terms, what we've been</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2843" target="_blank">00:47:23.240</a></span> | <span class="t">calling a backbone, something that's going to try and turn this into some kind of representation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2848" target="_blank">00:47:28.720</a></span> | <span class="t">That's just going to be an RNN.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2851" target="_blank">00:47:31.920</a></span> | <span class="t">That's going to spit out the final hidden state, which for each sentence is just a vector.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2858" target="_blank">00:47:38.960</a></span> | <span class="t">None of this is going to be new.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2865" target="_blank">00:47:45.560</a></span> | <span class="t">That's all going to be using very direct simple techniques that we've already learnt.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2870" target="_blank">00:47:50.200</a></span> | <span class="t">And then we're going to take that and we're going to spit it into a different RNN, which</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2874" target="_blank">00:47:54.960</a></span> | <span class="t">is a decoder, and that's going to have some new stuff because we need something that can</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2879" target="_blank">00:47:59.040</a></span> | <span class="t">go through one word at a time.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2883" target="_blank">00:48:03.840</a></span> | <span class="t">And it's going to keep going until it thinks it's finished the sentence, it doesn't know</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2887" target="_blank">00:48:07.840</a></span> | <span class="t">how long the sentence is going to be ahead of time, it keeps going until it thinks it's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2891" target="_blank">00:48:11.480</a></span> | <span class="t">finished the sentence, and then it stops and returns the sentence.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2895" target="_blank">00:48:15.640</a></span> | <span class="t">So let's start with the encoder.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2899" target="_blank">00:48:19.800</a></span> | <span class="t">So in terms of variable naming here, there's basically identical variables for encoder</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2907" target="_blank">00:48:27.000</a></span> | <span class="t">and decoder, well attributes for encoder and decoder.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2909" target="_blank">00:48:29.880</a></span> | <span class="t">The encoder versions have 'enc', the decoder versions have 'dec'.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2914" target="_blank">00:48:34.220</a></span> | <span class="t">So for the encoder, here's our embeddings.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2919" target="_blank">00:48:39.120</a></span> | <span class="t">And so I always try to mention what the mnemonics are, rather than writing things out in too</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2927" target="_blank">00:48:47.380</a></span> | <span class="t">long hand.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2928" target="_blank">00:48:48.920</a></span> | <span class="t">So just remember, 'enc' is an encoder, 'dec' is a decoder, and there's an embedding.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2934" target="_blank">00:48:54.720</a></span> | <span class="t">The final thing that comes out is 'out'.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2937" target="_blank">00:48:57.680</a></span> | <span class="t">The RNN, in this case, is a GRU, not an LSTM, they're nearly the same thing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2944" target="_blank">00:49:04.000</a></span> | <span class="t">So don't worry about the difference, you could replace it with an LSTM and you'll get basically</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2947" target="_blank">00:49:07.360</a></span> | <span class="t">the same results.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2948" target="_blank">00:49:08.360</a></span> | <span class="t">To replace it with an LSTM, simply type LSTM and you're done.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2957" target="_blank">00:49:17.440</a></span> | <span class="t">So we need to create an embedding layer to take -- because remember what we're being</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2963" target="_blank">00:49:23.320</a></span> | <span class="t">passed is the index of the words into a vocabulary, and we want to grab their fast text embedding,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2970" target="_blank">00:49:30.240</a></span> | <span class="t">and then over time we might want to also fine-tune to train that embedding into it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2977" target="_blank">00:49:37.640</a></span> | <span class="t">So to create an embedding, we'll create embedding up here, so we'll just say nn.embedding.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2983" target="_blank">00:49:43.760</a></span> | <span class="t">So it's important that you know now how to set the rows and columns for your embedding.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2989" target="_blank">00:49:49.160</a></span> | <span class="t">So the number of rows has to be equal to your vocabulary size, so each vocabulary item has</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2994" target="_blank">00:49:54.160</a></span> | <span class="t">a word vector.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2996" target="_blank">00:49:56.280</a></span> | <span class="t">And how big is your embedding?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=2998" target="_blank">00:49:58.480</a></span> | <span class="t">Well in this case it was determined by fast text, and the fast text embeddings are size</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3004" target="_blank">00:50:04.120</a></span> | <span class="t">300.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3005" target="_blank">00:50:05.120</a></span> | <span class="t">So we have to use size 300 as well, otherwise we can't start out by using their embeddings.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3014" target="_blank">00:50:14.000</a></span> | <span class="t">So what we want to do is this is initially going to give us a random set of embeddings,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3018" target="_blank">00:50:18.760</a></span> | <span class="t">and so we're going to now go through each one of these, and if we find it in fast text</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3022" target="_blank">00:50:22.840</a></span> | <span class="t">we'll replace it with a fast text embedding.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3025" target="_blank">00:50:25.580</a></span> | <span class="t">So again, something that you should already know is that a PyTorch module that is learnable</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3034" target="_blank">00:50:34.080</a></span> | <span class="t">has a weight attribute, and the weight attribute is a variable, and the variables have a data</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3040" target="_blank">00:50:40.920</a></span> | <span class="t">attribute, and the data attribute is a tensor.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3044" target="_blank">00:50:44.440</a></span> | <span class="t">And you'll notice very often today I'm saying here is something you should know, not so</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3048" target="_blank">00:50:48.440</a></span> | <span class="t">that you think oh I don't know that I'm a bad person, but so that you think okay this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3053" target="_blank">00:50:53.760</a></span> | <span class="t">is a concept that I haven't learned yet and Jeremy thinks I ought to know about, and so</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3061" target="_blank">00:51:01.400</a></span> | <span class="t">I've got to write that down and I'm going to go home and I've got to Google -- this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3065" target="_blank">00:51:05.640</a></span> | <span class="t">is a normal PyTorch attribute in every single learnable PyTorch module.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3071" target="_blank">00:51:11.280</a></span> | <span class="t">This is a normal PyTorch attribute in every single PyTorch variable.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3075" target="_blank">00:51:15.840</a></span> | <span class="t">And so if you don't know how to grab the weights out of a module, or you don't know how to grab</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3079" target="_blank">00:51:19.520</a></span> | <span class="t">the tensor out of a variable, it's going to be hard for you to build new things or debug</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3084" target="_blank">00:51:24.140</a></span> | <span class="t">things or maintain things or whatever.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3086" target="_blank">00:51:26.440</a></span> | <span class="t">So if I say you ought to know this, and you're thinking I don't know this, don't run away</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3091" target="_blank">00:51:31.200</a></span> | <span class="t">and hide, go home and learn the thing, and if you're having trouble learning the thing,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3096" target="_blank">00:51:36.200</a></span> | <span class="t">because you can't find documentation about it, or you don't understand that documentation,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3100" target="_blank">00:51:40.080</a></span> | <span class="t">or you don't know why Jeremy thought it was important you know it, jump on the forum and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3104" target="_blank">00:51:44.080</a></span> | <span class="t">say please explain this thing, here's my best understanding of that thing as I have it at</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3109" target="_blank">00:51:49.360</a></span> | <span class="t">the moment, here's the resources I've looked at, help fill me in.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3114" target="_blank">00:51:54.440</a></span> | <span class="t">And normally if I respond, it's very likely I will not tell you the answer, but I will</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3120" target="_blank">00:52:00.520</a></span> | <span class="t">instead give you a problem that you could solve that if you solve it will solve it for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3126" target="_blank">00:52:06.500</a></span> | <span class="t">you because I know that that way it will be something you remember.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3130" target="_blank">00:52:10.600</a></span> | <span class="t">So again, don't be put off if I'm like okay, go read this link, try and summarize that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3135" target="_blank">00:52:15.080</a></span> | <span class="t">thing, tell us what you think, like I'm trying to be helpful, not unhelpful, and if you're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3138" target="_blank">00:52:18.920</a></span> | <span class="t">still not following, just come back and say I had a look, honestly that link you sent,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3145" target="_blank">00:52:25.000</a></span> | <span class="t">I don't know what any of it means, I wouldn't know where to start, whatever.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3148" target="_blank">00:52:28.680</a></span> | <span class="t">I'll keep trying to help you until you fully understand it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3155" target="_blank">00:52:35.680</a></span> | <span class="t">So now that we've got our weight tensor, we can just go through our vocabulary and we can</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3162" target="_blank">00:52:42.880</a></span> | <span class="t">look up the word in our pre-trained vectors, and if we find it we will replace the random</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3169" target="_blank">00:52:49.320</a></span> | <span class="t">weights with that pre-trained vector.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3172" target="_blank">00:52:52.680</a></span> | <span class="t">The random weights have a standard deviation of 1, our pre-trained vectors it turned out</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3178" target="_blank">00:52:58.920</a></span> | <span class="t">had a standard deviation of about 0.3, so again this is the kind of hacky thing I do when</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3183" target="_blank">00:53:03.240</a></span> | <span class="t">I'm prototyping stuff, I just multiply it by 3.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3187" target="_blank">00:53:07.480</a></span> | <span class="t">Obviously by the time you see the video of this and then you're able to put all this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3191" target="_blank">00:53:11.320</a></span> | <span class="t">sequence to sequence stuff into the fastAI library, you won't find horrible hacks like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3195" target="_blank">00:53:15.360</a></span> | <span class="t">that in there, sure hope, but hack away when you're prototyping.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3203" target="_blank">00:53:23.080</a></span> | <span class="t">Some things won't be in fast text, in which case we'll just keep track of it, and I've</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3207" target="_blank">00:53:27.400</a></span> | <span class="t">just added this print statement here just so that I can kind of see why am I missing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3212" target="_blank">00:53:32.860</a></span> | <span class="t">stuff, basically I'll probably comment it out when I actually commit this to GitHub.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3223" target="_blank">00:53:43.180</a></span> | <span class="t">So we create those embeddings, and so when we actually create the sequence to sequence</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3227" target="_blank">00:53:47.640</a></span> | <span class="t">RNN, it will print out how many were missed, and so remember we had about 30,000 words,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3234" target="_blank">00:53:54.960</a></span> | <span class="t">so we're not missing too many.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3237" target="_blank">00:53:57.040</a></span> | <span class="t">And interesting, the things that are missing, well there's our special token for uppercase,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3243" target="_blank">00:54:03.260</a></span> | <span class="t">not surprising that's missing, but also remember it's not token to vec, it's not token text,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3250" target="_blank">00:54:10.000</a></span> | <span class="t">it does words, so L apostrophe and D apostrophe and apostrophe S, they're not appearing either.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3255" target="_blank">00:54:15.480</a></span> | <span class="t">So that's interesting.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3256" target="_blank">00:54:16.480</a></span> | <span class="t">That does suggest that maybe we could have slightly better embeddings if we tried to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3261" target="_blank">00:54:21.520</a></span> | <span class="t">find some which would be tokenized the same way we tokenize, but that's okay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3267" target="_blank">00:54:27.440</a></span> | <span class="t">Do we just keep embedding vectors from training?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3271" target="_blank">00:54:31.400</a></span> | <span class="t">Why don't we keep all word embeddings in case you have new words in the test set?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3282" target="_blank">00:54:42.800</a></span> | <span class="t">We're going to be fine-tuning them, and so I don't know, it's an interesting idea.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3290" target="_blank">00:54:50.440</a></span> | <span class="t">Maybe that would work, I haven't tried it, obviously you can also add random embedding</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3305" target="_blank">00:55:05.760</a></span> | <span class="t">to those, and at the beginning just keep them random, but it's going to make an effect in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3313" target="_blank">00:55:13.000</a></span> | <span class="t">the sense that you're going to be using those words.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3318" target="_blank">00:55:18.000</a></span> | <span class="t">I think it's an interesting line of inquiry, but I will say this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3322" target="_blank">00:55:22.000</a></span> | <span class="t">The vast majority of the time when you're doing this in the real world, your vocabulary</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3327" target="_blank">00:55:27.640</a></span> | <span class="t">will be bigger than 40,000, and once your vocabulary is bigger than 40,000, using the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3333" target="_blank">00:55:33.160</a></span> | <span class="t">standard techniques, the embedding layers get so big that it takes up all your memory,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3339" target="_blank">00:55:39.200</a></span> | <span class="t">it takes up all of the time in the backdrop.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3341" target="_blank">00:55:41.920</a></span> | <span class="t">There are tricks to dealing with very large vocabries, I don't think we'll have time to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3346" target="_blank">00:55:46.400</a></span> | <span class="t">handle them in this session, but you definitely would not want to have all 3.5 million fast-text</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3354" target="_blank">00:55:54.240</a></span> | <span class="t">vectors in an embedding layer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3359" target="_blank">00:55:59.360</a></span> | <span class="t">I wonder, if you're not touching a word, it's not going to change, given you're fine-tuning.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3369" target="_blank">00:56:09.360</a></span> | <span class="t">It's in GPU RAM, and you've got to remember, 3.5 million times 300 times the size of a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3376" target="_blank">00:56:16.360</a></span> | <span class="t">single-precision floating-point vector, plus all of the gradients for them, even if it's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3380" target="_blank">00:56:20.760</a></span> | <span class="t">not touched.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3384" target="_blank">00:56:24.400</a></span> | <span class="t">Without being very careful and adding a lot more code and stuff, it is slow and hard and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3393" target="_blank">00:56:33.820</a></span> | <span class="t">we wouldn't touch it for now.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3395" target="_blank">00:56:35.480</a></span> | <span class="t">I think it's an interesting path of inquiry, but it's the kind of path of inquiry that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3399" target="_blank">00:56:39.680</a></span> | <span class="t">leads to multiple academic papers, not something that you do on a weekend.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3405" target="_blank">00:56:45.440</a></span> | <span class="t">I think it would be very interesting, maybe we can look at it sometime.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3412" target="_blank">00:56:52.000</a></span> | <span class="t">As I say, I have actually started doing some stuff around incorporating large vocabulary</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3417" target="_blank">00:56:57.600</a></span> | <span class="t">handling into fast.ai.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3418" target="_blank">00:56:58.600</a></span> | <span class="t">It's not finished, but hopefully by the time we get here, this kind of stuff will be possible.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3428" target="_blank">00:57:08.160</a></span> | <span class="t">We create our encoder embedding, add a bit of dropout, and then we create our RNN.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3435" target="_blank">00:57:15.720</a></span> | <span class="t">This input to the RNN obviously is the size of the embedding by definition.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3441" target="_blank">00:57:21.240</a></span> | <span class="t">Number of hidden is whatever we want, so we set it to 256 for now, however many layers</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3446" target="_blank">00:57:26.080</a></span> | <span class="t">we want, and some dropout inside the RNN as well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3451" target="_blank">00:57:31.080</a></span> | <span class="t">This is all standard PyTorch stuff, you could use an LSTM here as well, and then finally</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3455" target="_blank">00:57:35.880</a></span> | <span class="t">we need to turn that into some output that we're going to feed to the decoder, so let's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3460" target="_blank">00:57:40.960</a></span> | <span class="t">use a linear layer to convert the number of hidden into the decoder embedding size.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3468" target="_blank">00:57:48.160</a></span> | <span class="t">In the forward pass, here's how that's used.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3472" target="_blank">00:57:52.620</a></span> | <span class="t">We first of all initialize our hidden state to a bunch of zeros.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3478" target="_blank">00:57:58.760</a></span> | <span class="t">So we've now got a vector of zeros, and then we're going to take our input and put it through</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3485" target="_blank">00:58:05.920</a></span> | <span class="t">our embedding, we're going to put that through dropout, we then pass our currently zeros</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3492" target="_blank">00:58:12.440</a></span> | <span class="t">hidden state and our embeddings into our RNN, and it's going to spit out the usual stuff</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3498" target="_blank">00:58:18.560</a></span> | <span class="t">that RNN spit out, which includes the final hidden state.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3505" target="_blank">00:58:25.320</a></span> | <span class="t">We're then going to take that final hidden state and stick it through that linear layer,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3509" target="_blank">00:58:29.880</a></span> | <span class="t">so we now have something of the right size to feed to our decoder.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3513" target="_blank">00:58:33.040</a></span> | <span class="t">So that's it, and again this ought to be very familiar and very comfortable, it's like the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3520" target="_blank">00:58:40.800</a></span> | <span class="t">most simple possible RNN, so if it's not, go back, check out lesson 6, make sure you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3526" target="_blank">00:58:46.120</a></span> | <span class="t">can write it from scratch and you understand what it does.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3529" target="_blank">00:58:49.680</a></span> | <span class="t">But the key thing to know is that it takes our inputs and spits out a hidden vector that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3541" target="_blank">00:59:01.000</a></span> | <span class="t">hopefully will learn to contain all of the information about what that sentence says</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3549" target="_blank">00:59:09.480</a></span> | <span class="t">and how it says it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3551" target="_blank">00:59:11.340</a></span> | <span class="t">Because if it can't do that, then we can't feed it into a decoder and hope it to spit</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3561" target="_blank">00:59:21.080</a></span> | <span class="t">out our sentence in a different language, so that's what we want it to learn to do.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3568" target="_blank">00:59:28.520</a></span> | <span class="t">And we're not going to do anything special to make it learn to do that, we're just going</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3571" target="_blank">00:59:31.560</a></span> | <span class="t">to do the three things and cross our fingers because that's what we do.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3580" target="_blank">00:59:40.720</a></span> | <span class="t">So that's h is that s, it's a hidden state.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3588" target="_blank">00:59:48.720</a></span> | <span class="t">I guess Steven used s for state, I used h for hidden, but there you go, you would think</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3593" target="_blank">00:59:53.720</a></span> | <span class="t">that two Australians could agree on something like that, but apparently not.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3599" target="_blank">00:59:59.080</a></span> | <span class="t">So how do we now do the new bit?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3603" target="_blank">01:00:03.780</a></span> | <span class="t">And so the basic idea of the new bit is the same, we're going to do exactly the same thing,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3609" target="_blank">01:00:09.360</a></span> | <span class="t">but we're going to write our own for loop.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3613" target="_blank">01:00:13.560</a></span> | <span class="t">And so the for loop is going to do exactly what the for loop inside pytorch does here,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3619" target="_blank">01:00:19.760</a></span> | <span class="t">but we're going to do it manually.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3621" target="_blank">01:00:21.080</a></span> | <span class="t">So we're going to go through the for loop, and how big is the for loop?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3625" target="_blank">01:00:25.720</a></span> | <span class="t">It's an output sequence length.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3628" target="_blank">01:00:28.200</a></span> | <span class="t">Well what is output sequence length?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3630" target="_blank">01:00:30.400</a></span> | <span class="t">It's something that got passed to the constructor, and it is equal to the length of the largest</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3638" target="_blank">01:00:38.120</a></span> | <span class="t">English sentence.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3640" target="_blank">01:00:40.080</a></span> | <span class="t">So we're going to do this for loop as long as the largest English sentence, because we're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3645" target="_blank">01:00:45.760</a></span> | <span class="t">translating it into English, so we can't possibly be longer than that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3653" target="_blank">01:00:53.080</a></span> | <span class="t">At least not in this corpus.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3655" target="_blank">01:00:55.100</a></span> | <span class="t">If we then used it on some different corpus that was longer, this is going to fail.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3662" target="_blank">01:01:02.720</a></span> | <span class="t">You could always pass in a different parameter, of course.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3667" target="_blank">01:01:07.400</a></span> | <span class="t">So the basic idea is the same, we're going to go through and put it through the embedding,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3672" target="_blank">01:01:12.560</a></span> | <span class="t">we're going to stick it through the RNN, we're going to stick it through dropout, and we're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3676" target="_blank">01:01:16.600</a></span> | <span class="t">going to stick it through a linear layer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3679" target="_blank">01:01:19.040</a></span> | <span class="t">So the basic four steps are the same.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3682" target="_blank">01:01:22.840</a></span> | <span class="t">And once we've done that, we're then going to append that output to a list, and then</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3689" target="_blank">01:01:29.840</a></span> | <span class="t">when we're going to finish, we're going to stack that list up into a single tensor and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3693" target="_blank">01:01:33.840</a></span> | <span class="t">return it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3694" target="_blank">01:01:34.840</a></span> | <span class="t">So that's the basic idea.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3698" target="_blank">01:01:38.840</a></span> | <span class="t">Normally a recurrent neural network works in a whole sequence at a time, but we've got</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3707" target="_blank">01:01:47.720</a></span> | <span class="t">a for loop to go through each part of the sequence separately.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3711" target="_blank">01:01:51.520</a></span> | <span class="t">So we have to add a leading unit axis to the start to basically say this is a sequence</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3718" target="_blank">01:01:58.640</a></span> | <span class="t">of length 1.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3720" target="_blank">01:02:00.240</a></span> | <span class="t">So we're not really taking advantage of the recurrent net much at all, we could easily</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3724" target="_blank">01:02:04.280</a></span> | <span class="t">rewrite this with a linear layer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3726" target="_blank">01:02:06.640</a></span> | <span class="t">That would be an interesting experiment if you wanted to try it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3731" target="_blank">01:02:11.260</a></span> | <span class="t">So we basically take our input and we feed it into our embedding, and we add something</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3739" target="_blank">01:02:19.300</a></span> | <span class="t">to the front saying treat this as a sequence of length 1, and then we pass that to our</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3744" target="_blank">01:02:24.160</a></span> | <span class="t">RNN.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3746" target="_blank">01:02:26.800</a></span> | <span class="t">We then get the output of that RNN, feed it into our dropout, and feed it into our linear</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3753" target="_blank">01:02:33.960</a></span> | <span class="t">layer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3754" target="_blank">01:02:34.960</a></span> | <span class="t">So there's two extra things now to be aware of.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3759" target="_blank">01:02:39.560</a></span> | <span class="t">The one thing is, what's this?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3763" target="_blank">01:02:43.520</a></span> | <span class="t">What is the input to that embedding?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3766" target="_blank">01:02:46.660</a></span> | <span class="t">And the answer is, it's the previous word that we translated.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3772" target="_blank">01:02:52.380</a></span> | <span class="t">See how the input here is the previous word here?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3775" target="_blank">01:02:55.680</a></span> | <span class="t">The input here is the previous word here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3778" target="_blank">01:02:58.160</a></span> | <span class="t">So the basic idea is, if you're trying to translate, if you're about to translate, tell</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3784" target="_blank">01:03:04.960</a></span> | <span class="t">me the fourth word of the new sentence, but you don't know what the third word you just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3789" target="_blank">01:03:09.560</a></span> | <span class="t">said was, that's going to be really hard.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3793" target="_blank">01:03:13.060</a></span> | <span class="t">So we're going to feed that in at each time step, let's make it as easy as possible.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3799" target="_blank">01:03:19.040</a></span> | <span class="t">And so what was the previous word at the start?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3801" target="_blank">01:03:21.000</a></span> | <span class="t">Well there was none.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3803" target="_blank">01:03:23.340</a></span> | <span class="t">So specifically we're going to start out with a beginning of stream token.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3817" target="_blank">01:03:37.940</a></span> | <span class="t">So the beginning of stream token is a zero.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3822" target="_blank">01:03:42.080</a></span> | <span class="t">So let's start out our decoder with a beginning of stream token, which is zero.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3829" target="_blank">01:03:49.880</a></span> | <span class="t">And of course we're doing a mini-batch, so we need batch size number of them.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3833" target="_blank">01:03:53.400</a></span> | <span class="t">But let's just think about one part of that batch.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3835" target="_blank">01:03:55.760</a></span> | <span class="t">So we start out with a zero.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3838" target="_blank">01:03:58.480</a></span> | <span class="t">We look up that zero in our embedding matrix to find out what the vector for the beginning</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3844" target="_blank">01:04:04.240</a></span> | <span class="t">of stream token is.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3846" target="_blank">01:04:06.160</a></span> | <span class="t">We stick a unit axis on the front to say we have a single sequence length of beginning</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3850" target="_blank">01:04:10.720</a></span> | <span class="t">of stream token.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3852" target="_blank">01:04:12.480</a></span> | <span class="t">We stick that through our RNN, which gets not only the fact that there's a zero at the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3858" target="_blank">01:04:18.720</a></span> | <span class="t">beginning of stream, but also the hidden state which at this point is whatever came out of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3865" target="_blank">01:04:25.200</a></span> | <span class="t">our encoder.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3866" target="_blank">01:04:26.880</a></span> | <span class="t">So now its job is to try and figure out what is the first word to translate this sentence.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3879" target="_blank">01:04:39.760</a></span> | <span class="t">Pop the trees in dropout, go through one linear layer in order to convert that into the correct</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3885" target="_blank">01:04:45.160</a></span> | <span class="t">size for our decoder embedding matrix, append that to our list of translated words, and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3894" target="_blank">01:04:54.720</a></span> | <span class="t">now we need to figure out what word that was because we need to feed it to the next time</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3900" target="_blank">01:05:00.440</a></span> | <span class="t">step.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3902" target="_blank">01:05:02.440</a></span> | <span class="t">We need to feed it to the next time step.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3904" target="_blank">01:05:04.680</a></span> | <span class="t">So remember what we actually output here, and don't forget, use a debugger, pdb.settrace,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3912" target="_blank">01:05:12.760</a></span> | <span class="t">put it here, what is @p? @p is a tensor.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3917" target="_blank">01:05:17.840</a></span> | <span class="t">How big is the tensor?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3919" target="_blank">01:05:19.100</a></span> | <span class="t">So before you look it up in the debugger, try and figure it out from first principles</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3923" target="_blank">01:05:23.000</a></span> | <span class="t">and check your rate.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3924" target="_blank">01:05:24.400</a></span> | <span class="t">So @p is a tensor whose length is equal to the number of words in our English vocabulary,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3932" target="_blank">01:05:32.040</a></span> | <span class="t">and it contains the probability for every one of those words that it is that word.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3938" target="_blank">01:05:38.760</a></span> | <span class="t">So then if we now say @p.data.max, that looks in its tensor to find out which word has the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3948" target="_blank">01:05:48.600</a></span> | <span class="t">highest probability, and max implies which returns two things.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3953" target="_blank">01:05:53.960</a></span> | <span class="t">The first thing is what is that max probability, and the second is what is the index into the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3958" target="_blank">01:05:58.880</a></span> | <span class="t">array of that max probability.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3961" target="_blank">01:06:01.160</a></span> | <span class="t">And so we want that second item, index number 1, which is the word index with the largest</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3966" target="_blank">01:06:06.720</a></span> | <span class="t">thing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3968" target="_blank">01:06:08.180</a></span> | <span class="t">So now that contains the word, or the word index into our vocabulary of the word.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3977" target="_blank">01:06:17.120</a></span> | <span class="t">If it's a 1, you might remember 1 was padding, then that means we're done.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3982" target="_blank">01:06:22.720</a></span> | <span class="t">That means we've reached the end because we've finished with a bunch of padding.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3986" target="_blank">01:06:26.340</a></span> | <span class="t">If it's not 1, let's go back and continue.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3990" target="_blank">01:06:30.440</a></span> | <span class="t">Now deck_imp is whatever the highest probability word was.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=3997" target="_blank">01:06:37.880</a></span> | <span class="t">So we keep looping through, either until we get to the largest length of a sentence, or</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=4004" target="_blank">01:06:44.840</a></span> | <span class="t">until everything in our mini-batch is padding.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=4009" target="_blank">01:06:49.320</a></span> | <span class="t">And each time we've appended our outputs, not the word but the probabilities, to this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=4017" target="_blank">01:06:57.120</a></span> | <span class="t">list which we stack up into a tensor and we can now go ahead and feed that to a loss function.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=4024" target="_blank">01:07:04.880</a></span> | <span class="t">So before we go to a break, since we've done 1 and 2, let's do 3, which is a loss function.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=4033" target="_blank">01:07:13.600</a></span> | <span class="t">The loss function is categorical cross-entropy loss.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=4038" target="_blank">01:07:18.320</a></span> | <span class="t">We've got a list of probabilities for each of our classes, the classes are all the words</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=4044" target="_blank">01:07:24.640</a></span> | <span class="t">in our English vocab, and we have a target which is the correct class, i.e. the correct</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=4050" target="_blank">01:07:30.240</a></span> | <span class="t">word at this location.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=4054" target="_blank">01:07:34.180</a></span> | <span class="t">There's two tweaks, which is why we need to write our own little loss function, but you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=4057" target="_blank">01:07:37.360</a></span> | <span class="t">can see basically it's going to be cross-entropy loss.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=4060" target="_blank">01:07:40.600</a></span> | <span class="t">And the tweaks are as follows.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=4062" target="_blank">01:07:42.280</a></span> | <span class="t">Tweak number 1 is we might have stopped a little bit early, and so the sequence length</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=4069" target="_blank">01:07:49.400</a></span> | <span class="t">that we generated may be different to the sequence length of the target, in which case</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=4073" target="_blank">01:07:53.700</a></span> | <span class="t">we need to add some padding.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=4077" target="_blank">01:07:57.180</a></span> | <span class="t">PyTorch padding function is weird.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=4079" target="_blank">01:07:59.740</a></span> | <span class="t">If you have a rank 3 tensor, which we do, we have sequence length by batch size by number</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=4092" target="_blank">01:08:12.360</a></span> | <span class="t">of words in the vocab, a rank 3 tensor requires a 6 tuple.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=4099" target="_blank">01:08:19.280</a></span> | <span class="t">Each pair in things in that tuple is the padding before and then the padding after that dimension.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=4106" target="_blank">01:08:26.760</a></span> | <span class="t">So in this case, the first dimension has no padding, the second dimension has no padding,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=4111" target="_blank">01:08:31.280</a></span> | <span class="t">the third dimension has no padding on the left, and as-matched padding is required on</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=4115" target="_blank">01:08:35.640</a></span> | <span class="t">the right.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=4116" target="_blank">01:08:36.640</a></span> | <span class="t">It's good to know how to use that function.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=4120" target="_blank">01:08:40.720</a></span> | <span class="t">Now that we've added any padding, that's necessary.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=4123" target="_blank">01:08:43.960</a></span> | <span class="t">The only other thing we need to do is cross-entropy loss expects a rank 2 tensor, but we've got</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=4131" target="_blank">01:08:51.440</a></span> | <span class="t">sequence length by batch size.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=4133" target="_blank">01:08:53.500</a></span> | <span class="t">So let's just flatten out the sequence length and batch size into a -1 in View.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=4141" target="_blank">01:09:01.120</a></span> | <span class="t">So flatten out that for both of them, and now we can go ahead and call cross-entropy.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=4146" target="_blank">01:09:06.760</a></span> | <span class="t">That's it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=4148" target="_blank">01:09:08.160</a></span> | <span class="t">So now we can just use standard approach, here's our sequence-to-sequence RNN, that's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=4155" target="_blank">01:09:15.200</a></span> | <span class="t">this one here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=4156" target="_blank">01:09:16.680</a></span> | <span class="t">So that is a standard PyTorch module.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=4160" target="_blank">01:09:20.760</a></span> | <span class="t">Stick it on the GPU.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=4163" target="_blank">01:09:23.240</a></span> | <span class="t">Hopefully by now you've noticed you can call .cuda, but if you call .gpu then it doesn't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=4169" target="_blank">01:09:29.840</a></span> | <span class="t">put it on the GPU if you don't have one.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=4172" target="_blank">01:09:32.060</a></span> | <span class="t">You can also set fastai.core.useGPU to false to force it to not use the GPU, and that can</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=4177" target="_blank">01:09:37.720</a></span> | <span class="t">be super handy for debugging.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=4181" target="_blank">01:09:41.320</a></span> | <span class="t">We then need something that tells it how to handle learning rate groups.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=4187" target="_blank">01:09:47.760</a></span> | <span class="t">So there's a thing called single model that you can pass it to which treats the whole</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=4191" target="_blank">01:09:51.320</a></span> | <span class="t">thing as a single learning rate group.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=4193" target="_blank">01:09:53.920</a></span> | <span class="t">So this is like the easiest way to turn a PyTorch module into a fastai model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=4201" target="_blank">01:10:01.280</a></span> | <span class="t">Here's the model data object we created before.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=4205" target="_blank">01:10:05.160</a></span> | <span class="t">We could then just call learner to turn that into a learner, but if we call RNN_learner,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=4211" target="_blank">01:10:11.240</a></span> | <span class="t">RNN_learner is a learner.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=4216" target="_blank">01:10:16.480</a></span> | <span class="t">It defines cross-entropy as the default criteria, in this case we're overriding that anyway,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=4221" target="_blank">01:10:21.000</a></span> | <span class="t">so that's not what we care about.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=4222" target="_blank">01:10:22.920</a></span> | <span class="t">But it does add in these save encoder and load encoder things that can be handy sometimes.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=4231" target="_blank">01:10:31.400</a></span> | <span class="t">So in this case we really put it to set learner, but RNN_learner also works.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=4238" target="_blank">01:10:38.400</a></span> | <span class="t">So here's how we turn our PyTorch module into a fastai model into a learner.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=4246" target="_blank">01:10:46.120</a></span> | <span class="t">And once we have a learner, give it our new loss function, and then we can call lrefind,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=4253" target="_blank">01:10:53.600</a></span> | <span class="t">and we can call fit, and it runs through a while, and we can save it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=4259" target="_blank">01:10:59.160</a></span> | <span class="t">So all the normal learn stuff now works.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=4262" target="_blank">01:11:02.760</a></span> | <span class="t">Remember the model attribute of a learner is a standard PyTorch model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=4266" target="_blank">01:11:06.480</a></span> | <span class="t">So we can pass that some x which we can grab out of our validation set, or you could use</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=4273" target="_blank">01:11:13.440</a></span> | <span class="t">learn.predict_array or whatever you like to get some predictions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=4279" target="_blank">01:11:19.820</a></span> | <span class="t">And then we can convert those predictions into words by going .max1 to grab the index</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=4286" target="_blank">01:11:26.000</a></span> | <span class="t">of the highest probability words to get some predictions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=4290" target="_blank">01:11:30.440</a></span> | <span class="t">And then we can go through a few examples and print out the French, the correct English,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=4297" target="_blank">01:11:37.680</a></span> | <span class="t">and the predicted English for things that are not padding.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=4303" target="_blank">01:11:43.560</a></span> | <span class="t">And here we go.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=4305" target="_blank">01:11:45.320</a></span> | <span class="t">So amazingly enough, this kind of simplest possible written largely from scratch PyTorch</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=4314" target="_blank">01:11:54.520</a></span> | <span class="t">module on only 50,000 sentences is sometimes capable on a validation set of giving you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=4320" target="_blank">01:12:00.760</a></span> | <span class="t">exactly the right answer, sometimes the right answer in slightly different wording, and sometimes</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=4329" target="_blank">01:12:09.400</a></span> | <span class="t">sentences that aren't grammatically sensible or even have too many question marks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=4334" target="_blank">01:12:14.120</a></span> | <span class="t">So we're well on the right track, I think you would agree.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=4338" target="_blank">01:12:18.400</a></span> | <span class="t">So even the simplest possible sec-to-sec trained for a very small number of epochs without</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=4345" target="_blank">01:12:25.780</a></span> | <span class="t">any pre-training other than the use of word embeddings is surprisingly good.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=4352" target="_blank">01:12:32.600</a></span> | <span class="t">So I think the message here -- and we're going to improve this in a moment after the break</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=4356" target="_blank">01:12:36.340</a></span> | <span class="t">-- but I think the message here is even sequence-to-sequence models that you think are simpler than could</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=4362" target="_blank">01:12:42.560</a></span> | <span class="t">possibly work, even with less data than you think you could learn from can be surprisingly</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=4368" target="_blank">01:12:48.480</a></span> | <span class="t">effective and in certain situations this may even be enough for your needs.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=4374" target="_blank">01:12:54.800</a></span> | <span class="t">So we're going to learn a few tricks after the break which will make this much better.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=4383" target="_blank">01:13:03.160</a></span> | <span class="t">So let's come back at 7.50.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=4390" target="_blank">01:13:10.740</a></span> | <span class="t">So one question that came up during the break is that some of the tokens that are missing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=4400" target="_blank">01:13:20.800</a></span> | <span class="t">in fast text had a curly quote rather than a straight quote, for example, and the question</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=4408" target="_blank">01:13:28.680</a></span> | <span class="t">was would it help to normalize punctuation?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=4415" target="_blank">01:13:35.700</a></span> | <span class="t">And the answer for this particular case is probably yes.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=4424" target="_blank">01:13:44.320</a></span> | <span class="t">You do have to be very careful though because it may turn out that people using beautiful</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=4431" target="_blank">01:13:51.140</a></span> | <span class="t">curly quotes like using more formal language and actually writing in a different way.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=4437" target="_blank">01:13:57.340</a></span> | <span class="t">So I generally -- if you're going to do some kind of pre-processing like punctuation normalization,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=4444" target="_blank">01:14:04.360</a></span> | <span class="t">you should definitely check your results with and without, because nearly always that kind</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=4449" target="_blank">01:14:09.680</a></span> | <span class="t">of pre-processing makes things worse even when I'm sure it won't.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=4454" target="_blank">01:14:14.400</a></span> | <span class="t">What might be some ways of regularizing these sequence-to-sequence models besides dropout</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=4462" target="_blank">01:14:22.880</a></span> | <span class="t">and weight gain?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=4468" target="_blank">01:14:28.220</a></span> | <span class="t">Let me think about that during the week.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=4472" target="_blank">01:14:32.240</a></span> | <span class="t">It's like, you know, AWDLSTM, which we've been relying on a lot, has so many great -- I mean,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=4481" target="_blank">01:14:41.560</a></span> | <span class="t">it's all dropout.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=4482" target="_blank">01:14:42.560</a></span> | <span class="t">Well, not all dropout.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=4483" target="_blank">01:14:43.560</a></span> | <span class="t">There's dropout of many different kinds.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=4486" target="_blank">01:14:46.880</a></span> | <span class="t">And then there's the -- we haven't talked about it much, but there's also a kind of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=4490" target="_blank">01:14:50.760</a></span> | <span class="t">regularization based on activations and stuff like that as well and on changes and whatever.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=4500" target="_blank">01:15:00.000</a></span> | <span class="t">I just haven't seen anybody put anything like that amount of work into regularization of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=4505" target="_blank">01:15:05.280</a></span> | <span class="t">sequence-to-sequence models, and I think there's a huge opportunity for somebody to do like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=4510" target="_blank">01:15:10.560</a></span> | <span class="t">the AWDLSTM of Sek2Sec, which might be as simple as stealing all the ideas from AWDLSTM and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=4518" target="_blank">01:15:18.640</a></span> | <span class="t">using them directly in Sek2Sec.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=4521" target="_blank">01:15:21.160</a></span> | <span class="t">That would be pretty easy to try, I think, and there's been an interesting paper that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=4527" target="_blank">01:15:27.440</a></span> | <span class="t">actually Stephen Merritt, he's added in the last couple of weeks, where he used an idea</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=4532" target="_blank">01:15:32.240</a></span> | <span class="t">which I don't know if he stole it from me, but it was certainly something I had also</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=4536" target="_blank">01:15:36.720</a></span> | <span class="t">recently done and talked about on Twitter.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=4538" target="_blank">01:15:38.560</a></span> | <span class="t">Either way, I'm thrilled that he's done it, which was to take all of those different AWDLSTM</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=4546" target="_blank">01:15:46.080</a></span> | <span class="t">hyperparameters and train a bunch of different models and then use a random forest to find</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=4551" target="_blank">01:15:51.720</a></span> | <span class="t">out with feature importance which ones actually matter the most and then figure out like how</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=4556" target="_blank">01:15:56.040</a></span> | <span class="t">to set them.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=4558" target="_blank">01:15:58.640</a></span> | <span class="t">I think you could totally use this approach to figure out the sequence-to-sequence regularization</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=4566" target="_blank">01:16:06.520</a></span> | <span class="t">approaches which ones are best and optimize them, and that would be amazing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=4574" target="_blank">01:16:14.560</a></span> | <span class="t">But at the moment, I don't know that there are additional ideas to sequence-to-sequence</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=4579" target="_blank">01:16:19.280</a></span> | <span class="t">regularization that I can think of beyond what's in that paper for regular language</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=4584" target="_blank">01:16:24.160</a></span> | <span class="t">model stuff, and probably all those same approaches would work.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=4589" target="_blank">01:16:29.680</a></span> | <span class="t">So tricks, trick number 1, go bidirectional.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=4597" target="_blank">01:16:37.960</a></span> | <span class="t">For classification, my approach to bidirectional that I've suggested you use is take all of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=4607" target="_blank">01:16:47.160</a></span> | <span class="t">your token sequences, spin them around, train a new language model, and train a new classifier,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=4614" target="_blank">01:16:54.080</a></span> | <span class="t">and I also mentioned the wiki text pre-trained model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=4618" target="_blank">01:16:58.080</a></span> | <span class="t">If you replace fwd with bwd in the name, you'll get the pre-trained backward model I created</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=4624" target="_blank">01:17:04.240</a></span> | <span class="t">for you.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=4625" target="_blank">01:17:05.240</a></span> | <span class="t">So you can use that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=4626" target="_blank">01:17:06.240</a></span> | <span class="t">Get a set of predictions and then average the predictions just like a normal ensemble,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=4632" target="_blank">01:17:12.040</a></span> | <span class="t">and that's kind of how we do bider for that kind of classification.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=4636" target="_blank">01:17:16.240</a></span> | <span class="t">There may be ways to do it end-to-end, but I haven't quite figured them out yet, they're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=4641" target="_blank">01:17:21.760</a></span> | <span class="t">not in fastAI yet and I don't think anybody has written a paper about them yet, so if</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=4645" target="_blank">01:17:25.840</a></span> | <span class="t">you figure it out, that's an interesting line of research.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=4651" target="_blank">01:17:31.680</a></span> | <span class="t">But because we're not doing massive documents where we have to chunk it into separate bits</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=4658" target="_blank">01:17:38.600</a></span> | <span class="t">and then pull over them and whatever, we can do bider very easily in this case, which is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=4665" target="_blank">01:17:45.480</a></span> | <span class="t">literally as simple as adding bidirectional equals true to our encoder.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=4673" target="_blank">01:17:53.960</a></span> | <span class="t">People tend not to do bidirectional for the decoder, I think partly because it's considered</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=4680" target="_blank">01:18:00.640</a></span> | <span class="t">cheating, but I don't know, I was just talking to somebody at the break about it, maybe it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=4690" target="_blank">01:18:10.120</a></span> | <span class="t">can work in some situations, although it might need to be more of an ensembling approach in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=4696" target="_blank">01:18:16.480</a></span> | <span class="t">the decoder because it's a bit less obvious.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=4700" target="_blank">01:18:20.120</a></span> | <span class="t">The encoder is very simple, bidirectional equals true, and with bidirectional equals</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=4709" target="_blank">01:18:29.600</a></span> | <span class="t">true rather than just having an RNN which is going this direction, we have a second</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=4716" target="_blank">01:18:36.120</a></span> | <span class="t">RNN that's going in this direction.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=4721" target="_blank">01:18:41.200</a></span> | <span class="t">And so that second RNN literally is visiting each token in the opposing order, so when</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=4730" target="_blank">01:18:50.240</a></span> | <span class="t">we get the final hidden state, it's here rather than here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=4736" target="_blank">01:18:56.740</a></span> | <span class="t">But the hidden state is of the same size, so the final result is that we end up with</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=4742" target="_blank">01:19:02.080</a></span> | <span class="t">a tensor that's got an extra too long axis.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=4747" target="_blank">01:19:07.000</a></span> | <span class="t">And depending on what library you use, often that will be then combined with the number</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=4751" target="_blank">01:19:11.360</a></span> | <span class="t">of layers thing, so if you've got two layers and bidirectional, that tensor dimension is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=4756" target="_blank">01:19:16.840</a></span> | <span class="t">now with length 4.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=4759" target="_blank">01:19:19.960</a></span> | <span class="t">With PyTorch, it kind of depends which bit of the process you're looking at as to whether</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=4765" target="_blank">01:19:25.140</a></span> | <span class="t">you get a separate result for each layer and each bidirectional bit and so forth.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=4769" target="_blank">01:19:29.320</a></span> | <span class="t">You have to look up the docs and it will tell you the inputs, outputs, tensor sizes, appropriate</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=4775" target="_blank">01:19:35.040</a></span> | <span class="t">for the number of layers and whether you have bidirectional equals true.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=4778" target="_blank">01:19:38.940</a></span> | <span class="t">In this particular case, you'll basically see all the changes I've had to make.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=4785" target="_blank">01:19:45.040</a></span> | <span class="t">So for example, you'll see when I added bidirectional equals true, my linear layer now needs number</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=4790" target="_blank">01:19:50.640</a></span> | <span class="t">of hidden times 2 to reflect the fact that we have that second direction in our hidden</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=4796" target="_blank">01:19:56.480</a></span> | <span class="t">state now, you'll see in it hidden, it's now self.number of layers times 2 here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=4805" target="_blank">01:20:05.000</a></span> | <span class="t">So you'll just see there's a few places where there's been an extra 2 that has to be thrown</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=4811" target="_blank">01:20:11.100</a></span> | <span class="t">in.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=4812" target="_blank">01:20:12.100</a></span> | <span class="t">Yes, Yannette?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=4813" target="_blank">01:20:13.100</a></span> | <span class="t">Why making a decoder bidirectional is considered cheating?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=4819" target="_blank">01:20:19.440</a></span> | <span class="t">Well, it's not just that it's cheating, it's like we have this loop going on, you know?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=4828" target="_blank">01:20:28.760</a></span> | <span class="t">It's not as simple as just kind of having two tensors, and then how do you turn those</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=4837" target="_blank">01:20:37.340</a></span> | <span class="t">two separate loops into a final result?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=4841" target="_blank">01:20:41.920</a></span> | <span class="t">After talking about it during the break, I've kind of gone from "Hey, everybody knows it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=4847" target="_blank">01:20:47.480</a></span> | <span class="t">doesn't work" to "Oh, maybe it kind of could work, but it requires more thought."</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=4853" target="_blank">01:20:53.080</a></span> | <span class="t">It's quite possible during the week I realized it's a dumb idea and I was being stupid, but</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=4857" target="_blank">01:20:57.920</a></span> | <span class="t">we'll think about it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=4858" target="_blank">01:20:58.920</a></span> | <span class="t">Another question people have, why do you need to have an end to that loop?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=4864" target="_blank">01:21:04.560</a></span> | <span class="t">Why do I have a what to the loop?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=4866" target="_blank">01:21:06.040</a></span> | <span class="t">Why do you need to have an end to that loop?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=4869" target="_blank">01:21:09.240</a></span> | <span class="t">You have like a range, if you are...</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=4872" target="_blank">01:21:12.640</a></span> | <span class="t">I mean, because when I start training everything's random, so this will probably never be true.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=4883" target="_blank">01:21:23.820</a></span> | <span class="t">Later on it will pretty much always break out eventually.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=4888" target="_blank">01:21:28.360</a></span> | <span class="t">It's basically like we're going to go forever.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=4893" target="_blank">01:21:33.640</a></span> | <span class="t">It's really important to remember when you're designing an architecture that when you start,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=4898" target="_blank">01:21:38.180</a></span> | <span class="t">the model knows nothing about anything.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=4901" target="_blank">01:21:41.040</a></span> | <span class="t">So you kind of want to make sure it's going to do something that's vaguely sensible.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=4906" target="_blank">01:21:46.400</a></span> | <span class="t">So bidirectional means we got out to 358 cross-entropy loss with a single direction.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=4919" target="_blank">01:21:59.560</a></span> | <span class="t">With bidirection, it's down to 351.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=4922" target="_blank">01:22:02.920</a></span> | <span class="t">So that improved it a bit, that's good, and as I say, it shouldn't really slow things</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=4929" target="_blank">01:22:09.260</a></span> | <span class="t">down too much, bidirectional does mean there's a little bit more sequential processing have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=4936" target="_blank">01:22:16.200</a></span> | <span class="t">to happen, but it's generally a good win.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=4940" target="_blank">01:22:20.520</a></span> | <span class="t">In the Google translation model of the eight layers, only the first layer is bidirectional</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=4947" target="_blank">01:22:27.160</a></span> | <span class="t">because it allows it to do more in parallel.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=4949" target="_blank">01:22:29.880</a></span> | <span class="t">So if you create really deep models, you may need to think about which one's bidirectional,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=4954" target="_blank">01:22:34.320</a></span> | <span class="t">otherwise you'll have performance issues.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=4956" target="_blank">01:22:36.360</a></span> | <span class="t">Okay, so 351.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=4959" target="_blank">01:22:39.440</a></span> | <span class="t">Now let's talk about teacher forcing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=4962" target="_blank">01:22:42.760</a></span> | <span class="t">So teacher forcing is going to come back to this idea that when the model starts learning,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=4972" target="_blank">01:22:52.320</a></span> | <span class="t">it knows nothing about nothing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=4974" target="_blank">01:22:54.460</a></span> | <span class="t">So when the model starts learning, it is not going to spit out 'uh' at this point, it's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=4980" target="_blank">01:23:00.160</a></span> | <span class="t">going to spit out some random, meaningless word because it doesn't know anything about</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=4985" target="_blank">01:23:05.080</a></span> | <span class="t">German or about English or about the idea of language or anything.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=4988" target="_blank">01:23:08.140</a></span> | <span class="t">And then it's going to feed it down here as an input and be totally unhelpful.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=4992" target="_blank">01:23:12.320</a></span> | <span class="t">And so that means that early learning is going to be very, very difficult because it's feeding</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=4996" target="_blank">01:23:16.960</a></span> | <span class="t">in an input that's stupid into a model that knows nothing, and somehow it's going to get</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=5002" target="_blank">01:23:22.440</a></span> | <span class="t">better.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=5003" target="_blank">01:23:23.440</a></span> | <span class="t">So it's not asking too much, eventually it gets there, but it's definitely not as helpful</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=5008" target="_blank">01:23:28.940</a></span> | <span class="t">as we can be.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=5010" target="_blank">01:23:30.600</a></span> | <span class="t">So what if instead of feeding in the thing I predicted just now, what if instead we feed</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=5024" target="_blank">01:23:44.840</a></span> | <span class="t">in the actual correct word it was meant to be?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=5029" target="_blank">01:23:49.880</a></span> | <span class="t">Now we can't do that at inference time because by definition we don't know the correct word</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=5034" target="_blank">01:23:54.480</a></span> | <span class="t">and we've been asked to translate it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=5037" target="_blank">01:23:57.200</a></span> | <span class="t">And we can't require a correct translation in order to do translation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=5041" target="_blank">01:24:01.760</a></span> | <span class="t">So the way I've set this up is I've got this thing called PR force, which is probability</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=5048" target="_blank">01:24:08.180</a></span> | <span class="t">of forcing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=5049" target="_blank">01:24:09.520</a></span> | <span class="t">And if some random number is less than that probability, then I'm going to replace my</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=5055" target="_blank">01:24:15.080</a></span> | <span class="t">decoder input with the actual correct thing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=5060" target="_blank">01:24:20.080</a></span> | <span class="t">And if we've already gone too far, if it's already longer than the target sentence, I'm</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=5064" target="_blank">01:24:24.480</a></span> | <span class="t">just going to stop because I can't give it the correct thing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=5068" target="_blank">01:24:28.480</a></span> | <span class="t">So you can see how beautiful PyTorch is for this, because if you tried to do this with</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=5073" target="_blank">01:24:33.760</a></span> | <span class="t">some static graph thing like classic TensorFlow, I tried.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=5080" target="_blank">01:24:40.600</a></span> | <span class="t">One of the key reasons we switched to PyTorch at this exact point in last year's class was</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=5086" target="_blank">01:24:46.120</a></span> | <span class="t">because Jeremy tried to implement teacher forcing in Keras and TensorFlow and went even</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=5090" target="_blank">01:24:50.840</a></span> | <span class="t">more insane than he started.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=5094" target="_blank">01:24:54.040</a></span> | <span class="t">It was weeks of getting nowhere.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=5097" target="_blank">01:24:57.300</a></span> | <span class="t">And then literally on Twitter, I think it was on Dracopathy, I said something about PyTorch</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=5107" target="_blank">01:25:07.280</a></span> | <span class="t">that just came out and it's really cool.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=5109" target="_blank">01:25:09.720</a></span> | <span class="t">And I tried it that day.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=5112" target="_blank">01:25:12.000</a></span> | <span class="t">By the next day, I had teacher forcing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=5114" target="_blank">01:25:14.920</a></span> | <span class="t">And so I was like, oh my gosh.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=5117" target="_blank">01:25:17.480</a></span> | <span class="t">And all the stuff of trying to debug things, it was suddenly so much easier, and this kind</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=5122" target="_blank">01:25:22.040</a></span> | <span class="t">of dynamic stuff is so much easier.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=5124" target="_blank">01:25:24.520</a></span> | <span class="t">So this is a great example of like, hey, I get to use random numbers and if statements</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=5129" target="_blank">01:25:29.120</a></span> | <span class="t">and stuff.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=5130" target="_blank">01:25:30.120</a></span> | <span class="t">So here's the basic idea, at the start of training, let's set PR force really high so</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=5139" target="_blank">01:25:39.600</a></span> | <span class="t">that nearly always it gets the actual correct previous word, and so it has a useful input.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=5147" target="_blank">01:25:47.800</a></span> | <span class="t">And then as I train a bit more, let's decrease PR force so that by the end, PR force is 0,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=5155" target="_blank">01:25:55.480</a></span> | <span class="t">and it has to learn properly, which is fine because it's now actually feeding in sensible</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=5160" target="_blank">01:26:00.600</a></span> | <span class="t">inputs most of the time anyway.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=5163" target="_blank">01:26:03.720</a></span> | <span class="t">So let's now write something such that in the training loop, it gradually decreases</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=5171" target="_blank">01:26:11.440</a></span> | <span class="t">PR force.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=5173" target="_blank">01:26:13.440</a></span> | <span class="t">So how do you do that?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=5175" target="_blank">01:26:15.000</a></span> | <span class="t">Well one approach would be to write our own training loop, but let's not do that because</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=5180" target="_blank">01:26:20.240</a></span> | <span class="t">we already have a training loop that has progress bars and uses exponential weighted averages</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=5185" target="_blank">01:26:25.420</a></span> | <span class="t">to smooth out the losses and keeps track of metrics.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=5188" target="_blank">01:26:28.080</a></span> | <span class="t">And it does a bunch of things which are not rocket science, but they're kind of convenient.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=5193" target="_blank">01:26:33.520</a></span> | <span class="t">And they also keep track of calling the reset for RNNs at the start of an epoch to make</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=5198" target="_blank">01:26:38.720</a></span> | <span class="t">sure that the hidden states set to zeros and little things like that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=5203" target="_blank">01:26:43.000</a></span> | <span class="t">You'd rather not have to write that from scratch.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=5205" target="_blank">01:26:45.600</a></span> | <span class="t">So what we've tended to find is that as I start to write some new thing, and I'm like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=5213" target="_blank">01:26:53.480</a></span> | <span class="t">I need to replace some part of the code, I'll then add some little hook so that we can all</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=5221" target="_blank">01:27:01.080</a></span> | <span class="t">use that hook to make things easier.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=5223" target="_blank">01:27:03.960</a></span> | <span class="t">In this particular case, there's a hook that I've ended up using all the damn time now,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=5228" target="_blank">01:27:08.880</a></span> | <span class="t">which is the hook called the stepper.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=5232" target="_blank">01:27:12.040</a></span> | <span class="t">And so if you look at our code, model.py is where our fit function lives.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=5241" target="_blank">01:27:21.320</a></span> | <span class="t">And so the fit function in model.py, we've seen it before, I think it's like the lowest</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=5246" target="_blank">01:27:26.840</a></span> | <span class="t">level thing that doesn't require a learner, it doesn't really require anything much at</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=5251" target="_blank">01:27:31.320</a></span> | <span class="t">all.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=5252" target="_blank">01:27:32.320</a></span> | <span class="t">It just requires a standard PyTorch model and a model data object.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=5255" target="_blank">01:27:35.360</a></span> | <span class="t">You just need to know how many epochs, a standard PyTorch optimizer, and a standard PyTorch</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=5260" target="_blank">01:27:40.640</a></span> | <span class="t">loss function.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=5262" target="_blank">01:27:42.120</a></span> | <span class="t">So we've hardly ever used it in the class, we normally call learn.fit, but learn.fit calls</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=5268" target="_blank">01:27:48.000</a></span> | <span class="t">this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=5269" target="_blank">01:27:49.000</a></span> | <span class="t">This is our lowest level thing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=5270" target="_blank">01:27:50.000</a></span> | <span class="t">But we've looked at the source code here sometimes, we've seen how it loops through each epoch</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=5274" target="_blank">01:27:54.800</a></span> | <span class="t">and it loops through each thing in our batch and calls stepper.step.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=5281" target="_blank">01:28:01.560</a></span> | <span class="t">And so stepper.step is the thing that's responsible for calling the model, finding the loss function</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=5287" target="_blank">01:28:07.360</a></span> | <span class="t">and calling the optimizer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=5290" target="_blank">01:28:10.080</a></span> | <span class="t">And so by default stepper.step uses a particular class called stepper, which there's a few things</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=5298" target="_blank">01:28:18.520</a></span> | <span class="t">you don't know about too much, but basically it calls the model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=5302" target="_blank">01:28:22.040</a></span> | <span class="t">So the model ends up inside m, zeros the gradients, calls the loss function, calls backwards,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=5312" target="_blank">01:28:32.640</a></span> | <span class="t">does gradient clipping if necessary, and then calls the optimizer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=5317" target="_blank">01:28:37.080</a></span> | <span class="t">So they're the basic steps that back when we looked at PyTorch from scratch, we had</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=5323" target="_blank">01:28:43.560</a></span> | <span class="t">to do.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=5324" target="_blank">01:28:44.920</a></span> | <span class="t">So the nice thing is we can replace that with something else rather than replacing the training</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=5333" target="_blank">01:28:53.160</a></span> | <span class="t">loop.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=5334" target="_blank">01:28:54.160</a></span> | <span class="t">So if you inherit from stepper and then write your own version of step, you can just copy</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=5341" target="_blank">01:29:01.480</a></span> | <span class="t">and paste the contents of step and add whatever you like.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=5346" target="_blank">01:29:06.180</a></span> | <span class="t">Or if it's something you're going to do before or afterwards, you could even call super.step.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=5352" target="_blank">01:29:12.640</a></span> | <span class="t">In this case, I'd rather suspect I've been unnecessarily complicated here, I probably</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=5358" target="_blank">01:29:18.900</a></span> | <span class="t">could have replaced, commented out all of that and just said super.step x's comma y</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=5367" target="_blank">01:29:27.640</a></span> | <span class="t">comma epoch.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=5368" target="_blank">01:29:28.640</a></span> | <span class="t">Because I think this is an exact copy of everything, but as I say, when I'm prototyping I don't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=5374" target="_blank">01:29:34.920</a></span> | <span class="t">think carefully about how to minimize my code.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=5377" target="_blank">01:29:37.560</a></span> | <span class="t">I copied and pasted the contents of the code from step, and I added a single line to the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=5382" target="_blank">01:29:42.280</a></span> | <span class="t">top which was to replace prforce in my module with something that gradually decreased linearly</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=5394" target="_blank">01:29:54.600</a></span> | <span class="t">for the first 10 epochs, and after 10 epochs it was zero.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=5399" target="_blank">01:29:59.600</a></span> | <span class="t">So total hack, but good enough to try it out.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=5404" target="_blank">01:30:04.960</a></span> | <span class="t">So the nice thing is that everything else is the same, I've added these three lines</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=5412" target="_blank">01:30:12.920</a></span> | <span class="t">of code to my module, and the only thing I need to do other than differently is when</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=5420" target="_blank">01:30:20.040</a></span> | <span class="t">I call fit is I pass in my customized stepper class.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=5426" target="_blank">01:30:26.880</a></span> | <span class="t">And so that's going to do teacher forcing, and so we don't have bidirectional, so we're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=5432" target="_blank">01:30:32.880</a></span> | <span class="t">just changing one thing at a time.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=5434" target="_blank">01:30:34.880</a></span> | <span class="t">So we should compare this to our unidirectional results, which was 3.58, and this is 3.49.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=5445" target="_blank">01:30:45.440</a></span> | <span class="t">So that was an improvement.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=5447" target="_blank">01:30:47.800</a></span> | <span class="t">So that's great!</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=5448" target="_blank">01:30:48.800</a></span> | <span class="t">I needed to make sure I at least did 10 epochs because before that it was cheating by using</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=5454" target="_blank">01:30:54.860</a></span> | <span class="t">the teacher forcing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=5458" target="_blank">01:30:58.400</a></span> | <span class="t">So that's good, that's an improvement.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=5461" target="_blank">01:31:01.400</a></span> | <span class="t">So we've got another trick, and this next trick is a bigger trick.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=5467" target="_blank">01:31:07.840</a></span> | <span class="t">It's a pretty cool trick, and it's called attention.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=5472" target="_blank">01:31:12.760</a></span> | <span class="t">And the basic idea of attention is this, which is, expecting the entirety of the sentence</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=5485" target="_blank">01:31:25.920</a></span> | <span class="t">to be summarized into this single hidden vector is asking a lot.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=5492" target="_blank">01:31:32.340</a></span> | <span class="t">It has to know what was said and how it was said and everything necessary to create the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=5498" target="_blank">01:31:38.880</a></span> | <span class="t">sentence in German.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=5501" target="_blank">01:31:41.240</a></span> | <span class="t">And so the idea of attention is basically like maybe we're asking too much, particularly</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=5506" target="_blank">01:31:46.800</a></span> | <span class="t">because we could use this form of model where we output every step of the loop to not just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=5517" target="_blank">01:31:57.280</a></span> | <span class="t">have a hidden state at the end, but to hit a hidden state after every single word.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=5522" target="_blank">01:32:02.680</a></span> | <span class="t">And why not try and use that information?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=5527" target="_blank">01:32:07.040</a></span> | <span class="t">It's already there, and so far we've just been throwing it away.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=5533" target="_blank">01:32:13.120</a></span> | <span class="t">And not only that, but bidirectional, we've got every step, we've got two vectors of state</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=5542" target="_blank">01:32:22.360</a></span> | <span class="t">that we can use.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=5544" target="_blank">01:32:24.200</a></span> | <span class="t">So how could we use this piece of state, this piece of state, this piece of state, this piece</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=5549" target="_blank">01:32:29.000</a></span> | <span class="t">of state and this piece of state rather than just the final state?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=5554" target="_blank">01:32:34.000</a></span> | <span class="t">And so the basic idea is, well, let's say I'm translating this word right now.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=5562" target="_blank">01:32:42.120</a></span> | <span class="t">Which of these five pieces of state do I want?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=5566" target="_blank">01:32:46.040</a></span> | <span class="t">And of course the answer is if I'm doing -- well, actually let's pick a more interesting word.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=5573" target="_blank">01:32:53.080</a></span> | <span class="t">So if I'm trying to do loved, then clearly the hidden state I want is this one, because</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=5579" target="_blank">01:32:59.920</a></span> | <span class="t">this is the word.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=5583" target="_blank">01:33:03.360</a></span> | <span class="t">And then for this preposition, whatever, this little word here, no it's not a preposition,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=5590" target="_blank">01:33:10.000</a></span> | <span class="t">I guess it's part of the verb.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=5591" target="_blank">01:33:11.380</a></span> | <span class="t">So for this part of the verb, I probably would need this and this and this to make sure that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=5598" target="_blank">01:33:18.000</a></span> | <span class="t">I've got the tense right and know that I actually need this part of the verb and so forth.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=5603" target="_blank">01:33:23.760</a></span> | <span class="t">So depending on which bit I'm translating, I'm going to need one or more bits of these</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=5612" target="_blank">01:33:32.200</a></span> | <span class="t">various hidden states.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=5613" target="_blank">01:33:33.960</a></span> | <span class="t">And in fact, I probably want some weighting of them.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=5618" target="_blank">01:33:38.580</a></span> | <span class="t">So like what I'm doing here, I probably mainly want this state, but I maybe want a little</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=5624" target="_blank">01:33:44.440</a></span> | <span class="t">bit of that one and a little bit of that one.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=5627" target="_blank">01:33:47.780</a></span> | <span class="t">So in other words, for these five pieces of hidden state, we want a weighted average, and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=5634" target="_blank">01:33:54.440</a></span> | <span class="t">we want it weighted by something that can figure out which bits of the sentence are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=5640" target="_blank">01:34:00.720</a></span> | <span class="t">most important right now.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=5643" target="_blank">01:34:03.080</a></span> | <span class="t">So how do we figure out something like which bits of the sentence are important right now?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=5649" target="_blank">01:34:09.680</a></span> | <span class="t">We create a neural net, and we train the neural net to figure it out.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=5655" target="_blank">01:34:15.400</a></span> | <span class="t">When do we train that neural net?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=5657" target="_blank">01:34:17.720</a></span> | <span class="t">End to end.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=5659" target="_blank">01:34:19.440</a></span> | <span class="t">So let's now train two neural nets.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=5661" target="_blank">01:34:21.920</a></span> | <span class="t">We've actually already got a bunch, we've got an RNN encoder, an RNN decoder, a couple</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=5666" target="_blank">01:34:26.720</a></span> | <span class="t">of linear layers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=5669" target="_blank">01:34:29.040</a></span> | <span class="t">What the hell?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=5670" target="_blank">01:34:30.040</a></span> | <span class="t">Let's put the neural net into the mix.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=5672" target="_blank">01:34:32.760</a></span> | <span class="t">And this neural net is going to spit out a weight for every one of these things, and we're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=5678" target="_blank">01:34:38.760</a></span> | <span class="t">going to take the weighted average at every step.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=5681" target="_blank">01:34:41.120</a></span> | <span class="t">And it's just another set of parameters that we learn all at the same time.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=5686" target="_blank">01:34:46.700</a></span> | <span class="t">And so that's called attention.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=5690" target="_blank">01:34:50.140</a></span> | <span class="t">So the idea is that once that attention has been learned, we can see this terrific demo</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=5696" target="_blank">01:34:56.040</a></span> | <span class="t">from Priscilla and Sean Carter, each different word is going to take a weighted average.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=5701" target="_blank">01:35:01.520</a></span> | <span class="t">See how the weights are different depending on which word is being translated.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=5706" target="_blank">01:35:06.880</a></span> | <span class="t">And you can see how it's kind of figuring out the color, the deepness of the blue is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=5710" target="_blank">01:35:10.280</a></span> | <span class="t">how much weight it's using.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=5712" target="_blank">01:35:12.080</a></span> | <span class="t">You can see that each word is basically which word are we translating from.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=5716" target="_blank">01:35:16.480</a></span> | <span class="t">So when we say European, we need to know that both of these two parts are going to be influenced</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=5720" target="_blank">01:35:20.360</a></span> | <span class="t">or if we're doing economic, both of these three parts are going to be influenced, including</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=5723" target="_blank">01:35:23.880</a></span> | <span class="t">the gender of the definite article and so forth.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=5727" target="_blank">01:35:27.960</a></span> | <span class="t">So check out this distill.pub article.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=5733" target="_blank">01:35:33.360</a></span> | <span class="t">These things are all nice little interactive diagrams.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=5738" target="_blank">01:35:38.040</a></span> | <span class="t">It basically shows you how attention works and what the actual attention looks like in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=5744" target="_blank">01:35:44.320</a></span> | <span class="t">a trained translation model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=5748" target="_blank">01:35:48.040</a></span> | <span class="t">So let's try and implement attention.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=5753" target="_blank">01:35:53.160</a></span> | <span class="t">So with attention, it's basically this is all identical, and the encoder is identical,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=5768" target="_blank">01:36:08.360</a></span> | <span class="t">and all of this bit of the decoder is identical.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=5772" target="_blank">01:36:12.280</a></span> | <span class="t">There's one difference, which is that we basically are going to take a weighted average.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=5790" target="_blank">01:36:30.880</a></span> | <span class="t">And the way that we're going to do the weighted average is we create a little neural net,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=5795" target="_blank">01:36:35.320</a></span> | <span class="t">which we're going to see here and here, and then we use softmax, because of course the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=5801" target="_blank">01:36:41.600</a></span> | <span class="t">nice thing about softmax is that we want to ensure that all of the weights that we're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=5807" target="_blank">01:36:47.400</a></span> | <span class="t">using add up to 1, and we also kind of expect that one of those weights should probably</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=5813" target="_blank">01:36:53.720</a></span> | <span class="t">be quite a bit higher than the other ones.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=5816" target="_blank">01:36:56.200</a></span> | <span class="t">So softmax gives us the guarantee that they add up to 1, and because it's the eta in it,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=5824" target="_blank">01:37:04.840</a></span> | <span class="t">it tends to encourage one of the weights to be higher than the other ones.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=5829" target="_blank">01:37:09.480</a></span> | <span class="t">So let's see how this works.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=5831" target="_blank">01:37:11.720</a></span> | <span class="t">So what's going to happen is we're going to take the last layer's hidden state, and we're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=5840" target="_blank">01:37:20.280</a></span> | <span class="t">going to stick it into a linear layer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=5844" target="_blank">01:37:24.000</a></span> | <span class="t">And then we're going to stick it into a nonlinear activation, and then we're going to do matrix</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=5852" target="_blank">01:37:32.560</a></span> | <span class="t">multiply, and so if you think about it, linear layer, nonlinear activation, matrix multiply,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=5860" target="_blank">01:37:40.200</a></span> | <span class="t">that's a neural net.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=5861" target="_blank">01:37:41.200</a></span> | <span class="t">It's a neural net with one hidden layer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=5865" target="_blank">01:37:45.640</a></span> | <span class="t">Stick it into a softmax, and then we can use that to weight our encoder outputs.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=5876" target="_blank">01:37:56.600</a></span> | <span class="t">So now, rather than just taking the last encoder output, we've got this is going to be the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=5882" target="_blank">01:38:02.240</a></span> | <span class="t">whole tensor of all of the encoder outputs, which I just weight by this little neural</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=5888" target="_blank">01:38:08.780</a></span> | <span class="t">net that I've created.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=5891" target="_blank">01:38:11.140</a></span> | <span class="t">And that's basically it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=5898" target="_blank">01:38:18.160</a></span> | <span class="t">So what I'll do is I'll put on the wiki thread a couple of papers to check out.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=5907" target="_blank">01:38:27.680</a></span> | <span class="t">There was basically one amazing paper that really originally introduced this idea of attention.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=5915" target="_blank">01:38:35.120</a></span> | <span class="t">And I say amazing because it actually introduced a couple of key things which have really changed</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=5920" target="_blank">01:38:40.480</a></span> | <span class="t">how people work in this field.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=5923" target="_blank">01:38:43.640</a></span> | <span class="t">This area of attention has been used not just for text, but for things like reading text</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=5933" target="_blank">01:38:53.400</a></span> | <span class="t">out of pictures, or doing various stuff with computer vision, and stuff like that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=5939" target="_blank">01:38:59.280</a></span> | <span class="t">And then there's a second paper which Jeffrey Hinton was involved in called Grammar as a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=5945" target="_blank">01:39:05.440</a></span> | <span class="t">Foreign Language, which used this idea of RNNs with attention to basically try to replace</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=5951" target="_blank">01:39:11.880</a></span> | <span class="t">rules-based grammar with an RNN which automatically tagged the grammatical, each word based on</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=5962" target="_blank">01:39:22.440</a></span> | <span class="t">this grammar, and turned out to do it better than any rules-based system.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=5966" target="_blank">01:39:26.320</a></span> | <span class="t">Which today actually kind of seems obvious.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=5969" target="_blank">01:39:29.480</a></span> | <span class="t">I think we're now used to the idea that neural nets do lots of this stuff better than rules-based</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=5975" target="_blank">01:39:35.880</a></span> | <span class="t">systems, but at the time it was considered really surprising.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=5979" target="_blank">01:39:39.800</a></span> | <span class="t">One nice thing is that their summary of how attention works is really nice and concise.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=5987" target="_blank">01:39:47.000</a></span> | <span class="t">Let's go back and look at our original encoder.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=6012" target="_blank">01:40:12.040</a></span> | <span class="t">So an RNN spits out two things.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=6014" target="_blank">01:40:14.960</a></span> | <span class="t">It spits out a list of the state after every time step, and it also tells you the state</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=6023" target="_blank">01:40:23.720</a></span> | <span class="t">at the last time step.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=6025" target="_blank">01:40:25.720</a></span> | <span class="t">And we used the state at the last time step to create the input state for our decoder,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=6034" target="_blank">01:40:34.680</a></span> | <span class="t">which is what we see here, one vector.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=6045" target="_blank">01:40:45.920</a></span> | <span class="t">But we know that it's actually creating a vector at every time step, so wouldn't it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=6050" target="_blank">01:40:50.480</a></span> | <span class="t">be nice to use them all?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=6053" target="_blank">01:40:53.440</a></span> | <span class="t">But wouldn't it be nice to use the ones that's most relevant to translating the word I'm</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=6059" target="_blank">01:40:59.680</a></span> | <span class="t">translating now?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=6062" target="_blank">01:41:02.680</a></span> | <span class="t">So wouldn't it be nice to take a weighted average of the hidden state at each time step,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=6068" target="_blank">01:41:08.140</a></span> | <span class="t">weighted by whatever is the appropriate weight right now?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=6072" target="_blank">01:41:12.340</a></span> | <span class="t">Which for example in this case, "libter" would definitely be time step number 2, which is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=6078" target="_blank">01:41:18.120</a></span> | <span class="t">what it's all about, because that's the word I'm translating.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=6081" target="_blank">01:41:21.720</a></span> | <span class="t">So how do we get a list of weights that is suitable for the word we're training right</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=6090" target="_blank">01:41:30.640</a></span> | <span class="t">now, or the answer is by training a neural net to figure out the list of weights.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=6097" target="_blank">01:41:37.020</a></span> | <span class="t">And so anytime we want to figure out how to train a little neural net that does any task,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=6103" target="_blank">01:41:43.320</a></span> | <span class="t">the easiest way normally always to do that is to include it in your module and train</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=6108" target="_blank">01:41:48.880</a></span> | <span class="t">it in line with everything else.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=6113" target="_blank">01:41:53.480</a></span> | <span class="t">The minimal possible neural net is something that contains two layers and one nonlinear</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=6125" target="_blank">01:42:05.120</a></span> | <span class="t">activation function.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=6129" target="_blank">01:42:09.640</a></span> | <span class="t">So here is one linear layer, and in fact instead of a linear layer, we can't even just grab</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=6145" target="_blank">01:42:25.000</a></span> | <span class="t">a random matrix if we don't care about bias.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=6149" target="_blank">01:42:29.400</a></span> | <span class="t">And so here's a random matrix, it's just a random tensor wrapped up in a parameter.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=6156" target="_blank">01:42:36.000</a></span> | <span class="t">A parameter, remember, is just a PyTorch variable, it's like identical to a variable, but it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=6162" target="_blank">01:42:42.600</a></span> | <span class="t">just tells PyTorch I want you to learn the weights for this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=6168" target="_blank">01:42:48.440</a></span> | <span class="t">So here we've got a linear layer, here we've got a random matrix, and so here at this point</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=6176" target="_blank">01:42:56.760</a></span> | <span class="t">where we start out our decoder, let's take the current hidden state of the decoder, put</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=6190" target="_blank">01:43:10.560</a></span> | <span class="t">that into a linear layer, because what's the information we use to decide what words we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=6198" target="_blank">01:43:18.840</a></span> | <span class="t">should focus on next?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=6200" target="_blank">01:43:20.640</a></span> | <span class="t">The only information we have to go on is what the decoder's hidden state is now.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=6205" target="_blank">01:43:25.000</a></span> | <span class="t">So let's grab that, put it into the linear layer, put it through a nonlinearity, put</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=6214" target="_blank">01:43:34.400</a></span> | <span class="t">it through one more nonlinear layer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=6216" target="_blank">01:43:36.880</a></span> | <span class="t">This one actually doesn't have a bias in it, so it's actually just a matrix multiply.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=6221" target="_blank">01:43:41.360</a></span> | <span class="t">Put that into a softmax, and that's it, that's a little neural net.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=6228" target="_blank">01:43:48.020</a></span> | <span class="t">It doesn't do anything, it's just a neural net, no neural nets do anything, they're just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=6234" target="_blank">01:43:54.520</a></span> | <span class="t">linear layers with nonlinear activations with random weights.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=6238" target="_blank">01:43:58.240</a></span> | <span class="t">But it starts to do something if we give it a job to do, and in this case the job we give</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=6244" target="_blank">01:44:04.520</a></span> | <span class="t">it to do is to say, don't just take the final state, but now let's use all of the encoder</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=6253" target="_blank">01:44:13.000</a></span> | <span class="t">states and let's take all of them and multiply them by the output of that little neural net.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=6262" target="_blank">01:44:22.280</a></span> | <span class="t">And so given that the things in this little neural net are learnable weights, hopefully</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=6268" target="_blank">01:44:28.640</a></span> | <span class="t">it's going to learn to weight those encoder outputs, those encoder hidden states by something</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=6274" target="_blank">01:44:34.080</a></span> | <span class="t">useful.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=6275" target="_blank">01:44:35.840</a></span> | <span class="t">That's all a neural net ever does, is we give it some random weights to start with and a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=6281" target="_blank">01:44:41.460</a></span> | <span class="t">job to do, and hope that it learns to do the job.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=6285" target="_blank">01:44:45.480</a></span> | <span class="t">And it turns out that it does.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=6289" target="_blank">01:44:49.200</a></span> | <span class="t">So everything else in here is identical to what it was before.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=6294" target="_blank">01:44:54.680</a></span> | <span class="t">We've got teacher forcing, it's not bidirectional.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=6298" target="_blank">01:44:58.880</a></span> | <span class="t">So we can see how this goes.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=6300" target="_blank">01:45:00.680</a></span> | <span class="t">You can see, here we are using teacher forcing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=6311" target="_blank">01:45:11.340</a></span> | <span class="t">Teacher forcing had 3.49, and so now we've got nearly exactly the same thing, but we've</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=6318" target="_blank">01:45:18.900</a></span> | <span class="t">got this little minimal neural net figuring out what weightings to give our inputs.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=6325" target="_blank">01:45:25.240</a></span> | <span class="t">Oh wow, now it's down to 3.37.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=6330" target="_blank">01:45:30.060</a></span> | <span class="t">However these things are logs, so e^ of this is quite a significant change.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=6337" target="_blank">01:45:37.540</a></span> | <span class="t">So 3.37, let's try it out.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=6345" target="_blank">01:45:45.340</a></span> | <span class="t">Not bad, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=6346" target="_blank">01:45:46.340</a></span> | <span class="t">Where are they located?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=6347" target="_blank">01:45:47.340</a></span> | <span class="t">What are their skills?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=6348" target="_blank">01:45:48.820</a></span> | <span class="t">What do you do?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=6351" target="_blank">01:45:51.340</a></span> | <span class="t">They're still not perfect, why or why not, but quite a few of them are correct.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=6362" target="_blank">01:46:02.020</a></span> | <span class="t">And again, considering that we're asking it to learn about the very idea of language for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=6366" target="_blank">01:46:06.660</a></span> | <span class="t">two different languages, and how to translate them between the two, and grammar, and vocabulary,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=6371" target="_blank">01:46:11.820</a></span> | <span class="t">and we only have 50,000 sentences, and a lot of the words only appear once, I would say</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=6377" target="_blank">01:46:17.260</a></span> | <span class="t">this is actually pretty amazing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=6384" target="_blank">01:46:24.340</a></span> | <span class="t">Why do we use tan(h) instead of relu for attention-mini-net?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=6388" target="_blank">01:46:28.500</a></span> | <span class="t">I don't quite remember, it's been a while since I looked at it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=6397" target="_blank">01:46:37.180</a></span> | <span class="t">You should totally try using relu and see how it goes.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=6400" target="_blank">01:46:40.660</a></span> | <span class="t">The key difference is that it can go in each direction, and it's limited both at the top</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=6408" target="_blank">01:46:48.900</a></span> | <span class="t">and the bottom.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=6411" target="_blank">01:46:51.060</a></span> | <span class="t">I know very often for the gates inside RNNs and LSTMs and GRUs, tan often works out better.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=6419" target="_blank">01:46:59.260</a></span> | <span class="t">But it's been about a year since I actually looked at that specific question, so I'll</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=6422" target="_blank">01:47:02.900</a></span> | <span class="t">look at it during the week.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=6425" target="_blank">01:47:05.100</a></span> | <span class="t">The short answer is you should try a different activation function and see if you can get</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=6429" target="_blank">01:47:09.100</a></span> | <span class="t">a better result.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=6433" target="_blank">01:47:13.640</a></span> | <span class="t">So what we can do also is we can actually grab the attentions out of the model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=6440" target="_blank">01:47:20.420</a></span> | <span class="t">So I actually added this returnAttention = true, see here, my forward, you can put anything</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=6450" target="_blank">01:47:30.740</a></span> | <span class="t">you like in forward.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=6451" target="_blank">01:47:31.860</a></span> | <span class="t">So I added a returnAttention parameter, false by default, because obviously the training</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=6457" target="_blank">01:47:37.180</a></span> | <span class="t">loop doesn't know anything about it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=6460" target="_blank">01:47:40.620</a></span> | <span class="t">But then I just had something here saying if returnAttention, then stick the attentions</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=6464" target="_blank">01:47:44.740</a></span> | <span class="t">on as well, and the attentions is simply that value, a, just check it in a list.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=6472" target="_blank">01:47:52.700</a></span> | <span class="t">So we can now call the model with returnAttention = true and get back the probabilities and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=6478" target="_blank">01:47:58.500</a></span> | <span class="t">the attentions, which means as well as printing out these here, we can draw pictures.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=6485" target="_blank">01:48:05.900</a></span> | <span class="t">That each time step of the attention.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=6488" target="_blank">01:48:08.700</a></span> | <span class="t">And so you can see at the start, the attention is all in the first word, second word, third</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=6492" target="_blank">01:48:12.860</a></span> | <span class="t">word, a couple of different words.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=6494" target="_blank">01:48:14.780</a></span> | <span class="t">And this is just for one particular sentence.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=6500" target="_blank">01:48:20.340</a></span> | <span class="t">So you can kind of see, this is the equivalent, this is like when your Chris Oler and Sean</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=6509" target="_blank">01:48:29.420</a></span> | <span class="t">Carter make things that look like this, when you're Jeremy Howard, the exact same information</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=6514" target="_blank">01:48:34.660</a></span> | <span class="t">looks like this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=6515" target="_blank">01:48:35.660</a></span> | <span class="t">It's the same thing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=6516" target="_blank">01:48:36.940</a></span> | <span class="t">Just pretend that it's beautiful.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=6521" target="_blank">01:48:41.820</a></span> | <span class="t">So you can see basically at each different time step, we've got a different attention.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=6527" target="_blank">01:48:47.340</a></span> | <span class="t">And it's really important when you try to build something like this, you don't really</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=6534" target="_blank">01:48:54.780</a></span> | <span class="t">know if it's not working.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=6536" target="_blank">01:48:56.980</a></span> | <span class="t">Because if it's not working, and as per usual my first 12 attempts at this were broken,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=6543" target="_blank">01:49:03.300</a></span> | <span class="t">and they were broken in the sense that it wasn't really learning anything useful, and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=6546" target="_blank">01:49:06.940</a></span> | <span class="t">so therefore it was basically giving equal attention to everything, and therefore it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=6550" target="_blank">01:49:10.180</a></span> | <span class="t">wasn't worse.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=6551" target="_blank">01:49:11.180</a></span> | <span class="t">It just wasn't better, or it wasn't much better.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=6554" target="_blank">01:49:14.980</a></span> | <span class="t">And so until you actually find ways to visualize the thing in a way that you know what it ought</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=6562" target="_blank">01:49:22.220</a></span> | <span class="t">to look like ahead of time, you don't really know if it's working.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=6564" target="_blank">01:49:24.820</a></span> | <span class="t">So it's really important that you try to find ways to kind of check your intermediate steps</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=6569" target="_blank">01:49:29.640</a></span> | <span class="t">and your outputs.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=6570" target="_blank">01:49:30.640</a></span> | <span class="t">So people are asking what is the loss function for the attentional neural network?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=6578" target="_blank">01:49:38.260</a></span> | <span class="t">No, no, no loss function for the attentional neural network.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=6581" target="_blank">01:49:41.380</a></span> | <span class="t">It's trained end-to-end.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=6583" target="_blank">01:49:43.140</a></span> | <span class="t">So it's just sitting here inside our decoder loop.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=6588" target="_blank">01:49:48.100</a></span> | <span class="t">So the loss function for the decoder loop is that this result contains exactly the same</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=6594" target="_blank">01:49:54.580</a></span> | <span class="t">as before.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=6595" target="_blank">01:49:55.580</a></span> | <span class="t">Just the outputs, the probabilities of the words.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=6599" target="_blank">01:49:59.680</a></span> | <span class="t">So like the loss function, it's the same loss function.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=6605" target="_blank">01:50:05.440</a></span> | <span class="t">So how come the little mini neural nets learning something, well because in order to make the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=6612" target="_blank">01:50:12.960</a></span> | <span class="t">outputs better and better, it would be great if it made the weights of this weighted average</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=6619" target="_blank">01:50:19.380</a></span> | <span class="t">better and better.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=6621" target="_blank">01:50:21.300</a></span> | <span class="t">So part of creating our output is to please do a good job of finding a good set of weights.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=6626" target="_blank">01:50:26.540</a></span> | <span class="t">And if it doesn't do a good job of finding a good set of weights, then the loss function</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=6629" target="_blank">01:50:29.580</a></span> | <span class="t">would improve from that bit.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=6631" target="_blank">01:50:31.700</a></span> | <span class="t">So end-to-end learning means you throw in everything that you can into one loss function.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=6641" target="_blank">01:50:41.420</a></span> | <span class="t">And the gradients of all the different parameters point in a direction that says basically,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=6647" target="_blank">01:50:47.740</a></span> | <span class="t">hey, if you had put more weight over there, it would have been better.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=6652" target="_blank">01:50:52.540</a></span> | <span class="t">And thanks to the magic of the train rule, it then knows, oh, it would have put more</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=6655" target="_blank">01:50:55.800</a></span> | <span class="t">weight over there if you would change the parameter in this matrix, multiply a little</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=6660" target="_blank">01:51:00.220</a></span> | <span class="t">bit over there.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=6662" target="_blank">01:51:02.360</a></span> | <span class="t">And so that's the magic of end-to-end learning.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=6667" target="_blank">01:51:07.940</a></span> | <span class="t">So it's a very understandable question of how did this little mini neural net work.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=6677" target="_blank">01:51:17.060</a></span> | <span class="t">But you've got to realize there's nothing particularly about this code that says, hey,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=6682" target="_blank">01:51:22.300</a></span> | <span class="t">this particular bit's a separate little mini neural net work any more than the GRU is a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=6686" target="_blank">01:51:26.460</a></span> | <span class="t">separate little neural net work, or this linear layer is a separate little function.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=6691" target="_blank">01:51:31.900</a></span> | <span class="t">It all ends up pushed into one output, which ends up in one loss function that returns</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=6700" target="_blank">01:51:40.580</a></span> | <span class="t">a single number that says this either was or wasn't a good translation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=6706" target="_blank">01:51:46.220</a></span> | <span class="t">And so thanks to the magic of the train rule, we then back-propagate little updates to all</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=6712" target="_blank">01:51:52.380</a></span> | <span class="t">the parameters to make them a little bit better.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=6715" target="_blank">01:51:55.460</a></span> | <span class="t">So this is a big, weird counterintuitive idea, and it's totally okay if it's a bit mind bending.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=6727" target="_blank">01:52:07.700</a></span> | <span class="t">And it's the bit where, even back to lesson 1, it's like, how did we make it find dogs</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=6735" target="_blank">01:52:15.380</a></span> | <span class="t">versus cats?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=6737" target="_blank">01:52:17.540</a></span> | <span class="t">We didn't.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=6739" target="_blank">01:52:19.300</a></span> | <span class="t">All we did was we said, this is our data, this is our architecture, this is our loss</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=6745" target="_blank">01:52:25.020</a></span> | <span class="t">function, please back-propagate into the weights to make them better.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=6749" target="_blank">01:52:29.220</a></span> | <span class="t">And after you've made them better a while, it'll start finding cats from dogs.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=6754" target="_blank">01:52:34.140</a></span> | <span class="t">In this case, we haven't used somebody else's convolutional network architecture.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=6759" target="_blank">01:52:39.260</a></span> | <span class="t">We've said here's like a custom architecture which we hope is going to be particularly</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=6763" target="_blank">01:52:43.260</a></span> | <span class="t">good at this problem.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=6765" target="_blank">01:52:45.180</a></span> | <span class="t">And even without this custom architecture, it was still okay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=6769" target="_blank">01:52:49.300</a></span> | <span class="t">But then when we kind of made it in a way that made more sense to what we think it ought</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=6774" target="_blank">01:52:54.900</a></span> | <span class="t">to do, it worked even better.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=6777" target="_blank">01:52:57.100</a></span> | <span class="t">But at no point did we kind of do anything different other than say here's data, here's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=6784" target="_blank">01:53:04.020</a></span> | <span class="t">an architecture, here's a loss function, go and find the parameters please.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=6789" target="_blank">01:53:09.620</a></span> | <span class="t">And it did it because that's what neural nets do.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=6798" target="_blank">01:53:18.000</a></span> | <span class="t">So that is sequence-to-sequence learning.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=6805" target="_blank">01:53:25.140</a></span> | <span class="t">If you want to encode an image using a CNN backbone of some kind and then pass that into</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=6814" target="_blank">01:53:34.620</a></span> | <span class="t">a decoder which is like an RNN with a tension, and you make your Y values the actual correct</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=6821" target="_blank">01:53:41.860</a></span> | <span class="t">captions for each of those images, you will end up with an image caption generator.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=6826" target="_blank">01:53:46.860</a></span> | <span class="t">If you do the same thing with videos and captions, you'll end up with a video caption generator.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=6830" target="_blank">01:53:50.460</a></span> | <span class="t">If you do the same thing with 3D CT scans and radiology reports, you'll end up with</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=6835" target="_blank">01:53:55.340</a></span> | <span class="t">a radiology report generator.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=6837" target="_blank">01:53:57.140</a></span> | <span class="t">If you do the same thing with GitHub issues and people's chosen summaries of them, you'll</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=6844" target="_blank">01:54:04.300</a></span> | <span class="t">get a GitHub issue summary generator.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=6847" target="_blank">01:54:07.900</a></span> | <span class="t">Sec2Sec, I agree.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=6852" target="_blank">01:54:12.180</a></span> | <span class="t">They're magical, but they work.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=6858" target="_blank">01:54:18.540</a></span> | <span class="t">And I don't feel like people have begun to scratch the surface of how to use Sec2Sec models</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=6863" target="_blank">01:54:23.540</a></span> | <span class="t">in their own domains.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=6866" target="_blank">01:54:26.460</a></span> | <span class="t">Not being a GitHub person, it would never have occurred to me that it would be kind of cool</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=6870" target="_blank">01:54:30.900</a></span> | <span class="t">to start with some issue and automatically create a summary.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=6874" target="_blank">01:54:34.620</a></span> | <span class="t">But now I'm like, of course, next time I go to GitHub I want to see a summary written there</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=6880" target="_blank">01:54:40.660</a></span> | <span class="t">for me.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=6881" target="_blank">01:54:41.660</a></span> | <span class="t">I don't want to write my own damn commit message through that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=6884" target="_blank">01:54:44.780</a></span> | <span class="t">Why should I write my own summary of the code review when I finish adding comments to lots</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=6889" target="_blank">01:54:49.260</a></span> | <span class="t">of clients?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=6890" target="_blank">01:54:50.260</a></span> | <span class="t">It should do that for me as well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=6891" target="_blank">01:54:51.260</a></span> | <span class="t">Now I'm thinking, GitHub is so behind, it could be doing this stuff.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=6895" target="_blank">01:54:55.500</a></span> | <span class="t">So what are the things in your industry that you could start with a sequence and generate</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=6900" target="_blank">01:55:00.540</a></span> | <span class="t">something from it?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=6901" target="_blank">01:55:01.660</a></span> | <span class="t">I can't begin to imagine.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=6904" target="_blank">01:55:04.860</a></span> | <span class="t">So again, it's kind of like a fairly new area, the tools for it are not easy to use, they're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=6912" target="_blank">01:55:12.500</a></span> | <span class="t">not even built into fastai yet, as you can see, hopefully they will be soon.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=6918" target="_blank">01:55:18.740</a></span> | <span class="t">And I don't think anybody knows what the opportunities are.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=6924" target="_blank">01:55:24.420</a></span> | <span class="t">So I've got good news, bad news.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=6927" target="_blank">01:55:27.880</a></span> | <span class="t">The bad news is we have 20 minutes to cover a topic which in last year's course took a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=6934" target="_blank">01:55:34.660</a></span> | <span class="t">whole lesson.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=6937" target="_blank">01:55:37.580</a></span> | <span class="t">The good news is that when I went to rewrite this using fastai and PyTorch I ended up with</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=6942" target="_blank">01:55:42.140</a></span> | <span class="t">almost no code.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=6944" target="_blank">01:55:44.840</a></span> | <span class="t">So all of the stuff that made it hard last year is basically gone now.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=6949" target="_blank">01:55:49.360</a></span> | <span class="t">So we're going to do something bringing together for the first time our two little worlds we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=6955" target="_blank">01:55:55.500</a></span> | <span class="t">focused on, text and images, and we're going to try and bring them together.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=6961" target="_blank">01:56:01.220</a></span> | <span class="t">And so this idea came up really in a paper by this extraordinary deep learning practitioner</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=6968" target="_blank">01:56:08.300</a></span> | <span class="t">and researcher named Andrea Fromm.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=6971" target="_blank">01:56:11.140</a></span> | <span class="t">And Andrea was at Google at the time, and her basic crazy idea was to say words can</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=6982" target="_blank">01:56:22.380</a></span> | <span class="t">have a distributed representation, a space, which at that time really was just word vectors.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=6991" target="_blank">01:56:31.260</a></span> | <span class="t">And images can be represented in a space, like in the end if we have a fully connected</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=6996" target="_blank">01:56:36.340</a></span> | <span class="t">layer they kind of ended up as a vector representation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7001" target="_blank">01:56:41.180</a></span> | <span class="t">Could we merge the two?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7002" target="_blank">01:56:42.660</a></span> | <span class="t">Could we somehow encourage the vector space that the images end up with be the same vector</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7010" target="_blank">01:56:50.140</a></span> | <span class="t">space that the words are in?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7012" target="_blank">01:56:52.100</a></span> | <span class="t">And if we could do that, what would that mean?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7014" target="_blank">01:56:54.820</a></span> | <span class="t">What could we do with that?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7017" target="_blank">01:56:57.380</a></span> | <span class="t">So what could we do with that covers things like, well, what if I'm wrong?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7025" target="_blank">01:57:05.300</a></span> | <span class="t">What if I'm predicting that this image is a beagle, and I predict jumboject, and Yanet's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7036" target="_blank">01:57:16.920</a></span> | <span class="t">model predicts corgi.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7040" target="_blank">01:57:20.220</a></span> | <span class="t">The normal loss function says that Yanet and Jeremy's models are equally good, i.e. they're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7045" target="_blank">01:57:25.540</a></span> | <span class="t">both wrong.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7047" target="_blank">01:57:27.700</a></span> | <span class="t">But what if we could somehow say corgi is closer to beagle than it is to jumboject,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7054" target="_blank">01:57:34.220</a></span> | <span class="t">so Yanet's model is better than Jeremy's.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7056" target="_blank">01:57:36.860</a></span> | <span class="t">And we should be able to do that because in word vector space, beagle and corgi are pretty</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7063" target="_blank">01:57:43.340</a></span> | <span class="t">close together, but jumboject not so much.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7068" target="_blank">01:57:48.460</a></span> | <span class="t">So it would give us a nice situation where hopefully our inferences would be like wrong</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7075" target="_blank">01:57:55.060</a></span> | <span class="t">in saner ways, if they're wrong.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7077" target="_blank">01:57:57.620</a></span> | <span class="t">It would also allow us to search for things that aren't at an ImageNet, like a category</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7087" target="_blank">01:58:07.940</a></span> | <span class="t">in ImageNet, like dog and cat.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7091" target="_blank">01:58:11.700</a></span> | <span class="t">Why did I have to train a whole new model to find dogs versus cats when we already had</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7095" target="_blank">01:58:15.340</a></span> | <span class="t">something that found corgis and tabbies?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7099" target="_blank">01:58:19.980</a></span> | <span class="t">Why can't I just say find me dogs?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7101" target="_blank">01:58:21.980</a></span> | <span class="t">Well if I had trained it in word vector space, I totally could, because there's now a word</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7108" target="_blank">01:58:28.540</a></span> | <span class="t">vector, I can find things with the right image vector, and so forth.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7114" target="_blank">01:58:34.740</a></span> | <span class="t">So we'll look at some cool things we can do with it in a moment, but first of all let's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7118" target="_blank">01:58:38.140</a></span> | <span class="t">train a model where this model is not learning a category, a one-hot encoded ID where every</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7127" target="_blank">01:58:47.700</a></span> | <span class="t">category is equally far from every other category.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7131" target="_blank">01:58:51.340</a></span> | <span class="t">Let's instead train a model where we're finding the dependent variable which is a word vector.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7139" target="_blank">01:58:59.420</a></span> | <span class="t">So what word vector?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7140" target="_blank">01:59:00.660</a></span> | <span class="t">Well obviously the word vector for the word you want.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7143" target="_blank">01:59:03.700</a></span> | <span class="t">So if it's corgi, let's train it to create a word vector that's the corgi word vector.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7150" target="_blank">01:59:10.060</a></span> | <span class="t">And if it's a jumbo-jet, let's train it with a dependent variable that says this is the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7153" target="_blank">01:59:13.980</a></span> | <span class="t">word vector for a jumbo-jet.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7156" target="_blank">01:59:16.300</a></span> | <span class="t">So as I said, it's now shockingly easy.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7160" target="_blank">01:59:20.500</a></span> | <span class="t">So let's grab the fast text word vectors again, load them in, we only need English this time.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7168" target="_blank">01:59:28.780</a></span> | <span class="t">And so here's an example of the word vector for king, it's just 300 numbers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7176" target="_blank">01:59:36.220</a></span> | <span class="t">So for example, little j Jeremy and big j Jeremy have a correlation of 0.6, I don't like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7182" target="_blank">01:59:42.420</a></span> | <span class="t">bananas at all, this is good, banana and Jeremy, 0.14.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7186" target="_blank">01:59:46.580</a></span> | <span class="t">So words that you would expect to be correlated are correlated in words that should be as</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7192" target="_blank">01:59:52.080</a></span> | <span class="t">far away from each other as possible, unfortunately they're still slightly correlated but not</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7195" target="_blank">01:59:55.620</a></span> | <span class="t">so much.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7197" target="_blank">01:59:57.140</a></span> | <span class="t">So let's now grab all of the ImageNet classes because we actually want to know which one's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7208" target="_blank">02:00:08.000</a></span> | <span class="t">corgi and which one's jumbo-jet.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7210" target="_blank">02:00:10.740</a></span> | <span class="t">So we've got a list of all of those up on files.fast.ai, we can grab them.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7217" target="_blank">02:00:17.580</a></span> | <span class="t">And let's also grab a list of all of the nouns in English which I've made available here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7223" target="_blank">02:00:23.180</a></span> | <span class="t">as well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7224" target="_blank">02:00:24.620</a></span> | <span class="t">So here are the names of each of the 1000 ImageNet classes.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7229" target="_blank">02:00:29.540</a></span> | <span class="t">And here are all of the nouns in English according to WordNet, which is a popular thing for kind</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7238" target="_blank">02:00:38.620</a></span> | <span class="t">of representing what words are or not.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7241" target="_blank">02:00:41.460</a></span> | <span class="t">So we can now go ahead and load that list of nouns, load the list of ImageNet classes,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7254" target="_blank">02:00:54.300</a></span> | <span class="t">turn that into a dictionary.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7255" target="_blank">02:00:55.820</a></span> | <span class="t">So these are the class IDs for the 1000 ImageNet classes that are in the competition data set.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7261" target="_blank">02:01:01.660</a></span> | <span class="t">There are 1000.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7263" target="_blank">02:01:03.620</a></span> | <span class="t">So here's an example, n01, is a tench which apparently is a kind of fish.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7271" target="_blank">02:01:11.980</a></span> | <span class="t">Let's do the same thing for all those WordNet nouns.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7274" target="_blank">02:01:14.820</a></span> | <span class="t">And you can see actually it turns out that ImageNet is using WordNet class names, so that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7281" target="_blank">02:01:21.220</a></span> | <span class="t">makes it nice and easy to map between the two.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7285" target="_blank">02:01:25.580</a></span> | <span class="t">And WordNet, the most basic thing is an entity, and then that includes an abstraction, and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7291" target="_blank">02:01:31.580</a></span> | <span class="t">a physical entity can be an object and so forth.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7295" target="_blank">02:01:35.020</a></span> | <span class="t">So these are our two worlds.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7296" target="_blank">02:01:36.420</a></span> | <span class="t">We've got the ImageNet 1000 and we've got the 82,000 which are in WordNet.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7303" target="_blank">02:01:43.500</a></span> | <span class="t">So we want to map the two together, which is as simple as creating a couple of dictionaries</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7307" target="_blank">02:01:47.220</a></span> | <span class="t">to map them based on the Synset ID or the WordNet ID.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7312" target="_blank">02:01:52.060</a></span> | <span class="t">And it turns out that 49,469 Synset to WordVector, what I need to do now is grab the 82,000 nouns</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7338" target="_blank">02:02:18.820</a></span> | <span class="t">in WordNet and try and look them up in fast text.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7343" target="_blank">02:02:23.140</a></span> | <span class="t">And so I've managed to look up 49,000 of them in fast text.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7347" target="_blank">02:02:27.920</a></span> | <span class="t">So I've now got a dictionary that goes from Synset ID, which is what WordNet calls them,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7353" target="_blank">02:02:33.580</a></span> | <span class="t">to WordVectors.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7354" target="_blank">02:02:34.580</a></span> | <span class="t">So that's what this dictionary is, Synset to WordVector.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7361" target="_blank">02:02:41.740</a></span> | <span class="t">And I've also got the same thing specifically for the 1000 WordNet classes.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7370" target="_blank">02:02:50.920</a></span> | <span class="t">So save them away, that's fine.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7374" target="_blank">02:02:54.580</a></span> | <span class="t">Now I grab all of the ImageNet, which you can actually download from Kaggle now.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7380" target="_blank">02:03:00.980</a></span> | <span class="t">If you look up the Kaggle ImageNet localization competition, that contains the entirety of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7385" target="_blank">02:03:05.820</a></span> | <span class="t">the ImageNet classifications as well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7388" target="_blank">02:03:08.140</a></span> | <span class="t">It's got a validation set of 28,650 items in it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7395" target="_blank">02:03:15.740</a></span> | <span class="t">And so I can basically just grab for every image in ImageNet, I can grab using that Synset</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7403" target="_blank">02:03:23.420</a></span> | <span class="t">to WordVector, grab its fast text WordVector, and I can now stick that into this ImageVectors</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7415" target="_blank">02:03:35.200</a></span> | <span class="t">array.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7417" target="_blank">02:03:37.200</a></span> | <span class="t">Stack that all up into a single matrix and save that away.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7423" target="_blank">02:03:43.260</a></span> | <span class="t">And so now what I've got is something for every ImageNet image.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7429" target="_blank">02:03:49.660</a></span> | <span class="t">I've also got the fast text WordVector that it's associated with.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7435" target="_blank">02:03:55.520</a></span> | <span class="t">Just by looking up the Synset ID, going to WordNet, then going to fast text and grabbing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7444" target="_blank">02:04:04.820</a></span> | <span class="t">the WordVector.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7445" target="_blank">02:04:05.820</a></span> | <span class="t">And so here's a cool trick.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7450" target="_blank">02:04:10.340</a></span> | <span class="t">I can now create a model data object, which specifically is an image classifier data object.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7457" target="_blank">02:04:17.940</a></span> | <span class="t">And I've got this thing called from_names_an_array, I'm not sure if we've used it before.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7461" target="_blank">02:04:21.340</a></span> | <span class="t">But we can pass it a list of file names, and so these are all of the file names in ImageNet.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7469" target="_blank">02:04:29.340</a></span> | <span class="t">And we can just pass it an array of our dependent variables.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7472" target="_blank">02:04:32.900</a></span> | <span class="t">And so this is all of the fast text WordVectors.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7478" target="_blank">02:04:38.140</a></span> | <span class="t">And then I can pass in the validation indexes, which in this case is just all of the last</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7483" target="_blank">02:04:43.820</a></span> | <span class="t">IDs.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7484" target="_blank">02:04:44.820</a></span> | <span class="t">I need to make sure that they're the same as ImageNet users, otherwise I'll be cheating.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7490" target="_blank">02:04:50.100</a></span> | <span class="t">And then I pass in continuous = true, which means this puts a lie again to this image</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7495" target="_blank">02:04:55.740</a></span> | <span class="t">classifier data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7496" target="_blank">02:04:56.740</a></span> | <span class="t">It's now really an image regressor data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7499" target="_blank">02:04:59.020</a></span> | <span class="t">So continuous = true means don't want hot encode my outputs, but treat them just as continuous</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7505" target="_blank">02:05:05.380</a></span> | <span class="t">values.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7506" target="_blank">02:05:06.580</a></span> | <span class="t">So now I've got a model data object that contains all of my file names, and for every file name</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7512" target="_blank">02:05:12.900</a></span> | <span class="t">a continuous array representing the WordVector for that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7517" target="_blank">02:05:17.500</a></span> | <span class="t">So I have an x, I have a y, so I have data, now I need an architecture and a loss function.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7522" target="_blank">02:05:22.940</a></span> | <span class="t">Once I've got that, I should be done.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7526" target="_blank">02:05:26.400</a></span> | <span class="t">So let's create an architecture, and we'll revise this next week, but basically we can</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7533" target="_blank">02:05:33.620</a></span> | <span class="t">use the tricks we've learned so far, but it's actually incredibly simple.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7538" target="_blank">02:05:38.020</a></span> | <span class="t">Fast AI has a ConvNet builder, which is when you say conv_learner.pre_trained, it calls</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7547" target="_blank">02:05:47.060</a></span> | <span class="t">this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7548" target="_blank">02:05:48.300</a></span> | <span class="t">And you basically say, okay, what architecture do you want?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7551" target="_blank">02:05:51.060</a></span> | <span class="t">So we're going to use ResNet-50.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7554" target="_blank">02:05:54.480</a></span> | <span class="t">How many classes do you want?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7555" target="_blank">02:05:55.780</a></span> | <span class="t">In this case it's not really classes, it's how many outputs do you want, which is the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7560" target="_blank">02:06:00.260</a></span> | <span class="t">length of the fast text WordVector, 300.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7564" target="_blank">02:06:04.780</a></span> | <span class="t">Obviously it's not multi-class classification, it's not classification at all.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7568" target="_blank">02:06:08.260</a></span> | <span class="t">Is it regression?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7569" target="_blank">02:06:09.260</a></span> | <span class="t">Yes it is regression.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7572" target="_blank">02:06:12.480</a></span> | <span class="t">And then you can just say, alright, what fully connected layers do you want?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7576" target="_blank">02:06:16.820</a></span> | <span class="t">So I'm just going to add one fully connected layer, hidden layer of length 1024.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7581" target="_blank">02:06:21.740</a></span> | <span class="t">Why 1024?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7583" target="_blank">02:06:23.620</a></span> | <span class="t">Well I've got the last layer of ResNet-50, I think it's 1024 long.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7591" target="_blank">02:06:31.860</a></span> | <span class="t">The final output I need is 300 long.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7594" target="_blank">02:06:34.940</a></span> | <span class="t">I obviously need my penultimate layer to be longer than 300, otherwise there's not enough</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7599" target="_blank">02:06:39.180</a></span> | <span class="t">information, so I kind of just picked something a bit bigger.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7602" target="_blank">02:06:42.780</a></span> | <span class="t">Maybe different numbers would be better, but this worked for me.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7607" target="_blank">02:06:47.260</a></span> | <span class="t">How much dropout do you want?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7608" target="_blank">02:06:48.420</a></span> | <span class="t">I found that the default dropout I was consistently underfitting, so I just decreased the dropout</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7613" target="_blank">02:06:53.460</a></span> | <span class="t">from 0.5 to 0.2.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7616" target="_blank">02:06:56.500</a></span> | <span class="t">And so this is now a convolutional neural network that does not have any softmax or</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7623" target="_blank">02:07:03.020</a></span> | <span class="t">anything like that because it's regression, it's just a linear layer at the end.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7628" target="_blank">02:07:08.060</a></span> | <span class="t">And that's basically it, that's my model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7634" target="_blank">02:07:14.680</a></span> | <span class="t">So I can create a convlearner from that model, give it an optimization function.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7641" target="_blank">02:07:21.460</a></span> | <span class="t">So now all I need, I've got data, I've got an architecture, because I said I've got this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7648" target="_blank">02:07:28.060</a></span> | <span class="t">many 300 outputs, it knows there are 300 outputs because that's the size of this array.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7656" target="_blank">02:07:36.760</a></span> | <span class="t">So now all I need is a loss function.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7659" target="_blank">02:07:39.140</a></span> | <span class="t">Now the default loss function for regression is L1-loss, so the absolute differences.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7666" target="_blank">02:07:46.260</a></span> | <span class="t">That's not bad, but unfortunately in really high dimensional spaces, anybody who's studied</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7675" target="_blank">02:07:55.220</a></span> | <span class="t">a bit of machine learning probably knows this, in really high dimensional spaces, in this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7678" target="_blank">02:07:58.700</a></span> | <span class="t">case it's 300 dimensional, basically everything is on the outside.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7684" target="_blank">02:08:04.060</a></span> | <span class="t">And when everything's on the outside, distance is not meaningless, but it's a little bit</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7692" target="_blank">02:08:12.220</a></span> | <span class="t">awkward, things tend to be close together or far away, doesn't really mean much in these</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7699" target="_blank">02:08:19.780</a></span> | <span class="t">really high dimensional spaces where everything's on the edge.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7704" target="_blank">02:08:24.440</a></span> | <span class="t">What does mean something though is that if one thing's on the edge over here, and one</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7709" target="_blank">02:08:29.180</a></span> | <span class="t">thing's on the edge over here, you can form an angle between those vectors, and the angle</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7714" target="_blank">02:08:34.760</a></span> | <span class="t">is meaningful.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7716" target="_blank">02:08:36.900</a></span> | <span class="t">And so that's why we use cosine similarity when we're basically looking for how close</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7723" target="_blank">02:08:43.700</a></span> | <span class="t">or far apart are things in high dimensional spaces.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7727" target="_blank">02:08:47.500</a></span> | <span class="t">And if you haven't seen cosine similarity before, it's basically the same as Euclidean</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7731" target="_blank">02:08:51.500</a></span> | <span class="t">distance, but it's normalized to be basically a unit norm, so basically divide by the length.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7740" target="_blank">02:09:00.980</a></span> | <span class="t">So we don't care about the length of the vector, we only care about its angle.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7745" target="_blank">02:09:05.260</a></span> | <span class="t">So there's a bunch of stuff that you could easily learn in a couple of hours, but if</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7751" target="_blank">02:09:11.580</a></span> | <span class="t">you haven't seen it before, it's a bit mysterious.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7754" target="_blank">02:09:14.620</a></span> | <span class="t">For now, just know that loss functions in high dimensional spaces where you're trying</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7758" target="_blank">02:09:18.780</a></span> | <span class="t">to find similarity, you care about angle and you don't care about distance.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7766" target="_blank">02:09:26.300</a></span> | <span class="t">If you didn't use this custom loss function, it would still work, I tried it, it's just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7770" target="_blank">02:09:30.500</a></span> | <span class="t">a little bit less good.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7772" target="_blank">02:09:32.420</a></span> | <span class="t">So we've got an architecture, we've got data, we've got a loss function, therefore we're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7777" target="_blank">02:09:37.620</a></span> | <span class="t">done.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7779" target="_blank">02:09:39.340</a></span> | <span class="t">So we can go ahead and fit.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7781" target="_blank">02:09:41.540</a></span> | <span class="t">Now I'm training on all of ImageNet, that's going to take a long time, so pre-compute</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7786" target="_blank">02:09:46.860</a></span> | <span class="t">equals true is your friend.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7788" target="_blank">02:09:48.900</a></span> | <span class="t">You remember pre-compute equals true?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7790" target="_blank">02:09:50.380</a></span> | <span class="t">That's that thing we learned ages ago that caches the output of the final convolutional</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7794" target="_blank">02:09:54.500</a></span> | <span class="t">layer and just trains the fully connected bit.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7800" target="_blank">02:10:00.160</a></span> | <span class="t">And like even with pre-compute equals true, it takes like 3 minutes to train an epoch</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7806" target="_blank">02:10:06.260</a></span> | <span class="t">on all of ImageNet.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7808" target="_blank">02:10:08.580</a></span> | <span class="t">So I trained it for a while longer, so that's like an hour's worth of training.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7814" target="_blank">02:10:14.080</a></span> | <span class="t">But it's pretty cool that with fast.ai, we can train a new custom head basically on all</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7820" target="_blank">02:10:20.100</a></span> | <span class="t">of ImageNet for 40 epochs in an hour or so.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7826" target="_blank">02:10:26.260</a></span> | <span class="t">And so at the end of all that, we can now say, let's grab the 1000 ImageNet classes,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7836" target="_blank">02:10:36.300</a></span> | <span class="t">and let's predict on a whole validation set.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7840" target="_blank">02:10:40.580</a></span> | <span class="t">And let's just take a look at a few pictures.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7843" target="_blank">02:10:43.580</a></span> | <span class="t">So here's a look at a few pictures.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7846" target="_blank">02:10:46.300</a></span> | <span class="t">And because the validation set is ordered, all the stuff is the same type as in the same</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7851" target="_blank">02:10:51.260</a></span> | <span class="t">place.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7852" target="_blank">02:10:52.260</a></span> | <span class="t">I don't know what this thing is.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7855" target="_blank">02:10:55.940</a></span> | <span class="t">And what we can now do is we can now use nearest neighbors search.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7860" target="_blank">02:11:00.740</a></span> | <span class="t">So nearest neighbors search means here's one 300-dimensional vector, here's a whole lot</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7866" target="_blank">02:11:06.260</a></span> | <span class="t">of other 3-dimensional vectors, which things is it closest to.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7870" target="_blank">02:11:10.460</a></span> | <span class="t">And normally that takes a very long time because you have to look through every 300-dimensional</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7873" target="_blank">02:11:13.420</a></span> | <span class="t">vector, calculate its distance, and find out how far away it is.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7878" target="_blank">02:11:18.380</a></span> | <span class="t">But there's an amazing almost unknown library called NMSlib that does that incredibly fast.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7887" target="_blank">02:11:27.100</a></span> | <span class="t">Almost nobody's heard of it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7889" target="_blank">02:11:29.100</a></span> | <span class="t">Some of you may have tried other nearest neighbors libraries.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7891" target="_blank">02:11:31.740</a></span> | <span class="t">I guarantee this is faster than what you're using.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7894" target="_blank">02:11:34.540</a></span> | <span class="t">I can tell you that because it's been benchmarked by people who do this stuff for a living.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7900" target="_blank">02:11:40.120</a></span> | <span class="t">This is by far the fastest on every possible dimension.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7904" target="_blank">02:11:44.580</a></span> | <span class="t">So this is basically a super fast way.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7906" target="_blank">02:11:46.980</a></span> | <span class="t">We basically look here, this is angular distance.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7909" target="_blank">02:11:49.920</a></span> | <span class="t">So we want to create an index on angular distance, and we're going to do it on all of our image</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7916" target="_blank">02:11:56.220</a></span> | <span class="t">network vectors to add in a whole batch, create the index, and now I can query a bunch of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7921" target="_blank">02:12:01.780</a></span> | <span class="t">vectors all at once, get their 10 nearest neighbors, use this multi-threading.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7926" target="_blank">02:12:06.260</a></span> | <span class="t">It's absolutely fantastic, this library.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7929" target="_blank">02:12:09.280</a></span> | <span class="t">You can install it from pip, it just works, and it tells you how far away they are and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7935" target="_blank">02:12:15.660</a></span> | <span class="t">their indexes.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7937" target="_blank">02:12:17.260</a></span> | <span class="t">So we can now go through and print out the top 3.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7941" target="_blank">02:12:21.620</a></span> | <span class="t">So it turns out that bird actually is a limpkin.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7946" target="_blank">02:12:26.980</a></span> | <span class="t">This is the top 3 for each one.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7949" target="_blank">02:12:29.820</a></span> | <span class="t">Interestingly, this one doesn't say it's a limpkin, and I looked it up, it's the 4th one.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7954" target="_blank">02:12:34.780</a></span> | <span class="t">I don't know much about birds, but everything else here is brown with white spots, that's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7959" target="_blank">02:12:39.780</a></span> | <span class="t">not.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7961" target="_blank">02:12:41.460</a></span> | <span class="t">So I don't know if that's actually a limpkin or if it's a mislabeled, but it sure as hell</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7966" target="_blank">02:12:46.640</a></span> | <span class="t">doesn't look like the other birds.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7968" target="_blank">02:12:48.860</a></span> | <span class="t">So I thought that was pretty interesting.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7973" target="_blank">02:12:53.980</a></span> | <span class="t">It's kind of saying I don't think it's that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7975" target="_blank">02:12:55.780</a></span> | <span class="t">Now this is not a particularly hard thing to do because it's only 1,000 ImageNet classes,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7980" target="_blank">02:13:00.380</a></span> | <span class="t">it's not doing anything new, but what if we now bring in the entirety of WordNet, and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7986" target="_blank">02:13:06.380</a></span> | <span class="t">we now say which of those 45,000 things is it closest to, exactly the same.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7993" target="_blank">02:13:13.780</a></span> | <span class="t">So it's now searching all of WordNet.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=7996" target="_blank">02:13:16.460</a></span> | <span class="t">So now let's do something a bit different, which is take all of our predictions, so basically</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=8002" target="_blank">02:13:22.180</a></span> | <span class="t">take our whole validation set of images and create a KNN index of the image representations,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=8012" target="_blank">02:13:32.220</a></span> | <span class="t">because remember it's predicting things that are meant to be word vectors.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=8017" target="_blank">02:13:37.260</a></span> | <span class="t">And now let's grab the fast text vector for boat, and boat is not an ImageNet concept.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=8029" target="_blank">02:13:49.380</a></span> | <span class="t">And yet I can now find all of the images in my predicted word vectors in my validation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=8035" target="_blank">02:13:55.980</a></span> | <span class="t">set that are closest to the word boat.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=8039" target="_blank">02:13:59.320</a></span> | <span class="t">And it works, even though it's not something that was ever trained on.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=8044" target="_blank">02:14:04.340</a></span> | <span class="t">What if we now take engine's vector and boat's vector and take their average?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=8050" target="_blank">02:14:10.140</a></span> | <span class="t">And what if we now look in our nearest neighbors for that?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=8053" target="_blank">02:14:13.100</a></span> | <span class="t">These are boats with engines.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=8054" target="_blank">02:14:14.860</a></span> | <span class="t">I mean, yes, this is actually a boat with an engine, it just happens to have wings on</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=8059" target="_blank">02:14:19.860</a></span> | <span class="t">as well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=8060" target="_blank">02:14:20.860</a></span> | <span class="t">By the way, sail is not an ImageNet thing, boat is not an ImageNet thing, here's the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=8067" target="_blank">02:14:27.700</a></span> | <span class="t">average of two things that are not ImageNet things.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=8071" target="_blank">02:14:31.060</a></span> | <span class="t">And yet, with one exception, it's bound with two sailboats.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=8076" target="_blank">02:14:36.140</a></span> | <span class="t">Okay let's do something else crazy.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=8078" target="_blank">02:14:38.340</a></span> | <span class="t">Let's open up an image in the validation set.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=8082" target="_blank">02:14:42.420</a></span> | <span class="t">Here it is.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=8083" target="_blank">02:14:43.420</a></span> | <span class="t">I don't know what it is.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=8086" target="_blank">02:14:46.780</a></span> | <span class="t">Let's call predict_array on that image to get its kind of word-vector-like thing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=8093" target="_blank">02:14:53.380</a></span> | <span class="t">And let's do a nearest-neighbors search on all the other images.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=8097" target="_blank">02:14:57.420</a></span> | <span class="t">And here's all the other images of whatever the hell that is.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=8101" target="_blank">02:15:01.660</a></span> | <span class="t">So you can see this is crazy.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=8104" target="_blank">02:15:04.980</a></span> | <span class="t">We've trained a thing on all of ImageNet in an hour using a custom head that required</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=8109" target="_blank">02:15:09.740</a></span> | <span class="t">basically two lines of code.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=8112" target="_blank">02:15:12.340</a></span> | <span class="t">And these things run in like 300 milliseconds to do these searches.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=8116" target="_blank">02:15:16.980</a></span> | <span class="t">I actually taught this basic idea last year as well, but it was in Keras and it was just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=8122" target="_blank">02:15:22.180</a></span> | <span class="t">pages and pages and pages of code and everything took a long time and it was complicated.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=8127" target="_blank">02:15:27.060</a></span> | <span class="t">Back then I kind of said, I can't begin to think all the stuff you could do with this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=8131" target="_blank">02:15:31.420</a></span> | <span class="t">I don't think anybody has really thought deeply about this yet, but I think it's fascinating.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=8136" target="_blank">02:15:36.880</a></span> | <span class="t">And so go back and read the device paper because like Andrea had a whole bunch of other thoughts.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=8143" target="_blank">02:15:43.420</a></span> | <span class="t">And now that it's so easy to do, hopefully people will dig into this now because I think</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=8149" target="_blank">02:15:49.300</a></span> | <span class="t">it's crazy and amazing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=8151" target="_blank">02:15:51.100</a></span> | <span class="t">Alright, thanks everybody.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=8153" target="_blank">02:15:53.800</a></span> | <span class="t">See you next week.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tY0n9OT5_nA&t=8154" target="_blank">02:15:54.300</a></span> | <span class="t">[APPLAUSE]</span></div></div></body></html>