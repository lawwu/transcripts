<html><head><title>State Space Models for Realtime Multimodal Intelligence: Karan Goel</title>
<style>
    body {
        font-family: Arial, sans-serif;
        margin: 0;
        padding: 0;
        background-color: #f4f4f4;
        color: #333;
    }
    .container {
        width: 95%;  /* Increased width to use more space */
        margin: auto;
        overflow: auto;  /* Added to handle overflow by adding a scrollbar if necessary */
    }
    h2, h3 {
        color: #333;
        text-align: center;
    }
    a {
        color: #0000FF;  /* Traditional blue color for links */
        text-decoration: none;
    }
    a:hover {
        text-decoration: underline;
    }
    img {
        display: block;
        margin: auto;
        max-width: 100%;
    }
    .c {
        margin: 10px 0;
    }
    .s, .t {
        display: inline-block;
        margin-right: 5px;
    }
    .max-width {
        max-width: 800px;
        margin: auto;
        padding-left: 20px;
    }
    table {
        width: 100%;
        border-collapse: collapse;
    }
    th, td {
        border: 1px solid #ddd;
        padding: 8px;
        text-align: left;  /* Ensure text alignment is consistent */
    }
    tr:nth-child(even) {
        background-color: #f2f2f2;
    }
    tr:nth-child(odd) {
        background-color: #e6e6e6;
    }
</style>

    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-69VLBMTTP0"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-69VLBMTTP0');
    </script>
    </head><body><div class='container'><a href="index.html">back to index</a><h2>State Space Models for Realtime Multimodal Intelligence: Karan Goel</h2><a href="https://www.youtube.com/watch?v=U9DPRZ0lSIQ"><img src="https://i.ytimg.com/vi_webp/U9DPRZ0lSIQ/maxresdefault.webp" style="width:50%;"></a><div><br></div><div style="text-align: left;"><a href="./U9DPRZ0lSIQ.html">Whisper Transcript</a> | <a href="./transcript_U9DPRZ0lSIQ.html">Transcript Only Page</a></div><br><div style="max-width: 800px;"><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=U9DPRZ0lSIQ&t=0" target="_blank">00:00:00.000</a></span> | <span class="t">Maybe to set the stage a little bit, the last four or five years of AI have basically been</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=U9DPRZ0lSIQ&t=19" target="_blank">00:00:19.200</a></span> | <span class="t">really focused on this idea of batch intelligence, which is sort of pretty core to this idea of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=U9DPRZ0lSIQ&t=25" target="_blank">00:00:25.920</a></span> | <span class="t">building like an AI system that can reason for long periods of time on a problem and then solve it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=U9DPRZ0lSIQ&t=31" target="_blank">00:00:31.600</a></span> | <span class="t">So you can think about like math problems or, you know, physics problems that are hard.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=U9DPRZ0lSIQ&t=35" target="_blank">00:00:35.120</a></span> | <span class="t">There's a lot of applications where actually what you need are systems that are streaming.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=U9DPRZ0lSIQ&t=40" target="_blank">00:00:40.320</a></span> | <span class="t">So they're real time. They work instantly. So imagine generating video, audio, or doing like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=U9DPRZ0lSIQ&t=47" target="_blank">00:00:47.200</a></span> | <span class="t">understanding applications on sensor streams, et cetera. So it sort of bifurcates where there's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=U9DPRZ0lSIQ&t=53" target="_blank">00:00:53.360</a></span> | <span class="t">these two different types of applications, similar to how there's, you know, generally this idea of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=U9DPRZ0lSIQ&t=58" target="_blank">00:00:58.400</a></span> | <span class="t">having batch workloads and streaming workloads. And so a lot of what we've seen over the last few years</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=U9DPRZ0lSIQ&t=63" target="_blank">00:01:03.760</a></span> | <span class="t">has really been focused on batch APIs where you call a model in the cloud, it takes a few seconds,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=U9DPRZ0lSIQ&t=69" target="_blank">00:01:09.120</a></span> | <span class="t">and then you get a pretty good response back. And now we're seeing some shift towards more real-time</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=U9DPRZ0lSIQ&t=75" target="_blank">00:01:15.040</a></span> | <span class="t">applications where you constantly will be querying a model and asking it to return responses at low</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=U9DPRZ0lSIQ&t=81" target="_blank">00:01:21.920</a></span> | <span class="t">latency and then using that to sort of interpret or generate information.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=U9DPRZ0lSIQ&t=86" target="_blank">00:01:26.720</a></span> | <span class="t">And I think this, you know, this area is really exciting because it's going to be transformative to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=U9DPRZ0lSIQ&t=93" target="_blank">00:01:33.680</a></span> | <span class="t">a lot of interesting applications that have so far actually not necessarily been the main focus for a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=U9DPRZ0lSIQ&t=101" target="_blank">00:01:41.280</a></span> | <span class="t">lot of what we've seen over the last few years. So conversational voice is an example of this where you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=U9DPRZ0lSIQ&t=106" target="_blank">00:01:46.240</a></span> | <span class="t">should be able to interact with the system and then talk to it, and it should be able to understand you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=U9DPRZ0lSIQ&t=111" target="_blank">00:01:51.280</a></span> | <span class="t">and do all kinds of tasks on your behalf. This is similar to having assistants that are on device and run</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=U9DPRZ0lSIQ&t=118" target="_blank">00:01:58.000</a></span> | <span class="t">kind of really efficiently at low power at, you know, all times, regardless of whether you're on a phone or a laptop.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=U9DPRZ0lSIQ&t=125" target="_blank">00:02:05.360</a></span> | <span class="t">And then things like world generation where, like, you can imagine actually playing a game that is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=U9DPRZ0lSIQ&t=130" target="_blank">00:02:10.320</a></span> | <span class="t">generated in real time, similar to how the graphics are rendered on GPUs. And all of this, you know,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=U9DPRZ0lSIQ&t=138" target="_blank">00:02:18.000</a></span> | <span class="t">should be able to happen in real time, on low power, on your phone, on your MacBook, et cetera. Robotics is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=U9DPRZ0lSIQ&t=146" target="_blank">00:02:26.640</a></span> | <span class="t">another great example where it sort of culminates with all of these coming together on a single</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=U9DPRZ0lSIQ&t=151" target="_blank">00:02:31.760</a></span> | <span class="t">device that is trying to kind of interpret everything in the world. And so I think this is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=U9DPRZ0lSIQ&t=158" target="_blank">00:02:38.400</a></span> | <span class="t">sort of the exciting intersection, which is, like, how do we make intelligence faster and cheaper so that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=U9DPRZ0lSIQ&t=163" target="_blank">00:02:43.520</a></span> | <span class="t">we can put it everywhere, basically. And a couple of examples that are really powerful, real-time</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=U9DPRZ0lSIQ&t=169" target="_blank">00:02:49.840</a></span> | <span class="t">intelligence for conversational interfaces is going to be really interesting because you would be able to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=U9DPRZ0lSIQ&t=175" target="_blank">00:02:55.040</a></span> | <span class="t">have an agent that can provide customer support for a problem, answer questions about health insurance,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=U9DPRZ0lSIQ&t=180" target="_blank">00:03:00.320</a></span> | <span class="t">you know, call your vendor to pick up a shipment. All these coordination tasks that generally are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=U9DPRZ0lSIQ&t=187" target="_blank">00:03:07.040</a></span> | <span class="t">annoying to do should be really automated and real-time intelligent agents should be doing them.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=U9DPRZ0lSIQ&t=193" target="_blank">00:03:13.600</a></span> | <span class="t">And then humans can spend their time solving sort of harder problems that are more interesting. And</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=U9DPRZ0lSIQ&t=198" target="_blank">00:03:18.320</a></span> | <span class="t">in customer support, that could be dealing with, you know, the tail customers that are much more important</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=U9DPRZ0lSIQ&t=203" target="_blank">00:03:23.360</a></span> | <span class="t">because they're pissed off or they're more important because they have, you know, more customer value,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=U9DPRZ0lSIQ&t=209" target="_blank">00:03:29.280</a></span> | <span class="t">et cetera. And similarly in robotics, there's this idea of, like, ingesting similar to humans, like audio,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=U9DPRZ0lSIQ&t=215" target="_blank">00:03:35.360</a></span> | <span class="t">video, sensor data, and then responding instantly to a lot of these pieces of information. So I think</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=U9DPRZ0lSIQ&t=220" target="_blank">00:03:40.960</a></span> | <span class="t">this is sort of the world we should be living in where all of these intelligent models run super fast.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=U9DPRZ0lSIQ&t=225" target="_blank">00:03:45.520</a></span> | <span class="t">they saw all these different problems and they're able to really kind of power these new experiences that are interactive at their core.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=U9DPRZ0lSIQ&t=234" target="_blank">00:03:54.480</a></span> | <span class="t">So this is where we come in. We're building these real-time foundation models. So some of what I'll talk about is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=U9DPRZ0lSIQ&t=242" target="_blank">00:04:02.800</a></span> | <span class="t">the work we've done in really building kind of new ideas for how you can create deep learning models. So</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=U9DPRZ0lSIQ&t=251" target="_blank">00:04:11.920</a></span> | <span class="t">I did my PhD before this. I was working with a lot of these folks for my PhD. Chris was our PhD advisor.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=U9DPRZ0lSIQ&t=256" target="_blank">00:04:16.800</a></span> | <span class="t">And we were really focused on this idea that you should be able to have a model that can compress</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=U9DPRZ0lSIQ&t=262" target="_blank">00:04:22.400</a></span> | <span class="t">information as it comes into the model and use that to really kind of build powerful systems that are streaming at their core.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=U9DPRZ0lSIQ&t=270" target="_blank">00:04:30.240</a></span> | <span class="t">And I'll talk a little bit about this, but that's really the technology that we've been working with for the last four or five years.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=U9DPRZ0lSIQ&t=276" target="_blank">00:04:36.000</a></span> | <span class="t">We've been developing academia and some of you might have heard of things like Mamba, which is sort of a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=U9DPRZ0lSIQ&t=280" target="_blank">00:04:40.960</a></span> | <span class="t">more recent iteration of this technology. You know, I did my PhD working on some of the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=U9DPRZ0lSIQ&t=286" target="_blank">00:04:46.000</a></span> | <span class="t">early iterations that nobody uses anymore, but are sort of the precursors to a lot of the modern stuff that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=U9DPRZ0lSIQ&t=291" target="_blank">00:04:51.920</a></span> | <span class="t">is now more widely used. And now what we're doing at Cartesia is basically taking this and trying to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=U9DPRZ0lSIQ&t=297" target="_blank">00:04:57.360</a></span> | <span class="t">understand how we can improve it, how we push the boundaries on what architectures can do.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=U9DPRZ0lSIQ&t=302" target="_blank">00:05:02.400</a></span> | <span class="t">And I think it's an interesting question because, you know, we should not settle for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=U9DPRZ0lSIQ&t=306" target="_blank">00:05:06.800</a></span> | <span class="t">having one way of doing things. I think that's sort of a poor way to kind of think about the future.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=U9DPRZ0lSIQ&t=313" target="_blank">00:05:13.200</a></span> | <span class="t">So our approach is sort of like let's think about new ways of actually designing models that aren't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=U9DPRZ0lSIQ&t=318" target="_blank">00:05:18.240</a></span> | <span class="t">necessarily built on, let's say, the transformer architecture and the standard recipe for deep learning</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=U9DPRZ0lSIQ&t=323" target="_blank">00:05:23.120</a></span> | <span class="t">that's, you know, prevalent today. And I think it boils down to this question of like efficiently</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=U9DPRZ0lSIQ&t=329" target="_blank">00:05:29.520</a></span> | <span class="t">modeling long context is a huge problem because, you know, a lot of practical data is really long</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=U9DPRZ0lSIQ&t=334" target="_blank">00:05:34.800</a></span> | <span class="t">sequence data. I think text is maybe the least interesting long sequence data because text is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=U9DPRZ0lSIQ&t=339" target="_blank">00:05:39.840</a></span> | <span class="t">actually fairly compressed already, right? Like you have a lot of information that is embedded in two</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=U9DPRZ0lSIQ&t=346" target="_blank">00:05:46.400</a></span> | <span class="t">minutes of -- or two sentences of text. But there's all these other domains where, you know, audio, video,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=U9DPRZ0lSIQ&t=352" target="_blank">00:05:52.240</a></span> | <span class="t">et cetera, where there's so much information. You know, imagine looking at a security camera for a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=U9DPRZ0lSIQ&t=356" target="_blank">00:05:56.880</a></span> | <span class="t">day. Like you would probably have just so much information coming into the system and just very</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=U9DPRZ0lSIQ&t=362" target="_blank">00:06:02.320</a></span> | <span class="t">little of that would be useful. So compression is kind of really fundamental to intelligence because</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=U9DPRZ0lSIQ&t=366" target="_blank">00:06:06.640</a></span> | <span class="t">we're able to do this where we can look at all this information and then sort of compress it down to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=U9DPRZ0lSIQ&t=371" target="_blank">00:06:11.360</a></span> | <span class="t">whatever's necessary to remember or understand. And I think so far what we've seen is that the AI</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=U9DPRZ0lSIQ&t=377" target="_blank">00:06:17.360</a></span> | <span class="t">systems that we built have not necessarily exhibited that same behavior. So they're really kind of built</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=U9DPRZ0lSIQ&t=382" target="_blank">00:06:22.400</a></span> | <span class="t">not on the principles of compression, but more on this idea of retrieval, like keeping all the context</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=U9DPRZ0lSIQ&t=387" target="_blank">00:06:27.040</a></span> | <span class="t">around and then using it to reason over all the information that you've seen. So I think our kind of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=U9DPRZ0lSIQ&t=392" target="_blank">00:06:32.640</a></span> | <span class="t">point of view is that multimodal AI will remain challenging as long as you're sort of working in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=U9DPRZ0lSIQ&t=397" target="_blank">00:06:37.680</a></span> | <span class="t">this paradigm. Because if you try to think about what humans do in a year, you're basically processing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=U9DPRZ0lSIQ&t=404" target="_blank">00:06:44.080</a></span> | <span class="t">understanding about a billion text tokens, 10 billion audio tokens. These are, you know,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=U9DPRZ0lSIQ&t=408" target="_blank">00:06:48.960</a></span> | <span class="t">back of the envelope calculations that I did. And about a trillion video tokens probably underestimates</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=U9DPRZ0lSIQ&t=413" target="_blank">00:06:53.840</a></span> | <span class="t">how much video we process and not including all the other sensory information that you're processing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=U9DPRZ0lSIQ&t=418" target="_blank">00:06:58.720</a></span> | <span class="t">And you're doing it simultaneously. And you're doing it on a computer that fits in your brain.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=U9DPRZ0lSIQ&t=422" target="_blank">00:07:02.880</a></span> | <span class="t">And you, you know, sometimes don't eat and drink and, you know, you're still functioning fine. So,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=U9DPRZ0lSIQ&t=428" target="_blank">00:07:08.320</a></span> | <span class="t">you know, you can have variable amounts of power in the system. So I think the idea that, like,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=U9DPRZ0lSIQ&t=434" target="_blank">00:07:14.320</a></span> | <span class="t">intelligence is solved is sort of very far from the truth because humans just are an extremely amazing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=U9DPRZ0lSIQ&t=440" target="_blank">00:07:20.320</a></span> | <span class="t">machine that does something very extraordinary in a very compressed way that our AI models can't do.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=U9DPRZ0lSIQ&t=447" target="_blank">00:07:27.200</a></span> | <span class="t">So I think that's sort of our, you know, sort of the reason we get up in the morning is we think</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=U9DPRZ0lSIQ&t=452" target="_blank">00:07:32.400</a></span> | <span class="t">about this and we're like, yeah, we're very far away from where we should be. And the best models</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=U9DPRZ0lSIQ&t=457" target="_blank">00:07:37.840</a></span> | <span class="t">today are in the, you know, 10 million, 100 million sort of token range. So that's really good. A lot of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=U9DPRZ0lSIQ&t=463" target="_blank">00:07:43.280</a></span> | <span class="t">progress has been made. But really, this is sort of what we aspire to is how do you kind of build these</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=U9DPRZ0lSIQ&t=467" target="_blank">00:07:47.200</a></span> | <span class="t">machines that are long lived that can actually understand information over very long periods of time.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=U9DPRZ0lSIQ&t=472" target="_blank">00:07:52.480</a></span> | <span class="t">And I think the cool thing is, like, as a human, you can remember things that happened 30 years ago with very</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=U9DPRZ0lSIQ&t=477" target="_blank">00:07:57.200</a></span> | <span class="t">little effort. You don't need to do rag or retrieval or anything. You just, you know, you remember it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=U9DPRZ0lSIQ&t=481" target="_blank">00:08:01.840</a></span> | <span class="t">It's gisted in your brain and then you figure it out, basically. So I think that's kind of an extraordinary</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=U9DPRZ0lSIQ&t=486" target="_blank">00:08:06.720</a></span> | <span class="t">capability that we should be able to put into our AI models as well. And so some of the big problems with</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=U9DPRZ0lSIQ&t=494" target="_blank">00:08:14.720</a></span> | <span class="t">models today are, you know, they're built on transformers, really optimized for data center. I think we see this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=U9DPRZ0lSIQ&t=500" target="_blank">00:08:20.880</a></span> | <span class="t">with, like, a lot of the work we did, which was on sub-quadratic models. So quadratic scaling and context</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=U9DPRZ0lSIQ&t=505" target="_blank">00:08:25.600</a></span> | <span class="t">length really just means that, you know, the amount of computation you have to do to process long</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=U9DPRZ0lSIQ&t=511" target="_blank">00:08:31.120</a></span> | <span class="t">amounts of context is very large. And so right now the sort of predominant approach is to throw compute</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=U9DPRZ0lSIQ&t=516" target="_blank">00:08:36.400</a></span> | <span class="t">at that problem and then hope that that would scale. Obviously, compute is a very important piece of the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=U9DPRZ0lSIQ&t=521" target="_blank">00:08:41.440</a></span> | <span class="t">puzzle because you do need more computation to be able to do more difficult things. But this type of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=U9DPRZ0lSIQ&t=526" target="_blank">00:08:46.880</a></span> | <span class="t">approach, because of the quadratic scaling, actually has poor scaling with, you know, very large multimodal</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=U9DPRZ0lSIQ&t=531" target="_blank">00:08:51.280</a></span> | <span class="t">context. And text contexts tend to be shorter. Multimodal contexts will get larger because you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=U9DPRZ0lSIQ&t=536" target="_blank">00:08:56.400</a></span> | <span class="t">have just way more tokens and information that's going into the system. So that's going to be a big</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=U9DPRZ0lSIQ&t=540" target="_blank">00:09:00.320</a></span> | <span class="t">challenge for these models, especially how do you do this inference efficiently so you're not, you know,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=U9DPRZ0lSIQ&t=544" target="_blank">00:09:04.880</a></span> | <span class="t">burning down the data centers to, you know, do a fairly limited amount of inference. Like, you have to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=U9DPRZ0lSIQ&t=550" target="_blank">00:09:10.160</a></span> | <span class="t">imagine that we're doing a thousand times or, you know, a hundred thousand times more inference. And then</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=U9DPRZ0lSIQ&t=555" target="_blank">00:09:15.040</a></span> | <span class="t">if the models are scaling the same way, it's going to be really, really, really expensive. So you're not going to be able to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=U9DPRZ0lSIQ&t=559" target="_blank">00:09:19.840</a></span> | <span class="t">permeate all these applications that I talked about very easily. And so, you know, that's sort of a big</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=U9DPRZ0lSIQ&t=564" target="_blank">00:09:24.960</a></span> | <span class="t">challenge, I would say. And so, you know, again, our hypothesis is you need new architectures and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=U9DPRZ0lSIQ&t=570" target="_blank">00:09:30.400</a></span> | <span class="t">that's kind of where we spend our time and we want to make these models more efficient, faster, more capable</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=U9DPRZ0lSIQ&t=574" target="_blank">00:09:34.640</a></span> | <span class="t">while being able to handle all these long context problems. This is a slide about, you know, transformers</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=U9DPRZ0lSIQ&t=580" target="_blank">00:09:40.160</a></span> | <span class="t">being somewhat inefficient at handling this, but obviously a very good recipe for scaling these models out.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=U9DPRZ0lSIQ&t=588" target="_blank">00:09:48.640</a></span> | <span class="t">And so, you know, some of the work that we've been doing is new fundamentally efficient architectures.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=U9DPRZ0lSIQ&t=592" target="_blank">00:09:52.880</a></span> | <span class="t">So they have compression at their core. So they sort of -- the way they operate -- I'll have a slide</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=U9DPRZ0lSIQ&t=598" target="_blank">00:09:58.000</a></span> | <span class="t">on this just to give you kind of a quick illustration. But they really scale more linearly in context lens.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=U9DPRZ0lSIQ&t=604" target="_blank">00:10:04.880</a></span> | <span class="t">So you should be able to have -- because of this, like, more low power implementations of these models,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=U9DPRZ0lSIQ&t=610" target="_blank">00:10:10.320</a></span> | <span class="t">you can compress information as it comes into the system. You have low memory usage.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=U9DPRZ0lSIQ&t=615" target="_blank">00:10:15.600</a></span> | <span class="t">And you can actually scale to much more massive context because of that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=U9DPRZ0lSIQ&t=618" target="_blank">00:10:18.480</a></span> | <span class="t">And this is all the work around SSMs. I just threw this nice slide, which I thought was cool.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=U9DPRZ0lSIQ&t=626" target="_blank">00:10:26.080</a></span> | <span class="t">Jensen had an interesting quote about SSMs in one of his Wired articles that I like to keep talking</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=U9DPRZ0lSIQ&t=631" target="_blank">00:10:31.440</a></span> | <span class="t">about. But I think it's a cool technology that has a lot of potential and sort of that's where we're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=U9DPRZ0lSIQ&t=636" target="_blank">00:10:36.880</a></span> | <span class="t">spending a lot of our time. And if you folks are interested in reading more, there's lots of videos on</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=U9DPRZ0lSIQ&t=641" target="_blank">00:10:41.120</a></span> | <span class="t">YouTube and lots of sort of resources that try to make this more accessible to understand and kind</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=U9DPRZ0lSIQ&t=645" target="_blank">00:10:45.760</a></span> | <span class="t">of get into some of the details. But, you know, the working intuition is basically --</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=U9DPRZ0lSIQ&t=650" target="_blank">00:10:50.560</a></span> | <span class="t">transformers are generating quadratically by attending to every past token of information.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=U9DPRZ0lSIQ&t=654" target="_blank">00:10:54.720</a></span> | <span class="t">So as tokens come into the system, you're sort of keeping them around</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=U9DPRZ0lSIQ&t=658" target="_blank">00:10:58.160</a></span> | <span class="t">and then looking at all the past tokens. So if you want to generate the word "jumped"</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=U9DPRZ0lSIQ&t=661" target="_blank">00:11:01.840</a></span> | <span class="t">from the quick brown fox, you would actually look at the entire context,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=U9DPRZ0lSIQ&t=664" target="_blank">00:11:04.960</a></span> | <span class="t">try to understand what the next word should be,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=U9DPRZ0lSIQ&t=666" target="_blank">00:11:06.960</a></span> | <span class="t">and then generate it, push it into the context, do it again.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=U9DPRZ0lSIQ&t=670" target="_blank">00:11:10.480</a></span> | <span class="t">With SSMs, you just have a streaming system. So you have a token stream in,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=U9DPRZ0lSIQ&t=675" target="_blank">00:11:15.040</a></span> | <span class="t">they update an internal memory for the model, and then the token gets thrown away.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=U9DPRZ0lSIQ&t=679" target="_blank">00:11:19.520</a></span> | <span class="t">So that actually really simplifies the system. And that's why it's such a core</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=U9DPRZ0lSIQ&t=682" target="_blank">00:11:22.880</a></span> | <span class="t">sort of streaming interface, because you're just not keeping all this memory around about</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=U9DPRZ0lSIQ&t=686" target="_blank">00:11:26.800</a></span> | <span class="t">what happened in the past. You're compressing it into some sort of zipped file state inside the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=U9DPRZ0lSIQ&t=691" target="_blank">00:11:31.840</a></span> | <span class="t">model that's going to be used to do a future generation. And so this is sort of taking this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=U9DPRZ0lSIQ&t=697" target="_blank">00:11:37.600</a></span> | <span class="t">idea of -- taking advantage of this idea of recurrence, which is sort of core to how even humans</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=U9DPRZ0lSIQ&t=702" target="_blank">00:11:42.960</a></span> | <span class="t">do a lot of their raising. And, you know, last few months, a lot of these models have been getting</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=U9DPRZ0lSIQ&t=708" target="_blank">00:11:48.240</a></span> | <span class="t">adopted. So it's great that, you know, a lot of folks are now excited about the -- this, you know,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=U9DPRZ0lSIQ&t=713" target="_blank">00:11:53.360</a></span> | <span class="t">alternate way of doing things that is much more sort of oriented around this idea of recurrence,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=U9DPRZ0lSIQ&t=719" target="_blank">00:11:59.440</a></span> | <span class="t">rather than retrieval. And so I think, like, we'll see a lot more activity in this,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=U9DPRZ0lSIQ&t=723" target="_blank">00:12:03.920</a></span> | <span class="t">especially with multimodal data becoming more important. And, you know, a lot of the challenges</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=U9DPRZ0lSIQ&t=728" target="_blank">00:12:08.480</a></span> | <span class="t">of multimodal data around efficiency will mean that I think that these models will have more of a role</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=U9DPRZ0lSIQ&t=733" target="_blank">00:12:13.120</a></span> | <span class="t">to play in the next three to five years, as we also do our work in scaling them up and making them</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=U9DPRZ0lSIQ&t=738" target="_blank">00:12:18.320</a></span> | <span class="t">more interesting. A lot of people ask me about quality. I only have a few minutes, so I'll go through</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=U9DPRZ0lSIQ&t=743" target="_blank">00:12:23.120</a></span> | <span class="t">the rest of the slide super fast. But, you know, SSMs generally have the right quality. Obviously,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=U9DPRZ0lSIQ&t=749" target="_blank">00:12:29.680</a></span> | <span class="t">there's a tradeoff between compression and keeping all of the information around. But actually, like,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=U9DPRZ0lSIQ&t=754" target="_blank">00:12:34.480</a></span> | <span class="t">compression can be helpful. So if you imagine the security camera example, if you're watching 24</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=U9DPRZ0lSIQ&t=759" target="_blank">00:12:39.280</a></span> | <span class="t">hours of footage, actually compressing all of that information on the fly would help you solve tasks</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=U9DPRZ0lSIQ&t=763" target="_blank">00:12:43.600</a></span> | <span class="t">and answer questions better rather than looking at all 24 hours every time. So I think that's sort</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=U9DPRZ0lSIQ&t=768" target="_blank">00:12:48.720</a></span> | <span class="t">of the rule of thumb to think about, which is compression super helpful for a large context,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=U9DPRZ0lSIQ&t=772" target="_blank">00:12:52.400</a></span> | <span class="t">not as helpful for short context. And so we see that quality actually is very good for long context</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=U9DPRZ0lSIQ&t=778" target="_blank">00:12:58.560</a></span> | <span class="t">problems and multimodal problems. Let me talk quickly about some of the work we've been doing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=U9DPRZ0lSIQ&t=783" target="_blank">00:13:03.120</a></span> | <span class="t">So we've been starting to work on sort of multimodal data. And we did a release a few weeks ago</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=U9DPRZ0lSIQ&t=787" target="_blank">00:13:07.600</a></span> | <span class="t">for a voice generation model. So this is sort of text-to-speech and sort of in line with some of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=U9DPRZ0lSIQ&t=792" target="_blank">00:13:12.320</a></span> | <span class="t">the work we're doing to bring more multimodal data into a single model and use SSMs to power the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=U9DPRZ0lSIQ&t=799" target="_blank">00:13:19.280</a></span> | <span class="t">inference and the training and so on. So this is a model you can actually play with. I'll try to show</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=U9DPRZ0lSIQ&t=803" target="_blank">00:13:23.600</a></span> | <span class="t">you a demo. But one of the things we're proudest off with this model is that we really shrunk the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=U9DPRZ0lSIQ&t=808" target="_blank">00:13:28.320</a></span> | <span class="t">latency down. So when you play with it on the playground, you get instant voice back generated from</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=U9DPRZ0lSIQ&t=812" target="_blank">00:13:32.720</a></span> | <span class="t">the data center. And there's some cool work we're doing to actually run these models on Mac.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=U9DPRZ0lSIQ&t=817" target="_blank">00:13:37.680</a></span> | <span class="t">And other devices so that you can basically have the same experience as you have in the data center,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=U9DPRZ0lSIQ&t=821" target="_blank">00:13:41.680</a></span> | <span class="t">but on any device. And do that efficiently and at low power. How much time do I have?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=U9DPRZ0lSIQ&t=826" target="_blank">00:13:46.000</a></span> | <span class="t">Okay. We're out of time, but I was also almost done. So go to the website, play.cartesia.ai. I</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=U9DPRZ0lSIQ&t=834" target="_blank">00:13:54.000</a></span> | <span class="t">unfortunately couldn't walk through the demo, but play with it and send us feedback. This is my email,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=U9DPRZ0lSIQ&t=839" target="_blank">00:13:59.120</a></span> | <span class="t">in case you want to send me a note. I would love to hear feedback and anything that you folks find</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=U9DPRZ0lSIQ&t=844" target="_blank">00:14:04.080</a></span> | <span class="t">interesting. Thank you.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=U9DPRZ0lSIQ&t=856" target="_blank">00:14:16.800</a></span> | <span class="t">Thank you.</span></div></div></body></html>