<html><head><title>Shane Legg (DeepMind Founder) - 2028 AGI, Superhuman Alignment, New Architectures</title>
<style>
    body {
        font-family: Arial, sans-serif;
        margin: 0;
        padding: 0;
        background-color: #f4f4f4;
        color: #333;
    }
    .container {
        width: 95%;  /* Increased width to use more space */
        margin: auto;
        overflow: auto;  /* Added to handle overflow by adding a scrollbar if necessary */
    }
    h2, h3 {
        color: #333;
        text-align: center;
    }
    a {
        color: #0000FF;  /* Traditional blue color for links */
        text-decoration: none;
    }
    a:hover {
        text-decoration: underline;
    }
    img {
        display: block;
        margin: auto;
        max-width: 100%;
    }
    .c {
        margin: 10px 0;
    }
    .s, .t {
        display: inline-block;
        margin-right: 5px;
    }
    .max-width {
        max-width: 800px;
        margin: auto;
        padding-left: 20px;
    }
    table {
        width: 100%;
        border-collapse: collapse;
    }
    th, td {
        border: 1px solid #ddd;
        padding: 8px;
        text-align: left;  /* Ensure text alignment is consistent */
    }
    tr:nth-child(even) {
        background-color: #f2f2f2;
    }
    tr:nth-child(odd) {
        background-color: #e6e6e6;
    }
</style>

    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-69VLBMTTP0"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-69VLBMTTP0');
    </script>
    </head><body><div class='container'><a href="index.html">back to index</a><h2>Shane Legg (DeepMind Founder) - 2028 AGI, Superhuman Alignment, New Architectures</h2><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU"><img src="https://i.ytimg.com/vi/Kc1atfJkiJU/maxresdefault.jpg" style="width:50%;"></a><div><br></div><h3>Chapters</h3><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=0">0:0</a> Measuring AGI<br><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=701">11:41</a> Do we need new architectures?<br><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=986">16:26</a> Is search needed for creativity?<br><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=1159">19:19</a> Superhuman alignment<br><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=1798">29:58</a> Impact of Deepmind on safety vs capabilities<br><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=2043">34:3</a> Timelines<br><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=2484">41:24</a> Multimodality<br><br><div style="text-align: left;"><a href="./Kc1atfJkiJU.html">Whisper Transcript</a> | <a href="./transcript_Kc1atfJkiJU.html">Transcript Only Page</a></div><br><div style="max-width: 800px;"><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=0" target="_blank">00:00:00.720</a></span> | <span class="t">Okay, today I have the pleasure of interviewing Shane Legge, who is a founder and the chief</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=8" target="_blank">00:00:08.480</a></span> | <span class="t">AGI scientist of Google DeepMind. Shane, welcome to the podcast.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=12" target="_blank">00:00:12.320</a></span> | <span class="t">Thank you. It's a pleasure to be here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=13" target="_blank">00:00:13.920</a></span> | <span class="t">So first question, how do we measure progress towards AGI concretely?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=18" target="_blank">00:00:18.880</a></span> | <span class="t">So we have these loss numbers and we can see how the loss improves from one model to another,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=23" target="_blank">00:00:23.760</a></span> | <span class="t">but it's just a number. How do we interpret this?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=25" target="_blank">00:00:25.360</a></span> | <span class="t">How do we see how much progress we're actually making?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=28" target="_blank">00:00:28.800</a></span> | <span class="t">That's a hard question, actually.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=30" target="_blank">00:00:30.240</a></span> | <span class="t">AGI, by its definition, is about generality. So it's not about doing a specific thing. It's much</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=38" target="_blank">00:00:38.080</a></span> | <span class="t">easier to measure performance when you have a very specific thing in mind, because you can</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=42" target="_blank">00:00:42.320</a></span> | <span class="t">construct a test around that. Well, maybe I should first explain what do I mean by AGI,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=47" target="_blank">00:00:47.280</a></span> | <span class="t">because there are a few different notions around. When I say AGI, I mean a machine that can do</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=53" target="_blank">00:00:53.280</a></span> | <span class="t">the sorts of cognitive things that people can typically do, possibly more.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=58" target="_blank">00:00:58.160</a></span> | <span class="t">But to be an AGI, that's kind of the bar you need to meet.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=61" target="_blank">00:01:01.360</a></span> | <span class="t">So if we want to test whether we're meeting this threshold or we're getting close to the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=66" target="_blank">00:01:06.720</a></span> | <span class="t">threshold, what we actually need then is a lot of different kinds of measurements and tests</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=73" target="_blank">00:01:13.600</a></span> | <span class="t">spans the breadth of all the sorts of cognitive tasks that people can do,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=79" target="_blank">00:01:19.040</a></span> | <span class="t">and then to have a sense of what is human performance on these sorts of tasks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=84" target="_blank">00:01:24.960</a></span> | <span class="t">And that then allows us to sort of judge whether or not we're there.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=88" target="_blank">00:01:28.720</a></span> | <span class="t">It's difficult because you'll never have a complete set of everything that people can do,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=93" target="_blank">00:01:33.600</a></span> | <span class="t">because it's such a large set. But I think that if you ever get to the point where</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=97" target="_blank">00:01:37.600</a></span> | <span class="t">you have a pretty good range of tests of all sorts of different things that people do,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=103" target="_blank">00:01:43.920</a></span> | <span class="t">cognitive things people do, and you have an AI system which can</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=107" target="_blank">00:01:47.520</a></span> | <span class="t">meet human performance and all those things, and with some effort, you can't actually come up with</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=114" target="_blank">00:01:54.160</a></span> | <span class="t">new examples of cognitive tasks where the machine is below human performance, then at that point,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=120" target="_blank">00:02:00.880</a></span> | <span class="t">it's conceptually possible that there is something that the machine can't do that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=126" target="_blank">00:02:06.160</a></span> | <span class="t">people can do. But if you can't find it with some effort, I think for practical purposes,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=130" target="_blank">00:02:10.400</a></span> | <span class="t">you now have an AGI. So let's get more concrete.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=133" target="_blank">00:02:13.920</a></span> | <span class="t">We measure the performance of these large language models on MMLU or something, and maybe you can</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=139" target="_blank">00:02:19.760</a></span> | <span class="t">explain what all these different benchmarks are. But the ones we use right now that you might see</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=144" target="_blank">00:02:24.880</a></span> | <span class="t">in a paper, what are they missing? What aspect of human cognition do they not measure adequately?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=150" target="_blank">00:02:30.560</a></span> | <span class="t">Yeah, I never had hard green. These are quite big areas. So they don't measure things like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=158" target="_blank">00:02:38.400</a></span> | <span class="t">understanding streaming video, for example, because these are language models and people</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=162" target="_blank">00:02:42.880</a></span> | <span class="t">can do things like understand streaming video. They don't do things, like humans have what we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=170" target="_blank">00:02:50.480</a></span> | <span class="t">call episodic memory. So we have a working memory, which are things that have happened</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=174" target="_blank">00:02:54.720</a></span> | <span class="t">quite recently, and then we have the sort of cortical memory. So these are things that have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=179" target="_blank">00:02:59.040</a></span> | <span class="t">sort of been in our cortex, but there's also a system in between, which is episodic memory,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=184" target="_blank">00:03:04.080</a></span> | <span class="t">which is the hippocampus. And so this is about learning specific things very, very rapidly.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=189" target="_blank">00:03:09.680</a></span> | <span class="t">So some of the things I say to you today, if you remember them tomorrow, that'll be your</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=193" target="_blank">00:03:13.680</a></span> | <span class="t">episodic memory, your hippocampus. Our models don't really have that kind of thing, and we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=198" target="_blank">00:03:18.560</a></span> | <span class="t">don't really test for that kind of thing. We just sort of try to make the context windows, which is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=202" target="_blank">00:03:22.800</a></span> | <span class="t">I think more like a working memory, longer and longer to sort of compensate for this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=207" target="_blank">00:03:27.040</a></span> | <span class="t">But yeah, we don't really test for that kind of a thing. So there is all sorts of bits and pieces,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=213" target="_blank">00:03:33.200</a></span> | <span class="t">but it is a difficult question because you really need to, as I said, intelligence,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=217" target="_blank">00:03:37.920</a></span> | <span class="t">the generality of human intelligence is very, very broad. So you really have to start going</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=222" target="_blank">00:03:42.160</a></span> | <span class="t">into the weeds of trying to find if there's specific types of things that are missing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=227" target="_blank">00:03:47.280</a></span> | <span class="t">from existing benchmarks or different categories of benchmarks that don't currently exist or</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=232" target="_blank">00:03:52.800</a></span> | <span class="t">something. Yeah. The thing you're referring to with episodic memory, would it be fair to call</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=238" target="_blank">00:03:58.160</a></span> | <span class="t">that sample efficiency or is that a different? It's very much related to sample efficiency. It's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=243" target="_blank">00:04:03.680</a></span> | <span class="t">one of the things that enables humans to be very sample efficient. Right. Large language models</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=249" target="_blank">00:04:09.520</a></span> | <span class="t">have a certain kind of sample efficiency because when something's in their context window,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=254" target="_blank">00:04:14.080</a></span> | <span class="t">they can then, that sort of biases the distribution to behave in a different way.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=259" target="_blank">00:04:19.840</a></span> | <span class="t">And so that's a very rapid kind of learning. So there are multiple kinds of learning and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=264" target="_blank">00:04:24.400</a></span> | <span class="t">the existing systems have some of them, but not others. So it's a little bit complicated.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=269" target="_blank">00:04:29.840</a></span> | <span class="t">So this kind of memory or we call it sample efficiency, whatever, is it a fatal flaw of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=276" target="_blank">00:04:36.960</a></span> | <span class="t">these deep learning models that it just takes trillions of tokens, far more, many orders of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=281" target="_blank">00:04:41.520</a></span> | <span class="t">magnitude more than a human will see throughout their lifetime? Or is this something that just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=285" target="_blank">00:04:45.200</a></span> | <span class="t">solved over time? So the models can learn things immediately when it's in a context window.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=291" target="_blank">00:04:51.680</a></span> | <span class="t">And then they have this sort of this longer process of when you actually train the base</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=295" target="_blank">00:04:55.040</a></span> | <span class="t">model and so on. And that's, they're learning over trillions of tokens, but they sort of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=299" target="_blank">00:04:59.120</a></span> | <span class="t">miss something in the middle. Right. Right. That's sort of what I'm getting at here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=302" target="_blank">00:05:02.160</a></span> | <span class="t">I don't think it's a fundamental limitation. I think what's happened with large language models</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=309" target="_blank">00:05:09.040</a></span> | <span class="t">is something fundamental has changed. We know how to build models now that have some degree of,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=315" target="_blank">00:05:15.760</a></span> | <span class="t">I would say, understanding of what's going on. And that did not exist in the past. And because</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=322" target="_blank">00:05:22.080</a></span> | <span class="t">we've got a scalable way to do this now, that unlocks lots and lots of new things.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=328" target="_blank">00:05:28.240</a></span> | <span class="t">Now we can then look at things which are missing, such as the sort of episodic memory type thing,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=334" target="_blank">00:05:34.000</a></span> | <span class="t">and we can then start to imagine ways to address that. So my feeling is that there are kind of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=342" target="_blank">00:05:42.160</a></span> | <span class="t">relatively clear paths forwards now to address most of the shortcomings we see in existing models,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=348" target="_blank">00:05:48.400</a></span> | <span class="t">whether it's about delusions, factuality, the type of memory and learning that they have,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=354" target="_blank">00:05:54.320</a></span> | <span class="t">or understanding video or all sorts of things like that. So I don't see there are big blockers here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=360" target="_blank">00:06:00.400</a></span> | <span class="t">I don't see big walls in front of us. I just see there's more research and work and these things</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=365" target="_blank">00:06:05.920</a></span> | <span class="t">will improve and probably be adequately solved. But going back to the original question of how</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=371" target="_blank">00:06:11.360</a></span> | <span class="t">do you measure when human level AI has arrived or beyond it, as you mentioned, there's these other</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=378" target="_blank">00:06:18.640</a></span> | <span class="t">sorts of benchmarks you can use and other sorts of traits. But concretely, what would it have to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=383" target="_blank">00:06:23.680</a></span> | <span class="t">do for you to be like, okay, we've reached human level? Would it have to beat Minecraft from start</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=386" target="_blank">00:06:26.960</a></span> | <span class="t">to finish? Would it have to get 100% on MMLU? What would it have to do? There is no one thing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=392" target="_blank">00:06:32.800</a></span> | <span class="t">that would do it, because I think that's the nature of it. It's about general intelligence,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=396" target="_blank">00:06:36.640</a></span> | <span class="t">so I'd have to make sure it could do lots and lots of different things and it didn't have a gap.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=401" target="_blank">00:06:41.200</a></span> | <span class="t">We already have systems that can do very impressive categories of things to human</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=406" target="_blank">00:06:46.560</a></span> | <span class="t">level or even beyond. So I would want a whole suite of tests that I felt was very comprehensive.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=414" target="_blank">00:06:54.560</a></span> | <span class="t">And then furthermore, when people come in and say, okay, so it's passing a big suite of tests,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=419" target="_blank">00:06:59.600</a></span> | <span class="t">let's try to find examples. Let's take an adversarial approach to this. Let's deliberately</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=427" target="_blank">00:07:07.280</a></span> | <span class="t">try to find examples where people can clearly typically do this, but the machine fails.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=432" target="_blank">00:07:12.720</a></span> | <span class="t">And when those people cannot succeed, I'll go, okay, we're probably there.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=436" target="_blank">00:07:16.480</a></span> | <span class="t">A lot of your earlier research, at least on that Zack I find,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=440" target="_blank">00:07:20.880</a></span> | <span class="t">emphasized that AI should be able to manipulate and succeed in a variety of open-ended environments.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=448" target="_blank">00:07:28.080</a></span> | <span class="t">It kind of sounds like a video game almost. Is that where your head is still at now,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=450" target="_blank">00:07:30.960</a></span> | <span class="t">or do you think about it differently?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=452" target="_blank">00:07:32.080</a></span> | <span class="t">Yeah, it's evolved a bit. When I did my thesis work around universal intelligence and so on,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=459" target="_blank">00:07:39.840</a></span> | <span class="t">I was trying to come up with a sort of extremely universal, general, mathematically clean</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=467" target="_blank">00:07:47.520</a></span> | <span class="t">framework for defining and measuring intelligence. And I think there were aspects of that that were</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=477" target="_blank">00:07:57.280</a></span> | <span class="t">successful. I think in my own mind, it clarified the nature of intelligence as being able to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=484" target="_blank">00:08:04.560</a></span> | <span class="t">perform well in lots of different domains and different tasks and so on. It's about that sort</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=489" target="_blank">00:08:09.040</a></span> | <span class="t">of capability of performance and the breadth of performance. So I found that was quite helpful</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=496" target="_blank">00:08:16.960</a></span> | <span class="t">and enlightening. There was always the issue of the reference machine, because in the framework,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=504" target="_blank">00:08:24.000</a></span> | <span class="t">you have a weighting of things according to their complexity. It's like an Occam's razor type of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=509" target="_blank">00:08:29.920</a></span> | <span class="t">thing, where you weight tasks, environments, which is simpler, more highly in this sort of...</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=517" target="_blank">00:08:37.600</a></span> | <span class="t">Because you've got an infinite, it's a countable space of different computable environments,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=524" target="_blank">00:08:44.480</a></span> | <span class="t">or semi-computable environments. And that combined complexity measure has something</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=531" target="_blank">00:08:51.040</a></span> | <span class="t">built into it, which is called a reference machine. And that's a free parameter.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=535" target="_blank">00:08:55.600</a></span> | <span class="t">So that means that the intelligence measure has a free parameter in it. And as you change that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=542" target="_blank">00:09:02.160</a></span> | <span class="t">free parameter, it changes the weighting and the distribution over the space of all the different</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=547" target="_blank">00:09:07.040</a></span> | <span class="t">tasks and environments. So this is sort of an unresolved part of the whole problem.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=552" target="_blank">00:09:12.240</a></span> | <span class="t">So what reference machine should we ideally use? There isn't really a... There's no universal,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=561" target="_blank">00:09:21.120</a></span> | <span class="t">like one specific reference machine. People will usually put a universal Turing machine in there,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=566" target="_blank">00:09:26.480</a></span> | <span class="t">but there are many kinds of universal Turing machines. You have to put a universal Turing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=570" target="_blank">00:09:30.240</a></span> | <span class="t">machine in there, but there are many different ones. So I think, given that it's a free parameter,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=575" target="_blank">00:09:35.600</a></span> | <span class="t">I think the most natural thing to do is say, okay, let's think about what's meaningful to us</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=582" target="_blank">00:09:42.800</a></span> | <span class="t">in terms of intelligence. I think human intelligence is meaningful to us and the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=587" target="_blank">00:09:47.520</a></span> | <span class="t">environment that we live in. We know what human intelligence is. We are human too. We interact</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=592" target="_blank">00:09:52.720</a></span> | <span class="t">with other people who have human intelligence. We know that human intelligence is possible,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=597" target="_blank">00:09:57.040</a></span> | <span class="t">obviously, because it exists in the world. We know that human intelligence is very,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=602" target="_blank">00:10:02.000</a></span> | <span class="t">very powerful because it's affected the world profoundly in countless ways.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=606" target="_blank">00:10:06.080</a></span> | <span class="t">And we know if human-level intelligence was achieved, that would be economically transformative</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=613" target="_blank">00:10:13.120</a></span> | <span class="t">because the types of cognitive tasks people do in the economy could be done by machines then.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=617" target="_blank">00:10:17.600</a></span> | <span class="t">And it would be philosophically important because this is sort of how we often think</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=623" target="_blank">00:10:23.520</a></span> | <span class="t">about intelligence. And I think historically it would be a key point. So I think that human</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=628" target="_blank">00:10:28.480</a></span> | <span class="t">intelligence is actually quite, in a human-like environment, is quite a natural sort of reference</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=632" target="_blank">00:10:32.720</a></span> | <span class="t">point. So you could imagine setting your reference machine to be such that it emphasizes the kinds</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=642" target="_blank">00:10:42.960</a></span> | <span class="t">of environments that we live in, as opposed to some abstract mathematical environment or something</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=647" target="_blank">00:10:47.840</a></span> | <span class="t">like that. And so that's how I've kind of gone on this journey of, let's try to define a completely</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=653" target="_blank">00:10:53.440</a></span> | <span class="t">universal, clean, mathematical notion of intelligence to, well, it's got a free parameter.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=660" target="_blank">00:11:00.080</a></span> | <span class="t">One way of thinking about it is say, okay, let's think more concretely now about human intelligence.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=665" target="_blank">00:11:05.600</a></span> | <span class="t">And can we build machines that can match human intelligence? Because we understand what that is,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=670" target="_blank">00:11:10.640</a></span> | <span class="t">and we know that that is a very powerful thing. It has economic, philosophical, historical kind</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=676" target="_blank">00:11:16.400</a></span> | <span class="t">of importance. So that's kind of the... And the other aspect, of course, is that in this pure</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=682" target="_blank">00:11:22.160</a></span> | <span class="t">formulation of combographic complexity, it's actually not computable. And I obviously knew</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=686" target="_blank">00:11:26.880</a></span> | <span class="t">that there was a limitation at the time, but it was an effort to say, okay, can we just even very</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=693" target="_blank">00:11:33.120</a></span> | <span class="t">theoretically come up with a clean definition? I think we can sort of get there, but we have this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=697" target="_blank">00:11:37.600</a></span> | <span class="t">issue of a reference machine, which is unspecified. - So before we move on, I do want to ask,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=703" target="_blank">00:11:43.840</a></span> | <span class="t">on the original point you made about these machines, or these LLMs need episodic memory,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=711" target="_blank">00:11:51.680</a></span> | <span class="t">you said that these are problems that we can solve. These are not fundamental impediments.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=717" target="_blank">00:11:57.600</a></span> | <span class="t">But when you say that, do you think they'll just be solved by scale? Or do each of these need a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=722" target="_blank">00:12:02.000</a></span> | <span class="t">fine-grained specific solution that is architectural in nature? - I think it'll be architectural in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=727" target="_blank">00:12:07.440</a></span> | <span class="t">nature, because the... Well, the current architectures, they don't really have what</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=734" target="_blank">00:12:14.240</a></span> | <span class="t">you need to do this. They basically have a context window, which is very, very fluid,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=738" target="_blank">00:12:18.880</a></span> | <span class="t">of course, and they have the weights, which things get baked into very slowly. So to my mind,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=743" target="_blank">00:12:23.360</a></span> | <span class="t">it feels like working memory, which is like the activations in your brain, and then the weights,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=748" target="_blank">00:12:28.880</a></span> | <span class="t">the synapses and so on in your cortex. Now, the brain separates these things out. It has a separate</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=754" target="_blank">00:12:34.480</a></span> | <span class="t">mechanism for rapidly learning specific information, because that's a different type of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=760" target="_blank">00:12:40.320</a></span> | <span class="t">optimization problem compared to slowly learning deep generalities, right? There's a tension</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=768" target="_blank">00:12:48.560</a></span> | <span class="t">between the two, but you want to be able to do both. You want to be able to, I don't know,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=773" target="_blank">00:12:53.520</a></span> | <span class="t">hear someone's name and remember it the next day. And you also want to be able to integrate</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=777" target="_blank">00:12:57.680</a></span> | <span class="t">information over a lifetime, so you start to see deeper patterns in the world. These are quite</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=783" target="_blank">00:13:03.120</a></span> | <span class="t">different optimization targets, different processes, but a comprehensive system should</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=791" target="_blank">00:13:11.520</a></span> | <span class="t">be able to do both. And so I think it's conceivable you could build one system that does both,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=796" target="_blank">00:13:16.080</a></span> | <span class="t">but you can see because they're quite different things that it makes sense for them to be</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=799" target="_blank">00:13:19.120</a></span> | <span class="t">different. I think that's why the brain does it separately. I'm curious about how concretely you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=804" target="_blank">00:13:24.080</a></span> | <span class="t">think that would be achieved. And I'm specifically curious, I guess you can answer this as part of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=809" target="_blank">00:13:29.040</a></span> | <span class="t">the answer. You know, DeepMind has been working on these domain-specific reinforcement learning</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=815" target="_blank">00:13:35.680</a></span> | <span class="t">type setups, AlphaFold, AlphaCode, and so on. How does that fit into what you see as a path to AGI?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=822" target="_blank">00:13:42.720</a></span> | <span class="t">Have these just been orthogonal domain-specific models, or do they feed into the eventual AGI?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=828" target="_blank">00:13:48.160</a></span> | <span class="t">Things like AlphaFold are not really feeding into AGI. We may learn things in the process</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=836" target="_blank">00:13:56.800</a></span> | <span class="t">that may end up being relevant, but I don't see them as likely being on the path to AGI.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=844" target="_blank">00:14:04.400</a></span> | <span class="t">But yeah, we're a big group. We've got hundreds and hundreds and hundreds of PhDs working on lots</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=850" target="_blank">00:14:10.400</a></span> | <span class="t">of different projects. So when we find what we see like opportunities to do something significant</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=857" target="_blank">00:14:17.280</a></span> | <span class="t">like AlphaFold, we'll go and do it. It's not like we only do AGI type work. We work on fusion</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=864" target="_blank">00:14:24.400</a></span> | <span class="t">reactors and various things in sustainability, energy. We've got people looking at satellite</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=874" target="_blank">00:14:34.400</a></span> | <span class="t">images of deforestation. We have people looking at weather forecasting. We've got tons of people.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=881" target="_blank">00:14:41.840</a></span> | <span class="t">We've got lots of things. On the point you made earlier about the reference class or the reference</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=887" target="_blank">00:14:47.040</a></span> | <span class="t">machine as human intelligence, it's interesting because in your 2008 thesis, one of the things</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=891" target="_blank">00:14:51.600</a></span> | <span class="t">you mentioned almost as a side note is, well, how would you measure intelligence? And you said,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=895" target="_blank">00:14:55.680</a></span> | <span class="t">well, you could do a compression test and you could see if it fills in words and a sample of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=900" target="_blank">00:15:00.640</a></span> | <span class="t">text, and that could measure intelligence. And funnily enough, that's basically how LLMs are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=905" target="_blank">00:15:05.760</a></span> | <span class="t">trained. At the time, did it stick out to you as an especially fruitful thing to train for?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=911" target="_blank">00:15:11.120</a></span> | <span class="t">Well, yeah. I mean, in a sense, what's happened is actually very aligned with</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=916" target="_blank">00:15:16.720</a></span> | <span class="t">what I write about my thesis, which are the ideas from Markus Hatta with AIX, where</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=923" target="_blank">00:15:23.200</a></span> | <span class="t">you take Solomonov induction, which is this incomputable, but sort of theoretically very</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=929" target="_blank">00:15:29.440</a></span> | <span class="t">elegant and extremely sample efficient prediction system. And then once you have that, you can build</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=938" target="_blank">00:15:38.800</a></span> | <span class="t">a general agent on top of it by basically adding search and reinforcement signal. That's what you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=945" target="_blank">00:15:45.840</a></span> | <span class="t">do with AIX. But what that sort of tells you is that if you have a fantastically good sequence</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=952" target="_blank">00:15:52.960</a></span> | <span class="t">predictor, some approximation of Solomonov induction, then going from that to a very powerful,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=960" target="_blank">00:16:00.080</a></span> | <span class="t">very general AGI system is just sort of another step. You've actually solved a lot of the problem</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=968" target="_blank">00:16:08.480</a></span> | <span class="t">already. And I think that's what we're seeing today, actually, that these incredibly powerful</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=973" target="_blank">00:16:13.520</a></span> | <span class="t">foundation models are incredibly good sequence predictors. They're compressing the world based</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=978" target="_blank">00:16:18.480</a></span> | <span class="t">on all this data, and then you will be able to extend these in different ways and build very,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=983" target="_blank">00:16:23.680</a></span> | <span class="t">very powerful agents out of them. Okay. Let me ask you more about that. So</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=987" target="_blank">00:16:27.040</a></span> | <span class="t">Richard Sutton's bitter lesson essay says that there's two things you can scale,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=991" target="_blank">00:16:31.920</a></span> | <span class="t">search and learning. And I guess you could say that LLMs are about the learning aspect.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=996" target="_blank">00:16:36.880</a></span> | <span class="t">The search stuff, which you've worked on throughout your career, where you have an</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=1001" target="_blank">00:16:41.440</a></span> | <span class="t">agent that is interacting with this environment. Is that the direction that needs to be explored</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=1008" target="_blank">00:16:48.560</a></span> | <span class="t">again? Or is that something that needs to be added to LLMs where they can actually interact</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=1011" target="_blank">00:16:51.840</a></span> | <span class="t">with their data or the world or in some way? Yeah. I think that's on the right track. I think</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=1018" target="_blank">00:16:58.000</a></span> | <span class="t">these foundation models are world models of a kind. And to do really creative problem solving,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=1027" target="_blank">00:17:07.920</a></span> | <span class="t">you need to start searching. So if I think about something like AlphaGo and the move 37,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=1033" target="_blank">00:17:13.920</a></span> | <span class="t">the famous move 37, where did that come from? Did that come from all this data that it's seen of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=1040" target="_blank">00:17:20.400</a></span> | <span class="t">human games or something like that? No, it didn't. It came from it identifying a move as being</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=1046" target="_blank">00:17:26.880</a></span> | <span class="t">quite unlikely, but possible. And then via a process of search, coming to understand that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=1055" target="_blank">00:17:35.440</a></span> | <span class="t">was actually a very, very good move. So to get real creativity, you need to search through spaces</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=1061" target="_blank">00:17:41.840</a></span> | <span class="t">of possibilities and find these sort of hidden gems. That's what creativity is.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=1065" target="_blank">00:17:45.360</a></span> | <span class="t">I think current language models, they don't really do that kind of a thing. They really are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=1072" target="_blank">00:17:52.000</a></span> | <span class="t">mimicking the data. They are mimicking all the human ingenuity and everything, which they have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=1077" target="_blank">00:17:57.600</a></span> | <span class="t">seen from all this data that's coming from the internet that's originally derived from humans.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=1082" target="_blank">00:18:02.400</a></span> | <span class="t">If you want a system that can go truly beyond that and not just generalize in novel ways,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=1088" target="_blank">00:18:08.560</a></span> | <span class="t">these models can blend things. They can do Harry Potter in the style of a Kanye West rap or</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=1095" target="_blank">00:18:15.280</a></span> | <span class="t">something, even though it's never happened. They can blend things together. But to do something</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=1099" target="_blank">00:18:19.440</a></span> | <span class="t">that's truly creative, that is not just a blending of existing things, that requires searching</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=1105" target="_blank">00:18:25.120</a></span> | <span class="t">through a space of possibilities and finding these hidden gems that are sort of hidden away in there</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=1111" target="_blank">00:18:31.360</a></span> | <span class="t">somewhere. And that requires search. So I don't think we'll see systems that truly step beyond</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=1118" target="_blank">00:18:38.720</a></span> | <span class="t">their training data until we have powerful search in the process.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=1122" target="_blank">00:18:42.160</a></span> | <span class="t">So there are rumors that Google DeepMind is training newer models, and you don't have to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=1127" target="_blank">00:18:47.520</a></span> | <span class="t">comment on those specifically. But when you do that, if it's the case that search or something</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=1133" target="_blank">00:18:53.520</a></span> | <span class="t">like that is required to go to the next level, are you training in a completely different way</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=1138" target="_blank">00:18:58.160</a></span> | <span class="t">than, say, GPT-4 or other transformers are trained? I can't say much about how we're training. I think</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=1144" target="_blank">00:19:04.880</a></span> | <span class="t">it's fair to say we're doing the sorts of scaling and training, roughly, that you see many people in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=1152" target="_blank">00:19:12.080</a></span> | <span class="t">the field doing. But we have our own take on it and our own different tricks and techniques.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=1159" target="_blank">00:19:19.040</a></span> | <span class="t">Okay, maybe we'll come back to it and get another answer on that. But let's talk about alignment</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=1163" target="_blank">00:19:23.200</a></span> | <span class="t">briefly. So what will it take to align human-level and superhuman AIs? And it's interesting because</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=1172" target="_blank">00:19:32.320</a></span> | <span class="t">the sorts of reinforcement learning and self-play kinds of setups that are popular now, like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=1176" target="_blank">00:19:36.640</a></span> | <span class="t">Constitution AI or RLHF, DeepMind obviously has expertise in it for decades longer. So I'm curious</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=1183" target="_blank">00:19:43.760</a></span> | <span class="t">what you think of the current landscape and how DeepMind pursues that problem of safety towards</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=1189" target="_blank">00:19:49.120</a></span> | <span class="t">human-level models. So do you want to know about what we're currently doing, or do you want me to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=1192" target="_blank">00:19:52.800</a></span> | <span class="t">have a stab at what I think needs to be done? Needs to be done.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=1195" target="_blank">00:19:55.840</a></span> | <span class="t">Needs to be done. So in terms of what we're currently doing, we're doing lots of things.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=1200" target="_blank">00:20:00.400</a></span> | <span class="t">We're doing interpretability, we're doing process supervision, we're doing red teaming,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=1204" target="_blank">00:20:04.880</a></span> | <span class="t">we're doing evaluation for dangerous capabilities, we're doing work on institutions and governance</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=1211" target="_blank">00:20:11.120</a></span> | <span class="t">and tons of stuff. There's lots of different things. Anyway, what do I think needs to be done?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=1217" target="_blank">00:20:17.120</a></span> | <span class="t">So I think that powerful machine learning, powerful AGI is coming in some time.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=1224" target="_blank">00:20:24.880</a></span> | <span class="t">And if the system is really capable, really intelligent, really powerful,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=1232" target="_blank">00:20:32.000</a></span> | <span class="t">trying to somehow contain it or limit it is probably not a winning strategy because these</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=1236" target="_blank">00:20:36.960</a></span> | <span class="t">systems ultimately will be very, very capable. So what you have to do is you have to align it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=1242" target="_blank">00:20:42.400</a></span> | <span class="t">You have to get it so it's fundamentally a highly ethical value-aligned system from the get-go.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=1250" target="_blank">00:20:50.880</a></span> | <span class="t">How do you do that? Well, maybe this is slightly naive, but this is my take on it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=1260" target="_blank">00:21:00.640</a></span> | <span class="t">How do people do it? If you have a really difficult ethical decision in front of you,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=1266" target="_blank">00:21:06.720</a></span> | <span class="t">what do you do? Well, you don't just do the first thing that comes to mind because there could be a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=1274" target="_blank">00:21:14.560</a></span> | <span class="t">lot of emotions involved in other things. It's a difficult problem. So what you have to do is you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=1279" target="_blank">00:21:19.040</a></span> | <span class="t">have to calm yourself down, you've got to sit down, and you've got to think about it. You've</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=1283" target="_blank">00:21:23.040</a></span> | <span class="t">got to think, well, okay, what could I do? I could do this, I could do this, I could do this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=1287" target="_blank">00:21:27.760</a></span> | <span class="t">If I do each of these things, what will happen? And then you have to think about,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=1294" target="_blank">00:21:34.640</a></span> | <span class="t">so that requires a model of the world, and then you have to think about ethically,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=1299" target="_blank">00:21:39.760</a></span> | <span class="t">how do I view each of these different actions and the possibilities of what may happen from it?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=1306" target="_blank">00:21:46.000</a></span> | <span class="t">What is the right thing to do? And as you think about all the different possibilities and your</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=1313" target="_blank">00:21:53.440</a></span> | <span class="t">actions and what can follow from them and how it aligns with your values and your ethics,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=1317" target="_blank">00:21:57.920</a></span> | <span class="t">you can then come to some conclusion of what is really the best choice that you should be making</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=1323" target="_blank">00:22:03.360</a></span> | <span class="t">if you want to be really ethical about this. I think AI systems need to essentially do the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=1329" target="_blank">00:22:09.840</a></span> | <span class="t">same thing. So when you sample from a foundational model at the moment,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=1334" target="_blank">00:22:14.000</a></span> | <span class="t">it's like it's blurting out the first thing. It's like system one, if you like, from psychology,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=1340" target="_blank">00:22:20.320</a></span> | <span class="t">from Kahneman, right? That's not good enough. And if we do RLHF, or what's it called? I can't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=1348" target="_blank">00:22:28.800</a></span> | <span class="t">remember. Anyway, it's the AI version without the human feedback. RAIF, is that what it is?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=1354" target="_blank">00:22:34.320</a></span> | <span class="t">Oh, gosh, I'm confusing myself. Anyway, constitutional AI tries to do that sort of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=1357" target="_blank">00:22:37.920</a></span> | <span class="t">thing. You're trying to fix the underlying system one in a sense, right? And that can shift the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=1364" target="_blank">00:22:44.160</a></span> | <span class="t">distribution and that can be very helpful, but it's a very high dimensional distribution and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=1368" target="_blank">00:22:48.800</a></span> | <span class="t">you're sort of poking it in a whole lot of points. And so it's not likely to be a very robust</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=1374" target="_blank">00:22:54.080</a></span> | <span class="t">solution, right? It's like trying to train yourself out of a bad habit. You can sort of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=1379" target="_blank">00:22:59.520</a></span> | <span class="t">do it eventually. But what you need to do is you need to have a system two. You need the system</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=1385" target="_blank">00:23:05.760</a></span> | <span class="t">to not just sample from the model, you need the system to go, "Okay, I'm going to reason this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=1391" target="_blank">00:23:11.680</a></span> | <span class="t">through. I'm going to do like step-by-step reasoning. What are the options in front of me?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=1395" target="_blank">00:23:15.600</a></span> | <span class="t">I'm going to use my world model now and I'm going to use a good world model to understand</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=1400" target="_blank">00:23:20.400</a></span> | <span class="t">what's likely to happen from each of these options and then reason about each of these</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=1405" target="_blank">00:23:25.680</a></span> | <span class="t">from an ethical perspective." So you need a system which has a deep understanding of the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=1410" target="_blank">00:23:30.800</a></span> | <span class="t">world, has a good world model, it has a good understanding of people, it has a good understanding</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=1414" target="_blank">00:23:34.960</a></span> | <span class="t">of ethics, and it has robust and very reliable reasoning. And then you set it up in such a way</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=1420" target="_blank">00:23:40.880</a></span> | <span class="t">that it applies this reasoning and this understanding of ethics to analyze the different</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=1426" target="_blank">00:23:46.240</a></span> | <span class="t">options which are in front of it and then execute on which is the most ethical way forwards.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=1432" target="_blank">00:23:52.160</a></span> | <span class="t">But I think when a lot of people think about the fundamental alignment problem,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=1436" target="_blank">00:23:56.000</a></span> | <span class="t">the worry is not that it's not going to have a world model necessary to understand</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=1440" target="_blank">00:24:00.800</a></span> | <span class="t">its actions, or sorry, to understand the effects of its actions. I guess it's one</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=1445" target="_blank">00:24:05.760</a></span> | <span class="t">worry but not the main worry. The main worry is that the effects it cares about are not the ones</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=1452" target="_blank">00:24:12.480</a></span> | <span class="t">we will care about. And so even if you improve its systems you're thinking and do better planning,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=1456" target="_blank">00:24:16.880</a></span> | <span class="t">the fundamental problem of we have this really nuanced values about what we want,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=1460" target="_blank">00:24:20.560</a></span> | <span class="t">how do we communicate those values and make sure they're reinforced in the AI?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=1465" target="_blank">00:24:25.920</a></span> | <span class="t">It needs not just a good model of the world, but it needs a really good understanding of ethics.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=1470" target="_blank">00:24:30.960</a></span> | <span class="t">And we need to communicate to the system what ethics and values it should be following.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=1475" target="_blank">00:24:35.840</a></span> | <span class="t">And how do we do that in a way that we can be confident that a human level,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=1480" target="_blank">00:24:40.240</a></span> | <span class="t">or eventually a superhuman level model will preserve those values or learn them in the first</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=1484" target="_blank">00:24:44.880</a></span> | <span class="t">place? Well, it should preserve them because if it's making all its decisions based on a good</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=1490" target="_blank">00:24:50.720</a></span> | <span class="t">understanding of ethics and values, and it's consistent in doing this, it shouldn't take</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=1495" target="_blank">00:24:55.920</a></span> | <span class="t">actions which undermine that. That would be inconsistent. Right. So then how do we get to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=1499" target="_blank">00:24:59.600</a></span> | <span class="t">the point where it's learned them in the first place? Yeah, that's the challenge. We need to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=1504" target="_blank">00:25:04.400</a></span> | <span class="t">have systems. The way I think about it is this, to have a profoundly ethical AI system, it also</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=1511" target="_blank">00:25:11.360</a></span> | <span class="t">has to be very, very capable. It needs a really good world model, a really good understanding</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=1516" target="_blank">00:25:16.080</a></span> | <span class="t">of ethics, and it needs really good reasoning. Because if you don't have any of those things,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=1520" target="_blank">00:25:20.560</a></span> | <span class="t">how can you possibly be consistently profoundly ethical? You can't. So we actually need better</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=1528" target="_blank">00:25:28.000</a></span> | <span class="t">reasoning, better understanding of the world and better understanding of ethics in our systems.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=1533" target="_blank">00:25:33.040</a></span> | <span class="t">Right. So it seems to me the former two would just come along for the ride as these models</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=1536" target="_blank">00:25:36.880</a></span> | <span class="t">get more powerful. Yeah. So that's a nice property because it's actually a capabilities thing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=1541" target="_blank">00:25:41.680</a></span> | <span class="t">Right. But then if the third one is a bottleneck, or if the third one is a thing that doesn't come</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=1546" target="_blank">00:25:46.080</a></span> | <span class="t">along with the AI itself, what is the actual technique to make sure that that happens?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=1550" target="_blank">00:25:50.800</a></span> | <span class="t">The third one, sorry. The ethical model. What do humans value?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=1554" target="_blank">00:25:54.480</a></span> | <span class="t">Well, we've got a couple of problems. First of all, we need to decide, we should train the system</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=1560" target="_blank">00:26:00.800</a></span> | <span class="t">on ethics generally. I mean, there's a lot of lectures and papers and books and all sorts of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=1566" target="_blank">00:26:06.160</a></span> | <span class="t">things. So it understands human ethics well. And we need to make sure it understands humans ethics</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=1571" target="_blank">00:26:11.920</a></span> | <span class="t">well, because that's important, at least as well as a very good ethicist. And we then need to decide,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=1580" target="_blank">00:26:20.480</a></span> | <span class="t">okay, of this sort of general understanding of ethics, what do we want the system to actually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=1587" target="_blank">00:26:27.280</a></span> | <span class="t">value? And what sort of ethics do we want it to apply? Now, that's not a technical problem.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=1593" target="_blank">00:26:33.600</a></span> | <span class="t">That's a problem for society and ethicists and so on to come up with. Now, I'm not sure there's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=1602" target="_blank">00:26:42.240</a></span> | <span class="t">such a thing as true or correct optimal ethics or something like that. But I'm pretty sure</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=1607" target="_blank">00:26:47.280</a></span> | <span class="t">that it's possible to come up with a set of ethics, which is much better than the so-called</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=1616" target="_blank">00:26:56.640</a></span> | <span class="t">doomers worry about in terms of the behavior of these AGI systems. And then what you do is you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=1622" target="_blank">00:27:02.000</a></span> | <span class="t">engineer the system to actually follow these things. So every time it makes a decision,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=1629" target="_blank">00:27:09.360</a></span> | <span class="t">it does an analysis using a deep understanding of the world and of ethics and very robust and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=1636" target="_blank">00:27:16.480</a></span> | <span class="t">precise reasoning to do an ethical analysis of what it's doing. And of course, we'd want lots</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=1641" target="_blank">00:27:21.920</a></span> | <span class="t">of other things. We want people checking these processes of reasoning. We'd want people verifying</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=1647" target="_blank">00:27:27.600</a></span> | <span class="t">that it's behaving itself in terms of how it reaches these conclusions. But I still feel</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=1653" target="_blank">00:27:33.120</a></span> | <span class="t">like I don't understand how that fundamental problem of making sure it follows that ethic,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=1657" target="_blank">00:27:37.600</a></span> | <span class="t">because presumably, it has Mao's little red book, so it understands Maoist ethics and understands</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=1662" target="_blank">00:27:42.160</a></span> | <span class="t">all these other ethics. How do we make sure the ethic that we say, this is the one we've decided</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=1668" target="_blank">00:27:48.000</a></span> | <span class="t">at this society and so on today, that is the one it ends up following and not the other ones it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=1672" target="_blank">00:27:52.560</a></span> | <span class="t">understands. Right. So you have to specify to the system, these are the ethical principles that you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=1677" target="_blank">00:27:57.200</a></span> | <span class="t">should follow. And how do we make sure it does that? We have to check it as it's doing it. We</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=1681" target="_blank">00:28:01.120</a></span> | <span class="t">have to assure ourselves that it is consistently following these ethical principles, at least,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=1688" target="_blank">00:28:08.000</a></span> | <span class="t">I mean, I'm not sure there's such a thing as optimally, but at least as well as a group of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=1693" target="_blank">00:28:13.360</a></span> | <span class="t">human experts. Are you worried that if you do it the default way, which is just reinforcing it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=1698" target="_blank">00:28:18.000</a></span> | <span class="t">whenever it seems to be following them, you could be training deception as well?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=1701" target="_blank">00:28:21.440</a></span> | <span class="t">Reinforcement has some dangerous aspects to it. I think it's actually more robust to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=1711" target="_blank">00:28:31.680</a></span> | <span class="t">check the process of reasoning and check its understanding of ethics. So to reassure</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=1719" target="_blank">00:28:39.760</a></span> | <span class="t">ourselves that the system has a really good understanding of ethics, it should be grilled</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=1723" target="_blank">00:28:43.920</a></span> | <span class="t">for some time to try to really pull apart its understanding and make sure it has a very robust.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=1731" target="_blank">00:28:51.440</a></span> | <span class="t">And then also if it's deployed, we should have people constantly looking for how the decision</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=1738" target="_blank">00:28:58.240</a></span> | <span class="t">is making and the reasoning process that goes into those decisions to try to understand how</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=1744" target="_blank">00:29:04.400</a></span> | <span class="t">that is correctly reasoning about these types of things. Speaking of which, do you at Google</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=1749" target="_blank">00:29:09.600</a></span> | <span class="t">DeepMind have some sort of framework for this? This is not so much a Google DeepMind perspective</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=1755" target="_blank">00:29:15.280</a></span> | <span class="t">on this. This is my take on how I think we need to do this kind of thing. There are many different</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=1761" target="_blank">00:29:21.360</a></span> | <span class="t">views and there are different variants on these sorts of ideas as well. So then do you personally</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=1767" target="_blank">00:29:27.040</a></span> | <span class="t">think there needs to be some sort of framework for as you arrive at certain capabilities,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=1771" target="_blank">00:29:31.200</a></span> | <span class="t">these are the concrete safety benchmarks that you must have instated at this point or you should</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=1776" target="_blank">00:29:36.080</a></span> | <span class="t">pause or slow down or something? I think that's a sensible thing to do. It's actually quite hard to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=1780" target="_blank">00:29:40.800</a></span> | <span class="t">do. And there are some people thinking about, I know Anthropx has put out some things like that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=1786" target="_blank">00:29:46.000</a></span> | <span class="t">We're thinking about similar things. Actually, putting concrete things down is actually quite</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=1792" target="_blank">00:29:52.720</a></span> | <span class="t">a hard thing to do. So I think it's an important problem and I certainly encourage people to work</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=1796" target="_blank">00:29:56.480</a></span> | <span class="t">on it. It's interesting because you have these blog posts that you wrote when you started</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=1803" target="_blank">00:30:03.120</a></span> | <span class="t">DeepMind back in 2008 where you talk about the motivation was to accelerate safety. On net,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=1812" target="_blank">00:30:12.240</a></span> | <span class="t">what do you think the impact of DeepMind has been on safety versus capabilities?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=1819" target="_blank">00:30:19.360</a></span> | <span class="t">Interesting. I don't know. It's hard to judge, actually.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=1827" target="_blank">00:30:27.360</a></span> | <span class="t">I've been worried about AGI safety for a long time, well before DeepMind.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=1836" target="_blank">00:30:36.320</a></span> | <span class="t">But it was always really hard to hire people, actually, particularly in the early days to work</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=1843" target="_blank">00:30:43.360</a></span> | <span class="t">on AGI safety. I think back in 2013 or so, I think we had the first hire and he only agreed to do it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=1850" target="_blank">00:30:50.880</a></span> | <span class="t">part-time because he didn't want to drop all the capabilities work because the impact it would have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=1858" target="_blank">00:30:58.400</a></span> | <span class="t">on his career and stuff. And this was someone who had already previously been publishing in AGI</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=1862" target="_blank">00:31:02.640</a></span> | <span class="t">safety. So, yeah, I don't know. It's hard to know what is the counterfactual if we weren't there</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=1872" target="_blank">00:31:12.080</a></span> | <span class="t">doing it. I think we have been a group that's been talked about this openly. I've talked about</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=1883" target="_blank">00:31:23.120</a></span> | <span class="t">this on many occasions, the importance of it. We've been hiring people to work on these topics.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=1888" target="_blank">00:31:28.720</a></span> | <span class="t">I know a lot of other people in the area and I've talked to them over many, many years. I've known</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=1895" target="_blank">00:31:35.040</a></span> | <span class="t">Dario since 2005 or something or rather. We've talked on and off about AGI safety and so on. So,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=1901" target="_blank">00:31:41.760</a></span> | <span class="t">I don't know. The impact that DeepMind has had, I guess we were the first,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=1906" target="_blank">00:31:46.880</a></span> | <span class="t">I'd say the first AGI company. And as the first AGI company, we always had an AGI safety group.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=1915" target="_blank">00:31:55.680</a></span> | <span class="t">We've been publishing papers in this for many years. I think that's lent some credibility</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=1922" target="_blank">00:32:02.320</a></span> | <span class="t">to the area when people see, "Oh, here's a AGI." I mean, AGI was a, you know,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=1926" target="_blank">00:32:06.560</a></span> | <span class="t">there was a fringe term not that long ago. And this person's doing AGI safety and they're DeepMind?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=1931" target="_blank">00:32:11.280</a></span> | <span class="t">Oh, okay. I hope that sort of, you know, creates some space for people.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=1936" target="_blank">00:32:16.880</a></span> | <span class="t">And where do you think AI progress itself would have been without DeepMind? And this is not just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=1941" target="_blank">00:32:21.600</a></span> | <span class="t">a point that people make about DeepMind. I think this is a general point we make about</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=1944" target="_blank">00:32:24.880</a></span> | <span class="t">OpenAI and Anthropic as well, that these people went into the business to accelerate safety</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=1950" target="_blank">00:32:30.400</a></span> | <span class="t">and sort of the net effect might've been to accelerate capabilities far more.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=1953" target="_blank">00:32:33.600</a></span> | <span class="t">Right. I think we have accelerated capabilities, but again, the counterfactuals are quite difficult.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=1959" target="_blank">00:32:39.680</a></span> | <span class="t">I mean, we didn't do ImageNet, for example, and ImageNet, I think, was very influential in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=1965" target="_blank">00:32:45.440</a></span> | <span class="t">attracting investment to the field. We did do AlphaGo and that changed some people's minds.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=1974" target="_blank">00:32:54.960</a></span> | <span class="t">But, you know, the community is a lot bigger than just DeepMind. I mean, we have,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=1979" target="_blank">00:32:59.920</a></span> | <span class="t">well, not so much now, but because there are a number of other, you know,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=1985" target="_blank">00:33:05.680</a></span> | <span class="t">players with significant resources. But if you went back more than five years in the future,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=1990" target="_blank">00:33:10.560</a></span> | <span class="t">we were able to do bigger projects with bigger teams and take on more ambitious things than</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=1996" target="_blank">00:33:16.960</a></span> | <span class="t">a lot of the smaller academic groups, right? And so the sort of nature of the type of work</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=2002" target="_blank">00:33:22.560</a></span> | <span class="t">we could do was a bit different. And that, I think, that affected the dynamics in some ways.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=2008" target="_blank">00:33:28.880</a></span> | <span class="t">But, you know, the community is much, much bigger than, say, DeepMind. So</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=2012" target="_blank">00:33:32.640</a></span> | <span class="t">maybe we've sped things up a bit, but I think a lot of these things would have happened</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=2018" target="_blank">00:33:38.400</a></span> | <span class="t">before too long anyway. I think these often good ideas are kind of in the air and, you know,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=2026" target="_blank">00:33:46.160</a></span> | <span class="t">as a researcher, you know, when sometimes you publish something or you're about to publish</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=2031" target="_blank">00:33:51.040</a></span> | <span class="t">something, you see somebody else who's got a very similar idea coming out with some good results.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=2034" target="_blank">00:33:54.800</a></span> | <span class="t">I think often it's the time is right for things. So, you know, I find it very hard to reason about</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=2041" target="_blank">00:34:01.280</a></span> | <span class="t">the counterfactuals there. Speaking of the early years, it's really interesting that in 2009,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=2046" target="_blank">00:34:06.240</a></span> | <span class="t">you had a blog post where you say, "My modal expectation of when we get human-level AI is 2025.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=2052" target="_blank">00:34:12.880</a></span> | <span class="t">Expected value is 2028." And this is before deep learning. This is when nobody's talking about AI.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=2059" target="_blank">00:34:19.760</a></span> | <span class="t">And it turns out, like, if you, if the trends continue, this is not an unreasonable prediction.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=2063" target="_blank">00:34:23.520</a></span> | <span class="t">This was, how did you, I mean, before all these trends came into effect, how did you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=2068" target="_blank">00:34:28.160</a></span> | <span class="t">have that accurate an estimate? Well, first, let's say it's not before deep learning.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=2071" target="_blank">00:34:31.360</a></span> | <span class="t">Deep learning was getting started around 2008. Oh, sorry. I meant to say before ImageNet.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=2078" target="_blank">00:34:38.560</a></span> | <span class="t">Before ImageNet. That was 2012. Yeah. So, well, I first formed those beliefs in about 2001 after</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=2088" target="_blank">00:34:48.560</a></span> | <span class="t">reading Ray Kurzweil's The Age of Spiritual Machines. And I came to the conclusion he was,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=2094" target="_blank">00:34:54.800</a></span> | <span class="t">there was two really important points that in his book that I came to believe is true. One is that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=2102" target="_blank">00:35:02.160</a></span> | <span class="t">computational power would grow exponentially for at least a few decades. And that the quantity</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=2109" target="_blank">00:35:09.200</a></span> | <span class="t">of data in the world would grow exponentially for a few decades. And when you have exponentially</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=2115" target="_blank">00:35:15.680</a></span> | <span class="t">increasing quantities of computation and data, then the value of highly scalable algorithms</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=2122" target="_blank">00:35:22.720</a></span> | <span class="t">gets higher and higher. So then there's a lot of incentive to make a more scalable algorithm to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=2128" target="_blank">00:35:28.000</a></span> | <span class="t">harness all this computing data. And so I thought it would be very likely that we'll start to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=2133" target="_blank">00:35:33.840</a></span> | <span class="t">discover scalable algorithms to do this. And then there's a positive feedback between all these</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=2139" target="_blank">00:35:39.600</a></span> | <span class="t">things, because if your algorithm gets better at harnessing computing data, then the value of the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=2144" target="_blank">00:35:44.320</a></span> | <span class="t">data and the compute goes up because it can be more effectively used. And so that drives more</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=2148" target="_blank">00:35:48.640</a></span> | <span class="t">investment to these areas. If your compute performance goes up, then the value of the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=2153" target="_blank">00:35:53.920</a></span> | <span class="t">data goes up because you can utilize more data. So there are positive feedback loops between all</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=2157" target="_blank">00:35:57.920</a></span> | <span class="t">these things. So that was the first thing. And then the second thing was just looking at the trends.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=2163" target="_blank">00:36:03.760</a></span> | <span class="t">If the scalable algorithms were to be discovered, then during the 2020s, it should be possible to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=2173" target="_blank">00:36:13.040</a></span> | <span class="t">start training models on significantly more data than a human would experience in a lifetime.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=2178" target="_blank">00:36:18.320</a></span> | <span class="t">And I figured that that would be a time where big things would start to happen,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=2183" target="_blank">00:36:23.760</a></span> | <span class="t">and that would eventually unlock AGI. So that was my reasoning process. And I think we're now</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=2189" target="_blank">00:36:29.520</a></span> | <span class="t">at that first part. I think we can start training models now where the scale of the data is beyond</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=2194" target="_blank">00:36:34.400</a></span> | <span class="t">what a human can experience in a lifetime. So I think this is the first unlocking step.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=2199" target="_blank">00:36:39.120</a></span> | <span class="t">And so yeah, I think there's a 50% chance that something like 2028. Now, it's just a 50% chance.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=2206" target="_blank">00:36:46.240</a></span> | <span class="t">I mean, I'm sure what's going to happen. It's going to get to 2029 and someone's going to say,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=2210" target="_blank">00:36:50.160</a></span> | <span class="t">oh, Shane, you were wrong. It's like, come on, it's 50% chance. So yeah, I think it's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=2216" target="_blank">00:36:56.080</a></span> | <span class="t">entirely plausible. Yeah, it's a 50% chance it could happen by 2028. But I'm not going to be</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=2223" target="_blank">00:37:03.200</a></span> | <span class="t">surprised if it doesn't happen by then. You often hit unexpected problems in research and science,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=2231" target="_blank">00:37:11.200</a></span> | <span class="t">but sometimes things take longer than you expect. If there was a problem that caused it,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=2235" target="_blank">00:37:15.440</a></span> | <span class="t">if we're in 2029 and it hasn't happened yet, looking back, what would be the most likely</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=2239" target="_blank">00:37:19.440</a></span> | <span class="t">reason that would be the case? I don't know. I don't know. At the moment, it looks to me</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=2251" target="_blank">00:37:31.680</a></span> | <span class="t">like all the problems are likely solvable with a number of years of research. That's my current</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=2258" target="_blank">00:37:38.000</a></span> | <span class="t">sense. And what does the time from here to 2028 look like if the 2028 ends up being the year?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=2263" target="_blank">00:37:43.600</a></span> | <span class="t">Is it just we have trillions of dollars of economic impact in the meantime and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=2267" target="_blank">00:37:47.920</a></span> | <span class="t">the world gets crazy or what happens? I think what you'll see is the existing models maturing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=2275" target="_blank">00:37:55.360</a></span> | <span class="t">They'll be less delusional, much more factual. They'll be more up to date on what's currently</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=2281" target="_blank">00:38:01.520</a></span> | <span class="t">going on when they answer questions. They'll become multimodal much more than they currently</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=2288" target="_blank">00:38:08.960</a></span> | <span class="t">are. And this will just make them much more useful. So I think probably what we'll see</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=2294" target="_blank">00:38:14.720</a></span> | <span class="t">more than anything is just loads of great applications for the coming years. I think</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=2301" target="_blank">00:38:21.600</a></span> | <span class="t">there can be some misuse cases as well. I'm sure somebody will come up with something to do with</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=2308" target="_blank">00:38:28.400</a></span> | <span class="t">these models that is quite unhelpful. But my expectation for the coming years is mostly a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=2314" target="_blank">00:38:34.640</a></span> | <span class="t">positive one. We'll see all kinds of really impressive, really amazing applications for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=2321" target="_blank">00:38:41.040</a></span> | <span class="t">the coming years. And on the safety point, you mentioned these different research directions</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=2327" target="_blank">00:38:47.680</a></span> | <span class="t">that are out there and that you are doing internally in DeepMind as well. Interoperability,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=2331" target="_blank">00:38:51.600</a></span> | <span class="t">RAIF and so on. Which are you most optimistic about? I don't know. I don't pick favorites.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=2341" target="_blank">00:39:01.920</a></span> | <span class="t">It's hard picking favorites. I know the people working on all these areas.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=2346" target="_blank">00:39:06.560</a></span> | <span class="t">I think things of the sort of system two flavor. There's a work we have going on that Jeffrey</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=2358" target="_blank">00:39:18.320</a></span> | <span class="t">Irving leads called Deliberative Dialogue, which kind of has the system two flavor where</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=2364" target="_blank">00:39:24.400</a></span> | <span class="t">you have this sort of debate takes place about the actions that an agent could take or what's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=2372" target="_blank">00:39:32.880</a></span> | <span class="t">the correct answer to something like this. And people then can sort of review these debates and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=2378" target="_blank">00:39:38.880</a></span> | <span class="t">so on. And they use these sort of AI algorithms to help them judge the correct outcomes and so on.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=2386" target="_blank">00:39:46.240</a></span> | <span class="t">And so this is sort of meant to be a way in which to try to scale the alignment to sort of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=2393" target="_blank">00:39:53.840</a></span> | <span class="t">increasingly powerful systems. So I think things of that kind of flavor, I think have quite a lot</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=2401" target="_blank">00:40:01.280</a></span> | <span class="t">of promise in my opinion, but that's kind of quite a broad category. There are many different topics</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=2406" target="_blank">00:40:06.160</a></span> | <span class="t">within that. That's interesting. So you mentioned two areas in which algorithms need to improve.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=2413" target="_blank">00:40:13.440</a></span> | <span class="t">One is the episodic memory and the other is the system two thinking. Are those two related or are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=2417" target="_blank">00:40:17.840</a></span> | <span class="t">they two separate drawbacks? I think they're fairly separate,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=2425" target="_blank">00:40:25.280</a></span> | <span class="t">but they can be somewhat related. So you can learn different ways of thinking through problems</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=2432" target="_blank">00:40:32.080</a></span> | <span class="t">and actually learn about this rapidly using your episodic memory. So all these different</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=2437" target="_blank">00:40:37.120</a></span> | <span class="t">systems and subsystems interact, so they're never completely separate. But I think conceptually,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=2442" target="_blank">00:40:42.240</a></span> | <span class="t">you can probably think of them as quite separate things. I think delusions and factuality is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=2446" target="_blank">00:40:46.800</a></span> | <span class="t">another area that's going to be quite important and particularly important in lots of applications.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=2452" target="_blank">00:40:52.960</a></span> | <span class="t">If you want a model that writes creative poetry, then that's fine because you want to be able to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=2459" target="_blank">00:40:59.040</a></span> | <span class="t">be very free to suggest all kinds of possibilities and so on. You're not really constrained by a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=2463" target="_blank">00:41:03.440</a></span> | <span class="t">specific reality. Whereas if you want something that's in a particular application, normally you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=2470" target="_blank">00:41:10.160</a></span> | <span class="t">have to be quite concrete about what's currently going on and what is true and what is not true</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=2475" target="_blank">00:41:15.120</a></span> | <span class="t">and so on. Models are a little bit freewheeling when it comes to truth and creativity at the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=2481" target="_blank">00:41:21.040</a></span> | <span class="t">moment. That, I think, limits their applications in many ways. So final question is this. You've</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=2487" target="_blank">00:41:27.680</a></span> | <span class="t">been in this field for over a decade, much longer than many others, and you've seen these different</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=2494" target="_blank">00:41:34.000</a></span> | <span class="t">landmarks, ImageNet, transformers. What do you think the next landmark will look like?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=2499" target="_blank">00:41:39.920</a></span> | <span class="t">I think the next landmark that people will think back to and remember is going much more fully</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=2510" target="_blank">00:41:50.160</a></span> | <span class="t">multimodal, I think. Because I think that will open out the sort of understanding that you see</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=2518" target="_blank">00:41:58.160</a></span> | <span class="t">in language models into a much larger space of possibilities. And when people think back,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=2524" target="_blank">00:42:04.160</a></span> | <span class="t">they'll think about, "Oh, those old-fashioned models, they just did like chat. They just did</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=2528" target="_blank">00:42:08.560</a></span> | <span class="t">text." It just felt like a very narrow thing. Whereas now they understand when you talk to them,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=2534" target="_blank">00:42:14.880</a></span> | <span class="t">and they understand images and pictures and video, and you can show them things or things like that,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=2540" target="_blank">00:42:20.080</a></span> | <span class="t">and they will have much more understanding of what's going on. And it'll feel like the system's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=2543" target="_blank">00:42:23.680</a></span> | <span class="t">kind of opened up into the world in a much more powerful way.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=2548" target="_blank">00:42:28.800</a></span> | <span class="t">Do you mind if I ask a follow-up on that? So Chad GPT just released their multimodal feature,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=2553" target="_blank">00:42:33.600</a></span> | <span class="t">and then you in DeepMind, you had the Gato paper where you have this one model, you can images,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=2559" target="_blank">00:42:39.440</a></span> | <span class="t">even actions, video games, whatever you can throw in there. And so far, it hasn't percolated as</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=2566" target="_blank">00:42:46.800</a></span> | <span class="t">much as even like Chad GPT initially from GPT-3 or something. What explains that? Is it just that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=2571" target="_blank">00:42:51.520</a></span> | <span class="t">people haven't learned to use multimodality, they're not powerful enough yet?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=2574" target="_blank">00:42:54.400</a></span> | <span class="t">I think it's early days. I think there's, you can see promise there, understanding images and things</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=2580" target="_blank">00:43:00.720</a></span> | <span class="t">more and more. But I think it's early days in this transition, is when you start really digesting a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=2586" target="_blank">00:43:06.880</a></span> | <span class="t">lot of video and other things like that, that the systems will start having a much more grounded</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=2592" target="_blank">00:43:12.560</a></span> | <span class="t">understanding of the world and all kinds of other aspects. And then when that works well,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=2597" target="_blank">00:43:17.200</a></span> | <span class="t">that will open up naturally lots and lots of new applications and all sorts of new possibilities</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=2602" target="_blank">00:43:22.720</a></span> | <span class="t">because you're not confined to text chat anymore. The new avenues of training data as well, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=2608" target="_blank">00:43:28.000</a></span> | <span class="t">Yeah, new training data and all kinds of different applications that aren't just purely textual</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=2613" target="_blank">00:43:33.360</a></span> | <span class="t">anymore. And what are those applications? Well, probably a lot of them we can't even imagine at</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=2619" target="_blank">00:43:39.360</a></span> | <span class="t">the moment, because there are just so many possibilities once you can start dealing with</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=2623" target="_blank">00:43:43.760</a></span> | <span class="t">all sorts of different modalities in a consistent way. Awesome. Shane, I think that's an excellent</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=2627" target="_blank">00:43:47.920</a></span> | <span class="t">place to leave it off. Thank you so much for coming on the podcast. Thank you.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=2630" target="_blank">00:43:50.960</a></span> | <span class="t">Hey everybody. I hope you enjoyed that episode. As always, the most helpful thing you can do</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=2637" target="_blank">00:43:57.440</a></span> | <span class="t">is to share the podcast. Send it to people you think might enjoy it, put it in Twitter,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=2641" target="_blank">00:44:01.760</a></span> | <span class="t">your group chats, etc. It just splits the world. Appreciate you listening. I'll see you next time.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Kc1atfJkiJU&t=2655" target="_blank">00:44:15.200</a></span> | <span class="t">[Music]</span></div></div></body></html>