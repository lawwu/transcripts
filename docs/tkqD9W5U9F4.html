<html><head><title>Google Gemini: AlphaGo-GPT?</title>
<style>
    body {
        font-family: Arial, sans-serif;
        margin: 0;
        padding: 0;
        background-color: #f4f4f4;
        color: #333;
    }
    .container {
        width: 80%;
        margin: auto;
        overflow: hidden;
    }
    h2, h3 {
        color: #333;
        text-align: center;
    }
    a {
        color: #0000FF;  /* Traditional blue color for links */
        text-decoration: none;
    }
    a:hover {
        text-decoration: underline;
    }
    img {
        display: block;
        margin: auto;
        max-width: 100%;
    }
    .c {
        margin: 10px 0;
    }
    .s, .t {
        display: inline-block;
        margin-right: 5px;
    }
    .max-width {
        max-width: 800px;
        margin: auto;
        padding-left: 20px;
    }
    table {
        width: 100%;
        border-collapse: collapse;
    }
    th, td {
        border: 1px solid #ddd;
        padding: 8px;
    }
    tr:nth-child(even) {
        background-color: #f2f2f2;
    }
    tr:nth-child(odd) {
        background-color: #e6e6e6;
    }
</style>

    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-69VLBMTTP0"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-69VLBMTTP0');
    </script>
    </head><body><div class='container'><a href="index.html">back to index</a><h2>Google Gemini: AlphaGo-GPT?</h2><a href="https://www.youtube.com/watch?v=tkqD9W5U9F4"><img src="https://i.ytimg.com/vi_webp/tkqD9W5U9F4/maxresdefault.webp" style="width:50%;"></a><div><br></div><h3>Chapters</h3><a href="https://www.youtube.com/watch?v=tkqD9W5U9F4&t=0">0:0</a> Intro<br><a href="https://www.youtube.com/watch?v=tkqD9W5U9F4&t=15">0:15</a> Context<br><a href="https://www.youtube.com/watch?v=tkqD9W5U9F4&t=240">4:0</a> AlphaGoGPT<br><a href="https://www.youtube.com/watch?v=tkqD9W5U9F4&t=390">6:30</a> Truth of Thoughts Paper<br><a href="https://www.youtube.com/watch?v=tkqD9W5U9F4&t=529">8:49</a> Implications<br><br><div style="text-align: left;"><a href="./tkqD9W5U9F4.html">Whisper Transcript</a> | <a href="./transcript_tkqD9W5U9F4.html">Transcript Only Page</a></div><br><div style="max-width: 800px;"><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tkqD9W5U9F4&t=0" target="_blank">00:00:00.000</a></span> | <span class="t">In a somewhat provocative new interview with Wired Magazine, Demis Hassabis, head of Google</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tkqD9W5U9F4&t=6" target="_blank">00:00:06.000</a></span> | <span class="t">DeepMind, is quoted as saying that Gemini, which could be released as soon as this winter,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tkqD9W5U9F4&t=11" target="_blank">00:00:11.120</a></span> | <span class="t">will be more capable than OpenAI's ChatGPT. He reveals that they are attempting to combine</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tkqD9W5U9F4&t=17" target="_blank">00:00:17.500</a></span> | <span class="t">some of the strengths of AlphaGo type systems with the amazing language capabilities of large</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tkqD9W5U9F4&t=23" target="_blank">00:00:23.700</a></span> | <span class="t">models. Before we look into how that might work, here is the context of the Gemini announcement</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tkqD9W5U9F4&t=28" target="_blank">00:00:28.840</a></span> | <span class="t">from Sundar Pichai. They are focused on building more capable systems safely and responsibly.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tkqD9W5U9F4&t=35" target="_blank">00:00:35.280</a></span> | <span class="t">This includes our next generation foundation model, Gemini, which is still in training. While</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tkqD9W5U9F4&t=41" target="_blank">00:00:41.200</a></span> | <span class="t">still early, we are already seeing impressive multi-model capabilities not seen in prior models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tkqD9W5U9F4&t=47" target="_blank">00:00:47.340</a></span> | <span class="t">Hassabis promises that we also have some new innovations that are going to be pretty</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tkqD9W5U9F4&t=52" target="_blank">00:00:52.560</a></span> | <span class="t">interesting. And I know many people will dismiss this as all talk, but remember DeepMind was behind</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tkqD9W5U9F4&t=58" target="_blank">00:00:58.680</a></span> | <span class="t">not just AlphaGo, but also AlphaZero, which can play any two-player full information game from</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tkqD9W5U9F4&t=65" target="_blank">00:01:05.220</a></span> | <span class="t">scratch. They were also behind AlphaStar, which conquered StarCraft 2 with quote,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tkqD9W5U9F4&t=70" target="_blank">00:01:10.140</a></span> | <span class="t">long-term planning. And let's remember that for later. And most famously, perhaps, Hassabis led</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tkqD9W5U9F4&t=75" target="_blank">00:01:15.220</a></span> | <span class="t">them to the incredible breakthrough of AlphaFold and AlphaFold2, which are already impacting the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tkqD9W5U9F4&t=81" target="_blank">00:01:21.860</a></span> | <span class="t">fight against plastic pollution and antibiotic resistance. So let's not underestimate DeepMind.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tkqD9W5U9F4&t=88" target="_blank">00:01:28.520</a></span> | <span class="t">To Gemini, we hear from the information recently that the multi-modality of Gemini will be helped</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tkqD9W5U9F4&t=94" target="_blank">00:01:34.300</a></span> | <span class="t">in part by training on YouTube videos. And apparently YouTube was also mined by OpenAI.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tkqD9W5U9F4&t=101" target="_blank">00:01:41.320</a></span> | <span class="t">Of course, that's not just the text transcripts, but also the audio, imagery, and probably</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tkqD9W5U9F4&t=106" target="_blank">00:01:46.760</a></span> | <span class="t">comments. I wonder if Google DeepMind might one day use YouTube for more than that. A few days</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tkqD9W5U9F4&t=112" target="_blank">00:01:52.380</a></span> | <span class="t">ago, they released this paper on RoboCat, which they call a self-improving foundation agent for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tkqD9W5U9F4&t=118" target="_blank">00:01:58.360</a></span> | <span class="t">robotic manipulation. And the paper says that with RoboCat, we demonstrate the ability to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tkqD9W5U9F4&t=123" target="_blank">00:02:03.480</a></span> | <span class="t">generalize to new tasks and robots, both zero-shot as well as through adaptation using only a hundred</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tkqD9W5U9F4&t=130" target="_blank">00:02:10.240</a></span> | <span class="t">to a thousand examples for the target task. We also show how a trained model itself can be used</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tkqD9W5U9F4&t=135" target="_blank">00:02:15.500</a></span> | <span class="t">to generate data for subsequent training iterations, thus providing a basic building block</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tkqD9W5U9F4&t=141" target="_blank">00:02:21.580</a></span> | <span class="t">for an autonomous improvement loop. Notice that part about using the model itself to generate data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tkqD9W5U9F4&t=148" target="_blank">00:02:28.200</a></span> | <span class="t">That reminded me of a conversation I had with one of the authors of the textbooks are all you need</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tkqD9W5U9F4&t=154" target="_blank">00:02:34.260</a></span> | <span class="t">paper, Ronan Eldan from Microsoft. I'm making a video on their new Phi1 model for coding. We had</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tkqD9W5U9F4&t=160" target="_blank">00:02:40.880</a></span> | <span class="t">a really great chat and we were discussing at one point AGI timelines. And I said this, when you get</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tkqD9W5U9F4&t=166" target="_blank">00:02:46.420</a></span> | <span class="t">elite math papers with proofs and elite scientific research, if you train on much more of those for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tkqD9W5U9F4&t=172" target="_blank">00:02:52.340</a></span> | <span class="t">way more epochs, I don't think we're that far away from AGI. I personally can't see any barrier within</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tkqD9W5U9F4&t=178" target="_blank">00:02:58.040</a></span> | <span class="t">the next five years. Ronan said this, as you said, I also don't see any barrier to AGI. My intuition is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tkqD9W5U9F4&t=184" target="_blank">00:03:04.200</a></span> | <span class="t">that there's probably a lot more improvement we can do with the data we have and maybe a little</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tkqD9W5U9F4&t=189" target="_blank">00:03:09.160</a></span> | <span class="t">bit more synthetic data. And this is even without starting to talk about self-improving mechanisms</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tkqD9W5U9F4&t=194" target="_blank">00:03:14.920</a></span> | <span class="t">like AlphaZero, where the more you train models with some verification process and you generate</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tkqD9W5U9F4&t=201" target="_blank">00:03:21.160</a></span> | <span class="t">more data, this can be done in math and other things as we see here with RoboCat. So you know, there's just so many</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tkqD9W5U9F4&t=207" target="_blank">00:03:27.880</a></span> | <span class="t">directions where we can still go that I don't think we're going to hit a ceiling anytime soon.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tkqD9W5U9F4&t=212" target="_blank">00:03:32.920</a></span> | <span class="t">Can't wait to show you guys the rest of that paper and what else I learned from Ronan, who is also by</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tkqD9W5U9F4&t=217" target="_blank">00:03:37.240</a></span> | <span class="t">the way the author of the Tiny Stories paper. But back to Gemini. If you remember the planning bit</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tkqD9W5U9F4&t=222" target="_blank">00:03:42.600</a></span> | <span class="t">from DeepMind's earlier systems, that reminded me of something else from Gemini's introduction.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tkqD9W5U9F4&t=228" target="_blank">00:03:48.040</a></span> | <span class="t">Gemini was created from the ground up to be multi-modal,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tkqD9W5U9F4&t=231" target="_blank">00:03:51.640</a></span> | <span class="t">highly efficient at tool and API integrations and built to enable future</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tkqD9W5U9F4&t=237" target="_blank">00:03:57.720</a></span> | <span class="t">innovations like memory and planning. This is echoed in the article in which</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tkqD9W5U9F4&t=242" target="_blank">00:04:02.600</a></span> | <span class="t">Hassabis says his team will combine a language model like GPT-4 with techniques used in AlphaGo,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tkqD9W5U9F4&t=248" target="_blank">00:04:08.760</a></span> | <span class="t">aiming to give the system new capabilities such as planning or the ability to solve problems.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tkqD9W5U9F4&t=255" target="_blank">00:04:15.560</a></span> | <span class="t">Interestingly, this comes just a few weeks after DeepMind's Extreme Risks paper, which identified</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tkqD9W5U9F4&t=261" target="_blank">00:04:21.560</a></span> | <span class="t">long horizon planning as a dangerous capability. For example, adapting its plans in the light of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tkqD9W5U9F4&t=267" target="_blank">00:04:27.560</a></span> | <span class="t">unexpected obstacles or adversaries and generalizing to novel or new settings.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tkqD9W5U9F4&t=272" target="_blank">00:04:32.920</a></span> | <span class="t">For me, this is a bit like when a model can predict what humans would do in reaction to its own output.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tkqD9W5U9F4&t=278" target="_blank">00:04:38.520</a></span> | <span class="t">Back to the article, it's interesting though that Hassabis is both tasked with accelerating</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tkqD9W5U9F4&t=283" target="_blank">00:04:43.960</a></span> | <span class="t">Google's AI efforts while also managing unknown and potentially grave risks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tkqD9W5U9F4&t=289" target="_blank">00:04:49.000</a></span> | <span class="t">So what's his take? Hassabis says the extraordinary potential benefits of AI,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tkqD9W5U9F4&t=293" target="_blank">00:04:53.720</a></span> | <span class="t">such as forced scientific discovery in areas like health or climate,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tkqD9W5U9F4&t=297" target="_blank">00:04:57.400</a></span> | <span class="t">and the ability to develop new technologies and technologies that will help humanity.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tkqD9W5U9F4&t=301" target="_blank">00:05:01.240</a></span> | <span class="t">He also believes that mandating a pause is impractical as it would be near impossible to enforce.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tkqD9W5U9F4&t=306" target="_blank">00:05:06.120</a></span> | <span class="t">If done correctly, it will be the most beneficial technology for humanity ever, he says of AI.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tkqD9W5U9F4&t=311" target="_blank">00:05:11.880</a></span> | <span class="t">We've got to boldly and bravely go after those things.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tkqD9W5U9F4&t=315" target="_blank">00:05:15.880</a></span> | <span class="t">So how would AlphaGo become AlphaGo GPT?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tkqD9W5U9F4&t=319" target="_blank">00:05:19.560</a></span> | <span class="t">Hassabis described the basic approach behind AlphaGo in two of his recent talks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tkqD9W5U9F4&t=324" target="_blank">00:05:24.120</a></span> | <span class="t">So what's going on here then? Well, effectively, if one</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tkqD9W5U9F4&t=327" target="_blank">00:05:27.240</a></span> | <span class="t">thinks of a Go tree as the tree of all possibilities, and you imagine each node in this tree is a Go position.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tkqD9W5U9F4&t=333" target="_blank">00:05:33.880</a></span> | <span class="t">So what we're basically doing is guiding the search with the model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tkqD9W5U9F4&t=337" target="_blank">00:05:37.000</a></span> | <span class="t">So the model is coming up with most probable moves and therefore guiding the tree search to be very efficient.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tkqD9W5U9F4&t=344" target="_blank">00:05:44.280</a></span> | <span class="t">And then when it runs out of time, of course, then it outputs the best tree that it's found up to that point.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tkqD9W5U9F4&t=349" target="_blank">00:05:49.960</a></span> | <span class="t">We've learned that from data or from simulated data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tkqD9W5U9F4&t=353" target="_blank">00:05:53.720</a></span> | <span class="t">Ideally, you have both in many cases. So in games, obviously, we have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tkqD9W5U9F4&t=357" target="_blank">00:05:57.080</a></span> | <span class="t">this, it's effectively simulated data. And then what you do is you take that model,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tkqD9W5U9F4&t=361" target="_blank">00:06:01.320</a></span> | <span class="t">and then you use that model to guide a search process according to some objective function.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tkqD9W5U9F4&t=367" target="_blank">00:06:07.240</a></span> | <span class="t">I think this is a general way to think about a lot of problems.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tkqD9W5U9F4&t=370" target="_blank">00:06:10.040</a></span> | <span class="t">I'm not saying every problem can fit into that. I mean, maybe.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tkqD9W5U9F4&t=373" target="_blank">00:06:13.000</a></span> | <span class="t">And I'll give you an example from drug discovery, which is what we're trying to do at Isomorphic.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tkqD9W5U9F4&t=377" target="_blank">00:06:17.720</a></span> | <span class="t">So this is the tree I showed you earlier, finding the best Go move, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tkqD9W5U9F4&t=380" target="_blank">00:06:20.920</a></span> | <span class="t">You're trying to find a near optimal or close to optimal Go move and Go strategy. Well,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tkqD9W5U9F4&t=386" target="_blank">00:06:26.920</a></span> | <span class="t">what happens if we just change those nodes to chemical compounds?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tkqD9W5U9F4&t=391" target="_blank">00:06:31.240</a></span> | <span class="t">Now, let me know in the comments if that reminded anyone else of the Tree of Thoughts paper in which</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tkqD9W5U9F4&t=396" target="_blank">00:06:36.680</a></span> | <span class="t">multiple plans are sampled and results were exponentially better on tasks that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tkqD9W5U9F4&t=401" target="_blank">00:06:41.880</a></span> | <span class="t">GPT-4 finds impossible, like creating workable crosswords or mathematical</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tkqD9W5U9F4&t=406" target="_blank">00:06:46.280</a></span> | <span class="t">problems that require a bit of planning, like creating the greatest integer from a set of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tkqD9W5U9F4&t=411" target="_blank">00:06:51.240</a></span> | <span class="t">four integers using operations like multiplying and addition. Well, I think my theory might have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tkqD9W5U9F4&t=416" target="_blank">00:06:56.760</a></span> | <span class="t">some legs because look at where many of the authors of this paper work.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tkqD9W5U9F4&t=421" target="_blank">00:07:01.640</a></span> | <span class="t">And just yesterday, as I was researching for this video, the Tree of Thoughts paper was also cited</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tkqD9W5U9F4&t=427" target="_blank">00:07:07.720</a></span> | <span class="t">in this paper on using language models to prove mathematical theorems. As you can see at the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tkqD9W5U9F4&t=433" target="_blank">00:07:13.000</a></span> | <span class="t">moment, GPT-4 doesn't do a great job. But my point in bringing this up was this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tkqD9W5U9F4&t=437" target="_blank">00:07:17.000</a></span> | <span class="t">They say towards the end of the paper that another key limitation of ChatGPT</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tkqD9W5U9F4&t=441" target="_blank">00:07:21.560</a></span> | <span class="t">was its inability to search systematically in a large space. Remember, that's what AlphaGo is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tkqD9W5U9F4&t=446" target="_blank">00:07:26.600</a></span> | <span class="t">really good at. We frequently found that it stuck to an unpromising path when the correct solution</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tkqD9W5U9F4&t=452" target="_blank">00:07:32.200</a></span> | <span class="t">could be found by backtracking, a la Tree of Thoughts, and exploring alternative paths.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tkqD9W5U9F4&t=457" target="_blank">00:07:37.720</a></span> | <span class="t">This behavior is consistent with the general observation that LLMs are weak at search and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tkqD9W5U9F4&t=462" target="_blank">00:07:42.760</a></span> | <span class="t">planning. Addressing this weakness is an active area of research and then they reference the Tree</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tkqD9W5U9F4&t=467" target="_blank">00:07:47.480</a></span> | <span class="t">of Thoughts paper. It could well be that Gemini, let alone Gemini 2,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tkqD9W5U9F4&t=471" target="_blank">00:07:51.720</a></span> | <span class="t">reaches state of the art for mathematical theorem proving. And to be honest, once we can</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tkqD9W5U9F4&t=476" target="_blank">00:07:56.440</a></span> | <span class="t">prove theorems we won't be as far from generating new ones. And in my opinion, fusing this AlphaGo</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tkqD9W5U9F4&t=482" target="_blank">00:08:02.600</a></span> | <span class="t">style branching mechanism with a large language model could work for other things. We've all seen</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tkqD9W5U9F4&t=487" target="_blank">00:08:07.640</a></span> | <span class="t">models like GPT-4 sometimes give a bad initial answer, picking just the most probable output</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tkqD9W5U9F4&t=493" target="_blank">00:08:13.000</a></span> | <span class="t">in a way that's sometimes called "greedy decoding". But methods like SmartGPT and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tkqD9W5U9F4&t=497" target="_blank">00:08:17.320</a></span> | <span class="t">self-consistency demonstrate that the first initial or most probable output</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tkqD9W5U9F4&t=502" target="_blank">00:08:22.280</a></span> | <span class="t">doesn't always reflect the best that a model can do. And this is just one of the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tkqD9W5U9F4&t=506" target="_blank">00:08:26.280</a></span> | <span class="t">reasons, as I said to Ronan, that I honestly think we could see a model hit 100% in the MMLU</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tkqD9W5U9F4&t=512" target="_blank">00:08:32.760</a></span> | <span class="t">in less than 5 years. The MMLU, which I talked about in my SmartGPT video, is a famous machine</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tkqD9W5U9F4&t=518" target="_blank">00:08:38.440</a></span> | <span class="t">learning benchmark, testing everything from formal logic to physics and politics. And I know that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tkqD9W5U9F4&t=523" target="_blank">00:08:43.800</a></span> | <span class="t">predicting 100% performance within 5 years is a very bold prediction, but that is my prediction.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tkqD9W5U9F4&t=529" target="_blank">00:08:49.480</a></span> | <span class="t">But if those are the growing capabilities, what does Demis Hassabis think about the implications of the sheer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tkqD9W5U9F4&t=536" target="_blank">00:08:56.120</a></span> | <span class="t">power of such a model? One of the biggest challenges right now, Hassabis says, is to determine</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tkqD9W5U9F4&t=541" target="_blank">00:09:01.880</a></span> | <span class="t">what the risks of a more capable AI are likely to be. I think more research by the field needs to be</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tkqD9W5U9F4&t=548" target="_blank">00:09:08.120</a></span> | <span class="t">done very urgently on things like evaluation tests, he says, to determine how capable and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tkqD9W5U9F4&t=554" target="_blank">00:09:14.680</a></span> | <span class="t">controllable new AI models are. He later mentions giving academia early access to these frontier</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tkqD9W5U9F4&t=560" target="_blank">00:09:20.600</a></span> | <span class="t">models. And they do seem to be following through on this with DeepMind, OpenAI and Anthropic giving</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tkqD9W5U9F4&t=565" target="_blank">00:09:25.960</a></span> | <span class="t">early access to their foundation models to the UK AI Task Force. This Foundation Model Task Force is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tkqD9W5U9F4&t=572" target="_blank">00:09:32.920</a></span> | <span class="t">led by Ian Hogarth, who was actually the author of this, the "We Must Slow Down the Race to Godlike</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tkqD9W5U9F4&t=579" target="_blank">00:09:39.560</a></span> | <span class="t">AI" paper that I did a video on back in April. Do check that video out. But in the article,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tkqD9W5U9F4&t=584" target="_blank">00:09:44.600</a></span> | <span class="t">Hogarth mentioned a practical plan to transform these companies into a CERN-like organisation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tkqD9W5U9F4&t=591" target="_blank">00:09:51.240</a></span> | <span class="t">And somewhat unexpectedly, this idea was echoed this week by none other than</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tkqD9W5U9F4&t=595" target="_blank">00:09:55.800</a></span> | <span class="t">Satya Nadella, who had earlier called on Google to "dance".</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tkqD9W5U9F4&t=599" target="_blank">00:09:59.560</a></span> | <span class="t">Satya Nadella: Essentially, the biggest unsolved problem is how do you ensure both at sort of a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tkqD9W5U9F4&t=605" target="_blank">00:10:05.480</a></span> | <span class="t">scientific understanding level and then the practical engineering level that you can make</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tkqD9W5U9F4&t=611" target="_blank">00:10:11.480</a></span> | <span class="t">sure that the AI never goes out of control. And that's where I think there needs to be a CERN-like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tkqD9W5U9F4&t=617" target="_blank">00:10:17.480</a></span> | <span class="t">project where both the academics along with corporations and governments all come together to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tkqD9W5U9F4&t=624" target="_blank">00:10:24.360</a></span> | <span class="t">perhaps solve that alignment problem.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tkqD9W5U9F4&t=625" target="_blank">00:10:25.640</a></span> | <span class="t">But back to the article, the interview with Hassabis ended with this somewhat chilling</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tkqD9W5U9F4&t=633" target="_blank">00:10:33.000</a></span> | <span class="t">response to the question "How worried should you be?" Hassabis says that no one really knows for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tkqD9W5U9F4&t=637" target="_blank">00:10:37.480</a></span> | <span class="t">sure that AI will become a major danger, but he is certain that if progress continues at its current</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tkqD9W5U9F4&t=643" target="_blank">00:10:43.240</a></span> | <span class="t">pace, there isn't much time to develop safeguards. I can see the kind of things we're building into</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tkqD9W5U9F4&t=648" target="_blank">00:10:48.760</a></span> | <span class="t">the Gemini series and we have no reason to believe they won't work. My own thoughts on this article</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tkqD9W5U9F4&t=654" target="_blank">00:10:54.600</a></span> | <span class="t">are twofold. First, I think it's a good idea to have a CERN-like organisation. I think it's a good</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tkqD9W5U9F4&t=655" target="_blank">00:10:55.480</a></span> | <span class="t">idea to have a CERN-like organisation. I think it's a good idea to have a CERN-like organisation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tkqD9W5U9F4&t=655" target="_blank">00:10:55.800</a></span> | <span class="t">That we might not want to underestimate Google and Hassabis and that adding AlphaGo type systems</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tkqD9W5U9F4&t=661" target="_blank">00:11:01.720</a></span> | <span class="t">probably will work. And second, based on his comments, I do think there needs to be more</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tkqD9W5U9F4&t=666" target="_blank">00:11:06.280</a></span> | <span class="t">clarity on just how much of Google DeepMind's workforce is working on these evaluations and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tkqD9W5U9F4&t=672" target="_blank">00:11:12.600</a></span> | <span class="t">pre-emptive measures. This article from a few months ago estimates that there may be less than</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tkqD9W5U9F4&t=677" target="_blank">00:11:17.400</a></span> | <span class="t">100 researchers focused on those areas. Out of 1000, so is it even 5% of the total? And if not,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tkqD9W5U9F4&t=685" target="_blank">00:11:25.320</a></span> | <span class="t">why take too seriously the commitments at any AI summit such as the one happening this autumn in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tkqD9W5U9F4&t=690" target="_blank">00:11:30.920</a></span> | <span class="t">the UK on safety? On the other hand, if Hassabis revealed that half or more of his workforce were</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tkqD9W5U9F4&t=696" target="_blank">00:11:36.920</a></span> | <span class="t">on the case, then we could be more confident that the creators of AlphaGo and my fellow Londoners</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tkqD9W5U9F4&t=703" target="_blank">00:11:43.320</a></span> | <span class="t">had a good chance of tree-searching to safety and success.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tkqD9W5U9F4&t=707" target="_blank">00:11:47.800</a></span> | <span class="t">As always, thank you so much for watching and have a wonderful day.</span></div></div></body></html>