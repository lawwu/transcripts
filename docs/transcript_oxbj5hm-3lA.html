<html><head><title>Brain & Transformers Work The Same Way - Association Is All You Need</title>
<style>
    body {
        font-family: Arial, sans-serif;
        margin: 0;
        padding: 0;
        background-color: #f4f4f4;
        color: #333;
    }
    .container {
        width: 95%;  /* Increased width to use more space */
        margin: auto;
        overflow: auto;  /* Added to handle overflow by adding a scrollbar if necessary */
    }
    h2, h3 {
        color: #333;
        text-align: center;
    }
    a {
        color: #0000FF;  /* Traditional blue color for links */
        text-decoration: none;
    }
    a:hover {
        text-decoration: underline;
    }
    img {
        display: block;
        margin: auto;
        max-width: 100%;
    }
    .c {
        margin: 10px 0;
    }
    .s, .t {
        display: inline-block;
        margin-right: 5px;
    }
    .max-width {
        max-width: 800px;
        margin: auto;
        padding-left: 20px;
    }
    table {
        width: 100%;
        border-collapse: collapse;
    }
    th, td {
        border: 1px solid #ddd;
        padding: 8px;
        text-align: left;  /* Ensure text alignment is consistent */
    }
    tr:nth-child(even) {
        background-color: #f2f2f2;
    }
    tr:nth-child(odd) {
        background-color: #e6e6e6;
    }
</style>

    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-69VLBMTTP0"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-69VLBMTTP0');
    </script>
    </head><body><div class='container'><a href="index.html">Back to Index</a><h2>Brain & Transformers Work The Same Way - Association Is All You Need</h2><a href="https://www.youtube.com/watch?v=oxbj5hm-3lA" target="_blank"><img src="https://i.ytimg.com/vi_webp/oxbj5hm-3lA/maxresdefault.webp" style="width:50%;"></a><div><br></div><h3>Transcript</h3><div class='max-width'><p>So maybe my hot take here, I don't know how hot it is, is that like most intelligence is pattern matching. And you can do a lot of really good pattern matching if you have a hierarchy of associated memories. So you start with your very basic associations between just like objects in the real world, but you can then chain those and have more abstract associations, such as like a wedding ring symbolizes like so many other associations that are downstream.</p><p>And so, and you can even generalize the attention operation and this associated memory as the MLP layer as well. And it's in a long-term setting where you don't have like tokens in your current context. But I think this is an argument that like association is all you need. Okay, so let me ask a stupid question.</p><p>So you like reach Sherlock Holmes, right? And like the guy's incredibly sample efficient. He'll like see a few observations and he'll like basically figure out who committed the crime 'cause there's a series of deductive steps that leads from somebody's tattoo and what's on the wall to the implications of that.</p><p>How does that fit into this picture? 'Cause like crucially what makes them smart is that there's not like an association, but there's a sort of deductive connection between different pieces of information. Would you just explain it as that's just like higher level association? Like, yeah. - I think so, yeah.</p><p>So I think learning these higher level associations to be able to then map patterns to each other as kind of like a meta learning. I think in this case, he would also just have a really long context length or a really long working memory, right? Where he can like have all of these bits and continuously query them as he's coming up with whatever theory.</p><p>So that the theory is moving through the residual stream and then his attention heads are querying his context, but then how he's projecting his query and keys in the space and how his MLPs are then retrieving like longer term facts or modifying that information is allowing him to then in later layers do even more sophisticated queries and slowly be able to reason through and come to a meaningful conclusion.</p><p>- That feels right to me in terms of like looking back in the past, you're selectively reading in certain piece of information, comparing them. Maybe that informs your next step of like what piece of information you now need to pull in. And then you build this representation, which I like progressively looks closer and closer and closer to like the suspect in your case.</p><p>- Yeah, yeah. - That doesn't feel at all outlandish. It does bring to mind like a very funny eval to do would be like a Sherlock Holmes eval. Let's say you put the entire book into context and then you have like a sentence, which is like the suspect is like X, then you have like a logic probability distribution over like the different characters in the book.</p><p>And then like, as you put more like-- - That would be super cool. - I wonder if you'd get anything at all, but it'd be cool. - Sherlock Holmes is probably already in the training data. - Yeah. - You gotta get like a mystery novel that was written in the-- - You can get an hour long to write it.</p><p>- Or we can like, we can purposely exclude it, right? - Oh, you can, how do you-- - Well, you need to scrape any discussion of it from Reddit or any other thing, right? - Right, it's hard. But that's like one of the challenges that goes into things like long context evals is to get a good one.</p><p>You need to know that it's not in your training data. You just like put in the effort to exclude it. - If it's all associations all the way down, does that mean we should be less worried about super intelligence? 'Cause there's not this sense in which it's like Sherlock Holmes plus plus.</p><p>It'll still need to just like find these associations, like humans find associations and like, you know what I mean? It's not just like, it sees a frame of the world and it's like figured out all the laws of physics. - So for me, 'cause this is a very legitimate response, right?</p><p>It's like, well, artificial general intelligence aren't, if you say humans are generally intelligent, then they're no more capable or competent. I'm just worried that you have that level of general intelligence in Silicon, where you can then immediately clone hundreds of thousands of agents and they don't need to sleep and they can have super long context windows and then they can start recursively improving and then things get really scary.</p><p>So I think to answer your original question, yes, you're right. They would still need to learn associations, but-- - But the recursive self-improvement would still have to be them, like if intelligence is fundamentally about these associations, like the improvement is just them getting better at association. There's not like another thing that's happening.</p><p>And so then it seems like you might disagree with the intuition that, well, they can't be that much more powerful if they're just doing associations. - Well, I think then you can get into really interesting cases of meta-learning. Like when you play a new video game or like study a new textbook, you're bringing a whole bunch of skills to the table to form those associations much more quickly.</p><p>And like, because everything in some way ties back to the physical worlds, I think there are like general features that you can pick up and then apply in novel circumstances.</p></div></div></body></html>