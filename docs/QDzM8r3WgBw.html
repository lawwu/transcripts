<html><head><title>MIT 6.S094: Deep Reinforcement Learning for Motion Planning</title>
<style>
    body {
        font-family: Arial, sans-serif;
        margin: 0;
        padding: 0;
        background-color: #f4f4f4;
        color: #333;
    }
    .container {
        width: 80%;
        margin: auto;
        overflow: hidden;
    }
    h2, h3 {
        color: #333;
        text-align: center;
    }
    a {
        color: #0000FF;  /* Traditional blue color for links */
        text-decoration: none;
    }
    a:hover {
        text-decoration: underline;
    }
    img {
        display: block;
        margin: auto;
        max-width: 100%;
    }
    .c {
        margin: 10px 0;
    }
    .s, .t {
        display: inline-block;
        margin-right: 5px;
    }
    .max-width {
        max-width: 800px;
        margin: auto;
        padding-left: 20px;
    }
    table {
        width: 100%;
        border-collapse: collapse;
    }
    th, td {
        border: 1px solid #ddd;
        padding: 8px;
    }
    tr:nth-child(even) {
        background-color: #f2f2f2;
    }
    tr:nth-child(odd) {
        background-color: #e6e6e6;
    }
</style>

    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-69VLBMTTP0"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-69VLBMTTP0');
    </script>
    </head><body><div class='container'><a href="index.html">back to index</a><h2>MIT 6.S094: Deep Reinforcement Learning for Motion Planning</h2><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw"><img src="https://i.ytimg.com/vi_webp/QDzM8r3WgBw/maxresdefault.webp" style="width:50%;"></a><div><br></div><h3>Chapters</h3><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=0">0:0</a> Intro<br><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=43">0:43</a> Types of machine learning<br><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=348">5:48</a> Perceptron: Weighing the Evidence<br><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=454">7:34</a> Perceptron: Implement a NAND Gate<br><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=606">10:6</a> Perceptron NAND Gate<br><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=661">11:1</a> The Process of Learning Small Change in Weights â†’ Small Change in Output<br><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=782">13:2</a> Combining Neurons into Layers<br><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=829">13:49</a> Task: Classify and Image of a Number<br><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=1185">19:45</a> Philosophical Motivation for Reinforcement Learning<br><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=1280">21:20</a> Agent and Environment<br><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=1495">24:55</a> Markov Decision Process<br><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=1530">25:30</a> Major Components of an Rl Agent<br><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=1613">26:53</a> Robot in a Room<br><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=1677">27:57</a> Is this a solution?<br><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=1702">28:22</a> Optimal policy<br><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=1722">28:42</a> Reward for each step-2<br><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=1751">29:11</a> Reward for each step: +0.01<br><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=1815">30:15</a> Value Function<br><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=1879">31:19</a> Q Learning<br><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2103">35:3</a> Exploration vs Exploitation<br><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2167">36:7</a> Q-Learning: Value Iteration<br><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2283">38:3</a> Q-Learning: Representation Matters<br><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2748">45:48</a> Philosophical Motivation for Deep Reinforcement Learning<br><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2880">48:0</a> Deep Q-Network: Atari<br><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2964">49:24</a> Deep Q-Network Training<br><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3138">52:18</a> Atari Breakout<br><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3233">53:53</a> Deep Q-Learning Algorithm<br><br><div style="text-align: left;"><a href="./QDzM8r3WgBw.html">Whisper Transcript</a> | <a href="./transcript_QDzM8r3WgBw.html">Transcript Only Page</a></div><br><div style="max-width: 800px;"><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=0" target="_blank">00:00:00.000</a></span> | <span class="t">All right. Hello everybody. Welcome back. Glad you came back.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4" target="_blank">00:00:04.120</a></span> | <span class="t">Today, we will unveil the first tutorial, the first project.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=13" target="_blank">00:00:13.580</a></span> | <span class="t">This is Deep Traffic, code named Deep Traffic,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=17" target="_blank">00:00:17.220</a></span> | <span class="t">where your task is to solve the traffic problem using deep reinforcement learning.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=23" target="_blank">00:00:23.820</a></span> | <span class="t">And I'll talk about what's involved in designing a network there,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=29" target="_blank">00:00:29.760</a></span> | <span class="t">how you submit your own network,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=31" target="_blank">00:00:31.560</a></span> | <span class="t">and how you participate in the competition.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=33" target="_blank">00:00:33.900</a></span> | <span class="t">As I said, the winner gets a very special prize to be announced later.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=40" target="_blank">00:00:40.540</a></span> | <span class="t">What is machine learning?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=43" target="_blank">00:00:43.240</a></span> | <span class="t">There are several types.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=45" target="_blank">00:00:45.340</a></span> | <span class="t">There's supervised learning.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=47" target="_blank">00:00:47.100</a></span> | <span class="t">As I mentioned yesterday, that's what's meant usually when you discuss about,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=52" target="_blank">00:00:52.480</a></span> | <span class="t">you talk about machine learning and talk about its successes.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=56" target="_blank">00:00:56.320</a></span> | <span class="t">Supervised learning requires a data set where you know the ground truth.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=61" target="_blank">00:01:01.320</a></span> | <span class="t">You know the inputs and the outputs.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=63" target="_blank">00:01:03.860</a></span> | <span class="t">And you provide that to a machine learning algorithm in order to learn the mapping</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=71" target="_blank">00:01:11.840</a></span> | <span class="t">between the inputs and the outputs in such a way that you can generalize</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=75" target="_blank">00:01:15.140</a></span> | <span class="t">to further examples in the future.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=79" target="_blank">00:01:19.480</a></span> | <span class="t">Unsupervised learning is the other side,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=82" target="_blank">00:01:22.340</a></span> | <span class="t">when you know absolutely nothing about the outputs,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=88" target="_blank">00:01:28.120</a></span> | <span class="t">about the truth of the data that you're working with.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=91" target="_blank">00:01:31.860</a></span> | <span class="t">All you get is data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=93" target="_blank">00:01:33.220</a></span> | <span class="t">And you have to find underlying structure,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=97" target="_blank">00:01:37.760</a></span> | <span class="t">underlying representation of the data that's meaningful</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=101" target="_blank">00:01:41.600</a></span> | <span class="t">for you to accomplish a certain task, whatever that is.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=106" target="_blank">00:01:46.500</a></span> | <span class="t">There's semi-supervised data, where only parts, usually a very small amount, is labeled.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=114" target="_blank">00:01:54.940</a></span> | <span class="t">There's ground truth available for just a small fraction of it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=119" target="_blank">00:01:59.280</a></span> | <span class="t">If you think of images that are out there on the Internet,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=123" target="_blank">00:02:03.440</a></span> | <span class="t">and then you think about ImageNet, a data set where every image is labeled,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=128" target="_blank">00:02:08.080</a></span> | <span class="t">the size of that ImageNet data set is a tiny subset of all the images</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=136" target="_blank">00:02:16.100</a></span> | <span class="t">available online.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=138" target="_blank">00:02:18.500</a></span> | <span class="t">But that's the task we're dealing with as human beings,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=143" target="_blank">00:02:23.300</a></span> | <span class="t">as people interested in doing machine learning,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=145" target="_blank">00:02:25.700</a></span> | <span class="t">is how to expand the size of that,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=151" target="_blank">00:02:31.340</a></span> | <span class="t">of the part of our data that we know something confidently about.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=157" target="_blank">00:02:37.480</a></span> | <span class="t">And reinforcement learning sits somewhere in between.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=161" target="_blank">00:02:41.680</a></span> | <span class="t">It's semi-supervised learning.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=166" target="_blank">00:02:46.460</a></span> | <span class="t">Where there's an agent that has to exist in the world.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=172" target="_blank">00:02:52.660</a></span> | <span class="t">And that agent knows the inputs that the world provides,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=179" target="_blank">00:02:59.460</a></span> | <span class="t">but knows very little about that world except through occasional time-delayed rewards.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=188" target="_blank">00:03:08.480</a></span> | <span class="t">This is what it's like to be human.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=191" target="_blank">00:03:11.540</a></span> | <span class="t">This is what life is about.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=194" target="_blank">00:03:14.420</a></span> | <span class="t">You don't know what's good and bad.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=196" target="_blank">00:03:16.420</a></span> | <span class="t">You kind of have to just live it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=197" target="_blank">00:03:17.820</a></span> | <span class="t">And every once in a while, you find out that all that stuff you did last week was a pretty bad idea.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=205" target="_blank">00:03:25.360</a></span> | <span class="t">That's reinforcement learning.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=207" target="_blank">00:03:27.220</a></span> | <span class="t">That's semi-supervised in the sense that only a small subset of the data comes with some ground truth,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=215" target="_blank">00:03:35.500</a></span> | <span class="t">some certainty that you have to then extract knowledge from.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=221" target="_blank">00:03:41.200</a></span> | <span class="t">So first, at the core of anything that works currently,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=225" target="_blank">00:03:45.900</a></span> | <span class="t">in terms of a practical sense, there has to be some ground truth.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=230" target="_blank">00:03:50.900</a></span> | <span class="t">There has to be some truth that we can hold on to as we try to generalize.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=236" target="_blank">00:03:56.980</a></span> | <span class="t">And that's supervised learning.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=239" target="_blank">00:03:59.440</a></span> | <span class="t">Even as in reinforcement learning, the only thing we can count on is that truth</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=243" target="_blank">00:04:03.820</a></span> | <span class="t">that comes in a form of a reward.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=247" target="_blank">00:04:07.380</a></span> | <span class="t">So the standard supervised learning pipeline is you have some raw data, the inputs.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=253" target="_blank">00:04:13.340</a></span> | <span class="t">You have ground truth, the labels, the outputs that matches to the inputs.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=260" target="_blank">00:04:20.380</a></span> | <span class="t">Then you run a certain, any kind of algorithm, whether that's a neural network</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=266" target="_blank">00:04:26.360</a></span> | <span class="t">or another pre-processing, processing algorithm that extracts the features from that data set.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=272" target="_blank">00:04:32.660</a></span> | <span class="t">You can think of a picture of a face.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=274" target="_blank">00:04:34.460</a></span> | <span class="t">That algorithm could extract the nose, the eyes, the corners of the eyes, the pupil,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=281" target="_blank">00:04:41.500</a></span> | <span class="t">or even lower level features in that image.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=286" target="_blank">00:04:46.560</a></span> | <span class="t">After that, we insert those features into a model, a machine learning model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=296" target="_blank">00:04:56.040</a></span> | <span class="t">We train that model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=301" target="_blank">00:05:01.040</a></span> | <span class="t">Then we, as we, whatever that algorithm is, as we pass it through that training process,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=306" target="_blank">00:05:06.840</a></span> | <span class="t">we then evaluate.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=308" target="_blank">00:05:08.040</a></span> | <span class="t">After we've seen this one particular example, how much better are we at other tasks?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=316" target="_blank">00:05:16.840</a></span> | <span class="t">And as we repeat this loop, the model learns to perform better and better</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=323" target="_blank">00:05:23.720</a></span> | <span class="t">at generalizing from the raw data to the labels that we have.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=329" target="_blank">00:05:29.180</a></span> | <span class="t">And finally, you get to release that model into the wild to actually do prediction</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=334" target="_blank">00:05:34.580</a></span> | <span class="t">on data it has never seen before, that you don't know about.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=339" target="_blank">00:05:39.720</a></span> | <span class="t">And the task there is to predict the labels.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=348" target="_blank">00:05:48.020</a></span> | <span class="t">Okay, so neural networks is what this class is about.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=356" target="_blank">00:05:56.920</a></span> | <span class="t">It's one of the machine learning algorithms that has proven to be very successful.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=361" target="_blank">00:06:01.120</a></span> | <span class="t">And the building block, the computational building block of a neural network is a neuron.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=368" target="_blank">00:06:08.860</a></span> | <span class="t">A perceptron is a type of neuron.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=373" target="_blank">00:06:13.760</a></span> | <span class="t">It's the original old-school neuron where the output is binary, a zero or one.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=381" target="_blank">00:06:21.160</a></span> | <span class="t">It's not real valued.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=385" target="_blank">00:06:25.360</a></span> | <span class="t">And the process that a perceptron goes through is it has multiple inputs and a single output.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=395" target="_blank">00:06:35.120</a></span> | <span class="t">The inputs, each of the inputs have weights on them, shown here on the left as 0.7, 0.6, 1.4.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=405" target="_blank">00:06:45.160</a></span> | <span class="t">Those weights are applied to the inputs and a perceptron, the inputs are ones or zeros, binary.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=414" target="_blank">00:06:54.160</a></span> | <span class="t">And those weights are applied and then sum together.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=419" target="_blank">00:06:59.320</a></span> | <span class="t">A bias on each neuron is then added on top and a threshold.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=430" target="_blank">00:07:10.560</a></span> | <span class="t">There's a test whether that summed value plus the bias is below or above a threshold.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=437" target="_blank">00:07:17.060</a></span> | <span class="t">If it's above a threshold, it produces a one. If it's below a threshold, it produces a zero. Simple.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=443" target="_blank">00:07:23.760</a></span> | <span class="t">It's one of the only things we understand about neural networks confidently.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=448" target="_blank">00:07:28.260</a></span> | <span class="t">We can prove a lot of things about this neuron.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=450" target="_blank">00:07:30.860</a></span> | <span class="t">For example, what we know is that a neuron can approximate a NAND gate.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=464" target="_blank">00:07:44.960</a></span> | <span class="t">A NAND gate is a logical operation, a logical function that takes its input.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=474" target="_blank">00:07:54.060</a></span> | <span class="t">It has two inputs, A and B, here on the diagram on the left.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=479" target="_blank">00:07:59.660</a></span> | <span class="t">And the table shows what that function is.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=483" target="_blank">00:08:03.460</a></span> | <span class="t">When the inputs are zeros, 0, 1 in any order, the output is a one. Otherwise, it's a zero.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=494" target="_blank">00:08:14.260</a></span> | <span class="t">The cool thing about a NAND gate is that it's a universal gate.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=499" target="_blank">00:08:19.160</a></span> | <span class="t">That you can build up any computer you have.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=503" target="_blank">00:08:23.460</a></span> | <span class="t">Your phone in your pocket today can be built out of just NAND gates.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=507" target="_blank">00:08:27.960</a></span> | <span class="t">So it's functionally complete.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=511" target="_blank">00:08:31.360</a></span> | <span class="t">You can build any logical function out of them if you stack them together in arbitrary ways.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=516" target="_blank">00:08:36.560</a></span> | <span class="t">The problem with NAND gates and computers is they're built from the bottom up.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=523" target="_blank">00:08:43.360</a></span> | <span class="t">You have to design these circuits of NAND gates.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=525" target="_blank">00:08:45.360</a></span> | <span class="t">So the cool thing here is with the Perceptron, we can learn this magical NAND gate.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=533" target="_blank">00:08:53.260</a></span> | <span class="t">We can learn this function.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=534" target="_blank">00:08:54.660</a></span> | <span class="t">So let's go through how we can do that, how a Perceptron can perform the NAND operation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=545" target="_blank">00:09:05.260</a></span> | <span class="t">Here's the four examples.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=548" target="_blank">00:09:08.060</a></span> | <span class="t">If we put the weights of -2 on each of the inputs and a bias of 3 on the neuron,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=555" target="_blank">00:09:15.460</a></span> | <span class="t">and if we perform that same operation of summing the weights times the inputs plus the bias,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=564" target="_blank">00:09:24.860</a></span> | <span class="t">in the top left, we get, when the inputs are zeros and there's sum to the bias, we get a 3.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=575" target="_blank">00:09:35.460</a></span> | <span class="t">That's a positive number, which means the output of a Perceptron will be a 1.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=579" target="_blank">00:09:39.960</a></span> | <span class="t">In the top right, when the input is a 0 and a 1, that sum is still a positive number.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=587" target="_blank">00:09:47.660</a></span> | <span class="t">Again, produces a 1 and so on.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=591" target="_blank">00:09:51.160</a></span> | <span class="t">When the inputs are both 1s, then the output is a -1, less than 0.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=601" target="_blank">00:10:01.160</a></span> | <span class="t">So while this is simple, it's really important to think about.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=607" target="_blank">00:10:07.760</a></span> | <span class="t">It's a sort of the one basic computational truth you can hold on to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=616" target="_blank">00:10:16.960</a></span> | <span class="t">as we talk about some of the magical things neural network can do.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=619" target="_blank">00:10:19.860</a></span> | <span class="t">Because if you compare a circuit of NAND gates and a circuit of neurons,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=629" target="_blank">00:10:29.760</a></span> | <span class="t">the difference while a circuit of neurons, which is what we think of as a neural network,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=638" target="_blank">00:10:38.360</a></span> | <span class="t">can perform the same thing as the circuit of NAND gates.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=642" target="_blank">00:10:42.760</a></span> | <span class="t">What it can also do is it can learn.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=645" target="_blank">00:10:45.560</a></span> | <span class="t">It can learn the arbitrary logical functions that an arbitrary circuit of NAND gates can represent.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=654" target="_blank">00:10:54.460</a></span> | <span class="t">But it doesn't require the human designer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=658" target="_blank">00:10:58.960</a></span> | <span class="t">We can evolve, if you will.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=662" target="_blank">00:11:02.460</a></span> | <span class="t">So one of the key aspects here, one of the key drawbacks of Perceptron</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=671" target="_blank">00:11:11.460</a></span> | <span class="t">is it's not very smooth in its output.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=674" target="_blank">00:11:14.960</a></span> | <span class="t">As we change the weights on the inputs and we change the bias and we tweak it a little bit,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=683" target="_blank">00:11:23.860</a></span> | <span class="t">it's very likely that when you get, it's very easy to make the neuron output a 0 instead of a 1,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=692" target="_blank">00:11:32.960</a></span> | <span class="t">or 1 instead of a 0.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=694" target="_blank">00:11:34.360</a></span> | <span class="t">So when we start stacking many of these together, it's hard to control the output of the thing as a whole.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=704" target="_blank">00:11:44.860</a></span> | <span class="t">Now the essential step that makes a neural network work that a circuit of Perceptron doesn't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=714" target="_blank">00:11:54.160</a></span> | <span class="t">is if the output is made smooth, is made continuous with an activation function.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=720" target="_blank">00:12:00.360</a></span> | <span class="t">And so instead of using a step function like a Perceptron does, shown there on the left,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=730" target="_blank">00:12:10.760</a></span> | <span class="t">we use any kind of smooth function, sigmoid, where the output can change gradually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=740" target="_blank">00:12:20.960</a></span> | <span class="t">as you change the weights and the bias.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=744" target="_blank">00:12:24.960</a></span> | <span class="t">And this is a basic but critical step.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=753" target="_blank">00:12:33.260</a></span> | <span class="t">And so learning is generally the process of adjusting those weights gradually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=761" target="_blank">00:12:41.060</a></span> | <span class="t">and seeing how it has an effect on the rest of the network.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=765" target="_blank">00:12:45.360</a></span> | <span class="t">You just keep tweaking weights here and there and seeing how much closer you get to the ground truth.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=774" target="_blank">00:12:54.260</a></span> | <span class="t">And if you get farther away, you just adjust the weights in the opposite direction.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=781" target="_blank">00:13:01.360</a></span> | <span class="t">That's neural networks in a nutshell.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=783" target="_blank">00:13:03.260</a></span> | <span class="t">There is what we'll mostly talk about today is feed-forward neural networks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=791" target="_blank">00:13:11.060</a></span> | <span class="t">On the left, going from inputs to outputs with no loops.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=797" target="_blank">00:13:17.860</a></span> | <span class="t">There is also these amazing things called recurrent neural networks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=807" target="_blank">00:13:27.960</a></span> | <span class="t">They're amazing because they have memory. They have a memory of state.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=812" target="_blank">00:13:32.460</a></span> | <span class="t">They remember the temporal dynamics of the data that went through.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=818" target="_blank">00:13:38.360</a></span> | <span class="t">But the painful thing is that they're really hard to train.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=825" target="_blank">00:13:45.760</a></span> | <span class="t">Today we'll talk about feed-forward neural networks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=831" target="_blank">00:13:51.860</a></span> | <span class="t">So let's look at this example. An example of stacking a few of these neurons together.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=839" target="_blank">00:13:59.860</a></span> | <span class="t">Let's think of the task, the basic task now famous using the classification of numbers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=848" target="_blank">00:14:08.160</a></span> | <span class="t">You have an image of a number, handwritten number, and your task is given that image</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=855" target="_blank">00:14:15.160</a></span> | <span class="t">to say what number is in that image.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=861" target="_blank">00:14:21.660</a></span> | <span class="t">Now what is an image? An image is a collection of pixels. In this case, 28 by 28 pixels.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=866" target="_blank">00:14:26.960</a></span> | <span class="t">That's a total of 784 numbers. Those numbers are from 0 to 255.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=873" target="_blank">00:14:33.260</a></span> | <span class="t">And on the left of the network, the size of that input, despite the diagram, is 784 neurons.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=885" target="_blank">00:14:45.360</a></span> | <span class="t">That's the input. Then comes the hidden layer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=891" target="_blank">00:14:51.360</a></span> | <span class="t">It's called the hidden layer because it has no interaction with the input or the output.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=902" target="_blank">00:15:02.060</a></span> | <span class="t">It is simply a block used at the core of the computational power of neural networks, is the hidden layer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=914" target="_blank">00:15:14.860</a></span> | <span class="t">It's tasked with forming a representation of the data in such a way that it maps from the inputs to the outputs.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=923" target="_blank">00:15:23.160</a></span> | <span class="t">In this case, there is 15 neurons in the hidden layer. There is 10 values on the output</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=932" target="_blank">00:15:32.160</a></span> | <span class="t">corresponding to each of the numbers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=936" target="_blank">00:15:36.060</a></span> | <span class="t">There's several ways you can build this kind of network and this is what the magic of neural networks is.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=942" target="_blank">00:15:42.860</a></span> | <span class="t">You can do it a lot of ways. You only really need four outputs to represent values 0 through 9.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=948" target="_blank">00:15:48.860</a></span> | <span class="t">But in practice, it seems that having 10 outputs works better. And how do these work?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=955" target="_blank">00:15:55.560</a></span> | <span class="t">Whenever the input is a 5, the output neuron in charge of the 5 gets really excited</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=962" target="_blank">00:16:02.760</a></span> | <span class="t">and outputs a value that's close to 1, from 0 to 1.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=968" target="_blank">00:16:08.060</a></span> | <span class="t">Close to 1. And then the other ones get an output of value, hopefully, that's close to 0.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=975" target="_blank">00:16:15.460</a></span> | <span class="t">And when they don't, we adjust the weights in such a way that they get closer to 0 and closer to 1,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=982" target="_blank">00:16:22.960</a></span> | <span class="t">depending on whether it's the correct neuron associated with the picture.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=986" target="_blank">00:16:26.960</a></span> | <span class="t">We'll talk about the details of this training process more tomorrow when it's more relevant.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=995" target="_blank">00:16:35.660</a></span> | <span class="t">But what we've discussed just now is the forward pass through the network.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=1003" target="_blank">00:16:43.360</a></span> | <span class="t">It's the pass when you take the inputs, apply the weights, sum them together, add the bias,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=1010" target="_blank">00:16:50.160</a></span> | <span class="t">produce the output and check which of the outputs produces the highest confidence of the number.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=1015" target="_blank">00:16:55.860</a></span> | <span class="t">Then once those probabilities for each of the numbers is provided,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=1022" target="_blank">00:17:02.860</a></span> | <span class="t">we determine the gradient that's used to punish or reward the weights</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=1032" target="_blank">00:17:12.260</a></span> | <span class="t">that resulted in either the correct or the incorrect decisions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=1036" target="_blank">00:17:16.360</a></span> | <span class="t">And that's called back propagation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=1038" target="_blank">00:17:18.660</a></span> | <span class="t">We step backwards through the network applying those punishments or rewards.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=1043" target="_blank">00:17:23.160</a></span> | <span class="t">Because of the smoothness of the activation functions, that is a mathematically efficient operation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=1052" target="_blank">00:17:32.460</a></span> | <span class="t">That's where the GPUs step in.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=1054" target="_blank">00:17:34.860</a></span> | <span class="t">So far, example of numbers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=1058" target="_blank">00:17:38.360</a></span> | <span class="t">The ground truth for number 6 looks like the following in the slides.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=1067" target="_blank">00:17:47.560</a></span> | <span class="t">Y of X equals to a 10-dimensional vector, where only one of them, the 6th value is a 1, the rest are 0.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=1082" target="_blank">00:18:02.560</a></span> | <span class="t">That's the ground truth that comes with the image.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=1086" target="_blank">00:18:06.060</a></span> | <span class="t">The loss function here, the basic loss function is the squared error.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=1091" target="_blank">00:18:11.760</a></span> | <span class="t">Y of X is the ground truth and A is the output of the neural network resulting from the forward pass.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=1101" target="_blank">00:18:21.360</a></span> | <span class="t">So when you input that number of a 6 and it outputs whatever it outputs, that's A, a 10-dimensional vector.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=1111" target="_blank">00:18:31.260</a></span> | <span class="t">And it's summed over the inputs to produce the squared error.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=1115" target="_blank">00:18:35.960</a></span> | <span class="t">That's our loss function.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=1118" target="_blank">00:18:38.160</a></span> | <span class="t">The loss function, the objective function, that's what's used to determine</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=1123" target="_blank">00:18:43.960</a></span> | <span class="t">how much to reward or punish the back propagated weights throughout the network.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=1130" target="_blank">00:18:50.260</a></span> | <span class="t">And the basic operation of optimizing that loss function, of minimizing that loss function</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=1140" target="_blank">00:19:00.660</a></span> | <span class="t">is done with various variants of gradient descent.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=1144" target="_blank">00:19:04.260</a></span> | <span class="t">It's hopefully a somewhat smooth function, but it's a highly nonlinear function.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=1151" target="_blank">00:19:11.960</a></span> | <span class="t">This is why we can't prove much about neural networks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=1155" target="_blank">00:19:15.360</a></span> | <span class="t">It's a highly high-dimensional, highly nonlinear function that's hopefully smooth enough</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=1163" target="_blank">00:19:23.660</a></span> | <span class="t">where the gradient descent can find its way to at least a good solution.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=1170" target="_blank">00:19:30.860</a></span> | <span class="t">And there has to be some stochastic element there that jumps around</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=1179" target="_blank">00:19:39.060</a></span> | <span class="t">to ensure that it doesn't get stuck in a local minima of this very complex function.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=1185" target="_blank">00:19:45.060</a></span> | <span class="t">Okay, that's supervised learning.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=1187" target="_blank">00:19:47.860</a></span> | <span class="t">There's inputs, there's outputs, ground truth.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=1192" target="_blank">00:19:52.260</a></span> | <span class="t">That's our comfort zone.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=1193" target="_blank">00:19:53.360</a></span> | <span class="t">Because we're pretty confident, we know what's going on.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=1195" target="_blank">00:19:55.960</a></span> | <span class="t">All you have to do is just, you have this data set, you train and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=1199" target="_blank">00:19:59.660</a></span> | <span class="t">you train a network on that data set and you can evaluate it, you can write a paper</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=1205" target="_blank">00:20:05.260</a></span> | <span class="t">and try to beat a previous paper, it's great.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=1207" target="_blank">00:20:07.760</a></span> | <span class="t">The problem is when you then use that neural network to create an intelligent system</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=1215" target="_blank">00:20:15.160</a></span> | <span class="t">that you put out there in the world.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=1216" target="_blank">00:20:16.860</a></span> | <span class="t">And now that system no longer is working with your data set.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=1222" target="_blank">00:20:22.560</a></span> | <span class="t">It has to exist in this world that's maybe very different from the ground truth.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=1229" target="_blank">00:20:29.560</a></span> | <span class="t">So the takeaway from supervised learning is that neural networks are great memorization.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=1236" target="_blank">00:20:36.060</a></span> | <span class="t">But in a sort of philosophical way, they might not be great at generalizing,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=1241" target="_blank">00:20:41.460</a></span> | <span class="t">at reasoning beyond the specific flavor of data set that they were trained on.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=1249" target="_blank">00:20:49.260</a></span> | <span class="t">The hope for reinforcement learning is that we can extend the knowledge we gain in a supervised way</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=1256" target="_blank">00:20:56.960</a></span> | <span class="t">to the huge world outside where we don't have the ground truth of how to act,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=1268" target="_blank">00:21:08.160</a></span> | <span class="t">of what does, how good a certain state is or how bad a certain state is.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=1273" target="_blank">00:21:13.660</a></span> | <span class="t">This is a kind of brute force reasoning.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=1276" target="_blank">00:21:16.760</a></span> | <span class="t">And I'll talk about kind of what I mean there.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=1280" target="_blank">00:21:20.360</a></span> | <span class="t">But it feels like it's closer to reasoning as opposed to memorization.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=1284" target="_blank">00:21:24.560</a></span> | <span class="t">That's a good way to think of supervised learning is memorization.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=1288" target="_blank">00:21:28.360</a></span> | <span class="t">You're just studying for an exam.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=1290" target="_blank">00:21:30.660</a></span> | <span class="t">And as many of you know, that doesn't mean you're going to be successful in life</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=1295" target="_blank">00:21:35.660</a></span> | <span class="t">just because you get an A.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=1296" target="_blank">00:21:36.760</a></span> | <span class="t">And so a reinforcement learning agent or just any agent,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=1306" target="_blank">00:21:46.560</a></span> | <span class="t">a human being or any machine existing in this world</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=1311" target="_blank">00:21:51.960</a></span> | <span class="t">can operate in the following way from the perspective of the agent.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=1317" target="_blank">00:21:57.960</a></span> | <span class="t">It can execute an action, it can receive an observation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=1322" target="_blank">00:22:02.060</a></span> | <span class="t">resulting from that action in a form of a new state</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=1327" target="_blank">00:22:07.560</a></span> | <span class="t">and it can receive a reward or a punishment.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=1331" target="_blank">00:22:11.660</a></span> | <span class="t">You can break down our existence in this way, simplistic view.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=1338" target="_blank">00:22:18.360</a></span> | <span class="t">But it's a convenient one on the computational side.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=1343" target="_blank">00:22:23.460</a></span> | <span class="t">And from the environment side, the environment receives the action,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=1348" target="_blank">00:22:28.860</a></span> | <span class="t">emits the observation, so your action changes the world,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=1353" target="_blank">00:22:33.560</a></span> | <span class="t">therefore that world has to change.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=1357" target="_blank">00:22:37.960</a></span> | <span class="t">And then tell you about it and give you a reward or punishment for it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=1362" target="_blank">00:22:42.760</a></span> | <span class="t">So let's look at, again, one of the most fascinating things.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=1374" target="_blank">00:22:54.560</a></span> | <span class="t">I'll try to convey why this is fascinating a little bit later on.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=1378" target="_blank">00:22:58.760</a></span> | <span class="t">Is the work of DeepMind on Atari.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=1386" target="_blank">00:23:06.160</a></span> | <span class="t">This is Atari Breakout, a game where a paddle has to move around.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=1393" target="_blank">00:23:13.660</a></span> | <span class="t">That's the world that's existing in.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=1395" target="_blank">00:23:15.960</a></span> | <span class="t">It's a paddle, the agent is a paddle and there's a bouncing ball</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=1401" target="_blank">00:23:21.460</a></span> | <span class="t">and you're trying to move your actions to the right, move right, move left.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=1405" target="_blank">00:23:25.960</a></span> | <span class="t">You're trying to move in such a way that the ball doesn't get past you.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=1410" target="_blank">00:23:30.860</a></span> | <span class="t">And so here is a human level performance of that agent.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=1416" target="_blank">00:23:36.660</a></span> | <span class="t">And so what does this paddle have to do?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=1418" target="_blank">00:23:38.260</a></span> | <span class="t">It has to operate in this environment.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=1420" target="_blank">00:23:40.060</a></span> | <span class="t">It has to act, move left, move right.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=1422" target="_blank">00:23:42.260</a></span> | <span class="t">Each action changes the state of the world.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=1427" target="_blank">00:23:47.060</a></span> | <span class="t">This may seem obvious but moving right changes visually the state of the world.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=1434" target="_blank">00:23:54.860</a></span> | <span class="t">In fact, what we're watching now on the slides is the world changing before your eyes for this little guy.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=1443" target="_blank">00:24:03.160</a></span> | <span class="t">And it gets rewards or punishments.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=1446" target="_blank">00:24:06.860</a></span> | <span class="t">Rewards it gets in the form of points.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=1450" target="_blank">00:24:10.160</a></span> | <span class="t">They're racking up points in the top left of the video.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=1454" target="_blank">00:24:14.860</a></span> | <span class="t">And then when the ball gets past the paddle, it gets punished by dying, quote-unquote.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=1462" target="_blank">00:24:22.660</a></span> | <span class="t">And that's the number of lives it has left, going from five to four to three, down to zero.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=1470" target="_blank">00:24:30.860</a></span> | <span class="t">And so the goal is to select at any one moment the action that maximizes future reward.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=1478" target="_blank">00:24:38.660</a></span> | <span class="t">Without any knowledge of what a reward is, in a greater sense of the word,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=1485" target="_blank">00:24:45.260</a></span> | <span class="t">all you have is an instantaneous reward or punishment, instantaneous response of the world to your actions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=1491" target="_blank">00:24:51.660</a></span> | <span class="t">And this can be modeled as a Markov decision process.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=1501" target="_blank">00:25:01.160</a></span> | <span class="t">Markov decision process is a mathematically convenient construct.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=1506" target="_blank">00:25:06.460</a></span> | <span class="t">It has no memory. All you get is you have a state that you're currently in,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=1512" target="_blank">00:25:12.460</a></span> | <span class="t">you perform an action, you get a reward and you find yourself in a new state.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=1516" target="_blank">00:25:16.860</a></span> | <span class="t">And that repeats over and over.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=1518" target="_blank">00:25:18.860</a></span> | <span class="t">You start from state zero, you go to state one, you once again repeat an action, get a reward, go to the next state.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=1527" target="_blank">00:25:27.860</a></span> | <span class="t">Okay, that's the formulation that we're operating in.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=1530" target="_blank">00:25:30.060</a></span> | <span class="t">When you're in a certain state, you have no memory of what happened two states ago.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=1535" target="_blank">00:25:35.960</a></span> | <span class="t">Everything is operating on the instantaneous, instantaneously.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=1543" target="_blank">00:25:43.360</a></span> | <span class="t">And so what are the major components of a reinforcement learning agent?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=1547" target="_blank">00:25:47.260</a></span> | <span class="t">There's a policy. That's the agent, the function broadly defined of an agent's behavior.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=1556" target="_blank">00:25:56.960</a></span> | <span class="t">That includes the knowledge of how for any given state, what is an action that I will take with some probability.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=1569" target="_blank">00:26:09.560</a></span> | <span class="t">Value function is how good each state and action are in any particular state.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=1580" target="_blank">00:26:20.960</a></span> | <span class="t">And there's a model. Now this is a little, a subtle thing that is actually the biggest problem with everything you'll see today.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=1591" target="_blank">00:26:31.560</a></span> | <span class="t">Is the model is how we represent the environment.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=1595" target="_blank">00:26:35.260</a></span> | <span class="t">And what you'll see today is some amazing things that neural networks can achieve</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=1599" target="_blank">00:26:39.760</a></span> | <span class="t">on a relatively simplistic model of the world.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=1603" target="_blank">00:26:43.360</a></span> | <span class="t">And the question whether that model can extend to the real world</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=1607" target="_blank">00:26:47.260</a></span> | <span class="t">where human lives are at stake in the case of driving.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=1610" target="_blank">00:26:50.260</a></span> | <span class="t">Yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=1610" target="_blank">00:26:50.760</a></span> | <span class="t">So let's look at the simplistic world. A robot in a room.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=1618" target="_blank">00:26:58.660</a></span> | <span class="t">You start at the bottom left. Your goal is to get to the top right.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=1624" target="_blank">00:27:04.260</a></span> | <span class="t">Your possible actions are going up, down, left and right.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=1630" target="_blank">00:27:10.560</a></span> | <span class="t">Now this world can be deterministic, which means when you go up, you actually go up.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=1639" target="_blank">00:27:19.560</a></span> | <span class="t">Or it could be non-deterministic as human life is.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=1644" target="_blank">00:27:24.960</a></span> | <span class="t">It's when you go up, sometimes you go right.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=1648" target="_blank">00:27:28.160</a></span> | <span class="t">So in this case, if you choose to go up, you move up 80% of the time.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=1654" target="_blank">00:27:34.660</a></span> | <span class="t">You move left 10% of the time and you move right 10% of the time.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=1658" target="_blank">00:27:38.560</a></span> | <span class="t">And when you get to the top right, you get a reward of +1.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=1664" target="_blank">00:27:44.060</a></span> | <span class="t">When you get to the second block from that, 4, 2, you get -1. You get punished.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=1669" target="_blank">00:27:49.660</a></span> | <span class="t">And every time you take a step, you get a slight punishment of 0.04.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=1674" target="_blank">00:27:54.760</a></span> | <span class="t">Okay, so the question is, if you start at the bottom left, is this a good solution?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=1683" target="_blank">00:28:03.060</a></span> | <span class="t">Is this a good policy by which you exist in the world?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=1686" target="_blank">00:28:06.660</a></span> | <span class="t">And it is if the world is deterministic.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=1690" target="_blank">00:28:10.860</a></span> | <span class="t">If whenever you choose to go up, you go up.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=1695" target="_blank">00:28:15.260</a></span> | <span class="t">Whenever you choose to go right, you go right.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=1697" target="_blank">00:28:17.960</a></span> | <span class="t">But if the actions are stochastic, that's not the case.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=1705" target="_blank">00:28:25.460</a></span> | <span class="t">In what I described previously with 0.8 up and probability of 0.1 going left and right,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=1716" target="_blank">00:28:36.160</a></span> | <span class="t">this is the optimal policy.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=1722" target="_blank">00:28:42.560</a></span> | <span class="t">Now, if we punish every single step with a -2 as opposed to -0.04.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=1728" target="_blank">00:28:48.960</a></span> | <span class="t">So, every time you take a step, it hurts.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=1732" target="_blank">00:28:52.760</a></span> | <span class="t">You're going to try to get to a positive block as quickly as possible.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=1739" target="_blank">00:28:59.360</a></span> | <span class="t">And that's what this policy says.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=1743" target="_blank">00:29:03.160</a></span> | <span class="t">I'll walk through a -1 if I have to, as long as I stop getting a -2.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=1751" target="_blank">00:29:11.860</a></span> | <span class="t">Now, if the reward for each step is -0.1,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=1755" target="_blank">00:29:15.060</a></span> | <span class="t">you might choose to go around that -1 block.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=1759" target="_blank">00:29:19.460</a></span> | <span class="t">Slight detour to avoid the pain.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=1763" target="_blank">00:29:23.360</a></span> | <span class="t">And then you might take an even longer detour as the reward for each step goes up</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=1771" target="_blank">00:29:31.560</a></span> | <span class="t">or the punishment goes down, I guess.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=1779" target="_blank">00:29:39.360</a></span> | <span class="t">And then if there's an actual positive reward for every step you take,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=1791" target="_blank">00:29:51.160</a></span> | <span class="t">then you'll avoid going to the finish line.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=1797" target="_blank">00:29:57.060</a></span> | <span class="t">You'll just wander the world.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=1800" target="_blank">00:30:00.060</a></span> | <span class="t">We saw that with the coast racer yesterday.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=1806" target="_blank">00:30:06.460</a></span> | <span class="t">The boat that chose not to finish the race</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=1810" target="_blank">00:30:10.360</a></span> | <span class="t">because it was having too much fun getting points in the middle.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=1813" target="_blank">00:30:13.560</a></span> | <span class="t">So, let's look at the world that this agent is operating in.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=1822" target="_blank">00:30:22.460</a></span> | <span class="t">It's a value function.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=1824" target="_blank">00:30:24.560</a></span> | <span class="t">That value function depends on a reward.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=1828" target="_blank">00:30:28.060</a></span> | <span class="t">The word that comes in the future.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=1831" target="_blank">00:30:31.160</a></span> | <span class="t">And that reward is discounted because the world is stochastic.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=1836" target="_blank">00:30:36.160</a></span> | <span class="t">We can't expect the reward to come along to us in the way that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=1843" target="_blank">00:30:43.160</a></span> | <span class="t">we hope it does based on the policy, based on the way we choose to act.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=1848" target="_blank">00:30:48.060</a></span> | <span class="t">And so there's a gamma there that over time,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=1852" target="_blank">00:30:52.560</a></span> | <span class="t">as the reward is farther and farther into the future,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=1857" target="_blank">00:30:57.060</a></span> | <span class="t">discounts that reward, diminishes the impact of that future award</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=1865" target="_blank">00:31:05.260</a></span> | <span class="t">in your evaluation of the current state.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=1867" target="_blank">00:31:07.660</a></span> | <span class="t">And so your goal is to develop a strategy that maximizes</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=1873" target="_blank">00:31:13.460</a></span> | <span class="t">the discounted future reward, the sum, this discounted sum.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=1878" target="_blank">00:31:18.760</a></span> | <span class="t">And reinforcement learning,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=1885" target="_blank">00:31:25.060</a></span> | <span class="t">there is a lot of approaches for coming up with a good policy,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=1890" target="_blank">00:31:30.160</a></span> | <span class="t">a near optimal, an optimal policy.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=1893" target="_blank">00:31:33.860</a></span> | <span class="t">There's a lot of fun math there.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=1897" target="_blank">00:31:37.560</a></span> | <span class="t">You can try to construct a model that optimizes some estimate of this world.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=1905" target="_blank">00:31:45.860</a></span> | <span class="t">You can try in a Monte Carlo way to just simulate that world</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=1912" target="_blank">00:31:52.860</a></span> | <span class="t">and see how it unrolls.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=1914" target="_blank">00:31:54.460</a></span> | <span class="t">And as it unrolls, you try to compute the optimal policy.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=1919" target="_blank">00:31:59.460</a></span> | <span class="t">Or what we'll talk about today is Q-learning.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=1923" target="_blank">00:32:03.960</a></span> | <span class="t">It's an off-policy approach where the policy is estimated as we go along.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=1935" target="_blank">00:32:15.460</a></span> | <span class="t">The policy is represented as a Q-function.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=1942" target="_blank">00:32:22.560</a></span> | <span class="t">The Q-function shown there on the left is,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=1947" target="_blank">00:32:27.660</a></span> | <span class="t">I apologize for the equations, I lied.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=1951" target="_blank">00:32:31.160</a></span> | <span class="t">There'll be some equations.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=1953" target="_blank">00:32:33.560</a></span> | <span class="t">The input to the Q-function is a state at time t, s, t,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=1962" target="_blank">00:32:42.660</a></span> | <span class="t">and an action that you choose to take in that state, a, t.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=1968" target="_blank">00:32:48.960</a></span> | <span class="t">And your goal is in that state to choose an action which maximizes the reward in the next step.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=1975" target="_blank">00:32:55.560</a></span> | <span class="t">And what Q-learning does, and I'll describe the process,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=1981" target="_blank">00:33:01.260</a></span> | <span class="t">is it's able to approximate through experience the optimal Q-function.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=1988" target="_blank">00:33:08.460</a></span> | <span class="t">The optimal function that tells you how to act in any state of the world.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=1996" target="_blank">00:33:16.960</a></span> | <span class="t">You just have to live it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=1999" target="_blank">00:33:19.560</a></span> | <span class="t">You have to simulate this world.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2001" target="_blank">00:33:21.560</a></span> | <span class="t">You have to move about it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2003" target="_blank">00:33:23.260</a></span> | <span class="t">You have to explore in order to see every possible state,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2008" target="_blank">00:33:28.060</a></span> | <span class="t">try every different action, get rewarded, get punished,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2011" target="_blank">00:33:31.860</a></span> | <span class="t">and figure out what is the optimal thing to do.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2016" target="_blank">00:33:36.260</a></span> | <span class="t">That's done using this Bellman equation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2023" target="_blank">00:33:43.460</a></span> | <span class="t">On the left, the output is the new state, the estimate,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2028" target="_blank">00:33:48.460</a></span> | <span class="t">the Q-function estimate of the new state for new action.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2032" target="_blank">00:33:52.860</a></span> | <span class="t">And this is the update rule at the core of Q-learning.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2038" target="_blank">00:33:58.060</a></span> | <span class="t">You take the old estimate and add based on the learning rate,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2048" target="_blank">00:34:08.360</a></span> | <span class="t">alpha from 0 to 1, update the evaluation of that state</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2055" target="_blank">00:34:15.860</a></span> | <span class="t">based on your new reward that you received at that time.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2061" target="_blank">00:34:21.360</a></span> | <span class="t">So you've arrived in a certain state, s, t, you try to do an action</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2068" target="_blank">00:34:28.560</a></span> | <span class="t">and then you got a certain reward and you update your estimate of that state</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2073" target="_blank">00:34:33.360</a></span> | <span class="t">and action pair based on this rule.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2077" target="_blank">00:34:37.860</a></span> | <span class="t">When the learning rate is 0, you don't learn.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2081" target="_blank">00:34:41.960</a></span> | <span class="t">When alpha is 0, you never change your worldview based on the new incoming evidence.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2090" target="_blank">00:34:50.660</a></span> | <span class="t">When alpha is 1, you every time change your evaluation,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2100" target="_blank">00:35:00.160</a></span> | <span class="t">your world evaluation based on the new evidence.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2104" target="_blank">00:35:04.760</a></span> | <span class="t">And that's the key ingredient to reinforcement learning.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2108" target="_blank">00:35:08.060</a></span> | <span class="t">First you explore, then you exploit.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2111" target="_blank">00:35:11.460</a></span> | <span class="t">First you explore in a non-greedy way and then you get greedy.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2115" target="_blank">00:35:15.660</a></span> | <span class="t">You figure out what's good for you and you keep doing it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2118" target="_blank">00:35:18.160</a></span> | <span class="t">So if you want to learn an Atari game, first you try every single action, every state,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2124" target="_blank">00:35:24.360</a></span> | <span class="t">you screw up, get punished, get rewarded and eventually you figure out</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2128" target="_blank">00:35:28.160</a></span> | <span class="t">what's actually the right thing to do and you just keep doing it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2130" target="_blank">00:35:30.760</a></span> | <span class="t">And that's how you win against the greatest human players in the world</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2136" target="_blank">00:35:36.960</a></span> | <span class="t">in a game of Go, for example, as we'll talk about.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2139" target="_blank">00:35:39.760</a></span> | <span class="t">And the way you do that is you have an epsilon greedy policy</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2144" target="_blank">00:35:44.960</a></span> | <span class="t">that over time with a probability of 1-epsilon, you perform an optimal greedy action.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2152" target="_blank">00:35:52.960</a></span> | <span class="t">With a probability of epsilon, you perform a random action.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2155" target="_blank">00:35:55.860</a></span> | <span class="t">Random action being explore.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2160" target="_blank">00:36:00.260</a></span> | <span class="t">And so as epsilon goes down from 1 to 0, you explore less and less.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2165" target="_blank">00:36:05.560</a></span> | <span class="t">So the algorithm here is really simple on the bottom of the slide there.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2173" target="_blank">00:36:13.460</a></span> | <span class="t">It's the algorithm version, the pseudocode version of the equation,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2179" target="_blank">00:36:19.760</a></span> | <span class="t">the Bellman equation update.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2183" target="_blank">00:36:23.160</a></span> | <span class="t">You initialize your estimate of state action pairs arbitrarily, a random number.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2190" target="_blank">00:36:30.360</a></span> | <span class="t">Now this is an important point.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2192" target="_blank">00:36:32.360</a></span> | <span class="t">When you start playing or living or doing whatever you're doing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2198" target="_blank">00:36:38.360</a></span> | <span class="t">and whatever you're doing with reinforcement learning or driving,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2201" target="_blank">00:36:41.460</a></span> | <span class="t">you have no preconceived notion of what's good and bad.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2207" target="_blank">00:36:47.560</a></span> | <span class="t">It's random or however you choose to initialize it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2211" target="_blank">00:36:51.760</a></span> | <span class="t">And the fact that it learns anything is amazing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2214" target="_blank">00:36:54.860</a></span> | <span class="t">I want you to remember that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2218" target="_blank">00:36:58.260</a></span> | <span class="t">That's one of the amazing things about the Q-learning at all</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2225" target="_blank">00:37:05.760</a></span> | <span class="t">and then the deep neural network version of Q-learning.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2229" target="_blank">00:37:09.460</a></span> | <span class="t">The algorithm repeats the following step.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2234" target="_blank">00:37:14.360</a></span> | <span class="t">You step into the world, observe an initial state.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2238" target="_blank">00:37:18.760</a></span> | <span class="t">You select an action A.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2241" target="_blank">00:37:21.960</a></span> | <span class="t">So that action, if you're exploring, will be a random action.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2245" target="_blank">00:37:25.660</a></span> | <span class="t">If you're greedily pursuing the best action you can,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2248" target="_blank">00:37:28.760</a></span> | <span class="t">it will be the action that maximizes the Q function.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2251" target="_blank">00:37:31.460</a></span> | <span class="t">You observe or reward after you take the action</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2254" target="_blank">00:37:34.660</a></span> | <span class="t">and a new state that you find yourself in.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2257" target="_blank">00:37:37.760</a></span> | <span class="t">And then you update your estimate of the previous state you were in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2261" target="_blank">00:37:41.860</a></span> | <span class="t">having taken that action using that Bellman equation update.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2265" target="_blank">00:37:45.460</a></span> | <span class="t">And repeat this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2268" target="_blank">00:37:48.760</a></span> | <span class="t">Over and over.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2269" target="_blank">00:37:49.460</a></span> | <span class="t">And so there on the bottom of the slide is a summary of life.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2279" target="_blank">00:37:59.460</a></span> | <span class="t">Yes.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2285" target="_blank">00:38:05.360</a></span> | <span class="t">The Q function?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2290" target="_blank">00:38:10.060</a></span> | <span class="t">Yes.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2292" target="_blank">00:38:12.960</a></span> | <span class="t">Yes.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2294" target="_blank">00:38:14.060</a></span> | <span class="t">Yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2294" target="_blank">00:38:14.460</a></span> | <span class="t">It's a single.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2296" target="_blank">00:38:16.160</a></span> | <span class="t">The question was, is the Q function a single value?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2299" target="_blank">00:38:19.160</a></span> | <span class="t">And yes, it's just a single continuous value.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2303" target="_blank">00:38:23.460</a></span> | <span class="t">So the question was, how do you model the world?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2317" target="_blank">00:38:37.060</a></span> | <span class="t">So the way you model, so let's start this very simplistic world</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2325" target="_blank">00:38:45.960</a></span> | <span class="t">of Atari paddle.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2327" target="_blank">00:38:47.960</a></span> | <span class="t">You model it as a paddle that can move left and right</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2331" target="_blank">00:38:51.460</a></span> | <span class="t">and there's some blocks and you model the physics of the ball.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2336" target="_blank">00:38:56.160</a></span> | <span class="t">That requires a lot of expert knowledge in that particular game.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2341" target="_blank">00:39:01.960</a></span> | <span class="t">So you sit there hand crafting this model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2344" target="_blank">00:39:04.760</a></span> | <span class="t">That's hard to do even for a simplistic game.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2347" target="_blank">00:39:07.660</a></span> | <span class="t">The other model you could take is looking at this world</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2354" target="_blank">00:39:14.460</a></span> | <span class="t">in the way that humans do visually.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2356" target="_blank">00:39:16.160</a></span> | <span class="t">So take the model in as a set of pixels.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2359" target="_blank">00:39:19.460</a></span> | <span class="t">Just the model is all the pixels of the world.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2365" target="_blank">00:39:25.360</a></span> | <span class="t">You know nothing about paddles or balls or physics or colors and points.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2371" target="_blank">00:39:31.460</a></span> | <span class="t">They're just pixels coming in.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2372" target="_blank">00:39:32.860</a></span> | <span class="t">That seems like a ridiculous model of the world</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2376" target="_blank">00:39:36.260</a></span> | <span class="t">but it seems to work for Atari.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2378" target="_blank">00:39:38.060</a></span> | <span class="t">It seems to work for human beings.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2380" target="_blank">00:39:40.260</a></span> | <span class="t">When you're born, you see there's light coming into your eyes</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2384" target="_blank">00:39:44.460</a></span> | <span class="t">and you don't have any, as far as we know,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2392" target="_blank">00:39:52.260</a></span> | <span class="t">you don't come with an instruction when you're born.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2395" target="_blank">00:39:55.160</a></span> | <span class="t">You know there's people in the world and there is good guys and bad guys</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2400" target="_blank">00:40:00.960</a></span> | <span class="t">and there's this is how you walk.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2402" target="_blank">00:40:02.260</a></span> | <span class="t">No, all you get is light, sound and the other sensors.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2408" target="_blank">00:40:08.160</a></span> | <span class="t">And you get to learn about every single thing you think of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2417" target="_blank">00:40:17.060</a></span> | <span class="t">as the way you model the world is a learned representation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2421" target="_blank">00:40:21.160</a></span> | <span class="t">And we'll talk about how a neural network does that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2423" target="_blank">00:40:23.760</a></span> | <span class="t">It learns to represent the world.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2426" target="_blank">00:40:26.160</a></span> | <span class="t">But if we have to hand model the world, it's an impossible task.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2433" target="_blank">00:40:33.260</a></span> | <span class="t">That's the question.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2436" target="_blank">00:40:36.060</a></span> | <span class="t">If we have to hand model the world, then that world better be a simplistic one.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2441" target="_blank">00:40:41.260</a></span> | <span class="t">That's a great question.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2445" target="_blank">00:40:45.260</a></span> | <span class="t">So the question was, what is the robustness of this model?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2448" target="_blank">00:40:48.360</a></span> | <span class="t">If the way you represent the world is at all even slightly different</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2453" target="_blank">00:40:53.260</a></span> | <span class="t">from the way you thought that world is,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2455" target="_blank">00:40:55.960</a></span> | <span class="t">that's not that well studied as far as I'm aware.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2460" target="_blank">00:41:00.060</a></span> | <span class="t">I mean it's already amazing that if you construct,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2463" target="_blank">00:41:03.460</a></span> | <span class="t">if you have a certain input of the world,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2465" target="_blank">00:41:05.760</a></span> | <span class="t">if you have a certain model of the world,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2467" target="_blank">00:41:07.160</a></span> | <span class="t">you can learn anything, it's already amazing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2468" target="_blank">00:41:08.660</a></span> | <span class="t">The question is, and it's an important one,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2471" target="_blank">00:41:11.760</a></span> | <span class="t">is we'll talk a little bit about it,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2474" target="_blank">00:41:14.760</a></span> | <span class="t">not about the world model but the reward function.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2477" target="_blank">00:41:17.560</a></span> | <span class="t">If the reward function is slightly different,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2479" target="_blank">00:41:19.760</a></span> | <span class="t">the real reward function of life or driving or of coast runner</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2485" target="_blank">00:41:25.760</a></span> | <span class="t">is different than what you expected it to be.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2488" target="_blank">00:41:28.860</a></span> | <span class="t">What's the negative there?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2491" target="_blank">00:41:31.060</a></span> | <span class="t">Yeah, it could be huge.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2494" target="_blank">00:41:34.260</a></span> | <span class="t">So, there's another question or no?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2497" target="_blank">00:41:37.760</a></span> | <span class="t">Never mind. Yep.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2499" target="_blank">00:41:39.260</a></span> | <span class="t">Sorry, can you ask that again?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2502" target="_blank">00:41:42.360</a></span> | <span class="t">Yes, you can change it over.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2507" target="_blank">00:41:47.060</a></span> | <span class="t">So the question was, do you change the alpha value over time?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2510" target="_blank">00:41:50.660</a></span> | <span class="t">And you certainly should change the alpha value over time.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2520" target="_blank">00:42:00.360</a></span> | <span class="t">So the question was, what is the complex interplay of the epsilon function</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2524" target="_blank">00:42:04.860</a></span> | <span class="t">with the Q-learning update?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2526" target="_blank">00:42:06.160</a></span> | <span class="t">That's 100% fine-tuned, hand-tuned to the particular learning problem.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2532" target="_blank">00:42:12.560</a></span> | <span class="t">So you certainly want to,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2536" target="_blank">00:42:16.960</a></span> | <span class="t">the more complex, the larger the number of states in the world</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2544" target="_blank">00:42:24.960</a></span> | <span class="t">and the larger the number of actions,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2547" target="_blank">00:42:27.260</a></span> | <span class="t">the longer you have to wait before you decrease the epsilon to zero.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2552" target="_blank">00:42:32.660</a></span> | <span class="t">But you have to play with it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2554" target="_blank">00:42:34.260</a></span> | <span class="t">It's one of the parameters you have to play with, unfortunately,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2557" target="_blank">00:42:37.660</a></span> | <span class="t">and there's quite a few of them,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2558" target="_blank">00:42:38.860</a></span> | <span class="t">which is why you can't just drop a reinforcement learning agent into the world.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2562" target="_blank">00:42:42.960</a></span> | <span class="t">Oh, the effect in that sense.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2568" target="_blank">00:42:48.460</a></span> | <span class="t">No, no, it's just a coin flip.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2570" target="_blank">00:42:50.160</a></span> | <span class="t">And if that epsilon is 0.5,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2573" target="_blank">00:42:53.960</a></span> | <span class="t">half the time you're going to take a random action.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2576" target="_blank">00:42:56.860</a></span> | <span class="t">So it's no, there's no specific,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2578" target="_blank">00:42:58.960</a></span> | <span class="t">it's not like you'll take the best action</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2581" target="_blank">00:43:01.960</a></span> | <span class="t">and then with some probability take the second best and so on.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2585" target="_blank">00:43:05.160</a></span> | <span class="t">I mean, you could certainly do that,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2586" target="_blank">00:43:06.460</a></span> | <span class="t">but in the simple formulation that works,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2589" target="_blank">00:43:09.360</a></span> | <span class="t">is you just take a random action</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2591" target="_blank">00:43:11.060</a></span> | <span class="t">because you don't want to have a preconceived notion of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2593" target="_blank">00:43:13.260</a></span> | <span class="t">what's a good action to try when you're exploring.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2596" target="_blank">00:43:16.260</a></span> | <span class="t">The whole point is you try crazy stuff, if it's a simulation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2600" target="_blank">00:43:20.460</a></span> | <span class="t">So, good question.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2606" target="_blank">00:43:26.560</a></span> | <span class="t">So, representation matters.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2608" target="_blank">00:43:28.160</a></span> | <span class="t">This is the question about how we represent the world.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2612" target="_blank">00:43:32.160</a></span> | <span class="t">So we can think of this world of breakout, for example,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2617" target="_blank">00:43:37.460</a></span> | <span class="t">of this Atari game as a paddle that moves left and right</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2623" target="_blank">00:43:43.560</a></span> | <span class="t">and the exact position of the different things it can hit,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2627" target="_blank">00:43:47.160</a></span> | <span class="t">construct this complex model,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2628" target="_blank">00:43:48.960</a></span> | <span class="t">this expert driven model that has to fine tune it to this particular problem.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2634" target="_blank">00:43:54.460</a></span> | <span class="t">But in practice, the more complex this model gets,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2642" target="_blank">00:44:02.360</a></span> | <span class="t">the worse that Bellman equation update,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2645" target="_blank">00:44:05.860</a></span> | <span class="t">that trying to construct the Q function</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2648" target="_blank">00:44:08.760</a></span> | <span class="t">for every single combination of state and actions</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2651" target="_blank">00:44:11.660</a></span> | <span class="t">becomes too difficult because that function is too sparse and huge.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2656" target="_blank">00:44:16.760</a></span> | <span class="t">So if you think of looking at this world in a general way,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2663" target="_blank">00:44:23.260</a></span> | <span class="t">in the way human beings would,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2664" target="_blank">00:44:24.460</a></span> | <span class="t">is a collection of pixels visually.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2666" target="_blank">00:44:26.960</a></span> | <span class="t">If you just take in a pixel,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2669" target="_blank">00:44:29.560</a></span> | <span class="t">this game is a collection of 84 by 84 pixels, an image, RGB image.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2675" target="_blank">00:44:35.160</a></span> | <span class="t">And then you look at not just the current image,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2680" target="_blank">00:44:40.860</a></span> | <span class="t">but look at the temporal trajectory of those images.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2685" target="_blank">00:44:45.960</a></span> | <span class="t">So like if there's a ball moving, you want to know about that movement.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2689" target="_blank">00:44:49.160</a></span> | <span class="t">So you look at four images.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2692" target="_blank">00:44:52.060</a></span> | <span class="t">So current image and three images back.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2694" target="_blank">00:44:54.060</a></span> | <span class="t">And say they're grayscale with 256 gray levels.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2700" target="_blank">00:45:00.560</a></span> | <span class="t">That size of the Q table that the Q value function has to learn</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2708" target="_blank">00:45:08.360</a></span> | <span class="t">is whatever that number is,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2712" target="_blank">00:45:12.560</a></span> | <span class="t">but it's certainly larger than the number of atoms in the universe.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2715" target="_blank">00:45:15.860</a></span> | <span class="t">That's a large number.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2719" target="_blank">00:45:19.660</a></span> | <span class="t">So you have to run the simulation long enough</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2723" target="_blank">00:45:23.260</a></span> | <span class="t">to touch at least a few times most of the states in that Q table.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2730" target="_blank">00:45:30.260</a></span> | <span class="t">So as Elon Musk says,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2734" target="_blank">00:45:34.360</a></span> | <span class="t">"You may need to run," you know, "we live in a simulation."</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2738" target="_blank">00:45:38.260</a></span> | <span class="t">You may have to run a universe just to compute the Q function in this case.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2749" target="_blank">00:45:49.360</a></span> | <span class="t">So that's where deep learning steps in.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2751" target="_blank">00:45:51.160</a></span> | <span class="t">Instead of modeling the world as a Q table,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2758" target="_blank">00:45:58.360</a></span> | <span class="t">you estimate, you try to learn that function.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2764" target="_blank">00:46:04.160</a></span> | <span class="t">And so the takeaway from supervised learning, if you remember,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2769" target="_blank">00:46:09.760</a></span> | <span class="t">that it's good at memorizing or good at memorizing data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2772" target="_blank">00:46:12.560</a></span> | <span class="t">The hope for reinforcement learning with a Q learning</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2779" target="_blank">00:46:19.560</a></span> | <span class="t">is that we can extend the occasional rewards we get</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2784" target="_blank">00:46:24.360</a></span> | <span class="t">to generalize over the operation,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2787" target="_blank">00:46:27.160</a></span> | <span class="t">the actions you take in that world leading up to the rewards.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2790" target="_blank">00:46:30.760</a></span> | <span class="t">And the hope for deep learning is that we can move this reinforcement learning system</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2798" target="_blank">00:46:38.260</a></span> | <span class="t">into a world that doesn't need to be,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2801" target="_blank">00:46:41.360</a></span> | <span class="t">that can be defined arbitrarily,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2803" target="_blank">00:46:43.360</a></span> | <span class="t">can include all the pixels of an Atari game,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2808" target="_blank">00:46:48.560</a></span> | <span class="t">can include all the pixels sensed by a drone or a robot or a car.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2812" target="_blank">00:46:52.460</a></span> | <span class="t">But still it needs a formalized definition of that world,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2819" target="_blank">00:46:59.160</a></span> | <span class="t">which is much easier to do when you're able to take in sensors like an image.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2825" target="_blank">00:47:05.960</a></span> | <span class="t">So deep Q learning, deep version.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2829" target="_blank">00:47:09.760</a></span> | <span class="t">So instead of learning a Q table, a Q function,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2836" target="_blank">00:47:16.460</a></span> | <span class="t">we try in estimating that Q prime,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2840" target="_blank">00:47:20.760</a></span> | <span class="t">we try to learn it using machine learning.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2844" target="_blank">00:47:24.460</a></span> | <span class="t">So it tries to learn some parameters.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2847" target="_blank">00:47:27.560</a></span> | <span class="t">This huge complex function, we try to learn it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2853" target="_blank">00:47:33.460</a></span> | <span class="t">And the way we do that is we have a neural network,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2859" target="_blank">00:47:39.260</a></span> | <span class="t">the same kind that I showed that learned the numbers to map from an image</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2862" target="_blank">00:47:42.960</a></span> | <span class="t">to a classification of that image into a number.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2867" target="_blank">00:47:47.060</a></span> | <span class="t">The same kind of network is used to take in a state and action and produce a Q value.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2874" target="_blank">00:47:54.560</a></span> | <span class="t">Now here's the amazing thing,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2878" target="_blank">00:47:58.660</a></span> | <span class="t">that without knowing anything in the beginning,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2886" target="_blank">00:48:06.060</a></span> | <span class="t">as I said with a Q table, it's initialized randomly.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2892" target="_blank">00:48:12.460</a></span> | <span class="t">The Q function, this deep network knows nothing in the beginning.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2897" target="_blank">00:48:17.560</a></span> | <span class="t">All it knows is in the simulated world, the rewards you get for a particular game.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2906" target="_blank">00:48:26.060</a></span> | <span class="t">So you have to play time and time again and see</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2909" target="_blank">00:48:29.560</a></span> | <span class="t">the rewards you get for every single iteration of the game.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2915" target="_blank">00:48:35.660</a></span> | <span class="t">But in the beginning it knows nothing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2920" target="_blank">00:48:40.060</a></span> | <span class="t">And it's able to learn to play better than human beings.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2924" target="_blank">00:48:44.460</a></span> | <span class="t">This is a DeepMind paper playing Atari with deep reinforcement learning from 2013.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2932" target="_blank">00:48:52.160</a></span> | <span class="t">There's one of the key things that got everybody excited about the role of deep learning</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2938" target="_blank">00:48:58.160</a></span> | <span class="t">and artificial intelligence.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2939" target="_blank">00:48:59.360</a></span> | <span class="t">Is that using a convolutional neural network, which I'll talk about tomorrow,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2947" target="_blank">00:49:07.160</a></span> | <span class="t">but it's a vanilla network like any other, like I talked about earlier today.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2951" target="_blank">00:49:11.160</a></span> | <span class="t">Just a regular network that takes the raw pixels, as I said,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2955" target="_blank">00:49:15.760</a></span> | <span class="t">and estimates that Q function from the raw pixels</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2959" target="_blank">00:49:19.260</a></span> | <span class="t">and is able to play on many of those games better than a human being.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2962" target="_blank">00:49:22.860</a></span> | <span class="t">And the loss function that I mentioned previously.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2967" target="_blank">00:49:27.860</a></span> | <span class="t">So again, very vanilla loss function, very simple objective function.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2976" target="_blank">00:49:36.960</a></span> | <span class="t">The first one you'll probably implement.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2978" target="_blank">00:49:38.860</a></span> | <span class="t">We have a tutorial in TensorFlow.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2980" target="_blank">00:49:40.860</a></span> | <span class="t">Squared error.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2983" target="_blank">00:49:43.460</a></span> | <span class="t">So we take this Bellman equation where the estimate is Q,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2988" target="_blank">00:49:48.560</a></span> | <span class="t">the Q function estimate of state and action is the maximum reward you get</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=2995" target="_blank">00:49:55.860</a></span> | <span class="t">for taking any of the actions that takes you to any of the future states.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3003" target="_blank">00:50:03.260</a></span> | <span class="t">And you try to take that action, observe the result of that action,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3009" target="_blank">00:50:09.460</a></span> | <span class="t">and if the target is different that your learned target,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3014" target="_blank">00:50:14.960</a></span> | <span class="t">what the function has learned is the expected reward in that case,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3019" target="_blank">00:50:19.360</a></span> | <span class="t">is different than what you actually got, you adjust it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3023" target="_blank">00:50:23.760</a></span> | <span class="t">You adjust the weights in the network.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3028" target="_blank">00:50:28.560</a></span> | <span class="t">And this is exactly the process by which we learn how to exist in this pixel world.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3035" target="_blank">00:50:35.360</a></span> | <span class="t">So you're mapping states and actions to a Q value.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3042" target="_blank">00:50:42.260</a></span> | <span class="t">The algorithm is as follows.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3046" target="_blank">00:50:46.060</a></span> | <span class="t">This is how we train it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3048" target="_blank">00:50:48.160</a></span> | <span class="t">We're given a transition, S, current state, action taken in that state,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3055" target="_blank">00:50:55.060</a></span> | <span class="t">R, the reward you get, and S' is the state you find yourself in.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3059" target="_blank">00:50:59.360</a></span> | <span class="t">And so we replace the basic update rule in the previous pseudocode</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3066" target="_blank">00:51:06.460</a></span> | <span class="t">by taking a forward pass through the network, given that S state.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3074" target="_blank">00:51:14.860</a></span> | <span class="t">We look at what the predicted Q value is of that action.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3080" target="_blank">00:51:20.660</a></span> | <span class="t">We then do another forward pass through that network.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3085" target="_blank">00:51:25.160</a></span> | <span class="t">And see what we actually get.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3086" target="_blank">00:51:26.960</a></span> | <span class="t">And then if we're totally off, we punish, we back propagate the weights</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3097" target="_blank">00:51:37.160</a></span> | <span class="t">in a way that next time we'll make less of that mistake.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3101" target="_blank">00:51:41.960</a></span> | <span class="t">And you repeat this process.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3104" target="_blank">00:51:44.660</a></span> | <span class="t">And this is a simulation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3111" target="_blank">00:51:51.360</a></span> | <span class="t">You're learning against yourself.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3115" target="_blank">00:51:55.060</a></span> | <span class="t">And again, the same rule applies here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3120" target="_blank">00:52:00.560</a></span> | <span class="t">Exploration versus exploitation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3122" target="_blank">00:52:02.260</a></span> | <span class="t">You start out with an epsilon of 0 or 1.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3128" target="_blank">00:52:08.960</a></span> | <span class="t">You're mostly exploring and then you move towards an epsilon of 0.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3137" target="_blank">00:52:17.460</a></span> | <span class="t">And with Atari breakout, this is the DeepMind paper result.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3144" target="_blank">00:52:24.260</a></span> | <span class="t">It's training epochs on the X axis.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3146" target="_blank">00:52:26.360</a></span> | <span class="t">On the Y axis is the average action value and the average reward per episode.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3151" target="_blank">00:52:31.560</a></span> | <span class="t">I'll show why it's kind of an amazing result, but it's messy.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3157" target="_blank">00:52:37.260</a></span> | <span class="t">Because there's a lot of tricks involved.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3160" target="_blank">00:52:40.060</a></span> | <span class="t">So it's not just putting in a bunch of pixels of a game</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3164" target="_blank">00:52:44.560</a></span> | <span class="t">and getting an agent that knows how to win at that game.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3168" target="_blank">00:52:48.160</a></span> | <span class="t">There's a lot of pre-processing and playing with the data required.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3173" target="_blank">00:52:53.360</a></span> | <span class="t">So which is unfortunate because the truth is messier than the hope.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3179" target="_blank">00:52:59.760</a></span> | <span class="t">But one of the critical tricks needed is called experience replay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3185" target="_blank">00:53:05.960</a></span> | <span class="t">So as opposed to letting an agent, so you're learning this big network</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3192" target="_blank">00:53:12.560</a></span> | <span class="t">that tries to build a model of what's good to do in the world and what's not.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3197" target="_blank">00:53:17.460</a></span> | <span class="t">And you're learning as you go.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3201" target="_blank">00:53:21.560</a></span> | <span class="t">So with experience replay, you're keeping a track of all the things you did.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3206" target="_blank">00:53:26.260</a></span> | <span class="t">And every once in a while, you look back into your memory</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3209" target="_blank">00:53:29.660</a></span> | <span class="t">and pull out some of those old experiences, the good old times, and train on those again.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3214" target="_blank">00:53:34.960</a></span> | <span class="t">As opposed to letting the agent run itself into some local optima</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3221" target="_blank">00:53:41.960</a></span> | <span class="t">where it tries to learn a very subtle aspect of the game</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3224" target="_blank">00:53:44.760</a></span> | <span class="t">that actually in the global sense doesn't get you farther to winning the game.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3230" target="_blank">00:53:50.360</a></span> | <span class="t">Very much like life.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3232" target="_blank">00:53:52.260</a></span> | <span class="t">So here's the algorithm, deep Q learning algorithm, pseudocode.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3237" target="_blank">00:53:57.960</a></span> | <span class="t">We initialize the replay memory.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3241" target="_blank">00:54:01.860</a></span> | <span class="t">Again, there's this little trick that's required.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3245" target="_blank">00:54:05.260</a></span> | <span class="t">It's keeping a track of stuff that's happened in the past.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3248" target="_blank">00:54:08.860</a></span> | <span class="t">We initialize the action value function Q with random weights</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3253" target="_blank">00:54:13.260</a></span> | <span class="t">and observe initial state.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3255" target="_blank">00:54:15.660</a></span> | <span class="t">Again, same thing, select an action with a probability epsilon, explore.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3261" target="_blank">00:54:21.760</a></span> | <span class="t">Otherwise, choose the best one based on the estimate provided by the neural network.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3267" target="_blank">00:54:27.560</a></span> | <span class="t">And then carry out the action, observe the reward and store that experience in the replay memory.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3274" target="_blank">00:54:34.160</a></span> | <span class="t">And then sample random transition from replay memory.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3281" target="_blank">00:54:41.860</a></span> | <span class="t">So with a certain probability, you bring those old times back to get yourself out of the local minima.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3288" target="_blank">00:54:48.960</a></span> | <span class="t">And then you train the Q network using the difference between what you actually got and your estimate.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3301" target="_blank">00:55:01.060</a></span> | <span class="t">You repeat this process over and over.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3304" target="_blank">00:55:04.160</a></span> | <span class="t">So here's what you can do.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3308" target="_blank">00:55:08.160</a></span> | <span class="t">After 10 minutes of training on the left, so that's very little training,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3314" target="_blank">00:55:14.060</a></span> | <span class="t">what you get is a paddle that learns hardly anything and it just keeps dying.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3322" target="_blank">00:55:22.360</a></span> | <span class="t">If you look at, it goes from 5 to 4 to 3 to 2 to 1, those are the number of lives left.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3328" target="_blank">00:55:28.360</a></span> | <span class="t">Then after two hours of training on a single GPU, it learns to win, you know, not die,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3338" target="_blank">00:55:38.160</a></span> | <span class="t">rack up points and learns to avoid the ball from passing the paddle, which is great.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3348" target="_blank">00:55:48.260</a></span> | <span class="t">That's human level performance really, better than some humans, you know,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3353" target="_blank">00:55:53.560</a></span> | <span class="t">but it still dies sometimes so it's very human level.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3358" target="_blank">00:55:58.060</a></span> | <span class="t">And then after four hours, it does something really amazing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3363" target="_blank">00:56:03.560</a></span> | <span class="t">It figures out how to win at the game in a very lazy way, which is drill a hole through the blocks</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3375" target="_blank">00:56:15.060</a></span> | <span class="t">up to the top and get the ball stuck up there and then it does all the hard work for you.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3379" target="_blank">00:56:19.960</a></span> | <span class="t">That minimizes the probability of the ball getting past your paddle because it's just stuck in the blocks up top.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3388" target="_blank">00:56:28.560</a></span> | <span class="t">So that might be something that you wouldn't even figure out to do yourself.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3392" target="_blank">00:56:32.260</a></span> | <span class="t">And that's an... I need to sort of pause here to clearly explain what's happening.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3400" target="_blank">00:56:40.560</a></span> | <span class="t">The input to this algorithm is just the pixels of the game.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3406" target="_blank">00:56:46.660</a></span> | <span class="t">It's the same thing that human beings take in when they take the visual perception</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3413" target="_blank">00:56:53.060</a></span> | <span class="t">and it's able to learn under this constrained definition of what is a reward and a punishment.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3420" target="_blank">00:57:00.360</a></span> | <span class="t">It's able to learn to get a high reward.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3423" target="_blank">00:57:03.860</a></span> | <span class="t">That's general artificial intelligence.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3430" target="_blank">00:57:10.060</a></span> | <span class="t">A very small example of it but it's general.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3433" target="_blank">00:57:13.760</a></span> | <span class="t">It's general purpose. It knows nothing about games.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3437" target="_blank">00:57:17.460</a></span> | <span class="t">It knows nothing about paddles or physics. It's just taking sensory input of the game.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3443" target="_blank">00:57:23.160</a></span> | <span class="t">And they've did the same thing for a bunch of different games in Atari.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3447" target="_blank">00:57:27.760</a></span> | <span class="t">And what's shown here in this plot on the X-axis is a bunch of different games from Atari</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3458" target="_blank">00:57:38.460</a></span> | <span class="t">and on the Y-axis is a percentile where 100% is about the best that human beings can do.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3466" target="_blank">00:57:46.660</a></span> | <span class="t">Meaning it's the score that human beings would get.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3468" target="_blank">00:57:48.560</a></span> | <span class="t">So everything about there in the middle, everything to the left of that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3472" target="_blank">00:57:52.360</a></span> | <span class="t">is far exceeding human level performance</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3474" target="_blank">00:57:54.860</a></span> | <span class="t">and below that is on par or worse than human level performance.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3479" target="_blank">00:57:59.460</a></span> | <span class="t">So it can learn all, so many boxing, pinball, all of these games</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3486" target="_blank">00:58:06.660</a></span> | <span class="t">and it doesn't know anything about any of the individual games.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3489" target="_blank">00:58:09.760</a></span> | <span class="t">It's just taking in pixels.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3491" target="_blank">00:58:11.160</a></span> | <span class="t">It's just as if you put a human being behind any of these games</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3496" target="_blank">00:58:16.960</a></span> | <span class="t">and ask them to learn to beat the game.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3503" target="_blank">00:58:23.260</a></span> | <span class="t">And there's been a lot of improvements in this algorithm recently.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3508" target="_blank">00:58:28.460</a></span> | <span class="t">Yes, question.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3509" target="_blank">00:58:29.260</a></span> | <span class="t">(inaudible)</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3511" target="_blank">00:58:31.960</a></span> | <span class="t">No, no.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3512" target="_blank">00:58:32.960</a></span> | <span class="t">There's no...</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3514" target="_blank">00:58:34.260</a></span> | <span class="t">So the question was, do they customize the model for a particular game?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3518" target="_blank">00:58:38.260</a></span> | <span class="t">And no. The point, you could of course,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3521" target="_blank">00:58:41.560</a></span> | <span class="t">but the point is it doesn't need to be customized for the game.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3525" target="_blank">00:58:45.060</a></span> | <span class="t">But the important thing is that it's still only on Atari games.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3534" target="_blank">00:58:54.060</a></span> | <span class="t">Right, so the question whether this is transferable to driving.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3538" target="_blank">00:58:58.060</a></span> | <span class="t">Perhaps not.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3539" target="_blank">00:58:59.960</a></span> | <span class="t">Right, you play the game. Well you do.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3552" target="_blank">00:59:12.660</a></span> | <span class="t">No, you don't have the... Well yeah, you play one step of the game.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3555" target="_blank">00:59:15.960</a></span> | <span class="t">So you take action in a state and then you observe that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3563" target="_blank">00:59:23.960</a></span> | <span class="t">So you have the simulation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3566" target="_blank">00:59:26.660</a></span> | <span class="t">I mean that's really, that's one of the biggest problems here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3571" target="_blank">00:59:31.860</a></span> | <span class="t">is you require the simulation in order to get the ground truth.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3576" target="_blank">00:59:36.660</a></span> | <span class="t">(inaudible)</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3582" target="_blank">00:59:42.060</a></span> | <span class="t">So that's a great question or comment.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3585" target="_blank">00:59:45.960</a></span> | <span class="t">The comment was that for a lot of these situations,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3589" target="_blank">00:59:49.760</a></span> | <span class="t">the reward function might not change at all depending on your actions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3594" target="_blank">00:59:54.060</a></span> | <span class="t">The rewards are really, most of the time, delayed 10, 20, 30 steps down the line.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3602" target="_blank">01:00:02.860</a></span> | <span class="t">Which is why it is amazing that this works at all.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3608" target="_blank">01:00:08.260</a></span> | <span class="t">That it's learning locally and through that process of simulation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3615" target="_blank">01:00:15.760</a></span> | <span class="t">of hundreds of thousands of times it runs through the game,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3617" target="_blank">01:00:17.960</a></span> | <span class="t">it's able to learn what to do now such that I get a reward later.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3624" target="_blank">01:00:24.260</a></span> | <span class="t">If you just pause, look at the math of it, it's very simple math,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3632" target="_blank">01:00:32.160</a></span> | <span class="t">and look at the result, it's incredible.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3638" target="_blank">01:00:38.060</a></span> | <span class="t">So there's a lot of improvements.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3639" target="_blank">01:00:39.460</a></span> | <span class="t">This one called the General Reinforcement Learning Architecture or GORILLA.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3645" target="_blank">01:00:45.460</a></span> | <span class="t">The cool thing about this in the simulated world at least</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3650" target="_blank">01:00:50.860</a></span> | <span class="t">is that you can run deep reinforcement learning in distributed way.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3656" target="_blank">01:00:56.160</a></span> | <span class="t">You could do both the simulation in distributed way,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3658" target="_blank">01:00:58.660</a></span> | <span class="t">you could do the learning in the distributed way.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3660" target="_blank">01:01:00.960</a></span> | <span class="t">You can generate experiences which is what this kind of diagram shows.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3667" target="_blank">01:01:07.560</a></span> | <span class="t">You can either from human beings or from simulation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3672" target="_blank">01:01:12.060</a></span> | <span class="t">So for example, the way that AlphaGo, the DeepMind team has beat the game of Go</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3681" target="_blank">01:01:21.160</a></span> | <span class="t">is they learn from both expert games and by playing itself.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3686" target="_blank">01:01:26.360</a></span> | <span class="t">So you can do this in a distributed way</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3689" target="_blank">01:01:29.760</a></span> | <span class="t">and you could do the learning in distributed way so you can scale.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3693" target="_blank">01:01:33.360</a></span> | <span class="t">And in this particular case, the GORILLA has achieved a better result than the DQN network.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3701" target="_blank">01:01:41.960</a></span> | <span class="t">That's part of their nature paper.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3705" target="_blank">01:01:45.360</a></span> | <span class="t">Okay, so let me now get to driving for a second here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3713" target="_blank">01:01:53.460</a></span> | <span class="t">Where does reinforcement learning,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3719" target="_blank">01:01:59.860</a></span> | <span class="t">where reinforcement learning can step in and help?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3723" target="_blank">01:02:03.560</a></span> | <span class="t">So this is back to the open question that I asked yesterday.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3727" target="_blank">01:02:07.160</a></span> | <span class="t">Is driving closer to chess or to everyday conversation?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3731" target="_blank">01:02:11.460</a></span> | <span class="t">Chess meaning it can be formalized in a simplistic way</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3736" target="_blank">01:02:16.560</a></span> | <span class="t">and we could think about it as an obstacle avoidance problem</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3740" target="_blank">01:02:20.260</a></span> | <span class="t">and once the obstacle avoidance is solved,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3742" target="_blank">01:02:22.860</a></span> | <span class="t">you just navigate that constrained space.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3747" target="_blank">01:02:27.060</a></span> | <span class="t">You choose to move left, you choose to move right in a lane,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3750" target="_blank">01:02:30.560</a></span> | <span class="t">you choose to speed up or slow down.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3752" target="_blank">01:02:32.860</a></span> | <span class="t">Well, if it's a game like chess, which we'll assume for today</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3758" target="_blank">01:02:38.660</a></span> | <span class="t">as opposed to for tomorrow, for today we're going to go with the one on the left</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3765" target="_blank">01:02:45.460</a></span> | <span class="t">and we're going to look at deep traffic.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3771" target="_blank">01:02:51.660</a></span> | <span class="t">Here's this game, a simulation, where the goal is to achieve the highest average speed you can</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3781" target="_blank">01:03:01.160</a></span> | <span class="t">on this seven lane highway full of cars.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3787" target="_blank">01:03:07.060</a></span> | <span class="t">And so, as a side note for students, the requirement is they have to follow the tutorial</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3794" target="_blank">01:03:14.060</a></span> | <span class="t">that I'll present a link for at the end of this presentation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3798" target="_blank">01:03:18.760</a></span> | <span class="t">And what they have to do is achieve a speed,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3801" target="_blank">01:03:21.860</a></span> | <span class="t">build a network that achieves a speed of 65 miles an hour or higher.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3806" target="_blank">01:03:26.060</a></span> | <span class="t">There is a leaderboard and you get to submit the model you come up with</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3813" target="_blank">01:03:33.660</a></span> | <span class="t">with a simple click of a button.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3815" target="_blank">01:03:35.160</a></span> | <span class="t">So all of this runs in the browser, which is also another amazing thing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3818" target="_blank">01:03:38.860</a></span> | <span class="t">And then you immediately or relatively so, make your way up the leaderboard.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3826" target="_blank">01:03:46.160</a></span> | <span class="t">So let's look, let's zoom in.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3830" target="_blank">01:03:50.860</a></span> | <span class="t">What is this world, two-dimensional world of traffic is?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3836" target="_blank">01:03:56.260</a></span> | <span class="t">What does it look like for the intelligence system?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3841" target="_blank">01:04:01.260</a></span> | <span class="t">We discretize that world into a grid shown here on the left.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3846" target="_blank">01:04:06.960</a></span> | <span class="t">That's the representation of the state.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3848" target="_blank">01:04:08.560</a></span> | <span class="t">There are seven lanes and every single lane is broken up into blocks spatially.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3854" target="_blank">01:04:14.460</a></span> | <span class="t">And if there's a car in that block, the length of a car is about three blocks,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3858" target="_blank">01:04:18.260</a></span> | <span class="t">three of those grid blocks, then that grid is seen as occupied.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3865" target="_blank">01:04:25.560</a></span> | <span class="t">And then the red car is you.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3870" target="_blank">01:04:30.360</a></span> | <span class="t">That's the thing that's running in the intelligent agent.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3873" target="_blank">01:04:33.860</a></span> | <span class="t">There is on the left is the current speed of the red car.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3880" target="_blank">01:04:40.760</a></span> | <span class="t">It actually says MIT on top.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3882" target="_blank">01:04:42.360</a></span> | <span class="t">And then you also have a count of how many cars you passed.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3887" target="_blank">01:04:47.760</a></span> | <span class="t">And if your network sucks, then that number is going to get to be negative.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3894" target="_blank">01:04:54.160</a></span> | <span class="t">You can also change with a drop down the simulation speed</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3901" target="_blank">01:05:01.160</a></span> | <span class="t">from normal on the left to fast on the right.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3905" target="_blank">01:05:05.060</a></span> | <span class="t">So normal is, so you know, the fast speeds up the replay of the simulation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3914" target="_blank">01:05:14.260</a></span> | <span class="t">The one on the left, normal, it feels a little more like real driving.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3920" target="_blank">01:05:20.160</a></span> | <span class="t">There's a drop down for different display options.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3928" target="_blank">01:05:28.860</a></span> | <span class="t">The default is none in terms of stuff you show on the road.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3933" target="_blank">01:05:33.960</a></span> | <span class="t">Then there is the learning input, which is the, while the whole space is discretized,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3939" target="_blank">01:05:39.860</a></span> | <span class="t">you can choose what your car sees.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3944" target="_blank">01:05:44.060</a></span> | <span class="t">And that's, you can choose how far ahead it sees, behind, how far to the left and right it sees.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3952" target="_blank">01:05:52.060</a></span> | <span class="t">And so by choosing the learning input, to visualize learning input,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3956" target="_blank">01:05:56.860</a></span> | <span class="t">you get to see what you set that input to be.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3959" target="_blank">01:05:59.060</a></span> | <span class="t">Then there is the safety system.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3964" target="_blank">01:06:04.160</a></span> | <span class="t">This is a system that protects you from yourself.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3967" target="_blank">01:06:07.460</a></span> | <span class="t">The way we've made this game is that it operates under something similar.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3975" target="_blank">01:06:15.860</a></span> | <span class="t">If you have some intelligence, if you drive and you have adaptive cruise control in your car,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3982" target="_blank">01:06:22.960</a></span> | <span class="t">it operates in the same way.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3984" target="_blank">01:06:24.960</a></span> | <span class="t">When it gets close to the car in front, it slows down for you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3989" target="_blank">01:06:29.760</a></span> | <span class="t">and it doesn't let you run the car to the left of you, to the right of you, off the road.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=3995" target="_blank">01:06:35.460</a></span> | <span class="t">So it constrains the movement capabilities of your car in such a way that you don't hit anybody</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4004" target="_blank">01:06:44.160</a></span> | <span class="t">because then it would have to simulate collisions and it would just be a mess.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4008" target="_blank">01:06:48.060</a></span> | <span class="t">So it protects you from that and so you can choose to visualize that "safety system" with the visualization box.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4018" target="_blank">01:06:58.860</a></span> | <span class="t">And then you can also choose to visualize the full map.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4021" target="_blank">01:07:01.360</a></span> | <span class="t">This is the full occupancy map that you get, if you would like to, provide as input to the network.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4029" target="_blank">01:07:09.560</a></span> | <span class="t">Now that input for every single grid, it's a number.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4034" target="_blank">01:07:14.860</a></span> | <span class="t">It's not just a zero one whether there's a car in there.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4037" target="_blank">01:07:17.860</a></span> | <span class="t">It's the maximum speed limit, which is 80 miles per hour.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4044" target="_blank">01:07:24.060</a></span> | <span class="t">Don't get crazy. 80 miles an hour is the speed limit.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4049" target="_blank">01:07:29.260</a></span> | <span class="t">That block, when it's empty, is set to the 80 miles an hour.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4054" target="_blank">01:07:34.560</a></span> | <span class="t">And when it's occupied, it's set to the number that's the speed of the car.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4060" target="_blank">01:07:40.960</a></span> | <span class="t">And then the blocks that the red car is occupying,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4066" target="_blank">01:07:46.360</a></span> | <span class="t">is set to a very large number, much higher than the speed limit.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4077" target="_blank">01:07:57.860</a></span> | <span class="t">So safety system, here shown in red, are the parts of the grid that your car can't move into.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4087" target="_blank">01:08:07.960</a></span> | <span class="t">Question?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4088" target="_blank">01:08:08.660</a></span> | <span class="t">What's that?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4092" target="_blank">01:08:12.660</a></span> | <span class="t">Yes.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4099" target="_blank">01:08:19.060</a></span> | <span class="t">Yes. The question was, what was the third option I just mentioned?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4104" target="_blank">01:08:24.460</a></span> | <span class="t">And it's the red car itself.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4107" target="_blank">01:08:27.660</a></span> | <span class="t">You yourself, the blocks underneath that car, are set to a really high number.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4112" target="_blank">01:08:32.660</a></span> | <span class="t">It's a way for the algorithm to know, for the learning algorithm to know, that these blocks are special.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4119" target="_blank">01:08:39.760</a></span> | <span class="t">So safety system shows red here if the car can't move into those blocks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4132" target="_blank">01:08:52.660</a></span> | <span class="t">So any, in terms of, when it lights up red, it means the car can't speed up anymore in front of it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4141" target="_blank">01:09:01.260</a></span> | <span class="t">And when the blocks to the left or to the right light up as red,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4144" target="_blank">01:09:04.660</a></span> | <span class="t">that means you can't change lanes to the left or right.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4146" target="_blank">01:09:06.760</a></span> | <span class="t">On the right of the slide, you're free to go, free to do whatever you want.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4153" target="_blank">01:09:13.860</a></span> | <span class="t">That's what that indicates.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4155" target="_blank">01:09:15.360</a></span> | <span class="t">There's all the blocks are yellow. Safety system says you're free to choose any of the five actions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4162" target="_blank">01:09:22.760</a></span> | <span class="t">And the five actions are move left, move right, stay in place, accelerate or slow down.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4171" target="_blank">01:09:31.460</a></span> | <span class="t">And those actions are given as input.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4175" target="_blank">01:09:35.160</a></span> | <span class="t">That action is, that's what's produced by the, what's called here the brain.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4183" target="_blank">01:09:43.260</a></span> | <span class="t">The brain takes in the current state as input, the last reward and produces and learns,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4190" target="_blank">01:09:50.460</a></span> | <span class="t">uses that reward to train the network through backward function there, back propagation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4199" target="_blank">01:09:59.660</a></span> | <span class="t">And then ask the brain, given the current state, to give it the next action with a forward pass, the forward function.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4209" target="_blank">01:10:09.760</a></span> | <span class="t">You don't need to know the operation of this function in particular.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4213" target="_blank">01:10:13.760</a></span> | <span class="t">This is not something you need to worry about, but you can if you want.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4217" target="_blank">01:10:17.560</a></span> | <span class="t">You can customize this learning step.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4219" target="_blank">01:10:19.560</a></span> | <span class="t">There is, by the way, what I'm describing now, there's just a few lines of code right there in the browser.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4229" target="_blank">01:10:29.160</a></span> | <span class="t">That you can change and immediately, well, with the press of a button,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4234" target="_blank">01:10:34.460</a></span> | <span class="t">changes the simulation or the design of the network.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4237" target="_blank">01:10:37.860</a></span> | <span class="t">You don't need to have any special hardware, you don't need to do anything special.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4241" target="_blank">01:10:41.560</a></span> | <span class="t">And the tutorial cleanly outlines exactly all of these steps.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4245" target="_blank">01:10:45.160</a></span> | <span class="t">But it's kind of amazing that you can design a deep neural network</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4250" target="_blank">01:10:50.160</a></span> | <span class="t">that's part of the reinforcement learning agent.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4252" target="_blank">01:10:52.460</a></span> | <span class="t">So it's a deep Q learning agent right there in the browser.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4259" target="_blank">01:10:59.460</a></span> | <span class="t">So you can choose the lane side variable which controls how many lanes to the side you see.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4268" target="_blank">01:11:08.460</a></span> | <span class="t">So when that value is zero, you only look forward.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4270" target="_blank">01:11:10.760</a></span> | <span class="t">When that value is one, you have one lane to the left, one value to the right.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4274" target="_blank">01:11:14.860</a></span> | <span class="t">It's really the lane, the radius of your perception system.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4278" target="_blank">01:11:18.560</a></span> | <span class="t">Patches ahead is how far ahead you look, patches behind is how far behind you look.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4286" target="_blank">01:11:26.260</a></span> | <span class="t">And so for example here, the lane side equals two, that means it looks two to the left, two to the right.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4293" target="_blank">01:11:33.160</a></span> | <span class="t">Obviously, if two to the right is off-road, it provides a value of zero in those blocks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4301" target="_blank">01:11:41.860</a></span> | <span class="t">If we set the patches behind to be ten, it looks ten patches back.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4308" target="_blank">01:11:48.460</a></span> | <span class="t">Behind starting at the one patch back is starting from the front of the car.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4314" target="_blank">01:11:54.160</a></span> | <span class="t">The scoring for the evaluation, for the competition is your average speed over a predefined period of time.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4323" target="_blank">01:12:03.060</a></span> | <span class="t">And so the method we use to collect that speed is we run the agent ten runs,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4330" target="_blank">01:12:10.960</a></span> | <span class="t">about 30 simulated minutes of game each and take the median speed of the ten runs.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4336" target="_blank">01:12:16.660</a></span> | <span class="t">That's the score.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4341" target="_blank">01:12:21.060</a></span> | <span class="t">This is done server-side and so given that we've gotten some,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4350" target="_blank">01:12:30.360</a></span> | <span class="t">for this code, recently gotten some publicity online unfortunately.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4355" target="_blank">01:12:35.160</a></span> | <span class="t">This might be a dangerous thing to say, it's no cheating possible.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4360" target="_blank">01:12:40.160</a></span> | <span class="t">But because it's done server-side and we did, this is JavaScript and it runs in the browser,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4366" target="_blank">01:12:46.660</a></span> | <span class="t">it's hopefully sandboxed so we can't do anything tricky.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4371" target="_blank">01:12:51.260</a></span> | <span class="t">But we dare you to try.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4372" target="_blank">01:12:52.960</a></span> | <span class="t">You can try it locally to get an estimate.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4380" target="_blank">01:13:00.560</a></span> | <span class="t">And there's a button that says evaluate and it gives you a score right back</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4386" target="_blank">01:13:06.360</a></span> | <span class="t">of how well you're doing with the current network.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4392" target="_blank">01:13:12.460</a></span> | <span class="t">That button is start evaluation run.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4396" target="_blank">01:13:16.360</a></span> | <span class="t">You press the button, it does a progress bar and it gives you the average speed.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4400" target="_blank">01:13:20.960</a></span> | <span class="t">You can, there's a code box where you modify all the variables I mentioned</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4410" target="_blank">01:13:30.960</a></span> | <span class="t">and the tutorial describes this in detail.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4412" target="_blank">01:13:32.960</a></span> | <span class="t">And then once you're ready, you modify a few things, you can press apply code, it restarts,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4420" target="_blank">01:13:40.660</a></span> | <span class="t">it kills all the training that you've done up to this point or resets it and starts the training again.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4427" target="_blank">01:13:47.660</a></span> | <span class="t">So save often and there's a save button.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4432" target="_blank">01:13:52.360</a></span> | <span class="t">So the training is done on a separate thread in web workers</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4438" target="_blank">01:13:58.960</a></span> | <span class="t">which are exciting things that allow you to allow JavaScript to run amazingly in a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4450" target="_blank">01:14:10.660</a></span> | <span class="t">on multiple CPU cores in a parallel way.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4454" target="_blank">01:14:14.860</a></span> | <span class="t">So the simulation that scores this or the training is done a lot faster than real time.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4462" target="_blank">01:14:22.860</a></span> | <span class="t">A thousand frames a second, a thousand movement steps a second.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4469" target="_blank">01:14:29.060</a></span> | <span class="t">This is all in JavaScript.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4471" target="_blank">01:14:31.660</a></span> | <span class="t">And the next day gets shipped to the main simulation from time to time as the training goes on.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4480" target="_blank">01:14:40.160</a></span> | <span class="t">So all you have to do is press run training and it trains and the car behaves better over time.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4487" target="_blank">01:14:47.460</a></span> | <span class="t">Maybe I'll actually show it in the browser to, let's see if we work.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4495" target="_blank">01:14:55.760</a></span> | <span class="t">Well, is it going to mess up? We're good.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4499" target="_blank">01:14:59.260</a></span> | <span class="t">Why is it being weird?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4505" target="_blank">01:15:05.060</a></span> | <span class="t">(silence)</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4512" target="_blank">01:15:12.260</a></span> | <span class="t">What can possibly go wrong?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4513" target="_blank">01:15:13.860</a></span> | <span class="t">(silence)</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4526" target="_blank">01:15:26.660</a></span> | <span class="t">So here's the game.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4527" target="_blank">01:15:27.660</a></span> | <span class="t">When it starts, this is running live in the browser.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4533" target="_blank">01:15:33.560</a></span> | <span class="t">(silence)</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4535" target="_blank">01:15:35.560</a></span> | <span class="t">Artificial intelligence, ladies and gentlemen, in the browser, a neural network.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4540" target="_blank">01:15:40.660</a></span> | <span class="t">So currently it's not very good.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4542" target="_blank">01:15:42.560</a></span> | <span class="t">It's driving at two miles an hour and watching everybody pass.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4547" target="_blank">01:15:47.760</a></span> | <span class="t">So what's being shown live is the loss function which is pretty poor.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4557" target="_blank">01:15:57.260</a></span> | <span class="t">So in order to train, like I said, a thousand frames a second, you just press the run training button.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4564" target="_blank">01:16:04.560</a></span> | <span class="t">And pretty quickly it learns based on the network you specify in the code box,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4570" target="_blank">01:16:10.060</a></span> | <span class="t">how to, and based on the input and all the things that I mentioned, training finished.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4578" target="_blank">01:16:18.060</a></span> | <span class="t">It learns how to do a little better.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4582" target="_blank">01:16:22.260</a></span> | <span class="t">We on purpose put in a network that's not very good in there.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4586" target="_blank">01:16:26.360</a></span> | <span class="t">So right now it won't, on average, be doing that well, but it does better than standing there in place.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4592" target="_blank">01:16:32.060</a></span> | <span class="t">And then you can do the start evaluation run to simulate the network much faster than real time,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4601" target="_blank">01:16:41.460</a></span> | <span class="t">to see how well it does.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4603" target="_blank">01:16:43.960</a></span> | <span class="t">This is a similar evaluation step that we take when determining where you stand on the leaderboard.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4611" target="_blank">01:16:51.760</a></span> | <span class="t">The current average speed in that 10 run simulation is 56.56 miles per hour.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4621" target="_blank">01:17:01.160</a></span> | <span class="t">Now I may be logged in, maybe not.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4626" target="_blank">01:17:06.160</a></span> | <span class="t">If you're logged in, you click submit your code.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4631" target="_blank">01:17:11.160</a></span> | <span class="t">If you're not logged in, it says you're not logged in, please log in to submit your code.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4638" target="_blank">01:17:18.360</a></span> | <span class="t">And then all you have to do is log in.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4641" target="_blank">01:17:21.260</a></span> | <span class="t">This is the most flawless demo of my life.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4645" target="_blank">01:17:25.260</a></span> | <span class="t">And then you press submit model again and success.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4650" target="_blank">01:17:30.360</a></span> | <span class="t">Oh man.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4652" target="_blank">01:17:32.260</a></span> | <span class="t">Thank you for your submission.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4656" target="_blank">01:17:36.860</a></span> | <span class="t">And so now my submission is entered as Lex in the leaderboard,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4661" target="_blank">01:17:41.660</a></span> | <span class="t">and my 56.56 or whatever it was.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4664" target="_blank">01:17:44.560</a></span> | <span class="t">So I dare all of you to try to beat that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4668" target="_blank">01:17:48.460</a></span> | <span class="t">So to, as you play around with stuff, if you want to save the code,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4675" target="_blank">01:17:55.360</a></span> | <span class="t">you could do so by pressing the save code button.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4680" target="_blank">01:18:00.660</a></span> | <span class="t">That saves the various JavaScript configurations,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4684" target="_blank">01:18:04.360</a></span> | <span class="t">and that saves the network layout to file.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4688" target="_blank">01:18:08.260</a></span> | <span class="t">And then you can load from file as well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4691" target="_blank">01:18:11.160</a></span> | <span class="t">Again, danger, it overrides the code for you.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4695" target="_blank">01:18:15.660</a></span> | <span class="t">And you press the submit button to submit the model to competition.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4698" target="_blank">01:18:18.560</a></span> | <span class="t">Make sure that you train the network.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4701" target="_blank">01:18:21.360</a></span> | <span class="t">We don't train it for you.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4702" target="_blank">01:18:22.560</a></span> | <span class="t">You bring us, you submit a model and you have to press train.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4706" target="_blank">01:18:26.260</a></span> | <span class="t">And it gets evaluated with, in time.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4710" target="_blank">01:18:30.560</a></span> | <span class="t">It enters a queue to get evaluated.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4712" target="_blank">01:18:32.560</a></span> | <span class="t">This is public facing, so the queue can grow pretty big.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4716" target="_blank">01:18:36.460</a></span> | <span class="t">And it goes to that queue, evaluates it,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4719" target="_blank">01:18:39.560</a></span> | <span class="t">and then depending on where you stand, you get added to the leaderboard.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4723" target="_blank">01:18:43.760</a></span> | <span class="t">You get added to the leaderboard, showing the top 10 entries.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4726" target="_blank">01:18:46.560</a></span> | <span class="t">You can resubmit often,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4729" target="_blank">01:18:49.360</a></span> | <span class="t">and only the highest score counts.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4733" target="_blank">01:18:53.760</a></span> | <span class="t">Okay, we're using code,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4738" target="_blank">01:18:58.860</a></span> | <span class="t">the implementation of neural networks,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4743" target="_blank">01:19:03.460</a></span> | <span class="t">done in just JavaScript,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4746" target="_blank">01:19:06.660</a></span> | <span class="t">by Andrej Karpathy from Stanford, now OpenAI.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4752" target="_blank">01:19:12.460</a></span> | <span class="t">ComNetJS is a library.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4754" target="_blank">01:19:14.260</a></span> | <span class="t">And what's being visualized there,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4758" target="_blank">01:19:18.260</a></span> | <span class="t">it's also being visualized in the game,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4759" target="_blank">01:19:19.960</a></span> | <span class="t">is the inputs to the network.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4761" target="_blank">01:19:21.660</a></span> | <span class="t">In this case, it's 135 inputs.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4764" target="_blank">01:19:24.260</a></span> | <span class="t">You can also specify not just the,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4767" target="_blank">01:19:27.860</a></span> | <span class="t">not just how far ahead behind you see into the left and to the right,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4772" target="_blank">01:19:32.960</a></span> | <span class="t">you can specify how far back in time you look as well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4780" target="_blank">01:19:40.060</a></span> | <span class="t">And so, what's visualized there is the input to the network, 135 neurons,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4787" target="_blank">01:19:47.360</a></span> | <span class="t">and then the output, a regression,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4789" target="_blank">01:19:49.960</a></span> | <span class="t">similar to the kind of output we saw with numbers,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4793" target="_blank">01:19:53.260</a></span> | <span class="t">where there's 10 outputs saying if it's a 0, 1, or 9.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4797" target="_blank">01:19:57.560</a></span> | <span class="t">Here, the output is one of the five actions,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4800" target="_blank">01:20:00.160</a></span> | <span class="t">left, right, stay in place, speed up or slow down.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4803" target="_blank">01:20:03.060</a></span> | <span class="t">The ComNetJS settings,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4806" target="_blank">01:20:06.460</a></span> | <span class="t">is you can select the number of inputs,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4809" target="_blank">01:20:09.660</a></span> | <span class="t">if you want to mess with this stuff,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4811" target="_blank">01:20:11.960</a></span> | <span class="t">this is all the stuff you don't need to mess with,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4813" target="_blank">01:20:13.760</a></span> | <span class="t">because we already give you the variables of lane side and patches ahead and so on.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4817" target="_blank">01:20:17.660</a></span> | <span class="t">You can select the number of actions,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4819" target="_blank">01:20:19.860</a></span> | <span class="t">the temporal window, and the network size.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4823" target="_blank">01:20:23.960</a></span> | <span class="t">So, the network definition here is the,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4834" target="_blank">01:20:34.860</a></span> | <span class="t">this is the input, the size of the input.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4839" target="_blank">01:20:39.060</a></span> | <span class="t">Again, all this is in the tutorial, just to give you a little outline.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4841" target="_blank">01:20:41.960</a></span> | <span class="t">There is a, the first fully connected layer has 10 neurons,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4847" target="_blank">01:20:47.260</a></span> | <span class="t">with ReLU activation functions,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4850" target="_blank">01:20:50.560</a></span> | <span class="t">same kind of smooth function that we talked about before,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4855" target="_blank">01:20:55.960</a></span> | <span class="t">and a regression layer for the output.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4859" target="_blank">01:20:59.560</a></span> | <span class="t">And there's a bunch of other messy options that you can play with, if you dare.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4868" target="_blank">01:21:08.460</a></span> | <span class="t">But those aren't the ones I mentioned before, it's really the important ones.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4871" target="_blank">01:21:11.460</a></span> | <span class="t">It's selecting the number of layers, the size of those layers,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4874" target="_blank">01:21:14.960</a></span> | <span class="t">you get to build your own very neural network that drives.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4877" target="_blank">01:21:17.960</a></span> | <span class="t">And the actual learning is done with a backward propagation,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4882" target="_blank">01:21:22.160</a></span> | <span class="t">and then that returns the action by doing a forward pass to the network.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4887" target="_blank">01:21:27.260</a></span> | <span class="t">In case you're interested in this kind of stuff,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4890" target="_blank">01:21:30.560</a></span> | <span class="t">there is an amazingly cool code editor,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4896" target="_blank">01:21:36.660</a></span> | <span class="t">that's a Monaco editor,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4898" target="_blank">01:21:38.160</a></span> | <span class="t">that's, it just works, it does some auto-completion,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4903" target="_blank">01:21:43.460</a></span> | <span class="t">so you get to play with it, makes everything very convenient in terms of code editing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4907" target="_blank">01:21:47.360</a></span> | <span class="t">A lot of this visualization of the game,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4911" target="_blank">01:21:51.160</a></span> | <span class="t">and the simulation, and the simulation we'll talk about tomorrow,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4917" target="_blank">01:21:57.060</a></span> | <span class="t">is done in the browser using HTML5 Canvas.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4921" target="_blank">01:22:01.760</a></span> | <span class="t">So here is a simple specification of a blue box with Canvas,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4926" target="_blank">01:22:06.060</a></span> | <span class="t">and this is very efficient and easy to work with.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4929" target="_blank">01:22:09.860</a></span> | <span class="t">And the thing that a lot of us are excited about, a very subtle one,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4937" target="_blank">01:22:17.260</a></span> | <span class="t">but that you can not just run,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4940" target="_blank">01:22:20.760</a></span> | <span class="t">so with the V8 engine, JavaScript has become super fast.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4946" target="_blank">01:22:26.160</a></span> | <span class="t">You can train neural networks in the browser, that's already amazing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4950" target="_blank">01:22:30.060</a></span> | <span class="t">And then with web workers, as long as you have Chrome, a modern browser.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4955" target="_blank">01:22:35.260</a></span> | <span class="t">So, is you can run multiple processes in separate threads.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4962" target="_blank">01:22:42.060</a></span> | <span class="t">So you could do a lot of stuff, you can do visualization separately,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4966" target="_blank">01:22:46.360</a></span> | <span class="t">and you can train in separate threads.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4968" target="_blank">01:22:48.260</a></span> | <span class="t">It's very cool.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4969" target="_blank">01:22:49.660</a></span> | <span class="t">Okay, so the tutorial is cars.mit.edu and deep traffic.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4974" target="_blank">01:22:54.560</a></span> | <span class="t">We won't put these links on the website for a little bit,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4977" target="_blank">01:22:57.760</a></span> | <span class="t">because we got put on the front page of Hacker News.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4985" target="_blank">01:23:05.760</a></span> | <span class="t">Which we don't want those to leak out,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4988" target="_blank">01:23:08.860</a></span> | <span class="t">especially with the claims that you can't cheat.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4992" target="_blank">01:23:12.160</a></span> | <span class="t">And while it's pretty efficient in terms of running time,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=4997" target="_blank">01:23:17.960</a></span> | <span class="t">so everything is running on your machine, client side.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=5000" target="_blank">01:23:20.360</a></span> | <span class="t">It's still, you have to pull some images here and pull some of the code.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=5004" target="_blank">01:23:24.460</a></span> | <span class="t">So the tutorial is on cars.mit.edu/deep-traffic</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=5008" target="_blank">01:23:28.660</a></span> | <span class="t">and the simulation is deep-traffic.js.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=5011" target="_blank">01:23:31.960</a></span> | <span class="t">So cars.mit.edu/deep-traffic.js.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=5015" target="_blank">01:23:35.460</a></span> | <span class="t">I encourage you to go there, play with the network, submit your code,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=5019" target="_blank">01:23:39.360</a></span> | <span class="t">and win the very special prize.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=5022" target="_blank">01:23:42.260</a></span> | <span class="t">It is a pretty cool one, but we're still working on it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=5025" target="_blank">01:23:45.260</a></span> | <span class="t">It's not, there is a prize, I swear.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=5028" target="_blank">01:23:48.260</a></span> | <span class="t">All right, so let's take a pause and think about what we talked about today.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=5038" target="_blank">01:23:58.860</a></span> | <span class="t">So the very best of deep reinforcement learning is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=5043" target="_blank">01:24:03.760</a></span> | <span class="t">the most exciting accomplishment, I think,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=5049" target="_blank">01:24:09.060</a></span> | <span class="t">is when the game, when I first started as a freshman,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=5056" target="_blank">01:24:16.060</a></span> | <span class="t">took intro to artificial intelligence.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=5058" target="_blank">01:24:18.860</a></span> | <span class="t">It was said that it's a game that's impossible for machines to beat</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=5065" target="_blank">01:24:25.160</a></span> | <span class="t">because of the combinatorial complexity.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=5067" target="_blank">01:24:27.860</a></span> | <span class="t">It's just the sheer number of options.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=5070" target="_blank">01:24:30.360</a></span> | <span class="t">It's so much more complex than chess.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=5072" target="_blank">01:24:32.360</a></span> | <span class="t">And so the most amazing accomplishment of deep reinforcement learning to me</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=5079" target="_blank">01:24:39.460</a></span> | <span class="t">is the design of AlphaGo.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=5081" target="_blank">01:24:41.260</a></span> | <span class="t">When for the first time, the world champion in Go was beaten by DeepMind's AlphaGo.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=5088" target="_blank">01:24:48.660</a></span> | <span class="t">And the way they did it, and this is, I think, very relevant to driving,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=5095" target="_blank">01:24:55.360</a></span> | <span class="t">is you start by creating first in a supervised way, training a policy network.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=5102" target="_blank">01:25:02.460</a></span> | <span class="t">So you take expert games to construct a network first.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=5111" target="_blank">01:25:11.160</a></span> | <span class="t">So you don't play against yourself, the agent doesn't play against itself,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=5118" target="_blank">01:25:18.160</a></span> | <span class="t">but they learn from expert games.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=5121" target="_blank">01:25:21.360</a></span> | <span class="t">So there's some human ground truth.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=5124" target="_blank">01:25:24.860</a></span> | <span class="t">This human ground truth represents reality.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=5126" target="_blank">01:25:26.960</a></span> | <span class="t">So for driving, this is important.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=5128" target="_blank">01:25:28.860</a></span> | <span class="t">We have a, well, we're starting to get a lot of data</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=5131" target="_blank">01:25:31.960</a></span> | <span class="t">where video of drivers is being recorded.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=5134" target="_blank">01:25:34.660</a></span> | <span class="t">So we can learn on that data before we then run the agents through simulation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=5139" target="_blank">01:25:39.660</a></span> | <span class="t">where it learns much larger magnitudes of data sets through simulation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=5145" target="_blank">01:25:45.260</a></span> | <span class="t">And they did just that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=5150" target="_blank">01:25:50.760</a></span> | <span class="t">Now as a reminder that when you let an agent drive itself,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=5159" target="_blank">01:25:59.860</a></span> | <span class="t">this is probably one of my favorite videos of all time,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=5164" target="_blank">01:26:04.260</a></span> | <span class="t">but I just recently saw it so I could just watch this for hours.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=5166" target="_blank">01:26:06.760</a></span> | <span class="t">But it's a reminder that you can't trust your first estimates of a reward function.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=5180" target="_blank">01:26:20.360</a></span> | <span class="t">To be those that are safe and productive for our society</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=5184" target="_blank">01:26:24.460</a></span> | <span class="t">when you're talking about an intelligent system that gets to operate in the real world.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=5189" target="_blank">01:26:29.060</a></span> | <span class="t">This is just as clear of a reminder of that as there is.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=5193" target="_blank">01:26:33.760</a></span> | <span class="t">So again, all the references are available online for these slides.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=5200" target="_blank">01:26:40.560</a></span> | <span class="t">We'll put up the slides.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=5201" target="_blank">01:26:41.560</a></span> | <span class="t">I imagine you might have, if you want to come down and talk to us for questions</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=5206" target="_blank">01:26:46.960</a></span> | <span class="t">for the either Docker or JavaScript question.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=5211" target="_blank">01:26:51.360</a></span> | <span class="t">So the question was, what is the visualization you're seeing in deep traffic?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=5220" target="_blank">01:27:00.160</a></span> | <span class="t">You're seeing a car move about.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=5222" target="_blank">01:27:02.460</a></span> | <span class="t">How is it moving?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=5223" target="_blank">01:27:03.860</a></span> | <span class="t">It's moving based on the latest snapshot of the network you trained.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=5227" target="_blank">01:27:07.060</a></span> | <span class="t">So it's just visualizing for you just for fun the network you trained most recently.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=5235" target="_blank">01:27:15.060</a></span> | <span class="t">Okay, so if people have questions, stick around afterwards.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=5238" target="_blank">01:27:18.260</a></span> | <span class="t">Just details on Docker and yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=5243" target="_blank">01:27:23.060</a></span> | <span class="t">Do you want to do it offline?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QDzM8r3WgBw&t=5247" target="_blank">01:27:27.760</a></span> | <span class="t">Want me to tuck up?</span></div></div></body></html>