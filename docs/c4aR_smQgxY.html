<html><head><title>GPT 5 is All About Data</title></head><body><a href="index.html">back to index</a><h2>GPT 5 is All About Data</h2><a href="https://www.youtube.com/watch?v=c4aR_smQgxY"><img src="https://i.ytimg.com/vi/c4aR_smQgxY/maxresdefault.jpg" style="width:50%;"></a><div><br></div><div style="text-align: left;"><a href="./c4aR_smQgxY.html">Whisper Transcript</a> | <a href="./transcript_c4aR_smQgxY.html">Transcript Only Page</a></div><br><div style="max-width: 800px;"><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=c4aR_smQgxY&t=0">00:00:00.000</a></span> | <span class="t">To find out what I could about GPT-5, I have read every academic paper I could find about it,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=c4aR_smQgxY&t=6">00:00:06.520</a></span> | <span class="t">every leak report, interview snippet and media article. I can summarize it like this,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=c4aR_smQgxY&t=12">00:00:12.260</a></span> | <span class="t">it will come down to data, how much of it there is, how it's used and where it comes from.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=c4aR_smQgxY&t=18">00:00:18.660</a></span> | <span class="t">These are the factors that will dictate whether GPT-5 gets released later this year and whether</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=c4aR_smQgxY&t=24">00:00:24.900</a></span> | <span class="t">it will actually approach genius level IQ. Some media reports have picked up on this potential</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=c4aR_smQgxY&t=30">00:00:30.800</a></span> | <span class="t">leak about GPT-5, you can read it here. I have put quite a few hours in trying to verify whether</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=c4aR_smQgxY&t=37">00:00:37.140</a></span> | <span class="t">this might be accurate and even though it's now being quoted by reputable sources, I still can't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=c4aR_smQgxY&t=42">00:00:42.840</a></span> | <span class="t">confirm its accuracy. So for now I'll just say that the rest of the document seems accurate</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=c4aR_smQgxY&t=47">00:00:47.560</a></span> | <span class="t">but who knows. I am not relying on this for my research about GPT-5 but the scale, 25,000 GPUs,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=c4aR_smQgxY&t=54">00:00:54.880</a></span> | <span class="t">does seem right. TechRadar here describes ChatGPT as having been trained on 10,000 NVIDIA GPUs.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=c4aR_smQgxY&t=62">00:01:02.160</a></span> | <span class="t">And don't forget those were A100 GPUs. Microsoft might well now have access to the H100 GPU which</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=c4aR_smQgxY&t=70">00:01:10.220</a></span> | <span class="t">according to every source is a big step up from A100 GPUs on pretty much every metric.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=c4aR_smQgxY&t=76">00:01:16.540</a></span> | <span class="t">And what about timelines for GPT-5? Would later this year be accurate? Well we can infer from</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=c4aR_smQgxY&t=83">00:01:23.160</a></span> | <span class="t">Jordi Rybas that GPT-5 is a good idea. If you're not sure, you can look at the chart on the right</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=c4aR_smQgxY&t=84">00:01:24.860</a></span> | <span class="t">side of the screen. GPT-4 or equivalent was completed sometime around late spring/early summer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=c4aR_smQgxY&t=90">00:01:30.740</a></span> | <span class="t">of 2022. That would be just around the time that DeepMind published this which in massively</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=c4aR_smQgxY&t=97">00:01:37.760</a></span> | <span class="t">oversimplified terms lays out a framework for optimizing parameter size with the number</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=c4aR_smQgxY&t=104">00:01:44.180</a></span> | <span class="t">of training tokens aka how much info from the web it's trained on. Turns out models</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=c4aR_smQgxY&t=109">00:01:49.940</a></span> | <span class="t">like GPT-3 and Palm had way more parameters than needed anyway.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=c4aR_smQgxY&t=114">00:01:54.360</a></span> | <span class="t">It was the data and especially high quality data that it was lacking. So all those graphs about GPT-4</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=c4aR_smQgxY&t=121">00:02:01.680</a></span> | <span class="t">needing 100 trillion parameters were absolutely farcical. It could even be that GPT-5 has the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=c4aR_smQgxY&t=128">00:02:08.640</a></span> | <span class="t">same or fewer parameters than GPT-4. This less wrong post from July of 2022 picks up on that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=c4aR_smQgxY&t=137">00:02:17.100</a></span> | <span class="t">finding and points out that it is data not size that is currently the active constraint on language</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=c4aR_smQgxY&t=143">00:02:23.860</a></span> | <span class="t">modeling performance. Current returns to additional data are immense and current returns to additional</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=c4aR_smQgxY&t=150">00:02:30.520</a></span> | <span class="t">model size are miniscule. Indeed most recent landmark models are wastefully big. If we can</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=c4aR_smQgxY&t=156">00:02:36.340</a></span> | <span class="t">leverage enough data there is no reason to run 500 billion parameter models much less 1 trillion</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=c4aR_smQgxY&t=162">00:02:42.700</a></span> | <span class="t">parameter or larger models. Remember it's data not parameter count. The link to all of these articles</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=c4aR_smQgxY&t=168">00:02:48.760</a></span> | <span class="t">by the way will be in the description. At this point let me quickly say that if you're learning anything don't forget to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=c4aR_smQgxY&t=173">00:02:53.360</a></span> | <span class="t">leave a like or a comment. Frankly even abuse helps the algorithm so go for it. What about chat GPT?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=c4aR_smQgxY&t=178">00:02:58.760</a></span> | <span class="t">Well GPT-3 along with a host of other models was trained on about 300 billion tokens. By the way</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=c4aR_smQgxY&t=186">00:03:06.320</a></span> | <span class="t">what defines a token shifts in the literature but it's somewhere between 1 and 1.4 words. Therefore</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=c4aR_smQgxY&t=192">00:03:12.680</a></span> | <span class="t">think of a token as roughly one word. As you can see from the graph below Palm was trained on about</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=c4aR_smQgxY&t=199">00:03:19.640</a></span> | <span class="t">800 billion tokens approximately.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=c4aR_smQgxY&t=202">00:03:22.860</a></span> | <span class="t">DeepMind's chinchilla on about 1.4 trillion tokens. That particular less wrong post was referenced here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=c4aR_smQgxY&t=210">00:03:30.540</a></span> | <span class="t">in this academic paper released in October. This paper is absolutely key to this video. It's focused</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=c4aR_smQgxY&t=218">00:03:38.700</a></span> | <span class="t">entirely on whether we will run out of data as it pertains to machine learning and large language</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=c4aR_smQgxY&t=224">00:03:44.520</a></span> | <span class="t">models. One of the key takeaways of this paper is the approximation given for how much high quality data / tokens</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=c4aR_smQgxY&t=232">00:03:52.360</a></span> | <span class="t">might be out there. The stock of high quality language data is approximated at between 4.6</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=c4aR_smQgxY&t=238">00:03:58.660</a></span> | <span class="t">trillion and 17 trillion words. The next point it makes is key. We are within one order of magnitude</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=c4aR_smQgxY&t=246">00:04:06.580</a></span> | <span class="t">of exhausting high quality data and this will likely happen between 2023 and 2027. For those that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=c4aR_smQgxY&t=254">00:04:14.920</a></span> | <span class="t">don't know being an order of magnitude bigger means being 10 times bigger than what came previously.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=c4aR_smQgxY&t=259">00:04:19.540</a></span> | <span class="t">Now I want you to remember that 2023 to 2027 timeline for a moment because first I want to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=c4aR_smQgxY&t=265">00:04:25.660</a></span> | <span class="t">mention why high quality data is important. Running out of that could mean running out of the rapid</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=c4aR_smQgxY&t=271">00:04:31.960</a></span> | <span class="t">improvements in GPT models. The paper says models trained on the latter kind of high quality data</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=c4aR_smQgxY&t=278">00:04:38.320</a></span> | <span class="t">perform better so it is common practice to use high quality data for training language models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=c4aR_smQgxY&t=284">00:04:44.380</a></span> | <span class="t">And where does that high quality data come from? Well to be honest not knowing that is a big part of the data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=c4aR_smQgxY&t=289">00:04:49.040</a></span> | <span class="t">Which we will definitely come back to but here is a rough idea. We have scientific papers, books,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=c4aR_smQgxY&t=296">00:04:56.720</a></span> | <span class="t">scraped content from the web, the news, code etc. Plus Wikipedia of course. The paper also mentions</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=c4aR_smQgxY&t=305">00:05:05.000</a></span> | <span class="t">here the middle of the road estimate of 9 trillion tokens of high quality data available. That</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=c4aR_smQgxY&t=311">00:05:11.480</a></span> | <span class="t">estimate will be central in defining the near-term future of artificial intelligence. One order of magnitude</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=c4aR_smQgxY&t=318">00:05:18.540</a></span> | <span class="t">more as an increase in performance is a huge deal. That would change everything. But I must say this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=c4aR_smQgxY&t=325">00:05:25.800</a></span> | <span class="t">estimate contrasts with some others such as the 3.2 trillion token estimate from that original post.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=c4aR_smQgxY&t=333">00:05:33.180</a></span> | <span class="t">And the author did say that they were trying to make it an overestimate. And what about this from</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=c4aR_smQgxY&t=339">00:05:39.000</a></span> | <span class="t">David Chapman a PhD in AI from MIT. He references the DeepMind study and that less wrong post and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=c4aR_smQgxY&t=347">00:05:47.040</a></span> | <span class="t">makes two important and very important statements. The first one is that the data is not necessarily</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=c4aR_smQgxY&t=348">00:05:48.040</a></span> | <span class="t">and plausible observations. First that GPT-4 or Bing may have scraped the bottom of the web text</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=c4aR_smQgxY&t=355">00:05:55.720</a></span> | <span class="t">barrel and that this might be why its responses sometimes turn out like emoting teenagers. I</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=c4aR_smQgxY&t=363">00:06:03.200</a></span> | <span class="t">actually did a video on the crazy conversations you can have with Bing that you can check out</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=c4aR_smQgxY&t=368">00:06:08.340</a></span> | <span class="t">after this one. But second he suggests that there might be a reason that neither Google nor OpenAI</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=c4aR_smQgxY&t=374">00:06:14.220</a></span> | <span class="t">have been forthcoming about where they get their data from. Now I'm not saying it might be about</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=c4aR_smQgxY&t=380">00:06:20.540</a></span> | <span class="t">illegality but it might be about avoiding controversy over attribution and compensation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=c4aR_smQgxY&t=386">00:06:26.880</a></span> | <span class="t">Take me, I have math tutorials on the web that I'm sure have been scraped and now lo and behold</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=c4aR_smQgxY&t=393">00:06:33.760</a></span> | <span class="t">Bing can teach math. I'm not complaining but it would be nice to at least know what has been used</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=c4aR_smQgxY&t=398">00:06:38.740</a></span> | <span class="t">and what hasn't. This of course mirrors the raging legal issues around AI image generation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=c4aR_smQgxY&t=404">00:06:44.200</a></span> | <span class="t">Fights that are only just beginning for these web techs. Wanting to know where the data came from</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=c4aR_smQgxY&t=410">00:06:50.720</a></span> | <span class="t">is going to become a huge issue and this article lays out just some of the surprising sources of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=c4aR_smQgxY&t=416">00:06:56.620</a></span> | <span class="t">data for Google's BARD model. Check out one of them which is YouTube. Could it be that your</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=c4aR_smQgxY&t=422">00:07:02.500</a></span> | <span class="t">comments right now are being harvested? Quite possibly. But I want to get back to the central</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=c4aR_smQgxY&t=428">00:07:08.200</a></span> | <span class="t">question. What of GPT-5? Well here on the far right is Google Parallel.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=c4aR_smQgxY&t=433">00:07:13.880</a></span> | <span class="t">Which if you remember back from the earlier paper was powered by only 800 billion tokens</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=c4aR_smQgxY&t=440">00:07:20.900</a></span> | <span class="t">and Palm was definitely not optimized for parameters. GPT-5 will learn the lessons from this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=c4aR_smQgxY&t=447">00:07:27.560</a></span> | <span class="t">and will probably scrape as much high quality data as it possibly can. And don't forget another year</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=c4aR_smQgxY&t=453">00:07:33.580</a></span> | <span class="t">has gone by since GPT-4 was handed to Microsoft and the stock of high quality data grows by around</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=c4aR_smQgxY&t=461">00:07:41.360</a></span> | <span class="t">10% annually anyway.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=c4aR_smQgxY&t=463">00:07:43.620</a></span> | <span class="t">Even without further efficiencies in data use or extraction. So even if Bing did use all the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=c4aR_smQgxY&t=469">00:07:49.800</a></span> | <span class="t">high quality data available I don't think it did. And even if David Chapman is right,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=c4aR_smQgxY&t=473">00:07:53.760</a></span> | <span class="t">the stock of data now available is going to be greater. But if Bing was trained on a similar</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=c4aR_smQgxY&t=480">00:08:00.000</a></span> | <span class="t">amount of data to Palm, say 1 trillion tokens, but now GPT-5 maxes out, we could genuinely be</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=c4aR_smQgxY&t=488">00:08:08.280</a></span> | <span class="t">talking about an order of magnitude improvement. I'm going to briefly survey some of the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=c4aR_smQgxY&t=493">00:08:13.320</a></span> | <span class="t">implications of that in a moment. But before I do I want to show you the ways that OpenAI will</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=c4aR_smQgxY&t=498">00:08:18.840</a></span> | <span class="t">likely be improving GPT-5 regardless of previous limitations. First, more ways might be found to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=c4aR_smQgxY&t=505">00:08:25.740</a></span> | <span class="t">extract high quality data from low quality sources. No offense Facebook. Second, this paper from only</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=c4aR_smQgxY&t=513">00:08:33.660</a></span> | <span class="t">last week shows that gains can be made by automating chain of thought prompting into the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=c4aR_smQgxY&t=520">00:08:40.860</a></span> | <span class="t">model. If you're not sure what chain of thought prompting is, you can look at the chart above.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=c4aR_smQgxY&t=523">00:08:43.020</a></span> | <span class="t">It's a form of prompt engineering that I discussed in my video "8 Upgrades in GPT-4" where essentially</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=c4aR_smQgxY&t=530">00:08:50.520</a></span> | <span class="t">you force the model to lay out its working and thereby improve its output. Now this paper talks</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=c4aR_smQgxY&t=536">00:08:56.160</a></span> | <span class="t">about 2-3% gains but even those small gains when Bing is already this strong would be significant.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=c4aR_smQgxY&t=542">00:09:02.760</a></span> | <span class="t">Don't forget these are separate upgrades to the data discussion.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=c4aR_smQgxY&t=546">00:09:06.480</a></span> | <span class="t">Third, this paper from three weeks ago shows that language models can teach themselves</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=c4aR_smQgxY&t=552">00:09:12.720</a></span> | <span class="t">to use tools such as calculators, calendars and APIs. If there were no other improvements</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=c4aR_smQgxY&t=560">00:09:20.100</a></span> | <span class="t">honestly in GPT-5 other than this it would change the world. And I know for a fact that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=c4aR_smQgxY&t=565">00:09:25.680</a></span> | <span class="t">people are working on integrating Wolfram Alpha into a large language model and look</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=c4aR_smQgxY&t=571">00:09:31.200</a></span> | <span class="t">at the number of tools that Wolfram Alpha has in science, math, money and more. These models</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=c4aR_smQgxY&t=577">00:09:37.560</a></span> | <span class="t">can actually teach themselves how to use tools and that chimes perfectly</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=c4aR_smQgxY&t=582">00:09:42.420</a></span> | <span class="t">with this paper which essentially lays out that using a Python interpreter models can actually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=c4aR_smQgxY&t=588">00:09:48.600</a></span> | <span class="t">check if their code compiles and thereby teach themselves better coding. The links to all of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=c4aR_smQgxY&t=594">00:09:54.300</a></span> | <span class="t">these papers will be in the description as I said. The fourth way that GPT-5 might be improved</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=c4aR_smQgxY&t=599">00:09:59.400</a></span> | <span class="t">even without more high quality data would be it being trained multiple times on the same data,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=c4aR_smQgxY&t=606">00:10:06.120</a></span> | <span class="t">as laid out here by Professor Swayam Dipta. He says that currently these models are trained</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=c4aR_smQgxY&t=612">00:10:12.120</a></span> | <span class="t">on the same data just once owing to performance and cost constraints but it may be possible to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=c4aR_smQgxY&t=618">00:10:18.600</a></span> | <span class="t">train a model several times using the same data. Sure it might cost more but I think that for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=c4aR_smQgxY&t=624">00:10:24.420</a></span> | <span class="t">Microsoft when all of search and its profits is the prize a few billion could be deemed worth it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=c4aR_smQgxY&t=630">00:10:30.660</a></span> | <span class="t">And this paper co-authored by that same professor lays out how models can generate additional data</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=c4aR_smQgxY&t=637">00:10:37.020</a></span> | <span class="t">sets on problems with which they struggle such as those with complex patterns and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=c4aR_smQgxY&t=641">00:10:41.820</a></span> | <span class="t">humans could filter their answers for correctness. Think of this as artificial data generation and it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=c4aR_smQgxY&t=649">00:10:49.080</a></span> | <span class="t">can lead to 10% or more in improvements. And if artificial data can be integrated honestly what</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=c4aR_smQgxY&t=655">00:10:55.740</a></span> | <span class="t">is actually going to bottleneck these GPT models? I could go on with the improvements that might be</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=c4aR_smQgxY&t=661">00:11:01.440</a></span> | <span class="t">made without new data. My central point is that data will be the big determinant but</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=c4aR_smQgxY&t=667">00:11:07.560</a></span> | <span class="t">there are other ways to improve GPT-5 if data turns out to be a bottleneck.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=c4aR_smQgxY&t=671">00:11:11.520</a></span> | <span class="t">But what if they can fully utilize 9 trillion tokens as the original paper surmised by the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=c4aR_smQgxY&t=678">00:11:18.300</a></span> | <span class="t">end of 2024 or even the beginning of 2024? What could one more order of magnitude improvement</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=c4aR_smQgxY&t=684">00:11:24.240</a></span> | <span class="t">actually look like? The short answer is that no one knows. Probably not AGI but certainly a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=c4aR_smQgxY&t=691">00:11:31.260</a></span> | <span class="t">revolution in the jobs market. Maybe this is why Sam Altman tweeted 2023 $30,000 to get a simple iPhone app created $300 for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=c4aR_smQgxY&t=701">00:11:41.220</a></span> | <span class="t">a plumbing job. I wonder what those relative prices will look like in 2028. The likely coming</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=c4aR_smQgxY&t=707">00:11:47.520</a></span> | <span class="t">divergence between changes to cognitive work and changes to physical work could be quite dramatic.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=c4aR_smQgxY&t=712">00:11:52.800</a></span> | <span class="t">That gives a sense of his timelines but my own guess is that the best human raters will be</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=c4aR_smQgxY&t=718">00:11:58.980</a></span> | <span class="t">beaten on at least some of the following benchmarks. Take reading comprehension where you can imagine</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=c4aR_smQgxY&t=724">00:12:04.500</a></span> | <span class="t">the extrapolation to GPT-5. If and when it occurs that would have huge implications for summarization</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=c4aR_smQgxY&t=730">00:12:10.920</a></span> | <span class="t">and creative writing. Next logic and critical reasoning. We're talking debating topics,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=c4aR_smQgxY&t=736">00:12:16.740</a></span> | <span class="t">doing law work, discerning causality in complex scenarios. That would be huge in finance where</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=c4aR_smQgxY&t=743">00:12:23.820</a></span> | <span class="t">you have to sort the signal from the noise in large data sets. Physics and high school math</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=c4aR_smQgxY&t=749">00:12:29.280</a></span> | <span class="t">would be close to solved by an order of magnitude improvement. AI tutors replacing my job for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=c4aR_smQgxY&t=756">00:12:36.240</a></span> | <span class="t">example could be with us by the end of next year. Don't forget the release</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=c4aR_smQgxY&t=760">00:12:40.620</a></span> | <span class="t">of GPT-5 in whichever month it comes will likely roughly coincide with the final refinements in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=c4aR_smQgxY&t=767">00:12:47.880</a></span> | <span class="t">text to speech, image to text, text to image and text to video avatars. So don't think AI tutors</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=c4aR_smQgxY&t=775">00:12:55.320</a></span> | <span class="t">are as far as you might imagine. The reason why no one and certainly not me can be sure of timelines</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=c4aR_smQgxY&t=781">00:13:01.800</a></span> | <span class="t">for GPT-5 though is because they depend partly on internal safety research at Google and OpenAI. Take</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=c4aR_smQgxY&t=789">00:13:09.480</a></span> | <span class="t">this quote from</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=c4aR_smQgxY&t=790">00:13:10.320</a></span> | <span class="t">Sam Altman to the New York Times: "And when we are ready, when we think we have completed our</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=c4aR_smQgxY&t=795">00:13:15.720</a></span> | <span class="t">alignment work and all of our safety thinking and worked with external auditors, other AGI Labs,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=c4aR_smQgxY&t=802">00:13:22.680</a></span> | <span class="t">then we'll release those things." Here he's probably talking about GPT-4 but the same would</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=c4aR_smQgxY&t=807">00:13:27.780</a></span> | <span class="t">apply even more so to GPT-5. On the other hand the release and then unrelease of the Sydney model of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=c4aR_smQgxY&t=814">00:13:34.800</a></span> | <span class="t">Bing might suggest otherwise. But at least according to him safety and alignment are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=c4aR_smQgxY&t=820">00:13:40.020</a></span> | <span class="t">the goal. I'm going to end with this quote from Sam Altman again. He added the blue text last</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=c4aR_smQgxY&t=825">00:13:45.720</a></span> | <span class="t">minute to his public post on AGI released the other week. It says: "It's important that the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=c4aR_smQgxY&t=832">00:13:52.680</a></span> | <span class="t">ratio of safety progress to capability progress increases." In other words these models are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=c4aR_smQgxY&t=839">00:13:59.640</a></span> | <span class="t">getting much more powerful much faster than they can keep up with.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=c4aR_smQgxY&t=844">00:14:04.680</a></span> | <span class="t">But thank you for keeping up with this video. Thank you for watching to the end. Please</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=c4aR_smQgxY&t=849">00:14:09.720</a></span> | <span class="t">do check out my other videos on Bing chat and its use cases and either way have a wonderful day.</span></div></div></body></html>