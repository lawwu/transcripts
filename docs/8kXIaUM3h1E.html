<html><head><title>Stanford CS25: V5 I Multimodal World Models for Drug Discovery,  Eshed Margalit of Noetik.ai</title>
<style>
    body {
        font-family: Arial, sans-serif;
        margin: 0;
        padding: 0;
        background-color: #f4f4f4;
        color: #333;
    }
    .container {
        width: 95%;  /* Increased width to use more space */
        margin: auto;
        overflow: auto;  /* Added to handle overflow by adding a scrollbar if necessary */
    }
    h2, h3 {
        color: #333;
        text-align: center;
    }
    a {
        color: #0000FF;  /* Traditional blue color for links */
        text-decoration: none;
    }
    a:hover {
        text-decoration: underline;
    }
    img {
        display: block;
        margin: auto;
        max-width: 100%;
    }
    .c {
        margin: 10px 0;
    }
    .s, .t {
        display: inline-block;
        margin-right: 5px;
    }
    .max-width {
        max-width: 800px;
        margin: auto;
        padding-left: 20px;
    }
    table {
        width: 100%;
        border-collapse: collapse;
    }
    th, td {
        border: 1px solid #ddd;
        padding: 8px;
        text-align: left;  /* Ensure text alignment is consistent */
    }
    tr:nth-child(even) {
        background-color: #f2f2f2;
    }
    tr:nth-child(odd) {
        background-color: #e6e6e6;
    }
</style>

    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-69VLBMTTP0"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-69VLBMTTP0');
    </script>
    </head><body><div class='container'><a href="index.html">back to index</a><h2>Stanford CS25: V5 I Multimodal World Models for Drug Discovery,  Eshed Margalit of Noetik.ai</h2><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E"><img src="https://i.ytimg.com/vi/8kXIaUM3h1E/maxresdefault.jpg" style="width:50%;"></a><div><br></div><div style="text-align: left;"><a href="./8kXIaUM3h1E.html">Whisper Transcript</a> | <a href="./transcript_8kXIaUM3h1E.html">Transcript Only Page</a></div><br><div style="max-width: 800px;"><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=0" target="_blank">00:00:00.000</a></span> | <span class="t">All right, welcome everyone to CS25, I believe week eight.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=8" target="_blank">00:00:08.760</a></span> | <span class="t">Today we're very excited to have Ishad Margulit, who is a neuroscientist and ML researcher working</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=16" target="_blank">00:00:16.080</a></span> | <span class="t">to understand biological systems with AI. He completed his PhD in neuroscience here at</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=21" target="_blank">00:00:21.220</a></span> | <span class="t">Stanford, where he constructed self-supervised neural networks that incorporate biologically</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=26" target="_blank">00:00:26.000</a></span> | <span class="t">inspired constraints to explain the structure, function, and development of primary visual</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=31" target="_blank">00:00:31.000</a></span> | <span class="t">cortex. He's currently an ML scientist at NoTik, an AI-native biotech startup focused on</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=37" target="_blank">00:00:37.700</a></span> | <span class="t">curing cancer. In his work, he develops novel transformer model architectures and tasks that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=43" target="_blank">00:00:43.300</a></span> | <span class="t">learn from large multimodal data sets of patient tumor biology and applies these models to drug</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=49" target="_blank">00:00:49.580</a></span> | <span class="t">discovery. As a reminder, please fill out the attendance form, and if you're online, you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=55" target="_blank">00:00:55.000</a></span> | <span class="t">can ask any questions on Slido. With that, I'll let you take it away.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=60" target="_blank">00:01:00.000</a></span> | <span class="t">Awesome. Thank you for that introduction. I feel like that covered it all, so we're done here,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=64" target="_blank">00:01:04.000</a></span> | <span class="t">we can wrap it up. I'm going to talk today about kind of a mix of basic ML ideas about how to do</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=71" target="_blank">00:01:11.780</a></span> | <span class="t">multimodal learning and a little bit of the kind of research we're doing at NoTik, where I work now.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=78" target="_blank">00:01:18.000</a></span> | <span class="t">I'm going to talk really in three parts. You can tell I'm fond of alliteration here. I'll do multimodal</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=84" target="_blank">00:01:24.000</a></span> | <span class="t">model madness and tell you a little bit about ideas for incorporating information streams from multiple</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=89" target="_blank">00:01:29.000</a></span> | <span class="t">modalities. Then I'll focus more specifically on cancer. So in that first part, you know, if you're not</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=95" target="_blank">00:01:35.000</a></span> | <span class="t">interested in biology or cancer, one, I'll convince you otherwise, and two, you'll get a lot out of that first part, I hope.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=102" target="_blank">00:01:42.000</a></span> | <span class="t">And then I have a few random things I threw in at the end about work in progress that might be exciting.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=107" target="_blank">00:01:47.000</a></span> | <span class="t">So just to put it out there, my assumptions about this audience are that you're interested in research on</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=114" target="_blank">00:01:54.000</a></span> | <span class="t">transformers, given the course title, and specifically maybe novel transformer architectures that you haven't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=121" target="_blank">00:02:01.000</a></span> | <span class="t">encountered before. I'll assume that you're curious about how we're actually trying to use transformers</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=126" target="_blank">00:02:06.000</a></span> | <span class="t">outside of an academic context and to bring it into a clinically useful context. I will assume that you're kind of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=133" target="_blank">00:02:13.000</a></span> | <span class="t">familiar with the basics of transformers in machine learning, but not necessarily experts. There will be no</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=138" target="_blank">00:02:18.000</a></span> | <span class="t">pop quiz about equations or formulas or architecture diagrams today. And I will assume that you don't have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=144" target="_blank">00:02:24.000</a></span> | <span class="t">any familiarity with cancer immunology. So this will hopefully be friendly to people that have never really</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=149" target="_blank">00:02:29.000</a></span> | <span class="t">thought about that world. But I hope you all agree that curing cancer is a worthwhile thing to do. And I'll tell you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=154" target="_blank">00:02:34.000</a></span> | <span class="t">about the ways we're trying to bring these worlds together. What you should know about me, this was covered a bit in the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=160" target="_blank">00:02:40.000</a></span> | <span class="t">intro, but I did my PhD here at Stanford in neuroscience. So I'm actually not a cancer immunologist by</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=167" target="_blank">00:02:47.000</a></span> | <span class="t">training or background. I'm new to that field. My background is in computational neuroscience and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=173" target="_blank">00:02:53.000</a></span> | <span class="t">specifically visual cortex and how the primate visual system works. And when I was here, I mostly studied how we can</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=179" target="_blank">00:02:59.000</a></span> | <span class="t">build in biological constraints into, at the time, convolutional neural networks to make them more brain-like. And my broad interest is in understanding how complex biological systems get put together,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=192" target="_blank">00:03:12.000</a></span> | <span class="t">how they work when they're working, and how they don't work when they stop working. Before I go further, I should call out the other people that I work with at Noetic. We're a pretty small machine learning research team. But the stuff I'm going to show you today is due to their efforts as much as mine.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=208" target="_blank">00:03:28.000</a></span> | <span class="t">And I'll do my best to call out when they contributed specific things. But in case I forget, these are their names and faces.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=215" target="_blank">00:03:35.000</a></span> | <span class="t">Okay, and the last bit of housekeeping. This is kind of my plan for roughly the next hour. I might try to go a little faster to save time for questions at the end. I'm going to try to convince you primarily that there's a lot of really exciting and creative work to be done in multimodal machine learning, especially with transformers. And two, something that I became convinced of in the past year and a half, really, that cancer biology is just a really fantastic place to do that kind of research.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=242" target="_blank">00:04:02.000</a></span> | <span class="t">But the kind of data we're generating is really unique and something that I wouldn't have considered as a substrate to do basic ML research.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=249" target="_blank">00:04:09.000</a></span> | <span class="t">For bonus points, I'll also try to convince you that we're actually making progress on drug discovery for cancer at Noetic. And then the way that I normally prefer to give presentations is I'm super happy to have clarifying questions. So please, if something doesn't make sense, it's probably I forgot a sentence or a definition. Do let me know.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=269" target="_blank">00:04:29.000</a></span> | <span class="t">If you have larger philosophical questions about why we're all here, I'd also love to talk about those. But I'll try to save a little time at the end for the more freewheeling discussion.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=279" target="_blank">00:04:39.000</a></span> | <span class="t">Okay. So with that said, let me jump into my conceptual framework for thinking about multimodal model madness.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=286" target="_blank">00:04:46.000</a></span> | <span class="t">I think a unifying goal for much of AI, I won't say all of AI, but much of it is to build world models. And by that, I mean, a system that can simulate the future state of the world, conditioned on observations of the current state of the world, and also being able to simulate forward the effects that that system's actions will have on the future.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=309" target="_blank">00:05:09.000</a></span> | <span class="t">So this necessarily means you have the reality that is out there, you have sensors that collect information about that reality, you perceive it with your world model, and ideally, you're able to run a simulation of, okay, well, if I take this action, how will the world change in the future?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=325" target="_blank">00:05:25.000</a></span> | <span class="t">And that is a very powerful and generic framework for being able to reason about why the world is the way it is, how you should act, it obviously plays into planning and perception.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=335" target="_blank">00:05:35.000</a></span> | <span class="t">So one thing that I think is obvious is that the world is perceived at least by us and the world models in our heads in a multimodal way.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=344" target="_blank">00:05:44.000</a></span> | <span class="t">So, you know, you have visual modality that will tell you, for example, that this roundabout that I biked through many times on my way to lab is very dangerous and chaotic when people are running late to class and panicking.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=357" target="_blank">00:05:57.000</a></span> | <span class="t">I mean, but you're not just getting the visual information, you, of course, also have the audio modality, which comes from a different sensor, a microphone for a machine or ears for us, and you get an audio stream.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=369" target="_blank">00:06:09.000</a></span> | <span class="t">And often when you encounter video or image data, you could also have a text representation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=375" target="_blank">00:06:15.000</a></span> | <span class="t">Someone might have written a caption under their video saying, well, this roundabout is extremely chaotic and I'm going to try to avoid it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=382" target="_blank">00:06:22.000</a></span> | <span class="t">My thesis or my assumption is that the best world models are going to be able to incorporate all of these modalities and make decisions about what to do based not just on one of them, but all of them in a productive way.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=395" target="_blank">00:06:35.000</a></span> | <span class="t">So when you're running the world model in your head where you're perceiving the data from all of these modalities, you might have a question like, what will happen if I start walking forward into this roundabout?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=407" target="_blank">00:06:47.000</a></span> | <span class="t">And because you have the combination of maybe someone warned you ahead of time, you can hear what's going on, you can see what's going on, you're able to predict that you might get crashed into by somebody on a bike who's running late for class.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=421" target="_blank">00:07:01.000</a></span> | <span class="t">So the task of that model is effectively multimodal learning.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=425" target="_blank">00:07:05.000</a></span> | <span class="t">You need to know how to integrate these various information streams, which natively come in many different formats.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=431" target="_blank">00:07:11.000</a></span> | <span class="t">And you need to learn from them in a way that gives you the best chance of making accurate simulations of what's going to happen in the world.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=439" target="_blank">00:07:19.000</a></span> | <span class="t">I want to make a distinction that I think is important and will come up a couple of times in this talk about two reasons you might care about combining multimodal streams.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=448" target="_blank">00:07:28.000</a></span> | <span class="t">One of them is the idea that you could do multimodality as translation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=452" target="_blank">00:07:32.000</a></span> | <span class="t">You could say there's information in the visual domain, there's information in the audio domain.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=456" target="_blank">00:07:36.000</a></span> | <span class="t">And what I want to do is have a representation of the world that merges those things so that I've captured all of the information about one modality in the other modality.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=466" target="_blank">00:07:46.000</a></span> | <span class="t">The other thing that you might want to do is disambiguation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=470" target="_blank">00:07:50.000</a></span> | <span class="t">So there could be information that just is not available in one modality.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=474" target="_blank">00:07:54.000</a></span> | <span class="t">And so you kind of have a blind spot, both figuratively and literally here, where if you only had a camera, you wouldn't know everything about the state of the world.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=482" target="_blank">00:08:02.000</a></span> | <span class="t">And you're going to need to incorporate this other modality to get a full picture of what is happening in the world around you.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=488" target="_blank">00:08:08.000</a></span> | <span class="t">So I'll try to talk a little bit as I'm giving examples in the literature and in our work about whether I think we're doing translation or disambiguation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=500" target="_blank">00:08:20.000</a></span> | <span class="t">OK, so translation has a very familiar shape.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=504" target="_blank">00:08:24.000</a></span> | <span class="t">It's about capturing all of the information in one modality and another modality.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=509" target="_blank">00:08:29.000</a></span> | <span class="t">So when you're building, for example, a text to image system, what you want is for all of the information in the prompt that you're sending to the system to be reflected in the image.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=520" target="_blank">00:08:40.000</a></span> | <span class="t">You want to basically push these things together so that when I include a bit of information in the text stream, I want it reflected back to me in the image stream.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=531" target="_blank">00:08:51.000</a></span> | <span class="t">And when I talk about disambiguation, what I mean is that you need to piece together information that is only going to be available in one modality or another.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=539" target="_blank">00:08:59.000</a></span> | <span class="t">So for example, let's say you're approaching this building and you see everyone sprinting out of it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=544" target="_blank">00:09:04.000</a></span> | <span class="t">Now there's some ambiguity here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=546" target="_blank">00:09:06.000</a></span> | <span class="t">There are actually many reasons why people could be running out of the building.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=549" target="_blank">00:09:09.000</a></span> | <span class="t">Now, if you combine that with your sense of hearing, you might hear that there is a fire alarm going off inside.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=555" target="_blank">00:09:15.000</a></span> | <span class="t">And that rapidly disambiguates which state of the world you're in, that there's a fire and everyone's running away from it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=560" target="_blank">00:09:20.000</a></span> | <span class="t">But you could also have a second scenario where you hear an announcement that there's free boba for the first 10 students that get to it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=567" target="_blank">00:09:27.000</a></span> | <span class="t">And now everyone is sprinting out of the building and your world model should update, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=571" target="_blank">00:09:31.000</a></span> | <span class="t">If you want boba, you need to turn around and go one direction, maybe to where the announcement is saying to go.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=576" target="_blank">00:09:36.000</a></span> | <span class="t">If there's a fire, you know, you head to the nearest evacuation point or whatever it is we're all supposed to do if that happens.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=582" target="_blank">00:09:42.000</a></span> | <span class="t">OK, the next few slides will be kind of a tour that I will acknowledge is both brief and incomplete about how people have tried to incorporate multimodal streams in the literature.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=598" target="_blank">00:09:58.000</a></span> | <span class="t">And I'm really going to go over five things here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=601" target="_blank">00:10:01.000</a></span> | <span class="t">You don't have to memorize them now.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=602" target="_blank">00:10:02.000</a></span> | <span class="t">I'll go through them one by one.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=604" target="_blank">00:10:04.000</a></span> | <span class="t">But one thing that I want to call out is when people talk about multimodality or merging streams from one modality and another, there's often this nomenclature of whether you do an early fusion or late fusion.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=618" target="_blank">00:10:18.000</a></span> | <span class="t">And what people usually mean by that is are you bringing the modalities together kind of as soon as possible and then running your processing forward from there?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=626" target="_blank">00:10:26.000</a></span> | <span class="t">Or do you process each information stream separately and then bring them together at the very end when you actually need to make a decision about the state of the world and your actions in it?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=635" target="_blank">00:10:35.000</a></span> | <span class="t">So I have to admit that this framework doesn't help me think about this space too much, but I've tried to map onto these five things where I think they fall.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=645" target="_blank">00:10:45.000</a></span> | <span class="t">And there's kind of a range here from super early fusion to what I would think of as late fusion and everything in between.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=651" target="_blank">00:10:51.000</a></span> | <span class="t">So we'll see if you agree with me as I go through it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=654" target="_blank">00:10:54.000</a></span> | <span class="t">OK, the first thing I'm going to talk about is learning joint embedding spaces.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=658" target="_blank">00:10:58.000</a></span> | <span class="t">So a model that many of you might be familiar with is the clip approach for combining the modalities of image and text.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=666" target="_blank">00:11:06.000</a></span> | <span class="t">The primary idea here is to do contrastive learning where you have two encoders, an image encoder.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=673" target="_blank">00:11:13.000</a></span> | <span class="t">Let's see if my mouse shows up.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=675" target="_blank">00:11:15.000</a></span> | <span class="t">You have an image encoder that pushes images down into an embedding.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=679" target="_blank">00:11:19.000</a></span> | <span class="t">And you have a text encoder that takes corresponding captions and pushes those down into an embedding.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=685" target="_blank">00:11:25.000</a></span> | <span class="t">And the objective for the model is to make the embeddings for corresponding image and text pairs as similar as possible,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=693" target="_blank">00:11:33.000</a></span> | <span class="t">while pushing away the representations of mismatched pairs.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=696" target="_blank">00:11:36.000</a></span> | <span class="t">For example, the similarity between the embedding for image two and caption one should be as low as possible,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=703" target="_blank">00:11:43.000</a></span> | <span class="t">while increasing the similarity between the embedding for image one and text one.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=707" target="_blank">00:11:47.000</a></span> | <span class="t">And this is kind of explicitly trying to learn a single joint representation space,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=713" target="_blank">00:11:53.000</a></span> | <span class="t">where if you pick a point in that space, there should be kind of an image that corresponds to that point,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=718" target="_blank">00:11:58.000</a></span> | <span class="t">and also a text sample that also corresponds to that point.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=721" target="_blank">00:12:01.000</a></span> | <span class="t">And that way you can kind of translate between the text modality and the image modality.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=726" target="_blank">00:12:06.000</a></span> | <span class="t">You can see this explicitly in the paper.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=729" target="_blank">00:12:09.000</a></span> | <span class="t">On the right of this figure, you can see that what they're doing is taking an image,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=733" target="_blank">00:12:13.000</a></span> | <span class="t">figuring out what the embedding of that image is with the image encoder,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=736" target="_blank">00:12:16.000</a></span> | <span class="t">and then searching over many possible text inputs that will bring you as close as possible to that point in the representation space.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=745" target="_blank">00:12:25.000</a></span> | <span class="t">So I would consider this actually relatively late fusion,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=748" target="_blank">00:12:28.000</a></span> | <span class="t">because you're learning the image encoder pretty much separately from the text encoder.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=753" target="_blank">00:12:33.000</a></span> | <span class="t">Those don't interact until there's pressure through the loss function to make those embeddings as similar as possible.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=759" target="_blank">00:12:39.000</a></span> | <span class="t">I would say kind of like, I don't want to call it the grown-up version of this, but an expanded version of this is the image bind approach.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=769" target="_blank">00:12:49.000</a></span> | <span class="t">And if people aren't familiar with this, it is still a contrastive learning objective between modalities.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=774" target="_blank">00:12:54.000</a></span> | <span class="t">But instead of just doing images and captions, it uses images as kind of an anchor and learns pairwise contrastive between images and text, images and depth maps, images and audio.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=787" target="_blank">00:13:07.000</a></span> | <span class="t">And the underlying objective here is the same, that you want a single representation space where it doesn't matter which modality you came in through.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=794" target="_blank">00:13:14.000</a></span> | <span class="t">Once you know where you are, you can kind of back out what all the modalities should look like.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=798" target="_blank">00:13:18.000</a></span> | <span class="t">And in fact, in this paper, they do some interesting demonstrations of that space by doing things like embedding space arithmetic or prompting with one modality and seeing where you fall in that space on other modalities.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=812" target="_blank">00:13:32.000</a></span> | <span class="t">Okay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=815" target="_blank">00:13:35.000</a></span> | <span class="t">The other option that I have done occasionally but I think is not popular for technical reasons is super, super, super early fusion, where you can just directly concatenate raw inputs.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=825" target="_blank">00:13:45.000</a></span> | <span class="t">So consider if you had, for example, a 3D RGB color image, and you also had a depth image.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=832" target="_blank">00:13:52.000</a></span> | <span class="t">What you could do is just staple on the depth image as a fourth channel and then train a continent or train your vision transformer and pretend that you had four channels all along.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=840" target="_blank">00:14:00.000</a></span> | <span class="t">And that is a totally valid way to incorporate information from multiple modalities.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=845" target="_blank">00:14:05.000</a></span> | <span class="t">The reason that I think it is not super popular is it requires that there's something to concatenate on.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=851" target="_blank">00:14:11.000</a></span> | <span class="t">So people typically will first kind of project raw inputs down to tokens and then concatenate token streams, which I'll talk about in a second.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=858" target="_blank">00:14:18.000</a></span> | <span class="t">But if you want to jump really, really, really to the front of that encoding stack, sometimes you have your height and width dimensions on images lineup and you can just concatenate directly.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=868" target="_blank">00:14:28.000</a></span> | <span class="t">Okay, the third option that you could do is cross attention.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=874" target="_blank">00:14:34.000</a></span> | <span class="t">So now we're getting much more transformer specific.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=877" target="_blank">00:14:37.000</a></span> | <span class="t">The idea here is you have two token streams, one from each modality.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=882" target="_blank">00:14:42.000</a></span> | <span class="t">In the example from the Lou et al 2019 paper, you have one token stream that comes from images, and then you also have a second token stream that comes from text.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=890" target="_blank">00:14:50.000</a></span> | <span class="t">So those are your two modalities.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=892" target="_blank">00:14:52.000</a></span> | <span class="t">You can have as many self attention layers as you want within each stream.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=897" target="_blank">00:14:57.000</a></span> | <span class="t">But then you can also have these cross attention layers, which are shown here in the diagram, where you're basically giving each modality the chance to be kind of the primary.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=908" target="_blank">00:15:08.000</a></span> | <span class="t">The primary will generate the queries in the attention operation, and the secondary stream will provide the keys and values.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=915" target="_blank">00:15:15.000</a></span> | <span class="t">And because that is an asymmetric procedure, you will often see these cross attention layers duplicated on either side of the processing stream.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=926" target="_blank">00:15:26.000</a></span> | <span class="t">So that in one example, the images get to provide the queries, and in the other side of it, the text stream gets to provide the queries.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=934" target="_blank">00:15:34.000</a></span> | <span class="t">I broke this out just because when I was first implementing this, it was helpful to think about.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=939" target="_blank">00:15:39.000</a></span> | <span class="t">But if you look at what is actually happening in an attention layer, you have your input x, you will have a linear projection to your queries q, your keys k, and your values v.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=952" target="_blank">00:15:52.000</a></span> | <span class="t">And then those go into your scale dot product attention operator, and then linear projection and dropout.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=959" target="_blank">00:15:59.000</a></span> | <span class="t">All you're doing in a cross attention layer is you're taking input from another stream y, and you're using that to generate the keys and values.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=966" target="_blank">00:16:06.000</a></span> | <span class="t">But everything else stays as is.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=969" target="_blank">00:16:09.000</a></span> | <span class="t">This gives you a chance to have the two information streams mingle somewhere in the middle of the network.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=974" target="_blank">00:16:14.000</a></span> | <span class="t">So I would call this intermediate fusion, depending which layers you're doing it in.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=980" target="_blank">00:16:20.000</a></span> | <span class="t">Okay, the fourth option which I alluded to when I was talking about concatenation is you can just slap tokens onto a stream.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=987" target="_blank">00:16:27.000</a></span> | <span class="t">I think one thing that has really resonated with me is, as we move into using transformers in more and more domains, the fact that everything is just tokens all the way down makes it really easy to add more tokens to a sequence, and they can come from other modalities if you'd like.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1002" target="_blank">00:16:42.000</a></span> | <span class="t">One way that this happens all the time, but I think we don't really think of it as multimodal learning is, if you have, for example, a vision transformer, you might add on, in this case you're prepending a class token that really is like, you could think of it as text, I guess, because the class is literally a text label.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1021" target="_blank">00:17:01.000</a></span> | <span class="t">But you have an embedding for the text, and that just goes and participates in the stream of tokens, and participates in the self-attention operations, and there you go, you've integrated a text label with your image data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1037" target="_blank">00:17:17.000</a></span> | <span class="t">The other place you see this is actually in the Dolly1 implementation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1041" target="_blank">00:17:21.000</a></span> | <span class="t">So the way that this worked is you have text tokens, which are captions for images.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1046" target="_blank">00:17:26.000</a></span> | <span class="t">You also have image tokens, which in this case come from learning a code book with a discrete VAE, and you concatenate on the image tokens after the text tokens, and then at inference time you can provide only the text tokens and autoregressively predict what the image tokens should be.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1062" target="_blank">00:17:42.000</a></span> | <span class="t">So again, you've solved the multimodality problem by first boiling everything down into token space, and then once they're tokens, your decoder doesn't need to know which ones are image and which ones are text.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1073" target="_blank">00:17:53.000</a></span> | <span class="t">And finally, something that we have increasingly been using at Noetic is this adaptive layer norm idea.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1081" target="_blank">00:18:01.000</a></span> | <span class="t">So I really like this figure. This is from the diffusion transformer paper.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1085" target="_blank">00:18:05.000</a></span> | <span class="t">What I like about it is that they also talk about two other things I've already mentioned.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1089" target="_blank">00:18:09.000</a></span> | <span class="t">The middle column there shows how you might do this with cross-attention.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1093" target="_blank">00:18:13.000</a></span> | <span class="t">I guess I should back up and say, in the diffusion transformer case, the extra modality you're feeding in is a conditioning token.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1101" target="_blank">00:18:21.000</a></span> | <span class="t">You want to guide the diffusion in a particular direction.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1105" target="_blank">00:18:25.000</a></span> | <span class="t">So you have some text label.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1107" target="_blank">00:18:27.000</a></span> | <span class="t">And you want that to interact with the main transformer block that is going to be doing the diffusion.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1113" target="_blank">00:18:33.000</a></span> | <span class="t">So you could do that with cross-attention, which is shown here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1117" target="_blank">00:18:37.000</a></span> | <span class="t">You could do it with what is called in this paper in-context conditioning, which is just the concatenation approach.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1123" target="_blank">00:18:43.000</a></span> | <span class="t">You can actually see that here, concatenate on the sequence dimension, as we just saw.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1129" target="_blank">00:18:49.000</a></span> | <span class="t">But the thing introduced in this paper, which is very parameter efficient and cool that it works, is you can take that conditioning information and use effectively a linear layer to push it into small scalar parameters.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1143" target="_blank">00:19:03.000</a></span> | <span class="t">So here what they're doing is predicting an alpha, beta, and a gamma.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1147" target="_blank">00:19:07.000</a></span> | <span class="t">They actually predict two triplets of alpha, beta, gamma.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1149" target="_blank">00:19:09.000</a></span> | <span class="t">And use those in the layer norm operation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1151" target="_blank">00:19:11.000</a></span> | <span class="t">So this is just kind of another way, as far as I understand, to push information from one modality and have it steer or influence or guide what is happening in the processing of the primary sensory stream.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1165" target="_blank">00:19:25.000</a></span> | <span class="t">I have a little code snippet here, probably not worth lingering on, but it's just striking how straightforward this approach is.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1171" target="_blank">00:19:31.000</a></span> | <span class="t">But really all that's happening is you have a single linear layer in here hiding after a non-linearity.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1177" target="_blank">00:19:37.000</a></span> | <span class="t">And then you're using that to determine the parameters for shifting and scaling operations in layer norm.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1183" target="_blank">00:19:43.000</a></span> | <span class="t">And this turns out to be a very effective way to get information about a text-based conditioning label into the image domain.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1191" target="_blank">00:19:51.000</a></span> | <span class="t">Okay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1192" target="_blank">00:19:52.000</a></span> | <span class="t">Okay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1193" target="_blank">00:19:53.000</a></span> | <span class="t">This is a pretty good place to pause and see if anyone has any questions before I move on.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1198" target="_blank">00:19:58.000</a></span> | <span class="t">Yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1199" target="_blank">00:19:59.000</a></span> | <span class="t">Yeah, particularly when we're talking about cross-attention.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1204" target="_blank">00:20:04.000</a></span> | <span class="t">Can cross-attention, one could be used as the other in the layer norm as a linear reference?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1216" target="_blank">00:20:16.000</a></span> | <span class="t">Yeah, if I understand correctly, I think you can.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1223" target="_blank">00:20:23.000</a></span> | <span class="t">And the thing that you run into here that's both a blessing and a curse is like you can do pretty much anything.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1229" target="_blank">00:20:29.000</a></span> | <span class="t">Like at some point if you think that there's more useful processing to do before you derive these layer norm shift and scale parameters, this doesn't have to be a linear layer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1238" target="_blank">00:20:38.000</a></span> | <span class="t">It can be an arbitrarily complicated function.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1240" target="_blank">00:20:40.000</a></span> | <span class="t">It could be a cross-attention layer that is using the information from two streams that way and then also doing the layer norm.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1249" target="_blank">00:20:49.000</a></span> | <span class="t">The question is, is it parameter efficient?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1251" target="_blank">00:20:51.000</a></span> | <span class="t">Does it work empirically?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1252" target="_blank">00:20:52.000</a></span> | <span class="t">And do you have a good principled reason to do it?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1255" target="_blank">00:20:55.000</a></span> | <span class="t">And I think often that third thing is missing in a lot of these approaches, which is just like, yeah, it seems to work.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1261" target="_blank">00:21:01.000</a></span> | <span class="t">So we're going to roll with it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1263" target="_blank">00:21:03.000</a></span> | <span class="t">Yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1264" target="_blank">00:21:04.000</a></span> | <span class="t">Yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1265" target="_blank">00:21:05.000</a></span> | <span class="t">Can you speak in a complex level, maybe the big consumption level, why in the cancer research</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1275" target="_blank">00:21:15.000</a></span> | <span class="t">space that transformer is important in the sense that does it combine, let's say image of a patient,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1281" target="_blank">00:21:21.000</a></span> | <span class="t">let's say biopsy and maybe the text description of this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1286" target="_blank">00:21:26.000</a></span> | <span class="t">So what makes a transformer so rather than for cancer research in a different context?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1292" target="_blank">00:21:32.000</a></span> | <span class="t">Yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1293" target="_blank">00:21:33.000</a></span> | <span class="t">So the question is why are transformers important for cancer research?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1296" target="_blank">00:21:36.000</a></span> | <span class="t">And I think the answers could have basically two shapes.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1301" target="_blank">00:21:41.000</a></span> | <span class="t">One of them is if you format your data and your task properly, I think transformers are both simpler</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1307" target="_blank">00:21:47.000</a></span> | <span class="t">to scale and empirically scale better than other approaches.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1311" target="_blank">00:21:51.000</a></span> | <span class="t">The second reason I would say is not all data modalities are amenable to other architectures.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1316" target="_blank">00:21:56.000</a></span> | <span class="t">So sometimes you do have image data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1318" target="_blank">00:21:58.000</a></span> | <span class="t">And I'll show examples of that in a second.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1320" target="_blank">00:22:00.000</a></span> | <span class="t">Sometimes you have data that looks a lot more like text.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1322" target="_blank">00:22:02.000</a></span> | <span class="t">And so you want to use the approaches that have been successful in modeling text.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1326" target="_blank">00:22:06.000</a></span> | <span class="t">And then the third thing I would say is that specifically for multimodal learning, it's extremely helpful</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1332" target="_blank">00:22:12.000</a></span> | <span class="t">to be able to push everything into token soup and bring it back together however you want.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1337" target="_blank">00:22:17.000</a></span> | <span class="t">So it turns out the transformers are just a very good substrate for combining kind of arbitrarily creative ideas</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1342" target="_blank">00:22:22.000</a></span> | <span class="t">about how to integrate various measurements.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1345" target="_blank">00:22:25.000</a></span> | <span class="t">But in a couple of slides, I'll show exactly what those measurements are.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1347" target="_blank">00:22:27.000</a></span> | <span class="t">And I'll walk through architectures we're using to learn from patient data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1351" target="_blank">00:22:31.000</a></span> | <span class="t">Cool.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1355" target="_blank">00:22:35.000</a></span> | <span class="t">OK, I will go ahead and do that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1358" target="_blank">00:22:38.000</a></span> | <span class="t">OK, so as a reminder, this is kind of my mental model for how things work in the macroscopic world.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1364" target="_blank">00:22:44.000</a></span> | <span class="t">And I think the analogy in the microscopic world is now we want to understand the world of cancer biology.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1371" target="_blank">00:22:51.000</a></span> | <span class="t">And the queries that we want to pose to this world model are not things like what happens if I walk into a roundabout.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1378" target="_blank">00:22:58.000</a></span> | <span class="t">There are things like what will happen if I give this drug to this patient?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1382" target="_blank">00:23:02.000</a></span> | <span class="t">Will the tumor go away or not?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1384" target="_blank">00:23:04.000</a></span> | <span class="t">And you want effectively a simulator that can help you answer those questions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1388" target="_blank">00:23:08.000</a></span> | <span class="t">I will fill in the question marks momentarily about what these sensors are and what the data looks like.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1393" target="_blank">00:23:13.000</a></span> | <span class="t">But I want to put this up front as like our goal is to take this world modeling approach and to build a system that we can use to simulate answers to clinically relevant questions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1404" target="_blank">00:23:24.000</a></span> | <span class="t">OK, this is my like crash course in cancer immunology.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1407" target="_blank">00:23:27.000</a></span> | <span class="t">I was talking to a card-carrying immunologist this morning and apologized for trying to boil down their entire career into a few bullet points.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1415" target="_blank">00:23:35.000</a></span> | <span class="t">So please know that this is a gross simplification.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1419" target="_blank">00:23:39.000</a></span> | <span class="t">The basic idea behind cancer immunotherapy is that we know that in some cases, your immune system can detect and destroy cancers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1428" target="_blank">00:23:48.000</a></span> | <span class="t">But tumors are sneaky and they evolve to either hide from the immune system or to actively suppress the immune system so that the immune system can't do its job and destroy the tumor.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1440" target="_blank">00:24:00.000</a></span> | <span class="t">The idea behind immunotherapy as a type of treatment is you want to basically get rid of those immune evasion mechanisms or the immune suppression mechanisms and help reactivate immune cells to help them do their job.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1452" target="_blank">00:24:12.000</a></span> | <span class="t">So you already have the machinery in your body to fight cancer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1456" target="_blank">00:24:16.000</a></span> | <span class="t">It's just losing that fight and you want to find a way to tip the scales so that the immune system can start winning.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1461" target="_blank">00:24:21.000</a></span> | <span class="t">The way that we do that could have two shapes and we're interested in both of them at Noetic.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1467" target="_blank">00:24:27.000</a></span> | <span class="t">One of them is you just find new drugs that no one has thought of before.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1471" target="_blank">00:24:31.000</a></span> | <span class="t">But the other thing that I was interested to learn when I started working in this space is actually there's a lot of drugs that have progressed in various clinical trials</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1480" target="_blank">00:24:40.000</a></span> | <span class="t">and they fail because there's just a mixed response.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1483" target="_blank">00:24:43.000</a></span> | <span class="t">For some patients, they work really well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1485" target="_blank">00:24:45.000</a></span> | <span class="t">For other patients, they don't work at all.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1487" target="_blank">00:24:47.000</a></span> | <span class="t">And we don't have the right way of targeting the right drug to the right patient.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1491" target="_blank">00:24:51.000</a></span> | <span class="t">So for both of these, the thing you would want is, again, a world model that can help you simulate the answer to the question,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1498" target="_blank">00:24:58.000</a></span> | <span class="t">given what you know about the world of this patient's biology, if I take this action, does the tumor go away or not?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1505" target="_blank">00:25:05.000</a></span> | <span class="t">OK, so here's the oversimplified schematic again of you want something that tells you given a patient's data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1512" target="_blank">00:25:12.000</a></span> | <span class="t">You want to be able to simulate kind of rapidly a bunch of different treatment options and get a reasonable prediction of whether they'll be effective or ineffective.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1520" target="_blank">00:25:20.000</a></span> | <span class="t">So our approach to this is, first, we need to deploy our sensors and collect a bunch of data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1527" target="_blank">00:25:27.000</a></span> | <span class="t">This is a video of our lab up in South San Francisco in action.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1532" target="_blank">00:25:32.000</a></span> | <span class="t">So what we do is we get human lung tumor specimens and a few other tumors from a few other organs.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1538" target="_blank">00:25:38.000</a></span> | <span class="t">These numbers are also a little bit outdated at this point.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1541" target="_blank">00:25:41.000</a></span> | <span class="t">But we source our tissue blocks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1543" target="_blank">00:25:43.000</a></span> | <span class="t">We have a lab that processes them.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1545" target="_blank">00:25:45.000</a></span> | <span class="t">We punch out these cores from the tissue that are about one millimeter in diameter.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1551" target="_blank">00:25:51.000</a></span> | <span class="t">So they're very tiny.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1552" target="_blank">00:25:52.000</a></span> | <span class="t">But I'll show you in a second that there's an unthinkable amount of data packaged in that small one millimeter core.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1558" target="_blank">00:25:58.000</a></span> | <span class="t">And then we will basically put those through four different data processing pipelines that I'll show you in a second.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1569" target="_blank">00:26:09.000</a></span> | <span class="t">One of those pipelines, which is a fairly common one to run on tissue samples, is we collect these H&E images.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1576" target="_blank">00:26:16.000</a></span> | <span class="t">H&E has the benefit of being relatively cheap and easy to acquire, and a lot of people have it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1581" target="_blank">00:26:21.000</a></span> | <span class="t">So most hospitals and research centers are sitting on a ton of H&E.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1585" target="_blank">00:26:25.000</a></span> | <span class="t">There's a lot of public H&E.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1587" target="_blank">00:26:27.000</a></span> | <span class="t">And if you want to do machine learning on biological data, it basically looks already like images.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1592" target="_blank">00:26:32.000</a></span> | <span class="t">So you kind of know what to do with it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1593" target="_blank">00:26:33.000</a></span> | <span class="t">It's like a three-channel RGB image that you can work with.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1596" target="_blank">00:26:36.000</a></span> | <span class="t">Technically, it's like a two-channel thing because there's two elements at the same, but you can decovalve them if you want.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1602" target="_blank">00:26:42.000</a></span> | <span class="t">It's not super relevant to the rest of this talk.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1604" target="_blank">00:26:44.000</a></span> | <span class="t">The other thing that we do is, instead of just looking at the gross morphology, which is what you mostly get out of this H&E stain, is we have a 16-plex protein immunofluorescence panel.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1617" target="_blank">00:26:57.000</a></span> | <span class="t">So that means that we're able to detect proteins, 16 different kinds of proteins, by designing fluorescent antibodies that bind to them.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1625" target="_blank">00:27:05.000</a></span> | <span class="t">And we can see the composition of this tissue.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1629" target="_blank">00:27:09.000</a></span> | <span class="t">So in this pseudo-color map, what I'm showing is green are T cells, which are part of your immune system.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1636" target="_blank">00:27:16.000</a></span> | <span class="t">Blue is B cells, which is another part of your immune system.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1639" target="_blank">00:27:19.000</a></span> | <span class="t">And then the red blob in the middle is a tumor.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1642" target="_blank">00:27:22.000</a></span> | <span class="t">We're able to go ask what's actually in the sample.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1645" target="_blank">00:27:25.000</a></span> | <span class="t">This is kind of like an RGB image, but with 16 channels instead of three channels.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1651" target="_blank">00:27:31.000</a></span> | <span class="t">The other thing to call out here is, you'll notice that the white box has moved with us.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1655" target="_blank">00:27:35.000</a></span> | <span class="t">So these are spatially aligned samples.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1657" target="_blank">00:27:37.000</a></span> | <span class="t">And if you remember what I was saying about RGB in depth, you might already be thinking, oh, well, you could just staple these together in the channel dimension and do multimodal learning that way.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1668" target="_blank">00:27:48.000</a></span> | <span class="t">One of the cooler kinds of data that we have is spatial transcriptomics.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1672" target="_blank">00:27:52.000</a></span> | <span class="t">So on, again, these exact same samples, you'll see the white boxes moving with us again.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1677" target="_blank">00:27:57.000</a></span> | <span class="t">We are able to detect in a 1,000-plex panel.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1681" target="_blank">00:28:01.000</a></span> | <span class="t">So we're looking for 1,000 different genes worth of RNA transcripts.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1684" target="_blank">00:28:04.000</a></span> | <span class="t">And those transcripts are spatially localized.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1687" target="_blank">00:28:07.000</a></span> | <span class="t">So we don't have to boil down the sample into soup before feeding it in and asking which RNA is in the sample.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1693" target="_blank">00:28:13.000</a></span> | <span class="t">We get an xy coordinate and, well, it's really like an xy by gene tuple that tells us this gene has RNA expressed at this location.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1703" target="_blank">00:28:23.000</a></span> | <span class="t">And you'll get anywhere between a few thousand to a few million such transcripts in just one millimeter of data, which I'll try to show in a second if it doesn't crash my computer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1714" target="_blank">00:28:34.000</a></span> | <span class="t">So this data is very rich.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1716" target="_blank">00:28:36.000</a></span> | <span class="t">It's also very complicated.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1717" target="_blank">00:28:37.000</a></span> | <span class="t">It's also very expensive.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1718" target="_blank">00:28:38.000</a></span> | <span class="t">So collecting this data is the hardest, and it's the thing that the fewest people have.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1724" target="_blank">00:28:44.000</a></span> | <span class="t">In fact, on one of the previous slides, I had mentioned that we at Noetic estimate that we have well over 1% and probably over 2% of, like, the world's spatial transcriptomics data using this platform, which is called Cosmix.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1737" target="_blank">00:28:57.000</a></span> | <span class="t">Okay, and the last thing we do is genetic sequencing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1741" target="_blank">00:29:01.000</a></span> | <span class="t">We do whole exome sequencing of the patient's data so we know if they have genetic mutations that could be relevant to understanding their tumor biology.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1748" target="_blank">00:29:08.000</a></span> | <span class="t">Okay, so this is the data that lives out there.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1751" target="_blank">00:29:11.000</a></span> | <span class="t">And the question is, how are we going to learn from it?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1754" target="_blank">00:29:14.000</a></span> | <span class="t">Before we do that, I just want to talk a little bit more about the spatial transcriptomics data because it's so cool.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1760" target="_blank">00:29:20.000</a></span> | <span class="t">So these are what the raw transcripts look like in 3D.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1765" target="_blank">00:29:25.000</a></span> | <span class="t">We do actually detect them in X, Y, and Z, but the Z plane is 4 micrometers, 4 microns.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1772" target="_blank">00:29:32.000</a></span> | <span class="t">So it's very, very thin.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1773" target="_blank">00:29:33.000</a></span> | <span class="t">It's effectively just X, Y.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1775" target="_blank">00:29:35.000</a></span> | <span class="t">And the colors here are different genes.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1778" target="_blank">00:29:38.000</a></span> | <span class="t">I'm going to try to run a live demo of just what this raw data looks like because it's a lot of fun to play around with.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1786" target="_blank">00:29:46.000</a></span> | <span class="t">But there's an overwhelming amount of data jammed into this one millimeter diameter chunk of tissue.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1813" target="_blank">00:30:13.000</a></span> | <span class="t">I promise this computer is not underpowered.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1815" target="_blank">00:30:15.000</a></span> | <span class="t">It's just loading 11 million points.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1817" target="_blank">00:30:17.000</a></span> | <span class="t">So this is what it looks like at the micro level.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1820" target="_blank">00:30:20.000</a></span> | <span class="t">You have this incredibly rich tissue.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1822" target="_blank">00:30:22.000</a></span> | <span class="t">And we are actually showing here one of the first whole transcriptome runs we've been able to do.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1829" target="_blank">00:30:29.000</a></span> | <span class="t">So instead of detecting a thousand gene panel, we're able to try to detect over 18,000 genes.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1834" target="_blank">00:30:34.000</a></span> | <span class="t">And we ran out of colors after the first 20 or so, but you'll have to take my word for it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1840" target="_blank">00:30:40.000</a></span> | <span class="t">So what are the colors denote here?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1842" target="_blank">00:30:42.000</a></span> | <span class="t">The colors are different genes.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1843" target="_blank">00:30:43.000</a></span> | <span class="t">Different genes?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1844" target="_blank">00:30:44.000</a></span> | <span class="t">Yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1845" target="_blank">00:30:45.000</a></span> | <span class="t">Okay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1846" target="_blank">00:30:46.000</a></span> | <span class="t">I will spare my computer from trying to render that for too long.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1851" target="_blank">00:30:51.000</a></span> | <span class="t">Here's another example from our thousandplex panel just to give you another sense of the kind of data that we work with.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1858" target="_blank">00:30:58.000</a></span> | <span class="t">So at the local scale, now we're talking about tens of microns.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1863" target="_blank">00:31:03.000</a></span> | <span class="t">You have these highly localized reads of what RNA is being transcribed where in the cell.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1869" target="_blank">00:31:09.000</a></span> | <span class="t">And I'll try to render the labels.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1871" target="_blank">00:31:11.000</a></span> | <span class="t">But again, the plotting software struggles a bit with it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1875" target="_blank">00:31:15.000</a></span> | <span class="t">Okay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1876" target="_blank">00:31:16.000</a></span> | <span class="t">That's kind of an aside.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1877" target="_blank">00:31:17.000</a></span> | <span class="t">I just think those data are so cool that I like showing it whenever I have the chance.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1882" target="_blank">00:31:22.000</a></span> | <span class="t">Okay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1883" target="_blank">00:31:23.000</a></span> | <span class="t">So let me talk about how we're trying to model this data and the kinds of world models that we're trying to construct.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1888" target="_blank">00:31:28.000</a></span> | <span class="t">So we have thousands, at this point over 10,000 cores from different patients.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1895" target="_blank">00:31:35.000</a></span> | <span class="t">Each of those cores is one of those one millimeter diameter circles.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1898" target="_blank">00:31:38.000</a></span> | <span class="t">In each core, there will be thousands of cells.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1901" target="_blank">00:31:41.000</a></span> | <span class="t">And we can assign these transcripts to cells with a segmentation algorithm to say, in a given cell, you can count up, you know, how often do you get a read of this gene, CD3E, within the borders of a cell.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1912" target="_blank">00:31:52.000</a></span> | <span class="t">And so the data you get is effectively tabular.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1915" target="_blank">00:31:55.000</a></span> | <span class="t">It's also very, very sparse.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1917" target="_blank">00:31:57.000</a></span> | <span class="t">Most cells don't express most genes.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1919" target="_blank">00:31:59.000</a></span> | <span class="t">And we're going to try to model this so that we can simulate things and ask, well, does this tilt the tumor immune microenvironment in a more or less favorable direction?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1931" target="_blank">00:32:11.000</a></span> | <span class="t">Our general approach is to use masked autoencoders.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1934" target="_blank">00:32:14.000</a></span> | <span class="t">This ends up being a transformer backbone.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1937" target="_blank">00:32:17.000</a></span> | <span class="t">The thing worth calling out is that it's not autoregressive transformer processing, so there's no real sequence to the genes to care about.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1946" target="_blank">00:32:26.000</a></span> | <span class="t">It's more like masked language modeling, where what we'll do is take the input, we'll mask out some of the tokens, and we predict the tokens we mask out.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1954" target="_blank">00:32:34.000</a></span> | <span class="t">I'll show on the next slide what that actually looks like operationally.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1958" target="_blank">00:32:38.000</a></span> | <span class="t">So if this is your input, imagine this has 1,000 rows, soon 18,000 rows.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1963" target="_blank">00:32:43.000</a></span> | <span class="t">You have every gene and how often it was detected in a single cell.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1966" target="_blank">00:32:46.000</a></span> | <span class="t">So the input is one cell here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1968" target="_blank">00:32:48.000</a></span> | <span class="t">We have a tokenization process that assigns a token to each combination of gene identity and the expression level.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1978" target="_blank">00:32:58.000</a></span> | <span class="t">So you're encoding both how much of that thing you have and also what the identity of it is.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1983" target="_blank">00:33:03.000</a></span> | <span class="t">And then we do partial masking.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1987" target="_blank">00:33:07.000</a></span> | <span class="t">In our work, we tend to do pretty aggressive masking.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1990" target="_blank">00:33:10.000</a></span> | <span class="t">So the number you should have in your head is like north of 90% of the tokens are removed and replaced with a learned mask token.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=1998" target="_blank">00:33:18.000</a></span> | <span class="t">So almost everything is removed from the sample.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=2002" target="_blank">00:33:22.000</a></span> | <span class="t">And the job of the model is to predict the things we removed.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=2006" target="_blank">00:33:26.000</a></span> | <span class="t">This is intentionally a very hard task.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=2008" target="_blank">00:33:28.000</a></span> | <span class="t">We want it to be basically as difficult as possible while still learning the biology.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=2013" target="_blank">00:33:33.000</a></span> | <span class="t">Because if you are able to do this, what it means is that you're able to use a very small amount of context to infer,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=2021" target="_blank">00:33:41.000</a></span> | <span class="t">OK, well, I see I have a lot of CD3.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=2023" target="_blank">00:33:43.000</a></span> | <span class="t">I don't get to see how much CD8 I have because that got masked out in the masking process.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=2028" target="_blank">00:33:48.000</a></span> | <span class="t">So I have to guess based on my knowledge of biology from learning from this dataset, is it likely that I express CD8, which would make me a cytotoxic or a killer T cell, if I express CD3, which is kind of a more generic marker for T cells that may or may not be killer T cells.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=2047" target="_blank">00:34:07.000</a></span> | <span class="t">So at inference time, what you can do with this kind of model is provide a couple of things that are not masked, like two tokens worth of information.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=2057" target="_blank">00:34:17.000</a></span> | <span class="t">And then staple on a bunch of mask tokens, you know, the other 998 genes in this panel.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=2062" target="_blank">00:34:22.000</a></span> | <span class="t">And then you can predict everything that's masked out.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=2065" target="_blank">00:34:25.000</a></span> | <span class="t">So you can say, given that you're conditioned on knowing you're a T cell and you're not a tumor, what else do you think is happening?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=2072" target="_blank">00:34:32.000</a></span> | <span class="t">And, you know, if you've learned from this huge dataset, you might think maybe the best you can do is say, well, OK, what does the average T cell look like?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=2080" target="_blank">00:34:40.000</a></span> | <span class="t">Because all I've told you is you have this T cell marker, CD3E, and you're definitely not a tumor cell because you're expressing none of this keratin marker.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=2087" target="_blank">00:34:47.000</a></span> | <span class="t">I don't want to say that this model is boring.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=2090" target="_blank">00:34:50.000</a></span> | <span class="t">There's a lot of interesting stuff you can do with it, but it's distinctly not multimodal.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=2094" target="_blank">00:34:54.000</a></span> | <span class="t">And I promised you multimodality.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=2095" target="_blank">00:34:55.000</a></span> | <span class="t">So I'm going to keep going with this background in mind and tell you about one kind of model that we have gotten a lot of leverage out of, which is to say, this task is very hard and there's a lot of ambiguity.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=2108" target="_blank">00:35:08.000</a></span> | <span class="t">And if you remember, I was talking about multimodality as a way to resolve ambiguity in predictions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=2113" target="_blank">00:35:13.000</a></span> | <span class="t">So one thing that we do is we will take the local spatial neighborhood of a cell, the one we're trying to make predictions about.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=2120" target="_blank">00:35:20.000</a></span> | <span class="t">We'll ask, who are your eight nearest neighbors?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=2123" target="_blank">00:35:23.000</a></span> | <span class="t">And we will force the information about what those eight nearest neighbors are expressing through a bottleneck.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=2129" target="_blank">00:35:29.000</a></span> | <span class="t">That bottleneck is just another transformer, but it is required to boil down basically all of that rich spatial context about what's happening in the local environment down into one token.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=2141" target="_blank">00:35:41.000</a></span> | <span class="t">And then we use this adaptive layer norm approach or we've tried the append tokens thing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=2147" target="_blank">00:35:47.000</a></span> | <span class="t">We've tried cross attention.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=2148" target="_blank">00:35:48.000</a></span> | <span class="t">They all seem to work.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=2149" target="_blank">00:35:49.000</a></span> | <span class="t">Some are just more efficient than others.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=2151" target="_blank">00:35:51.000</a></span> | <span class="t">And that feeds in as an additional input to what we refer to as the backbone.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=2157" target="_blank">00:35:57.000</a></span> | <span class="t">So now, if you have a prompt in your training that's ambiguous, you have a little bit of help because you might say, well, I don't know if I'm a killer T cell or not, but seven of my neighbors are killer T cells.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=2170" target="_blank">00:36:10.000</a></span> | <span class="t">And maybe I'm also a killer T cell.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=2171" target="_blank">00:36:11.000</a></span> | <span class="t">And that should help you do a little bit better.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=2173" target="_blank">00:36:13.000</a></span> | <span class="t">And the thing that I should have added here and forgot is showing that if you're just monitoring like the training loss of the backbone, it really likes having the spatial context.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=2182" target="_blank">00:36:22.000</a></span> | <span class="t">It helps quite a lot in lowering that loss curve.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=2188" target="_blank">00:36:28.000</a></span> | <span class="t">Once you have a model like that, you can do very large scale inference with it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=2193" target="_blank">00:36:33.000</a></span> | <span class="t">So what we will do is take a real patient sample.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=2198" target="_blank">00:36:38.000</a></span> | <span class="t">We'll pick a location in that sample.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=2200" target="_blank">00:36:40.000</a></span> | <span class="t">Look up the nearest neighbors.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=2202" target="_blank">00:36:42.000</a></span> | <span class="t">And then we will ask the model to do inference with a specified prompt.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=2207" target="_blank">00:36:47.000</a></span> | <span class="t">In this case, I'm telling it, you are a killer T cell.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=2210" target="_blank">00:36:50.000</a></span> | <span class="t">You express these markers for regular T cells and for cytotoxicity.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=2214" target="_blank">00:36:54.000</a></span> | <span class="t">And I'm asking it to predict the other 990 plus genes conditioned on the spatial context.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=2221" target="_blank">00:37:01.000</a></span> | <span class="t">And on the right, I'm going to slowly build up at each position here what the model thinks is happening for one such gene, IL-7R.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=2230" target="_blank">00:37:10.000</a></span> | <span class="t">And you will already get a sense once this starts to speed up of how many simulations we're doing here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=2237" target="_blank">00:37:17.000</a></span> | <span class="t">As of last week, I think we had run on the order of 6 billion virtual cell simulations like this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=2243" target="_blank">00:37:23.000</a></span> | <span class="t">So we are able to ask basically arbitrary queries about what is happening in patient tissue by saying, hypothetically, if this cell type were in this location in the patient tissue, what do I think it's doing?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=2258" target="_blank">00:37:38.000</a></span> | <span class="t">And to close the loop in a second, I'll tell you about how you can do counterfactual simulations that will help you think about potential drugs.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=2266" target="_blank">00:37:46.000</a></span> | <span class="t">But for now, just appreciating that once you have this additional input stream to the model, you can pull out a lot of richness about what it's learned, about how spatial context affects what is happening at the single cell level.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=2279" target="_blank">00:37:59.000</a></span> | <span class="t">So we built a little web UI that lets you explore some of this data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=2286" target="_blank">00:38:06.000</a></span> | <span class="t">I won't spend too long on it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=2288" target="_blank">00:38:08.000</a></span> | <span class="t">But it lets you kind of pick a cell type, fly around a real patient sample, see what the cell identities of those nearest neighbors is, and then see how the model's prediction of different genes changes as you move around the space.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=2303" target="_blank">00:38:23.000</a></span> | <span class="t">So I could spend all day kind of mucking around in this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=2306" target="_blank">00:38:26.000</a></span> | <span class="t">But it's public.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=2307" target="_blank">00:38:27.000</a></span> | <span class="t">Feel free to poke around.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=2308" target="_blank">00:38:28.000</a></span> | <span class="t">Let us know if you find anything interesting that we should turn into a drug.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=2311" target="_blank">00:38:31.000</a></span> | <span class="t">Yeah, the link is cellaporter.ai.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=2316" target="_blank">00:38:36.000</a></span> | <span class="t">We think of it as like teleporting cells around in patient data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=2321" target="_blank">00:38:41.000</a></span> | <span class="t">May I ask you a question?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=2322" target="_blank">00:38:42.000</a></span> | <span class="t">Sure.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=2323" target="_blank">00:38:43.000</a></span> | <span class="t">So masking seems like a really interesting approach in strategy that it has applied.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=2328" target="_blank">00:38:48.000</a></span> | <span class="t">Is that to narrow it down to that one particular pathway?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=2332" target="_blank">00:38:52.000</a></span> | <span class="t">Is one of the 90% masking so you can actually trace like every single one?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=2339" target="_blank">00:38:59.000</a></span> | <span class="t">Is that the core function of masking?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=2341" target="_blank">00:39:01.000</a></span> | <span class="t">I think it advises two things.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=2343" target="_blank">00:39:03.000</a></span> | <span class="t">The first is that at training time, it makes the task very, very hard.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=2347" target="_blank">00:39:07.000</a></span> | <span class="t">So that the only way you could answer it is by learning about fundamental patient biology.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=2351" target="_blank">00:39:11.000</a></span> | <span class="t">If you provided, you know, go to the other extreme, you provide 999 genes, you only need to predict one, you will probably identify that, oh, I can usually predict this gene by the combination of these other two.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=2361" target="_blank">00:39:21.000</a></span> | <span class="t">The other thing that it helps us do is, I'll show this in a second, but if you train with a very high masking ratio, at inference time, you can bump the masking ratio to 100%, and the model doesn't freak out.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=2374" target="_blank">00:39:34.000</a></span> | <span class="t">It's like, oh, yeah, I'm used to seeing almost nothing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=2376" target="_blank">00:39:36.000</a></span> | <span class="t">And then you can do interesting things like, well, what if I give you no information about that center cell and you only get to use the local spatial context, which is a mode we actually operate in quite often.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=2387" target="_blank">00:39:47.000</a></span> | <span class="t">Yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=2388" target="_blank">00:39:48.000</a></span> | <span class="t">OK, this is another kind of thing we would do with these virtual cells.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=2396" target="_blank">00:39:56.000</a></span> | <span class="t">So the thing that I showed on this slide is the surrounding context is real data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=2404" target="_blank">00:40:04.000</a></span> | <span class="t">We go to a real location in a real patient's tissue, look at the eight nearest cells, feed that expression in.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=2410" target="_blank">00:40:10.000</a></span> | <span class="t">But the model doesn't know what's real data and what isn't.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=2412" target="_blank">00:40:12.000</a></span> | <span class="t">So you can go create a synthetic neighborhood and say, OK, I'm going to start from the real data, and I'm going to simulate the effect of a drug by knocking down a particular target I'm interested in.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=2422" target="_blank">00:40:22.000</a></span> | <span class="t">And say the neighborhood is basically the same, except that I've removed a target of interest.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=2428" target="_blank">00:40:28.000</a></span> | <span class="t">I've done a synthetic knockout in the surrounding context.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=2430" target="_blank">00:40:30.000</a></span> | <span class="t">And I want to know, when I do that knockout, do I make this hypothetical center T cell more or less likely to be in tumor killing mode?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=2440" target="_blank">00:40:40.000</a></span> | <span class="t">So that's what this animation shows.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=2442" target="_blank">00:40:42.000</a></span> | <span class="t">The gene identities are redacted.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=2444" target="_blank">00:40:44.000</a></span> | <span class="t">But the y-axis is the increase in the production or predicted production of Granzyme K, which is part of the T cell cytotoxic arsenal for attacking tumors.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=2456" target="_blank">00:40:56.000</a></span> | <span class="t">And we can do these simulations for each of these 10,000-plus patient samples for each of the 1,000 genes in the panel.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=2464" target="_blank">00:41:04.000</a></span> | <span class="t">And you start to see how, with the right scale, you can very quickly search over hypotheses for what's happening in the patient tissue.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=2471" target="_blank">00:41:11.000</a></span> | <span class="t">Yeah?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=2473" target="_blank">00:41:13.000</a></span> | <span class="t">I would just look at the question.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=2476" target="_blank">00:41:16.000</a></span> | <span class="t">We have data for about 8,000 to 7,000 people.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=2481" target="_blank">00:41:21.000</a></span> | <span class="t">Yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=2495" target="_blank">00:41:35.000</a></span> | <span class="t">Good question.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=2496" target="_blank">00:41:36.000</a></span> | <span class="t">So the question is, is 8,000 patients worth of data enough?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=2499" target="_blank">00:41:39.000</a></span> | <span class="t">Or do you need more?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=2500" target="_blank">00:41:40.000</a></span> | <span class="t">Yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=2504" target="_blank">00:41:44.000</a></span> | <span class="t">Could you augment synthetic data?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=2505" target="_blank">00:41:45.000</a></span> | <span class="t">I think the answer is maybe.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=2509" target="_blank">00:41:49.000</a></span> | <span class="t">I would say if you are staying within a single indication, like we often think about non-small cell lung cancer, it's possible 8,000 patients covers the diversity of different patient biology or different modes that the tumor might be using to escape the immune system.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=2523" target="_blank">00:42:03.000</a></span> | <span class="t">I think there are things you could learn from expanding to more indications, different cancer types in different organs that could be generalizable even back to non-small cell lung cancer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=2533" target="_blank">00:42:13.000</a></span> | <span class="t">And so we are actively collecting right now more data and more indications and more organs to make sure we're not ignoring a pocket of how the tumors might be learning to evade the immune system.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=2545" target="_blank">00:42:25.000</a></span> | <span class="t">Yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=2546" target="_blank">00:42:26.000</a></span> | <span class="t">I think there probably are ways that you generate synthetic data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=2558" target="_blank">00:42:38.000</a></span> | <span class="t">I'm not sure learning from it directly would help.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=2571" target="_blank">00:42:51.000</a></span> | <span class="t">Like if you're using a model that has trained on real data, I'm not sure if it's going to do better when it's generating its own synthetic data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=2577" target="_blank">00:42:57.000</a></span> | <span class="t">But there are ways you can use your own knowledge about the biological system to produce things like these synthetic neighborhoods where you're saying, I'm going to go make a targeted change and then run inference and see what the model thinks will happen when I do a very specific perturbation in the data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=2592" target="_blank">00:43:12.000</a></span> | <span class="t">Thanks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=2593" target="_blank">00:43:13.000</a></span> | <span class="t">Okay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=2594" target="_blank">00:43:14.000</a></span> | <span class="t">The thing about this data that I mentioned earlier is it's expensive and it's rare and it's hard to collect.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=2605" target="_blank">00:43:25.000</a></span> | <span class="t">I also mentioned that this H&E data is image based.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=2608" target="_blank">00:43:28.000</a></span> | <span class="t">It's pretty cheap.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=2609" target="_blank">00:43:29.000</a></span> | <span class="t">It's fairly ubiquitous.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=2610" target="_blank">00:43:30.000</a></span> | <span class="t">A lot of people have it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=2611" target="_blank">00:43:31.000</a></span> | <span class="t">And one thing that we've been doing increasingly is seeing if we can use our model, which we call octo in part informally because it kind of looks like an octopus with a bunch of arms that sample different modalities to just translate from one to the other.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=2626" target="_blank">00:43:46.000</a></span> | <span class="t">So now we're back to multimodality as translation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=2629" target="_blank">00:43:49.000</a></span> | <span class="t">The way that you do this is take this model that we're now familiar with.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=2634" target="_blank">00:43:54.000</a></span> | <span class="t">And now this diagram should look very familiar, except instead of gene expression data from the local neighborhood, we're passing in the surrounding H&E morphology of what is happening local to that cell in the patient's tissue.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=2646" target="_blank">00:44:06.000</a></span> | <span class="t">You know, we can only do this because the samples are spatially aligned as precisely as they are.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=2651" target="_blank">00:44:11.000</a></span> | <span class="t">And now the model gets to use this additional input as help.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=2654" target="_blank">00:44:14.000</a></span> | <span class="t">It's saying, I'm facing ambiguity.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=2656" target="_blank">00:44:16.000</a></span> | <span class="t">What can I do?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=2657" target="_blank">00:44:17.000</a></span> | <span class="t">Oh, well, I can look at the morphology of the cells around me and try to understand if that makes me, for example, a cytotoxic T cell or not.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=2664" target="_blank">00:44:24.000</a></span> | <span class="t">Once you've trained this model, you can then go to full masking.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=2670" target="_blank">00:44:30.000</a></span> | <span class="t">Just say, OK, I'm going to effectively ablate the primary input and just pass in 1,000 mask tokens.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=2676" target="_blank">00:44:36.000</a></span> | <span class="t">And now the only thing the model can do is use the local spatial context to say, well, I don't know anything about what the expression should be.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=2684" target="_blank">00:44:44.000</a></span> | <span class="t">I have to use this local context to try to make a prediction of what the gene expression of a hypothetical cell at the center of that spatial window is doing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=2692" target="_blank">00:44:52.000</a></span> | <span class="t">And because we've trained it at a very high masking ratio, the model is not totally clueless about this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=2698" target="_blank">00:44:58.000</a></span> | <span class="t">And we were curious if it makes reasonable predictions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=2701" target="_blank">00:45:01.000</a></span> | <span class="t">So what we will do at inference time is take one of these H and E images, which, again, are fairly easy to acquire.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=2707" target="_blank">00:45:07.000</a></span> | <span class="t">Pick a spatial window and run the model forward in inference mode and say, OK, I'm not going to tell you anything about the expression of the cell.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=2714" target="_blank">00:45:14.000</a></span> | <span class="t">In this case, because I don't have it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=2716" target="_blank">00:45:16.000</a></span> | <span class="t">Like, we don't know what's going on there.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=2718" target="_blank">00:45:18.000</a></span> | <span class="t">It could be someone sent me this H and E image, and they never ran spatial transcriptomics.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=2723" target="_blank">00:45:23.000</a></span> | <span class="t">The model will make a prediction about what the expression of all 1,000 genes in our panel is at the center of that spatial window.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=2731" target="_blank">00:45:31.000</a></span> | <span class="t">And here it's giving me some value for keratin 19, which is a tumor marker.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=2736" target="_blank">00:45:36.000</a></span> | <span class="t">And you can just run this as many times as you want.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=2738" target="_blank">00:45:38.000</a></span> | <span class="t">So in practice, we'll run this 1,000 times.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=2741" target="_blank">00:45:41.000</a></span> | <span class="t">Yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=2742" target="_blank">00:45:42.000</a></span> | <span class="t">One question online is, are you only predicting the transcriptomics of non-cancer cells?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=2747" target="_blank">00:45:47.000</a></span> | <span class="t">No.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=2748" target="_blank">00:45:48.000</a></span> | <span class="t">We are predicting the transcriptomics for every cell, including immune cells, tumor cells, fibroblasts, thermal cells, whatever's in the data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=2757" target="_blank">00:45:57.000</a></span> | <span class="t">Yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=2758" target="_blank">00:45:58.000</a></span> | <span class="t">So if you run this process a few thousand times, you get basically a prediction heat map of where is it likely that there's a tumor,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=2766" target="_blank">00:46:06.000</a></span> | <span class="t">because you're asking the model to predict one of the 1,000 things it's predicting at each of these locations is a tumor marker.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=2772" target="_blank">00:46:12.000</a></span> | <span class="t">So here's the heat map you get.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=2774" target="_blank">00:46:14.000</a></span> | <span class="t">And then this is now going back.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=2777" target="_blank">00:46:17.000</a></span> | <span class="t">And for this core, we actually do have cell typing from transcriptomics data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=2782" target="_blank">00:46:22.000</a></span> | <span class="t">And the red dots are where there's actually tumor.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=2784" target="_blank">00:46:24.000</a></span> | <span class="t">You can see that the model is predicting where there's tumor markers pretty effectively.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=2789" target="_blank">00:46:29.000</a></span> | <span class="t">I won't pretend this is perfect.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=2791" target="_blank">00:46:31.000</a></span> | <span class="t">There are definitely examples where it doesn't do a great job.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=2793" target="_blank">00:46:33.000</a></span> | <span class="t">So here's another sample that has a ton of B cells.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=2797" target="_blank">00:46:37.000</a></span> | <span class="t">That's the blue in this diagram.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=2799" target="_blank">00:46:39.000</a></span> | <span class="t">And it does, you know, it mostly predicts that there isn't a lot of tumor marker, which is mostly accurate.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=2805" target="_blank">00:46:45.000</a></span> | <span class="t">There isn't a lot of tumor in the sample, but it's still missing the few areas where there is.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=2810" target="_blank">00:46:50.000</a></span> | <span class="t">But for other markers, even within the same sample, it's doing a very good job of predicting from just this morphology image what the expression of various genes is.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=2820" target="_blank">00:47:00.000</a></span> | <span class="t">And, you know, there's imagine 997 more columns of this diagram and then 10,000 more slides with other samples.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=2827" target="_blank">00:47:07.000</a></span> | <span class="t">And that's how we're evaluating the ability of this model to do that translation from the images to the rich spatial transcriptomics.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=2835" target="_blank">00:47:15.000</a></span> | <span class="t">So essentially this is what you call masking.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=2839" target="_blank">00:47:19.000</a></span> | <span class="t">Right. We're leveraging the fact that we have the paired data in-house so we can teach the model to do that translation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=2856" target="_blank">00:47:36.000</a></span> | <span class="t">And then at inference time, it's the model is happy if you mask everything out.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=2861" target="_blank">00:47:41.000</a></span> | <span class="t">It'll just use H&E.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=2862" target="_blank">00:47:42.000</a></span> | <span class="t">Yeah. Yeah, totally.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=2874" target="_blank">00:47:54.000</a></span> | <span class="t">So the thing I'm going to show on the next slide is actually I've been playing with ideas for, you know, what would an interface look like for you have H&E data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=2882" target="_blank">00:48:02.000</a></span> | <span class="t">You don't have the ability to generate spatial transcriptomics.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=2885" target="_blank">00:48:05.000</a></span> | <span class="t">You can imagine an interface where someone uploads their own H&E.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=2890" target="_blank">00:48:10.000</a></span> | <span class="t">You predict a full thousand dimensional panel of what the expression is of a bunch of different genes at every location.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=2897" target="_blank">00:48:17.000</a></span> | <span class="t">We know what different gene programs look like.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=2900" target="_blank">00:48:20.000</a></span> | <span class="t">And you can actually use a large language model to find for you, you know, common areas where things are popping out and descriptions of what's happening.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=2909" target="_blank">00:48:29.000</a></span> | <span class="t">So you get a fully end-to-end automated, you upload a sample, we predict what the gene expression would be in that sample, and then you can go explore the data, talk with an LLM, explore whatever you want, ask questions about it, and eventually run simulations in browser.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=2928" target="_blank">00:48:48.000</a></span> | <span class="t">So basically what we have built here is a system that attempts to translate relatively easy-to-acquire data into rich patient representations.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=2937" target="_blank">00:48:57.000</a></span> | <span class="t">So this is kind of a pretty PCA projection of the first few principal components of the thousand-dimensional signal at each location.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=2946" target="_blank">00:49:06.000</a></span> | <span class="t">But what we will actually do with that is then each dot in the diagram to the right is one sample from one patient.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=2955" target="_blank">00:49:15.000</a></span> | <span class="t">And we're embedding it in a two-dimensional space.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=2957" target="_blank">00:49:17.000</a></span> | <span class="t">In this case, I think we're using PSNI, and we're putting patient samples together if their predicted gene expression profiles are similar.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=2965" target="_blank">00:49:25.000</a></span> | <span class="t">And what I'm labeling by here is actually the patient genetics.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=2969" target="_blank">00:49:29.000</a></span> | <span class="t">So the model has no idea about whether a patient has a genetic mutation in cancer driver mutations.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=2977" target="_blank">00:49:37.000</a></span> | <span class="t">But it turns out that because the model has learned patient biology, when you cluster together predictions from different patients,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=2984" target="_blank">00:49:44.000</a></span> | <span class="t">the ones that have common genetic mutations end up clustering in this space.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=2988" target="_blank">00:49:48.000</a></span> | <span class="t">So you can recover patient biology starting, again, just from this H and E image because we have trained this model on a bunch of paired data that has H and E and spatial transcriptomics.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3000" target="_blank">00:50:00.000</a></span> | <span class="t">Yeah, we spend a lot of time asking what the structure of the space is telling us about the data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3009" target="_blank">00:50:09.000</a></span> | <span class="t">I'm just going to give a quick tour of another kind of model that will look familiar because it's using similar masked autoencoding.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3019" target="_blank">00:50:19.000</a></span> | <span class="t">This is using that protein data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3021" target="_blank">00:50:21.000</a></span> | <span class="t">So in this example, the model is not predicting gene expression.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3024" target="_blank">00:50:24.000</a></span> | <span class="t">It's predicting protein images.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3026" target="_blank">00:50:26.000</a></span> | <span class="t">And we're feeding in the other three modalities as extra tokens.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3030" target="_blank">00:50:30.000</a></span> | <span class="t">So this is now not the adaptive layer norm thing I mentioned.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3033" target="_blank">00:50:33.000</a></span> | <span class="t">It's just stapling on bonus tokens into the token stream and letting them interact with the primary token stream, which comes from these 16-channel protein images.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3043" target="_blank">00:50:43.000</a></span> | <span class="t">So in this model, if I'm creating a new dataset given the earlier process, can that become another input dataset?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3057" target="_blank">00:50:57.000</a></span> | <span class="t">Yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3058" target="_blank">00:50:58.000</a></span> | <span class="t">Yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3059" target="_blank">00:50:59.000</a></span> | <span class="t">So you could only collect H and E, impute or predict what the spatial transcriptomics would have looked like if you collected it, feed that in.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3071" target="_blank">00:51:11.000</a></span> | <span class="t">The question is if that helps you learn anything.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3075" target="_blank">00:51:15.000</a></span> | <span class="t">And I don't have an answer to that yet.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3076" target="_blank">00:51:16.000</a></span> | <span class="t">We're exploring it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3077" target="_blank">00:51:17.000</a></span> | <span class="t">But it's an interesting idea.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3078" target="_blank">00:51:18.000</a></span> | <span class="t">Yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3079" target="_blank">00:51:19.000</a></span> | <span class="t">OK.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3080" target="_blank">00:51:20.000</a></span> | <span class="t">So what we do in this space is ask questions like, well, how do we want to simulate the effect of a drug?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3086" target="_blank">00:51:26.000</a></span> | <span class="t">The effect of a drug simulated might look like modifying the spatial transcriptomics data, where you say, this drug suppresses this protein.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3095" target="_blank">00:51:35.000</a></span> | <span class="t">And so you could say that the way that would look in the spatial transcriptomics data is suppressing the leads of one gene or a combination of genes.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3104" target="_blank">00:51:44.000</a></span> | <span class="t">And you're going to run this counterfactual, a what if, of, well, what if I had applied that drug, changed the spatial transcriptomics data in this way, and run that forward to a prediction of saying, well, how does that change the output of the model trying to predict the protein image on the other side?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3121" target="_blank">00:52:01.000</a></span> | <span class="t">And I have a small animation showing how that might happen.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3125" target="_blank">00:52:05.000</a></span> | <span class="t">So this is a sample from a patient.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3128" target="_blank">00:52:08.000</a></span> | <span class="t">The yellow here are immune cells.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3129" target="_blank">00:52:09.000</a></span> | <span class="t">The pink is tumor.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3131" target="_blank">00:52:11.000</a></span> | <span class="t">Now you can run two what ifs.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3134" target="_blank">00:52:14.000</a></span> | <span class="t">In one what if simulation, you're cranking up the expression of this gene whose identity is redacted here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3142" target="_blank">00:52:22.000</a></span> | <span class="t">And in the other one, you're suppressing the activity of that gene.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3145" target="_blank">00:52:25.000</a></span> | <span class="t">So now I'm back to creating synthetic data on my multimodal input arms.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3149" target="_blank">00:52:29.000</a></span> | <span class="t">And I'm going to now run both of those parallel universes forward.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3154" target="_blank">00:52:34.000</a></span> | <span class="t">And what I'm looking for is the readout is one of these 16 channels that's being predicted.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3161" target="_blank">00:52:41.000</a></span> | <span class="t">In this case, I'm looking for a tumor immunogenicity marker where higher would indicate more favorable.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3167" target="_blank">00:52:47.000</a></span> | <span class="t">And you can see that the simulation is telling us, yeah, you should crank up the expression of gene one if you can, because it leads to a more favorable outcome on the other side.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3177" target="_blank">00:52:57.000</a></span> | <span class="t">So one way that we often are using multimodal models is to say, we want this backbone that makes predictions to tell us what would change if we could impart a delta or a modification or a perturbation on another one of the input streams.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3192" target="_blank">00:53:12.000</a></span> | <span class="t">OK.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3193" target="_blank">00:53:13.000</a></span> | <span class="t">OK.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3194" target="_blank">00:53:14.000</a></span> | <span class="t">OK.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3195" target="_blank">00:53:15.000</a></span> | <span class="t">OK.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3196" target="_blank">00:53:16.000</a></span> | <span class="t">OK.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3197" target="_blank">00:53:17.000</a></span> | <span class="t">OK.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3198" target="_blank">00:53:18.000</a></span> | <span class="t">OK.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3199" target="_blank">00:53:19.000</a></span> | <span class="t">OK.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3199" target="_blank">00:53:19.000</a></span> | <span class="t">So if you have a-- if you're able to express your hypothesis for what a drug should do in the input space of the model,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3205" target="_blank">00:53:25.000</a></span> | <span class="t">and you have a readout on the other side of what is good or bad, then yeah, you could compare multiple different ideas and see which one looks like it'd be most effective.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3213" target="_blank">00:53:33.000</a></span> | <span class="t">OK.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3219" target="_blank">00:53:39.000</a></span> | <span class="t">I showed like a relatively small fraction of the research that we're doing here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3225" target="_blank">00:53:45.000</a></span> | <span class="t">But in general, we're very open about sharing the science we're doing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3228" target="_blank">00:53:48.000</a></span> | <span class="t">So we have three blog posts up.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3230" target="_blank">00:53:50.000</a></span> | <span class="t">You can get to them at noetic.ai/research.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3234" target="_blank">00:53:54.000</a></span> | <span class="t">This first one is about the protein-image-based models that I just showed.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3239" target="_blank">00:53:59.000</a></span> | <span class="t">There's more detail on how we're generating data in lab.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3242" target="_blank">00:54:02.000</a></span> | <span class="t">And then some of this new spatial transcriptomic stuff is in a more recent post.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3247" target="_blank">00:54:07.000</a></span> | <span class="t">OK.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3249" target="_blank">00:54:09.000</a></span> | <span class="t">I just have a couple of more slides.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3250" target="_blank">00:54:10.000</a></span> | <span class="t">And then it looks like we'll have a bit of time for further questions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3254" target="_blank">00:54:14.000</a></span> | <span class="t">One thing that we're moving toward doing, if you'll excuse kind of the chaotic animation here, is instead of trying to assign these RNA detections to cells,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3263" target="_blank">00:54:23.000</a></span> | <span class="t">we're just going straight to the raw data and seeing what we can do with that point cloud of 10 million points that my computer choked on earlier.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3270" target="_blank">00:54:30.000</a></span> | <span class="t">And so we're training models that are able to look at the local spatial context in this raw point cloud of RNA transcripts and predict what is going to happen at many points spatially in the sample.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3285" target="_blank">00:54:45.000</a></span> | <span class="t">So we're breaking free of the need to think about cells as the atomic unit of simulating the biology and going basically as close to the raw data as we can get.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3297" target="_blank">00:54:57.000</a></span> | <span class="t">So this trajectory, you know, in biology a cell would not drive through a sample like this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3301" target="_blank">00:55:01.000</a></span> | <span class="t">But for a visualization, I'm showing in each position here we're running one inference step.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3306" target="_blank">00:55:06.000</a></span> | <span class="t">So I ran this model a few thousand times moving this hypothetical cell a few microns at a time.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3313" target="_blank">00:55:13.000</a></span> | <span class="t">And then simulating what the readout would be of saying, OK, well, when you're surrounded by this cloud of transcripts,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3319" target="_blank">00:55:19.000</a></span> | <span class="t">you're probably also seeing this cloud near you and this other cloud over there.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3323" target="_blank">00:55:23.000</a></span> | <span class="t">And so this is now the kind of simulation engine where basically any hypothesis you have about what a drug might be doing or what's happening in patient biology,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3332" target="_blank">00:55:32.000</a></span> | <span class="t">if this model has really learned about the world of the patient's biology, you should be able to get a reasonable simulation out on the other side.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3340" target="_blank">00:55:40.000</a></span> | <span class="t">So in summary, oh, I have one more slide.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3345" target="_blank">00:55:45.000</a></span> | <span class="t">I noticed last week was on the biology of a large language model, which is a paper I really liked.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3349" target="_blank">00:55:49.000</a></span> | <span class="t">So I have a tongue-in-cheek slide on the biology of a large multimodal model for biology, which is just a little teaser.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3356" target="_blank">00:55:56.000</a></span> | <span class="t">I don't have a ton of time again.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3358" target="_blank">00:55:58.000</a></span> | <span class="t">But we've been doing some interpretability research on these models to try to understand what it is they have learned about the patient biology.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3367" target="_blank">00:56:07.000</a></span> | <span class="t">So we've used things like sparse autoencoders to pull out consistent beans that keep popping out in the data</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3373" target="_blank">00:56:13.000</a></span> | <span class="t">and have used those to build interfaces for biologists of the company to basically do things like automatic semantic segmentation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3382" target="_blank">00:56:22.000</a></span> | <span class="t">with text labels from identifying persistent concepts that keep appearing in the dataset.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3388" target="_blank">00:56:28.000</a></span> | <span class="t">So again, this is starting from just the H&E.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3391" target="_blank">00:56:31.000</a></span> | <span class="t">So you upload H&E and you get back semantic segmentation with the different parts of the sample and what's happening in each of them.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3398" target="_blank">00:56:38.000</a></span> | <span class="t">OK.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3399" target="_blank">00:56:39.000</a></span> | <span class="t">This is basically my last slide, which is just saying I hope one thing I've communicated today is that this is just a big playground.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3407" target="_blank">00:56:47.000</a></span> | <span class="t">There's a ton of data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3408" target="_blank">00:56:48.000</a></span> | <span class="t">There's a ton of ways you can try to combine that data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3411" target="_blank">00:56:51.000</a></span> | <span class="t">And especially in biology, you have data spanning many spatial scales, many levels of abstraction, and also many modalities.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3421" target="_blank">00:57:01.000</a></span> | <span class="t">So we talked today about really the three of them, the H&E imaging, the immunofluorescence, and RNA sequencing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3427" target="_blank">00:57:07.000</a></span> | <span class="t">There's more to be done in looking at the patient genotyping.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3430" target="_blank">00:57:10.000</a></span> | <span class="t">There's immunohistochemistry.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3432" target="_blank">00:57:12.000</a></span> | <span class="t">So the field of omics keeps getting bigger and bigger.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3435" target="_blank">00:57:15.000</a></span> | <span class="t">And so the question that I think we have to solve and that I don't think has a concrete answer yet is what do you do with all of this?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3442" target="_blank">00:57:22.000</a></span> | <span class="t">How do you build a world model that incorporates all of this information?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3446" target="_blank">00:57:26.000</a></span> | <span class="t">And how do you craft your training tasks, your information bottlenecks, and your fusion points so that you're forcing a model to really learn real patient biology that is specific to each patient?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3457" target="_blank">00:57:37.000</a></span> | <span class="t">And I won't pretend to have the answer today.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3459" target="_blank">00:57:39.000</a></span> | <span class="t">We don't know.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3460" target="_blank">00:57:40.000</a></span> | <span class="t">We're trying a bunch of stuff and kind of throwing a lot of ideas at the wall and then having a lot of fun playing with it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3466" target="_blank">00:57:46.000</a></span> | <span class="t">But I just want to leave people with the idea that there's just a ton of things to try here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3471" target="_blank">00:57:51.000</a></span> | <span class="t">And I think it's going to be a very exciting few years ahead.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3474" target="_blank">00:57:54.000</a></span> | <span class="t">So with that, I'll now fill in the picture.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3477" target="_blank">00:57:57.000</a></span> | <span class="t">This is our idea for building a world model for tumor biology.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3481" target="_blank">00:58:01.000</a></span> | <span class="t">And I'll save the rest of the time for questions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3484" target="_blank">00:58:04.000</a></span> | <span class="t">You know, there's HIPAA, there's a lot of privacy protection laws that prevent, let's say, for researchers like you to probably have access to real data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3511" target="_blank">00:58:31.000</a></span> | <span class="t">So my question is, let's say if data is localized at each hospital, how do you see the future of research in this area can leverage the vast data set that is siloed in different hospitals so that this can advance so to speak to a place that can be diffused into healthcare space?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3534" target="_blank">00:58:54.000</a></span> | <span class="t">Yeah, that's a very important question.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3537" target="_blank">00:58:57.000</a></span> | <span class="t">I think there are a few different answers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3540" target="_blank">00:59:00.000</a></span> | <span class="t">One of them is open sourcing of methods that you could say, you know, we aren't going to ask you to send us your confidential data, but we're going to tell you how you can run it yourself.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3550" target="_blank">00:59:10.000</a></span> | <span class="t">There's probably also ways that I'm not familiar with to just secure end point basically and say, we're going to, as a service, process this data for you and we'll be compliant with the privacy regulations about how to get the data from your hospital to the servers and back.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3566" target="_blank">00:59:26.000</a></span> | <span class="t">It's very much not my area of expertise, so I don't know exactly what that looks like.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3569" target="_blank">00:59:29.000</a></span> | <span class="t">But I imagine someone is thinking very hard about it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3573" target="_blank">00:59:33.000</a></span> | <span class="t">And I think the third thing is partnership, that you can always have, you know, a hospital or research institution say, we want access to a bunch of these models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3582" target="_blank">00:59:42.000</a></span> | <span class="t">We're going to go into a formal partnership where we have access to the compute and the models that you've trained and we're going to work together to run these samples so that it isn't just kind of an arbitrary like, yeah, email us your H&E data and we'll process it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3596" target="_blank">00:59:56.000</a></span> | <span class="t">Yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3599" target="_blank">00:59:59.000</a></span> | <span class="t">Amazing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3600" target="_blank">01:00:00.000</a></span> | <span class="t">I just can't wait to see if it can be expanded to larger data sets than just 8,000 patients.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3607" target="_blank">01:00:07.000</a></span> | <span class="t">My other question is, I know cells and molecules and proteins, there are so many models beginning to happen.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3613" target="_blank">01:00:13.000</a></span> | <span class="t">Are we able to leverage a lot of the alpha-4 models that already exist in the protein layer data set and also exosomes?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3621" target="_blank">01:00:21.000</a></span> | <span class="t">In fact, the two new things which are getting to be very interesting is bioelectrics, you know, which is like beginning to be another holy grail, not just cells.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3630" target="_blank">01:00:30.000</a></span> | <span class="t">Is there any way you can also capture that data set in, you know, early experimentation out of the four, but add like two other layers?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3637" target="_blank">01:00:37.000</a></span> | <span class="t">Yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3638" target="_blank">01:00:38.000</a></span> | <span class="t">And exosomes, particularly the communication channel, that can add value.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3642" target="_blank">01:00:42.000</a></span> | <span class="t">Yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3643" target="_blank">01:00:43.000</a></span> | <span class="t">I think that's a great question.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3644" target="_blank">01:00:44.000</a></span> | <span class="t">One thing I've come to believe is that most forms of data can be jammed into these frameworks fairly easily.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3651" target="_blank">01:00:51.000</a></span> | <span class="t">And the question is empirically, does that help with anything or not?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3655" target="_blank">01:00:55.000</a></span> | <span class="t">And I don't know.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3656" target="_blank">01:00:56.000</a></span> | <span class="t">But I think, you know, to be totally candid, we're at a place in research where we can try a lot of stuff very quickly and see what helps us make better predictions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3664" target="_blank">01:01:04.000</a></span> | <span class="t">So in some cases, I think what we're doing is probably upstream of models like AlphaFold where, you know, once we have run our simulations and said, well, OK, our world model is telling us if you could only make reality look like this, then this patient would respond to treatment.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3679" target="_blank">01:01:19.000</a></span> | <span class="t">But then we might still have a challenge of, OK, well, what is the actual pharmacological path by which we get there?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3685" target="_blank">01:01:25.000</a></span> | <span class="t">And then you might need to engage with something at the molecular level.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3689" target="_blank">01:01:29.000</a></span> | <span class="t">So, yeah, I think it's possible that one of the big challenges that I'm thinking about is, indeed, how do you integrate across these spatial scales?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3699" target="_blank">01:01:39.000</a></span> | <span class="t">And we've tried some stuff, but we have not spanned this entire range yet in a single model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3705" target="_blank">01:01:45.000</a></span> | <span class="t">Is it an approach right now of research to start with patient data first or just to a broad predictive model, then, you know, I can figure out later who the patient is?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3717" target="_blank">01:01:57.000</a></span> | <span class="t">You know, because there's so much of the early prediction that's happening where you're not a patient yet.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3721" target="_blank">01:02:01.000</a></span> | <span class="t">Right.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3722" target="_blank">01:02:02.000</a></span> | <span class="t">You know, there are no markers, there's no tumor yet, but you're able to predict.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3725" target="_blank">01:02:05.000</a></span> | <span class="t">Yeah. Long shot.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3726" target="_blank">01:02:06.000</a></span> | <span class="t">Yeah. Right now we are working from patient data and one limitation of that data set, which I think is what you're pointing out,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3732" target="_blank">01:02:12.000</a></span> | <span class="t">is that healthy people don't get parts of their bodies removed and sent to hospitals or to, you know, research.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3738" target="_blank">01:02:18.000</a></span> | <span class="t">So really the thing we would want in a world model is evidence of, well, what does it look like when everything's working?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3743" target="_blank">01:02:23.000</a></span> | <span class="t">When there's no tumor?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3744" target="_blank">01:02:24.000</a></span> | <span class="t">When the immune system has identified a threat and eliminated it?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3747" target="_blank">01:02:27.000</a></span> | <span class="t">And we just don't know because what we're getting are these snapshots of a battlefield.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3751" target="_blank">01:02:31.000</a></span> | <span class="t">And if we're lucky, we will see a snapshot and then find out that that patient received some treatment and responded well to it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3758" target="_blank">01:02:38.000</a></span> | <span class="t">But we're missing probably the vast majority of the system operating in kind of normal operational mode.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3764" target="_blank">01:02:44.000</a></span> | <span class="t">And I don't see an immediate way out of that challenge other than acknowledging it and recognizing that, you know,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3769" target="_blank">01:02:49.000</a></span> | <span class="t">what we're trying to do is learn as much as we can about the snapshots we get of disease state and learn from that as a starting point.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3776" target="_blank">01:02:56.000</a></span> | <span class="t">Because Broad Institute has some really interesting projects where they're just taking like dead tumor specimens</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3782" target="_blank">01:03:02.000</a></span> | <span class="t">and they're just doing a bunch of computation modeling.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3785" target="_blank">01:03:05.000</a></span> | <span class="t">It's really cool to see, you know, if that can integrate into this overarching.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3789" target="_blank">01:03:09.000</a></span> | <span class="t">Yeah, our attitude is very much like as much data as we can get, we're going to throw it at this thing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3793" target="_blank">01:03:13.000</a></span> | <span class="t">So that's all.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3794" target="_blank">01:03:14.000</a></span> | <span class="t">Very cool. Thank you.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3795" target="_blank">01:03:15.000</a></span> | <span class="t">Thank you.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3796" target="_blank">01:03:16.000</a></span> | <span class="t">Any other questions?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3797" target="_blank">01:03:17.000</a></span> | <span class="t">So is Noetic just a model company?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3811" target="_blank">01:03:31.000</a></span> | <span class="t">Do you outsource the drug discovery to other people and just let them use your service as a platform?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3816" target="_blank">01:03:36.000</a></span> | <span class="t">Or how does it work?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3817" target="_blank">01:03:37.000</a></span> | <span class="t">No, we are effectively as full stack as it gets.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3821" target="_blank">01:03:41.000</a></span> | <span class="t">We generate our data in house.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3823" target="_blank">01:03:43.000</a></span> | <span class="t">We do the machine learning in house and then we have biologists and immunologists in house.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3827" target="_blank">01:03:47.000</a></span> | <span class="t">And I didn't talk about this at all, but we have an in vivo platform with mice where you can actually go test hypotheses about saying,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3834" target="_blank">01:03:54.000</a></span> | <span class="t">here's a mouse model for this patient population.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3836" target="_blank">01:03:56.000</a></span> | <span class="t">We think that this drug will be effective.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3838" target="_blank">01:03:58.000</a></span> | <span class="t">Let's go test it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3839" target="_blank">01:03:59.000</a></span> | <span class="t">So we right now actually do not provide any of these.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3843" target="_blank">01:04:03.000</a></span> | <span class="t">You know, even if you wanted to pay me today to go use one of these, I don't have an API endpoint for you.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3847" target="_blank">01:04:07.000</a></span> | <span class="t">But we are using these internally to do drug discovery and basic discovery every day.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3852" target="_blank">01:04:12.000</a></span> | <span class="t">So the model is like a lower latency version and then the mouse is just to-- so you do most of your testing with the model, I assume, and then the mouse is just if you-- after you do the initial filtering with the AI model?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3867" target="_blank">01:04:27.000</a></span> | <span class="t">Or how does that work?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3868" target="_blank">01:04:28.000</a></span> | <span class="t">Yeah, so the model can tell you two things.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3871" target="_blank">01:04:31.000</a></span> | <span class="t">In the best case, it tells you, hey, you should go try this drug in mice.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3874" target="_blank">01:04:34.000</a></span> | <span class="t">And then we don't pretend that this model is going to understand all of the complex biology that happens when you administer a drug.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3881" target="_blank">01:04:41.000</a></span> | <span class="t">So you still need to go to that in vivo test case and say, is this actually working to get rid of tumor?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3887" target="_blank">01:04:47.000</a></span> | <span class="t">The other thing the models tell us is maybe there's already drug people have tried, but they're trying it in the wrong population.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3894" target="_blank">01:04:54.000</a></span> | <span class="t">Like they're enrolling too broad of a clinical trial because they don't know that actually this small sliver of the patient space is the one that's going to respond well to your drug.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3903" target="_blank">01:05:03.000</a></span> | <span class="t">And so we are using the model in that capacity to give us ideas for things to try in our in vivo platform or to reexamine clinical data and see if we can understand why clinical trials have failed,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3915" target="_blank">01:05:15.000</a></span> | <span class="t">where other people are kind of shrugging and going, well, I don't know, like 10 people were totally cured, but the other 190 weren't and we don't know why.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3922" target="_blank">01:05:22.000</a></span> | <span class="t">That makes sense.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3923" target="_blank">01:05:23.000</a></span> | <span class="t">So is the end game to completely replace clinical trials or--?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3928" target="_blank">01:05:28.000</a></span> | <span class="t">I don't know.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3929" target="_blank">01:05:29.000</a></span> | <span class="t">I mean, maybe in many, many years, I think ultimately, you know, safety and efficacy proven out in humans will need to happen at some point.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3938" target="_blank">01:05:38.000</a></span> | <span class="t">If anything, I would assume that the earlier part of that funnel is going to be increasingly done synthetically.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3943" target="_blank">01:05:43.000</a></span> | <span class="t">But maybe we say, you know, you can in some cases skip a mouse model if you have a very clear mechanism of action and you want to go straight to checking for safety and efficacy.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3952" target="_blank">01:05:52.000</a></span> | <span class="t">Thanks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3953" target="_blank">01:05:53.000</a></span> | <span class="t">Yeah, thank you.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3954" target="_blank">01:05:54.000</a></span> | <span class="t">Thank you.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3955" target="_blank">01:05:55.000</a></span> | <span class="t">You have many different scenarios of simulations to test with many different combinations.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3961" target="_blank">01:06:01.000</a></span> | <span class="t">I'm wondering how you narrow it down to, like, prioritize, like, which one to test first?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3966" target="_blank">01:06:06.000</a></span> | <span class="t">Yeah, that's a fantastic question.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3968" target="_blank">01:06:08.000</a></span> | <span class="t">So I think of what we're doing is, like, let's say you had a really good world model, a simulator of the world, even in the macroscopic case.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3977" target="_blank">01:06:17.000</a></span> | <span class="t">You still need an agent to tell you what is worth simulating.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3980" target="_blank">01:06:20.000</a></span> | <span class="t">You can't just try things at random.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3982" target="_blank">01:06:22.000</a></span> | <span class="t">And I think there's two promising things here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3985" target="_blank">01:06:25.000</a></span> | <span class="t">One of them is you still have subject matter experts that say, oh, great, you've given me a perfect simulator of patient biology.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3992" target="_blank">01:06:32.000</a></span> | <span class="t">I know the first 30 things I'm going to try because I'm familiar with the things that have been considered in this space.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=3998" target="_blank">01:06:38.000</a></span> | <span class="t">We have hypotheses for how the tumor is evading the immune system and we want to go see if we can disrupt those.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=4003" target="_blank">01:06:43.000</a></span> | <span class="t">The other thing that I don't know how much weight I want to put behind right now but would be a little foolish to dismiss is that we have these LLMs now that are trained on basically the entirety of scientific literature know about a bunch of studies.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=4019" target="_blank">01:06:59.000</a></span> | <span class="t">And if they have access to effectively tool use and say, OK, what experiments do you want to run and start thinking about, you know, virtual scientists or AI scientist agents that are trying to decide this is the next experiment I would do.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=4033" target="_blank">01:07:13.000</a></span> | <span class="t">And maybe at some point you close the loop and you say, great, we're going to run that experiment and we'll be back to you tomorrow.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=4038" target="_blank">01:07:18.000</a></span> | <span class="t">And then tell me the next thing to try.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=4039" target="_blank">01:07:19.000</a></span> | <span class="t">But either way you need somebody who's familiar with the domain, whether that's an LLM or a scientist to make the decisions about how to use the simulator.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=4047" target="_blank">01:07:27.000</a></span> | <span class="t">Got it. Thanks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=4048" target="_blank">01:07:28.000</a></span> | <span class="t">Yeah, thank you.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=4049" target="_blank">01:07:29.000</a></span> | <span class="t">So I know your grand vision is to cure cancer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=4056" target="_blank">01:07:36.000</a></span> | <span class="t">Do you have some thoughts on cancer prevention, like probably vaccines or stuff like that?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=4063" target="_blank">01:07:43.000</a></span> | <span class="t">Yeah, that is a good question.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=4065" target="_blank">01:07:45.000</a></span> | <span class="t">I'm not sure I have a fantastic answer about, you know, how are we thinking about cancer prevention?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=4070" target="_blank">01:07:50.000</a></span> | <span class="t">It relates to this problem of we don't have healthy data to look at.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=4074" target="_blank">01:07:54.000</a></span> | <span class="t">And if there isn't an indicator right now in the clinic of, yeah, like you look healthy today, but we're still going to go biopsy this and send it off and fit you into this framework.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=4084" target="_blank">01:08:04.000</a></span> | <span class="t">Then I think you're going to be limited in what you can do about simulating the patient biology of patients that right now are totally asymptomatic.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=4092" target="_blank">01:08:12.000</a></span> | <span class="t">I could imagine that changing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=4094" target="_blank">01:08:14.000</a></span> | <span class="t">I mean, it's possible that data acquisition is going to be broad enough and cheap enough that it is just routine to have a little bit of H&E taken.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=4101" target="_blank">01:08:21.000</a></span> | <span class="t">And maybe there is information kind of in the latent space of this model that says, yeah, this looks like it's over in this part of the patient distribution.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=4109" target="_blank">01:08:29.000</a></span> | <span class="t">Maybe we keep an eye on this patient over the next few years.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=4114" target="_blank">01:08:34.000</a></span> | <span class="t">Same question.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=4115" target="_blank">01:08:35.000</a></span> | <span class="t">Great.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=4116" target="_blank">01:08:36.000</a></span> | <span class="t">Well, I have a follow-up question.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=4118" target="_blank">01:08:38.000</a></span> | <span class="t">Google scientists have a forward on all this stuff.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=4121" target="_blank">01:08:41.000</a></span> | <span class="t">Yesterday, Microsoft released a co-pilot or semi-autopilot for science discovery tool.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=4126" target="_blank">01:08:46.000</a></span> | <span class="t">I'm very curious how we can run a billion experiments autonomously, maybe modeling, instead of modeling what scenario, maybe model a person, right, as an agent, and figure out what drugs could potentially</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=4145" target="_blank">01:09:05.000</a></span> | <span class="t">you know, cure the context we just lost someone like two weeks ago to cancer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=4150" target="_blank">01:09:10.000</a></span> | <span class="t">So this is a very big thing for me.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=4151" target="_blank">01:09:11.000</a></span> | <span class="t">Yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=4152" target="_blank">01:09:12.000</a></span> | <span class="t">How do we prevent or cure intermediate cancer?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=4157" target="_blank">01:09:17.000</a></span> | <span class="t">So that's the way I'm thinking around where agents and science intersect.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=4162" target="_blank">01:09:22.000</a></span> | <span class="t">Right.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=4163" target="_blank">01:09:23.000</a></span> | <span class="t">Yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=4164" target="_blank">01:09:24.000</a></span> | <span class="t">I have a few thoughts here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=4166" target="_blank">01:09:26.000</a></span> | <span class="t">I'm not sure how coherent they are.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=4167" target="_blank">01:09:27.000</a></span> | <span class="t">One of them is I am not sure yet that speed and scale is the bottleneck on running these simulations.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=4174" target="_blank">01:09:34.000</a></span> | <span class="t">I have not also seen an example yet of an agent come up with a really brilliant experiment that our scientists didn't write down in like the first four minutes of thinking about how to use this thing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=4185" target="_blank">01:09:45.000</a></span> | <span class="t">So that doesn't mean I'm not optimistic about it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=4187" target="_blank">01:09:47.000</a></span> | <span class="t">I think these systems are going to get better.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=4189" target="_blank">01:09:49.000</a></span> | <span class="t">And if anything, I have been wrong every time on saying like, yeah, that's five years away.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=4193" target="_blank">01:09:53.000</a></span> | <span class="t">And then five months later, it turns out that we can do it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=4196" target="_blank">01:09:56.000</a></span> | <span class="t">So I would like to remain optimistic that we're going to be able to frame these problems, integrate things like tool use in a way that does allow agents to go run a bunch of experiments.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=4207" target="_blank">01:10:07.000</a></span> | <span class="t">And then, you know, for us, we probably still go test those out in mice and then think about them in that capacity.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=4212" target="_blank">01:10:12.000</a></span> | <span class="t">But yeah, it's a very interesting direction to think about.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=4215" target="_blank">01:10:15.000</a></span> | <span class="t">Give another hand to Mishet for the very interesting talk.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=4221" target="_blank">01:10:21.000</a></span> | <span class="t">Yeah, so you'll notice this talk was sort of different from a lot of the more recent talks or work, just focusing more on LLMs.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=4232" target="_blank">01:10:32.000</a></span> | <span class="t">But I think this is a very important space and an area, application area where machine learning and AI can make a lot of impact and save the world, change the world, positively impact the world and save lives.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=4247" target="_blank">01:10:47.000</a></span> | <span class="t">So we should definitely encourage more work for machine learning and AI for this area of cancer research and healthcare in general.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8kXIaUM3h1E&t=4256" target="_blank">01:10:56.740</a></span> | <span class="t">Thank you.</span></div></div></body></html>