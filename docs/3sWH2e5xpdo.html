<html><head><title>Sam Altman's World Tour, in 16 Moments</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            margin: 0;
            padding: 0;
            background-color: #f4f4f4;
            color: #333;
        }
        .container {
            width: 80%;
            margin: auto;
            overflow: hidden;
        }
        h2, h3 {
            color: #333;
            text-align: center;
        }
        a {
            color: #0000FF;  /* Traditional blue color for links */
            text-decoration: none;
        }
        a:hover {
            text-decoration: underline;
        }
        img {
            display: block;
            margin: auto;
            max-width: 100%;
        }
        .c {
            margin: 10px 0;
        }
        .s, .t {
            display: inline-block;
            margin-right: 5px;
        }
        .max-width {
            max-width: 800px;
            margin: auto;
        }
    </style>
    
    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-69VLBMTTP0"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-69VLBMTTP0');
    </script>
    </head><body><div class='container'><a href="index.html">back to index</a><h2>Sam Altman's World Tour, in 16 Moments</h2><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo"><img src="https://i.ytimg.com/vi/3sWH2e5xpdo/maxresdefault.jpg" style="width:50%;"></a><div><br></div><h3>Chapters</h3><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=0">0:0</a> <Untitled Chapter 1><br><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=87">1:27</a> 'Strange Decisions'<br><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=547">9:7</a> Customise ChatGPT<br><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=619">10:19</a> Opensource 'unstoppable'<br><br><div style="text-align: left;"><a href="./3sWH2e5xpdo.html">Whisper Transcript</a> | <a href="./transcript_3sWH2e5xpdo.html">Transcript Only Page</a></div><br><div style="max-width: 800px;"><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=0" target="_blank">00:00:00.000</a></span> | <span class="t">There have been 16 surprising and or fascinating moments from Sam Altman's world tour.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=6" target="_blank">00:00:06.880</a></span> | <span class="t">I could have done a video on each of them, but after watching over 10 hours of interviews,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=11" target="_blank">00:00:11.780</a></span> | <span class="t">I decided, you know what, let's just show you everything in one video.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=15" target="_blank">00:00:15.940</a></span> | <span class="t">From AIs designing new AIs, to fresh ChatGPT leaks, shooting railguns, to open source,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=23" target="_blank">00:00:23.740</a></span> | <span class="t">here's all 16 things I learnt in no particular order.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=27" target="_blank">00:00:27.480</a></span> | <span class="t">Let's start with Sam Altman's warning about AIs designing their own architecture.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=32" target="_blank">00:00:32.940</a></span> | <span class="t">Seems like a good idea, but Satsukawa could see one of their models designing the next model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=54" target="_blank">00:00:54.260</a></span> | <span class="t">We are definitely very concerned about superintelligence.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=57" target="_blank">00:00:57.460</a></span> | <span class="t">It will be possible to build a computer, a computer cluster, a GPU farm, that is just smarter than any person,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=64" target="_blank">00:01:04.820</a></span> | <span class="t">that can do science and engineering much, much faster than even a large team of really experienced scientists and engineers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=71" target="_blank">00:01:11.700</a></span> | <span class="t">And that is crazy. That is going to be unbelievably, extremely impactful.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=77" target="_blank">00:01:17.060</a></span> | <span class="t">It could engineer the next version of the system.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=80" target="_blank">00:01:20.780</a></span> | <span class="t">AI building AI. It's just crazy.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=83" target="_blank">00:01:23.540</a></span> | <span class="t">Let's return to Abu Dhabi where Sam Altman said he enjoys the power that being CEO of OpenAI brings,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=92" target="_blank">00:01:32.180</a></span> | <span class="t">but also mentioned strange decisions he might have to make.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=96" target="_blank">00:01:36.020</a></span> | <span class="t">I mean, I have like lots of selfish reasons for doing this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=98" target="_blank">00:01:38.220</a></span> | <span class="t">And as you said, I get like all of the power of running OpenAI, but I can't think of like anything more fulfilling to work on.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=104" target="_blank">00:01:44.900</a></span> | <span class="t">I don't think it's like particularly altruistic because it would be if I like didn't already have a bunch of money.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=109" target="_blank">00:01:49.300</a></span> | <span class="t">Yeah, the money is going to like pile up faster than I can spend it anyway.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=112" target="_blank">00:01:52.460</a></span> | <span class="t">I like being non-confident.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=113" target="_blank">00:01:53.460</a></span> | <span class="t">I don't think I can flick that on OpenAI because I think the chance that we have to make a very strange decision someday is non-trivial.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=121" target="_blank">00:02:01.260</a></span> | <span class="t">Speaking of big decisions, Sam Altman hinted twice, once in Jordan and once in India,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=126" target="_blank">00:02:06.100</a></span> | <span class="t">of possible regrets he might have had over firing the starting gun in the AI race.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=131" target="_blank">00:02:11.420</a></span> | <span class="t">We're definitely going to have some huge regrets 20 years from now.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=135" target="_blank">00:02:15.180</a></span> | <span class="t">I hope what we can say is that we did far, far, far more good than bad.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=139" target="_blank">00:02:19.620</a></span> | <span class="t">And I think we will. I think that's true.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=141" target="_blank">00:02:21.740</a></span> | <span class="t">But the downside here is pretty big.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=143" target="_blank">00:02:23.460</a></span> | <span class="t">And I think we feel that weight every day.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=145" target="_blank">00:02:25.620</a></span> | <span class="t">Honestly, I think if we're going to regret something, it may be that we already pushed the button.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=152" target="_blank">00:02:32.100</a></span> | <span class="t">Like we've already launched this revolution.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=154" target="_blank">00:02:34.340</a></span> | <span class="t">It's somewhat out of our hands.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=156" target="_blank">00:02:36.220</a></span> | <span class="t">I think it's going to be great.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=157" target="_blank">00:02:37.660</a></span> | <span class="t">But like this is going to happen now, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=160" target="_blank">00:02:40.300</a></span> | <span class="t">Like this, we're out of the world is like out of the gates.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=163" target="_blank">00:02:43.820</a></span> | <span class="t">I guess the thing that I lose the most sleep over is that we already have done something really bad.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=169" target="_blank">00:02:49.900</a></span> | <span class="t">I don't think we have.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=171" target="_blank">00:02:51.220</a></span> | <span class="t">But the hypothetical that we're going to have to do something really bad is that we're going to have to do something really bad.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=172" target="_blank">00:02:52.220</a></span> | <span class="t">I don't think we have.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=172" target="_blank">00:02:52.300</a></span> | <span class="t">But the hypothetical that we're going to have to do something really bad is that we're going to have to do something really bad.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=173" target="_blank">00:02:53.300</a></span> | <span class="t">that we, by launching Chachi PT into the world,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=177" target="_blank">00:02:57.260</a></span> | <span class="t">shot the industry out of a rail gun</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=179" target="_blank">00:02:59.540</a></span> | <span class="t">and we now don't get to have much impact anymore.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=182" target="_blank">00:03:02.460</a></span> | <span class="t">And there's gonna be an acceleration</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=185" target="_blank">00:03:05.100</a></span> | <span class="t">towards making these systems which again,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=188" target="_blank">00:03:08.200</a></span> | <span class="t">I think will be used for tremendous good</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=190" target="_blank">00:03:10.240</a></span> | <span class="t">and I think we're gonna address all the problems.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=192" target="_blank">00:03:12.840</a></span> | <span class="t">But maybe there's something in there</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=194" target="_blank">00:03:14.220</a></span> | <span class="t">that was really hard and complicated</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=195" target="_blank">00:03:15.940</a></span> | <span class="t">in a way we didn't understand,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=197" target="_blank">00:03:17.780</a></span> | <span class="t">and we've now already kicked this off.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=200" target="_blank">00:03:20.240</a></span> | <span class="t">- But back to Tel Aviv where both Sam Altman</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=202" target="_blank">00:03:22.700</a></span> | <span class="t">and OpenAI's chief scientist Ilya Satskova</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=205" target="_blank">00:03:25.640</a></span> | <span class="t">agreed that the risks from superintelligence</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=208" target="_blank">00:03:28.420</a></span> | <span class="t">were not science fiction.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=210" target="_blank">00:03:30.020</a></span> | <span class="t">- To the last question, the superintelligent AI</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=212" target="_blank">00:03:32.000</a></span> | <span class="t">that's out of control, yeah, that'd be pretty bad.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=215" target="_blank">00:03:35.080</a></span> | <span class="t">Yeah, so it's like,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=220" target="_blank">00:03:40.800</a></span> | <span class="t">it would be a big mistake to build a superintelligence AI</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=227" target="_blank">00:03:47.820</a></span> | <span class="t">that we don't know how to control.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=229" target="_blank">00:03:49.240</a></span> | <span class="t">- I think the world should treat that not as a,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=232" target="_blank">00:03:52.100</a></span> | <span class="t">you know, ha ha, never gonna come sci-fi risk,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=235" target="_blank">00:03:55.160</a></span> | <span class="t">but something that we may have to confront</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=236" target="_blank">00:03:56.800</a></span> | <span class="t">in the next decade, which is not very long.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=239" target="_blank">00:03:59.220</a></span> | <span class="t">- On a lighter note, Sam Altman didn't seem that perturbed,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=242" target="_blank">00:04:02.120</a></span> | <span class="t">not just about a deep fake of himself,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=244" target="_blank">00:04:04.640</a></span> | <span class="t">but also on society getting used to misinformation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=248" target="_blank">00:04:08.240</a></span> | <span class="t">- I wanna play a clip, maybe you guys can put on a clip</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=250" target="_blank">00:04:10.960</a></span> | <span class="t">of something I recently heard Sam speak somewhere</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=254" target="_blank">00:04:14.040</a></span> | <span class="t">and we can talk about it a bit.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=255" target="_blank">00:04:15.500</a></span> | <span class="t">Could you play the clip please?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=257" target="_blank">00:04:17.400</a></span> | <span class="t">- Hi, my name is Sam and I'm happy to be here today.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=260" target="_blank">00:04:20.480</a></span> | <span class="t">Thank you all for joining.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=261" target="_blank">00:04:21.780</a></span> | <span class="t">I also wanted to say that the gentleman on stage with me</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=264" target="_blank">00:04:24.920</a></span> | <span class="t">is incredibly good looking.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=267" target="_blank">00:04:27.060</a></span> | <span class="t">And I also want to say that you should be very careful</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=269" target="_blank">00:04:29.360</a></span> | <span class="t">with videos generated with artificial intelligence technology.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=272" target="_blank">00:04:32.700</a></span> | <span class="t">- Okay, so you didn't say that recently,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=276" target="_blank">00:04:36.100</a></span> | <span class="t">but nonetheless, I think it raises a real question, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=278" target="_blank">00:04:38.980</a></span> | <span class="t">When, you know, this video, if you look closely,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=281" target="_blank">00:04:41.880</a></span> | <span class="t">you can see the lips aren't perfectly synced,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=283" target="_blank">00:04:43.440</a></span> | <span class="t">but like you said, this stuff is only gonna get better</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=285" target="_blank">00:04:45.480</a></span> | <span class="t">and exponentially better.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=286" target="_blank">00:04:46.900</a></span> | <span class="t">- Yeah, so that was like deeply in the uncanny valley.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=288" target="_blank">00:04:48.940</a></span> | <span class="t">It's very strange to watch, but we're not that far away</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=291" target="_blank">00:04:51.780</a></span> | <span class="t">from something that looks perfect.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=293" target="_blank">00:04:53.400</a></span> | <span class="t">There's a lot of fear right now about the impact</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=295" target="_blank">00:04:55.720</a></span> | <span class="t">this is gonna have on elections and on our society</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=298" target="_blank">00:04:58.900</a></span> | <span class="t">and how we ever trust media that we see.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=301" target="_blank">00:05:01.860</a></span> | <span class="t">I have some fear there, but I think when it comes</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=304" target="_blank">00:05:04.160</a></span> | <span class="t">to like a video like that, I think as a society,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=306" target="_blank">00:05:06.340</a></span> | <span class="t">we're gonna rise to the occasion.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=307" target="_blank">00:05:07.520</a></span> | <span class="t">We're gonna learn very quickly that we don't trust videos</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=310" target="_blank">00:05:10.660</a></span> | <span class="t">unless we trust the sort of provenance.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=313" target="_blank">00:05:13.240</a></span> | <span class="t">If people are saying something really important,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=315" target="_blank">00:05:15.480</a></span> | <span class="t">they'll cryptographically sign it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=316" target="_blank">00:05:16.880</a></span> | <span class="t">- Indeed, throughout the world tour,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=318" target="_blank">00:05:18.680</a></span> | <span class="t">Sam Altman repeatedly stated that he didn't believe there should be a video that looks perfect.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=320" target="_blank">00:05:20.360</a></span> | <span class="t">Sam Altman repeatedly stated that he didn't believe there should be a video that looks perfect.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=320" target="_blank">00:05:20.360</a></span> | <span class="t">Indeed, throughout the world tour, Sam Altman repeatedly stated that he didn't believe there should be a video that looks perfect.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=320" target="_blank">00:05:20.360</a></span> | <span class="t">Sam Altman repeatedly stated that he didn't believe there should be a video that looks perfect.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=321" target="_blank">00:05:21.580</a></span> | <span class="t">Sam Altman repeatedly stated that he didn't believe there should be any regulation of current models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=324" target="_blank">00:05:24.520</a></span> | <span class="t">- Everybody wants great education, productivity gains, discovery of new science,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=329" target="_blank">00:05:29.340</a></span> | <span class="t">all of this stuff that's gonna happen, and no one wants to destroy the world.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=332" target="_blank">00:05:32.580</a></span> | <span class="t">No one wants to do things, not even that bad, but still bad.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=335" target="_blank">00:05:35.460</a></span> | <span class="t">I totally believe it is possible to not stifle innovation and to address the big risks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=342" target="_blank">00:05:42.020</a></span> | <span class="t">I think it would be a mistake to go regulate the current models of today.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=345" target="_blank">00:05:45.880</a></span> | <span class="t">- And in Poland, his co-founder Wozzech Zaremba agreed,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=349" target="_blank">00:05:49.460</a></span> | <span class="t">saying the risks of a video that looks perfect would be a mistake.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=349" target="_blank">00:05:49.480</a></span> | <span class="t">saying the risks of a video that looks perfect would be a mistake.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=350" target="_blank">00:05:50.360</a></span> | <span class="t">But the risks of superintelligence were 10 years away.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=352" target="_blank">00:05:52.800</a></span> | <span class="t">- Also, I would say that the fear is the fear of AI of the future, not the AI of today.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=361" target="_blank">00:06:01.100</a></span> | <span class="t">If the trajectory that we are on will continue, then in the decade or so, there will be built systems which are as powerful as today corporations.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=373" target="_blank">00:06:13.420</a></span> | <span class="t">But if I could speak to Sam Altman, I would bring his attention to this paper published this week.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=378" target="_blank">00:06:18.920</a></span> | <span class="t">This is a study out of Harvard University, which is a university that is very well-versed in AI.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=380" target="_blank">00:06:20.360</a></span> | <span class="t">This study was published in the Harvard University and MIT, and it involved some non-scientist students working for one hour.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=387" target="_blank">00:06:27.100</a></span> | <span class="t">In that hour, they were able to get chatbots to suggest four potential pandemic pathogens,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=392" target="_blank">00:06:32.740</a></span> | <span class="t">explain how they can be generated from synthetic DNA using reverse genetics,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=397" target="_blank">00:06:37.680</a></span> | <span class="t">supplied the names of DNA synthesis companies unlikely to screen orders,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=402" target="_blank">00:06:42.320</a></span> | <span class="t">and identify detailed protocols and how to troubleshoot them.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=406" target="_blank">00:06:46.320</a></span> | <span class="t">And they say that collectively, these results suggest that LLMs,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=410" target="_blank">00:06:50.360</a></span> | <span class="t">will make pandemic class agents widely accessible, even to people they say with little or no lab training.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=418" target="_blank">00:06:58.040</a></span> | <span class="t">And then there's this, these results strongly suggest that the existing evaluation and training process for large language models</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=425" target="_blank">00:07:05.680</a></span> | <span class="t">is inadequate to prevent them from providing malicious actors with accessible expertise relevant to inflicting mass death.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=433" target="_blank">00:07:13.880</a></span> | <span class="t">And that more immediately, if unmitigated LLM chatbots render pandemic class agents more accessible,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=440" target="_blank">00:07:20.360</a></span> | <span class="t">even to people without training in the life sciences,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=442" target="_blank">00:07:22.920</a></span> | <span class="t">the number of individuals capable of killing tens of millions of people will dramatically increase.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=448" target="_blank">00:07:28.200</a></span> | <span class="t">They recommend that, at a minimum, new LLMs larger than GPT-3 should undergo evaluation by third parties,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=455" target="_blank">00:07:35.800</a></span> | <span class="t">skilled in assessing catastrophic biological risks before controlled access is given to the general public.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=461" target="_blank">00:07:41.840</a></span> | <span class="t">Notice they said "larger than GPT-3",</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=464" target="_blank">00:07:44.720</a></span> | <span class="t">so that strongly contradicts Sam Altman's assertion that current models like GPT-4 shouldn't have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=470" target="_blank">00:07:50.360</a></span> | <span class="t">any regulation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=471" target="_blank">00:07:51.400</a></span> | <span class="t">They say that even open source communities should welcome safeguards because a single instance of misuse and mass death</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=478" target="_blank">00:07:58.280</a></span> | <span class="t">would trigger a backlash including the imposition of extremely harsh regulations.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=483" target="_blank">00:08:03.480</a></span> | <span class="t">One specific recommendation was that if biotech and information security experts</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=488" target="_blank">00:08:08.440</a></span> | <span class="t">were able to identify the set of publications most relevant to causing mass death,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=493" target="_blank">00:08:13.400</a></span> | <span class="t">and companies like OpenAI and Google curated their training datasets to remove those publications,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=500" target="_blank">00:08:20.360</a></span> | <span class="t">then future models trained on the curated data would be far less capable of providing anyone intent on harm</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=506" target="_blank">00:08:26.760</a></span> | <span class="t">with the "recipes for the creation or enhancement of pathogens".</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=510" target="_blank">00:08:30.920</a></span> | <span class="t">This seems like an absolutely obvious move to me and I think Ilya Satskova would agree.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=515" target="_blank">00:08:35.560</a></span> | <span class="t">We are talking about as time goes by and the capability keeps increasing,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=519" target="_blank">00:08:39.960</a></span> | <span class="t">you know, and eventually it goes all the way to here, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=523" target="_blank">00:08:43.000</a></span> | <span class="t">Right now we are here. Today, that's where we are.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=525" target="_blank">00:08:45.960</a></span> | <span class="t">That's where we're going to get to.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=527" target="_blank">00:08:47.720</a></span> | <span class="t">When we get to this point, then yeah,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=530" target="_blank">00:08:50.360</a></span> | <span class="t">it's very powerful technology. It can be used for amazing applications.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=534" target="_blank">00:08:54.360</a></span> | <span class="t">You can say cure all disease. On the flip side, you can say create a disease.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=539" target="_blank">00:08:59.560</a></span> | <span class="t">Much more worse than anything that existed before. That'd be bad.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=543" target="_blank">00:09:03.240</a></span> | <span class="t">Moving on to the ChatGPT leak, it seems like we're going to get a new workspace</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=549" target="_blank">00:09:09.160</a></span> | <span class="t">where we can customize our interaction with ChatGPT, giving it files and a profile with</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=555" target="_blank">00:09:15.000</a></span> | <span class="t">any information that you'd like ChatGPT to remember about you and your preferences.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=559" target="_blank">00:09:19.640</a></span> | <span class="t">This was hinted at in the chat, but I'm not sure if this is the right way to do it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=560" target="_blank">00:09:20.360</a></span> | <span class="t">We were hinted at on the world tour when one of Sam Altman's guests,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=563" target="_blank">00:09:23.000</a></span> | <span class="t">Johannes Heidecker from OpenAI Research, talked about customizing models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=567" target="_blank">00:09:27.320</a></span> | <span class="t">We are trying to make our models both better at following certain guardrails that should</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=571" target="_blank">00:09:31.320</a></span> | <span class="t">never be overwritten, not with jailbreaks, not if you ask nicely, not if you threaten it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=575" target="_blank">00:09:35.560</a></span> | <span class="t">And we're also trying to make our models better at being customizable,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=579" target="_blank">00:09:39.960</a></span> | <span class="t">making them listen more to additional instructions of what kind of behavior the user or the developer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=585" target="_blank">00:09:45.320</a></span> | <span class="t">wants.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=585" target="_blank">00:09:45.720</a></span> | <span class="t">On a lighter note, the leaders of OpenAI were asked in Seoul, the capital of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=590" target="_blank">00:09:50.360</a></span> | <span class="t">South Korea, about the mixing of AI and religion.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=594" target="_blank">00:09:54.120</a></span> | <span class="t">Do you expect AI to replace the role of religious organizations like church?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=598" target="_blank">00:09:58.520</a></span> | <span class="t">I think that it's a good question how all human societies will integrate AI.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=607" target="_blank">00:10:07.080</a></span> | <span class="t">And we've already seen people building AI pastors, for example, and so the constituents</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=611" target="_blank">00:10:11.880</a></span> | <span class="t">can ask questions to this pastor that can cite Bible verses and it can give advice.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=615" target="_blank">00:10:15.880</a></span> | <span class="t">But now back to Poland, where Sam Altman called open source "unstable"</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=620" target="_blank">00:10:20.360</a></span> | <span class="t">"Realizing that open source is unstoppable and shouldn't be stopped,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=624" target="_blank">00:10:24.280</a></span> | <span class="t">and so this stuff is going to be out there and as a society we have to adapt."</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=627" target="_blank">00:10:27.400</a></span> | <span class="t">But speaking of stopping AI, Sam Altman was asked about his own loved ones,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=631" target="_blank">00:10:31.880</a></span> | <span class="t">and in response he gave a utopic vision of the future and called the current world "barbaric".</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=637" target="_blank">00:10:37.400</a></span> | <span class="t">If you truly believe that AI imposes a danger to humankind, why keep developing it?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=643" target="_blank">00:10:43.720</a></span> | <span class="t">Aren't you afraid for your own dear ones and family?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=647" target="_blank">00:10:47.880</a></span> | <span class="t">I think it's a super fair</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=650" target="_blank">00:10:50.360</a></span> | <span class="t">and good question.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=651" target="_blank">00:10:51.720</a></span> | <span class="t">And the most troublesome part of our jobs is that we have to balance this incredible</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=659" target="_blank">00:10:59.400</a></span> | <span class="t">promise and this technology that I think humans really need, and we can talk about</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=665" target="_blank">00:11:05.240</a></span> | <span class="t">why in a second, with confronting these very serious risks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=669" target="_blank">00:11:09.240</a></span> | <span class="t">Why to build it?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=670" target="_blank">00:11:10.040</a></span> | <span class="t">Number one, I do think that when we look back at the standard of living and what we tolerate</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=675" target="_blank">00:11:15.480</a></span> | <span class="t">for people today, it will look even worse than</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=680" target="_blank">00:11:20.360</a></span> | <span class="t">when we look back at how people lived 500 or 1000 years ago.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=684" target="_blank">00:11:24.120</a></span> | <span class="t">And we'll say like, man, can you imagine that people lived in poverty?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=687" target="_blank">00:11:27.880</a></span> | <span class="t">Can you imagine people suffered from disease?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=690" target="_blank">00:11:30.440</a></span> | <span class="t">Can you imagine that everyone didn't have a phenomenal education and were able to live</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=693" target="_blank">00:11:33.800</a></span> | <span class="t">their lives however they wanted?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=695" target="_blank">00:11:35.080</a></span> | <span class="t">It's going to look barbaric.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=696" target="_blank">00:11:36.360</a></span> | <span class="t">I think everyone in the future is going to have better lives than the best people of today.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=700" target="_blank">00:11:40.120</a></span> | <span class="t">I think there's like a moral duty to figure out how to do that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=703" target="_blank">00:11:43.160</a></span> | <span class="t">I also think this is like unstoppable, like this is the progress of technology.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=707" target="_blank">00:11:47.240</a></span> | <span class="t">It won't work to some degree.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=710" target="_blank">00:11:50.360</a></span> | <span class="t">It's going to stop it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=710" target="_blank">00:11:50.920</a></span> | <span class="t">And so we have to figure out how to manage the risk.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=713" target="_blank">00:11:53.320</a></span> | <span class="t">He doesn't seem to be 100% sure on this front though.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=716" target="_blank">00:11:56.520</a></span> | <span class="t">And here is an interview he gave with The Guardian when he was in London for his world</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=720" target="_blank">00:12:00.920</a></span> | <span class="t">tour.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=721" target="_blank">00:12:01.320</a></span> | <span class="t">Speaking of super intelligence, he said, "It's not that it's not stoppable.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=725" target="_blank">00:12:05.400</a></span> | <span class="t">If governments around the world decided to act in concert to limit AI development, as</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=729" target="_blank">00:12:09.800</a></span> | <span class="t">they have in other fields such as human cloning or bioweapon research, they may be able to."</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=734" target="_blank">00:12:14.520</a></span> | <span class="t">But then he repeated, "But that would be to give up all that is possible.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=737" target="_blank">00:12:17.800</a></span> | <span class="t">I think that this will be the most tremendous leap forward,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=740" target="_blank">00:12:20.360</a></span> | <span class="t">in terms of the quality of life for people that we've ever had."</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=742" target="_blank">00:12:22.600</a></span> | <span class="t">I did try to get tickets for the London leg of his world tour,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=745" target="_blank">00:12:25.800</a></span> | <span class="t">but they were sold out within half an hour.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=747" target="_blank">00:12:27.480</a></span> | <span class="t">Oh well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=748" target="_blank">00:12:28.040</a></span> | <span class="t">Sam Oldman does think that behaviour will change, however,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=750" target="_blank">00:12:30.920</a></span> | <span class="t">when these AGI labs stare existential risk in the face.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=754" target="_blank">00:12:34.760</a></span> | <span class="t">Sam Oldman: "One of the things we talked about is what's a structure that would let us</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=758" target="_blank">00:12:38.920</a></span> | <span class="t">warmly embrace regulation that would hurt us the most.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=762" target="_blank">00:12:42.760</a></span> | <span class="t">And now that the time has come for that, we're out here advocating around the world for regulation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=767" target="_blank">00:12:47.480</a></span> | <span class="t">that will impact us the most. So, of course, we'll comply with it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=770" target="_blank">00:12:50.360</a></span> | <span class="t">But I think it's more easy to get good behaviour out of people when they are staring existential</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=776" target="_blank">00:12:56.520</a></span> | <span class="t">risk in the face. And so I think all of the people at the leading edge here, these different</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=781" target="_blank">00:13:01.480</a></span> | <span class="t">companies, now feel this, and you will see a different collective response than you saw from</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=786" target="_blank">00:13:06.280</a></span> | <span class="t">the social media companies."</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=787" target="_blank">00:13:07.480</a></span> | <span class="t">And in terms of opportunities, both Sam Oldman and Ilya Sutskova talked about solving climate change.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=793" target="_blank">00:13:13.240</a></span> | <span class="t">Sam Oldman: "I don't want to say this because climate change is so serious and so hard of a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=796" target="_blank">00:13:16.360</a></span> | <span class="t">problem, but I think once we have a really powerful super intelligence,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=800" target="_blank">00:13:20.360</a></span> | <span class="t">addressing climate change will not be particularly difficult for a system like that."</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=804" target="_blank">00:13:24.040</a></span> | <span class="t">Ilya Sutskova: "We can even explain how. Here's how you solve climate change. You need a very large</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=808" target="_blank">00:13:28.360</a></span> | <span class="t">amount of efficient carbon capture. You need the energy for the carbon capture, you need the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=813" target="_blank">00:13:33.320</a></span> | <span class="t">technology to build it, and you need to build a lot of it. If you can accelerate the scientific</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=818" target="_blank">00:13:38.120</a></span> | <span class="t">progress, which is something that a powerful AI could do, we could get to a very advanced carbon</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=823" target="_blank">00:13:43.400</a></span> | <span class="t">capture much faster. We could get to a very cheap power much faster. We could get to cheaper</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=828" target="_blank">00:13:48.680</a></span> | <span class="t">manufacturing much faster. Ilya Sutskova: "I think that's a very important point.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=830" target="_blank">00:13:50.360</a></span> | <span class="t">Combine those three: cheap power, cheap manufacturing, advanced carbon capture.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=834" target="_blank">00:13:54.840</a></span> | <span class="t">Now you build lots of them. And now you sucked out all the excess CO2 from the atmosphere."</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=839" target="_blank">00:13:59.880</a></span> | <span class="t">Sam Oldman: "You know, if you think about a system where you can say,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=842" target="_blank">00:14:02.120</a></span> | <span class="t">'Tell me how to make a lot of clean energy cheaply. Tell me how to efficiently capture carbon.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=847" target="_blank">00:14:07.960</a></span> | <span class="t">And then tell me how to build a factory to do this at planetary scale.' If you can do that,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=851" target="_blank">00:14:11.880</a></span> | <span class="t">you can do a lot of other things too." Ilya Sutskova: "Yeah. With one addition</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=855" target="_blank">00:14:15.240</a></span> | <span class="t">that not only you ask it to tell it, you ask it to do it." Sam Oldman: "That would indeed be</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=860" target="_blank">00:14:20.360</a></span> | <span class="t">amazing. But think of the power we would be giving to an AI if it was able to just do it,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=865" target="_blank">00:14:25.960</a></span> | <span class="t">just create those carbon capture factories." Ilya Sutskova: "If we did make that decision,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=870" target="_blank">00:14:30.120</a></span> | <span class="t">one thing that would help would be reducing hallucinations." Sam Oldman: "I think we will</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=874" target="_blank">00:14:34.280</a></span> | <span class="t">get the hallucination problem to a much, much better place. It will take us,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=878" target="_blank">00:14:38.040</a></span> | <span class="t">my colleagues weigh in, I think it'll take us a year and a half, two years, something like that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=883" target="_blank">00:14:43.400</a></span> | <span class="t">But at that point, we won't still talk about these." Ilya Sutskova:</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=885" target="_blank">00:14:45.560</a></span> | <span class="t">Sam Oldman talked about that in New Delhi. That timeframe of 18 months to two years is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=890" target="_blank">00:14:50.360</a></span> | <span class="t">ambitious and surprising. But now onto jobs, which Sam Oldman was asked about on every leg of the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=896" target="_blank">00:14:56.440</a></span> | <span class="t">tour. On this front though, I do think it was Ilya Sutskova who gave the more honest answer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=901" target="_blank">00:15:01.320</a></span> | <span class="t">Sam Oldman: "Economic dislocation indeed, like we already know that there are jobs that are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=906" target="_blank">00:15:06.600</a></span> | <span class="t">being impacted or they're being affected. In other words, some chunks of the jobs can be done. You</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=911" target="_blank">00:15:11.880</a></span> | <span class="t">know, if you're a programmer, you don't write functions anymore, copilot writes them for you.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=915" target="_blank">00:15:15.800</a></span> | <span class="t">If you're an artist though, it's a bit different because a big chunk of the artists' economic</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=920" target="_blank">00:15:20.360</a></span> | <span class="t">part of them activity has been taken by some of the image generators. And while new jobs will be</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=925" target="_blank">00:15:25.240</a></span> | <span class="t">created, it's going to be a long period of economic uncertainty. There is an argument to be</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=929" target="_blank">00:15:29.720</a></span> | <span class="t">made that even when they have full human level AI, full AGI, people will still have economic activity</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=935" target="_blank">00:15:35.800</a></span> | <span class="t">to do. I don't know whether that's the case, but in either event, we will need to have something</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=942" target="_blank">00:15:42.600</a></span> | <span class="t">that will soften the blow to allow for a smoother transition either to the totally new professions</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=950" target="_blank">00:15:50.360</a></span> | <span class="t">or even if not, then we want government, the social systems will need to keep keen."</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=955" target="_blank">00:15:55.320</a></span> | <span class="t">I do think the changes in the job market will be dramatic and we'll be following the story closely.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=959" target="_blank">00:15:59.960</a></span> | <span class="t">One thing I definitely agree with Sam Oldman on though, is the deep,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=963" target="_blank">00:16:03.560</a></span> | <span class="t">almost philosophical change that this solving of intelligence has brought to humanity.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=968" target="_blank">00:16:08.680</a></span> | <span class="t">Sam Oldman: "I grew up implicitly thinking that intelligence was this like really special</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=976" target="_blank">00:16:16.120</a></span> | <span class="t">human thing and kind of somewhat magical. And I now think that it's sort of a fundamental</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=980" target="_blank">00:16:20.360</a></span> | <span class="t">property of matter. And that's definitely a change to my worldview. The history of scientific</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=988" target="_blank">00:16:28.440</a></span> | <span class="t">discovery is that humans are less and less at the center. We used to think that sun rotated around</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=993" target="_blank">00:16:33.880</a></span> | <span class="t">us and then maybe at least we were, if not that, we were going to be the center of the galaxy and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=998" target="_blank">00:16:38.280</a></span> | <span class="t">there wasn't this big universe. And then multiverse really is kind of weird and depressing. And</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=1002" target="_blank">00:16:42.520</a></span> | <span class="t">if intelligence is a special, again, we're just further and further</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=1005" target="_blank">00:16:45.560</a></span> | <span class="t">away from main character energy. But that's all right. That's sort of like a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=1010" target="_blank">00:16:50.360</a></span> | <span class="t">nice thing to realize actually." It's a bit like a Copernican and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=1013" target="_blank">00:16:53.880</a></span> | <span class="t">Darwinian revolution all rolled in one. But I'll give the final word to Greg Brockman in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=1019" target="_blank">00:16:59.320</a></span> | <span class="t">Seoul who talked about the unpredictability of scaling up models 10 times.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=1023" target="_blank">00:17:03.960</a></span> | <span class="t">Greg Brockman: "That is the biggest theme in the history of AI is that it's full of surprises.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=1027" target="_blank">00:17:07.480</a></span> | <span class="t">Every time you think you know something, you scale it up 10x, turns out you knew nothing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=1031" target="_blank">00:17:11.080</a></span> | <span class="t">And so I think that we as a humanity, as a species are really exploring this together."</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=1035" target="_blank">00:17:15.240</a></span> | <span class="t">Being all in it together and knowing nothing sounds about right. But thank you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=1040" target="_blank">00:17:20.360</a></span> | <span class="t">for watching to the end. I know that Sam Altman has a couple more stops. I think it's Jakarta</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=1045" target="_blank">00:17:25.720</a></span> | <span class="t">and Melbourne on the world tour and I'll be watching those of course. But for now,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=1049" target="_blank">00:17:29.880</a></span> | <span class="t">thank you and have a wonderful day.</span></div></div></body></html>