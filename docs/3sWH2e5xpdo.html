<html><head><title>Sam Altman's World Tour, in 16 Moments</title></head><body><a href="index.html">back to index</a><h2>Sam Altman's World Tour, in 16 Moments</h2><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo"><img src="https://i.ytimg.com/vi/3sWH2e5xpdo/maxresdefault.jpg" style="width:50%;"></a><div><br></div><h3>Chapters</h3><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=0">0:0</a> <Untitled Chapter 1><br><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=87">1:27</a> 'Strange Decisions'<br><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=547">9:7</a> Customise ChatGPT<br><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=619">10:19</a> Opensource 'unstoppable'<br><br><div style="text-align: left;"><a href="./3sWH2e5xpdo.html">Whisper Transcript</a> | <a href="./transcript_3sWH2e5xpdo.html">Transcript Only Page</a></div><br><div style="max-width: 800px;"><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=0">00:00:00.000</a></span> | <span class="t">There have been 16 surprising and or fascinating moments from Sam Altman's world tour.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=6">00:00:06.880</a></span> | <span class="t">I could have done a video on each of them, but after watching over 10 hours of interviews,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=11">00:00:11.780</a></span> | <span class="t">I decided, you know what, let's just show you everything in one video.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=15">00:00:15.940</a></span> | <span class="t">From AIs designing new AIs, to fresh ChatGPT leaks, shooting railguns, to open source,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=23">00:00:23.740</a></span> | <span class="t">here's all 16 things I learnt in no particular order.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=27">00:00:27.480</a></span> | <span class="t">Let's start with Sam Altman's warning about AIs designing their own architecture.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=32">00:00:32.940</a></span> | <span class="t">Seems like a good idea, but Satsukawa could see one of their models designing the next model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=54">00:00:54.260</a></span> | <span class="t">We are definitely very concerned about superintelligence.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=57">00:00:57.460</a></span> | <span class="t">It will be possible to build a computer, a computer cluster, a GPU farm, that is just smarter than any person,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=64">00:01:04.820</a></span> | <span class="t">that can do science and engineering much, much faster than even a large team of really experienced scientists and engineers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=71">00:01:11.700</a></span> | <span class="t">And that is crazy. That is going to be unbelievably, extremely impactful.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=77">00:01:17.060</a></span> | <span class="t">It could engineer the next version of the system.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=80">00:01:20.780</a></span> | <span class="t">AI building AI. It's just crazy.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=83">00:01:23.540</a></span> | <span class="t">Let's return to Abu Dhabi where Sam Altman said he enjoys the power that being CEO of OpenAI brings,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=92">00:01:32.180</a></span> | <span class="t">but also mentioned strange decisions he might have to make.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=96">00:01:36.020</a></span> | <span class="t">I mean, I have like lots of selfish reasons for doing this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=98">00:01:38.220</a></span> | <span class="t">And as you said, I get like all of the power of running OpenAI, but I can't think of like anything more fulfilling to work on.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=104">00:01:44.900</a></span> | <span class="t">I don't think it's like particularly altruistic because it would be if I like didn't already have a bunch of money.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=109">00:01:49.300</a></span> | <span class="t">Yeah, the money is going to like pile up faster than I can spend it anyway.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=112">00:01:52.460</a></span> | <span class="t">I like being non-confident.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=113">00:01:53.460</a></span> | <span class="t">I don't think I can flick that on OpenAI because I think the chance that we have to make a very strange decision someday is non-trivial.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=121">00:02:01.260</a></span> | <span class="t">Speaking of big decisions, Sam Altman hinted twice, once in Jordan and once in India,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=126">00:02:06.100</a></span> | <span class="t">of possible regrets he might have had over firing the starting gun in the AI race.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=131">00:02:11.420</a></span> | <span class="t">We're definitely going to have some huge regrets 20 years from now.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=135">00:02:15.180</a></span> | <span class="t">I hope what we can say is that we did far, far, far more good than bad.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=139">00:02:19.620</a></span> | <span class="t">And I think we will. I think that's true.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=141">00:02:21.740</a></span> | <span class="t">But the downside here is pretty big.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=143">00:02:23.460</a></span> | <span class="t">And I think we feel that weight every day.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=145">00:02:25.620</a></span> | <span class="t">Honestly, I think if we're going to regret something, it may be that we already pushed the button.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=152">00:02:32.100</a></span> | <span class="t">Like we've already launched this revolution.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=154">00:02:34.340</a></span> | <span class="t">It's somewhat out of our hands.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=156">00:02:36.220</a></span> | <span class="t">I think it's going to be great.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=157">00:02:37.660</a></span> | <span class="t">But like this is going to happen now, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=160">00:02:40.300</a></span> | <span class="t">Like this, we're out of the world is like out of the gates.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=163">00:02:43.820</a></span> | <span class="t">I guess the thing that I lose the most sleep over is that we already have done something really bad.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=169">00:02:49.900</a></span> | <span class="t">I don't think we have.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=171">00:02:51.220</a></span> | <span class="t">But the hypothetical that we're going to have to do something really bad is that we're going to have to do something really bad.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=172">00:02:52.220</a></span> | <span class="t">I don't think we have.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=172">00:02:52.300</a></span> | <span class="t">But the hypothetical that we're going to have to do something really bad is that we're going to have to do something really bad.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=173">00:02:53.300</a></span> | <span class="t">that we, by launching Chachi PT into the world,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=177">00:02:57.260</a></span> | <span class="t">shot the industry out of a rail gun</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=179">00:02:59.540</a></span> | <span class="t">and we now don't get to have much impact anymore.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=182">00:03:02.460</a></span> | <span class="t">And there's gonna be an acceleration</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=185">00:03:05.100</a></span> | <span class="t">towards making these systems which again,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=188">00:03:08.200</a></span> | <span class="t">I think will be used for tremendous good</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=190">00:03:10.240</a></span> | <span class="t">and I think we're gonna address all the problems.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=192">00:03:12.840</a></span> | <span class="t">But maybe there's something in there</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=194">00:03:14.220</a></span> | <span class="t">that was really hard and complicated</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=195">00:03:15.940</a></span> | <span class="t">in a way we didn't understand,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=197">00:03:17.780</a></span> | <span class="t">and we've now already kicked this off.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=200">00:03:20.240</a></span> | <span class="t">- But back to Tel Aviv where both Sam Altman</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=202">00:03:22.700</a></span> | <span class="t">and OpenAI's chief scientist Ilya Satskova</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=205">00:03:25.640</a></span> | <span class="t">agreed that the risks from superintelligence</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=208">00:03:28.420</a></span> | <span class="t">were not science fiction.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=210">00:03:30.020</a></span> | <span class="t">- To the last question, the superintelligent AI</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=212">00:03:32.000</a></span> | <span class="t">that's out of control, yeah, that'd be pretty bad.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=215">00:03:35.080</a></span> | <span class="t">Yeah, so it's like,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=220">00:03:40.800</a></span> | <span class="t">it would be a big mistake to build a superintelligence AI</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=227">00:03:47.820</a></span> | <span class="t">that we don't know how to control.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=229">00:03:49.240</a></span> | <span class="t">- I think the world should treat that not as a,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=232">00:03:52.100</a></span> | <span class="t">you know, ha ha, never gonna come sci-fi risk,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=235">00:03:55.160</a></span> | <span class="t">but something that we may have to confront</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=236">00:03:56.800</a></span> | <span class="t">in the next decade, which is not very long.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=239">00:03:59.220</a></span> | <span class="t">- On a lighter note, Sam Altman didn't seem that perturbed,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=242">00:04:02.120</a></span> | <span class="t">not just about a deep fake of himself,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=244">00:04:04.640</a></span> | <span class="t">but also on society getting used to misinformation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=248">00:04:08.240</a></span> | <span class="t">- I wanna play a clip, maybe you guys can put on a clip</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=250">00:04:10.960</a></span> | <span class="t">of something I recently heard Sam speak somewhere</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=254">00:04:14.040</a></span> | <span class="t">and we can talk about it a bit.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=255">00:04:15.500</a></span> | <span class="t">Could you play the clip please?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=257">00:04:17.400</a></span> | <span class="t">- Hi, my name is Sam and I'm happy to be here today.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=260">00:04:20.480</a></span> | <span class="t">Thank you all for joining.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=261">00:04:21.780</a></span> | <span class="t">I also wanted to say that the gentleman on stage with me</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=264">00:04:24.920</a></span> | <span class="t">is incredibly good looking.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=267">00:04:27.060</a></span> | <span class="t">And I also want to say that you should be very careful</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=269">00:04:29.360</a></span> | <span class="t">with videos generated with artificial intelligence technology.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=272">00:04:32.700</a></span> | <span class="t">- Okay, so you didn't say that recently,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=276">00:04:36.100</a></span> | <span class="t">but nonetheless, I think it raises a real question, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=278">00:04:38.980</a></span> | <span class="t">When, you know, this video, if you look closely,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=281">00:04:41.880</a></span> | <span class="t">you can see the lips aren't perfectly synced,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=283">00:04:43.440</a></span> | <span class="t">but like you said, this stuff is only gonna get better</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=285">00:04:45.480</a></span> | <span class="t">and exponentially better.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=286">00:04:46.900</a></span> | <span class="t">- Yeah, so that was like deeply in the uncanny valley.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=288">00:04:48.940</a></span> | <span class="t">It's very strange to watch, but we're not that far away</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=291">00:04:51.780</a></span> | <span class="t">from something that looks perfect.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=293">00:04:53.400</a></span> | <span class="t">There's a lot of fear right now about the impact</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=295">00:04:55.720</a></span> | <span class="t">this is gonna have on elections and on our society</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=298">00:04:58.900</a></span> | <span class="t">and how we ever trust media that we see.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=301">00:05:01.860</a></span> | <span class="t">I have some fear there, but I think when it comes</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=304">00:05:04.160</a></span> | <span class="t">to like a video like that, I think as a society,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=306">00:05:06.340</a></span> | <span class="t">we're gonna rise to the occasion.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=307">00:05:07.520</a></span> | <span class="t">We're gonna learn very quickly that we don't trust videos</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=310">00:05:10.660</a></span> | <span class="t">unless we trust the sort of provenance.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=313">00:05:13.240</a></span> | <span class="t">If people are saying something really important,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=315">00:05:15.480</a></span> | <span class="t">they'll cryptographically sign it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=316">00:05:16.880</a></span> | <span class="t">- Indeed, throughout the world tour,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=318">00:05:18.680</a></span> | <span class="t">Sam Altman repeatedly stated that he didn't believe there should be a video that looks perfect.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=320">00:05:20.360</a></span> | <span class="t">Sam Altman repeatedly stated that he didn't believe there should be a video that looks perfect.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=320">00:05:20.360</a></span> | <span class="t">Indeed, throughout the world tour, Sam Altman repeatedly stated that he didn't believe there should be a video that looks perfect.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=320">00:05:20.360</a></span> | <span class="t">Sam Altman repeatedly stated that he didn't believe there should be a video that looks perfect.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=321">00:05:21.580</a></span> | <span class="t">Sam Altman repeatedly stated that he didn't believe there should be any regulation of current models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=324">00:05:24.520</a></span> | <span class="t">- Everybody wants great education, productivity gains, discovery of new science,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=329">00:05:29.340</a></span> | <span class="t">all of this stuff that's gonna happen, and no one wants to destroy the world.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=332">00:05:32.580</a></span> | <span class="t">No one wants to do things, not even that bad, but still bad.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=335">00:05:35.460</a></span> | <span class="t">I totally believe it is possible to not stifle innovation and to address the big risks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=342">00:05:42.020</a></span> | <span class="t">I think it would be a mistake to go regulate the current models of today.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=345">00:05:45.880</a></span> | <span class="t">- And in Poland, his co-founder Wozzech Zaremba agreed,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=349">00:05:49.460</a></span> | <span class="t">saying the risks of a video that looks perfect would be a mistake.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=349">00:05:49.480</a></span> | <span class="t">saying the risks of a video that looks perfect would be a mistake.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=350">00:05:50.360</a></span> | <span class="t">But the risks of superintelligence were 10 years away.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=352">00:05:52.800</a></span> | <span class="t">- Also, I would say that the fear is the fear of AI of the future, not the AI of today.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=361">00:06:01.100</a></span> | <span class="t">If the trajectory that we are on will continue, then in the decade or so, there will be built systems which are as powerful as today corporations.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=373">00:06:13.420</a></span> | <span class="t">But if I could speak to Sam Altman, I would bring his attention to this paper published this week.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=378">00:06:18.920</a></span> | <span class="t">This is a study out of Harvard University, which is a university that is very well-versed in AI.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=380">00:06:20.360</a></span> | <span class="t">This study was published in the Harvard University and MIT, and it involved some non-scientist students working for one hour.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=387">00:06:27.100</a></span> | <span class="t">In that hour, they were able to get chatbots to suggest four potential pandemic pathogens,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=392">00:06:32.740</a></span> | <span class="t">explain how they can be generated from synthetic DNA using reverse genetics,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=397">00:06:37.680</a></span> | <span class="t">supplied the names of DNA synthesis companies unlikely to screen orders,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=402">00:06:42.320</a></span> | <span class="t">and identify detailed protocols and how to troubleshoot them.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=406">00:06:46.320</a></span> | <span class="t">And they say that collectively, these results suggest that LLMs,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=410">00:06:50.360</a></span> | <span class="t">will make pandemic class agents widely accessible, even to people they say with little or no lab training.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=418">00:06:58.040</a></span> | <span class="t">And then there's this, these results strongly suggest that the existing evaluation and training process for large language models</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=425">00:07:05.680</a></span> | <span class="t">is inadequate to prevent them from providing malicious actors with accessible expertise relevant to inflicting mass death.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=433">00:07:13.880</a></span> | <span class="t">And that more immediately, if unmitigated LLM chatbots render pandemic class agents more accessible,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=440">00:07:20.360</a></span> | <span class="t">even to people without training in the life sciences,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=442">00:07:22.920</a></span> | <span class="t">the number of individuals capable of killing tens of millions of people will dramatically increase.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=448">00:07:28.200</a></span> | <span class="t">They recommend that, at a minimum, new LLMs larger than GPT-3 should undergo evaluation by third parties,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=455">00:07:35.800</a></span> | <span class="t">skilled in assessing catastrophic biological risks before controlled access is given to the general public.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=461">00:07:41.840</a></span> | <span class="t">Notice they said "larger than GPT-3",</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=464">00:07:44.720</a></span> | <span class="t">so that strongly contradicts Sam Altman's assertion that current models like GPT-4 shouldn't have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=470">00:07:50.360</a></span> | <span class="t">any regulation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=471">00:07:51.400</a></span> | <span class="t">They say that even open source communities should welcome safeguards because a single instance of misuse and mass death</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=478">00:07:58.280</a></span> | <span class="t">would trigger a backlash including the imposition of extremely harsh regulations.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=483">00:08:03.480</a></span> | <span class="t">One specific recommendation was that if biotech and information security experts</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=488">00:08:08.440</a></span> | <span class="t">were able to identify the set of publications most relevant to causing mass death,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=493">00:08:13.400</a></span> | <span class="t">and companies like OpenAI and Google curated their training datasets to remove those publications,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=500">00:08:20.360</a></span> | <span class="t">then future models trained on the curated data would be far less capable of providing anyone intent on harm</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=506">00:08:26.760</a></span> | <span class="t">with the "recipes for the creation or enhancement of pathogens".</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=510">00:08:30.920</a></span> | <span class="t">This seems like an absolutely obvious move to me and I think Ilya Satskova would agree.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=515">00:08:35.560</a></span> | <span class="t">We are talking about as time goes by and the capability keeps increasing,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=519">00:08:39.960</a></span> | <span class="t">you know, and eventually it goes all the way to here, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=523">00:08:43.000</a></span> | <span class="t">Right now we are here. Today, that's where we are.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=525">00:08:45.960</a></span> | <span class="t">That's where we're going to get to.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=527">00:08:47.720</a></span> | <span class="t">When we get to this point, then yeah,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=530">00:08:50.360</a></span> | <span class="t">it's very powerful technology. It can be used for amazing applications.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=534">00:08:54.360</a></span> | <span class="t">You can say cure all disease. On the flip side, you can say create a disease.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=539">00:08:59.560</a></span> | <span class="t">Much more worse than anything that existed before. That'd be bad.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=543">00:09:03.240</a></span> | <span class="t">Moving on to the ChatGPT leak, it seems like we're going to get a new workspace</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=549">00:09:09.160</a></span> | <span class="t">where we can customize our interaction with ChatGPT, giving it files and a profile with</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=555">00:09:15.000</a></span> | <span class="t">any information that you'd like ChatGPT to remember about you and your preferences.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=559">00:09:19.640</a></span> | <span class="t">This was hinted at in the chat, but I'm not sure if this is the right way to do it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=560">00:09:20.360</a></span> | <span class="t">We were hinted at on the world tour when one of Sam Altman's guests,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=563">00:09:23.000</a></span> | <span class="t">Johannes Heidecker from OpenAI Research, talked about customizing models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=567">00:09:27.320</a></span> | <span class="t">We are trying to make our models both better at following certain guardrails that should</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=571">00:09:31.320</a></span> | <span class="t">never be overwritten, not with jailbreaks, not if you ask nicely, not if you threaten it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=575">00:09:35.560</a></span> | <span class="t">And we're also trying to make our models better at being customizable,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=579">00:09:39.960</a></span> | <span class="t">making them listen more to additional instructions of what kind of behavior the user or the developer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=585">00:09:45.320</a></span> | <span class="t">wants.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=585">00:09:45.720</a></span> | <span class="t">On a lighter note, the leaders of OpenAI were asked in Seoul, the capital of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=590">00:09:50.360</a></span> | <span class="t">South Korea, about the mixing of AI and religion.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=594">00:09:54.120</a></span> | <span class="t">Do you expect AI to replace the role of religious organizations like church?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=598">00:09:58.520</a></span> | <span class="t">I think that it's a good question how all human societies will integrate AI.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=607">00:10:07.080</a></span> | <span class="t">And we've already seen people building AI pastors, for example, and so the constituents</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=611">00:10:11.880</a></span> | <span class="t">can ask questions to this pastor that can cite Bible verses and it can give advice.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=615">00:10:15.880</a></span> | <span class="t">But now back to Poland, where Sam Altman called open source "unstable"</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=620">00:10:20.360</a></span> | <span class="t">"Realizing that open source is unstoppable and shouldn't be stopped,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=624">00:10:24.280</a></span> | <span class="t">and so this stuff is going to be out there and as a society we have to adapt."</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=627">00:10:27.400</a></span> | <span class="t">But speaking of stopping AI, Sam Altman was asked about his own loved ones,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=631">00:10:31.880</a></span> | <span class="t">and in response he gave a utopic vision of the future and called the current world "barbaric".</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=637">00:10:37.400</a></span> | <span class="t">If you truly believe that AI imposes a danger to humankind, why keep developing it?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=643">00:10:43.720</a></span> | <span class="t">Aren't you afraid for your own dear ones and family?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=647">00:10:47.880</a></span> | <span class="t">I think it's a super fair</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=650">00:10:50.360</a></span> | <span class="t">and good question.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=651">00:10:51.720</a></span> | <span class="t">And the most troublesome part of our jobs is that we have to balance this incredible</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=659">00:10:59.400</a></span> | <span class="t">promise and this technology that I think humans really need, and we can talk about</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=665">00:11:05.240</a></span> | <span class="t">why in a second, with confronting these very serious risks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=669">00:11:09.240</a></span> | <span class="t">Why to build it?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=670">00:11:10.040</a></span> | <span class="t">Number one, I do think that when we look back at the standard of living and what we tolerate</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=675">00:11:15.480</a></span> | <span class="t">for people today, it will look even worse than</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=680">00:11:20.360</a></span> | <span class="t">when we look back at how people lived 500 or 1000 years ago.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=684">00:11:24.120</a></span> | <span class="t">And we'll say like, man, can you imagine that people lived in poverty?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=687">00:11:27.880</a></span> | <span class="t">Can you imagine people suffered from disease?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=690">00:11:30.440</a></span> | <span class="t">Can you imagine that everyone didn't have a phenomenal education and were able to live</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=693">00:11:33.800</a></span> | <span class="t">their lives however they wanted?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=695">00:11:35.080</a></span> | <span class="t">It's going to look barbaric.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=696">00:11:36.360</a></span> | <span class="t">I think everyone in the future is going to have better lives than the best people of today.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=700">00:11:40.120</a></span> | <span class="t">I think there's like a moral duty to figure out how to do that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=703">00:11:43.160</a></span> | <span class="t">I also think this is like unstoppable, like this is the progress of technology.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=707">00:11:47.240</a></span> | <span class="t">It won't work to some degree.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=710">00:11:50.360</a></span> | <span class="t">It's going to stop it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=710">00:11:50.920</a></span> | <span class="t">And so we have to figure out how to manage the risk.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=713">00:11:53.320</a></span> | <span class="t">He doesn't seem to be 100% sure on this front though.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=716">00:11:56.520</a></span> | <span class="t">And here is an interview he gave with The Guardian when he was in London for his world</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=720">00:12:00.920</a></span> | <span class="t">tour.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=721">00:12:01.320</a></span> | <span class="t">Speaking of super intelligence, he said, "It's not that it's not stoppable.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=725">00:12:05.400</a></span> | <span class="t">If governments around the world decided to act in concert to limit AI development, as</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=729">00:12:09.800</a></span> | <span class="t">they have in other fields such as human cloning or bioweapon research, they may be able to."</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=734">00:12:14.520</a></span> | <span class="t">But then he repeated, "But that would be to give up all that is possible.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=737">00:12:17.800</a></span> | <span class="t">I think that this will be the most tremendous leap forward,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=740">00:12:20.360</a></span> | <span class="t">in terms of the quality of life for people that we've ever had."</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=742">00:12:22.600</a></span> | <span class="t">I did try to get tickets for the London leg of his world tour,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=745">00:12:25.800</a></span> | <span class="t">but they were sold out within half an hour.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=747">00:12:27.480</a></span> | <span class="t">Oh well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=748">00:12:28.040</a></span> | <span class="t">Sam Oldman does think that behaviour will change, however,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=750">00:12:30.920</a></span> | <span class="t">when these AGI labs stare existential risk in the face.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=754">00:12:34.760</a></span> | <span class="t">Sam Oldman: "One of the things we talked about is what's a structure that would let us</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=758">00:12:38.920</a></span> | <span class="t">warmly embrace regulation that would hurt us the most.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=762">00:12:42.760</a></span> | <span class="t">And now that the time has come for that, we're out here advocating around the world for regulation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=767">00:12:47.480</a></span> | <span class="t">that will impact us the most. So, of course, we'll comply with it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=770">00:12:50.360</a></span> | <span class="t">But I think it's more easy to get good behaviour out of people when they are staring existential</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=776">00:12:56.520</a></span> | <span class="t">risk in the face. And so I think all of the people at the leading edge here, these different</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=781">00:13:01.480</a></span> | <span class="t">companies, now feel this, and you will see a different collective response than you saw from</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=786">00:13:06.280</a></span> | <span class="t">the social media companies."</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=787">00:13:07.480</a></span> | <span class="t">And in terms of opportunities, both Sam Oldman and Ilya Sutskova talked about solving climate change.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=793">00:13:13.240</a></span> | <span class="t">Sam Oldman: "I don't want to say this because climate change is so serious and so hard of a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=796">00:13:16.360</a></span> | <span class="t">problem, but I think once we have a really powerful super intelligence,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=800">00:13:20.360</a></span> | <span class="t">addressing climate change will not be particularly difficult for a system like that."</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=804">00:13:24.040</a></span> | <span class="t">Ilya Sutskova: "We can even explain how. Here's how you solve climate change. You need a very large</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=808">00:13:28.360</a></span> | <span class="t">amount of efficient carbon capture. You need the energy for the carbon capture, you need the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=813">00:13:33.320</a></span> | <span class="t">technology to build it, and you need to build a lot of it. If you can accelerate the scientific</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=818">00:13:38.120</a></span> | <span class="t">progress, which is something that a powerful AI could do, we could get to a very advanced carbon</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=823">00:13:43.400</a></span> | <span class="t">capture much faster. We could get to a very cheap power much faster. We could get to cheaper</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=828">00:13:48.680</a></span> | <span class="t">manufacturing much faster. Ilya Sutskova: "I think that's a very important point.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=830">00:13:50.360</a></span> | <span class="t">Combine those three: cheap power, cheap manufacturing, advanced carbon capture.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=834">00:13:54.840</a></span> | <span class="t">Now you build lots of them. And now you sucked out all the excess CO2 from the atmosphere."</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=839">00:13:59.880</a></span> | <span class="t">Sam Oldman: "You know, if you think about a system where you can say,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=842">00:14:02.120</a></span> | <span class="t">'Tell me how to make a lot of clean energy cheaply. Tell me how to efficiently capture carbon.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=847">00:14:07.960</a></span> | <span class="t">And then tell me how to build a factory to do this at planetary scale.' If you can do that,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=851">00:14:11.880</a></span> | <span class="t">you can do a lot of other things too." Ilya Sutskova: "Yeah. With one addition</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=855">00:14:15.240</a></span> | <span class="t">that not only you ask it to tell it, you ask it to do it." Sam Oldman: "That would indeed be</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=860">00:14:20.360</a></span> | <span class="t">amazing. But think of the power we would be giving to an AI if it was able to just do it,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=865">00:14:25.960</a></span> | <span class="t">just create those carbon capture factories." Ilya Sutskova: "If we did make that decision,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=870">00:14:30.120</a></span> | <span class="t">one thing that would help would be reducing hallucinations." Sam Oldman: "I think we will</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=874">00:14:34.280</a></span> | <span class="t">get the hallucination problem to a much, much better place. It will take us,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=878">00:14:38.040</a></span> | <span class="t">my colleagues weigh in, I think it'll take us a year and a half, two years, something like that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=883">00:14:43.400</a></span> | <span class="t">But at that point, we won't still talk about these." Ilya Sutskova:</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=885">00:14:45.560</a></span> | <span class="t">Sam Oldman talked about that in New Delhi. That timeframe of 18 months to two years is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=890">00:14:50.360</a></span> | <span class="t">ambitious and surprising. But now onto jobs, which Sam Oldman was asked about on every leg of the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=896">00:14:56.440</a></span> | <span class="t">tour. On this front though, I do think it was Ilya Sutskova who gave the more honest answer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=901">00:15:01.320</a></span> | <span class="t">Sam Oldman: "Economic dislocation indeed, like we already know that there are jobs that are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=906">00:15:06.600</a></span> | <span class="t">being impacted or they're being affected. In other words, some chunks of the jobs can be done. You</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=911">00:15:11.880</a></span> | <span class="t">know, if you're a programmer, you don't write functions anymore, copilot writes them for you.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=915">00:15:15.800</a></span> | <span class="t">If you're an artist though, it's a bit different because a big chunk of the artists' economic</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=920">00:15:20.360</a></span> | <span class="t">part of them activity has been taken by some of the image generators. And while new jobs will be</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=925">00:15:25.240</a></span> | <span class="t">created, it's going to be a long period of economic uncertainty. There is an argument to be</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=929">00:15:29.720</a></span> | <span class="t">made that even when they have full human level AI, full AGI, people will still have economic activity</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=935">00:15:35.800</a></span> | <span class="t">to do. I don't know whether that's the case, but in either event, we will need to have something</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=942">00:15:42.600</a></span> | <span class="t">that will soften the blow to allow for a smoother transition either to the totally new professions</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=950">00:15:50.360</a></span> | <span class="t">or even if not, then we want government, the social systems will need to keep keen."</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=955">00:15:55.320</a></span> | <span class="t">I do think the changes in the job market will be dramatic and we'll be following the story closely.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=959">00:15:59.960</a></span> | <span class="t">One thing I definitely agree with Sam Oldman on though, is the deep,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=963">00:16:03.560</a></span> | <span class="t">almost philosophical change that this solving of intelligence has brought to humanity.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=968">00:16:08.680</a></span> | <span class="t">Sam Oldman: "I grew up implicitly thinking that intelligence was this like really special</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=976">00:16:16.120</a></span> | <span class="t">human thing and kind of somewhat magical. And I now think that it's sort of a fundamental</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=980">00:16:20.360</a></span> | <span class="t">property of matter. And that's definitely a change to my worldview. The history of scientific</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=988">00:16:28.440</a></span> | <span class="t">discovery is that humans are less and less at the center. We used to think that sun rotated around</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=993">00:16:33.880</a></span> | <span class="t">us and then maybe at least we were, if not that, we were going to be the center of the galaxy and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=998">00:16:38.280</a></span> | <span class="t">there wasn't this big universe. And then multiverse really is kind of weird and depressing. And</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=1002">00:16:42.520</a></span> | <span class="t">if intelligence is a special, again, we're just further and further</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=1005">00:16:45.560</a></span> | <span class="t">away from main character energy. But that's all right. That's sort of like a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=1010">00:16:50.360</a></span> | <span class="t">nice thing to realize actually." It's a bit like a Copernican and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=1013">00:16:53.880</a></span> | <span class="t">Darwinian revolution all rolled in one. But I'll give the final word to Greg Brockman in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=1019">00:16:59.320</a></span> | <span class="t">Seoul who talked about the unpredictability of scaling up models 10 times.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=1023">00:17:03.960</a></span> | <span class="t">Greg Brockman: "That is the biggest theme in the history of AI is that it's full of surprises.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=1027">00:17:07.480</a></span> | <span class="t">Every time you think you know something, you scale it up 10x, turns out you knew nothing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=1031">00:17:11.080</a></span> | <span class="t">And so I think that we as a humanity, as a species are really exploring this together."</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=1035">00:17:15.240</a></span> | <span class="t">Being all in it together and knowing nothing sounds about right. But thank you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=1040">00:17:20.360</a></span> | <span class="t">for watching to the end. I know that Sam Altman has a couple more stops. I think it's Jakarta</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=1045">00:17:25.720</a></span> | <span class="t">and Melbourne on the world tour and I'll be watching those of course. But for now,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3sWH2e5xpdo&t=1049">00:17:29.880</a></span> | <span class="t">thank you and have a wonderful day.</span></div></div></body></html>