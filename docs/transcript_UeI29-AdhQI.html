<html><head><title>AI progress is about to rapidly accelerate in 2025 – Sholto Douglas & Trenton Bricken</title>
<style>
    body {
        font-family: Arial, sans-serif;
        margin: 0;
        padding: 0;
        background-color: #f4f4f4;
        color: #333;
    }
    .container {
        width: 95%;  /* Increased width to use more space */
        margin: auto;
        overflow: auto;  /* Added to handle overflow by adding a scrollbar if necessary */
    }
    h2, h3 {
        color: #333;
        text-align: center;
    }
    a {
        color: #0000FF;  /* Traditional blue color for links */
        text-decoration: none;
    }
    a:hover {
        text-decoration: underline;
    }
    img {
        display: block;
        margin: auto;
        max-width: 100%;
    }
    .c {
        margin: 10px 0;
    }
    .s, .t {
        display: inline-block;
        margin-right: 5px;
    }
    .max-width {
        max-width: 800px;
        margin: auto;
        padding-left: 20px;
    }
    table {
        width: 100%;
        border-collapse: collapse;
    }
    th, td {
        border: 1px solid #ddd;
        padding: 8px;
        text-align: left;  /* Ensure text alignment is consistent */
    }
    tr:nth-child(even) {
        background-color: #f2f2f2;
    }
    tr:nth-child(odd) {
        background-color: #e6e6e6;
    }
</style>

    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-69VLBMTTP0"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-69VLBMTTP0');
    </script>
    </head><body><div class='container'><a href="index.html">Back to Index</a><h2>AI progress is about to rapidly accelerate in 2025 – Sholto Douglas & Trenton Bricken</h2><a href="https://www.youtube.com/watch?v=UeI29-AdhQI" target="_blank"><img src="https://i.ytimg.com/vi_webp/UeI29-AdhQI/maxresdefault.webp" style="width:50%;"></a><div><br></div><h3>Chapters</h3><a href="https://www.youtube.com/watch?v=UeI29-AdhQI&t=0 target="_blank"">0:0</a> Introduction<br><a href="https://www.youtube.com/watch?v=UeI29-AdhQI&t=44 target="_blank"">0:44</a> Compute<br><a href="https://www.youtube.com/watch?v=UeI29-AdhQI&t=84 target="_blank"">1:24</a> Research vs Compute<br><a href="https://www.youtube.com/watch?v=UeI29-AdhQI&t=154 target="_blank"">2:34</a> AI Research<br><a href="https://www.youtube.com/watch?v=UeI29-AdhQI&t=308 target="_blank"">5:8</a> What is imperfect information<br><a href="https://www.youtube.com/watch?v=UeI29-AdhQI&t=355 target="_blank"">5:55</a> The problem with AI<br><a href="https://www.youtube.com/watch?v=UeI29-AdhQI&t=402 target="_blank"">6:42</a> The importance of ruthless prioritization<br><h3>Transcript</h3><div class='max-width'><p>- In the model of the intelligence explosion, what happens is you replace the AI researchers and then there's like a bunch of automated AI researchers who can speed up progress, make more AI researchers, make further progress. We should just ask the AI researchers about whether they think this is plausible.</p><p>So let me just ask you, like if I have a thousand Asian Shotos or Asian Trentons, are they just, do you think that you get an intelligence explosion? - I think we are less at the moment bound by the sheer engineering work of making these things than we are by compute to run and get signal and taste in terms of what the actual like right thing to do it.</p><p>And that like making those difficult inferences on imperfect information. - So compute and taste, that's interesting to think about because at least the compute part is not bottlenecked on more intelligence. It just bottlenecked on Sam 7 trillion or whatever, right? So if I gave you 10X the H100s to run your experiments, how much more effective a researcher are you?</p><p>- TPUs please. (all laughing) - How much more effective a researcher are you? - I think the Gemini program would probably be like maybe five times faster with 10 times more compute or something like that. - So that's pretty good elasticity of like 0.5. Wait, that's insane. - Yeah, I think like more compute would just like directly convert into progress.</p><p>- So you have some fixed size of compute and some of it goes to inference, some of it goes to running the experiments for the full model. - Yeah, that's right. - Shouldn't then the fraction goes to experiments be higher given that you would just be like, if like the bottleneck is research and research is bottlenecked by compute.</p><p>- One of the strategic decisions that every pre-training team has to make is like exactly what amount of compute do you allocate to different training runs? Just like to your research program versus like scaling the last best thing that you landed on. One of the reasons why you need to still keep training big models is that you get information there that you don't get otherwise.</p><p>So scale has all these emergent properties which you want to understand better. And if you like are always doing research, you're not sure what's gonna like fall off the curve, right? If you like keep doing research in this regime and like keep on getting more and more compute efficient, you may have actually like gone off the path to actually eventually scale.</p><p>So you need to constantly be investing in doing big runs too, at the frontier of what you sort of expect to work. - Okay, so then tell me what it looks like to be in the world where AI has significantly sped up AI research. 'Cause from this, it doesn't really sound like the AIs are going off and writing the code from scratch and that's leading to faster output.</p><p>It sounds like they're really augmenting the top researchers in some way. Like, yeah, tell me concretely, are they doing the experiments? Are they coming up with the ideas? Are they just like evaluating the outputs of the experiments? What's happening? - So I think there's like two walls you need to consider here.</p><p>One is where AI has meaningfully sped up our ability to make algorithmic progress. And one is where the output of the AI itself is the thing that's like the crucial ingredient towards like model capability progress. And like specifically what I mean there is - Synthetic data. - Synthetic data, right?</p><p>And in the first world where it's meaningfully speeding up algorithmic progress, I think a necessary component of that is more compute. And you probably like reach this elasticity point where like AIs maybe at some point are easier to speed up and get on to context than yourself, let's just say than other people.</p><p>And so AIs meaningfully speed up your work because they're like a fantastic copilot, basically that helps you code multiple times faster. And that seems like actually quite reasonable, super long context, super smart model, it's onboarded immediately and you can like send them off and to like complete sub tasks and sub goals for you.</p><p>- Walk me through like a day in the life of show, like you're working on an experiment or project that's going to make the model quote unquote better. - Right. - Like what is happening from observation to experiment to theory to like writing the code, what is happening? - I think the most important like part to illustrate is this cycle of coming up with an idea, proving it out at different points in scale and like interpreting and understanding what goes wrong.</p><p>And I think most people would be surprised to learn just how much goes into interpret, like interpreting and understanding what goes wrong. 'Cause the ideas, people have long lists of ideas that they wanna try, not every idea that you think should work will work and trying to understand why that is quite difficult and like working out what exactly you need to do to interrogate it.</p><p>So, so much of it is like introspection about what's going on. It's not pumping out thousands and thousands and thousands of line of code. It's not like the difficulty in coming up with ideas even. I think many people have a long list of ideas that they wanna try, but paring that down and shock calling under very imperfect information, what the right ideas to explore further is really hard.</p><p>- Tell me more about, what do you mean by imperfect information? Are these early experiments? Are these, like what is the information that you're- - Like scaling more increments. And you can see like in the GPT-4 paper, they have like a bunch of like dots, right? Where they say we can estimate the performance of our final model, like using all of these dots.</p><p>And there's a nice curve that like flows through them. Concretely, why is that imperfect information? Is you never actually know if the trend will hold. For certain architectures, the trend has held really well. And for certain changes, it's held really well. But that isn't always the case. And things which can help at smaller scales can actually hurt at larger scales.</p><p>So making guesses based on what the trend lines look like, and based on like your intuitive feeling of, okay, this is actually something that's gonna matter. - That's interesting to consider that for every chart you see in a release paper or technical report that shows that smooth curve, there's a graveyard of like first neurons and then it's like flat.</p><p>- Yeah, yeah, there's all these like other lines that go in like different directions, and you just like tail off and like, that's- - Yeah, it's crazy. Both like as a grad student and then also here, like the number of experiments that you have to run. - And then intuiting what went wrong is actually really hard.</p><p>Like working out what, like this is in many respects from the team that Trenton is on is trying to better understand is like what is going on inside these models. We have inferences and understanding and like head canon for why certain things work, but it's not an exact science.</p><p>And so you have to constantly be making guesses about why something might've happened, what experiment might reveal whether that is or isn't true. And that's probably the most complex part. - Yeah, I agree with a lot of that. But even on the interpretability team, I mean, especially with Chris Ola leading it, there are just so many ideas that we wanna test.</p><p>And it's really just having the engineering skill, but I'll put engineering in quotes because a lot of it is research, to like very quickly iterate on an experiment, look at the results, interpret it, try the next thing, communicate them. And then just ruthlessly prioritizing what the highest priority things to do are.</p><p>- And this is really important. Like the ruthless prioritization is something which I think separates a lot of like quality research from research that doesn't necessarily succeed as much. We're in this funny field where so many of our initial theoretical understanding is like broken down basically. And so you need to have this simplicity bias and like ruthless prioritization over what's actually going wrong.</p><p>And I think that's one of the things that separates the most effective people is they don't necessarily get like too attached to using a given solution that they're necessarily familiar with, but rather they attack the problem directly. You see this a lot in like, maybe people come in with a specific academic background, they try and solve problems with that toolbox.</p><p>And the best people are people who expand the toolbox dramatically. They're running around and they're taking ideas from reinforcement learning, but also from optimization theory. And also they have a great understanding of systems. And so they know what the sort of constraints that bound the problem are. And they're good engineers, they can iterate and try ideas fast.</p><p>Like by far the best researchers I've seen, they all have the ability to try experiments really, really, really, really fast. And that is that cycle time at smaller scales, cycle time separates people. - I mean, machine learning research is just so empirical. - Yeah. - And this is honestly one reason why I think our solutions might end up looking more brain-like than otherwise.</p><p>It's like, even though we wouldn't want to admit it, the whole community is kind of doing like, greedy evolutionary optimization over the landscape of like possible architectures and everything else. It's like no better than evolution.</p></div></div></body></html>