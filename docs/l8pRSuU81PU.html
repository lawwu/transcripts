<html><head><title>Let's reproduce GPT-2 (124M)</title>
<style>
    body {
        font-family: Arial, sans-serif;
        margin: 0;
        padding: 0;
        background-color: #f4f4f4;
        color: #333;
    }
    .container {
        width: 95%;  /* Increased width to use more space */
        margin: auto;
        overflow: auto;  /* Added to handle overflow by adding a scrollbar if necessary */
    }
    h2, h3 {
        color: #333;
        text-align: center;
    }
    a {
        color: #0000FF;  /* Traditional blue color for links */
        text-decoration: none;
    }
    a:hover {
        text-decoration: underline;
    }
    img {
        display: block;
        margin: auto;
        max-width: 100%;
    }
    .c {
        margin: 10px 0;
    }
    .s, .t {
        display: inline-block;
        margin-right: 5px;
    }
    .max-width {
        max-width: 800px;
        margin: auto;
        padding-left: 20px;
    }
    table {
        width: 100%;
        border-collapse: collapse;
    }
    th, td {
        border: 1px solid #ddd;
        padding: 8px;
        text-align: left;  /* Ensure text alignment is consistent */
    }
    tr:nth-child(even) {
        background-color: #f2f2f2;
    }
    tr:nth-child(odd) {
        background-color: #e6e6e6;
    }
</style>

    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-69VLBMTTP0"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-69VLBMTTP0');
    </script>
    </head><body><div class='container'><a href="index.html">back to index</a><h2>Let's reproduce GPT-2 (124M)</h2><a href="https://www.youtube.com/watch?v=l8pRSuU81PU"><img src="https://i.ytimg.com/vi/l8pRSuU81PU/maxresdefault.jpg" style="width:50%;"></a><div><br></div><h3>Chapters</h3><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=0">0:0</a> intro: Let’s reproduce GPT-2 (124M)<br><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=219">3:39</a> exploring the GPT-2 (124M) OpenAI checkpoint<br><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=827">13:47</a> SECTION 1: implementing the GPT-2 nn.Module<br><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=1688">28:8</a> loading the huggingface/GPT-2 parameters<br><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=1860">31:0</a> implementing the forward pass to get logits<br><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=2011">33:31</a> sampling init, prefix tokens, tokenization<br><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=2222">37:2</a> sampling loop<br><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=2507">41:47</a> sample, auto-detect the device<br><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=2750">45:50</a> let’s train: data batches (B,T) → logits (B,T,C)<br><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=3173">52:53</a> cross entropy loss<br><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=3402">56:42</a> optimization loop: overfit a single batch<br><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=3720">62:0</a> data loader lite<br><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=3974">66:14</a> parameter sharing wte and lm_head<br><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=4427">73:47</a> model initialization: std 0.02, residual init<br><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=4938">82:18</a> SECTION 2: Let’s make it fast. GPUs, mixed precision, 1000ms<br><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=5294">88:14</a> Tensor Cores, timing the code, TF32 precision, 333ms<br><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=5978">99:38</a> float16, gradient scalers, bfloat16, 300ms<br><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=6495">108:15</a> torch.compile, Python overhead, kernel fusion, 130ms<br><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=7218">120:18</a> flash attention, 96ms<br><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=7614">126:54</a> nice/ugly numbers. vocab size 50257 → 50304, 93ms<br><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=8095">134:55</a> SECTION 3: hyperpamaters, AdamW, gradient clipping<br><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=8466">141:6</a> learning rate scheduler: warmup + cosine decay<br><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=8781">146:21</a> batch size schedule, weight decay, FusedAdamW, 90ms<br><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=9249">154:9</a> gradient accumulation<br><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=10012">166:52</a> distributed data parallel (DDP)<br><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11421">190:21</a> datasets used in GPT-2, GPT-3, FineWeb (EDU)<br><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12190">203:10</a> validation data split, validation loss, sampling revive<br><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12503">208:23</a> evaluation: HellaSwag, starting the run<br><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13385">223:5</a> SECTION 4: results in the morning! GPT-2, GPT-3 repro<br><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=14181">236:21</a> shoutout to llm.c, equivalent but faster code in raw C/CUDA<br><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=14379">239:39</a> summary, phew, build-nanogpt github repo<br><br><div style="text-align: left;"><a href="./l8pRSuU81PU.html">Whisper Transcript</a> | <a href="./transcript_l8pRSuU81PU.html">Transcript Only Page</a></div><br><div style="max-width: 800px;"><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=0" target="_blank">00:00:00.000</a></span> | <span class="t">Hi, everyone. So, today we are going to be continuing our Zero to Hero series,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=4" target="_blank">00:00:04.320</a></span> | <span class="t">and in particular, today we are going to reproduce the GPT-2 model,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=7" target="_blank">00:00:07.840</a></span> | <span class="t">the 124 million version of it. So, when OpenAI released GPT-2, this was 2019,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=15" target="_blank">00:00:15.680</a></span> | <span class="t">and they released it with this blog post. On top of that, they released this paper,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=20" target="_blank">00:00:20.480</a></span> | <span class="t">and on top of that, they released this code on GitHub. So, OpenAI/GPT-2.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=24" target="_blank">00:00:24.560</a></span> | <span class="t">Now, when we talk about reproducing GPT-2, we have to be careful, because in particular,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=29" target="_blank">00:00:29.600</a></span> | <span class="t">in this video, we're going to be reproducing the 124 million parameter model. So, the thing to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=34" target="_blank">00:00:34.800</a></span> | <span class="t">realize is that there's always a miniseries when these releases are made. So, there are the GPT-2</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=41" target="_blank">00:00:41.040</a></span> | <span class="t">miniseries made up of models at different sizes, and usually the biggest model is called the GPT-2.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=46" target="_blank">00:00:46.800</a></span> | <span class="t">But basically, the reason we do that is because you can put the model sizes on the x-axis of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=52" target="_blank">00:00:52.160</a></span> | <span class="t">plots like this, and on the y-axis, you put a lot of downstream metrics that you're interested in,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=56" target="_blank">00:00:56.720</a></span> | <span class="t">like translation, summarization, question answering, and so on, and you can chart out</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=60" target="_blank">00:01:00.560</a></span> | <span class="t">these scaling laws. So, basically, as the model size increases, you're getting better and better</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=65" target="_blank">00:01:05.680</a></span> | <span class="t">at downstream metrics. And so, in particular for GPT-2, if we scroll down in the paper,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=72" target="_blank">00:01:12.000</a></span> | <span class="t">there are four models in the GPT-2 miniseries, starting at 124 million, all the way up to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=78" target="_blank">00:01:18.320</a></span> | <span class="t">1,558 million. Now, the reason my numbers, the way I say them, disagree with this table is that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=84" target="_blank">00:01:24.560</a></span> | <span class="t">this table is wrong. If you actually go to the GPT-2 GitHub repo, they sort of say that there</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=92" target="_blank">00:01:32.160</a></span> | <span class="t">was an error in how they added up the parameters. But basically, this is the 124 million parameter</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=96" target="_blank">00:01:36.400</a></span> | <span class="t">model, et cetera. So, the 124 million parameter had 12 layers in the transformer, and it had 768</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=103" target="_blank">00:01:43.680</a></span> | <span class="t">channels in the transformer, 768 dimensions. And I'm going to be assuming some familiarity with</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=109" target="_blank">00:01:49.360</a></span> | <span class="t">what these terms mean, because I covered all of this in my previous video, let's build GPT-2,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=113" target="_blank">00:01:53.520</a></span> | <span class="t">let's build GPT from scratch. So, I covered that in the previous video in this playlist.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=118" target="_blank">00:01:58.400</a></span> | <span class="t">Now, if we do everything correctly and everything works out well, by the end of this video,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=123" target="_blank">00:02:03.360</a></span> | <span class="t">we're going to see something like this, where we're looking at the validation loss, which basically</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=128" target="_blank">00:02:08.160</a></span> | <span class="t">measures how good we are at predicting the next token in a sequence on some validation data that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=134" target="_blank">00:02:14.720</a></span> | <span class="t">the model has not seen during training. And we see that we go from doing that task not very well,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=140" target="_blank">00:02:20.320</a></span> | <span class="t">because we're initializing from scratch, all the way to doing that task quite well</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=143" target="_blank">00:02:23.760</a></span> | <span class="t">by the end of the training. And hopefully, we're going to beat the GPT-2 124M model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=149" target="_blank">00:02:29.920</a></span> | <span class="t">Now, previously, when they were working on this, this is already five years ago.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=154" target="_blank">00:02:34.560</a></span> | <span class="t">So, this was probably a fairly complicated optimization at the time, and the GPUs and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=158" target="_blank">00:02:38.560</a></span> | <span class="t">the compute was a lot smaller. Today, you can reproduce this model in roughly an hour,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=164" target="_blank">00:02:44.160</a></span> | <span class="t">or probably less even, and it will cost you about 10 bucks if you want to do this on the cloud</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=168" target="_blank">00:02:48.320</a></span> | <span class="t">compute, a sort of computer that you can all rent. And if you pay $10 for that computer,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=174" target="_blank">00:02:54.400</a></span> | <span class="t">you wait about an hour or less, you can actually achieve a model that is as good as</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=178" target="_blank">00:02:58.960</a></span> | <span class="t">this model that OpenAI released. And one more thing to mention is, unlike many other models,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=185" target="_blank">00:03:05.200</a></span> | <span class="t">OpenAI did release the weights for GPT-2. So, those weights are all available in this repository.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=191" target="_blank">00:03:11.040</a></span> | <span class="t">But the GPT-2 paper is not always as good with all of the details of the training.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=196" target="_blank">00:03:16.160</a></span> | <span class="t">So, in addition to the GPT-2 paper, we're going to be referencing the GPT-3 paper,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=200" target="_blank">00:03:20.320</a></span> | <span class="t">which is a lot more concrete in a lot of the parameters and optimization settings and so on.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=205" target="_blank">00:03:25.600</a></span> | <span class="t">And it's not a huge departure in the architecture from the GPT-2 version of the model. So,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=211" target="_blank">00:03:31.920</a></span> | <span class="t">we're going to be referencing both GPT-2 and GPT-3 as we try to reproduce GPT-2 124M. So,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=218" target="_blank">00:03:38.080</a></span> | <span class="t">let's go. So, the first thing I would like to do is actually start at the end, or at the target.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=222" target="_blank">00:03:42.960</a></span> | <span class="t">So, in other words, let's load the GPT-2 124M model as it was released by OpenAI,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=228" target="_blank">00:03:48.480</a></span> | <span class="t">and maybe take it for a spin. Let's sample some tokens from it. Now, the issue with that is,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=232" target="_blank">00:03:52.640</a></span> | <span class="t">when you go to the code base of GPT-2 and you go into the source and you click in on the model.py,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=238" target="_blank">00:03:58.160</a></span> | <span class="t">you'll realize that actually this is using TensorFlow. So, the original GPT-2 code here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=242" target="_blank">00:04:02.880</a></span> | <span class="t">was written in TensorFlow, which is, you know, not, let's just say, not used as much anymore.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=250" target="_blank">00:04:10.560</a></span> | <span class="t">So, we'd like to use PyTorch, because it's a lot friendlier, easier, and I just personally like it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=255" target="_blank">00:04:15.680</a></span> | <span class="t">a lot more. The problem with that is the initial code is in TensorFlow. We'd like to use PyTorch.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=260" target="_blank">00:04:20.160</a></span> | <span class="t">So, instead, to get the target, we're going to use the hugging face transformers code,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=266" target="_blank">00:04:26.320</a></span> | <span class="t">which I like a lot more. So, when you go into the transformers, source, transformers, models,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=270" target="_blank">00:04:30.400</a></span> | <span class="t">GPT-2, modeling, GPT-2.py, you will see that they have the GPT-2 implementation of that transformer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=276" target="_blank">00:04:36.640</a></span> | <span class="t">here in this file. And it's, like, medium readable, but not fully readable. But what it does is it did</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=286" target="_blank">00:04:46.800</a></span> | <span class="t">all the work of converting all those weights from TensorFlow to PyTorch friendly, and so it's much</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=292" target="_blank">00:04:52.480</a></span> | <span class="t">easier to load and work with. So, in particular, we can look at the GPT-2 model here, and we can</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=299" target="_blank">00:04:59.120</a></span> | <span class="t">load it using hugging face transformers. So, swinging over, this is what that looks like.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=303" target="_blank">00:05:03.440</a></span> | <span class="t">From transformers, import the GPT-2 LM head model, and then from pre-trained GPT-2.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=311" target="_blank">00:05:11.840</a></span> | <span class="t">Now, one awkward thing about this is that when you do GPT-2 as the model that we're loading,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=317" target="_blank">00:05:17.920</a></span> | <span class="t">this actually is the 124 million parameter model. If you want the actual GPT-2, the 1.5 billion,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=325" target="_blank">00:05:25.440</a></span> | <span class="t">then you actually want to do -XL. So, this is the 124M, our target. Now, what we're doing is,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=332" target="_blank">00:05:32.480</a></span> | <span class="t">when we actually get this, we're initializing the PyTorch NN module as defined here in this class.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=338" target="_blank">00:05:38.160</a></span> | <span class="t">From it, I want to get just the state dict, which is just the raw tensors. So, we just have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=344" target="_blank">00:05:44.800</a></span> | <span class="t">the tensors of that file. And by the way, here, this is a Jupyter notebook, but this is a Jupyter</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=351" target="_blank">00:05:51.120</a></span> | <span class="t">notebook running inside VS Code, so I like to work with it all in a single interface, so I like to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=357" target="_blank">00:05:57.200</a></span> | <span class="t">use VS Code, so this is the Jupyter notebook extension inside VS Code. So, when we get the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=365" target="_blank">00:06:05.360</a></span> | <span class="t">state dict, this is just a dict, so we can print the key and the value, which is the tensor,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=371" target="_blank">00:06:11.280</a></span> | <span class="t">and let's just look at the shapes. So, these are sort of the different parameters inside the GPT-2</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=378" target="_blank">00:06:18.080</a></span> | <span class="t">model and their shape. So, the W weight for token embedding is of size 50257 by 768. Where this is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=390" target="_blank">00:06:30.400</a></span> | <span class="t">coming from is that we have 50257 tokens in the GPT-2 vocabulary, and the tokens, by the way,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=399" target="_blank">00:06:39.120</a></span> | <span class="t">these are exactly the tokens that we've spoken about in the previous video on my tokenization</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=403" target="_blank">00:06:43.520</a></span> | <span class="t">series. So, the previous video, just before this, I go into a ton of detail on tokenization.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=408" target="_blank">00:06:48.400</a></span> | <span class="t">GPT-2 tokenizer happens to have this many tokens. For each token, we have a 768-dimensional</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=416" target="_blank">00:06:56.240</a></span> | <span class="t">embedding that is the distributed representation that stands in for that token. So, each token is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=422" target="_blank">00:07:02.880</a></span> | <span class="t">a little string piece, and then these 768 numbers are the vector that represents that token.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=429" target="_blank">00:07:09.760</a></span> | <span class="t">And so, this is just our lookup table for tokens, and then here, we have the lookup table for the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=434" target="_blank">00:07:14.560</a></span> | <span class="t">positions. So, because GPT-2 has a maximum sequence length of 1024, we have up to 1024 positions that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=443" target="_blank">00:07:23.360</a></span> | <span class="t">each token can be attending to in the past, and every one of those positions in GPT-2 has a fixed</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=449" target="_blank">00:07:29.920</a></span> | <span class="t">vector of 768 that is learned by optimization. And so, this is the position embedding and the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=457" target="_blank">00:07:37.680</a></span> | <span class="t">token embedding, and then everything here is just the other weights and biases and everything else</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=463" target="_blank">00:07:43.760</a></span> | <span class="t">of this transformer. So, when you just take, for example, the positional embeddings and flatten it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=469" target="_blank">00:07:49.760</a></span> | <span class="t">out and take just the 20 elements, you can see that these are just the parameters. These are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=473" target="_blank">00:07:53.760</a></span> | <span class="t">weights, floats, just we can take and we can plot them. So, these are the position embeddings,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=480" target="_blank">00:08:00.640</a></span> | <span class="t">and we get something like this, and you can see that this has structure, and it has structure</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=485" target="_blank">00:08:05.280</a></span> | <span class="t">because what we have here really is every row in this visualization is a different position,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=492" target="_blank">00:08:12.560</a></span> | <span class="t">a fixed absolute position in the range from 0 to 1024, and each row here is the representation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=500" target="_blank">00:08:20.640</a></span> | <span class="t">of that position. And so, it has structure because these positional embeddings end up learning these</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=506" target="_blank">00:08:26.800</a></span> | <span class="t">sinusoids and cosines that sort of like represent each of these positions, and each row here stands</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=514" target="_blank">00:08:34.960</a></span> | <span class="t">in for that position and is processed by the transformer to recover all the relative positions</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=520" target="_blank">00:08:40.160</a></span> | <span class="t">and sort of realize which token is where and attend to them depending on their position,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=525" target="_blank">00:08:45.760</a></span> | <span class="t">not just their content. So, when we actually just look into an individual column inside these,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=533" target="_blank">00:08:53.200</a></span> | <span class="t">and I just grabbed three random columns, you'll see that, for example, here we are focusing on</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=539" target="_blank">00:08:59.200</a></span> | <span class="t">every single channel, and we're looking at what that channel is doing as a function of position</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=549" target="_blank">00:09:09.040</a></span> | <span class="t">from 1, from 0 to 1023, really. And we can see that some of these channels basically like respond</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=557" target="_blank">00:09:17.200</a></span> | <span class="t">more or less to different parts of the position spectrum. So, this green channel really likes to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=563" target="_blank">00:09:23.200</a></span> | <span class="t">fire for everything after 200 up to 800, but not less, but a lot less, and has a sharp drop-off</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=571" target="_blank">00:09:31.440</a></span> | <span class="t">here near 0. So, who knows what these embeddings are doing and why they are the way they are.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=576" target="_blank">00:09:36.160</a></span> | <span class="t">You can tell, for example, that because they're a bit more jagged and they're kind of noisy,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=579" target="_blank">00:09:39.600</a></span> | <span class="t">you can tell that this model was not fully trained. And the more trained this model was,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=584" target="_blank">00:09:44.640</a></span> | <span class="t">the more you would expect to smooth this out. And so, this is telling you that this is a little bit</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=588" target="_blank">00:09:48.560</a></span> | <span class="t">of an under-trained model, but in principle, actually, these curves don't even have to be</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=594" target="_blank">00:09:54.160</a></span> | <span class="t">smooth. This should just be totally random noise. And in fact, in the beginning of the optimization,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=598" target="_blank">00:09:58.720</a></span> | <span class="t">it is complete random noise, because this position embedding table is initialized completely at</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=603" target="_blank">00:10:03.600</a></span> | <span class="t">random. So, in the beginning, you have jaggedness, and the fact that you end up with something</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=608" target="_blank">00:10:08.160</a></span> | <span class="t">smooth is already kind of impressive, that that just falls out of the optimization,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=613" target="_blank">00:10:13.280</a></span> | <span class="t">because in principle, you shouldn't even be able to get any single graph out of this that makes</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=617" target="_blank">00:10:17.280</a></span> | <span class="t">sense. But we actually get something that looks a little bit noisy, but for the most part looks</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=621" target="_blank">00:10:21.280</a></span> | <span class="t">sinusoidal-like. In the original transformer paper, the attention is all you need paper,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=629" target="_blank">00:10:29.120</a></span> | <span class="t">the positional embeddings are actually initialized and fixed, if I remember correctly, to sinusoids</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=634" target="_blank">00:10:34.240</a></span> | <span class="t">and cosines of different frequencies. And that's the positional encoding, and it's fixed. But in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=639" target="_blank">00:10:39.520</a></span> | <span class="t">GPT-2, these are just parameters, and they're trained from scratch, just like any other</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=643" target="_blank">00:10:43.440</a></span> | <span class="t">parameter. And that seems to work about as well. And so what they do is they kind of recover these</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=648" target="_blank">00:10:48.720</a></span> | <span class="t">sinusoidal-like features during the optimization. We can also look at any of the other matrices</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=655" target="_blank">00:10:55.440</a></span> | <span class="t">here. So, here I took the first layer of the transformer, and looking at one of its weights,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=663" target="_blank">00:11:03.280</a></span> | <span class="t">and just the first block of 300 by 300, and you see some structure, but again, who knows what</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=670" target="_blank">00:11:10.560</a></span> | <span class="t">any of this is. If you're into mechanistic interpretability, you might get a real kick out</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=675" target="_blank">00:11:15.040</a></span> | <span class="t">of trying to figure out what is going on, what is this structure, and what does this all mean,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=679" target="_blank">00:11:19.440</a></span> | <span class="t">but we're not going to be doing that in this video. But we definitely see that there's some</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=682" target="_blank">00:11:22.880</a></span> | <span class="t">interesting structure, and that's kind of cool. What we're most interested in is we've loaded</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=687" target="_blank">00:11:27.360</a></span> | <span class="t">the weights of this model that was released by OpenAI, and now using the Hugging Face Transformers,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=692" target="_blank">00:11:32.800</a></span> | <span class="t">we can not just get all the raw weights, but we can also get what they call pipeline,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=699" target="_blank">00:11:39.520</a></span> | <span class="t">and sample from it. So, this is the prefix, "Hello, I'm a language model," comma,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=704" target="_blank">00:11:44.480</a></span> | <span class="t">and then we're sampling 30 tokens, and we're getting five sequences, and I ran this,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=711" target="_blank">00:11:51.760</a></span> | <span class="t">and this is what it produced. "Hello, I'm a language model," but what I'm really doing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=717" target="_blank">00:11:57.360</a></span> | <span class="t">is making a human-readable document. There are other languages, but those are dot, dot, dot,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=722" target="_blank">00:12:02.400</a></span> | <span class="t">so you can read through these if you like, but basically, these are five different completions</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=725" target="_blank">00:12:05.840</a></span> | <span class="t">of the same prefix from this GPT2124M. Now, if I go here, I took this example from here,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=734" target="_blank">00:12:14.560</a></span> | <span class="t">and sadly, even though we are fixing the seed, we are getting different generations</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=740" target="_blank">00:12:20.000</a></span> | <span class="t">from the snippet than what they got, so presumably the code changed, but what we see, though,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=748" target="_blank">00:12:28.240</a></span> | <span class="t">at this stage that's important is that we are getting coherent text, so we've loaded the model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=753" target="_blank">00:12:33.200</a></span> | <span class="t">successfully, we can look at all its parameters, and the keys tell us where in the model these</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=758" target="_blank">00:12:38.560</a></span> | <span class="t">come from, and we want to actually write our own GPT2 class so that we have a full understanding</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=763" target="_blank">00:12:43.760</a></span> | <span class="t">of what's happening there. We don't want to be working with something like the modeling GPT2.py,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=769" target="_blank">00:12:49.200</a></span> | <span class="t">because it's just too complicated. We want to write this from scratch ourselves,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=772" target="_blank">00:12:52.400</a></span> | <span class="t">so we're going to be implementing the GPT model here in parallel, and as our first task,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=777" target="_blank">00:12:57.120</a></span> | <span class="t">let's load the GPT2124M into the class that we are going to develop here from scratch.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=783" target="_blank">00:13:03.680</a></span> | <span class="t">That's going to give us confidence that we can load the OpenAI model, and therefore,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=789" target="_blank">00:13:09.200</a></span> | <span class="t">there's a setting of weights that exactly is the 124 model, but then, of course,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=793" target="_blank">00:13:13.680</a></span> | <span class="t">what we're going to do is we're going to initialize the model from scratch instead,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=796" target="_blank">00:13:16.880</a></span> | <span class="t">and try to train it ourselves on a bunch of documents that we're going to get,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=801" target="_blank">00:13:21.440</a></span> | <span class="t">and we're going to try to surpass that model, so we're going to get different weights,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=805" target="_blank">00:13:25.520</a></span> | <span class="t">and everything's going to look different, hopefully better even, but we're going to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=810" target="_blank">00:13:30.560</a></span> | <span class="t">have a lot of confidence that because we can load the OpenAI model, we are in the same model family</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=814" target="_blank">00:13:34.800</a></span> | <span class="t">and model class, and we just have to rediscover a good setting of the weights, but from scratch.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=819" target="_blank">00:13:39.280</a></span> | <span class="t">So let's now write the GPT2 model, and let's load the weights, and make sure that we can</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=825" target="_blank">00:13:45.360</a></span> | <span class="t">also generate text that looks coherent. Okay, so let's now swing over to the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=829" target="_blank">00:13:49.440</a></span> | <span class="t">attention is all you need paper that started everything, and let's scroll over to the model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=833" target="_blank">00:13:53.280</a></span> | <span class="t">architecture, the original transformer. Now, remember that GPT2 is slightly modified from</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=838" target="_blank">00:13:58.720</a></span> | <span class="t">the original transformer. In particular, we do not have the encoder. GPT2 is a decoder-only</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=845" target="_blank">00:14:05.120</a></span> | <span class="t">transformer, as we call it, so this entire encoder here is missing, and in addition to that,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=850" target="_blank">00:14:10.080</a></span> | <span class="t">this cross-attention here that was using that encoder is also missing, so we delete this entire</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=856" target="_blank">00:14:16.240</a></span> | <span class="t">part. Everything else stays almost the same, but there are some differences that we're going to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=861" target="_blank">00:14:21.680</a></span> | <span class="t">sort of look at here. So there are two main differences. When we go to the GPT2 paper under</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=869" target="_blank">00:14:29.680</a></span> | <span class="t">2.3.model, we notice that first, there's a reshuffling of the layer norms, so they change</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=875" target="_blank">00:14:35.680</a></span> | <span class="t">place, and second, an additional layer normalization was added here to the final</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=882" target="_blank">00:14:42.320</a></span> | <span class="t">self-attention block. So basically, all the layer norms here, instead of being after the MLP or</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=888" target="_blank">00:14:48.000</a></span> | <span class="t">after the attention, they swing before it, and an additional layer norm gets added here right before</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=893" target="_blank">00:14:53.040</a></span> | <span class="t">the final classifier. So now let's implement some of the first sort of skeleton NN modules</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=899" target="_blank">00:14:59.200</a></span> | <span class="t">here in our GPT NN module, and in particular, we're going to try to match up this schema here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=905" target="_blank">00:15:05.760</a></span> | <span class="t">that is used by Hugging Face Transformers because that will make it much easier to load these weights</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=910" target="_blank">00:15:10.480</a></span> | <span class="t">from this state dict. So we want something that reflects this schema here. So here's what I came</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=917" target="_blank">00:15:17.120</a></span> | <span class="t">up with. Basically, we see that the main container here that has all the modules is called transformer,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=925" target="_blank">00:15:25.920</a></span> | <span class="t">so I'm reflecting that with an NN module dict, and this is basically a module that allows you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=930" target="_blank">00:15:30.400</a></span> | <span class="t">to index into the sub-modules using keys, just like a dictionary strings. Within it, we have the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=938" target="_blank">00:15:38.480</a></span> | <span class="t">weights of the token embeddings, WT, and that's an NN embedding, and the weights of the position</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=944" target="_blank">00:15:44.320</a></span> | <span class="t">embeddings, which is also just an NN embedding, and if you remember, NN embedding is really just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=948" target="_blank">00:15:48.400</a></span> | <span class="t">a fancy little wrapper module around just a single array of numbers, a single block of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=957" target="_blank">00:15:57.440</a></span> | <span class="t">numbers just like this. It's a single tensor, and NN embedding is a glorified wrapper around a tensor</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=964" target="_blank">00:16:04.640</a></span> | <span class="t">that allows you to access its elements by indexing into the rows. Now, in addition to that, we see</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=970" target="_blank">00:16:10.960</a></span> | <span class="t">here that we have a .h, and then this is indexed using numbers instead of indexed using strings,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=977" target="_blank">00:16:17.920</a></span> | <span class="t">so there's a .h, .0, 1, 2, etc., all the way up till .h.11, and that's because there are 12 layers</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=985" target="_blank">00:16:25.680</a></span> | <span class="t">here in this transformer. So to reflect that, I'm creating also an h, I think that probably</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=991" target="_blank">00:16:31.440</a></span> | <span class="t">stands for hidden, and instead of a module dict, this is a model list, so we can index it using</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=996" target="_blank">00:16:36.480</a></span> | <span class="t">integers exactly as we see here, .0, .1, 2, etc., and the module list has N layer blocks, and the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=1005" target="_blank">00:16:45.680</a></span> | <span class="t">blocks are yet to be defined in a module in a bit. In addition to that, following the GPT-2 paper,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=1011" target="_blank">00:16:51.840</a></span> | <span class="t">we need an additional final layer norm that we're going to put in there, and then we have the final</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=1018" target="_blank">00:16:58.080</a></span> | <span class="t">classifier, the language model head, which projects from 768, the number of embedding</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=1026" target="_blank">00:17:06.000</a></span> | <span class="t">dimensions in this GPT, all the way to the vocab size, which is 50,257, and GPT-2 uses no bias for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=1033" target="_blank">00:17:13.200</a></span> | <span class="t">this final sort of projection. So this is the skeleton, and you can see that it reflects this,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=1040" target="_blank">00:17:20.160</a></span> | <span class="t">so the WTE is the token embeddings, here it's called output embedding, but it's really the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=1046" target="_blank">00:17:26.000</a></span> | <span class="t">token embeddings. The PE is the positional encodings, those two pieces of information,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=1051" target="_blank">00:17:31.440</a></span> | <span class="t">as we saw previously, are going to add, and then go into the transformer. The .h is all the blocks</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=1057" target="_blank">00:17:37.120</a></span> | <span class="t">in gray, and the LNF is this new layer that gets added here by the GPT-2 model, and LM_head is this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=1065" target="_blank">00:17:45.040</a></span> | <span class="t">linear part here. So that's the skeleton of the GPT-2. We now have to implement the block.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=1072" target="_blank">00:17:52.480</a></span> | <span class="t">Okay, so let's now recurse to the block itself. So we want to define the block.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=1076" target="_blank">00:17:56.400</a></span> | <span class="t">So I'll start putting them here. So the block, I like to write out like this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=1083" target="_blank">00:18:03.680</a></span> | <span class="t">These are some of the initializations, and then this is the actual forward pass of what this block</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=1089" target="_blank">00:18:09.040</a></span> | <span class="t">computes. And notice here that there's a change from the transformer again, that is mentioned</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=1094" target="_blank">00:18:14.800</a></span> | <span class="t">in the GPT-2 paper. So here, the layer normalizations are after the application of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=1100" target="_blank">00:18:20.480</a></span> | <span class="t">attention, or feedforward. In addition to that note, that the normalizations are inside the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=1105" target="_blank">00:18:25.840</a></span> | <span class="t">residual stream. You see how feedforward is applied, and this arrow goes through and through</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=1111" target="_blank">00:18:31.120</a></span> | <span class="t">the normalization. So that means that your residual pathway has normalizations inside them.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=1116" target="_blank">00:18:36.800</a></span> | <span class="t">And this is not very good or desirable. You actually prefer to have a single clean residual</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=1122" target="_blank">00:18:42.800</a></span> | <span class="t">stream, all the way from supervision, all the way down to the inputs, the tokens. And this is very</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=1128" target="_blank">00:18:48.400</a></span> | <span class="t">desirable and nice, because the gradients that flow from the top, if you remember from your</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=1134" target="_blank">00:18:54.240</a></span> | <span class="t">micrograd, addition just distributes gradients during the backward stage to both of its branches</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=1140" target="_blank">00:19:00.480</a></span> | <span class="t">equally. So addition is a branch in the gradients. And so that means that the gradients from the top</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=1147" target="_blank">00:19:07.360</a></span> | <span class="t">flow straight to the inputs, the tokens, through the residual pathways unchanged. But then in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=1153" target="_blank">00:19:13.280</a></span> | <span class="t">addition to that, the gradient also flows through the blocks, and the blocks, you know, contribute</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=1157" target="_blank">00:19:17.520</a></span> | <span class="t">their own contribution over time, and kick in and change the optimization over time. But basically,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=1162" target="_blank">00:19:22.240</a></span> | <span class="t">clean residual pathway is desirable from an optimization perspective. And then this is the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=1168" target="_blank">00:19:28.880</a></span> | <span class="t">pre-normalization version, where you see that Rx first goes through the layer normalization,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=1173" target="_blank">00:19:33.920</a></span> | <span class="t">and then the attention, and then goes back out to go to the layer normalization number two,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=1179" target="_blank">00:19:39.600</a></span> | <span class="t">and the multilayer perceptron, sometimes also referred to as a feedforward network, or an FFM.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=1186" target="_blank">00:19:46.160</a></span> | <span class="t">And then that goes into the residual stream again. And the one more thing that is kind of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=1190" target="_blank">00:19:50.800</a></span> | <span class="t">interesting to note is that recall that attention is a communication operation. It is where all the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=1196" target="_blank">00:19:56.000</a></span> | <span class="t">tokens, and there's 1024 tokens lined up in a sequence, and this is where the tokens communicate.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=1201" target="_blank">00:20:01.760</a></span> | <span class="t">This is where they exchange information. So attention is a aggregation function. It's a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=1208" target="_blank">00:20:08.080</a></span> | <span class="t">pooling function. It's a weighted sum function. It is a reduce operation. Whereas MLP, this MLP</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=1217" target="_blank">00:20:17.360</a></span> | <span class="t">here happens at every single token individually. There's no information being collected or</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=1221" target="_blank">00:20:21.440</a></span> | <span class="t">exchanged between the tokens. So the attention is the reduce, and the MLP is the map. And what you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=1227" target="_blank">00:20:27.680</a></span> | <span class="t">end up with is that the transformer just ends up just being a repeated application of map reduce,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=1232" target="_blank">00:20:32.320</a></span> | <span class="t">if you want to think about it that way. So this is where they communicate, and this is where they</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=1238" target="_blank">00:20:38.000</a></span> | <span class="t">think individually about the information that they gathered. And every one of these blocks</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=1242" target="_blank">00:20:42.560</a></span> | <span class="t">iteratively refines the representation inside the residual stream. So this is our block,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=1249" target="_blank">00:20:49.520</a></span> | <span class="t">slightly modified from this picture. Okay, so let's now move on to the MLP. So the MLP block,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=1256" target="_blank">00:20:56.880</a></span> | <span class="t">I implemented it as follows. It is relatively straightforward. We basically have two linear</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=1262" target="_blank">00:21:02.080</a></span> | <span class="t">projections here that are sandwiched in between the Gelu non-linearity. So nn.gelu approximate</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=1269" target="_blank">00:21:09.520</a></span> | <span class="t">is 10h. Now when we swing over to the PyTorch documentation, this is nn.gelu, and it has this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=1276" target="_blank">00:21:16.880</a></span> | <span class="t">format, and it has two versions, the original version of Gelu, which we'll step into in a bit,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=1282" target="_blank">00:21:22.320</a></span> | <span class="t">and the approximate version of Gelu, which we can request using 10h. So as you can see, just as a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=1288" target="_blank">00:21:28.080</a></span> | <span class="t">preview here, Gelu is basically like a ReLU, except there's no flat, exactly flat tail here at exactly</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=1296" target="_blank">00:21:36.400</a></span> | <span class="t">zero. But otherwise it looks very much like a slightly smoother ReLU. It comes from this paper</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=1302" target="_blank">00:21:42.080</a></span> | <span class="t">here, Gaussian Error Linear Units, and you can step through this paper, and there's some mathematical</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=1308" target="_blank">00:21:48.080</a></span> | <span class="t">kind of like reasoning that leads to an interpretation that leads to this specific</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=1311" target="_blank">00:21:51.840</a></span> | <span class="t">formulation. It has to do with stochastic radial risers and the expectation of a modification to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=1317" target="_blank">00:21:57.360</a></span> | <span class="t">adaptive dropout, so you can read through all of that if you'd like here. And there's a little bit</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=1322" target="_blank">00:22:02.320</a></span> | <span class="t">of a history as to why there's an approximate version of Gelu, and that comes from this issue</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=1327" target="_blank">00:22:07.520</a></span> | <span class="t">here, as far as I can tell. And in this issue, Daniel Hendrix mentions that at the time when</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=1334" target="_blank">00:22:14.320</a></span> | <span class="t">they developed this non-linearity, the IRF function, which you need to evaluate the exact Gelu,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=1340" target="_blank">00:22:20.800</a></span> | <span class="t">was very slow in TensorFlow, so they ended up basically developing this approximation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=1344" target="_blank">00:22:24.720</a></span> | <span class="t">And this approximation then ended up being picked up by BERT and by GPT-2, etc.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=1349" target="_blank">00:22:29.200</a></span> | <span class="t">But today there's no real good reason to use the approximate version. You'd prefer to just use the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=1353" target="_blank">00:22:33.680</a></span> | <span class="t">exact version, because my expectation is that there's no big difference anymore, and this is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=1359" target="_blank">00:22:39.760</a></span> | <span class="t">kind of like a historical kind of quirk. But we are trying to reproduce GPT-2 exactly, and GPT-2</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=1367" target="_blank">00:22:47.440</a></span> | <span class="t">used the 10H approximate version, so we prefer to stick with that. Now one other reason to actually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=1375" target="_blank">00:22:55.200</a></span> | <span class="t">just intuitively use Gelu instead of Relu is, previously in videos in the past, we've spoken</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=1380" target="_blank">00:23:00.240</a></span> | <span class="t">about the dead Relu neuron problem, where in this tail of a Relu, if it's exactly flat at zero,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=1387" target="_blank">00:23:07.360</a></span> | <span class="t">any activations that fall there will get exactly zero gradient. There's no change,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=1391" target="_blank">00:23:11.440</a></span> | <span class="t">there's no adaptation, there's no development of the network if any of these activations</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=1396" target="_blank">00:23:16.160</a></span> | <span class="t">end in this flat region. But the Gelu always contributes a local gradient, and so there's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=1401" target="_blank">00:23:21.680</a></span> | <span class="t">always going to be a change, always going to be an adaptation, and sort of smoothing it out</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=1405" target="_blank">00:23:25.840</a></span> | <span class="t">ends up empirically working better in practice, as demonstrated in this paper, and also as</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=1410" target="_blank">00:23:30.240</a></span> | <span class="t">demonstrated by it being picked up by the BERT paper, GPT-2 paper, and so on. So for that reason</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=1415" target="_blank">00:23:35.440</a></span> | <span class="t">we adopt this non-linearity here in the 10 in the GPT-2 reproduction. Now in more modern networks,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=1421" target="_blank">00:23:41.760</a></span> | <span class="t">also like Lama3 and so on, this non-linearity also further changes to Swiglu and other variants like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=1428" target="_blank">00:23:48.160</a></span> | <span class="t">that, but for GPT-2 they use this approximate Gelu. Okay, and finally we have the attention</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=1434" target="_blank">00:23:54.320</a></span> | <span class="t">operation. So let me paste in my attention. So I know this is a lot, so I'm gonna go through this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=1442" target="_blank">00:24:02.400</a></span> | <span class="t">a bit quickly, a bit slowly, but not too slowly, because we have covered this in the previous video</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=1447" target="_blank">00:24:07.200</a></span> | <span class="t">and I would just point you there. So this is the attention operation. Now in the previous video</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=1452" target="_blank">00:24:12.880</a></span> | <span class="t">you will remember this is not just attention, this is multi-headed attention, right? And so in the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=1459" target="_blank">00:24:19.520</a></span> | <span class="t">previous video we had this multi-headed attention module, and this implementation made it obvious</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=1464" target="_blank">00:24:24.960</a></span> | <span class="t">that these heads are not actually that complicated. There's basically, in parallel, inside every</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=1470" target="_blank">00:24:30.480</a></span> | <span class="t">attention block, there's multiple heads, and they're all functioning in parallel, and their</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=1476" target="_blank">00:24:36.640</a></span> | <span class="t">outputs are just being concatenated, and that becomes the output of the multi-headed attention.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=1481" target="_blank">00:24:41.520</a></span> | <span class="t">So the heads are just kind of like parallel streams, and their outputs get concatenated.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=1486" target="_blank">00:24:46.480</a></span> | <span class="t">And so it was very simple and made the head be kind of like fairly straightforward in terms of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=1492" target="_blank">00:24:52.640</a></span> | <span class="t">its implementation. What happens here is that instead of having two separate modules, and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=1498" target="_blank">00:24:58.320</a></span> | <span class="t">indeed many more modules that get concatenated, all of that is just put into a single self-attention</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=1504" target="_blank">00:25:04.800</a></span> | <span class="t">module. And instead I'm being very careful and doing a bunch of transpose-split tensor gymnastics</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=1512" target="_blank">00:25:12.800</a></span> | <span class="t">to make this very efficient in PyTorch, but fundamentally and algorithmically nothing is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=1516" target="_blank">00:25:16.720</a></span> | <span class="t">different from the implementation we saw before in this Git repository. So to remind you very</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=1525" target="_blank">00:25:25.520</a></span> | <span class="t">briefly, and I don't want to go into this in too much time, but we have these tokens lined up in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=1532" target="_blank">00:25:32.080</a></span> | <span class="t">a sequence, and there's 1020 of them. And then each token at this stage of the attention emits</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=1538" target="_blank">00:25:38.320</a></span> | <span class="t">three vectors, the query, key, and the value. And first what happens here is that the queries and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=1545" target="_blank">00:25:45.840</a></span> | <span class="t">the keys have to multiply each other to get sort of the attention amount, like how interesting they</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=1552" target="_blank">00:25:52.720</a></span> | <span class="t">find each other. So they have to interact multiplicatively. So what we're doing here is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=1556" target="_blank">00:25:56.720</a></span> | <span class="t">we're calculating the QKV while splitting it, and then there's a bunch of gymnastics as I mentioned</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=1561" target="_blank">00:26:01.520</a></span> | <span class="t">here. And the way this works is that we're basically making the number of heads, nh,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=1567" target="_blank">00:26:07.600</a></span> | <span class="t">into a batch dimension. And so it's a batch dimension just like b, so that in these operations</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=1573" target="_blank">00:26:13.360</a></span> | <span class="t">that follow, PyTorch treats b and nh as batches, and it applies all the operations on all of them</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=1580" target="_blank">00:26:20.480</a></span> | <span class="t">in parallel, in both the batch and the heads. And the operations that get applied are, number one,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=1586" target="_blank">00:26:26.560</a></span> | <span class="t">the queries and the keys interact to give us our attention. This is the autoregressive mask</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=1591" target="_blank">00:26:31.840</a></span> | <span class="t">that made sure that the tokens only attend to tokens before them and never to tokens in the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=1597" target="_blank">00:26:37.920</a></span> | <span class="t">future. The softmax here normalizes the attention, so it sums to one always. And then recall from</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=1606" target="_blank">00:26:46.160</a></span> | <span class="t">the previous video that doing the attention matrix multiply with the values is basically</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=1609" target="_blank">00:26:49.920</a></span> | <span class="t">a way to do a weighted sum of the values of the tokens that we found interesting at every single</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=1615" target="_blank">00:26:55.200</a></span> | <span class="t">token. And then the final transpose contiguous and view is just reassembling all of that again,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=1621" target="_blank">00:27:01.520</a></span> | <span class="t">and this actually performs a concatenation operation. So you can step through this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=1626" target="_blank">00:27:06.240</a></span> | <span class="t">slowly if you'd like, but it is equivalent mathematically to our previous implementation,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=1632" target="_blank">00:27:12.240</a></span> | <span class="t">it's just more efficient in PyTorch, so that's why I chose this implementation instead.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=1635" target="_blank">00:27:15.840</a></span> | <span class="t">Now in addition to that, I'm being careful with how I name my variables. So for example,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=1640" target="_blank">00:27:20.880</a></span> | <span class="t">seaten is the same as seaten, and so actually our keys should basically exactly follow the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=1646" target="_blank">00:27:26.880</a></span> | <span class="t">schema of the HuggingFaceTransformers code, and that will make it very easy for us to now</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=1651" target="_blank">00:27:31.040</a></span> | <span class="t">port over all the weights from exactly this sort of naming conventions, because all of our variables</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=1657" target="_blank">00:27:37.200</a></span> | <span class="t">are named the same thing. But at this point we have finished the GPT-2 implementation,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=1662" target="_blank">00:27:42.800</a></span> | <span class="t">and what that allows us to do is we don't have to basically use this file from HuggingFace,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=1667" target="_blank">00:27:47.920</a></span> | <span class="t">which is fairly long. This is 2,000 lines of code, instead we just have less than 100 lines of code,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=1679" target="_blank">00:27:59.280</a></span> | <span class="t">and this is the complete GPT-2 implementation. So at this stage we should just be able to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=1683" target="_blank">00:28:03.840</a></span> | <span class="t">take over all the weights, set them, and then do generation. So let's see what that looks like.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=1688" target="_blank">00:28:08.960</a></span> | <span class="t">Okay, so here I've also changed the GPT config so that the numbers here,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=1692" target="_blank">00:28:12.640</a></span> | <span class="t">the hybrid parameters, agree with the GPT-2-124M model. So the maximum sequence length, which I</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=1697" target="_blank">00:28:17.920</a></span> | <span class="t">call block size here, is 124. The number of tokens is 5250257, which if you watch my tokenizer video</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=1706" target="_blank">00:28:26.400</a></span> | <span class="t">know that this is 50,000 merges, BPE merges, 256 byte tokens, the leaves of the BPE tree,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=1714" target="_blank">00:28:34.880</a></span> | <span class="t">and one special end-of-text token that delimits different documents and can start generation as</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=1719" target="_blank">00:28:39.840</a></span> | <span class="t">well. And there are 12 layers, there are 12 heads in the attention, and the dimension of the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=1725" target="_blank">00:28:45.360</a></span> | <span class="t">transformer is 768. So here's how we can now load the parameters from HuggingFace to our code here,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=1733" target="_blank">00:28:53.200</a></span> | <span class="t">and initialize the GPT class with those parameters. So let me just copy-paste a bunch of code here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=1738" target="_blank">00:28:58.400</a></span> | <span class="t">And I'm not going to go through this code too slowly, because honestly it's not that interesting,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=1747" target="_blank">00:29:07.920</a></span> | <span class="t">it's not that exciting. We're just loading the weights, so it's kind of dry. But as I mentioned,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=1751" target="_blank">00:29:11.680</a></span> | <span class="t">there are four models in this mini-series of GPT-2. This is some of the Jupyter code</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=1756" target="_blank">00:29:16.400</a></span> | <span class="t">that we had here on the right. I'm just porting it over. These are the hyperparameters of the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=1762" target="_blank">00:29:22.240</a></span> | <span class="t">GPT-2 models. We're creating the config object and creating our own model. And then what's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=1767" target="_blank">00:29:27.600</a></span> | <span class="t">happening here is we're creating the state dict, both for our model and for the HuggingFace model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=1775" target="_blank">00:29:35.360</a></span> | <span class="t">And then what we're doing here is we're going over to HuggingFace model keys, and we're copying over</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=1781" target="_blank">00:29:41.600</a></span> | <span class="t">those tensors. And in the process, we are kind of ignoring a few of the buffers. They're not</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=1787" target="_blank">00:29:47.440</a></span> | <span class="t">parameters, they're buffers. So for example, attention.bias, that's just used for the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=1791" target="_blank">00:29:51.600</a></span> | <span class="t">autoregressive mask. And so we are ignoring some of those masks, and that's it. And then one</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=1798" target="_blank">00:29:58.240</a></span> | <span class="t">additional kind of annoyance is that this comes from the TensorFlow repo, and I'm not sure how...</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=1803" target="_blank">00:30:03.280</a></span> | <span class="t">This is a little bit annoying, but some of the weights are transposed from what PyTorch would</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=1807" target="_blank">00:30:07.440</a></span> | <span class="t">want. And so manually, I hardcoded the weights that should be transposed, and then we transpose</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=1813" target="_blank">00:30:13.040</a></span> | <span class="t">them if that is so. And then we return this model. So the from_pretrained is a constructor</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=1819" target="_blank">00:30:19.920</a></span> | <span class="t">or a class method in Python that returns the GPT object if we just give it the model type,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=1827" target="_blank">00:30:27.680</a></span> | <span class="t">which in our case is GPT-2, the smallest model that we're interested in. So this is the code,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=1832" target="_blank">00:30:32.800</a></span> | <span class="t">and this is how you would use it. And we can pop open the terminal here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=1837" target="_blank">00:30:37.200</a></span> | <span class="t">in VS Code, and we can Python train GPT-2.py, and fingers crossed.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=1844" target="_blank">00:30:44.960</a></span> | <span class="t">Okay, so we didn't crash. And so we can load the weights and the biases and everything else</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=1853" target="_blank">00:30:53.680</a></span> | <span class="t">into our NNModule. But now let's also get additional confidence that this is working,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=1858" target="_blank">00:30:58.080</a></span> | <span class="t">and let's try to actually generate from this model. Okay, now before we can actually generate</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=1862" target="_blank">00:31:02.160</a></span> | <span class="t">from this model, we have to be able to forward it. We didn't actually write that code yet.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=1866" target="_blank">00:31:06.080</a></span> | <span class="t">So here's the forward function. So the input to the forward is going to be our indices,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=1872" target="_blank">00:31:12.640</a></span> | <span class="t">our token indices. And they are always of shape B by T. And so we have batch dimension of B,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=1880" target="_blank">00:31:20.720</a></span> | <span class="t">and then we have the time dimension of up to T. And the T can't be more than the block size.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=1887" target="_blank">00:31:27.120</a></span> | <span class="t">The block size is the maximum sequence length. So B by T indices are arranged in sort of like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=1892" target="_blank">00:31:32.720</a></span> | <span class="t">a two-dimensional layout. And remember that basically every single row of this is of size</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=1898" target="_blank">00:31:38.000</a></span> | <span class="t">up to block size. And this is T tokens that are in a sequence. And then we have B independent</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=1904" target="_blank">00:31:44.720</a></span> | <span class="t">sequences stacked up in a batch so that this is efficient. Now here we are forwarding the position</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=1911" target="_blank">00:31:51.440</a></span> | <span class="t">embeddings and the token embeddings. And this code should be very recognizable from the previous</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=1915" target="_blank">00:31:55.360</a></span> | <span class="t">lecture. So we basically use a range, which is kind of like a version of range, but for PyTorch.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=1922" target="_blank">00:32:02.080</a></span> | <span class="t">And we're iterating from zero to T and creating this positions sort of indices.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=1928" target="_blank">00:32:08.880</a></span> | <span class="t">And then we are making sure that they're on the same device as IDX, because we're not going to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=1934" target="_blank">00:32:14.800</a></span> | <span class="t">be training on only CPU. That's going to be too inefficient. We want to be training on GPU,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=1938" target="_blank">00:32:18.640</a></span> | <span class="t">and that's going to come in a bit. Then we have the position embeddings and the token embeddings,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=1943" target="_blank">00:32:23.680</a></span> | <span class="t">and the addition operation of those two. Now notice that the position embeddings are going</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=1948" target="_blank">00:32:28.240</a></span> | <span class="t">to be identical for every single row of input. And so there's broadcasting hidden inside this plus,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=1956" target="_blank">00:32:36.000</a></span> | <span class="t">where we have to create an additional dimension here, and then these two add up because the same</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=1960" target="_blank">00:32:40.560</a></span> | <span class="t">position embeddings apply at every single row of our examples stacked up in a batch.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=1964" target="_blank">00:32:44.560</a></span> | <span class="t">Then we forward the transformer blocks, and finally the last layer norm and the LMAD.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=1971" target="_blank">00:32:51.120</a></span> | <span class="t">So what comes out after forward is the logits. And if the input was B by T indices,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=1977" target="_blank">00:32:57.120</a></span> | <span class="t">then at every single B by T, we will calculate the logits for what token comes next in the sequence.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=1985" target="_blank">00:33:05.200</a></span> | <span class="t">So what is the token B, T plus one, the one on the right of this token. And vocab size here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=1992" target="_blank">00:33:12.880</a></span> | <span class="t">is the number of possible tokens. And so therefore this is the tensor that we're going to obtain.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=1998" target="_blank">00:33:18.800</a></span> | <span class="t">And these logits are just a softmax away from becoming probabilities. So this is the forward</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=2005" target="_blank">00:33:25.040</a></span> | <span class="t">pass of the network, and now we can get logits. And so we're going to be able to generate from</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=2009" target="_blank">00:33:29.360</a></span> | <span class="t">the model imminently. Okay, so now we're going to try to set up the identical thing on the left here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=2015" target="_blank">00:33:35.440</a></span> | <span class="t">that matches hug and face on the right. So here we've sampled from the pipeline, and we sampled</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=2021" target="_blank">00:33:41.120</a></span> | <span class="t">five times up to 30 tokens with the prefix of hello, I'm a language model. And these are the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=2026" target="_blank">00:33:46.560</a></span> | <span class="t">completions that we achieved. So we're going to try to replicate that on the left here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=2029" target="_blank">00:33:49.920</a></span> | <span class="t">So number of turn sequences is five, max length is 30. So the first thing we do, of course,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=2034" target="_blank">00:33:54.320</a></span> | <span class="t">is we initialize our model, then we put it into evaluation mode. Now, this is a good practice to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=2039" target="_blank">00:33:59.440</a></span> | <span class="t">put the model into eval when you're not going to be training it, you're just going to be using it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=2043" target="_blank">00:34:03.200</a></span> | <span class="t">And I don't actually know if this is doing anything right now for the following reason.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=2048" target="_blank">00:34:08.720</a></span> | <span class="t">Our model up above here contains no modules or layers that actually have a different behavior</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=2054" target="_blank">00:34:14.880</a></span> | <span class="t">at training or evaluation time. So for example, dropout, batch norm, and a bunch of other layers</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=2059" target="_blank">00:34:19.600</a></span> | <span class="t">have this kind of behavior. But all of these layers that we've used here should be identical</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=2063" target="_blank">00:34:23.520</a></span> | <span class="t">in both training and evaluation time. So potentially, model.eval does nothing. But</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=2069" target="_blank">00:34:29.920</a></span> | <span class="t">then I'm not actually sure if this is the case. And maybe PyTorch internals do some clever things,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=2074" target="_blank">00:34:34.960</a></span> | <span class="t">depending on the evaluation mode inside here. The next thing we're doing here is we are moving</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=2080" target="_blank">00:34:40.640</a></span> | <span class="t">the entire model to CUDA. So we're moving all of the tensors to GPU. So I'm SSH'd here to a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=2087" target="_blank">00:34:47.520</a></span> | <span class="t">cloud box, and I have a bunch of GPUs on this box. And here, I'm moving the entire model and all of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=2093" target="_blank">00:34:53.840</a></span> | <span class="t">its members and all of its tensors and everything like that. Everything gets shipped off to basically</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=2099" target="_blank">00:34:59.280</a></span> | <span class="t">a whole separate computer that is sitting on the GPU. And the GPU is connected to the CPU,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=2105" target="_blank">00:35:05.040</a></span> | <span class="t">and they can communicate, but it's basically a whole separate computer with its own computer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=2108" target="_blank">00:35:08.240</a></span> | <span class="t">architecture. And it's really well catered to parallel processing tasks like those of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=2112" target="_blank">00:35:12.400</a></span> | <span class="t">running neural networks. So I'm doing this so that the model lives on the GPU, a whole separate</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=2118" target="_blank">00:35:18.080</a></span> | <span class="t">computer. And it's just going to make our code a lot more efficient, because all of this stuff</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=2122" target="_blank">00:35:22.720</a></span> | <span class="t">runs a lot more efficiently on the GPUs. So that's the model itself. Now, the next thing we want to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=2131" target="_blank">00:35:31.760</a></span> | <span class="t">do is we want to start with this as the prefix when we do the generation. So let's actually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=2137" target="_blank">00:35:37.920</a></span> | <span class="t">create those prefix tokens. So here's the code that I've written. We're going to import the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=2142" target="_blank">00:35:42.960</a></span> | <span class="t">tick token library from OpenAI, and we're going to get the GPT-2 encoding. So that's the tokenizer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=2149" target="_blank">00:35:49.120</a></span> | <span class="t">for GPT-2. And then we're going to encode this string and get a list of integers, which are the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=2155" target="_blank">00:35:55.680</a></span> | <span class="t">tokens. Now, these integers here should actually be fairly straightforward, because we can just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=2161" target="_blank">00:36:01.440</a></span> | <span class="t">copy/paste this string, and we can sort of inspect what it is in tick tokenizer. So just pasting that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=2167" target="_blank">00:36:07.520</a></span> | <span class="t">in, these are the tokens that are going to come out. So this list of integers is what we expect</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=2172" target="_blank">00:36:12.800</a></span> | <span class="t">tokens to become. And as you recall, if you saw my video, of course, all the tokens, they're just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=2178" target="_blank">00:36:18.400</a></span> | <span class="t">little string chunks, right? So this is the truncation of this string into GPT-2 tokens.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=2184" target="_blank">00:36:24.560</a></span> | <span class="t">So once we have those tokens, it's a list of integers, we can create a torch tensor out of it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=2191" target="_blank">00:36:31.280</a></span> | <span class="t">In this case, it's eight tokens. And then we're going to replicate these eight tokens for five</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=2195" target="_blank">00:36:35.920</a></span> | <span class="t">times to get five rows of eight tokens. And that is our initial input X, as I call it here. And</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=2205" target="_blank">00:36:45.120</a></span> | <span class="t">it lives on the GPU as well. So X now is this IDX that we can pin to forward to get our logits so</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=2214" target="_blank">00:36:54.080</a></span> | <span class="t">that we know what comes as the sixth token, sorry, as the ninth token in every one of these five</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=2221" target="_blank">00:37:01.760</a></span> | <span class="t">rows. Okay, and we are now ready to generate. So let me paste in one more code block here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=2226" target="_blank">00:37:06.880</a></span> | <span class="t">So what's happening here in this code block is we have these X, which is of size B by T, right? So</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=2234" target="_blank">00:37:14.560</a></span> | <span class="t">batch by time. And we're going to be in every iteration of this loop, we're going to be adding</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=2239" target="_blank">00:37:19.600</a></span> | <span class="t">a column of new indices into each one of these rows, right? And so these are the new indices,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=2245" target="_blank">00:37:25.680</a></span> | <span class="t">and we're appending them to the sequence as we're sampling. So with each loop iteration,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=2250" target="_blank">00:37:30.560</a></span> | <span class="t">we get one more column into X. And all of the operations happen in the context manager of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=2255" target="_blank">00:37:35.920</a></span> | <span class="t">torch.nograd. This is just telling PyTorch that we're not going to be calling that backward on</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=2260" target="_blank">00:37:40.080</a></span> | <span class="t">any of this. So it doesn't have to cache all the intermediate tensors, it's not going to have to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=2264" target="_blank">00:37:44.480</a></span> | <span class="t">prepare in any way for a potential backward later. And this saves a lot of space and also possibly</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=2270" target="_blank">00:37:50.560</a></span> | <span class="t">some time. So we get our logits, we get the logits at only the last location, we throw away all the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=2277" target="_blank">00:37:57.440</a></span> | <span class="t">other logits, we don't need them, we only care about the last columns logits. So this is being</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=2283" target="_blank">00:38:03.360</a></span> | <span class="t">wasteful. But this is just kind of like an inefficient implementation of sampling. So it's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=2289" target="_blank">00:38:09.680</a></span> | <span class="t">correct but inefficient. So we get the last column of logits, pass it through softmax to get our</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=2295" target="_blank">00:38:15.040</a></span> | <span class="t">probabilities. Then here I'm doing top k sampling of 50. And I'm doing that because this is the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=2299" target="_blank">00:38:19.760</a></span> | <span class="t">HuggingFace default. So just looking at the HuggingFace docs here of a pipeline, there's a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=2306" target="_blank">00:38:26.880</a></span> | <span class="t">bunch of quarks that go into HuggingFace. And I mean, it's kind of a lot, honestly. But I guess</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=2315" target="_blank">00:38:35.600</a></span> | <span class="t">the important one that I noticed is that they're using top k by default, which is 50. And what</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=2320" target="_blank">00:38:40.240</a></span> | <span class="t">that does is that, so that's being used here as well. And what that does is basically we want to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=2326" target="_blank">00:38:46.000</a></span> | <span class="t">take our probabilities, and we only want to keep the top 50 probabilities. And anything that is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=2331" target="_blank">00:38:51.280</a></span> | <span class="t">lower than the 50th probability, we just clamp to zero and renormalize. And so that way, we are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=2337" target="_blank">00:38:57.360</a></span> | <span class="t">never sampling very rare tokens. The tokens we're going to be sampling are always in the top 50 of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=2343" target="_blank">00:39:03.280</a></span> | <span class="t">most likely tokens. And this helps keep the model kind of on track, and it doesn't blabber on, and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=2348" target="_blank">00:39:08.080</a></span> | <span class="t">it doesn't get lost, and doesn't go off the rails as easily. And it kind of like sticks in the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=2353" target="_blank">00:39:13.520</a></span> | <span class="t">vicinity of likely tokens a lot better. So this is the way to do it in PyTorch. And you can step</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=2358" target="_blank">00:39:18.480</a></span> | <span class="t">through it if you like. I don't think it's super insightful, so I'll speed through it. But roughly</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=2362" target="_blank">00:39:22.480</a></span> | <span class="t">speaking, we get this new column of tokens. We append them on x. And basically the columns of x</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=2369" target="_blank">00:39:29.280</a></span> | <span class="t">grow until this while loop gets tripped up. And then finally, we have an entire x of size</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=2375" target="_blank">00:39:35.760</a></span> | <span class="t">5 by 30, in this case, in this example. And we can just basically print all those individual</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=2384" target="_blank">00:39:44.240</a></span> | <span class="t">rows. So I'm getting all the rows, I'm getting all the tokens that were sampled, and I'm using</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=2389" target="_blank">00:39:49.760</a></span> | <span class="t">the decode function from TickTokenizer to get back the string, which we can print. And so terminal,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=2396" target="_blank">00:39:56.480</a></span> | <span class="t">new terminal. And let me Python train GPT2.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=2401" target="_blank">00:40:01.600</a></span> | <span class="t">Okay. So these are the generations that we're getting. Hello, I'm a language model. Not a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=2414" target="_blank">00:40:14.160</a></span> | <span class="t">program. New line, new line, et cetera. Hello, I'm a language model, and one of the main things</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=2421" target="_blank">00:40:21.120</a></span> | <span class="t">that bothers me when they create languages is how easy it becomes to create something that -- I mean,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=2425" target="_blank">00:40:25.760</a></span> | <span class="t">so this will just like blabber on, right, in all these cases. Now, one thing you will notice is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=2429" target="_blank">00:40:29.680</a></span> | <span class="t">that these generations are not the generations of HuggingFace here. And I can't find the discrepancy,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=2436" target="_blank">00:40:36.640</a></span> | <span class="t">to be honest, and I didn't fully go through all these options, but probably there's something</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=2440" target="_blank">00:40:40.480</a></span> | <span class="t">else hiding in addition to the top P. So I'm not able to match it up. But just for correctness,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=2445" target="_blank">00:40:45.600</a></span> | <span class="t">down here below in the Jupyter Notebook, I'm using the HuggingFace model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=2451" target="_blank">00:40:51.120</a></span> | <span class="t">So this is the HuggingFace model here. I replicated the code, and if I do this and I run that,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=2458" target="_blank">00:40:58.160</a></span> | <span class="t">then I am getting the same results. So basically, the model internals are not wrong. It's just I'm</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=2465" target="_blank">00:41:05.520</a></span> | <span class="t">not 100% sure what the pipeline does in HuggingFace, and that's why we're not able to match</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=2470" target="_blank">00:41:10.320</a></span> | <span class="t">them up. But otherwise, the code is correct, and we've loaded all the tensors correctly. So we're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=2476" target="_blank">00:41:16.720</a></span> | <span class="t">initializing the model correctly, and everything here works. So long story short, we've ported all</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=2481" target="_blank">00:41:21.600</a></span> | <span class="t">the weights. We initialized the GPT-2. This is the exact opening at GPT-2, and it can generate</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=2487" target="_blank">00:41:27.360</a></span> | <span class="t">sequences, and they look sensible. And now here, of course, we're initializing with GPT-2 model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=2493" target="_blank">00:41:33.040</a></span> | <span class="t">weights. But now we want to initialize from scratch, from random numbers, and we want to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=2497" target="_blank">00:41:37.680</a></span> | <span class="t">actually train the model that will give us sequences as good as or better than these ones</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=2503" target="_blank">00:41:43.760</a></span> | <span class="t">in quality. And so that's what we turn to next. So it turns out that using the random model is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=2509" target="_blank">00:41:49.040</a></span> | <span class="t">actually fairly straightforward, because PyTorch already initializes our model randomly and by</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=2513" target="_blank">00:41:53.520</a></span> | <span class="t">default. So when we create the GPT model in the constructor, all of these layers and modules</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=2522" target="_blank">00:42:02.880</a></span> | <span class="t">have random initializers that are there by default. So when these linear layers get created and so on,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=2528" target="_blank">00:42:08.800</a></span> | <span class="t">there's default constructors, for example, using the Javier initialization that we saw in the past</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=2533" target="_blank">00:42:13.520</a></span> | <span class="t">to construct the weights of these layers. And so creating a random model instead of a GPT-2 model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=2539" target="_blank">00:42:19.920</a></span> | <span class="t">is actually fairly straightforward. And we would just come here, and instead we would create model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=2545" target="_blank">00:42:25.120</a></span> | <span class="t">equals GPT, and then we want to use the default config, GPT config. And the default config uses</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=2552" target="_blank">00:42:32.080</a></span> | <span class="t">the 124m parameters. So this is the random model initialization, and we can run it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=2563" target="_blank">00:42:43.120</a></span> | <span class="t">And we should be able to get results. Now, the results here, of course, are total garbage garble,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=2569" target="_blank">00:42:49.760</a></span> | <span class="t">and that's because it's a random model. And so we're just getting all these random token string</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=2573" target="_blank">00:42:53.680</a></span> | <span class="t">pieces chunked up totally at random. So that's what we have right now. Now, one more thing I</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=2579" target="_blank">00:42:59.360</a></span> | <span class="t">wanted to point out, by the way, is in case you do not have CUDA available, because you don't have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=2583" target="_blank">00:43:03.360</a></span> | <span class="t">a GPU, you can still follow along with what we're doing here to some extent. And probably not to the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=2590" target="_blank">00:43:10.320</a></span> | <span class="t">very end, because by the end, we're going to be using multiple GPUs and actually doing a serious</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=2594" target="_blank">00:43:14.400</a></span> | <span class="t">training run. But for now, you can actually follow along decently okay. So one thing that I like to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=2599" target="_blank">00:43:19.440</a></span> | <span class="t">do in PyTorch is I like to auto detect the device that is available to you. So in particular, you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=2604" target="_blank">00:43:24.640</a></span> | <span class="t">could do that like this. So here we are trying to detect the device to run on that has the highest</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=2611" target="_blank">00:43:31.680</a></span> | <span class="t">compute capability. You can think about it that way. So by default, we start with CPU, which of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=2616" target="_blank">00:43:36.560</a></span> | <span class="t">course is available everywhere, because every single computer will have a CPU. But then we can</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=2621" target="_blank">00:43:41.280</a></span> | <span class="t">try to detect, do you have a GPU? You still use a CUDA. And then if you don't have a CUDA, do you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=2627" target="_blank">00:43:47.040</a></span> | <span class="t">at least have MPS? MPS is the backend for Apple Silicon. So if you have a MacBook that is fairly</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=2632" target="_blank">00:43:52.720</a></span> | <span class="t">new, you probably have Apple Silicon on the inside. And then that has a GPU that is actually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=2636" target="_blank">00:43:56.960</a></span> | <span class="t">fairly capable, depending on which MacBook you have. And so you can use MPS, which will be</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=2641" target="_blank">00:44:01.600</a></span> | <span class="t">potentially faster than CPU. And so we can print the device here. Now once we have the device,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=2646" target="_blank">00:44:06.640</a></span> | <span class="t">we can actually use it in place of CUDA. So we just swap it in. And notice that here when we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=2654" target="_blank">00:44:14.400</a></span> | <span class="t">call model on x, if this x here is on CPU instead of GPU, then it will work fine because here in the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=2662" target="_blank">00:44:22.640</a></span> | <span class="t">forward, which is where PyTorch will come, when we create a pose, we are careful to use the device</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=2668" target="_blank">00:44:28.880</a></span> | <span class="t">of IDX to create this tensor as well. And so there won't be any mismatch where one tensor is on CPU,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=2674" target="_blank">00:44:34.880</a></span> | <span class="t">one is on GPU, and that you can't combine those. But here we are carefully initializing on the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=2680" target="_blank">00:44:40.960</a></span> | <span class="t">correct device as indicated by the input to this model. So this will auto detect device. For me,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=2688" target="_blank">00:44:48.080</a></span> | <span class="t">this will be, of course, GPU. So using device CUDA. But you can also run with, as I mentioned,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=2698" target="_blank">00:44:58.800</a></span> | <span class="t">another device. And it's not going to be too much slower. So if I override device here,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=2702" target="_blank">00:45:02.480</a></span> | <span class="t">if I override device equals CPU, then we'll still print CUDA, of course,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=2711" target="_blank">00:45:11.120</a></span> | <span class="t">but now we're actually using CPU. 1, 2, 3, 4, 5, 6. Okay, about six seconds. And actually,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=2721" target="_blank">00:45:21.280</a></span> | <span class="t">we're not using Torch compile and stuff like that, which will speed up everything a lot</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=2724" target="_blank">00:45:24.640</a></span> | <span class="t">faster as well. But you can follow along even on a CPU, I think, to a decent extent.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=2729" target="_blank">00:45:29.280</a></span> | <span class="t">So that's a note on that. Okay, so I do want to loop around eventually into what it means to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=2735" target="_blank">00:45:35.440</a></span> | <span class="t">have different devices in PyTorch and what it is exactly that PyTorch does in the background for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=2740" target="_blank">00:45:40.080</a></span> | <span class="t">you when you do something like module.to device, or where you take a Torch tensor and do a .to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=2746" target="_blank">00:45:46.240</a></span> | <span class="t">device, and what exactly happens and how that works. But for now, I'd like to get to training,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=2751" target="_blank">00:45:51.120</a></span> | <span class="t">and I'd like to start training the model. And for now, let's just say the device makes code go fast.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=2756" target="_blank">00:45:56.080</a></span> | <span class="t">And let's go into how we can actually train the model. So to train the model, we're going to need</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=2761" target="_blank">00:46:01.360</a></span> | <span class="t">some data set. And for me, the best debugging simplest data set that I like to use is the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=2766" target="_blank">00:46:06.000</a></span> | <span class="t">tiny Shakespeare data set. And it's available at this URL, so you can wget it, or you can just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=2771" target="_blank">00:46:11.760</a></span> | <span class="t">search tiny Shakespeare data set. And so I have in my file system is just lsinput.txt. So I already</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=2780" target="_blank">00:46:20.160</a></span> | <span class="t">downloaded it. And here, I'm reading the data set, getting the first 1000 characters and printing the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=2785" target="_blank">00:46:25.600</a></span> | <span class="t">first 100. Now remember that GPT-2 has roughly a compression ratio, the tokenizer has a compression</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=2792" target="_blank">00:46:32.800</a></span> | <span class="t">ratio of roughly three to one. So 1000 characters is roughly 300 tokens here that will come out of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=2798" target="_blank">00:46:38.480</a></span> | <span class="t">this in the slice that we're currently getting. So this is the first few characters. And if you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=2806" target="_blank">00:46:46.320</a></span> | <span class="t">want to get a few more statistics on this, we can do word count on input.txt. So we can see that this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=2812" target="_blank">00:46:52.160</a></span> | <span class="t">is 40,000 lines, about 200,000 words in this data set, and about 1 million bytes in this file.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=2820" target="_blank">00:47:00.320</a></span> | <span class="t">And knowing that this file is only ASCII characters, there's no crazy Unicode here,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=2823" target="_blank">00:47:03.840</a></span> | <span class="t">as far as I know. And so every ASCII character is encoded with one byte. And so this is the same</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=2829" target="_blank">00:47:09.360</a></span> | <span class="t">number, roughly a million characters inside this data set. So that's the data set size by default,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=2836" target="_blank">00:47:16.080</a></span> | <span class="t">very small and minimal data set for debugging. To get us off the ground, in order to tokenize</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=2841" target="_blank">00:47:21.040</a></span> | <span class="t">this data set, we're going to get tick token encoding for GPT-2, encode the data, the first</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=2849" target="_blank">00:47:29.040</a></span> | <span class="t">1000 characters, and then I'm only going to print the first 24 tokens. So these are the tokens as a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=2855" target="_blank">00:47:35.200</a></span> | <span class="t">list of integers. And if you can read GPT-2 tokens, you will see that 198 here, you'll recognize that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=2861" target="_blank">00:47:41.360</a></span> | <span class="t">as the slash in character. So that is a new line. And then here, for example, we have two new lines,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=2866" target="_blank">00:47:46.080</a></span> | <span class="t">so that's 198 twice here. So this is just a tokenization of the first 24 tokens. So what</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=2872" target="_blank">00:47:52.560</a></span> | <span class="t">we want to do now is we want to actually process these token sequences and feed them into a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=2877" target="_blank">00:47:57.760</a></span> | <span class="t">transformer. And in particular, we want them, we want to rearrange these tokens into this IDX</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=2884" target="_blank">00:48:04.960</a></span> | <span class="t">variable that we're going to be feeding into the transformer. So we don't want a single very long</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=2888" target="_blank">00:48:08.880</a></span> | <span class="t">one-dimensional sequence. We want an entire batch where each sequence is up to, is basically T</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=2896" target="_blank">00:48:16.080</a></span> | <span class="t">tokens, and T cannot be larger than the maximum sequence length. And then we have these T long</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=2903" target="_blank">00:48:23.680</a></span> | <span class="t">sequences of tokens, and we have B independent examples of sequences. So how can we create a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=2909" target="_blank">00:48:29.600</a></span> | <span class="t">B by T tensor that we can feed into the forward out of these one-dimensional sequences?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=2913" target="_blank">00:48:33.760</a></span> | <span class="t">So here's my favorite way to achieve this. So if we take Torch, and then we create a tensor object</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=2921" target="_blank">00:48:41.280</a></span> | <span class="t">out of this list of integers and just the first 24 tokens, my favorite way to do this is basically</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=2926" target="_blank">00:48:46.240</a></span> | <span class="t">you do a dot view of, for example, 4 by 6, which multiplied to 24. And so it's just a two-dimensional</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=2934" target="_blank">00:48:54.720</a></span> | <span class="t">rearrangement of these tokens. And you'll notice that when you view this one-dimensional sequence</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=2938" target="_blank">00:48:58.560</a></span> | <span class="t">as two-dimensional 4 by 6 here, the first six tokens up to here end up being the first row.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=2947" target="_blank">00:49:07.280</a></span> | <span class="t">The next six tokens here end up being the second row, and so on. And so basically, it's just going</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=2953" target="_blank">00:49:13.200</a></span> | <span class="t">to stack up every six tokens, in this case, as independent rows, and it creates a batch of tokens</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=2961" target="_blank">00:49:21.920</a></span> | <span class="t">in this case. And so for example, if we are token 25, in the transformer, when we feed this in and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=2968" target="_blank">00:49:28.160</a></span> | <span class="t">this becomes the IDX, this token is going to see these three tokens and is going to try to predict</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=2974" target="_blank">00:49:34.000</a></span> | <span class="t">that 198 comes next. So in this way, we are able to create this two-dimensional batch. That's quite</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=2981" target="_blank">00:49:41.440</a></span> | <span class="t">nice. Now, in terms of the label that we're going to need for the target to calculate the loss</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=2986" target="_blank">00:49:46.720</a></span> | <span class="t">function, how do we get that? Well, we could write some code inside the forward pass because we know</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=2991" target="_blank">00:49:51.760</a></span> | <span class="t">that the next token in a sequence, which is the label, is just to the right of us. But you'll</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=2996" target="_blank">00:49:56.960</a></span> | <span class="t">notice that actually, for this token at the very end, 13, we don't actually have the next correct</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=3002" target="_blank">00:50:02.960</a></span> | <span class="t">token because we didn't load it. So we actually didn't get enough information here. So I'll show</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=3009" target="_blank">00:50:09.680</a></span> | <span class="t">you my favorite way of basically getting these batches. And I like to personally have not just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=3015" target="_blank">00:50:15.200</a></span> | <span class="t">the input to the transformer, which I like to call X, but I also like to create the labels tensor,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=3021" target="_blank">00:50:21.760</a></span> | <span class="t">which is of the exact same size as X but contains the targets at every single position. And so</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=3027" target="_blank">00:50:27.360</a></span> | <span class="t">here's the way that I like to do that. I like to make sure that I fetch +1 token because we need</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=3032" target="_blank">00:50:32.720</a></span> | <span class="t">the ground truth for the very last token, for 13. And then when we're creating the input, we take</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=3039" target="_blank">00:50:39.920</a></span> | <span class="t">everything up to the last token, not including, and view it as 4 by 6. And when we're creating</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=3045" target="_blank">00:50:45.360</a></span> | <span class="t">targets, we do the buffer, but starting at index 1, not index 0. So we're skipping the first element</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=3052" target="_blank">00:50:52.720</a></span> | <span class="t">and we view it in the exact same size. And then when I print this,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=3058" target="_blank">00:50:58.000</a></span> | <span class="t">here's what happens, where we see that basically as an example for this token 25,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=3062" target="_blank">00:51:02.320</a></span> | <span class="t">its target was 198. And that's now just stored at the exact same position in the target tensor,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=3068" target="_blank">00:51:08.320</a></span> | <span class="t">which is 198. And also this last token 13 now has its label, which is 198. And that's just because</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=3076" target="_blank">00:51:16.320</a></span> | <span class="t">we loaded this +1 here. So basically, this is the way I like to do it. You take long sequences,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=3083" target="_blank">00:51:23.040</a></span> | <span class="t">you view them in two-dimensional terms so that you get batches of time. And then we make sure</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=3089" target="_blank">00:51:29.120</a></span> | <span class="t">to load one additional token. So we basically load a buffer of tokens of B times T +1. And then</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=3096" target="_blank">00:51:36.080</a></span> | <span class="t">we sort of offset things and view them. And then we have two tensors. One of them is the input to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=3100" target="_blank">00:51:40.800</a></span> | <span class="t">the transformer, and the other exactly is the labels. And so let's now reorganize this code</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=3107" target="_blank">00:51:47.120</a></span> | <span class="t">and create a very simple data loader object that tries to basically load these tokens and feed them</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=3115" target="_blank">00:51:55.040</a></span> | <span class="t">to the transformer and calculate the loss. Okay, so I reshuffled the code here accordingly.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=3119" target="_blank">00:51:59.600</a></span> | <span class="t">So as you can see here, I'm temporarily overriding to run on CPU. And importing the token,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=3126" target="_blank">00:52:06.400</a></span> | <span class="t">and all of this should look familiar. We're loading 1,000 characters. I'm setting bt to just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=3130" target="_blank">00:52:10.720</a></span> | <span class="t">be 4 and 32 right now, just because we're debugging. We just want to have a single batch that's very</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=3135" target="_blank">00:52:15.680</a></span> | <span class="t">small. And all of this should now look familiar and follows what we did on the right. And then</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=3141" target="_blank">00:52:21.040</a></span> | <span class="t">here we create the model and get the logits. And so here, as you see, I already ran this. It only</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=3149" target="_blank">00:52:29.280</a></span> | <span class="t">runs in a few seconds. But because we have a batch of 4 by 32, our logits are now of size 4 by 32 by</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=3157" target="_blank">00:52:37.440</a></span> | <span class="t">50,257. So those are the logits for what comes next at every position. And now we have the labels,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=3164" target="_blank">00:52:44.480</a></span> | <span class="t">which are stored in Y. So now is the time to calculate the loss, and then do the backward</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=3168" target="_blank">00:52:48.960</a></span> | <span class="t">pass, and then do the optimization. So let's first calculate the loss. Okay, so to calculate the loss,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=3175" target="_blank">00:52:55.040</a></span> | <span class="t">we're going to adjust the forward function of this NN module in the model. And in particular,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=3179" target="_blank">00:52:59.840</a></span> | <span class="t">we're not just going to be returning logits, but also we're going to return the loss.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=3183" target="_blank">00:53:03.040</a></span> | <span class="t">And we're going to not just pass in the input indices, but also the targets in Y. And now we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=3190" target="_blank">00:53:10.640</a></span> | <span class="t">will print not logits.shape anymore, we're actually going to print the loss function,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=3195" target="_blank">00:53:15.600</a></span> | <span class="t">and then sys.exit of zero so that we skip some of the sampling logic.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=3199" target="_blank">00:53:19.200</a></span> | <span class="t">So now let's swing up to the forward function, which gets called there, because now we also</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=3205" target="_blank">00:53:25.920</a></span> | <span class="t">have these optional targets. And when we get the targets, we can also calculate the loss. And</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=3212" target="_blank">00:53:32.800</a></span> | <span class="t">remember that we want to basically return logits.loss, and loss by default is none. But</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=3218" target="_blank">00:53:38.720</a></span> | <span class="t">let's put this here. If targets is not none, then we want to calculate the loss. And Copilot is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=3230" target="_blank">00:53:50.320</a></span> | <span class="t">already getting excited here and calculating the what looks to be correct loss. It is using the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=3235" target="_blank">00:53:55.600</a></span> | <span class="t">cross-entropy loss as is documented here. So this is a function in PyTorch under the functional.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=3243" target="_blank">00:54:03.440</a></span> | <span class="t">Now, what is actually happening here, because it looks a little bit scary,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=3247" target="_blank">00:54:07.280</a></span> | <span class="t">basically the FNet cross-entropy does not like multi-dimensional inputs. It can't take a b by t</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=3253" target="_blank">00:54:13.280</a></span> | <span class="t">by vocab size. So what's happening here is that we are flattening out this three-dimensional tensor</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=3258" target="_blank">00:54:18.720</a></span> | <span class="t">into just two dimensions. The first dimension is going to be calculated automatically, and it's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=3263" target="_blank">00:54:23.120</a></span> | <span class="t">going to be b times t. And then the last dimension is vocab size. So basically, this is flattening</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=3269" target="_blank">00:54:29.760</a></span> | <span class="t">out this three-dimensional tensor of logits to just be two-dimensional, b times t, all individual</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=3275" target="_blank">00:54:35.600</a></span> | <span class="t">examples, and vocab size in terms of the length of each row. And then it's also flattening out</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=3282" target="_blank">00:54:42.640</a></span> | <span class="t">the targets, which are also two-dimensional at this stage, but we're going to just flatten them</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=3287" target="_blank">00:54:47.120</a></span> | <span class="t">out so they're just a single tensor of b times t. And this can then pass into cross-entropy to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=3292" target="_blank">00:54:52.080</a></span> | <span class="t">calculate a loss, which we return. So this should basically, at this point, run, because it's not</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=3298" target="_blank">00:54:58.000</a></span> | <span class="t">too complicated. So let's run it, and let's see if we should be printing the loss.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=3304" target="_blank">00:55:04.320</a></span> | <span class="t">And here we see that we printed 11, roughly. And notice that this is the tensor of a single</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=3319" target="_blank">00:55:19.280</a></span> | <span class="t">element, which is this number 11. Now, we also want to be able to calculate a reasonable</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=3323" target="_blank">00:55:23.840</a></span> | <span class="t">kind of starting point for a randomly initialized network. So we covered this in previous videos,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=3329" target="_blank">00:55:29.040</a></span> | <span class="t">but our vocabulary size is 50,257. At initialization of the network, you would hope</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=3335" target="_blank">00:55:35.360</a></span> | <span class="t">that every vocab element is getting roughly a uniform probability, so that we're not favoring,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=3342" target="_blank">00:55:42.960</a></span> | <span class="t">at initialization, any token way too much. We're not confidently wrong at initialization. So we're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=3349" target="_blank">00:55:49.120</a></span> | <span class="t">hoping is that the probability of any arbitrary token is roughly 1/50,257. And now we can sanity</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=3356" target="_blank">00:55:56.160</a></span> | <span class="t">check the loss, because remember that the cross-entropy loss is just basically the negative</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=3360" target="_blank">00:56:00.320</a></span> | <span class="t">log likelihood. So if we now take this probability, and we take it through the natural logarithm,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=3367" target="_blank">00:56:07.120</a></span> | <span class="t">and then we do the negative, that is the loss we expect at initialization, and we covered this in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=3373" target="_blank">00:56:13.120</a></span> | <span class="t">previous videos. So I would expect something around 10.82, and we're seeing something around</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=3378" target="_blank">00:56:18.080</a></span> | <span class="t">11. So it's not way off. This is roughly the probability I expect at initialization.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=3382" target="_blank">00:56:22.640</a></span> | <span class="t">So that tells me that at initialization, our probability distribution is roughly diffuse,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=3387" target="_blank">00:56:27.520</a></span> | <span class="t">it's a good starting point, and we can now perform the optimization and tell the network which</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=3393" target="_blank">00:56:33.120</a></span> | <span class="t">elements should follow correctly in what order. So at this point, we can do a loss step backward,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=3399" target="_blank">00:56:39.120</a></span> | <span class="t">calculate the gradients, and do an optimization. So let's get to that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=3402" target="_blank">00:56:42.720</a></span> | <span class="t">Okay, so let's do the optimization now. So here we have the loss, this is how we get the loss.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=3411" target="_blank">00:56:51.120</a></span> | <span class="t">But now basically we want a little for loop here. So for i in range, let's do 50 steps or</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=3416" target="_blank">00:56:56.560</a></span> | <span class="t">something like that. Let's create an optimizer object in PyTorch. And so here we are using the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=3424" target="_blank">00:57:04.320</a></span> | <span class="t">atom optimizer, which is an alternative to the stochastic gradient descent optimizer, SGD,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=3430" target="_blank">00:57:10.320</a></span> | <span class="t">that we were using. So SGD is a lot simpler, atom is a bit more involved. And I actually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=3434" target="_blank">00:57:14.320</a></span> | <span class="t">specifically like the atom w variation, because in my opinion, it kind of just like fixes a bug.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=3439" target="_blank">00:57:19.920</a></span> | <span class="t">So atom w is a bug fix of atom, is what I would say. When we go to the documentation for atom w,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=3446" target="_blank">00:57:26.800</a></span> | <span class="t">oh my gosh, we see that it takes a bunch of hyperparameters, and it's a little bit more</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=3454" target="_blank">00:57:34.080</a></span> | <span class="t">complicated than the SGD we were looking at before. Because in addition to basically updating</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=3459" target="_blank">00:57:39.120</a></span> | <span class="t">the parameters with the gradient scaled by the learning rate, it keeps these buffers around,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=3464" target="_blank">00:57:44.000</a></span> | <span class="t">and it keeps two buffers, the M and the V, which it calls the first and the second moment.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=3469" target="_blank">00:57:49.280</a></span> | <span class="t">So something that looks a bit like momentum is something that looks a bit like RMS prop,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=3473" target="_blank">00:57:53.120</a></span> | <span class="t">if you're familiar with it. But you don't have to be, it's just kind of like a normalization</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=3477" target="_blank">00:57:57.120</a></span> | <span class="t">that happens on each gradient element individually, and speeds up the optimization,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=3481" target="_blank">00:58:01.600</a></span> | <span class="t">especially for language models. But I'm not going to go into the detail right here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=3485" target="_blank">00:58:05.360</a></span> | <span class="t">We're going to treat this a bit of a black box, and it just optimizes the objective faster than</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=3492" target="_blank">00:58:12.000</a></span> | <span class="t">SGD, which is what we've seen in the previous lectures. So let's use it as a black box in our</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=3496" target="_blank">00:58:16.560</a></span> | <span class="t">case. Create the optimizer object, and then go through the optimization.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=3503" target="_blank">00:58:23.680</a></span> | <span class="t">The first thing to always make sure, the copilot did not forget to zero the gradients.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=3513" target="_blank">00:58:33.440</a></span> | <span class="t">So always remember that you have to start with a zero gradient. Then when you get your loss,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=3518" target="_blank">00:58:38.880</a></span> | <span class="t">and you do a dot backward, dot backward adds to gradients. So it deposits gradients. It always</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=3524" target="_blank">00:58:44.800</a></span> | <span class="t">does a plus equals on whatever the gradients are, which is why you must set them to zero.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=3528" target="_blank">00:58:48.640</a></span> | <span class="t">So this accumulates the gradient from this loss, and then we call the step function on the optimizer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=3535" target="_blank">00:58:55.280</a></span> | <span class="t">to update the parameters, and to decrease the loss. Then we print the step, and the loss</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=3543" target="_blank">00:59:03.760</a></span> | <span class="t">dot item is used here, because loss is a tensor with a single element. Dot item will actually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=3549" target="_blank">00:59:09.680</a></span> | <span class="t">convert that to a single float, and this float will live on the CPU. So this gets to some of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=3556" target="_blank">00:59:16.880</a></span> | <span class="t">the internals, again, of the devices, but loss is a tensor with a single element, and it lives on</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=3562" target="_blank">00:59:22.800</a></span> | <span class="t">GPU for me, because I'm using GPUs. When you call dot item, PyTorch behind the scenes will take that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=3569" target="_blank">00:59:29.120</a></span> | <span class="t">one-dimensional tensor, ship it back to the CPU memory, and convert it into a float that we can</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=3574" target="_blank">00:59:34.240</a></span> | <span class="t">just print. So this is the optimization, and this should probably just work. Let's see what happens.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=3583" target="_blank">00:59:43.680</a></span> | <span class="t">Actually, sorry. Instead of using CPU override, let me delete that so this is a bit faster for me,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=3591" target="_blank">00:59:51.600</a></span> | <span class="t">and it runs on CUDA. Oh, expected all tensors to be on the same device, but found at least two</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=3602" target="_blank">01:00:02.080</a></span> | <span class="t">devices, CUDA0 and CPU. So CUDA0 is the 0th GPU, because I actually have eight GPUs on this box.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=3609" target="_blank">01:00:09.280</a></span> | <span class="t">So the 0th GPU on my box, and CPU. And model, we have moved to device, but when I was writing this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=3617" target="_blank">01:00:17.440</a></span> | <span class="t">code, I actually introduced a bug, because buff, we never moved to device. And you have to be</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=3622" target="_blank">01:00:22.640</a></span> | <span class="t">careful, because you can't just do buff dot two of device. It's not stateful. It doesn't convert</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=3630" target="_blank">01:00:30.240</a></span> | <span class="t">it to be a device. It instead returns a pointer to a new memory, which is on the device. So you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=3636" target="_blank">01:00:36.960</a></span> | <span class="t">see how we can just do model dot two of device, but it does not apply to tensors. You have to do</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=3641" target="_blank">01:00:41.360</a></span> | <span class="t">buff equals buff dot two device, and then this should work. Okay. So what do we expect to see?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=3651" target="_blank">01:00:51.920</a></span> | <span class="t">We expect to see a reasonable loss in the beginning, and then we continue to optimize</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=3655" target="_blank">01:00:55.600</a></span> | <span class="t">just a single batch. And so we want to see that we can overfit this single batch. We can crush</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=3660" target="_blank">01:01:00.720</a></span> | <span class="t">this little batch, and we can perfectly predict the indices on just this little batch. And in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=3665" target="_blank">01:01:05.520</a></span> | <span class="t">these, that is roughly what we're seeing here. So we started off at roughly 10.82, 11 in this case,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=3673" target="_blank">01:01:13.440</a></span> | <span class="t">and then as we continue optimizing on this single batch without loading new examples,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=3677" target="_blank">01:01:17.040</a></span> | <span class="t">we are making sure that we can overfit a single batch, and we are getting to very,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=3680" target="_blank">01:01:20.800</a></span> | <span class="t">very low loss. So the transformer is memorizing this single individual batch.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=3685" target="_blank">01:01:25.280</a></span> | <span class="t">And one more thing I didn't mention is the learning rate here is 3E negative 4,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=3690" target="_blank">01:01:30.240</a></span> | <span class="t">which is a pretty good default for most optimizations that you want to run at a very</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=3695" target="_blank">01:01:35.360</a></span> | <span class="t">early debugging stage. So this is our simple inner loop, and we are overfitting a single batch,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=3702" target="_blank">01:01:42.560</a></span> | <span class="t">and this looks good. So now what comes next is we don't just want to overfit a single batch,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=3707" target="_blank">01:01:47.200</a></span> | <span class="t">we actually want to do an optimization. So we actually need to iterate these XY batches</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=3712" target="_blank">01:01:52.000</a></span> | <span class="t">and create a little data loader that makes sure that we're always getting a fresh batch,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=3716" target="_blank">01:01:56.560</a></span> | <span class="t">and that we're actually optimizing a reasonable objective. So let's do that next.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=3720" target="_blank">01:02:00.240</a></span> | <span class="t">Okay, so this is what I came up with, and I wrote a little data loader light.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=3723" target="_blank">01:02:03.360</a></span> | <span class="t">So what this data loader does is we're importing the token up here,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=3728" target="_blank">01:02:08.320</a></span> | <span class="t">reading the entire text file from this single input.txt, tokenizing it, and then we're just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=3734" target="_blank">01:02:14.720</a></span> | <span class="t">printing the number of tokens in total, and the number of batches in a single epoch of iterating</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=3740" target="_blank">01:02:20.800</a></span> | <span class="t">over this dataset. So how many unique batches do we output before we loop back around at the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=3745" target="_blank">01:02:25.840</a></span> | <span class="t">beginning of the document and start reading it again? So we start off at position 0, and then</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=3751" target="_blank">01:02:31.600</a></span> | <span class="t">we simply walk the document in batches of B times T. So we take chunks of B times T, and then always</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=3757" target="_blank">01:02:37.920</a></span> | <span class="t">advance by B times T. And it's important to note that we're always advancing our position by exactly</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=3764" target="_blank">01:02:44.800</a></span> | <span class="t">B times T, but when we're fetching the tokens, we're actually fetching from current position</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=3769" target="_blank">01:02:49.840</a></span> | <span class="t">to B times T plus 1. And we need that plus 1 because remember, we need the target token for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=3776" target="_blank">01:02:56.960</a></span> | <span class="t">the last token in the current batch. And so that way we can do the XY exactly as we did it before.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=3784" target="_blank">01:03:04.560</a></span> | <span class="t">And if we are to run out of data, we'll just loop back around to 0. So this is one way to write a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=3792" target="_blank">01:03:12.640</a></span> | <span class="t">very, very simple data loader that simply just goes through the file in chunks. And it's good</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=3798" target="_blank">01:03:18.960</a></span> | <span class="t">enough for us for current purposes. And we're going to complexify it later. And now we'd like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=3804" target="_blank">01:03:24.800</a></span> | <span class="t">to come back around here, and we'd like to actually use our data loader. So the import</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=3808" target="_blank">01:03:28.800</a></span> | <span class="t">tick token has moved up. And actually, all of this is now useless. So instead, we just want a train</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=3814" target="_blank">01:03:34.960</a></span> | <span class="t">loader for the training data. And we want to use the same hyperparameters for 4. So batch size was</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=3821" target="_blank">01:03:41.600</a></span> | <span class="t">4 and time was 32. And then here, we need to get the XY for the current batch. So let's see if</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=3829" target="_blank">01:03:49.120</a></span> | <span class="t">Copilot gets it, because this is simple enough. So we call the next batch. And then we make sure</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=3836" target="_blank">01:03:56.080</a></span> | <span class="t">that we have to move our tensors from CPU to the device. So here, when I converted the tokens,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=3845" target="_blank">01:04:05.040</a></span> | <span class="t">notice that I didn't actually move these tokens to the GPU. I left them on the CPU, which is default.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=3851" target="_blank">01:04:11.600</a></span> | <span class="t">And that's just because I'm trying not to waste too much memory on the GPU. In this case,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=3856" target="_blank">01:04:16.320</a></span> | <span class="t">this is a tiny data set that it would fit. But it's fine to just ship it to GPU right now for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=3862" target="_blank">01:04:22.320</a></span> | <span class="t">our purposes right now. So we get the next batch. We keep the data loader simple CPU class. And then</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=3868" target="_blank">01:04:28.880</a></span> | <span class="t">here, we actually ship it to the GPU and do all the computation. And let's see if this runs.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=3875" target="_blank">01:04:35.920</a></span> | <span class="t">So Python train GPT 2.py. And what do we expect to see before this actually happens?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=3882" target="_blank">01:04:42.240</a></span> | <span class="t">What we expect to see is now we're actually getting the next batch. So we expect to not</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=3886" target="_blank">01:04:46.560</a></span> | <span class="t">overfit a single batch. And so I expect our loss to come down, but not too much. And that's because</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=3894" target="_blank">01:04:54.240</a></span> | <span class="t">I still expect it to come down because in the 50,257 tokens, many of those tokens never occur</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=3900" target="_blank">01:05:00.480</a></span> | <span class="t">in our data set. So there are some very easy gains to be made here in the optimization by,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=3905" target="_blank">01:05:05.280</a></span> | <span class="t">for example, taking the biases of all the logits that never occur and driving them to negative</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=3909" target="_blank">01:05:09.920</a></span> | <span class="t">infinity. And that would basically just, it's just that all of these crazy Unicodes or different</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=3914" target="_blank">01:05:14.800</a></span> | <span class="t">languages, those tokens never occur. So their probability should be very low. And so the gains</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=3919" target="_blank">01:05:19.360</a></span> | <span class="t">that we should be seeing are along the lines of basically deleting the usage of tokens that never</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=3924" target="_blank">01:05:24.880</a></span> | <span class="t">occur. That's probably most of the loss gain that we're going to see at this scale right now.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=3929" target="_blank">01:05:29.920</a></span> | <span class="t">But we shouldn't come to a zero because we are only doing 50 iterations. And I don't think that's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=3937" target="_blank">01:05:37.360</a></span> | <span class="t">enough to do an epoch right now. So let's see what we got. We have 338,000 tokens, which makes sense</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=3946" target="_blank">01:05:46.320</a></span> | <span class="t">with our three to one compression ratio, because there are 1 million characters. So one epoch with</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=3952" target="_blank">01:05:52.640</a></span> | <span class="t">the current setting of B and T will take 2,600 batches. And we're only doing 50 batches of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=3958" target="_blank">01:05:58.880</a></span> | <span class="t">optimization in here. So we start off in a familiar territory as expected, and then we seem</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=3965" target="_blank">01:06:05.600</a></span> | <span class="t">to come down to about 6.6. So basically, things seem to be working okay right now with respect</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=3972" target="_blank">01:06:12.160</a></span> | <span class="t">to our expectations. So that's good. Okay, next, I want to actually fix a bug that we have in our</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=3977" target="_blank">01:06:17.520</a></span> | <span class="t">code. It's not a major bug, but it is a bug with respect to how GPT-2 training should happen.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=3986" target="_blank">01:06:26.240</a></span> | <span class="t">So the bug is the following. We were not being careful enough when we were loading the weights</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=3990" target="_blank">01:06:30.480</a></span> | <span class="t">from Hug and Face, and we actually missed a little detail. So if we come here,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=3994" target="_blank">01:06:34.400</a></span> | <span class="t">notice that the shape of these two tensors is the same. So this one here is the token embedding at</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=4003" target="_blank">01:06:43.520</a></span> | <span class="t">the bottom of the transformer. And this one here is the language modeling head at the top of the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=4010" target="_blank">01:06:50.560</a></span> | <span class="t">transformer. And both of these are basically two-dimensional tensors, and their shape is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=4016" target="_blank">01:06:56.080</a></span> | <span class="t">identical. So here, the first one is the output embedding, the token embedding, and the second</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=4022" target="_blank">01:07:02.240</a></span> | <span class="t">one is this linear layer at the very top, the classifier layer. Both of them are of shape</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=4027" target="_blank">01:07:07.520</a></span> | <span class="t">50,257 by 768. This one here is giving us our token embeddings at the bottom, and this one</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=4036" target="_blank">01:07:16.080</a></span> | <span class="t">here is taking the 768 channels of the transformer and trying to upscale that to 50,257 to get the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=4043" target="_blank">01:07:23.680</a></span> | <span class="t">logis for the next token. So they're both the same shape, but more than that, actually, if you look</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=4049" target="_blank">01:07:29.520</a></span> | <span class="t">at comparing their elements, in PyTorch, this is an element-wise equality. So then we use .all,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=4057" target="_blank">01:07:37.360</a></span> | <span class="t">and we see that every single element is identical. And more than that, we see that if we actually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=4062" target="_blank">01:07:42.880</a></span> | <span class="t">look at the data pointer, this is a way in PyTorch to get the actual pointer to the data</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=4069" target="_blank">01:07:49.280</a></span> | <span class="t">and the storage, we see that actually the pointer is identical. So not only are these two separate</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=4074" target="_blank">01:07:54.480</a></span> | <span class="t">tensors that happen to have the same shape and elements, they're actually pointing to the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=4078" target="_blank">01:07:58.480</a></span> | <span class="t">identical tensor. So what's happening here is that this is a common wait-time scheme</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=4084" target="_blank">01:08:04.480</a></span> | <span class="t">that actually comes from the original "Attention is all you need" paper,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=4091" target="_blank">01:08:11.360</a></span> | <span class="t">and actually even the reference before it. So if we come here...</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=4095" target="_blank">01:08:15.040</a></span> | <span class="t">Embeddings in Softmax in the "Attention is all you need" paper, they mention that in our model,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=4105" target="_blank">01:08:25.920</a></span> | <span class="t">we shared the same weight matrix between the two embedding layers and the pre-Softmax linear</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=4110" target="_blank">01:08:30.720</a></span> | <span class="t">transformation similar to 30. So this is an awkward way to phrase that these two are shared</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=4117" target="_blank">01:08:37.520</a></span> | <span class="t">and they're tied and they're the same matrix. And the 30 reference is this paper. So this came out</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=4124" target="_blank">01:08:44.480</a></span> | <span class="t">in 2017. And you can read the full paper, but basically it argues for this wait-time scheme.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=4130" target="_blank">01:08:50.400</a></span> | <span class="t">And I think intuitively the idea for why you might want to do this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=4134" target="_blank">01:08:54.880</a></span> | <span class="t">comes from this paragraph here. And basically, you can observe that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=4143" target="_blank">01:09:03.280</a></span> | <span class="t">you actually want these two matrices to behave similar in the following sense. If two tokens</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=4150" target="_blank">01:09:10.080</a></span> | <span class="t">are very similar semantically, like maybe one of them is all lowercase and the other one is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=4154" target="_blank">01:09:14.560</a></span> | <span class="t">all uppercase, or it's the same token in a different language or something like that,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=4158" target="_blank">01:09:18.240</a></span> | <span class="t">if you have similarity between two tokens, presumably you would expect that they are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=4162" target="_blank">01:09:22.160</a></span> | <span class="t">nearby in the token embedding space. But in the exact same way, you'd expect that if you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=4167" target="_blank">01:09:27.520</a></span> | <span class="t">have two tokens that are similar semantically, you'd expect them to get the same probabilities</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=4173" target="_blank">01:09:33.120</a></span> | <span class="t">at the output of a transformer because they are semantically similar.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=4176" target="_blank">01:09:36.080</a></span> | <span class="t">And so both positions in the transformer at the very bottom and at the top have this property</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=4183" target="_blank">01:09:43.680</a></span> | <span class="t">that similar tokens should have similar embeddings or similar weights. And so this is what motivates</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=4190" target="_blank">01:09:50.400</a></span> | <span class="t">their exploration here. And they kind of, you know, I don't want to go through the entire paper</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=4194" target="_blank">01:09:54.400</a></span> | <span class="t">and you can go through it, but this is what they observe. They also observe that if you look at the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=4200" target="_blank">01:10:00.240</a></span> | <span class="t">output embeddings, they also behave like word embeddings. If you just kind of try to use those</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=4206" target="_blank">01:10:06.880</a></span> | <span class="t">weights as word embeddings. So they kind of observe this similarity, they try to tie them,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=4212" target="_blank">01:10:12.800</a></span> | <span class="t">and they observe that they can get much better performance in that way. And so this was adopted</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=4218" target="_blank">01:10:18.160</a></span> | <span class="t">in the attention is only paper, and then it was used again in GPT-2 as well. So I couldn't find</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=4225" target="_blank">01:10:25.760</a></span> | <span class="t">it in the transformers implementation. I'm not sure where they tie those embeddings,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=4230" target="_blank">01:10:30.080</a></span> | <span class="t">but I can find it in the original GPT-2 code introduced by OpenAI. So this is OpenAI GPT-2</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=4237" target="_blank">01:10:37.840</a></span> | <span class="t">source model. And here where they are forwarding this model, and this is in TensorFlow, but</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=4242" target="_blank">01:10:42.880</a></span> | <span class="t">that's okay. We see that they get the WTE token embeddings. And then here is the encoder of the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=4250" target="_blank">01:10:50.480</a></span> | <span class="t">token embeddings and the position. And then here at the bottom, they use the WTE again to do the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=4257" target="_blank">01:10:57.040</a></span> | <span class="t">logits. So when they get the logits, it's a matmul of this output from the transformer and the WTE</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=4263" target="_blank">01:11:03.920</a></span> | <span class="t">tensor is reused. And so the WTE tensor basically is used twice on the bottom of the transformer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=4270" target="_blank">01:11:10.880</a></span> | <span class="t">and on the top of the transformer. And in the backward pass, we'll get gradients contributions</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=4276" target="_blank">01:11:16.640</a></span> | <span class="t">from both branches, right? And these gradients will add up on the WTE tensor. So we'll get a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=4283" target="_blank">01:11:23.760</a></span> | <span class="t">contribution from the classifier layer. And then at the very end of the transformer, we'll get a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=4287" target="_blank">01:11:27.760</a></span> | <span class="t">contribution at the bottom of it, flowing again into the WTE tensor. So we are currently not</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=4296" target="_blank">01:11:36.960</a></span> | <span class="t">sharing WTE in our code, but we want to do that. So weight sharing scheme. And one way to do this,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=4308" target="_blank">01:11:48.720</a></span> | <span class="t">let's see if Copilot gets it. Oh, it does. Okay. So this is one way to do it. Basically,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=4316" target="_blank">01:11:56.720</a></span> | <span class="t">relatively straightforward. What we're doing here is we're taking the WTE.weight and we're simply</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=4323" target="_blank">01:12:03.920</a></span> | <span class="t">redirecting it to point to the LM head. So this basically copies the data pointer,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=4332" target="_blank">01:12:12.240</a></span> | <span class="t">right? It copies the reference. And now the WTE.weight becomes orphaned, the old value of it,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=4338" target="_blank">01:12:18.800</a></span> | <span class="t">and PyTorch will clean it up. Python will clean it up. And so we are only left with a single</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=4345" target="_blank">01:12:25.440</a></span> | <span class="t">tensor, and it's going to be used twice in the forward pass. And this is, to my knowledge,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=4352" target="_blank">01:12:32.720</a></span> | <span class="t">all that's required. So we should be able to use this, and this should probably train.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=4357" target="_blank">01:12:37.440</a></span> | <span class="t">We're just going to basically be using this exact same tensor twice. And we weren't being careful</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=4365" target="_blank">01:12:45.920</a></span> | <span class="t">with tracking the likelihoods, but according to the paper and according to the results,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=4370" target="_blank">01:12:50.240</a></span> | <span class="t">you'd actually expect slightly better results doing this. And in addition to that, one other</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=4374" target="_blank">01:12:54.480</a></span> | <span class="t">reason that this is very, very nice for us is that this is a ton of parameters, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=4379" target="_blank">01:12:59.600</a></span> | <span class="t">What is the size of here? It's 768 times 50,257. So this is 40 million parameters.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=4387" target="_blank">01:13:07.200</a></span> | <span class="t">And this is a 124 million parameter model. So 40 divide 124. So this is like 30% of the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=4394" target="_blank">01:13:14.000</a></span> | <span class="t">parameters are being saved using this weight tying scheme. And so this might be one of the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=4399" target="_blank">01:13:19.440</a></span> | <span class="t">reasons that this is working slightly better. If you're not training the model long enough,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=4403" target="_blank">01:13:23.120</a></span> | <span class="t">because of the weight tying, you don't have to train as many parameters. And so you become more</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=4407" target="_blank">01:13:27.760</a></span> | <span class="t">efficient in terms of the training process, because you have fewer parameters and you're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=4413" target="_blank">01:13:33.200</a></span> | <span class="t">putting in this inductive bias that these two embeddings should share similarities between</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=4418" target="_blank">01:13:38.560</a></span> | <span class="t">tokens. So this is the weight tying scheme, and we've saved a ton of parameters. And we expect</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=4424" target="_blank">01:13:44.400</a></span> | <span class="t">our model to work slightly better because of this scheme. Okay, next, I would like us to be a bit</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=4428" target="_blank">01:13:48.480</a></span> | <span class="t">more careful with the initialization and to try to follow the way GPT-2 initialized their model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=4433" target="_blank">01:13:53.680</a></span> | <span class="t">Now, unfortunately, the GPT-2 paper and the GPT-3 paper are not very explicit about</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=4438" target="_blank">01:13:58.640</a></span> | <span class="t">initialization. So we kind of have to read between the lines. And instead of going to the paper,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=4443" target="_blank">01:14:03.280</a></span> | <span class="t">which is quite vague, there's a bit of information in the code that OpenAI released. So when we go</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=4449" target="_blank">01:14:09.040</a></span> | <span class="t">to the model.py, we see that when they initialize their weights, they are using the standard</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=4454" target="_blank">01:14:14.560</a></span> | <span class="t">deviation of 0.02. And that's how they, so this is a normal distribution for the weights,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=4461" target="_blank">01:14:21.600</a></span> | <span class="t">and the standard deviation is 0.02. For the bias, they initialize that with zero.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=4466" target="_blank">01:14:26.560</a></span> | <span class="t">And then when we scroll down here, why is this not scrolling? The token embeddings are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=4475" target="_blank">01:14:35.920</a></span> | <span class="t">initialized at 0.02, and position embeddings at 0.01 for some reason. So those are the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=4482" target="_blank">01:14:42.320</a></span> | <span class="t">initializations, and we'd like to mirror that in GPT-2 in our module here. So here's a snippet of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=4488" target="_blank">01:14:48.720</a></span> | <span class="t">code that I sort of came up with very quickly. So what's happening here is at the end of our</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=4496" target="_blank">01:14:56.400</a></span> | <span class="t">initializer for the GPT module, we're calling the apply function of NNModule, and that iterates all</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=4501" target="_blank">01:15:01.920</a></span> | <span class="t">the sub-modules of this module, and applies init_weights function on them. And so what's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=4509" target="_blank">01:15:09.440</a></span> | <span class="t">happening here is that we're iterating all the modules here, and if they are an NN.linear module,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=4516" target="_blank">01:15:16.560</a></span> | <span class="t">then we're going to make sure to initialize the weight using a normal with a standard deviation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=4520" target="_blank">01:15:20.640</a></span> | <span class="t">of 0.02. If there's a bias in this layer, we will make sure to initialize that to zero. Note that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=4527" target="_blank">01:15:27.200</a></span> | <span class="t">zero initialization for the bias is not actually the PyTorch default.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=4530" target="_blank">01:15:30.160</a></span> | <span class="t">By default, the bias here is initialized with a uniform, so that's interesting. So we make sure</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=4537" target="_blank">01:15:37.520</a></span> | <span class="t">to use zero. And for the embedding, we're just going to use 0.02 and keep it the same. So we're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=4544" target="_blank">01:15:44.080</a></span> | <span class="t">not going to change it to 0.01 for positional, because it's about the same. And then if you look</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=4548" target="_blank">01:15:48.960</a></span> | <span class="t">through our model, the only other layer that requires initialization, and that has parameters,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=4553" target="_blank">01:15:53.520</a></span> | <span class="t">is the layer norm. And the PyTorch default initialization sets the scale in the layer norm</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=4558" target="_blank">01:15:58.240</a></span> | <span class="t">to be one, and the offset in the layer norm to be zero. So that's exactly what we want,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=4562" target="_blank">01:16:02.560</a></span> | <span class="t">and so we're just going to keep it that way. And so this is the default initialization</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=4568" target="_blank">01:16:08.480</a></span> | <span class="t">if we are following the, where is it, the GPT-2 source code that they released.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=4576" target="_blank">01:16:16.240</a></span> | <span class="t">I would like to point out, by the way, that typically the standard deviation here on this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=4581" target="_blank">01:16:21.760</a></span> | <span class="t">initialization, if you follow the Javier initialization, would be one over the square</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=4585" target="_blank">01:16:25.440</a></span> | <span class="t">root of the number of features that are incoming into this layer. But if you'll notice, actually,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=4591" target="_blank">01:16:31.120</a></span> | <span class="t">0.02 is basically consistent with that, because the d model sizes inside these transformers for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=4596" target="_blank">01:16:36.800</a></span> | <span class="t">GPT-2 are roughly 768, 1600, etc. So one over the square root of, for example, 768 gives us 0.03.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=4604" target="_blank">01:16:44.720</a></span> | <span class="t">If we plug in 1600, we get 0.02. If we plug in three times that, 0.014, etc. So basically 0.02</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=4615" target="_blank">01:16:55.520</a></span> | <span class="t">is roughly in the vicinity of reasonable values for these initializations anyway. So it's not</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=4624" target="_blank">01:17:04.640</a></span> | <span class="t">completely crazy to be hard coding 0.02 here, but you'd like typically something that grows with the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=4632" target="_blank">01:17:12.160</a></span> | <span class="t">model size instead. But we will keep this because that is the GPT-2 initialization per their source</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=4637" target="_blank">01:17:17.120</a></span> | <span class="t">code. But we are not fully done yet on initialization, because there's one more caveat</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=4641" target="_blank">01:17:21.120</a></span> | <span class="t">here. So here, a modified initialization which accounts for the accumulation on the residual</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=4647" target="_blank">01:17:27.520</a></span> | <span class="t">path with model depth is used. We scale the weight of residual layers of initialization</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=4652" target="_blank">01:17:32.160</a></span> | <span class="t">by a factor of one over square root of n, where n is the number of residual layers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=4655" target="_blank">01:17:35.520</a></span> | <span class="t">So this is what GPT-2 paper says. So we have not implemented that yet, and we can do so now.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=4661" target="_blank">01:17:41.760</a></span> | <span class="t">Now, I'd like to actually kind of like motivate a little bit what they mean here, I think. So</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=4667" target="_blank">01:17:47.440</a></span> | <span class="t">here's roughly what they mean. If you start out with zeros in your residual stream, remember that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=4674" target="_blank">01:17:54.320</a></span> | <span class="t">each residual stream is of this form, where we continue adding to it. x is x plus something,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=4681" target="_blank">01:18:01.520</a></span> | <span class="t">some kind of contribution. So every single block of the residual network contributes some</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=4687" target="_blank">01:18:07.040</a></span> | <span class="t">amount, and it gets added. And so what ends up happening is that the variance of the activations</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=4695" target="_blank">01:18:15.600</a></span> | <span class="t">in the residual stream grows. So here's a small example. If we start at zero, and then we for 100</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=4701" target="_blank">01:18:21.840</a></span> | <span class="t">times, we have sort of this residual stream of 768 zeros. And then 100 times, we add random,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=4711" target="_blank">01:18:31.040</a></span> | <span class="t">which is a normal distribution, zero mean, one standard deviation. If we add to it, then by the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=4717" target="_blank">01:18:37.120</a></span> | <span class="t">end, the residual stream has grown to have standard deviation of 10. And that's just because we're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=4723" target="_blank">01:18:43.600</a></span> | <span class="t">always adding these numbers. And so this scaling factor that they use here exactly compensates for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=4732" target="_blank">01:18:52.080</a></span> | <span class="t">that growth. So if we take n, and we basically scale down every one of these contributions into</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=4739" target="_blank">01:18:59.600</a></span> | <span class="t">the residual stream by one over the square root of n. So one over the square root of n is n to the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=4745" target="_blank">01:19:05.200</a></span> | <span class="t">negative 0.5, right? Because n to the 0.5 is the square root, and then one over the square root is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=4752" target="_blank">01:19:12.800</a></span> | <span class="t">n negative 0.5. If we scale it in this way, then we see that we actually get one. So this is a way</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=4763" target="_blank">01:19:23.120</a></span> | <span class="t">to control the growth of activations inside the residual stream in the forward pass. And so we'd</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=4769" target="_blank">01:19:29.040</a></span> | <span class="t">like to initialize in the same way, where these weights that are at the end of each block, so this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=4774" target="_blank">01:19:34.960</a></span> | <span class="t">CPROJ layer, the GPT paper proposes to scale down those weights by one over the square root of the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=4782" target="_blank">01:19:42.240</a></span> | <span class="t">number of residual layers. So one crude way to implement this is the following. I don't know if</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=4788" target="_blank">01:19:48.240</a></span> | <span class="t">this is PyTorch-sanctioned, but it works for me, is we all do in the initialization, see that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=4796" target="_blank">01:19:56.320</a></span> | <span class="t">special nano-GPT scale in it is one. So we're setting kind of like a flag for this module.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=4806" target="_blank">01:20:06.880</a></span> | <span class="t">There must be a better way than PyTorch, right? But I don't know. Okay, so we're basically</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=4813" target="_blank">01:20:13.200</a></span> | <span class="t">attaching this flag and trying to make sure that it doesn't conflict with anything previously.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=4817" target="_blank">01:20:17.920</a></span> | <span class="t">And then when we come down here, this STD should be 0.02 by default.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=4824" target="_blank">01:20:24.880</a></span> | <span class="t">But then if it has at her module of this thing, then STD times equals.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=4833" target="_blank">01:20:33.600</a></span> | <span class="t">Cobalt is not guessing correctly. So we want one over the square root of the number of layers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=4842" target="_blank">01:20:42.320</a></span> | <span class="t">So the number of residual layers here is twice times self.config layers, and then this times</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=4854" target="_blank">01:20:54.560</a></span> | <span class="t">negative 0.5. So we want to scale down that standard deviation, and this should be correct</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=4861" target="_blank">01:21:01.360</a></span> | <span class="t">and implement that. I should clarify, by the way, that the two times number of layers comes from the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=4866" target="_blank">01:21:06.000</a></span> | <span class="t">fact that every single one of our layers in the transformer actually has two blocks that add to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=4870" target="_blank">01:21:10.800</a></span> | <span class="t">the residual pathway, right? We have the attention and then the MLP. So that's where the two times</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=4875" target="_blank">01:21:15.280</a></span> | <span class="t">comes from. And the other thing to mention is that what's slightly awkward, but we're not going to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=4881" target="_blank">01:21:21.520</a></span> | <span class="t">fix it, is that because we are weight sharing the WTE and the LMHead, in this iteration of our old</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=4889" target="_blank">01:21:29.600</a></span> | <span class="t">submodules, we're going to actually come around to that tensor twice. So we're going to first</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=4893" target="_blank">01:21:33.920</a></span> | <span class="t">initialize it as an embedding with 0.02, and then we're going to come back around it again in the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=4898" target="_blank">01:21:38.800</a></span> | <span class="t">linear and initialize it again using 0.02. And it's going to be 0.02 because the LMHead is, of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=4904" target="_blank">01:21:44.720</a></span> | <span class="t">course, not scaled. So it's not going to come here. It's just it's going to be basically initialized</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=4909" target="_blank">01:21:49.680</a></span> | <span class="t">twice using the identical same initialization, but that's okay. And then scrolling over here,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=4915" target="_blank">01:21:55.920</a></span> | <span class="t">I added some code here so that we have reproducibility to set the seeds. And now</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=4923" target="_blank">01:22:03.680</a></span> | <span class="t">we should be able to Python train GPT2.py and let this running. And as far as I know,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=4929" target="_blank">01:22:09.360</a></span> | <span class="t">this is the GPT2 initialization in the way we've implemented it right now. So this looks</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=4937" target="_blank">01:22:17.360</a></span> | <span class="t">reasonable to me. Okay. So at this point, we have the GPT2 model. We have some confidence that it's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=4942" target="_blank">01:22:22.640</a></span> | <span class="t">correctly implemented. We've initialized it properly. And we have a data loader that's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=4946" target="_blank">01:22:26.400</a></span> | <span class="t">iterating through data batches, and we can train. So now comes the fun part. I'd like us to speed</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=4951" target="_blank">01:22:31.440</a></span> | <span class="t">up the training by a lot. So we're getting our money's worth with respect to the hardware that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=4955" target="_blank">01:22:35.360</a></span> | <span class="t">we are using here. And we're going to speed up the training by quite a bit. Now, you always want to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=4962" target="_blank">01:22:42.400</a></span> | <span class="t">start with what hardware do you have? What does it offer? And are you fully utilizing it? So in my</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=4967" target="_blank">01:22:47.520</a></span> | <span class="t">case, if we go to NVIDIA SMI, we can see that I have eight GPUs. And each one of those GPUs is an</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=4977" target="_blank">01:22:57.760</a></span> | <span class="t">A100 SXM 80 gigabytes. So this is the GPU that I have available to me in this box. Now, when I use</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=4987" target="_blank">01:23:07.680</a></span> | <span class="t">to spin up these kinds of boxes, by the way, my favorite place to go to is Lambda Labs. They do</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=4994" target="_blank">01:23:14.160</a></span> | <span class="t">sponsor my development and that of my projects. But this is my favorite place to go. And this is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=5000" target="_blank">01:23:20.320</a></span> | <span class="t">where you can spin up one of these machines, and you pay per hour, and it's very, very simple.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=5004" target="_blank">01:23:24.080</a></span> | <span class="t">So I like to spin them up and then connect VS Code to it, and that's how I develop.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=5008" target="_blank">01:23:28.320</a></span> | <span class="t">Now, when we look at the A100s that are available here, A100 80 gigabyte SXM is the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=5016" target="_blank">01:23:36.880</a></span> | <span class="t">GPU that I have here. And we have a bunch of numbers here for how many calculations you can</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=5022" target="_blank">01:23:42.720</a></span> | <span class="t">expect out of this GPU. So when I come over here and I break in right after here. So Python. So</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=5032" target="_blank">01:23:52.480</a></span> | <span class="t">I'm breaking in right after we calculate the logits and the loss. And the interesting thing I'd like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=5037" target="_blank">01:23:57.680</a></span> | <span class="t">you to note is when I do logits.dtype, this prints a torch.float32. So by default in PyTorch, when</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=5046" target="_blank">01:24:06.960</a></span> | <span class="t">you create tensors, and this is the case for all the activations and for the parameters of the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=5051" target="_blank">01:24:11.280</a></span> | <span class="t">network and so on, by default, everything is in float32. That means that every single number,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=5057" target="_blank">01:24:17.680</a></span> | <span class="t">activation or weight and so on, is using a float representation that has 32 bits.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=5064" target="_blank">01:24:24.560</a></span> | <span class="t">And that's actually quite a bit of memory. And it turns out empirically that for deep learning</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=5068" target="_blank">01:24:28.400</a></span> | <span class="t">as a computational workload, this is way too much. And deep learning and the training of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=5073" target="_blank">01:24:33.040</a></span> | <span class="t">these networks can tolerate significantly lower precisions. Not all computational workflows</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=5078" target="_blank">01:24:38.960</a></span> | <span class="t">can tolerate small precision. So for example, if we go back to the data sheet, you'll see that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=5086" target="_blank">01:24:46.000</a></span> | <span class="t">actually these GPUs support up to FB64. And this is quite useful, I understand, for a lot of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=5092" target="_blank">01:24:52.080</a></span> | <span class="t">scientific computing applications. And there they really need this. But we don't need that much</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=5096" target="_blank">01:24:56.720</a></span> | <span class="t">precision for deep learning training. So currently we are here, FP32. And with this code as it is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=5103" target="_blank">01:25:03.920</a></span> | <span class="t">right now, we expect to get at most 19.5 teraflops of performance. That means we're doing 19.5</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=5111" target="_blank">01:25:11.680</a></span> | <span class="t">trillion operations, floating point operations. So this is floating point multiply, add, most</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=5119" target="_blank">01:25:19.520</a></span> | <span class="t">likely. And so these are the floating point operations. Now notice that if we are willing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=5127" target="_blank">01:25:27.360</a></span> | <span class="t">to go down in precision, so TF32 is a lower precision format we're going to see in a second,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=5133" target="_blank">01:25:33.360</a></span> | <span class="t">you can actually get an 8x improvement here. And if you're willing to go down to float16 or</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=5138" target="_blank">01:25:38.160</a></span> | <span class="t">bfloat16, you can actually get times 16x performance, all the way to 312 teraflops.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=5145" target="_blank">01:25:45.520</a></span> | <span class="t">You see here that NVIDIA likes to cite numbers that have an asterisk here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=5149" target="_blank">01:25:49.120</a></span> | <span class="t">This asterisk says with sparsity. But we are not going to be using sparsity in our code. And I</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=5155" target="_blank">01:25:55.120</a></span> | <span class="t">don't know that this is very widely used in the industry right now. So most people look at this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=5159" target="_blank">01:25:59.840</a></span> | <span class="t">number here without sparsity. And you'll notice that we could have got even more here. But this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=5165" target="_blank">01:26:05.600</a></span> | <span class="t">is int8. And int8 is used for inference, not for training. Because int8 has a,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=5172" target="_blank">01:26:12.880</a></span> | <span class="t">it basically has uniform spacing. And we actually require a float so that we get a better match</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=5184" target="_blank">01:26:24.320</a></span> | <span class="t">to the normal distributions that occur during training of neural networks, where both</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=5190" target="_blank">01:26:30.160</a></span> | <span class="t">activations and weights are distributed as a normal distribution. And so floating points are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=5195" target="_blank">01:26:35.280</a></span> | <span class="t">really important to match that representation. So we're not typically using int8 for training,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=5202" target="_blank">01:26:42.160</a></span> | <span class="t">but we are using it for inference. And if we bring down the precision, we can get a lot more</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=5207" target="_blank">01:26:47.680</a></span> | <span class="t">teraflops out of the tensor cores available in the GPUs. We'll talk about that in a second.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=5212" target="_blank">01:26:52.400</a></span> | <span class="t">But in addition to that, if all of these numbers have fewer bits of representation, it's going to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=5218" target="_blank">01:26:58.080</a></span> | <span class="t">be much easier to move them around. And that's where we start to get into the memory bandwidth</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=5222" target="_blank">01:27:02.640</a></span> | <span class="t">and the memory of the model. So not only do we have a finite capacity of the number of bits that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=5227" target="_blank">01:27:07.760</a></span> | <span class="t">our GPU can store, but in addition to that, there's a speed with which you can access this memory.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=5233" target="_blank">01:27:13.440</a></span> | <span class="t">And you have a certain memory bandwidth. It's a very precious resource. And in fact, many of the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=5240" target="_blank">01:27:20.080</a></span> | <span class="t">deep learning workloads for training are memory bound. And what that means is actually that the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=5245" target="_blank">01:27:25.520</a></span> | <span class="t">tensor cores that do all these extremely fast multiplications, most of the time they're waiting</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=5250" target="_blank">01:27:30.400</a></span> | <span class="t">around, they're idle, because we can't feed them with data fast enough. We can't load the data</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=5256" target="_blank">01:27:36.880</a></span> | <span class="t">fast enough for memory. So typical utilizations of your hardware, if you're getting 60% utilization,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=5262" target="_blank">01:27:42.800</a></span> | <span class="t">you're actually doing extremely well. So half of the time in a well-tuned application,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=5268" target="_blank">01:27:48.400</a></span> | <span class="t">your tensor cores are not doing multiplies because the data is not available.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=5271" target="_blank">01:27:51.840</a></span> | <span class="t">So the memory bandwidth here is extremely important as well. And if we come down in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=5276" target="_blank">01:27:56.320</a></span> | <span class="t">the precision for all the floats, all the numbers, weights, and activations suddenly require less</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=5281" target="_blank">01:28:01.920</a></span> | <span class="t">memory. So we can store more and we can access it faster. So everything speeds up and it's amazing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=5288" target="_blank">01:28:08.320</a></span> | <span class="t">And now let's reap the benefits of it. And let's first look at the tensor float 32 format.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=5294" target="_blank">01:28:14.080</a></span> | <span class="t">Okay, so first of all, what are tensor cores? Well, tensor core is just an instruction</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=5300" target="_blank">01:28:20.800</a></span> | <span class="t">in the A100 architecture, right? So what it does is it does basically a little 4x4 matrix multiply.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=5308" target="_blank">01:28:28.000</a></span> | <span class="t">So this is just matrix multiplication here of 4x4 matrices. And there are multiple configurations</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=5317" target="_blank">01:28:37.200</a></span> | <span class="t">as to what precision any of these matrices are, in what precision the internal accumulate happens,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=5323" target="_blank">01:28:43.520</a></span> | <span class="t">and then what is the output precision, input precision, etc. So there's a few switches,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=5328" target="_blank">01:28:48.560</a></span> | <span class="t">but it's basically a 4x4 multiply. And then any time we have any operations that require matrix</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=5334" target="_blank">01:28:54.000</a></span> | <span class="t">multiplication, they get broken up into this instruction of a little 4x4 multiply. And so</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=5341" target="_blank">01:29:01.040</a></span> | <span class="t">everything gets broken up into this instruction because it's the fastest way to multiply matrices.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=5345" target="_blank">01:29:05.120</a></span> | <span class="t">And it turns out that most of the computational work that we're doing up above,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=5348" target="_blank">01:29:08.960</a></span> | <span class="t">all of it really is matrix multiplication. Most of the work computationally happens in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=5354" target="_blank">01:29:14.080</a></span> | <span class="t">the linear layers, linear, linear, etc. There's a few things sandwiched in between. So there's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=5362" target="_blank">01:29:22.400</a></span> | <span class="t">some additions in residuals, there's some Gelud nonlinearities, there's some layer norms, etc.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=5367" target="_blank">01:29:27.760</a></span> | <span class="t">But if you just time them, you'll see that these are nothing. Like basically,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=5371" target="_blank">01:29:31.760</a></span> | <span class="t">the entire transformer is just a bunch of matrix multiplications, really.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=5375" target="_blank">01:29:35.680</a></span> | <span class="t">And especially at this small scale, 124 million parameter model, actually the biggest matrix</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=5382" target="_blank">01:29:42.720</a></span> | <span class="t">multiplication by far is the classifier layer at the top. That is a massive matrix multiply</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=5387" target="_blank">01:29:47.840</a></span> | <span class="t">of going from 768 to 50,257. And that matrix multiply dominates anything else that happens</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=5394" target="_blank">01:29:54.880</a></span> | <span class="t">in that network, roughly speaking. So it's matrix multiplies that become a lot faster,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=5400" target="_blank">01:30:00.720</a></span> | <span class="t">which are hidden inside our linear layers. And they're accelerated through tensor cores.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=5405" target="_blank">01:30:05.680</a></span> | <span class="t">Now, the best reference I would say for tensor cores is basically just go to the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=5411" target="_blank">01:30:11.680</a></span> | <span class="t">A100 architecture whitepaper. And then it's pretty detailed. But I think people,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=5417" target="_blank">01:30:17.760</a></span> | <span class="t">it's like relatively readable mostly, if you half understand what's happening.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=5421" target="_blank">01:30:21.280</a></span> | <span class="t">So figure 9 tensor float 32. So this is the explanation basically for TF32 and what happens</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=5429" target="_blank">01:30:29.760</a></span> | <span class="t">here. And you see that there's many configuration options here available. So the input operands,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=5435" target="_blank">01:30:35.840</a></span> | <span class="t">and what precisions are they in, the accumulator, and what basically the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=5441" target="_blank">01:30:41.680</a></span> | <span class="t">internal representation within the instruction when you do the accumulate of this matrix</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=5447" target="_blank">01:30:47.840</a></span> | <span class="t">multiplication. So the intermediate plus equals of the intermediate little vector multiplies here,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=5454" target="_blank">01:30:54.880</a></span> | <span class="t">that all happens in FP32. And then this is an 8x improvement, as I mentioned, to the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=5461" target="_blank">01:31:01.520</a></span> | <span class="t">ops that we got. So TF32 specifically, we're looking at this row here. And the way this works is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=5466" target="_blank">01:31:06.960</a></span> | <span class="t">normally FP32 has 32 bits. TF32 is the exact same bits. We have one sine bit,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=5479" target="_blank">01:31:19.040</a></span> | <span class="t">we have eight exponent bits, except the mantissa bits get cropped in the float.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=5485" target="_blank">01:31:25.120</a></span> | <span class="t">And so basically, we end up with just 19 bits, instead of 32 bits, because the last 13 bits</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=5492" target="_blank">01:31:32.640</a></span> | <span class="t">get truncated, they get dropped. And all this is internal to the instruction. So none of it is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=5499" target="_blank">01:31:39.120</a></span> | <span class="t">visible to anything in our PyTorch. None of our PyTorch code will change, all the numbers will</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=5504" target="_blank">01:31:44.400</a></span> | <span class="t">look identical. It's just that when you call the tensor core instruction, internally in the hardware,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=5511" target="_blank">01:31:51.280</a></span> | <span class="t">it will crop out these 13 bits. And that allows it to calculate this little matrix multiply</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=5518" target="_blank">01:31:58.320</a></span> | <span class="t">significantly faster, 8x faster. Now, of course, this speed up comes at a cost. And the cost is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=5524" target="_blank">01:32:04.800</a></span> | <span class="t">that we are reducing the precision. Our accumulate is still in FP32, our output is FP32, our inputs</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=5530" target="_blank">01:32:10.880</a></span> | <span class="t">are FP32. But internally, things get truncated in the operands to perform the operation faster.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=5537" target="_blank">01:32:17.440</a></span> | <span class="t">And so our results are starting to be a bit more approximate. But empirically, when you actually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=5541" target="_blank">01:32:21.440</a></span> | <span class="t">train with this, you basically can't tell the difference. So the reason I like TF32 is because</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=5546" target="_blank">01:32:26.080</a></span> | <span class="t">if you can tolerate a little bit of a precision fudge, then this is free, like none of your code</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=5553" target="_blank">01:32:33.120</a></span> | <span class="t">sees this, it's fully internal to the operation, and the operation to you just go 8x faster,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=5559" target="_blank">01:32:39.120</a></span> | <span class="t">and it's a bit more approximate. And so it's a pretty sweet spot, I would say in optimization.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=5564" target="_blank">01:32:44.480</a></span> | <span class="t">And let's see what that looks like first. So I've set up our codes to just time the iterations.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=5570" target="_blank">01:32:50.720</a></span> | <span class="t">So import time, I changed the hyper parameters so that we have something a bit more that reflects</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=5576" target="_blank">01:32:56.240</a></span> | <span class="t">a kind of workload that we want to run, because we want to do a fairly large run at the end of this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=5581" target="_blank">01:33:01.040</a></span> | <span class="t">So let's use batch size 16. And let's now use the actual GPT-2 maximum sequence length of 1024</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=5588" target="_blank">01:33:08.000</a></span> | <span class="t">tokens. So this is the configuration. And then for 50 iterations, I'm just doing something very lazy</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=5596" target="_blank">01:33:16.640</a></span> | <span class="t">here. I'm doing time.time to get the current time. And then this is the optimization loop.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=5602" target="_blank">01:33:22.240</a></span> | <span class="t">And now I want to time how long this takes. Now, one issue with working with GPUs is that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=5611" target="_blank">01:33:31.040</a></span> | <span class="t">as your CPU-- when your CPU runs, it's just scheduling work on GPU. It's ordering some work,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=5618" target="_blank">01:33:38.640</a></span> | <span class="t">right? And so it sends a request, and then it continues running. And so it can happen sometimes</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=5624" target="_blank">01:33:44.400</a></span> | <span class="t">that we sort of speed through this, and we queue up a lot of kernels to run on the GPU,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=5631" target="_blank">01:33:51.360</a></span> | <span class="t">and then the CPU sort of gets here and takes time.time. But actually, the GPU is still running,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=5636" target="_blank">01:33:56.160</a></span> | <span class="t">because it takes it time to actually work through the work that was scheduled to run.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=5640" target="_blank">01:34:00.560</a></span> | <span class="t">And so you're just building up a queue for the GPU. And so actually, if you need to,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=5646" target="_blank">01:34:06.080</a></span> | <span class="t">you want to wait, torchatku.data.synchronize. And this will wait for the GPU to finish all the work</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=5651" target="_blank">01:34:11.680</a></span> | <span class="t">that was scheduled to run up above here. And then we can actually take the time. So basically,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=5657" target="_blank">01:34:17.840</a></span> | <span class="t">we're waiting for the GPU to stop this iteration, take the time, and then we're going to just print</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=5663" target="_blank">01:34:23.040</a></span> | <span class="t">it. So here, I'm going to run the training loop. And here on the right, I'm watching NVIDIA SMI.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=5670" target="_blank">01:34:30.400</a></span> | <span class="t">So we start off at 0. We're not using the GPU. And then by default, PyTorch will use GPU 0,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=5676" target="_blank">01:34:36.640</a></span> | <span class="t">so we see that it gets filled up. And we're using 35 gigabytes out of 80 gigabytes available.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=5682" target="_blank">01:34:42.160</a></span> | <span class="t">And then here on the left, we see that because we've cranked up the batch size,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=5689" target="_blank">01:34:49.840</a></span> | <span class="t">now it's only 20 batches to do a single epoch on our tiny Shakespeare.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=5693" target="_blank">01:34:53.120</a></span> | <span class="t">And we see that we're seeing roughly 1,000 milliseconds per iteration here, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=5698" target="_blank">01:34:58.160</a></span> | <span class="t">So the first iteration sometimes is slower. And that's because PyTorch might be doing a lot of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=5705" target="_blank">01:35:05.200</a></span> | <span class="t">initializations here on the very first iteration. And so it's probably initializing all these</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=5709" target="_blank">01:35:09.760</a></span> | <span class="t">tensors and buffers to hold all the gradients. And I'm not 100% sure all the work that happens here,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=5714" target="_blank">01:35:14.960</a></span> | <span class="t">but this could be a slower iteration. When you're timing your logic, you always want</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=5718" target="_blank">01:35:18.960</a></span> | <span class="t">to be careful with that. But basically, we're seeing 1,000 milliseconds per iteration.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=5723" target="_blank">01:35:23.360</a></span> | <span class="t">And so this will run for roughly 50 seconds as we have it right now.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=5728" target="_blank">01:35:28.000</a></span> | <span class="t">So that's our baseline in float32. One more thing I wanted to mention is that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=5733" target="_blank">01:35:33.760</a></span> | <span class="t">if this doesn't fit into your GPU and you're getting out of memory errors,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=5738" target="_blank">01:35:38.080</a></span> | <span class="t">then start decreasing your batch size until things fit. So instead of 16, try 8 or 4</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=5743" target="_blank">01:35:43.120</a></span> | <span class="t">or whatever you need to fit the batch into your GPU. And if you have a bigger GPU, you can actually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=5749" target="_blank">01:35:49.040</a></span> | <span class="t">potentially get away with 32 and so on. By default, you want to basically max out the batch size that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=5755" target="_blank">01:35:55.600</a></span> | <span class="t">fits on your GPU. And you want to keep it nice numbers. So use numbers that have lots of powers</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=5761" target="_blank">01:36:01.680</a></span> | <span class="t">of 2 in them. So 16 is a good number. 8, 24, 32, 48, these are nice numbers. But don't use something</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=5769" target="_blank">01:36:09.600</a></span> | <span class="t">like 17, because that will run very inefficiently on the GPU. And we're going to see that a bit</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=5774" target="_blank">01:36:14.560</a></span> | <span class="t">later as well. So for now, let's just stick with 16, 1,024. And the one thing that I added also</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=5782" target="_blank">01:36:22.320</a></span> | <span class="t">here, and I ran it again, is I'm calculating tokens per second throughput during training.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=5788" target="_blank">01:36:28.960</a></span> | <span class="t">Because we might end up changing the batch size around over time. But tokens per second is the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=5794" target="_blank">01:36:34.720</a></span> | <span class="t">objective measure that we actually really care about. How many tokens of data are we training</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=5798" target="_blank">01:36:38.960</a></span> | <span class="t">on? And what is the throughput of tokens that we're getting in our optimization? So right now,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=5803" target="_blank">01:36:43.280</a></span> | <span class="t">we're processing and training on 163,000 tokens per second, roughly. And that's a bit more</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=5809" target="_blank">01:36:49.360</a></span> | <span class="t">objective metric. Okay, so let's now enable TF32. Now, luckily, PyTorch makes this fairly easy for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=5816" target="_blank">01:36:56.240</a></span> | <span class="t">us. And to enable TF32, you just need to do a single line. And it's this. And when we go to the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=5823" target="_blank">01:37:03.600</a></span> | <span class="t">PyTorch documentation here for this function, basically, this tells PyTorch what kind of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=5828" target="_blank">01:37:08.000</a></span> | <span class="t">kernels to run. And by default, I believe it is highest. Highest precision for matmul. And that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=5835" target="_blank">01:37:15.520</a></span> | <span class="t">means that everything happens in float32, just like it did before. But if we set it to high,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=5840" target="_blank">01:37:20.480</a></span> | <span class="t">as we do right now, matrix multiplications will now use TensorFlow 32 when it's available.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=5846" target="_blank">01:37:26.480</a></span> | <span class="t">My GPU is the A100. So it's an ampere series. And therefore, TF32 is available. If you have an older</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=5854" target="_blank">01:37:34.640</a></span> | <span class="t">GPU, this might not be available for you. But for my GPU, it's available. And so what I expect</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=5860" target="_blank">01:37:40.080</a></span> | <span class="t">PyTorch to do is that every single place where we see an nn.linear, inside there, there's a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=5865" target="_blank">01:37:45.040</a></span> | <span class="t">matrix multiplication. And I expect that matrix multiplication now to be running on TensorCourse,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=5871" target="_blank">01:37:51.200</a></span> | <span class="t">utilizing the TF32 precision. So this is the single line of change that is, I believe, necessary. And</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=5879" target="_blank">01:37:59.200</a></span> | <span class="t">let's rerun this. Now, we saw that in terms of the throughput that is promised to us, we're supposed</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=5885" target="_blank">01:38:05.680</a></span> | <span class="t">to be getting 8x, roughly. So let's see what happens. And that 8x came from here, right? 8x.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=5896" target="_blank">01:38:16.640</a></span> | <span class="t">And it also came from looking at it here, 156 tflops instead of 19.5. Okay, so what actually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=5906" target="_blank">01:38:26.240</a></span> | <span class="t">happened? So we're seeing that our throughput, roughly 3x, not 8x. So we are going from 1000</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=5915" target="_blank">01:38:35.600</a></span> | <span class="t">milliseconds, we're going down to 300 milliseconds, and our throughput is now about 50,000 tokens per</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=5920" target="_blank">01:38:40.560</a></span> | <span class="t">second. So we have a roughly 3x instead of 8x. So what happened? And basically, what's happening</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=5926" target="_blank">01:38:46.240</a></span> | <span class="t">here is, again, a lot of these workloads are memory bound. And so even though the TF32 offers,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=5934" target="_blank">01:38:54.000</a></span> | <span class="t">in principle, a lot faster throughput, all of these numbers everywhere are still float32s.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=5941" target="_blank">01:39:01.280</a></span> | <span class="t">And it's float32 numbers that are being shipped all over the place through the memory system.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=5945" target="_blank">01:39:05.840</a></span> | <span class="t">And it's just costing us way too much time to shuttle around all this data. And so even though</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=5950" target="_blank">01:39:10.160</a></span> | <span class="t">we've made the multiply itself much faster, we are memory bound, and we're not actually seeing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=5954" target="_blank">01:39:14.480</a></span> | <span class="t">the full benefit that would come from this napkin math here. That said, we are getting</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=5961" target="_blank">01:39:21.200</a></span> | <span class="t">3x faster throughput. And this is free. Single line of code in PyTorch. All your variables are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=5968" target="_blank">01:39:28.640</a></span> | <span class="t">still float32 everywhere. It just runs faster. And it's slightly more approximate, but we're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=5973" target="_blank">01:39:33.760</a></span> | <span class="t">not going to notice it, basically. So that's TF32. Okay, so let's now continue. So we've exercised</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=5981" target="_blank">01:39:41.920</a></span> | <span class="t">this row. And we saw that we can crop out some of the precision inside the operation itself.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=5988" target="_blank">01:39:48.560</a></span> | <span class="t">But we saw that we're still memory bound. We're still moving around all these floats,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=5991" target="_blank">01:39:51.840</a></span> | <span class="t">right? Otherwise. And we're paying that cost because of this. So let's now decrease the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=5996" target="_blank">01:39:56.400</a></span> | <span class="t">amount of stuff that we're going to be moving around. And we're going to do that by dropping</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=6000" target="_blank">01:40:00.960</a></span> | <span class="t">down to bfloat16. So we're only going to be maintaining 16 bits per float. And we're going</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=6007" target="_blank">01:40:07.440</a></span> | <span class="t">to use the bfloat16. And I'll explain in a bit FP16 difference. And we're going to be in this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=6012" target="_blank">01:40:12.880</a></span> | <span class="t">row. So when we go back to the documentation here for the A100, we see here the precisions</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=6023" target="_blank">01:40:23.120</a></span> | <span class="t">that are available. And this is the original FP32. The TF32 crops out the precision. And then here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=6029" target="_blank">01:40:29.760</a></span> | <span class="t">in bfloat16, you see that it is very similar to TF32. But it's even more aggressive in cropping</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=6036" target="_blank">01:40:36.640</a></span> | <span class="t">off the precision, the mantissa, of this float. So the important thing with bfloat16 is that the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=6042" target="_blank">01:40:42.480</a></span> | <span class="t">exponent bits and the sign bit, of course, remain unchanged. So if you're familiar with your float</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=6048" target="_blank">01:40:48.000</a></span> | <span class="t">numbers, and I think this should probably be an entire video by itself, the exponent sets the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=6055" target="_blank">01:40:55.200</a></span> | <span class="t">range that you can represent of your numbers. And the precision is how much precision you have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=6060" target="_blank">01:41:00.880</a></span> | <span class="t">for your numbers. And so the range of numbers is identical. But we have fewer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=6067" target="_blank">01:41:07.520</a></span> | <span class="t">possibilities within that range, because we are truncating the mantissa. So we have less precision</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=6073" target="_blank">01:41:13.680</a></span> | <span class="t">in that range. What that means is that things are actually fairly nice, because we have the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=6079" target="_blank">01:41:19.600</a></span> | <span class="t">original range of numbers that are representable in float. But we just have less precision for it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=6085" target="_blank">01:41:25.920</a></span> | <span class="t">And the difference with FP16 is that they actually touch and change the range. So FP16 cannot</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=6092" target="_blank">01:41:32.640</a></span> | <span class="t">represent the full range of FP32. It has a reduced range. And that's where you start to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=6098" target="_blank">01:41:38.240</a></span> | <span class="t">actually run into issues, because now you need these gradient scalers and things like that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=6103" target="_blank">01:41:43.120</a></span> | <span class="t">And I'm not going to go into the detail of that in this video, because that's a whole video by</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=6108" target="_blank">01:41:48.240</a></span> | <span class="t">itself. But FP16 actually historically came first. That was available in the Volta series before</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=6114" target="_blank">01:41:54.400</a></span> | <span class="t">Ampere. And so FP16 came first, and everyone started to train in FP16. But everyone had to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=6119" target="_blank">01:41:59.680</a></span> | <span class="t">use all these gradient scaling operations, which are kind of annoying. And it's an additional source</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=6124" target="_blank">01:42:04.240</a></span> | <span class="t">of state and complexity. And the reason for that was because the exponent range was reduced in FP16.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=6130" target="_blank">01:42:10.160</a></span> | <span class="t">So that's the IEEE FP16's spec. And then they came out with BF16 and the Ampere. And they made it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=6137" target="_blank">01:42:17.680</a></span> | <span class="t">much simpler, because we're just truncating mantissa, we have the exact same range, and we do</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=6141" target="_blank">01:42:21.680</a></span> | <span class="t">not need gradient scalers. So everything is much, much simpler. Now, when we do use BF16, though,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=6147" target="_blank">01:42:27.680</a></span> | <span class="t">we are impacting the numbers that we might be seeing in our PyTorch code.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=6152" target="_blank">01:42:32.080</a></span> | <span class="t">This change is not just local to the operation itself. So let's see how that works.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=6158" target="_blank">01:42:38.160</a></span> | <span class="t">There's some documentation here that-- so I think this is probably the best page to explain how to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=6165" target="_blank">01:42:45.600</a></span> | <span class="t">use mixed precision in PyTorch. Because there are many other tutorials and so on, even within</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=6171" target="_blank">01:42:51.680</a></span> | <span class="t">PyTorch documentation, that are a lot more confusing. And so I recommend specifically</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=6175" target="_blank">01:42:55.920</a></span> | <span class="t">this one. Because there's five other copies that I would not recommend. And then when we come here,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=6181" target="_blank">01:43:01.680</a></span> | <span class="t">ignore everything about everything. Ignore everything about gradient scalers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=6186" target="_blank">01:43:06.560</a></span> | <span class="t">And only look at torch.autocast. And basically, also, this comes to a single line of code at</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=6194" target="_blank">01:43:14.640</a></span> | <span class="t">the end. So this is the context manager that we want. And we want to use that in our network.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=6202" target="_blank">01:43:22.400</a></span> | <span class="t">When you click into the torch.autocast, autocasting, it has a few more-- a bit more</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=6209" target="_blank">01:43:29.440</a></span> | <span class="t">guideline for you. So it's telling you, do not call BFloat16 on any of your tensors.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=6215" target="_blank">01:43:35.200</a></span> | <span class="t">Just use autocast. And only surround the forward pass of the model and the loss calculation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=6221" target="_blank">01:43:41.600</a></span> | <span class="t">And that's the only two things that you should be surrounding. Leave the backward and the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=6225" target="_blank">01:43:45.280</a></span> | <span class="t">optimizer step alone. So that's the guidance that comes from the PyTorch team. So we're going to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=6230" target="_blank">01:43:50.400</a></span> | <span class="t">follow that guidance. And for us, because the loss calculation is inside of the model forward pass for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=6235" target="_blank">01:43:55.600</a></span> | <span class="t">us, we are going to be doing this. And then we don't want to be using torch.float16. Because if</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=6241" target="_blank">01:44:01.840</a></span> | <span class="t">we do that, we need to start using gradient scalers as well. So we are going to be using BFloat16.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=6247" target="_blank">01:44:07.120</a></span> | <span class="t">This is only possible to do in Ampere. But this means that the changes are extremely minimal.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=6252" target="_blank">01:44:12.720</a></span> | <span class="t">Well, it's basically just this one line of code. Let me first break in to here, before we actually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=6261" target="_blank">01:44:21.440</a></span> | <span class="t">run this. So right after logits. I'd like to show you that, different from the TF32 that we saw,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=6268" target="_blank">01:44:28.720</a></span> | <span class="t">this is actually going to impact our tensors. So this logits tensor, if we now look at this,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=6276" target="_blank">01:44:36.720</a></span> | <span class="t">and we look at the D type, we suddenly see that this is now BFloat16. It's not float32 anymore.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=6283" target="_blank">01:44:43.360</a></span> | <span class="t">So our activations have been changed. The activations tensor is now BFloat16. But not</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=6288" target="_blank">01:44:48.640</a></span> | <span class="t">everything has changed. So model.transformer.wte. This is the weight token embedding table. It has</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=6299" target="_blank">01:44:59.120</a></span> | <span class="t">a dot weight inside it. And the D type of this weight, this parameter, is still torch.float32.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=6306" target="_blank">01:45:06.160</a></span> | <span class="t">So our parameters seem to still be in float32, but our activations, the logits, are now in BFloat16.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=6311" target="_blank">01:45:11.760</a></span> | <span class="t">So clearly, this is why we get the mixed precision. Some things PyTorch is keeping</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=6317" target="_blank">01:45:17.040</a></span> | <span class="t">in float32. Some things PyTorch is converting to lower precision. And what gets converted,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=6324" target="_blank">01:45:24.640</a></span> | <span class="t">at what point, is not super clear. I remember scrolling down. Is it here?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=6331" target="_blank">01:45:31.920</a></span> | <span class="t">Okay, I can't find it. I thought it was here. Okay, there we go. So there are a few docs on</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=6344" target="_blank">01:45:44.160</a></span> | <span class="t">when you're using this autocast, what gets converted to BFloat16 and when. So for example,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=6349" target="_blank">01:45:49.760</a></span> | <span class="t">only these matrix multiply-like operations get converted to BFloat16. But a lot of operations</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=6355" target="_blank">01:45:55.360</a></span> | <span class="t">remain in float32. So in particular, a lot of normalizations, like layer norms and things like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=6359" target="_blank">01:45:59.920</a></span> | <span class="t">that, not all of those layers might be converted. So only some layers selectively would be running</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=6366" target="_blank">01:46:06.400</a></span> | <span class="t">BFloat16. But things like softmax, layer norms, log softmax, so loss function calculations,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=6374" target="_blank">01:46:14.800</a></span> | <span class="t">a lot of those things might remain in float32 because they are more susceptible to precision</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=6379" target="_blank">01:46:19.040</a></span> | <span class="t">changes. Matrix multiplies are fairly robust to precision changes. So some parts of the network</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=6387" target="_blank">01:46:27.520</a></span> | <span class="t">are impacted more or less by the precision change. So basically only some parts of the model are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=6395" target="_blank">01:46:35.520</a></span> | <span class="t">running in reduced precision. Let's take it for a spin and let's actually see what kind of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=6401" target="_blank">01:46:41.680</a></span> | <span class="t">improvement we achieve here. Okay, so we used to be 333 milliseconds. We're now at 300.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=6412" target="_blank">01:46:52.880</a></span> | <span class="t">And we used to be somewhere around 50,000 tokens per second. We're now at 55.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=6416" target="_blank">01:46:56.960</a></span> | <span class="t">So we're definitely running faster, but maybe not a lot faster. And that's because there are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=6422" target="_blank">01:47:02.960</a></span> | <span class="t">still many, many bottlenecks in our GPT-2. We're just getting started. But we have dropped down</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=6427" target="_blank">01:47:07.840</a></span> | <span class="t">the precision as far as we can with my current GPU, which is A100. We're using PyTorch Autocast.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=6434" target="_blank">01:47:14.320</a></span> | <span class="t">Unfortunately, I don't actually exactly know what PyTorch Autocast does. I don't actually know</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=6440" target="_blank">01:47:20.000</a></span> | <span class="t">exactly what's in BFloat16, what's in float32. We could go in and we could start to scrutinize it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=6445" target="_blank">01:47:25.120</a></span> | <span class="t">But these are the kinds of rules that PyTorch has internally. And unfortunately, they don't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=6450" target="_blank">01:47:30.400</a></span> | <span class="t">document it very well. So we're not going to go into that in too much detail. But for now,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=6456" target="_blank">01:47:36.560</a></span> | <span class="t">we are training in BFloat16. We do not need a gradient scaler. And the reason things are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=6461" target="_blank">01:47:41.200</a></span> | <span class="t">running faster is because we are able to run TensorCourse in BFloat16 now. That means we are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=6469" target="_blank">01:47:49.360</a></span> | <span class="t">in this row. But we are also paying in precision for this. So we expect slightly less accurate</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=6477" target="_blank">01:47:57.840</a></span> | <span class="t">results with respect to the original FP32. But empirically, in many cases, this is a worth it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=6484" target="_blank">01:48:04.080</a></span> | <span class="t">trade-off because it allows you to run faster. And you could, for example, train longer and make</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=6488" target="_blank">01:48:08.800</a></span> | <span class="t">up for that precision decrease. So that's BFloat16 for now. Okay. So as we can see,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=6497" target="_blank">01:48:17.120</a></span> | <span class="t">we are currently at about 300 milliseconds per iteration. And we're now going to reach for some</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=6501" target="_blank">01:48:21.840</a></span> | <span class="t">really heavy weapons in the PyTorch arsenal. And in particular, we're going to introduce</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=6505" target="_blank">01:48:25.920</a></span> | <span class="t">Torch.compile. So Torch.compile is really quite incredible infrastructure from the PyTorch team.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=6511" target="_blank">01:48:31.840</a></span> | <span class="t">And it's basically a compiler for neural networks. It's almost like GCC for C and C++ code. This is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=6518" target="_blank">01:48:38.240</a></span> | <span class="t">just the GCC of neural nets. So it came out a while ago and extremely simple to use. The way</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=6526" target="_blank">01:48:46.800</a></span> | <span class="t">to use Torch.compile is to do this. It's a single line of code to compile your model and return it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=6533" target="_blank">01:48:53.200</a></span> | <span class="t">Now, this line of code will cost you compilation time. But as you might guess, it's going to make</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=6538" target="_blank">01:48:58.000</a></span> | <span class="t">the code a lot faster. So let's actually run that. Because this will take some time to run.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=6542" target="_blank">01:49:02.960</a></span> | <span class="t">But currently, remember, we're at 300 milliseconds. And we'll see what happens.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=6546" target="_blank">01:49:06.240</a></span> | <span class="t">Now, while this is running, I'd like to explain a little bit of what Torch.compile does under</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=6551" target="_blank">01:49:11.600</a></span> | <span class="t">the hood. So feel free to read this page of PyTorch. But basically, there's no real good</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=6557" target="_blank">01:49:17.680</a></span> | <span class="t">reason for you to not use Torch.compile in your PyTorch. I kind of feel like you should be using</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=6562" target="_blank">01:49:22.640</a></span> | <span class="t">it almost by default unless you're debugging and you want your code to run really fast.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=6567" target="_blank">01:49:27.920</a></span> | <span class="t">And there's one line here in Torch.compile that I found that actually kind of gets to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=6571" target="_blank">01:49:31.760</a></span> | <span class="t">why this is faster. Speed up mainly comes from reducing Python overhead and GPU read/writes.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=6578" target="_blank">01:49:38.240</a></span> | <span class="t">So let me unpack that a little bit. Okay. Here we are. Okay. So we went from 300 milliseconds.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=6584" target="_blank">01:49:44.400</a></span> | <span class="t">We're now running at 129 milliseconds. So this is 300 divided by 129, about 2.3x</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=6592" target="_blank">01:49:52.080</a></span> | <span class="t">improvement from a single line of code in PyTorch. So quite incredible. So what is happening? What's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=6597" target="_blank">01:49:57.520</a></span> | <span class="t">happening under the hood? Well, when you pass the model to Torch.compile, what we have here in this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=6603" target="_blank">01:50:03.840</a></span> | <span class="t">NN module, this is really just the algorithmic description of what we'd like to happen in our</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=6609" target="_blank">01:50:09.360</a></span> | <span class="t">network. And Torch.compile will analyze the entire thing. And it will look at what operations you'd</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=6615" target="_blank">01:50:15.840</a></span> | <span class="t">like to use. And with the benefit of knowing exactly what's going to happen, it doesn't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=6621" target="_blank">01:50:21.040</a></span> | <span class="t">have to run in what's called the eager mode. It doesn't have to just kind of like go layer by</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=6625" target="_blank">01:50:25.680</a></span> | <span class="t">layer. Like the Python interpreter normally would start at the forward. And the Python interpreter</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=6633" target="_blank">01:50:33.280</a></span> | <span class="t">will go, okay, let's do this operation. And then let's do that operation. And it kind of materializes</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=6638" target="_blank">01:50:38.640</a></span> | <span class="t">all the operations as it goes through. So these calculations are dispatched and run in this order.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=6645" target="_blank">01:50:45.360</a></span> | <span class="t">And the Python interpreter and this code doesn't know what kind of operations are going to happen</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=6649" target="_blank">01:50:49.680</a></span> | <span class="t">later. But Torch.compile sees your entire code at the same time. And it's able to know what</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=6655" target="_blank">01:50:55.200</a></span> | <span class="t">operations you intend to run. And it will kind of optimize that process. The first thing it will do</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=6660" target="_blank">01:51:00.640</a></span> | <span class="t">is it will take out the Python interpreter from the forward pass entirely. And it will kind of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=6665" target="_blank">01:51:05.120</a></span> | <span class="t">compile this entire neural net as a single object with no Python interpreter involved. So it knows</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=6670" target="_blank">01:51:10.800</a></span> | <span class="t">exactly what's going to run. It will just run that. And it's all going to be running in efficient code.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=6676" target="_blank">01:51:16.640</a></span> | <span class="t">The second thing that happens is this read/write that they mentioned very briefly. So a good</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=6683" target="_blank">01:51:23.120</a></span> | <span class="t">example of that, I think, is the Gelu nonlinearity that we've been looking at.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=6686" target="_blank">01:51:26.240</a></span> | <span class="t">So here we use the nngelu. Now, this here is me basically just breaking up the nngelu,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=6694" target="_blank">01:51:34.000</a></span> | <span class="t">which you remember has this formula. So this here is the equivalent implementation to what's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=6699" target="_blank">01:51:39.840</a></span> | <span class="t">happening inside Gelu. Algorithmically, it's identical. Now, by default, if we just were</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=6706" target="_blank">01:51:46.240</a></span> | <span class="t">using this instead of nngelu here, what would happen without Torch.compile? Well, the Python</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=6711" target="_blank">01:51:51.840</a></span> | <span class="t">interpreter would make its way here. And then it would be, okay, well, there's an input. Well,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=6716" target="_blank">01:51:56.160</a></span> | <span class="t">let me first let me raise this input to the third power. And it's going to dispatch a kernel that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=6721" target="_blank">01:52:01.840</a></span> | <span class="t">takes your input and raises it to the third power. And that kernel will run. And when this kernel</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=6728" target="_blank">01:52:08.400</a></span> | <span class="t">runs, what ends up happening is this input is stored in the memory of the GPU. So here's a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=6734" target="_blank">01:52:14.080</a></span> | <span class="t">helpful example of the layout of what's happening, right? You have your CPU. This is in every single</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=6740" target="_blank">01:52:20.240</a></span> | <span class="t">computer. There's a few cores in there. And you have your RAM, your memory. And the CPU can talk</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=6747" target="_blank">01:52:27.040</a></span> | <span class="t">to the memory. And this is all well known. But now we've added the GPU. And the GPU is a slightly</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=6751" target="_blank">01:52:31.840</a></span> | <span class="t">different architecture, of course. They can communicate. And it's different in that it's got</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=6755" target="_blank">01:52:35.920</a></span> | <span class="t">a lot more cores than a CPU. All of those cores are individually a lot simpler, too.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=6761" target="_blank">01:52:41.200</a></span> | <span class="t">But it also has memory, right? This high bandwidth memory. Sorry if I'm botching it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=6768" target="_blank">01:52:48.480</a></span> | <span class="t">HBM. I don't even know what that stands for. I'm just realizing now. But this is the memory. And</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=6774" target="_blank">01:52:54.480</a></span> | <span class="t">it's very equivalent to RAM, basically, in the computer. And what's happening is that input is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=6780" target="_blank">01:53:00.640</a></span> | <span class="t">living in the memory. And when you do input cubed, this has to travel to the GPU, to the cores,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=6790" target="_blank">01:53:10.240</a></span> | <span class="t">and to all the caches and registers on the actual chip of this GPU. And it has to calculate all</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=6797" target="_blank">01:53:17.680</a></span> | <span class="t">the elements of the third. And then it saves the result back to the memory. And it's this travel</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=6803" target="_blank">01:53:23.840</a></span> | <span class="t">time that actually causes a lot of issues. So here, remember this memory bandwidth? We can</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=6809" target="_blank">01:53:29.760</a></span> | <span class="t">communicate about 2 terabytes per second, which is a lot. But also, we have to traverse this link,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=6815" target="_blank">01:53:35.760</a></span> | <span class="t">and it's very slow. So here on the GPU, we're on chip, and everything is super fast within the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=6820" target="_blank">01:53:40.400</a></span> | <span class="t">chip. But going to the memory is extremely expensive. It takes an extremely long amount of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=6824" target="_blank">01:53:44.400</a></span> | <span class="t">time. And so we load the input, do the calculations, and load back the output. And this round trip</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=6831" target="_blank">01:53:51.520</a></span> | <span class="t">takes a lot of time. And now right after we do that, we multiply by this constant. So what happens</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=6837" target="_blank">01:53:57.840</a></span> | <span class="t">then is we dispatch another kernel. And then the result travels back. All the elements get</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=6843" target="_blank">01:54:03.280</a></span> | <span class="t">multiplied by a constant. And then the results travel back to the memory. And then we take the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=6848" target="_blank">01:54:08.960</a></span> | <span class="t">result, and we add back input. And so this entire thing, again, travels to the GPU, adds the inputs,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=6856" target="_blank">01:54:16.240</a></span> | <span class="t">and gets written back. So we're making all these round trips from the memory to actually where the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=6862" target="_blank">01:54:22.000</a></span> | <span class="t">computation happens. Because all the tensor cores and the ALUs and everything like that is all</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=6866" target="_blank">01:54:26.720</a></span> | <span class="t">stored on the chip and the GPU. So we're doing a ton of round trips. And PyTorch, without using</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=6872" target="_blank">01:54:32.480</a></span> | <span class="t">Torch Compile, doesn't know to optimize this, because it doesn't know what kind of operations</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=6877" target="_blank">01:54:37.200</a></span> | <span class="t">you're running later. You're just telling it, raise the power to the third, then do this, then</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=6882" target="_blank">01:54:42.160</a></span> | <span class="t">do that. And it will just do that in that sequence. But Torch Compile sees your entire code.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=6886" target="_blank">01:54:46.480</a></span> | <span class="t">It will come here, and it will realize, wait, all of these are element-wise operations. And actually,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=6891" target="_blank">01:54:51.440</a></span> | <span class="t">what I'm going to do is I'm going to do a single trip of input to the GPU.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=6896" target="_blank">01:54:56.320</a></span> | <span class="t">Then for every single element, I'm going to do all of these operations while that memory is on the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=6901" target="_blank">01:55:01.680</a></span> | <span class="t">GPU, or chunks of it, rather. And then I'm going to write back a single time. So we're not going</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=6907" target="_blank">01:55:07.520</a></span> | <span class="t">to have these round trips. And that's one example of what's called kernel fusion, and is a major way</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=6912" target="_blank">01:55:12.560</a></span> | <span class="t">in which everything is sped up. So basically, if you have your benefit of handset, and you know</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=6916" target="_blank">01:55:16.560</a></span> | <span class="t">exactly what you're going to compute, you can optimize your round trips to the memory. And</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=6921" target="_blank">01:55:21.600</a></span> | <span class="t">you're not going to pay the memory bandwidth cost. And that's fundamentally what makes some of these</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=6925" target="_blank">01:55:25.520</a></span> | <span class="t">operations a lot faster, and what they mean by read/writes here. So let me erase this, because</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=6932" target="_blank">01:55:32.320</a></span> | <span class="t">we are not using it. And yeah, we should be using Torch Compile. And our code is now significantly</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=6939" target="_blank">01:55:39.760</a></span> | <span class="t">faster. And we're doing about 125,000 tokens per second. But we still have a long way to go.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=6946" target="_blank">01:55:46.160</a></span> | <span class="t">Before we move on, I wanted to supplement the discussion a little bit with a few more figures.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=6950" target="_blank">01:55:50.640</a></span> | <span class="t">Because this is a complicated topic, but it's worth understanding on a high level</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=6955" target="_blank">01:55:55.040</a></span> | <span class="t">what's happening here. And I could probably spend an entire video of like two hours on this, but</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=6959" target="_blank">01:55:59.520</a></span> | <span class="t">just a preview of that basically. So this chip here, that is the GPU, this chip is where all</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=6966" target="_blank">01:56:06.640</a></span> | <span class="t">the calculations happen mostly. But this chip also does have some memory in it. But most of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=6973" target="_blank">01:56:13.200</a></span> | <span class="t">the memory by far is here in the high bandwidth memory, HBM, and is connected, they're connected.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=6980" target="_blank">01:56:20.240</a></span> | <span class="t">But these are two separate chips, basically. Now, here, this is a zoom in of kind of this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=6986" target="_blank">01:56:26.800</a></span> | <span class="t">cartoon diagram of a GPU. And we're seeing here is number one, you see this HBM, I realize it's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=6993" target="_blank">01:56:33.680</a></span> | <span class="t">probably very small for you. But on the sides here, it says HBM. And so that's the links to the HBM.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=6999" target="_blank">01:56:39.360</a></span> | <span class="t">Now the HBM is, again, off chip. On the chip, there are a large number of these streaming</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=7005" target="_blank">01:56:45.840</a></span> | <span class="t">multiprocessors. Every one of these is an SM, there's 120 of them in total. And this is where</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=7012" target="_blank">01:56:52.080</a></span> | <span class="t">a lot of the calculations happen. And this is a zoom in of a single individual SM. It has these</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=7017" target="_blank">01:56:57.440</a></span> | <span class="t">four quadrants. And see, for example, tensor core, this is where a lot of the matrix multiply stuff</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=7021" target="_blank">01:57:01.600</a></span> | <span class="t">happens. But there's all these other units to do all different kinds of calculations for FB64,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=7027" target="_blank">01:57:07.120</a></span> | <span class="t">FB32, and for integers, and so on. Now, so we have all this logic here to the calculations.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=7034" target="_blank">01:57:14.480</a></span> | <span class="t">But in addition to that, on the chip, there is memory sprinkled throughout the chip.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=7038" target="_blank">01:57:18.880</a></span> | <span class="t">So L2 cache is some amount of memory that lives on the chip. And then on the SMs themselves,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=7045" target="_blank">01:57:25.520</a></span> | <span class="t">there's L1 cache. I realize it's probably very small for you, but this blue bar is L1.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=7050" target="_blank">01:57:30.400</a></span> | <span class="t">And there's also registers. And so there is memory stored here. But the way this memory is stored is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=7057" target="_blank">01:57:37.840</a></span> | <span class="t">very different from the way memory is stored in HBM. This is a very different implementation using</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=7064" target="_blank">01:57:44.400</a></span> | <span class="t">just in terms of like what the silicon looks like, it's a very different implementation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=7069" target="_blank">01:57:49.520</a></span> | <span class="t">So here, you would be using transistors and capacitors. And here, it's a very different</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=7075" target="_blank">01:57:55.280</a></span> | <span class="t">implementation with SRAM and what that looks like. But long story short is there is memory</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=7084" target="_blank">01:58:04.240</a></span> | <span class="t">inside the chip, but it's not a lot of memory. That's the critical point. So this is an example</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=7090" target="_blank">01:58:10.320</a></span> | <span class="t">diagram of a slightly different GPU, just like here, where it shows that, for example, typical</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=7095" target="_blank">01:58:15.760</a></span> | <span class="t">numbers for CPU DRAM memory, which is this thing here, you might have one terabyte of disk, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=7102" target="_blank">01:58:22.640</a></span> | <span class="t">But it would be extremely expensive to access, especially for a GPU. You have to go through the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=7106" target="_blank">01:58:26.320</a></span> | <span class="t">CPU here. Now, next, we have the HBM. So we have tens of gigabytes of HBM memory on a typical GPU</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=7112" target="_blank">01:58:32.960</a></span> | <span class="t">here, but it's, as I mentioned, very expensive to access. And then on the chip itself, everything is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=7119" target="_blank">01:58:39.840</a></span> | <span class="t">extremely fast within the chip, but we only have a couple of 10 megabytes of memory collectively</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=7125" target="_blank">01:58:45.760</a></span> | <span class="t">throughout the chip. And so there's just not enough space because the memory is very expensive</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=7130" target="_blank">01:58:50.800</a></span> | <span class="t">on the chip. And so there's not a lot of it, but it is lightning fast to access in relative terms.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=7136" target="_blank">01:58:56.000</a></span> | <span class="t">And so basically, whenever we have these kernels, the more accurate picture of what's happening here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=7142" target="_blank">01:59:02.240</a></span> | <span class="t">is that we take these inputs, which live by default on the global memory, and now we need</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=7148" target="_blank">01:59:08.080</a></span> | <span class="t">to perform some calculation. So we start streaming the data from the global memory to the chip.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=7155" target="_blank">01:59:15.680</a></span> | <span class="t">We perform the calculations on the chip and then stream it back and store it back to the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=7159" target="_blank">01:59:19.840</a></span> | <span class="t">global memory, right? And so if we don't have Torch Compile, we are streaming the data through</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=7165" target="_blank">01:59:25.600</a></span> | <span class="t">the chip doing the calculations and saving to the memory, and we're doing those round trips many,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=7169" target="_blank">01:59:29.520</a></span> | <span class="t">many times. But if it's Torch Compiled, then we start streaming the memory as before, but then</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=7175" target="_blank">01:59:35.600</a></span> | <span class="t">while we're on the chip, we have a chunk of the data that we're trying to process. So that chunk</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=7182" target="_blank">01:59:42.880</a></span> | <span class="t">now lives on the chip. While it's on the chip, it's extremely fast to operate on. So if we have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=7187" target="_blank">01:59:47.360</a></span> | <span class="t">kernel fusion, we can do all the operations right there in an element-wise fashion, and those are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=7192" target="_blank">01:59:52.560</a></span> | <span class="t">very cheap. And then we do a single round trip back to the global memory. So operator fusion</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=7198" target="_blank">01:59:58.960</a></span> | <span class="t">basically allows you to keep your chunk of data on the chip and do lots of calculations on it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=7203" target="_blank">02:00:03.600</a></span> | <span class="t">before you write it back, and that gives huge savings. And that's why Torch Compile ends up</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=7209" target="_blank">02:00:09.280</a></span> | <span class="t">being a lot faster, or that's one of the major reasons. So again, just a very brief intro to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=7215" target="_blank">02:00:15.120</a></span> | <span class="t">the memory hierarchy and roughly what Torch Compile does for you. Now, Torch Compile is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=7219" target="_blank">02:00:19.920</a></span> | <span class="t">amazing, but there are operations that Torch Compile will not find. And an amazing example</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=7225" target="_blank">02:00:25.520</a></span> | <span class="t">of that is FlashAttention, to which we turn next. So FlashAttention comes from this paper from</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=7230" target="_blank">02:00:30.960</a></span> | <span class="t">Stanford in 2022, and it's this incredible algorithm for performing attention and running</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=7239" target="_blank">02:00:39.520</a></span> | <span class="t">it a lot faster. So FlashAttention will come here, and we will take out these four lines,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=7245" target="_blank">02:00:45.920</a></span> | <span class="t">and FlashAttention implements these four lines really, really quickly. And how does it do that?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=7252" target="_blank">02:00:52.880</a></span> | <span class="t">Well, FlashAttention is a kernel fusion operation. So you see here we have in this diagram,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=7260" target="_blank">02:01:00.080</a></span> | <span class="t">they're showing PyTorch, and you have these four operations. They're including dropout,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=7265" target="_blank">02:01:05.600</a></span> | <span class="t">but we are not using dropout here. So we just have these four lines of code here,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=7269" target="_blank">02:01:09.680</a></span> | <span class="t">and instead of those, we are fusing them into a single fused kernel of FlashAttention.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=7275" target="_blank">02:01:15.200</a></span> | <span class="t">So it's a kernel fusion algorithm, but it's a kernel fusion that Torch Compile cannot find.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=7282" target="_blank">02:01:22.480</a></span> | <span class="t">And the reason that it cannot find it is that it requires an algorithmic rewrite of how attention</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=7288" target="_blank">02:01:28.160</a></span> | <span class="t">is actually implemented here in this case. And what's remarkable about it is that FlashAttention,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=7293" target="_blank">02:01:33.920</a></span> | <span class="t">actually, if you just count the number of flops, FlashAttention does more flops than this attention</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=7300" target="_blank">02:01:40.080</a></span> | <span class="t">here. But FlashAttention is actually significantly faster. In fact, they cite 7.6 times faster,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=7307" target="_blank">02:01:47.120</a></span> | <span class="t">potentially. And that's because it is very mindful of the memory hierarchy, as I described it just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=7313" target="_blank">02:01:53.680</a></span> | <span class="t">now. And so it's very mindful about what's in high bandwidth memory, what's in the shared memory,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=7319" target="_blank">02:01:59.280</a></span> | <span class="t">and it is very careful with how it orchestrates the computation, such that we have fewer reads</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=7325" target="_blank">02:02:05.120</a></span> | <span class="t">and writes to the high bandwidth memory. And so even though we're doing more flops,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=7329" target="_blank">02:02:09.120</a></span> | <span class="t">the expensive part is their load and store into HBM, and that's what they avoid. And so in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=7334" target="_blank">02:02:14.000</a></span> | <span class="t">particular, they do not ever materialize this end-by-end attention matrix, this ATT here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=7340" target="_blank">02:02:20.560</a></span> | <span class="t">FlashAttention is designed such that this matrix never gets materialized at any point,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=7345" target="_blank">02:02:25.760</a></span> | <span class="t">and it never gets read or written to the HBM. And this is a very large matrix, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=7350" target="_blank">02:02:30.960</a></span> | <span class="t">So because this is where all the queries and keys interact, and we're sort of getting</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=7355" target="_blank">02:02:35.280</a></span> | <span class="t">for each head, for each batch element, we're getting a T-by-T matrix of attention,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=7363" target="_blank">02:02:43.120</a></span> | <span class="t">which is a million numbers, even for a single head at a single batch index.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=7367" target="_blank">02:02:47.600</a></span> | <span class="t">So basically, this is a ton of memory, and this is never materialized. And the way that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=7374" target="_blank">02:02:54.080</a></span> | <span class="t">this is achieved is that basically the fundamental algorithmic rewrite here relies on this online</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=7380" target="_blank">02:03:00.720</a></span> | <span class="t">softmax trick, which was proposed previously, and I'll show you the paper in a bit.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=7384" target="_blank">02:03:04.240</a></span> | <span class="t">And the online softmax trick, coming from a previous paper, shows how you can incrementally</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=7391" target="_blank">02:03:11.360</a></span> | <span class="t">evaluate a softmax without having to sort of realize all of the inputs to the softmax</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=7397" target="_blank">02:03:17.360</a></span> | <span class="t">to do the normalization. And you do that by having these intermediate variables m and l,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=7402" target="_blank">02:03:22.080</a></span> | <span class="t">and there's an update to them that allows you to evaluate the softmax in an online manner.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=7406" target="_blank">02:03:26.560</a></span> | <span class="t">Now FlashAttention, actually, so recently FlashAttention2 came out as well, so I have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=7413" target="_blank">02:03:33.120</a></span> | <span class="t">that paper up here as well, that has additional gains to how it calculates FlashAttention.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=7418" target="_blank">02:03:38.480</a></span> | <span class="t">And the original paper that this is based on, basically, is this online normalizing calculation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=7423" target="_blank">02:03:43.200</a></span> | <span class="t">for softmax. And remarkably, it came out of NVIDIA, and it came out of it like really early,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=7428" target="_blank">02:03:48.240</a></span> | <span class="t">2018. So this is four years before FlashAttention. And this paper says that we propose a way to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=7435" target="_blank">02:03:55.840</a></span> | <span class="t">compute the classical softmax with fewer memory accesses and hypothesize that this reduction in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=7440" target="_blank">02:04:00.240</a></span> | <span class="t">memory accesses should improve softmax performance on actual hardware. And so they are extremely</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=7446" target="_blank">02:04:06.480</a></span> | <span class="t">correct in this hypothesis, but it's really fascinating to me that they're from NVIDIA,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=7451" target="_blank">02:04:11.600</a></span> | <span class="t">and that they had this realization, but they didn't actually take it to the actual FlashAttention</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=7456" target="_blank">02:04:16.240</a></span> | <span class="t">that had to come four years later from Stanford. So I don't fully understand the historical,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=7461" target="_blank">02:04:21.840</a></span> | <span class="t">how this happened historically, but they do basically propose this online update to the softmax</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=7467" target="_blank">02:04:27.280</a></span> | <span class="t">right here. And this is fundamentally what they reuse here to calculate the softmax in a streaming</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=7473" target="_blank">02:04:33.360</a></span> | <span class="t">manner. And then they realized that they can actually fuse all the other operations</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=7476" target="_blank">02:04:36.880</a></span> | <span class="t">with the online softmax calculation into a single fused kernel, FlashAttention,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=7482" target="_blank">02:04:42.240</a></span> | <span class="t">and that's what we are about to use. So a great example, I think, of being aware of memory</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=7488" target="_blank">02:04:48.160</a></span> | <span class="t">hierarchy, the fact that flops don't matter, the entire memory access pattern matters,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=7492" target="_blank">02:04:52.960</a></span> | <span class="t">and that TorchCompile is amazing, but there are many optimizations that are still available to us</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=7497" target="_blank">02:04:57.200</a></span> | <span class="t">that potentially TorchCompile cannot find. Maybe one day it could, but right now it seems like a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=7503" target="_blank">02:05:03.200</a></span> | <span class="t">lot to ask. So here's what we're going to do. We're going to use FlashAttention, and the way</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=7509" target="_blank">02:05:09.200</a></span> | <span class="t">to do that basically in PyTorch is we are going to comment out these four lines, and we're going</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=7515" target="_blank">02:05:15.280</a></span> | <span class="t">to replace them with a single line. And here we are calling this compound operation in PyTorch</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=7520" target="_blank">02:05:20.960</a></span> | <span class="t">called scale.productAttention. And PyTorch will call FlashAttention when you use it in this way.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=7530" target="_blank">02:05:30.880</a></span> | <span class="t">I'm not actually 100% sure why TorchCompile doesn't realize that these four lines should</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=7534" target="_blank">02:05:34.720</a></span> | <span class="t">just call FlashAttention in this exact way. We have to do it again for it, which in my opinion</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=7540" target="_blank">02:05:40.240</a></span> | <span class="t">is a little bit odd, but here we are. So you have to use this compound op, and let's wait for a few</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=7550" target="_blank">02:05:50.480</a></span> | <span class="t">moments before TorchCompile gets around to it. And then let's remember that we achieved 6.05661.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=7558" target="_blank">02:05:58.400</a></span> | <span class="t">I have it here. That's the loss we were expecting to see, and we took 130 milliseconds before this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=7564" target="_blank">02:06:04.640</a></span> | <span class="t">change. So we're expecting to see the exact same result by iteration 49, but we expect to see</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=7571" target="_blank">02:06:11.120</a></span> | <span class="t">faster runtime because FlashAttention is just an algorithmic rewrite, and it's a faster kernel,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=7576" target="_blank">02:06:16.240</a></span> | <span class="t">but it doesn't actually change any of the computation, and we should have the exact</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=7579" target="_blank">02:06:19.120</a></span> | <span class="t">same optimization. So okay, so we're a lot faster. We're at about 95 milliseconds,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=7584" target="_blank">02:06:24.720</a></span> | <span class="t">and we achieved 6.058. Okay, so they're basically identical up to a floating-point</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=7592" target="_blank">02:06:32.640</a></span> | <span class="t">fudge factor. So it's the identical computation, but it's significantly faster going from 130 to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=7599" target="_blank">02:06:39.120</a></span> | <span class="t">roughly 96, and so this is 96 divide 130-ish, so this is maybe 27-ish percent improvement.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=7610" target="_blank">02:06:50.240</a></span> | <span class="t">So really interesting, and that is FlashAttention. Okay, we are now getting to one of my favorite</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=7616" target="_blank">02:06:56.560</a></span> | <span class="t">optimizations, and it is simultaneously the dumbest and the most brilliant optimization,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=7622" target="_blank">02:07:02.000</a></span> | <span class="t">and it's always a little bit surprising to me. Anyway, so basically I mentioned a few minutes</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=7627" target="_blank">02:07:07.760</a></span> | <span class="t">ago that there are some numbers that are nice and some numbers that are ugly. So 64 is a beautiful</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=7635" target="_blank">02:07:15.120</a></span> | <span class="t">nice number. 128 is even nicer. 256 is beautiful. What makes these numbers beautiful is that there</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=7641" target="_blank">02:07:21.120</a></span> | <span class="t">are many powers of two inside them. You can divide by two many times, and examples of ugly numbers</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=7647" target="_blank">02:07:27.360</a></span> | <span class="t">are like 13 and 17 and something like that, prime numbers, numbers that are not even, and so on,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=7652" target="_blank">02:07:32.560</a></span> | <span class="t">and so pretty much you always want to use nice numbers in all of your code that deals with neural</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=7656" target="_blank">02:07:36.880</a></span> | <span class="t">networks or CUDA because everything in CUDA works in sort of like powers of two, and lots of kernels</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=7663" target="_blank">02:07:43.840</a></span> | <span class="t">are written in terms of powers of two, and there are lots of blocks of sizes 16 and 64 and so on.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=7670" target="_blank">02:07:50.240</a></span> | <span class="t">So everything is written in those terms, and you always have special case handling for all kinds of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=7674" target="_blank">02:07:54.880</a></span> | <span class="t">logic that when your inputs are not made of nice numbers. So let's see what that looks like.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=7681" target="_blank">02:08:01.680</a></span> | <span class="t">Basically, scan your code and look for ugly numbers is roughly the heuristic. So three times</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=7688" target="_blank">02:08:08.000</a></span> | <span class="t">is kind of ugly. I'm not 100% sure maybe this can be improved, but this is ugly and not ideal.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=7694" target="_blank">02:08:14.640</a></span> | <span class="t">Four times is nice. So that's nice. 1024 is very nice. That's a power of two.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=7704" target="_blank">02:08:24.960</a></span> | <span class="t">12 is a little bit suspicious. Not too many powers of two. 768 is great. 50,257 is a really,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=7712" target="_blank">02:08:32.800</a></span> | <span class="t">really ugly number. First of all, it's odd, and there's not too many powers of two in there.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=7720" target="_blank">02:08:40.560</a></span> | <span class="t">So this is a very ugly number, and it's highly suspicious. And then when we scroll down,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=7726" target="_blank">02:08:46.080</a></span> | <span class="t">all these numbers are nice, and then here we have mostly nice numbers except for 25.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=7732" target="_blank">02:08:52.720</a></span> | <span class="t">So in this configuration of GPT-2XL, the number of heads is 25. That's a really ugly number. That's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=7737" target="_blank">02:08:57.840</a></span> | <span class="t">an odd number. Actually, this did cause a lot of headaches for us recently when we were trying to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=7742" target="_blank">02:09:02.960</a></span> | <span class="t">optimize some kernels to run this fast and required a bunch of special case handling.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=7748" target="_blank">02:09:08.320</a></span> | <span class="t">So basically, we have some ugly numbers, and some of them are easier to fix than others.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=7754" target="_blank">02:09:14.560</a></span> | <span class="t">In particular, the vocab size being 50,257, that's a very ugly number, very suspicious,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=7759" target="_blank">02:09:19.360</a></span> | <span class="t">and we want to fix it. Now, when you fix these things, one of the easy ways to do that is you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=7764" target="_blank">02:09:24.560</a></span> | <span class="t">basically increase the number until it's the nearest power of two that you like. So here's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=7771" target="_blank">02:09:31.280</a></span> | <span class="t">a much nicer number. It's 50,304. And why is that? Because 50,304 can be divided by 8, or by 16,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=7780" target="_blank">02:09:40.000</a></span> | <span class="t">or by 32, 64. It can even be divided by 128, I think. Yeah. So it's a very nice number.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=7788" target="_blank">02:09:48.400</a></span> | <span class="t">So what we're going to do here is this is the GPT config, and you see that we initialize</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=7793" target="_blank">02:09:53.360</a></span> | <span class="t">vocab size to 50,257. Let's override just that element to be 50,304.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=7800" target="_blank">02:10:00.960</a></span> | <span class="t">So everything else stays the same. We're just increasing our vocabulary size.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=7807" target="_blank">02:10:07.600</a></span> | <span class="t">So it's almost like we're adding fake tokens. So that vocab size has powers of two inside it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=7814" target="_blank">02:10:14.560</a></span> | <span class="t">Now, actually, what I'm doing here, by the way, is I'm increasing the amount of computation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=7819" target="_blank">02:10:19.200</a></span> | <span class="t">that our network will be doing. If you just count the flops on like, do the math of how many flops</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=7823" target="_blank">02:10:23.840</a></span> | <span class="t">we're doing, we're going to be doing more flops. And we still have to think through whether this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=7829" target="_blank">02:10:29.680</a></span> | <span class="t">doesn't break anything. But if I just run this, let's see what we get. Currently, this ran and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=7835" target="_blank">02:10:35.760</a></span> | <span class="t">maybe 96.5 milliseconds per step. I'm just kind of like eyeballing it. And let's see what kind of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=7843" target="_blank">02:10:43.840</a></span> | <span class="t">result we're going to get. While this is compiling, let's think through whether our code actually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=7851" target="_blank">02:10:51.280</a></span> | <span class="t">works okay when we increase the vocab size like this. Let's look at where vocab size is actually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=7856" target="_blank">02:10:56.000</a></span> | <span class="t">used. So we swing up to the init, and we see that it's used inside the embedding table, of course,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=7862" target="_blank">02:11:02.560</a></span> | <span class="t">so all the way at the bottom of the transformer. And it's used at the classifier layer, all the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=7866" target="_blank">02:11:06.400</a></span> | <span class="t">way at the top of the transformer, so in two places. And let's take a look. And we're running</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=7871" target="_blank">02:11:11.440</a></span> | <span class="t">at 93. So 93 milliseconds instead of 96.5. So we are seeing a roughly 4% improvement here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=7880" target="_blank">02:11:20.400</a></span> | <span class="t">by doing more calculations. And the reason for this is we've made an ugly number into a nice</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=7888" target="_blank">02:11:28.400</a></span> | <span class="t">number. I'm going to come into the explanation for that a little bit again. But for now, let's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=7893" target="_blank">02:11:33.920</a></span> | <span class="t">just convince ourselves that we're not breaking anything when we do this. So first of all, we've</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=7897" target="_blank">02:11:37.600</a></span> | <span class="t">made the WTE, the embedding table for the tokens, we've made it larger. It's almost like we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=7903" target="_blank">02:11:43.120</a></span> | <span class="t">introduced more tokens at the bottom. And these tokens are never used because the GPT tokenizer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=7909" target="_blank">02:11:49.600</a></span> | <span class="t">only has tokens up to 50,256. And so we'll never index into the rows that we've added. So we're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=7917" target="_blank">02:11:57.120</a></span> | <span class="t">wasting a little bit of space here by creating memory that's never going to be accessed, never</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=7921" target="_blank">02:12:01.360</a></span> | <span class="t">going to be used, etc. Now, that's not fully correct, because this WTE weight ends up being</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=7927" target="_blank">02:12:07.440</a></span> | <span class="t">shared and ends up being used in the classifier here at the end. So what is that doing to the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=7932" target="_blank">02:12:12.320</a></span> | <span class="t">classifier right here? Well, what that's doing is we're predicting additional dimensions of the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=7937" target="_blank">02:12:17.440</a></span> | <span class="t">classifier now. And we're predicting probabilities for tokens that will, of course, never be present</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=7942" target="_blank">02:12:22.160</a></span> | <span class="t">in the training set. And so therefore, the network has to learn that these probabilities have to be</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=7948" target="_blank">02:12:28.880</a></span> | <span class="t">driven to zero. And so the logits that the network produces have to drive those dimensions of the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=7954" target="_blank">02:12:34.320</a></span> | <span class="t">output to negative infinity. But that's no different from all the other tokens that are already in our</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=7959" target="_blank">02:12:39.760</a></span> | <span class="t">data set, or rather that are not in our data set. So Shakespeare only probably uses, let's say 1000</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=7966" target="_blank">02:12:46.400</a></span> | <span class="t">tokens out of 50,257 tokens. So most of the tokens are already being driven to zero probability by</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=7972" target="_blank">02:12:52.160</a></span> | <span class="t">the optimization, we've just introduced a few more tokens now that in a similar manner will never be</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=7977" target="_blank">02:12:57.120</a></span> | <span class="t">used and have to be driven to zero in probability. So functionally, though, nothing breaks, we're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=7983" target="_blank">02:13:03.920</a></span> | <span class="t">using a bit more extra memory. But otherwise, this is a harmless operation, as far as I can tell.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=7990" target="_blank">02:13:10.400</a></span> | <span class="t">But and we're adding calculation, but it's running faster. And it's running faster,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=7995" target="_blank">02:13:15.280</a></span> | <span class="t">because as I mentioned, in CUDA, so many kernels use block tiles, and these block tiles are usually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=8002" target="_blank">02:13:22.560</a></span> | <span class="t">nice numbers. So powers of two, so calculations are done in like chunks of 64, or chunks of 32.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=8008" target="_blank">02:13:28.720</a></span> | <span class="t">And when you're when your desired calculation doesn't neatly fit into those block tiles,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=8014" target="_blank">02:13:34.720</a></span> | <span class="t">there are all kinds of boundary kernels that can kick in to like, do the last part. So basically,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=8022" target="_blank">02:13:42.720</a></span> | <span class="t">in a lot of kernels, they will truncate up your input, and they will do the nice part first,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=8027" target="_blank">02:13:47.280</a></span> | <span class="t">and then they have a whole second second phase, where they come back to anything that like remains.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=8032" target="_blank">02:13:52.640</a></span> | <span class="t">And then they process the remaining part. And the kernels for that can be very inefficient.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=8038" target="_blank">02:13:58.000</a></span> | <span class="t">And so you're basically spinning up all this extra compute, and it's extremely inefficient.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=8043" target="_blank">02:14:03.680</a></span> | <span class="t">So you might as well pad your inputs and make it fit nicely. And usually that empirically ends up</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=8050" target="_blank">02:14:10.160</a></span> | <span class="t">actually running faster. So this is another example of a 4% improvement that we've added.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=8057" target="_blank">02:14:17.760</a></span> | <span class="t">And this is something that also Torch Compile did not find for us. You would hope that Torch Compile</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=8062" target="_blank">02:14:22.640</a></span> | <span class="t">at some point could figure an optimization like this out. But for now, this is it. And I also have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=8068" target="_blank">02:14:28.320</a></span> | <span class="t">to point out that we're using PyTorch nightly. So that's why we're only seeing 4%. If you're using</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=8072" target="_blank">02:14:32.880</a></span> | <span class="t">PyTorch 2.3.1, or earlier, you would actually see something like 30% improvement just from this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=8078" target="_blank">02:14:38.800</a></span> | <span class="t">change, from changing it from 50,000 to 57,000 to 5,304. So again, one of my favorite examples also</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=8088" target="_blank">02:14:48.000</a></span> | <span class="t">of having to understand the under the hood and how it all works, and to know what kinds of things to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=8092" target="_blank">02:14:52.320</a></span> | <span class="t">tinker with to push the performance of your code. Okay, so at this point, we have improved the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=8096" target="_blank">02:14:56.960</a></span> | <span class="t">performance by about 11x, right? Because we started at about 1000 milliseconds per step,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=8101" target="_blank">02:15:01.840</a></span> | <span class="t">and we're now down to like 93 milliseconds. So that's quite good. And we're doing a much better</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=8108" target="_blank">02:15:08.240</a></span> | <span class="t">job of utilizing our GPU resources. So I'm going to now turn to more algorithmic changes and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=8114" target="_blank">02:15:14.720</a></span> | <span class="t">improvements to the actual optimization itself. And what we would like to do is we'd like to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=8118" target="_blank">02:15:18.640</a></span> | <span class="t">follow the hyperparameters that are mentioned in the GPT-2 or GPT-3 paper. Now, sadly, GPT-2</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=8125" target="_blank">02:15:25.360</a></span> | <span class="t">doesn't actually say too much. It's very nice of them that they released the model weights and the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=8131" target="_blank">02:15:31.120</a></span> | <span class="t">code, but the paper itself is extremely vague as to the optimization details. The code itself that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=8136" target="_blank">02:15:36.320</a></span> | <span class="t">they released as well, the code we've been looking at, this is just the inference code. So there's no</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=8141" target="_blank">02:15:41.520</a></span> | <span class="t">training code here and very few hyperparameters. So this doesn't also tell us too much. So for that,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=8146" target="_blank">02:15:46.480</a></span> | <span class="t">we have to turn to the GPT-3 paper. And in the appendix of the GPT-3 paper, they have a lot</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=8154" target="_blank">02:15:54.400</a></span> | <span class="t">more hyperparameters here for us to use. And the GPT-3 paper in general is a lot more detailed as</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=8160" target="_blank">02:16:00.240</a></span> | <span class="t">to all the small details that go into the model training, but GPT-3 models were never released.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=8168" target="_blank">02:16:08.000</a></span> | <span class="t">So GPT-2, we have the weights, but no details, and GPT-3, we have lots of details, but no weights.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=8172" target="_blank">02:16:12.880</a></span> | <span class="t">But roughly speaking, GPT-2 and GPT-3 architectures are very, very similar.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=8178" target="_blank">02:16:18.560</a></span> | <span class="t">And basically, there are very few changes. The context length was expanded from 1024 to 2048,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=8185" target="_blank">02:16:25.760</a></span> | <span class="t">and that's kind of like the major change. And some of the hyperparameters around the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=8189" target="_blank">02:16:29.520</a></span> | <span class="t">transformer have changed. But otherwise, they're pretty much the same model. It's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=8192" target="_blank">02:16:32.880</a></span> | <span class="t">just that GPT-3 was trained for a lot longer on a bigger dataset and has a lot more thorough</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=8197" target="_blank">02:16:37.920</a></span> | <span class="t">evaluations. And the GPT-3 model is 175 billion instead of 1.6 billion in the GPT-2.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=8207" target="_blank">02:16:47.440</a></span> | <span class="t">So long story short, we're going to go to GPT-3 paper to follow along some of the hyperparameters.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=8212" target="_blank">02:16:52.160</a></span> | <span class="t">So to train all the versions of GPT-3, we use Atom with beta 1, beta 2 of 0.9 and 0.95.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=8219" target="_blank">02:16:59.440</a></span> | <span class="t">So let's swing over here and make sure that the betas parameter, which you can see here defaults</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=8224" target="_blank">02:17:04.880</a></span> | <span class="t">to 0.9 and 0.999, is actually set to 0.9 and 0.95. And then the epsilon parameter,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=8233" target="_blank">02:17:13.680</a></span> | <span class="t">you can see is the default is 1 and negative 8, and this is also 1 and negative 8. Let's just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=8239" target="_blank">02:17:19.680</a></span> | <span class="t">put it in so that we're explicit. Now, next up, they say we clip the global norm of the gradient</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=8247" target="_blank">02:17:27.120</a></span> | <span class="t">at 1.0. So what this is referring to is that once we calculate the gradients right after loss dot</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=8253" target="_blank">02:17:33.120</a></span> | <span class="t">backward, we basically have the gradients at all the parameter tensors. And what people like to do</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=8260" target="_blank">02:17:40.160</a></span> | <span class="t">is basically clip them to have some kind of a maximum norm. So in PyTorch, this is fairly easy</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=8266" target="_blank">02:17:46.160</a></span> | <span class="t">to do. It's one line of code here that we have to insert right after we calculate the gradients.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=8271" target="_blank">02:17:51.440</a></span> | <span class="t">And what this utility function is doing is it's calculating the global norm of the parameters.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=8279" target="_blank">02:17:59.040</a></span> | <span class="t">So every single gradient on all the parameters, you square it and you add it all up and you take</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=8285" target="_blank">02:18:05.120</a></span> | <span class="t">a big square root of that. And that's the norm of the parameter vector, basically. It's the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=8292" target="_blank">02:18:12.800</a></span> | <span class="t">length of it, if you if you'd like to look at it that way. And we are basically making sure that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=8297" target="_blank">02:18:17.040</a></span> | <span class="t">its length is no more than 1.0. And we're going to clip it. And the reason that people like to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=8302" target="_blank">02:18:22.880</a></span> | <span class="t">use this is that sometimes you can get unlucky during the optimization. Maybe it's a bad data</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=8307" target="_blank">02:18:27.760</a></span> | <span class="t">batch or something like that. And if you get very unlucky in the batch, you might get really high</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=8312" target="_blank">02:18:32.560</a></span> | <span class="t">loss and really high loss could lead to a really high gradient. And this could basically shock your</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=8318" target="_blank">02:18:38.880</a></span> | <span class="t">model and shock the optimization. So people like to use a gradient norm clipping to prevent the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=8325" target="_blank">02:18:45.680</a></span> | <span class="t">model from basically getting too big of shocks in terms of the gradient magnitude and the upper</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=8332" target="_blank">02:18:52.880</a></span> | <span class="t">bounded in this way. It's a bit of a hacky solution. It's got like a patch on top of like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=8337" target="_blank">02:18:57.840</a></span> | <span class="t">deeper issues, but people still do it fairly frequently. Now, the clip grad norm returns</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=8344" target="_blank">02:19:04.400</a></span> | <span class="t">the norm of the gradient, which I like to always visualize because it is useful information. And</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=8351" target="_blank">02:19:11.440</a></span> | <span class="t">sometimes you can look at the norm of the gradient and if it's well behaved, things are good. If it's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=8356" target="_blank">02:19:16.560</a></span> | <span class="t">climbing, things are bad and they're destabilizing during training. Sometimes you could get a spike</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=8361" target="_blank">02:19:21.040</a></span> | <span class="t">in the norm, and that means there's some kind of an issue or instability. So the norm here will be</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=8367" target="_blank">02:19:27.360</a></span> | <span class="t">a norm. And let's do a 0.4F or something like that. And I believe this is just a float.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=8376" target="_blank">02:19:36.720</a></span> | <span class="t">And so we should be able to print that. So that's global gradient clipping.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=8383" target="_blank">02:19:43.840</a></span> | <span class="t">Now they go into the details of the learning rate scheduler. So they don't just use a fixed</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=8390" target="_blank">02:19:50.560</a></span> | <span class="t">learning rate like we do here for 3E negative 4, but there's actually basically a cosine decay</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=8396" target="_blank">02:19:56.640</a></span> | <span class="t">learning rate schedule. It's got a warmup and it's got a cosine decay to 10% over some horizon.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=8404" target="_blank">02:20:04.800</a></span> | <span class="t">And so we're going to implement this in a second. I just like to see the norm printed here. Okay,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=8412" target="_blank">02:20:12.720</a></span> | <span class="t">there we go. So what happened here is the norm is actually really high in the beginning,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=8417" target="_blank">02:20:17.760</a></span> | <span class="t">30 or so. And you see that as we continue training, it kind of like stabilizes</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=8424" target="_blank">02:20:24.800</a></span> | <span class="t">at values below one. And this is not that crazy uncommon for the norm to be high in the very first</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=8431" target="_blank">02:20:31.440</a></span> | <span class="t">few stages. Basically what's happening here is the model is completely random. And so there's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=8435" target="_blank">02:20:35.520</a></span> | <span class="t">a ton of learning happening very early in the network, but that learning is kind of like,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=8439" target="_blank">02:20:39.520</a></span> | <span class="t">you know, it's mostly learning the biases of the output tokens. And so it's a bit of an unstable</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=8445" target="_blank">02:20:45.920</a></span> | <span class="t">time, but the network usually stabilizes in the very few iterations. So this looks relatively</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=8450" target="_blank">02:20:50.880</a></span> | <span class="t">reasonable to me, except usually I would expect this looks a little bit funky that we go from</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=8455" target="_blank">02:20:55.360</a></span> | <span class="t">28 to 6 to 2 and then to 10. It's not completely insane, but it's just kind of a little bit funky.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=8462" target="_blank">02:21:02.080</a></span> | <span class="t">Okay, so let's now get to the learning rate scheduler. So the learning rate schedule</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=8467" target="_blank">02:21:07.760</a></span> | <span class="t">that's used here in GPT-3 is what's called a cosine decay learning schedule with warmup.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=8474" target="_blank">02:21:14.240</a></span> | <span class="t">And the way this looks is that the learning rate is basically starts right at around zero,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=8479" target="_blank">02:21:19.840</a></span> | <span class="t">linearly ramps up over some amount of time, and then comes down with this cosine sort of form and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=8487" target="_blank">02:21:27.120</a></span> | <span class="t">comes down to some kind of a minimum learning rate that's up to you. So here the minimum learning</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=8490" target="_blank">02:21:30.720</a></span> | <span class="t">rate is zero. But here in the paper, they said that they use cosine decay for learning rate down</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=8496" target="_blank">02:21:36.640</a></span> | <span class="t">to 10% of its value over the first 260 billion tokens. And then training continues 10% after.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=8504" target="_blank">02:21:44.800</a></span> | <span class="t">And there's a linear warmup over the first 375 million tokens. So that's about the learning</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=8510" target="_blank">02:21:50.560</a></span> | <span class="t">rate. So let's now implement this. So I already implemented it here. And the way this works is,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=8516" target="_blank">02:21:56.560</a></span> | <span class="t">let me scroll down first here. I changed our training loop a little bit. So this was a 4i</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=8522" target="_blank">02:22:02.400</a></span> | <span class="t">in max steps. I just change it to step now so that we have the notion of a step as a single</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=8527" target="_blank">02:22:07.360</a></span> | <span class="t">optimization step in the for loop. And then here, I get the LR for this step of the optimization</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=8534" target="_blank">02:22:14.960</a></span> | <span class="t">using a new function I call getLR. And then in PyTorch to set the learning rate, I think this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=8540" target="_blank">02:22:20.400</a></span> | <span class="t">is the way to set the learning rate. It's a little bit gnarly. Because you have to basically there's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=8545" target="_blank">02:22:25.120</a></span> | <span class="t">a notion of different parameter groups that could exist in the optimizer. And so you actually have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=8549" target="_blank">02:22:29.200</a></span> | <span class="t">to iterate over them, even though we currently have a single param group only. And you have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=8554" target="_blank">02:22:34.080</a></span> | <span class="t">to set the LR in this for loop kind of style, is my impression right now. So we have this local</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=8560" target="_blank">02:22:40.400</a></span> | <span class="t">LR, we set the learning rate, and then on the bottom, I'm also printing it. So that's all the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=8566" target="_blank">02:22:46.240</a></span> | <span class="t">changes I made to this loop. And then of course, the getLR is my scheduler. Now it's worth pointing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=8571" target="_blank">02:22:51.200</a></span> | <span class="t">out that PyTorch actually has learning rate schedulers, and you can use them. And I believe</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=8575" target="_blank">02:22:55.680</a></span> | <span class="t">there's a cosine learning rate schedule in PyTorch. I just don't really love using that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=8580" target="_blank">02:23:00.880</a></span> | <span class="t">code, because honestly, it's like five lines of code. And I fully understand what's happening</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=8586" target="_blank">02:23:06.720</a></span> | <span class="t">inside these lines. So I don't love to use abstractions where they're kind of inscrutable,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=8592" target="_blank">02:23:12.160</a></span> | <span class="t">and then I don't know what they're doing. So personal style. So the max learning rate here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=8597" target="_blank">02:23:17.360</a></span> | <span class="t">is let's say 3e negative 4. But we're going to see that in GPT-3 here, they have a table of what the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=8605" target="_blank">02:23:25.280</a></span> | <span class="t">maximum learning rate is for every model size. So for this one, basically 12 layer 768 GPT-3.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=8616" target="_blank">02:23:36.560</a></span> | <span class="t">So the GPT-3 small is roughly like a GPT-2 124M. We see that here they use a learning rate of 6e</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=8623" target="_blank">02:23:43.280</a></span> | <span class="t">negative 4. So we could actually go higher. In fact, we may want to try to follow that and just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=8628" target="_blank">02:23:48.000</a></span> | <span class="t">set the maximal R here at 6. Then that's the maximum learning rate. The min learning rate is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=8634" target="_blank">02:23:54.400</a></span> | <span class="t">10% of that per description in the paper, some number of steps that we're going to warm up over,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=8641" target="_blank">02:24:01.600</a></span> | <span class="t">and then the maximum steps of the optimization, which I now use also in the for loop down here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=8646" target="_blank">02:24:06.080</a></span> | <span class="t">And then you can go over this code if you like. It's not terribly inside floor interesting.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=8652" target="_blank">02:24:12.240</a></span> | <span class="t">I'm just modulating based on the iteration number which learning rate there should be.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=8657" target="_blank">02:24:17.600</a></span> | <span class="t">So this is the warmup region. This is the region after the optimization. And then this is the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=8664" target="_blank">02:24:24.240</a></span> | <span class="t">region sort of in between. And this is where I calculate the cosine learning rate schedule.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=8668" target="_blank">02:24:28.960</a></span> | <span class="t">And you can step through this in detail if you'd like. But this is basically implementing this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=8673" target="_blank">02:24:33.040</a></span> | <span class="t">curve. And I ran this already. And this is what that looks like. So when we now run, we start at</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=8685" target="_blank">02:24:45.600</a></span> | <span class="t">some very low number. Now, note that we don't start exactly at zero because that would be not</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=8689" target="_blank">02:24:49.760</a></span> | <span class="t">useful to update with a learning rate of zero. That's why there's an it plus one, so that on</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=8694" target="_blank">02:24:54.320</a></span> | <span class="t">the zeroth iteration, we are not using exactly zero. We're using something very, very low.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=8698" target="_blank">02:24:58.640</a></span> | <span class="t">Then we linearly warm up to maximum learning rate, which in this case was 3e negative 4 when I ran</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=8704" target="_blank">02:25:04.320</a></span> | <span class="t">it. But now it would be 6e negative 4. And then it starts to decay all the way down to 3e negative 5,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=8712" target="_blank">02:25:12.640</a></span> | <span class="t">which was at the time 10% of the original learning rate. Now, one thing we are not</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=8716" target="_blank">02:25:16.880</a></span> | <span class="t">following exactly is that they mentioned that -- let me see if I can find it again.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=8722" target="_blank">02:25:22.640</a></span> | <span class="t">We're not exactly following what they did because</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=8726" target="_blank">02:25:26.960</a></span> | <span class="t">they mentioned that their training horizon is 300 billion tokens. And they come down to 10%</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=8734" target="_blank">02:25:34.400</a></span> | <span class="t">of the initial learning rate at 260 billion. And then they train after 260 with 10%. So basically,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=8741" target="_blank">02:25:41.440</a></span> | <span class="t">their decay time is less than the max steps time, whereas for us, they're exactly equal.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=8746" target="_blank">02:25:46.560</a></span> | <span class="t">So it's not exactly faithful, but it's an okay -- this is okay for us and for our purposes right</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=8754" target="_blank">02:25:54.240</a></span> | <span class="t">now. And we're just going to use this ourselves. I don't think it makes too big of a difference,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=8760" target="_blank">02:26:00.400</a></span> | <span class="t">honestly. I should point out that what learning rate schedule you use is totally up to you.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=8765" target="_blank">02:26:05.440</a></span> | <span class="t">There's many different types. Cosine learning rate has been popularized a lot by GPT-2 and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=8770" target="_blank">02:26:10.640</a></span> | <span class="t">GPT-3, but people have come up with all kinds of other learning rate schedules. And this is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=8775" target="_blank">02:26:15.600</a></span> | <span class="t">kind of like an active area of research as to which one is the most effective at training</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=8780" target="_blank">02:26:20.320</a></span> | <span class="t">these networks. Okay, next up, the paper talks about the gradual batch size increase. So there's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=8787" target="_blank">02:26:27.040</a></span> | <span class="t">a ramp on the batch size that is linear. And you start with very small batch size, and you ramp up</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=8792" target="_blank">02:26:32.400</a></span> | <span class="t">to a big batch size over time. We're going to actually skip this, and we're not going to work</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=8796" target="_blank">02:26:36.880</a></span> | <span class="t">with it. And the reason I don't love to use it is that it complicates a lot of the arithmetic,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=8801" target="_blank">02:26:41.760</a></span> | <span class="t">because you are changing the number of tokens that you're processing at every single step of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=8805" target="_blank">02:26:45.200</a></span> | <span class="t">the optimization. And I like to keep that math very, very simple. Also, my understanding is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=8810" target="_blank">02:26:50.080</a></span> | <span class="t">that this is not a major improvement. And also, my understanding is that this is not an algorithmic</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=8816" target="_blank">02:26:56.560</a></span> | <span class="t">optimization improvement. It's more of a systems and speed improvement. And roughly speaking,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=8821" target="_blank">02:27:01.360</a></span> | <span class="t">this is because in the early stages of the optimization, again, the model is in a very</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=8828" target="_blank">02:27:08.080</a></span> | <span class="t">atypical setting. And mostly what you're learning is that you're mostly learning to ignore the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=8834" target="_blank">02:27:14.000</a></span> | <span class="t">tokens that don't come up in your training set very often. You're learning very simple biases and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=8839" target="_blank">02:27:19.280</a></span> | <span class="t">that kind of a thing. And so every single example that you put through your network</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=8845" target="_blank">02:27:25.520</a></span> | <span class="t">is basically just telling you, use these tokens and don't use these tokens. And so the gradients</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=8850" target="_blank">02:27:30.080</a></span> | <span class="t">from every single example are actually extremely highly correlated. They all look roughly the same</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=8855" target="_blank">02:27:35.040</a></span> | <span class="t">in the original parts of the optimization, because they're all just telling you that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=8859" target="_blank">02:27:39.040</a></span> | <span class="t">these tokens don't appear and these tokens do appear. And so because the gradients are all</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=8864" target="_blank">02:27:44.240</a></span> | <span class="t">very similar, and they're highly correlated, then why are you doing batch sizes of millions,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=8869" target="_blank">02:27:49.280</a></span> | <span class="t">when if you do a batch size of 32k, you're basically getting the exact same gradient</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=8873" target="_blank">02:27:53.760</a></span> | <span class="t">early on in the training. And then later in the optimization, once you've learned all the simple</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=8879" target="_blank">02:27:59.040</a></span> | <span class="t">stuff, that's where the actual work starts. And that's where the gradients become more</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=8882" target="_blank">02:28:02.800</a></span> | <span class="t">decorrelated per examples. And that's where they actually offer you sort of statistical power,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=8887" target="_blank">02:28:07.760</a></span> | <span class="t">in some sense. So we're going to skip this just because it kind of complicates things.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=8893" target="_blank">02:28:13.200</a></span> | <span class="t">And we're going to go to data are sampled without replacement during training.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=8899" target="_blank">02:28:19.520</a></span> | <span class="t">So until an epoch boundary is reached. So without replacement means that they're not sampling from</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=8905" target="_blank">02:28:25.600</a></span> | <span class="t">some fixed pool, and then take a sequence, train on it, but then also like return to sequence the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=8912" target="_blank">02:28:32.480</a></span> | <span class="t">pool, they are exhausting a pool. So when they draw a sequence, it's it's gone until the next</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=8917" target="_blank">02:28:37.920</a></span> | <span class="t">epoch of training. So we're already doing that because our data loader iterates over chunks of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=8924" target="_blank">02:28:44.560</a></span> | <span class="t">data. So there's no replacement, they don't become eligible to be drawn again until the next epoch.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=8930" target="_blank">02:28:50.640</a></span> | <span class="t">So we're basically already doing that. All models use a weight decay of point one to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=8937" target="_blank">02:28:57.280</a></span> | <span class="t">provide a small amount of regularization. So let's implement a weight decay. And you see</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=8942" target="_blank">02:29:02.400</a></span> | <span class="t">here that I've already kind of made the changes. And in particular, instead of creating the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=8946" target="_blank">02:29:06.400</a></span> | <span class="t">optimizer right here, I'm creating a new configure optimizers function inside the model. And I'm</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=8953" target="_blank">02:29:13.680</a></span> | <span class="t">passing in some of the hyper parameters instead. So let's look at the configure optimizers,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=8958" target="_blank">02:29:18.080</a></span> | <span class="t">which is supposed to return the optimizer object. Okay, so it looks complicated, but it's actually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=8967" target="_blank">02:29:27.680</a></span> | <span class="t">really simple. And it's just, we're just being very careful. And there's a few settings here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=8972" target="_blank">02:29:32.400</a></span> | <span class="t">to go through. The most important thing with respect to this line is that you see there's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=8976" target="_blank">02:29:36.640</a></span> | <span class="t">a weight decay parameter here. And I'm passing that into well, I'm passing that into something</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=8984" target="_blank">02:29:44.960</a></span> | <span class="t">called optim_groups that eventually ends up going into the add_mw optimizer. And the weight decay</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=8990" target="_blank">02:29:50.720</a></span> | <span class="t">that's by default used in add_mw here is 0.01. So it's 10 times lower than what's used in GPT-3</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=8998" target="_blank">02:29:58.160</a></span> | <span class="t">paper here. So the weight decay basically ends up making its way into the add_mw3 optimizer groups.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=9005" target="_blank">02:30:05.200</a></span> | <span class="t">Now what else is going on here in this function? So the two things that are happening here that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=9009" target="_blank">02:30:09.600</a></span> | <span class="t">are important is that I'm splitting up the parameters into those that should be weight</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=9013" target="_blank">02:30:13.920</a></span> | <span class="t">decayed and those that should not be weight decayed. So in particular, it is common to not</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=9018" target="_blank">02:30:18.960</a></span> | <span class="t">weight decay biases and any other sort of one-dimensional tensors. So the one-dimensional</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=9025" target="_blank">02:30:25.840</a></span> | <span class="t">tensors are in the node decay parameters. And these are also things like layer norm,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=9031" target="_blank">02:30:31.760</a></span> | <span class="t">scales, and biases. It doesn't really make sense to weight decay those. You mostly want to weight</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=9036" target="_blank">02:30:36.240</a></span> | <span class="t">decay the weights that participate in matrix multiplications. And you want to potentially</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=9041" target="_blank">02:30:41.920</a></span> | <span class="t">weight decay the embeddings. And we've covered in a previous video why it makes sense to decay</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=9047" target="_blank">02:30:47.760</a></span> | <span class="t">the weights, because you can sort of think of it as a regularization. Because when you're pulling</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=9052" target="_blank">02:30:52.000</a></span> | <span class="t">down on all the weights, you're forcing the optimization to use more of the weights. And</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=9057" target="_blank">02:30:57.200</a></span> | <span class="t">you're not allowing any one of the weights individually to be way too large. You're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=9062" target="_blank">02:31:02.560</a></span> | <span class="t">forcing the network to kind of distribute the work across more channels, because there's sort</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=9067" target="_blank">02:31:07.600</a></span> | <span class="t">of like a pull of gravity on the weights themselves. So that's why we are separating it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=9074" target="_blank">02:31:14.400</a></span> | <span class="t">in those ways here. We're only decaying the embeddings and the matmul participating weights.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=9080" target="_blank">02:31:20.000</a></span> | <span class="t">We're printing the number of parameters that we're decaying and not. Most of the parameters</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=9085" target="_blank">02:31:25.120</a></span> | <span class="t">will be decayed. And then one more thing that we're doing here is I'm doing another optimization here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=9091" target="_blank">02:31:31.920</a></span> | <span class="t">And previous AdamW did not have this option, but later parts of PyTorch introduced it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=9097" target="_blank">02:31:37.840</a></span> | <span class="t">And that's why I'm guarding it with an inspect.signature, which is basically checking</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=9102" target="_blank">02:31:42.320</a></span> | <span class="t">if this fused quark is present inside AdamW. And then if it is present, I'm going to end up using</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=9110" target="_blank">02:31:50.560</a></span> | <span class="t">it and passing it in here. Because some earlier versions do not have fused equals. So here's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=9117" target="_blank">02:31:57.520</a></span> | <span class="t">AdamW fused equals. It did not used to exist and it was added later. And there's some docs here for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=9123" target="_blank">02:32:03.440</a></span> | <span class="t">what's happening. And basically they say that by default, they do not use fused because it is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=9129" target="_blank">02:32:09.440</a></span> | <span class="t">relatively new and we want to give it sufficient bake time. So by default, they don't use fused,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=9133" target="_blank">02:32:13.600</a></span> | <span class="t">but fused is a lot faster when it is available and when you're running on CUDA. And what that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=9138" target="_blank">02:32:18.720</a></span> | <span class="t">does is instead of iterating in a for loop over all the parameter tensors and updating them,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=9145" target="_blank">02:32:25.040</a></span> | <span class="t">that would launch a lot of kernels, right? And so fused just means that all those kernels are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=9150" target="_blank">02:32:30.640</a></span> | <span class="t">fused into a single kernel. You get rid of a lot of overhead and you a single time on all the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=9156" target="_blank">02:32:36.160</a></span> | <span class="t">parameters call a kernel that updates them. And so it's just basically a kernel fusion for the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=9163" target="_blank">02:32:43.440</a></span> | <span class="t">AdamW update instead of iterating over all the tensors. So that's the configure optimizers</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=9169" target="_blank">02:32:49.680</a></span> | <span class="t">function that I like to use. And we can rerun and we're not going to see any major differences from</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=9175" target="_blank">02:32:55.120</a></span> | <span class="t">what we saw before, but we are going to see some prints coming from here. So let's just take a look</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=9180" target="_blank">02:33:00.400</a></span> | <span class="t">at what they look like. So we see that number of decay tensors is 50 and it's most of the primers</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=9187" target="_blank">02:33:07.440</a></span> | <span class="t">and number of non-decay tensors is 98. And these are the biases and the layer norm parameters</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=9191" target="_blank">02:33:11.840</a></span> | <span class="t">mostly. And that's, there's only a hundred thousand of those. So most of it is decayed.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=9197" target="_blank">02:33:17.520</a></span> | <span class="t">And then we are using the fused implementation of AdamW, which will be a lot faster. So if you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=9202" target="_blank">02:33:22.480</a></span> | <span class="t">have it available, I would advise you to use it. I'm not actually a hundred percent sure why they</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=9206" target="_blank">02:33:26.720</a></span> | <span class="t">don't default to it. It seems fairly benign and harmless. And also because we are using the fused</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=9211" target="_blank">02:33:31.920</a></span> | <span class="t">implementation, I think this is why we have dropped, notice that the running time used to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=9218" target="_blank">02:33:38.000</a></span> | <span class="t">be 93 milliseconds per step. And we're now down to 90 milliseconds per step because of using the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=9223" target="_blank">02:33:43.200</a></span> | <span class="t">fused AdamW optimizer. So in a single commit here, we are introducing fused Adam, getting</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=9230" target="_blank">02:33:50.240</a></span> | <span class="t">improvements on the time, and we're adding or changing the weight decay, but we're only weight</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=9236" target="_blank">02:33:56.080</a></span> | <span class="t">decaying the two-dimensional parameters, the embeddings, and the matrices that participate</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=9240" target="_blank">02:34:00.320</a></span> | <span class="t">in the linear. So that is this, and we can take this out. And yeah, that is it for this line.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=9249" target="_blank">02:34:09.440</a></span> | <span class="t">One more quick note before we continue here. I just want to point out that the relationship between</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=9254" target="_blank">02:34:14.000</a></span> | <span class="t">weight decay, learning rate, batch size, the Adam parameters, beta1, beta2, the epsilon, and so on,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=9259" target="_blank">02:34:19.920</a></span> | <span class="t">these are very complicated mathematical relationships in the optimization literature.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=9265" target="_blank">02:34:25.120</a></span> | <span class="t">And for the most part, in this video, I'm just trying to copy paste the settings that OpenAI</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=9270" target="_blank">02:34:30.720</a></span> | <span class="t">used. But this is a complicated topic, quite deep. And yeah, in this video, I just want to copy the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=9276" target="_blank">02:34:36.880</a></span> | <span class="t">parameters because it's a whole different video to really talk about that in detail and give it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=9281" target="_blank">02:34:41.040</a></span> | <span class="t">a proper justice instead of just high-level intuitions. Now, the next thing that I want</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=9285" target="_blank">02:34:45.600</a></span> | <span class="t">to move on to is that this paragraph here, by the way, we're going to turn back around to when we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=9291" target="_blank">02:34:51.360</a></span> | <span class="t">improve our data loader. For now, I want to swing back around to this table,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=9302" target="_blank">02:35:02.000</a></span> | <span class="t">where you will notice that for different models, we, of course, have different hyperparameters</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=9307" target="_blank">02:35:07.760</a></span> | <span class="t">for the transformer that dictate the size of the transformer network. We also have a different</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=9312" target="_blank">02:35:12.160</a></span> | <span class="t">learning rate. So we're seeing the pattern that the bigger networks are trained with slightly</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=9315" target="_blank">02:35:15.600</a></span> | <span class="t">lower learning rates. And we also see this batch size, where in the small networks,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=9321" target="_blank">02:35:21.840</a></span> | <span class="t">they use a smaller batch size, and in the bigger networks, they use a bigger batch size.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=9326" target="_blank">02:35:26.240</a></span> | <span class="t">Now, the problem for us is we can't just use 0.5 million batch size,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=9330" target="_blank">02:35:30.960</a></span> | <span class="t">because if I just try to come in here and I try to set this B, where's my B?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=9336" target="_blank">02:35:36.800</a></span> | <span class="t">B equals...</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=9341" target="_blank">02:35:41.840</a></span> | <span class="t">Where do I call the data loader? Okay, B equals 16. If I try to set...</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=9348" target="_blank">02:35:48.720</a></span> | <span class="t">Well, we have to be careful. It's not 0.5 million, because this is the batch size</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=9354" target="_blank">02:35:54.960</a></span> | <span class="t">in the number of tokens. Every single one of our rows is 1,024 tokens. So 0.5E6,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=9361" target="_blank">02:36:01.840</a></span> | <span class="t">1 million divide 1,024. This would need about a 488 batch size. So the problem is I can't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=9369" target="_blank">02:36:09.440</a></span> | <span class="t">come in here and set this to 488, because my GPU would explode. This would not fit for sure.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=9376" target="_blank">02:36:16.400</a></span> | <span class="t">But we still want to use this batch size, because again, as I mentioned, the batch size is correlated</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=9383" target="_blank">02:36:23.600</a></span> | <span class="t">with all the other optimization hyperparameters and the learning rates and so on. So we want to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=9388" target="_blank">02:36:28.160</a></span> | <span class="t">have a faithful representation of all the hyperparameters, and therefore we need to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=9391" target="_blank">02:36:31.760</a></span> | <span class="t">use a batch size of 0.5 million, roughly. But the question is, how do we use 0.5 million if</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=9398" target="_blank">02:36:38.720</a></span> | <span class="t">we only have a small GPU? Well, for that, we need to use what's called gradient accumulation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=9403" target="_blank">02:36:43.120</a></span> | <span class="t">So we're going to turn to that next, and it allows us to simulate in a serial way</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=9408" target="_blank">02:36:48.400</a></span> | <span class="t">any arbitrary batch size that we set. And so we can do a batch size of 0.5 million. We just have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=9414" target="_blank">02:36:54.400</a></span> | <span class="t">to run longer, and we have to process multiple sequences and basically add up all the gradients</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=9420" target="_blank">02:37:00.720</a></span> | <span class="t">from them to simulate a batch size of 0.5 million. So let's turn to that next.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=9425" target="_blank">02:37:05.440</a></span> | <span class="t">Okay, so I started the implementation right here just by adding these lines of code.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=9428" target="_blank">02:37:08.800</a></span> | <span class="t">And basically what I did is first I set the total batch size that we desire. So this is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=9434" target="_blank">02:37:14.880</a></span> | <span class="t">exactly 0.5 million, and I used a nice number, a power of 2, because 2 to the 19 is 524288,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=9442" target="_blank">02:37:22.560</a></span> | <span class="t">so it's roughly 0.5 million. It's a nice number. Now, our micro-batch size, as we call it now,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=9448" target="_blank">02:37:28.000</a></span> | <span class="t">is 16. So this is going to be -- we still have B by T indices that go into the transformer and do</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=9455" target="_blank">02:37:35.120</a></span> | <span class="t">forward-backward, but we're not going to do an update, right? We're going to do many forward-</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=9458" target="_blank">02:37:38.960</a></span> | <span class="t">backwards. We're going to -- and those gradients are all going to plus equals on the parameter</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=9463" target="_blank">02:37:43.920</a></span> | <span class="t">gradients. They're all going to add up. So we're going to do forward-backward grad-accum-steps</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=9468" target="_blank">02:37:48.960</a></span> | <span class="t">number of times, and then we're going to do a single update once all that is accumulated.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=9473" target="_blank">02:37:53.200</a></span> | <span class="t">So in particular, our micro-batch size is just now controlling how many tokens,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=9478" target="_blank">02:37:58.960</a></span> | <span class="t">how many rows we're processing in a single go of a forward-backward.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=9481" target="_blank">02:38:01.840</a></span> | <span class="t">So here we are doing 16 times 124. We're doing 16384</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=9491" target="_blank">02:38:11.440</a></span> | <span class="t">tokens per forward-backward, and we are supposed to be doing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=9495" target="_blank">02:38:15.120</a></span> | <span class="t">2 to the 19 -- whoops, what am I doing -- 2 to the 19 in total, so the grad-accum will be 32.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=9504" target="_blank">02:38:24.000</a></span> | <span class="t">So therefore, grad-accum here will work out to 32, and we have to do 32 forward-backward</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=9512" target="_blank">02:38:32.560</a></span> | <span class="t">and then a single update. Now, we see that we have about 100 milliseconds for a single</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=9518" target="_blank">02:38:38.320</a></span> | <span class="t">forward-backward, so doing 32 of them will be -- will make every step roughly three seconds,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=9523" target="_blank">02:38:43.680</a></span> | <span class="t">just napkin math. So that's grad-accum-steps, but now we actually have to implement that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=9530" target="_blank">02:38:50.080</a></span> | <span class="t">So we're going to swing over to our training loop, because now this part here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=9535" target="_blank">02:38:55.920</a></span> | <span class="t">and this part here, the forward and the backward, we have to now repeat this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=9541" target="_blank">02:39:01.200</a></span> | <span class="t">32 times before we do everything else that follows. So let's see how we can implement that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=9547" target="_blank">02:39:07.520</a></span> | <span class="t">So let's come over here, and actually, we do have to load a new batch every single time,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=9551" target="_blank">02:39:11.520</a></span> | <span class="t">so let me move that over here, and now this is where we have the inner loop.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=9555" target="_blank">02:39:15.280</a></span> | <span class="t">So for micro-step in range grad-accum-steps, we do this. And remember that last-step-backward</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=9564" target="_blank">02:39:24.720</a></span> | <span class="t">always deposits gradients, so we're doing -- inside last-step-backward, there's always a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=9568" target="_blank">02:39:28.320</a></span> | <span class="t">plus-equals on the gradients. So in every single last-step-backward, gradients will add up on the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=9573" target="_blank">02:39:33.840</a></span> | <span class="t">gradient tensors. So we last-step-backward, and then we get all the gradients over there,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=9581" target="_blank">02:39:41.120</a></span> | <span class="t">and then we normalize, and everything else should just follow. So we're very close,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=9587" target="_blank">02:39:47.840</a></span> | <span class="t">but actually, there's a subtle and deep issue here, and this is actually incorrect.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=9593" target="_blank">02:39:53.280</a></span> | <span class="t">So I invite you to think about why this is not yet sufficient, and let me fix it then.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=9599" target="_blank">02:39:59.520</a></span> | <span class="t">Okay, so I brought back the Jupyter Notebook, so we can think about this carefully</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=9603" target="_blank">02:40:03.280</a></span> | <span class="t">in a simple toy setting and see what's happening. So let's create a very simple</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=9607" target="_blank">02:40:07.840</a></span> | <span class="t">neural net that takes a 16 -- vector of 16 numbers and returns a single number.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=9612" target="_blank">02:40:12.320</a></span> | <span class="t">And then here, I'm creating some random examples x and some targets y, and then we are using the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=9621" target="_blank">02:40:21.520</a></span> | <span class="t">mean-squared loss here to calculate the loss. So basically, what this is, is four individual</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=9628" target="_blank">02:40:28.640</a></span> | <span class="t">examples, and we're just doing simple regression with the mean-squared loss over those four</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=9633" target="_blank">02:40:33.600</a></span> | <span class="t">examples. Now, when we calculate the loss and we last-step-backward and look at the gradient,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=9639" target="_blank">02:40:39.360</a></span> | <span class="t">this is the gradient that we achieve. Now, the loss objective here -- notice that in MSC loss,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=9645" target="_blank">02:40:45.600</a></span> | <span class="t">the default for the loss function is reduction is mean. So we're calculating the average mean loss</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=9652" target="_blank">02:40:52.800</a></span> | <span class="t">here over the four examples. So this is the exact loss objective, and this is the average,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=9661" target="_blank">02:41:01.920</a></span> | <span class="t">the 1/4, because there are four independent examples here. And then we have the four</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=9667" target="_blank">02:41:07.280</a></span> | <span class="t">examples and their mean-squared error -- the squared error, and then this makes it the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=9671" target="_blank">02:41:11.760</a></span> | <span class="t">mean-squared error. So therefore, we calculate the squared error and then we normalize it to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=9678" target="_blank">02:41:18.240</a></span> | <span class="t">make it the mean over the examples, and there's four examples here. So now, when we come to the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=9682" target="_blank">02:41:22.880</a></span> | <span class="t">gradient accumulation version of it, this here is the gradient accumulation version of it,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=9691" target="_blank">02:41:31.200</a></span> | <span class="t">where we have grad-account steps of four, and I reset the gradient, with grad-account steps of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=9696" target="_blank">02:41:36.320</a></span> | <span class="t">four, and now I'm evaluating all the examples individually instead and calling last-step-backward</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=9701" target="_blank">02:41:41.280</a></span> | <span class="t">on them many times, and then we're looking at the gradient that we achieve from that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=9704" target="_blank">02:41:44.640</a></span> | <span class="t">So basically, now we forward our function, calculate the exact same loss, do a backward,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=9710" target="_blank">02:41:50.640</a></span> | <span class="t">and we do that four times, and when we look at the gradient, you'll notice that the gradients</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=9716" target="_blank">02:41:56.000</a></span> | <span class="t">don't match. So here we did a single batch of four, and here we did four gradient accumulation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=9723" target="_blank">02:42:03.600</a></span> | <span class="t">steps of batch size one, and the gradients are not the same. And basically, the reason that they're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=9729" target="_blank">02:42:09.600</a></span> | <span class="t">not the same is exactly because this mean squared error gets lost. This one quarter in this loss</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=9735" target="_blank">02:42:15.600</a></span> | <span class="t">gets lost, because what happens here is the loss objective for every one of the loops</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=9741" target="_blank">02:42:21.760</a></span> | <span class="t">is just a mean squared error, which in this case, because there's only a single example,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=9746" target="_blank">02:42:26.800</a></span> | <span class="t">is just this term here. So that was the loss in the zeroth iteration, the same in the first,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=9751" target="_blank">02:42:31.520</a></span> | <span class="t">third, and so on. And then when you do the last-step-backward, we're accumulating gradients,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=9757" target="_blank">02:42:37.200</a></span> | <span class="t">and what happens is that accumulation in the gradient is basically equivalent</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=9762" target="_blank">02:42:42.160</a></span> | <span class="t">to doing a sum in the loss. So our loss actually here is this without the factor of one quarter</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=9771" target="_blank">02:42:51.840</a></span> | <span class="t">outside of it. So we're missing the normalizer, and therefore our gradients are off. And so the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=9777" target="_blank">02:42:57.360</a></span> | <span class="t">way to fix this, or one of them, is basically we can actually come here and we can say loss equals</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=9782" target="_blank">02:43:02.480</a></span> | <span class="t">loss divide four. And what happens now is that we're scaling our loss, we're introducing a one</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=9790" target="_blank">02:43:10.720</a></span> | <span class="t">quarter in front of all of these places. So all the individual losses are now scaled by one quarter,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=9798" target="_blank">02:43:18.160</a></span> | <span class="t">and then when we backward, all of these accumulate with a sum, but now there's a one quarter inside</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=9804" target="_blank">02:43:24.880</a></span> | <span class="t">every one of these components, and now our losses will be equivalent. So when I run this,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=9811" target="_blank">02:43:31.680</a></span> | <span class="t">you see that the gradients are now identical. So long story short, with this simple example,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=9817" target="_blank">02:43:37.600</a></span> | <span class="t">when you step through it, you can see that basically the reason that this is not correct</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=9822" target="_blank">02:43:42.160</a></span> | <span class="t">is because in the same way as here in the MSC loss, the loss that we're calculating here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=9828" target="_blank">02:43:48.720</a></span> | <span class="t">in the model is using a reduction of mean as well. So where is the loss? F dot cross entropy.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=9839" target="_blank">02:43:59.200</a></span> | <span class="t">And by default, the reduction here in cross entropy is also, I don't know why they don't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=9844" target="_blank">02:44:04.000</a></span> | <span class="t">show it, but it's the mean loss at all the b by t elements, right? So there's a reduction</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=9852" target="_blank">02:44:12.880</a></span> | <span class="t">by mean in there, and if we're just doing this gradient accumulation here, we're missing that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=9857" target="_blank">02:44:17.040</a></span> | <span class="t">And so the way to fix this is to simply compensate for the number of gradient accumulation steps,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=9862" target="_blank">02:44:22.480</a></span> | <span class="t">and we can in the same way divide this loss. So in particular here, the number of steps that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=9866" target="_blank">02:44:26.720</a></span> | <span class="t">we're doing is loss equals loss divided gradient accumulation steps. So even Copilot gets the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=9874" target="_blank">02:44:34.800</a></span> | <span class="t">modification. But in the same way exactly, we are scaling down the loss so that when we do</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=9880" target="_blank">02:44:40.160</a></span> | <span class="t">loss step backward, which basically corresponds to a sum in the objective, we are summing up</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=9885" target="_blank">02:44:45.040</a></span> | <span class="t">the already normalized loss. And therefore, when we sum up the losses divided by grad-accum steps,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=9892" target="_blank">02:44:52.160</a></span> | <span class="t">we are recovering the additional normalizer. And so now these two will be, now this will be</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=9898" target="_blank">02:44:58.960</a></span> | <span class="t">equivalent to the original sort of optimization, because the gradient will come out the same.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=9903" target="_blank">02:45:03.680</a></span> | <span class="t">Okay, so I had to do a few more touch-ups, and I launched the optimization here. So in particular,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=9909" target="_blank">02:45:09.840</a></span> | <span class="t">one thing we want to do, because we want to print things nicely, is, well, first of all, we need to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=9914" target="_blank">02:45:14.880</a></span> | <span class="t">create like an accumulator over the loss. We can't just print the loss, because we'd be printing only</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=9918" target="_blank">02:45:18.960</a></span> | <span class="t">the final loss at the final microstep. So instead, we have loss-accum, which I initialized at zero,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=9924" target="_blank">02:45:24.800</a></span> | <span class="t">and then I accumulate the loss into it. And I'm using detach so that I'm detaching the tensor</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=9932" target="_blank">02:45:32.560</a></span> | <span class="t">from the graph, and I'm just trying to keep track of the values. So I'm making these leaf nodes when</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=9938" target="_blank">02:45:38.720</a></span> | <span class="t">I add them. So that's loss-accum, and then we're printing that here instead of loss.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=9943" target="_blank">02:45:43.840</a></span> | <span class="t">And then in addition to that, I had to account for the grad-accum steps inside the tokens processed,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=9949" target="_blank">02:45:49.120</a></span> | <span class="t">because now the tokens processed per step is b times t times gradient accumulation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=9953" target="_blank">02:45:53.920</a></span> | <span class="t">So long story short, here we have the optimization. It looks reasonable, right? We're starting at a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=9960" target="_blank">02:46:00.800</a></span> | <span class="t">good spot. We calculated the grad-accum steps to be 32, and we're getting about three seconds here,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=9967" target="_blank">02:46:07.280</a></span> | <span class="t">right? And so this looks pretty good. Now, if you'd like to verify that your optimization and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=9977" target="_blank">02:46:17.440</a></span> | <span class="t">the implementation here is correct and you're working on a side, well, now because we have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=9981" target="_blank">02:46:21.120</a></span> | <span class="t">the total batch size and the gradient accumulation steps, our setting of b is purely a performance</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=9986" target="_blank">02:46:26.640</a></span> | <span class="t">optimization kind of setting. So if you have a big GPU, you can actually increase this to 32,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=9992" target="_blank">02:46:32.080</a></span> | <span class="t">and you'll probably go a bit faster. If you have a very small GPU, you can try 8 or 4.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=9996" target="_blank">02:46:36.800</a></span> | <span class="t">But in any case, you should be getting the exact same optimization and the same answers</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=10000" target="_blank">02:46:40.720</a></span> | <span class="t">up to a floating point error, because the gradient accumulation kicks in and can handle everything</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=10007" target="_blank">02:46:47.360</a></span> | <span class="t">serially as necessary. So that's it for gradient accumulation, I think.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=10012" target="_blank">02:46:52.880</a></span> | <span class="t">Okay, so now is the time to bring out the heavy weapons. You've noticed that so far,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=10017" target="_blank">02:46:57.040</a></span> | <span class="t">we've only been using a single GPU for training. But actually, I am paying for eight GPUs here,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=10022" target="_blank">02:47:02.560</a></span> | <span class="t">and so we should be putting all of them to work. And in particular, they're all going to collaborate</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=10027" target="_blank">02:47:07.360</a></span> | <span class="t">and optimize over tokens at the same time and communicate so that they're all kind of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=10035" target="_blank">02:47:15.520</a></span> | <span class="t">collaborating on the optimization. For this, we are going to be using the distributed data parallel</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=10040" target="_blank">02:47:20.160</a></span> | <span class="t">from PyTorch. There's also a legacy data parallel, which I recommend you not use,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=10044" target="_blank">02:47:24.320</a></span> | <span class="t">and that's kind of like legacy. Distributed data parallel works in a very simple way.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=10049" target="_blank">02:47:29.680</a></span> | <span class="t">We have eight GPUs, so we're going to launch eight processes, and each process is going to be</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=10056" target="_blank">02:47:36.240</a></span> | <span class="t">assigned a GPU. And for each process, the training loop and everything we've worked on so far is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=10061" target="_blank">02:47:41.520</a></span> | <span class="t">going to look pretty much the same. Each GPU, as far as it's concerned, is just working on exactly</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=10066" target="_blank">02:47:46.480</a></span> | <span class="t">what we've built so far. But now secretly, there's eight of them, and they're all going to be</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=10071" target="_blank">02:47:51.280</a></span> | <span class="t">processing slightly different parts of the data. And we're going to add one more part, where once</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=10077" target="_blank">02:47:57.440</a></span> | <span class="t">they all calculate their gradients, there's one more part where we do an average of those gradients.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=10082" target="_blank">02:48:02.720</a></span> | <span class="t">And so that's how they're going to be collaborating on the computational workload here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=10088" target="_blank">02:48:08.720</a></span> | <span class="t">So to use all eight of them, we're not going to be launching our script anymore with just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=10094" target="_blank">02:48:14.000</a></span> | <span class="t">PyTorch-train-gpt2.py. We're going to be running it with a special command called "torch run"</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=10100" target="_blank">02:48:20.720</a></span> | <span class="t">in PyTorch. We'll see that in a bit. And torch run, when it runs our Python script,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=10106" target="_blank">02:48:26.720</a></span> | <span class="t">will actually make sure to run eight of them in parallel. And it creates these environmental</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=10113" target="_blank">02:48:33.120</a></span> | <span class="t">variables where each of these processes can look up basically which one of the processes it is.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=10120" target="_blank">02:48:40.400</a></span> | <span class="t">So for example, torch run will set rank, local rank, and world size, environmental variables.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=10126" target="_blank">02:48:46.320</a></span> | <span class="t">And so this is a bad way to detect whether DDP is running. So if we're using torch run,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=10132" target="_blank">02:48:52.960</a></span> | <span class="t">if DDP is running, then we have to make sure that CUDA is available,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=10137" target="_blank">02:48:57.920</a></span> | <span class="t">because I don't know that you can run this on CPU anymore, or that that makes sense to do.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=10142" target="_blank">02:49:02.320</a></span> | <span class="t">This is some setup code here. The important part is that there's a world size, which for us will</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=10150" target="_blank">02:49:10.800</a></span> | <span class="t">be eight. That's the total number of processes running. There's a rank, which is each process</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=10156" target="_blank">02:49:16.960</a></span> | <span class="t">will basically run the exact same code at the exact same time, roughly. But the only difference</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=10163" target="_blank">02:49:23.920</a></span> | <span class="t">between these processes is that they all have a different DDP rank. So the GPU 0 will have DDP</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=10170" target="_blank">02:49:30.960</a></span> | <span class="t">rank of 0, GPU 1 will have rank of 1, etc. So otherwise, they're all running the exact same</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=10177" target="_blank">02:49:37.440</a></span> | <span class="t">script. It's just that DDP rank will be a slightly different integer. And that is the way for us to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=10182" target="_blank">02:49:42.800</a></span> | <span class="t">coordinate that they don't, for example, run on the same data. We want them to run on different</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=10187" target="_blank">02:49:47.360</a></span> | <span class="t">parts of the data, and so on. Now, local rank is something that is only used in a multi-node</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=10193" target="_blank">02:49:53.600</a></span> | <span class="t">setting. We only have a single node with eight GPUs. And so local rank is the rank of the GPU</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=10199" target="_blank">02:49:59.920</a></span> | <span class="t">on a single node. So from 0 to 7, as an example. But for us, we're mostly going to be running on</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=10206" target="_blank">02:50:06.640</a></span> | <span class="t">a single box. So the things we care about are rank and world size. This is 8, and this will be</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=10212" target="_blank">02:50:12.400</a></span> | <span class="t">whatever it is, depending on the GPU, that this particular instantiation of the script runs on.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=10218" target="_blank">02:50:18.400</a></span> | <span class="t">Now, here, we make sure that according to the local rank, we are setting the device</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=10227" target="_blank">02:50:27.200</a></span> | <span class="t">to be CUDA colon. And colon indicates which GPU to use if there are more than one GPUs. So</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=10234" target="_blank">02:50:34.640</a></span> | <span class="t">depending on the local rank of this process, it's going to use just the appropriate GPU. So there's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=10240" target="_blank">02:50:40.640</a></span> | <span class="t">no collisions on which GPU is being used by which process. And finally, there's a boolean variable</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=10245" target="_blank">02:50:45.840</a></span> | <span class="t">that I like to create, which is the DDP rank equals equals zero. So the master process is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=10251" target="_blank">02:50:51.840</a></span> | <span class="t">arbitrarily process number zero, and it does a lot of the printing, logging, checkpointing, etc.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=10257" target="_blank">02:50:57.040</a></span> | <span class="t">And the other processes are thought of mostly as compute processes that are assisting.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=10261" target="_blank">02:51:01.280</a></span> | <span class="t">And so master process zero will have some additional work to do. All the other processes</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=10265" target="_blank">02:51:05.680</a></span> | <span class="t">will almost just be doing forward and backwards. And if we're not using DDP, and none of these</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=10270" target="_blank">02:51:10.640</a></span> | <span class="t">variables are set, we revert back to single GPU training. So that means that we only have rank</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=10275" target="_blank">02:51:15.440</a></span> | <span class="t">zero, the world size is just one. And we are the master process. And we try to auto detect the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=10282" target="_blank">02:51:22.400</a></span> | <span class="t">device. And this is world as normal. So so far, all we've done is we've initialized DDP.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=10288" target="_blank">02:51:28.480</a></span> | <span class="t">And in the case where we're running with Torch run, which we'll see in a bit,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=10294" target="_blank">02:51:34.000</a></span> | <span class="t">there's going to be eight copies running in parallel, each one of them will have a different</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=10297" target="_blank">02:51:37.520</a></span> | <span class="t">rank. And now we have to make sure that everything happens correctly afterwards.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=10302" target="_blank">02:51:42.880</a></span> | <span class="t">So the tricky thing with running multiple processes is you always have to imagine that there's going</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=10308" target="_blank">02:51:48.400</a></span> | <span class="t">to be eight processes running in parallel. So as you read the code, now you have to imagine there's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=10314" target="_blank">02:51:54.240</a></span> | <span class="t">eight, you know, eight Python interpreters running down these lines of code. And the only difference</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=10320" target="_blank">02:52:00.160</a></span> | <span class="t">between them is that they have a different DDP rank. So they all come here, they all pick the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=10325" target="_blank">02:52:05.120</a></span> | <span class="t">exact same seed, they all make all of these calculations, completely unaware of the other</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=10330" target="_blank">02:52:10.160</a></span> | <span class="t">copies running, roughly speaking, right. So they all make the exact same calculations. And now we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=10335" target="_blank">02:52:15.680</a></span> | <span class="t">have to adjust these calculations to take into account that there's actually like a certain</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=10340" target="_blank">02:52:20.960</a></span> | <span class="t">world size and certain ranks. So in particular, these micro batches and sequence links, these are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=10347" target="_blank">02:52:27.280</a></span> | <span class="t">all just per GPU, right. So now there's going to be num processes of them running in parallel.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=10353" target="_blank">02:52:33.600</a></span> | <span class="t">So we have to adjust this, right, because the Gradacom steps now is going to be total batch</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=10359" target="_blank">02:52:39.040</a></span> | <span class="t">size divided by B times T times DDP world size, because each process will do B times T, and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=10369" target="_blank">02:52:49.600</a></span> | <span class="t">there's this many of them. And so in addition to that, we want to make sure that this fits nicely</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=10376" target="_blank">02:52:56.800</a></span> | <span class="t">into total batch size, which for us it will because 16 times 124 times eight GPUs is 131K.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=10384" target="_blank">02:53:04.480</a></span> | <span class="t">And so 524288, this means that our Gradacom will be four with the current settings, right. So</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=10393" target="_blank">02:53:13.680</a></span> | <span class="t">there's going to be 16 times 124 processes in each GPU, and then there's eight GPUs. So we're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=10398" target="_blank">02:53:18.960</a></span> | <span class="t">going to be doing 131,000 tokens in a single forward backward on the eight GPUs.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=10406" target="_blank">02:53:26.240</a></span> | <span class="t">So we want to make sure that this fits nicely so that we can derive a nice gradient accumulation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=10411" target="_blank">02:53:31.520</a></span> | <span class="t">steps. And yeah, let's just adjust the comments here times DDP world size. Okay. So each GPU</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=10423" target="_blank">02:53:43.600</a></span> | <span class="t">calculates this. Now this is where we start to get run into issues, right. So we are each process</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=10429" target="_blank">02:53:49.280</a></span> | <span class="t">going to come by a print, and they're all going to print. So we're going to have eight copies</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=10434" target="_blank">02:53:54.240</a></span> | <span class="t">of these prints. So one way to deal with this is exactly this master process variable that we have.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=10439" target="_blank">02:53:59.360</a></span> | <span class="t">So if master process, then guard this. And that's just so that we just print this a single time,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=10445" target="_blank">02:54:05.760</a></span> | <span class="t">because otherwise, all the processes would have computed the exact same variables. And there's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=10449" target="_blank">02:54:09.600</a></span> | <span class="t">no need to print this eight times. Before getting into the data loader, and we're going to have to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=10455" target="_blank">02:54:15.520</a></span> | <span class="t">refactor it, obviously, maybe at this point is we should do some prints and just take it out for a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=10462" target="_blank">02:54:22.560</a></span> | <span class="t">spin and exit at this point. So import sys and sys.exit and print IMGPU DDP rank. IMGPU DDP rank</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=10480" target="_blank">02:54:40.960</a></span> | <span class="t">and print by. So now let's try to run this and just see how this works. So let's take it for a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=10491" target="_blank">02:54:51.600</a></span> | <span class="t">spin just so we see what it looks like. So normally we used to launch Python train gpt2.py like this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=10497" target="_blank">02:54:57.440</a></span> | <span class="t">Now we're going to run with Torch run, and this is what it looks like. So Torch run standalone,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=10502" target="_blank">02:55:02.400</a></span> | <span class="t">number of processes, for example, is eight for us because we have eight GPUs,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=10505" target="_blank">02:55:05.840</a></span> | <span class="t">and then train gpt2.py. So this is what the command would look like. And Torch run again,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=10512" target="_blank">02:55:12.480</a></span> | <span class="t">we'll run eight of these. So let's just see what happens. So first, it gets a little busy. So</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=10519" target="_blank">02:55:19.600</a></span> | <span class="t">there's a lot going on here. So first of all, there's some warnings from distributed, and I</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=10524" target="_blank">02:55:24.000</a></span> | <span class="t">don't actually know that these mean anything. I think this is just like, the code is setting up</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=10528" target="_blank">02:55:28.640</a></span> | <span class="t">and the processes are coming online. And we're seeing some preliminary failure to collect while</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=10533" target="_blank">02:55:33.440</a></span> | <span class="t">the processes come up. I'm not 100% sure about that. But we start to then get into actual prints.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=10539" target="_blank">02:55:39.920</a></span> | <span class="t">So all the processes went down. And then the first print actually comes from process five,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=10548" target="_blank">02:55:48.720</a></span> | <span class="t">just by chance. And then it printed. So process five basically got here first,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=10553" target="_blank">02:55:53.360</a></span> | <span class="t">it said on process on GPU five by, and then this these prints come from the master process.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=10560" target="_blank">02:56:00.800</a></span> | <span class="t">So process five just finished first, for whatever reason, it just depends on how</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=10565" target="_blank">02:56:05.760</a></span> | <span class="t">the operating system scheduled the processes to run. Then GPU zero ended, then GPU three and two.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=10571" target="_blank">02:56:11.600</a></span> | <span class="t">And then probably process five or something like that has exited.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=10578" target="_blank">02:56:18.080</a></span> | <span class="t">And DDP really doesn't like that, because we didn't properly dispose of the multi GPUs setting.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=10586" target="_blank">02:56:26.240</a></span> | <span class="t">And so process group has not been destroyed before we destruct. So it really doesn't like that. And</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=10592" target="_blank">02:56:32.640</a></span> | <span class="t">in an actual application, we would want to call destroy process group, so that we clean up DDP</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=10598" target="_blank">02:56:38.320</a></span> | <span class="t">properly. And so it doesn't like that too much. And then the rest of the GPUs finish. And that's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=10604" target="_blank">02:56:44.320</a></span> | <span class="t">it. So basically, we can't guarantee when these processes are running is totally arbitrary,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=10608" target="_blank">02:56:48.640</a></span> | <span class="t">but they are running in parallel, we don't want that to be printing. And next up, let's erase this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=10616" target="_blank">02:56:56.080</a></span> | <span class="t">Next up, we want to make sure that when we create data loader light, we need to now make it aware</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=10622" target="_blank">02:57:02.160</a></span> | <span class="t">of this multi process setting, because we don't want all the processes to be loading the exact</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=10628" target="_blank">02:57:08.800</a></span> | <span class="t">same data, we want every process to get its own chunk of data, so that they're all working on</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=10633" target="_blank">02:57:13.360</a></span> | <span class="t">different parts of the data set, of course. So let's adjust that. So one particularly simple</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=10639" target="_blank">02:57:19.040</a></span> | <span class="t">and a naive way to do this is we have to make sure that we pass in the rank and the size</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=10643" target="_blank">02:57:23.840</a></span> | <span class="t">to the data loader. And then we come up here, we see that we now take rank and processes and we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=10650" target="_blank">02:57:30.160</a></span> | <span class="t">save them. Now, the current position will not be zero. Because what we want is we want to stride</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=10657" target="_blank">02:57:37.200</a></span> | <span class="t">out all the processes. So one way to do this is we basically take self.b times self.t, and then</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=10664" target="_blank">02:57:44.080</a></span> | <span class="t">multiply it by the process rank. So process rank zero will start at zero, but process rank one</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=10671" target="_blank">02:57:51.520</a></span> | <span class="t">now starts at b times t process rank two is starts at two times b times t, etc. So that is the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=10678" target="_blank">02:57:58.080</a></span> | <span class="t">initialization. Now we still they still do this identically. But now when we advance, we don't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=10685" target="_blank">02:58:05.200</a></span> | <span class="t">advance by b times t, we advance by b times t times number of processes. Right? So basically,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=10692" target="_blank">02:58:12.400</a></span> | <span class="t">the total number of tokens that we're consuming is b times t times numProcesses. And they all go</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=10700" target="_blank">02:58:20.240</a></span> | <span class="t">off to a different rank. And the position has to advance by the entire chunk. And then here at b</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=10708" target="_blank">02:58:28.240</a></span> | <span class="t">times t times self.numProcesses plus one would be to exceed number of tokens, then we're going to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=10715" target="_blank">02:58:35.120</a></span> | <span class="t">loop. And when we loop, we want to of course, loop in the exact same way. So we sort of like reset</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=10720" target="_blank">02:58:40.800</a></span> | <span class="t">back. So this is the simplest change that I can find for kind of a very simple distributed data</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=10727" target="_blank">02:58:47.920</a></span> | <span class="t">loader like. And you can notice that if process rank is zero, and numProcesses is one, then the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=10734" target="_blank">02:58:54.320</a></span> | <span class="t">whole thing will be identical to what we had before. But now we can have actually multiple</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=10738" target="_blank">02:58:58.080</a></span> | <span class="t">processes running and this should work fine. So that's the data loader. Okay, so next up,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=10746" target="_blank">02:59:06.320</a></span> | <span class="t">once they've all initialized the data loader, they come here and they all create a GPT model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=10751" target="_blank">02:59:11.280</a></span> | <span class="t">So we create eight GPT models on eight processes. But because the seeds are fixed here,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=10757" target="_blank">02:59:17.360</a></span> | <span class="t">they all create the same identical model. They all move it to the device of their rank,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=10762" target="_blank">02:59:22.560</a></span> | <span class="t">and they all compile the model. And because the models are identical, there are eight identical</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=10767" target="_blank">02:59:27.200</a></span> | <span class="t">compilations happening in parallel, but that's okay. Now, none of this changes because that is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=10773" target="_blank">02:59:33.040</a></span> | <span class="t">on a per step basis. And we're currently working kind of within step because we need to just all</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=10779" target="_blank">02:59:39.520</a></span> | <span class="t">the all the changes we're making are kind of like a within step changes. Now, the important thing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=10784" target="_blank">02:59:44.400</a></span> | <span class="t">here is when we construct the model, we actually have a bit of work to do here. GetLogits is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=10789" target="_blank">02:59:49.680</a></span> | <span class="t">deprecated. So create model. We need to actually wrap the model into the distributed data parallel</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=10797" target="_blank">02:59:57.600</a></span> | <span class="t">container. So this is how we wrap the model into the DDP container. And these are the docs for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=10805" target="_blank">03:00:05.440</a></span> | <span class="t">DDP. And they're quite extensive. And there's a lot of caveats and a lot of things to be careful</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=10810" target="_blank">03:00:10.000</a></span> | <span class="t">with because everything complexifies times 10 when multiple processes are involved. But roughly</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=10815" target="_blank">03:00:15.920</a></span> | <span class="t">speaking, this device IDs I believe has to be passed in. Now, unfortunately, the docs for what</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=10820" target="_blank">03:00:20.320</a></span> | <span class="t">device IDs is, is extremely unclear. So when you actually like come here, this comment for what</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=10827" target="_blank">03:00:27.360</a></span> | <span class="t">device IDs is, is roughly nonsensical. But I'm pretty sure it's supposed to be the DDP local</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=10834" target="_blank">03:00:34.400</a></span> | <span class="t">rank. So not the DDP rank, the local rank. So this is what you pass in here. This wraps the model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=10841" target="_blank">03:00:41.840</a></span> | <span class="t">And in particular, what DDP does for you is in a forward pass, it actually behaves identically. So</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=10846" target="_blank">03:00:46.880</a></span> | <span class="t">my understanding of it is nothing should be changed in the forward pass.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=10851" target="_blank">03:00:51.120</a></span> | <span class="t">But in the backward pass, as you are doing the backward pass, in the simplest setting,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=10856" target="_blank">03:00:56.720</a></span> | <span class="t">once the backward pass is over on each independent GPU, each independent GPU has the gradient for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=10863" target="_blank">03:01:03.200</a></span> | <span class="t">all the parameters. And what DDP does for you is once the backward pass is over, it will call</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=10869" target="_blank">03:01:09.040</a></span> | <span class="t">what's called all reduce. And it basically does an average across all the ranks of their gradients.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=10876" target="_blank">03:01:16.720</a></span> | <span class="t">And then it will deposit that average on every single rank. So every single rank will end up</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=10883" target="_blank">03:01:23.040</a></span> | <span class="t">with the average on it. And so basically, that's the communication, it just synchronizes and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=10887" target="_blank">03:01:27.920</a></span> | <span class="t">averages the gradients. And that's what DDP offers you. Now, DDP actually is a little bit more,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=10892" target="_blank">03:01:32.320</a></span> | <span class="t">is a little bit more involved than that, because as you are doing the backward pass through the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=10898" target="_blank">03:01:38.240</a></span> | <span class="t">layers of the transformer, it actually can dispatch communications for the gradient while</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=10903" target="_blank">03:01:43.360</a></span> | <span class="t">the backward pass is still happening. So there's overlap of the communication of the gradients and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=10908" target="_blank">03:01:48.160</a></span> | <span class="t">the synchronization of them and the backward pass. And this is just more efficient to do it that way.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=10915" target="_blank">03:01:55.680</a></span> | <span class="t">So that's what DDP does for you. Forward is unchanged, and backward is mostly unchanged.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=10922" target="_blank">03:02:02.000</a></span> | <span class="t">And we're tacking on this average, as we'll see in a bit. Okay, so now let's go to the optimization.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=10929" target="_blank">03:02:09.120</a></span> | <span class="t">Nothing here changes. Let's go to the optimization here, the inner loop, and think through the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=10933" target="_blank">03:02:13.680</a></span> | <span class="t">synchronization of these gradients in the DDP. So basically, by default, what happens, as I</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=10938" target="_blank">03:02:18.800</a></span> | <span class="t">mentioned, is when you do loss dot backward here, it will do the backward pass, and then it will</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=10943" target="_blank">03:02:23.760</a></span> | <span class="t">synchronize the gradients. The problem here is because of the gradient accumulation steps loop</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=10950" target="_blank">03:02:30.320</a></span> | <span class="t">here, we don't actually want to do the synchronization after every single loss dot backward,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=10956" target="_blank">03:02:36.560</a></span> | <span class="t">because we are just depositing gradients, and we're doing that serially, and we just want them</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=10960" target="_blank">03:02:40.800</a></span> | <span class="t">adding up, and we don't want to synchronize every single time. That would be extremely wasteful.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=10964" target="_blank">03:02:44.960</a></span> | <span class="t">So basically, we want to add them up, and then on the very last — it's only on the very last step,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=10970" target="_blank">03:02:50.880</a></span> | <span class="t">when microstep becomes grad-accum steps minus one, only at that last step do we want to actually do</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=10977" target="_blank">03:02:57.840</a></span> | <span class="t">the all-reduce to average up the gradients. So to do that, we come here, and the official</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=10985" target="_blank">03:03:05.440</a></span> | <span class="t">sanctioned way, by the way, is to do this no-sync context manager. So PyTorch says this is a context</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=10992" target="_blank">03:03:12.560</a></span> | <span class="t">manager to disable gradient synchronization across DDP processes. So within this context,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=10997" target="_blank">03:03:17.280</a></span> | <span class="t">gradients will be accumulated, and basically, when you do no-sync, there will be no communication.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11003" target="_blank">03:03:23.760</a></span> | <span class="t">So they are telling us to do, with DDP no-sync, do the gradient accumulation, accumulate grads,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11010" target="_blank">03:03:30.080</a></span> | <span class="t">and then they are asking us to do DDP again with another input and dot backward. And I just really</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11015" target="_blank">03:03:35.600</a></span> | <span class="t">don't love this. I just really don't like it, the fact that you have to copy-paste your code here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11020" target="_blank">03:03:40.480</a></span> | <span class="t">and use a context manager, and this is just super ugly. So when I went to the source code here,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11024" target="_blank">03:03:44.720</a></span> | <span class="t">you can see that when you enter, you simply toggle this variable,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11030" target="_blank">03:03:50.880</a></span> | <span class="t">this require backward grad sync, and this is being toggled around and changed. And this is the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11038" target="_blank">03:03:58.560</a></span> | <span class="t">variable that basically, if you step through it, is being toggled to determine if the gradient is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11045" target="_blank">03:04:05.200</a></span> | <span class="t">going to be synchronized. So I actually just kind of like to use that directly. So instead, what I</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11050" target="_blank">03:04:10.960</a></span> | <span class="t">like to do is the following. Right here, before the last dot backward, if we are using DDP, then</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11059" target="_blank">03:04:19.680</a></span> | <span class="t">we only want to synchronize, we only want this variable to be true when it is the final iteration.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11069" target="_blank">03:04:29.600</a></span> | <span class="t">In all the other iterations inside the microsteps, we want it to be false. So I just toggle it like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11075" target="_blank">03:04:35.440</a></span> | <span class="t">this. So require backward grad sync should only turn on when the microstep is the last step.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11080" target="_blank">03:04:40.720</a></span> | <span class="t">And so I'm toggling this variable directly, and I hope that that impacts last dot backward,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11088" target="_blank">03:04:48.080</a></span> | <span class="t">and this is a naughty thing to do because they could probably change the DDP and this variable</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11092" target="_blank">03:04:52.640</a></span> | <span class="t">will go away. But for now, I believe this works, and it allows me to avoid the use of context</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11098" target="_blank">03:04:58.160</a></span> | <span class="t">managers and code duplication. I'm just toggling the variable, and then last dot backward will not</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11102" target="_blank">03:05:02.560</a></span> | <span class="t">synchronize most of the steps, and it will synchronize the very last step. And so once</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11106" target="_blank">03:05:06.480</a></span> | <span class="t">this is over, and we come out, every single rank will suddenly magically have the average</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11117" target="_blank">03:05:17.120</a></span> | <span class="t">of all the gradients that were stored on all the ranks. So now we have to think through whether</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11122" target="_blank">03:05:22.800</a></span> | <span class="t">that is what we want, and also if this suffices, and how it works with the loss,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11130" target="_blank">03:05:30.160</a></span> | <span class="t">and what is loss_accum. So let's think through that now. And the problem I'm getting at is that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11135" target="_blank">03:05:35.440</a></span> | <span class="t">we've averaged the gradients, which is great, but the loss_accum has not been impacted yet,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11141" target="_blank">03:05:41.200</a></span> | <span class="t">and this is outside of the DDP container, so that is not being averaged. And so here,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11147" target="_blank">03:05:47.360</a></span> | <span class="t">when we are printing loss_accum, well, presumably we're only going to be printing on the master</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11151" target="_blank">03:05:51.680</a></span> | <span class="t">process, rank 0, and it's just going to be printing the losses that it saw on its process.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11156" target="_blank">03:05:56.480</a></span> | <span class="t">But instead, we want it to print the loss over all the processes and the average of that loss,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11162" target="_blank">03:06:02.240</a></span> | <span class="t">because we did average of gradients, so we want the average of loss as well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11166" target="_blank">03:06:06.240</a></span> | <span class="t">So simply here, after this, this is the code that I've used in the past,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11171" target="_blank">03:06:11.200</a></span> | <span class="t">and instead of loss_eff, we want loss_accum. So if DDP, again, then dist is a PyTorch distributed.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11182" target="_blank">03:06:22.320</a></span> | <span class="t">I import it. Where do I import it? Oh, gosh. So this file is starting to get out of control, huh?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11192" target="_blank">03:06:32.080</a></span> | <span class="t">So import torch.dist, so dist.all_reduce, and we're doing the average on loss_accum.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11201" target="_blank">03:06:41.920</a></span> | <span class="t">And so this loss_accum tensor exists on all the ranks. When we call all_reduce of average,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11206" target="_blank">03:06:46.960</a></span> | <span class="t">it creates the average of those numbers, and it deposits that average on all the ranks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11212" target="_blank">03:06:52.000</a></span> | <span class="t">So all the ranks after this call will now contain loss_accum averaged up.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11218" target="_blank">03:06:58.880</a></span> | <span class="t">And so when we print here on the master process,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11221" target="_blank">03:07:01.120</a></span> | <span class="t">the loss_accum is identical in all the other ranks as well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11223" target="_blank">03:07:03.280</a></span> | <span class="t">So here, if master_process, oops, we want to print like this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11229" target="_blank">03:07:09.360</a></span> | <span class="t">Okay, and finally, we have to be careful, because we're not processing even more tokens.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11234" target="_blank">03:07:14.880</a></span> | <span class="t">So times DDP_world_size, that's the number of tokens that we've processed up above.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11240" target="_blank">03:07:20.640</a></span> | <span class="t">And everything else should be fine.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11247" target="_blank">03:07:27.760</a></span> | <span class="t">The only other thing to be careful with is, as I mentioned, you want to destroy the process group</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11252" target="_blank">03:07:32.160</a></span> | <span class="t">so that we are nice to nickel, and it's not going to DDP,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11256" target="_blank">03:07:36.160</a></span> | <span class="t">and it's not going to complain to us when we exit here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11259" target="_blank">03:07:39.600</a></span> | <span class="t">So that should be it. Let's try to take it for a spin.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11263" target="_blank">03:07:43.840</a></span> | <span class="t">Okay, so I launched the script, and it should be printing here imminently.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11267" target="_blank">03:07:47.840</a></span> | <span class="t">We're now training with eight GPUs at the same time.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11270" target="_blank">03:07:50.320</a></span> | <span class="t">So the gradient accumulation steps is not 32, it is now divide 8, and it's just 4.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11276" target="_blank">03:07:56.000</a></span> | <span class="t">So otherwise, this is what the optimization now looks like.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11280" target="_blank">03:08:00.800</a></span> | <span class="t">And wow, we're going really fast.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11282" target="_blank">03:08:02.320</a></span> | <span class="t">So we're processing 1.5 million tokens per second now.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11288" target="_blank">03:08:08.640</a></span> | <span class="t">So these are some serious numbers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11290" target="_blank">03:08:10.720</a></span> | <span class="t">And the tiny Shakespeare dataset is so tiny that we're just doing like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11293" target="_blank">03:08:13.520</a></span> | <span class="t">so many epochs over it, most likely.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11296" target="_blank">03:08:16.480</a></span> | <span class="t">But this is roughly what it looks like.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11297" target="_blank">03:08:17.840</a></span> | <span class="t">One thing that I had to fix, by the way, is that this was model.configure_optimizers,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11304" target="_blank">03:08:24.320</a></span> | <span class="t">which now doesn't work because model now is a DDP model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11307" target="_blank">03:08:27.440</a></span> | <span class="t">So instead, this has to become raw_model.configure_optimizers,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11312" target="_blank">03:08:32.080</a></span> | <span class="t">where raw_model is something I create here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11315" target="_blank">03:08:35.120</a></span> | <span class="t">So right after I wrap the model into DDP, I have to create the raw_model,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11319" target="_blank">03:08:39.760</a></span> | <span class="t">which in the case of DDP is a model.module,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11323" target="_blank">03:08:43.280</a></span> | <span class="t">is where it stores the raw NM module of GPT-2 as we have it,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11328" target="_blank">03:08:48.320</a></span> | <span class="t">which contains the configure_optimizers function that we want to call.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11332" target="_blank">03:08:52.080</a></span> | <span class="t">So that's one thing that I had to fix.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11334" target="_blank">03:08:54.320</a></span> | <span class="t">Otherwise, this seems to run.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11335" target="_blank">03:08:55.920</a></span> | <span class="t">Now, one thing you'll notice is that when you actually compare this run</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11339" target="_blank">03:08:59.200</a></span> | <span class="t">and the numbers in it to just running a single GPU,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11341" target="_blank">03:09:01.920</a></span> | <span class="t">you'll notice that this is a single GPU run with 32 Gradacom.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11346" target="_blank">03:09:06.640</a></span> | <span class="t">The numbers won't exactly match up.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11348" target="_blank">03:09:08.560</a></span> | <span class="t">And it's kind of a boring reason for why that happens.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11352" target="_blank">03:09:12.800</a></span> | <span class="t">The reason for that is that in the data loader,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11355" target="_blank">03:09:15.360</a></span> | <span class="t">we're basically just iterating through batches in a slightly different way,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11358" target="_blank">03:09:18.320</a></span> | <span class="t">because now we're looking for an entire page of data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11361" target="_blank">03:09:21.200</a></span> | <span class="t">And if that page for all the GPUs,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11364" target="_blank">03:09:24.240</a></span> | <span class="t">if that chunk exceeds the number of tokens, we just loop.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11367" target="_blank">03:09:27.920</a></span> | <span class="t">And so actually the single GPU and the GPU process</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11371" target="_blank">03:09:31.280</a></span> | <span class="t">will end up resetting in a slightly different manner.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11375" target="_blank">03:09:35.200</a></span> | <span class="t">And so our batches are slightly different.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11377" target="_blank">03:09:37.120</a></span> | <span class="t">And so we get slightly different numbers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11378" target="_blank">03:09:38.640</a></span> | <span class="t">But one way to convince yourself that this is okay</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11382" target="_blank">03:09:42.480</a></span> | <span class="t">is just make the total batch size much smaller and the B and a T.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11386" target="_blank">03:09:46.240</a></span> | <span class="t">And then so I think I used 4 times 124 times 8.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11392" target="_blank">03:09:52.000</a></span> | <span class="t">So I used 32768 as a total batch size.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11394" target="_blank">03:09:54.640</a></span> | <span class="t">And then so I made sure that the single GPU</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11398" target="_blank">03:09:58.240</a></span> | <span class="t">will do eight gradient accumulation steps.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11400" target="_blank">03:10:00.400</a></span> | <span class="t">And then I did multi GPU.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11401" target="_blank">03:10:01.600</a></span> | <span class="t">And then you're reducing the boundary effects of the data loader.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11405" target="_blank">03:10:05.120</a></span> | <span class="t">And you'll see that the numbers match up.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11407" target="_blank">03:10:07.120</a></span> | <span class="t">So long story short, we're now going really, really fast.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11410" target="_blank">03:10:10.560</a></span> | <span class="t">The optimization is mostly consistent with GPT-2 and 3 hybrid parameters.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11414" target="_blank">03:10:14.960</a></span> | <span class="t">And we have outgrown our tiny Shakespeare file.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11418" target="_blank">03:10:18.800</a></span> | <span class="t">And we want to upgrade it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11420" target="_blank">03:10:20.160</a></span> | <span class="t">So let's move to that next.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11421" target="_blank">03:10:21.760</a></span> | <span class="t">So let's now take a look at what data sets were used by GPT-2 and GPT-3.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11425" target="_blank">03:10:25.040</a></span> | <span class="t">So GPT-2 used this web text data set that was never released.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11429" target="_blank">03:10:29.520</a></span> | <span class="t">There's an attempt at reproducing it called open web text.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11433" target="_blank">03:10:33.840</a></span> | <span class="t">So basically, roughly speaking, what they say here in the paper is that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11436" target="_blank">03:10:36.880</a></span> | <span class="t">they scraped all outbound links from Reddit.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11439" target="_blank">03:10:39.040</a></span> | <span class="t">And then with at least three karma.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11442" target="_blank">03:10:42.560</a></span> | <span class="t">And that was kind of like their starting point.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11444" target="_blank">03:10:44.160</a></span> | <span class="t">And they collected all the web pages and all the text in them.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11447" target="_blank">03:10:47.520</a></span> | <span class="t">And so this was 45 million links.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11449" target="_blank">03:10:49.760</a></span> | <span class="t">And this ended up being 40 gigabytes of text.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11451" target="_blank">03:10:51.600</a></span> | <span class="t">So that's roughly what GPT-2 says about its data set.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11457" target="_blank">03:10:57.200</a></span> | <span class="t">So it's basically outbound links from Reddit.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11459" target="_blank">03:10:59.040</a></span> | <span class="t">Now, when we go over to GPT-3, there's a training data set section.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11463" target="_blank">03:11:03.360</a></span> | <span class="t">And that's where they start to talk about Common Crawl, which is a lot more used.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11468" target="_blank">03:11:08.720</a></span> | <span class="t">Actually, I think even GPT-2 talked about Common Crawl.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11473" target="_blank">03:11:13.600</a></span> | <span class="t">But basically, it's not a very high quality data set all by itself,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11476" target="_blank">03:11:16.640</a></span> | <span class="t">because it is extremely noisy.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11478" target="_blank">03:11:18.000</a></span> | <span class="t">This is a completely random subset of the internet.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11480" target="_blank">03:11:20.560</a></span> | <span class="t">And it's much worse than you think.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11482" target="_blank">03:11:22.000</a></span> | <span class="t">So people go into great lengths to filter Common Crawl,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11485" target="_blank">03:11:25.040</a></span> | <span class="t">because there's good stuff in it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11486" target="_blank">03:11:26.480</a></span> | <span class="t">But most of it is just like ad spam, random tables and numbers and stock tickers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11491" target="_blank">03:11:31.440</a></span> | <span class="t">And it's just a total mess.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11494" target="_blank">03:11:34.320</a></span> | <span class="t">So that's why people like to train on these data mixtures</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11499" target="_blank">03:11:39.840</a></span> | <span class="t">that they curate and are careful with.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11502" target="_blank">03:11:42.880</a></span> | <span class="t">So a large chunk of these data mixtures typically will be Common Crawl.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11506" target="_blank">03:11:46.400</a></span> | <span class="t">Like, for example, 50% of the tokens will be Common Crawl.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11509" target="_blank">03:11:49.440</a></span> | <span class="t">But then here in GPT-3, they're also using WebText2 from before.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11512" target="_blank">03:11:52.880</a></span> | <span class="t">So that's Reddit outbound.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11514" target="_blank">03:11:54.320</a></span> | <span class="t">But they're also adding, for example, books.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11516" target="_blank">03:11:56.480</a></span> | <span class="t">And they're adding Wikipedia.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11517" target="_blank">03:11:57.840</a></span> | <span class="t">There's many other things you can decide to add.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11519" target="_blank">03:11:59.840</a></span> | <span class="t">Now, this data set for GPT-3 was also never released.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11523" target="_blank">03:12:03.680</a></span> | <span class="t">So today, some of the data sets that I'm familiar with that are quite good</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11526" target="_blank">03:12:06.640</a></span> | <span class="t">and would be representative of something along these lines</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11529" target="_blank">03:12:09.840</a></span> | <span class="t">are, number one, the Red Pajama data set.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11532" target="_blank">03:12:12.400</a></span> | <span class="t">Or more specifically, for example, the Slim Pajama subset of the Red Pajama data set,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11537" target="_blank">03:12:17.520</a></span> | <span class="t">which is a cleaned and deduplicated version of it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11540" target="_blank">03:12:20.160</a></span> | <span class="t">And just to give you a sense, again, it's a bunch of Common Crawl.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11543" target="_blank">03:12:23.440</a></span> | <span class="t">C4, which is also, as far as I know, more Common Crawl, but processed differently.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11549" target="_blank">03:12:29.200</a></span> | <span class="t">And then we have GitHub, Books, Archive, Wikipedia, StackExchange.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11553" target="_blank">03:12:33.600</a></span> | <span class="t">These are the kinds of data sets that would go into these data mixtures.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11556" target="_blank">03:12:36.160</a></span> | <span class="t">Now, specifically the one that I like that came out recently</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11559" target="_blank">03:12:39.680</a></span> | <span class="t">is called FineWebDataset.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11561" target="_blank">03:12:41.520</a></span> | <span class="t">So this is an attempt to basically collect really high-quality Common Crawl data</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11567" target="_blank">03:12:47.760</a></span> | <span class="t">and filter it, in this case, to 15 trillion tokens.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11570" target="_blank">03:12:50.320</a></span> | <span class="t">And then in addition to that, more recently, Hugging Face released this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11574" target="_blank">03:12:54.080</a></span> | <span class="t">FineWebEDU subset, which is 1.3 trillion of educational</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11579" target="_blank">03:12:59.120</a></span> | <span class="t">and 5.4 trillion of high-educational content.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11582" target="_blank">03:13:02.080</a></span> | <span class="t">So basically, they're trying to filter Common Crawl</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11585" target="_blank">03:13:05.200</a></span> | <span class="t">to very high-quality educational subsets.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11588" target="_blank">03:13:08.480</a></span> | <span class="t">And this is the one that we will use.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11590" target="_blank">03:13:10.880</a></span> | <span class="t">There's a long web page here on FineWeb.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11594" target="_blank">03:13:14.240</a></span> | <span class="t">And they go into a ton of detail about how they process the data,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11596" target="_blank">03:13:16.960</a></span> | <span class="t">which is really fascinating reading, by the way.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11599" target="_blank">03:13:19.040</a></span> | <span class="t">And I would definitely recommend, if you're interested</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11600" target="_blank">03:13:20.880</a></span> | <span class="t">into data mixtures and so on, and how data gets processed at these scales,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11604" target="_blank">03:13:24.640</a></span> | <span class="t">look at this page.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11605" target="_blank">03:13:25.760</a></span> | <span class="t">And more specifically, we'll be working with the FineWebEDU, I think.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11609" target="_blank">03:13:29.920</a></span> | <span class="t">And it's basically educational content from the internet.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11615" target="_blank">03:13:35.200</a></span> | <span class="t">They show that training on educational content in their metrics</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11618" target="_blank">03:13:38.640</a></span> | <span class="t">works really, really well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11621" target="_blank">03:13:41.920</a></span> | <span class="t">And we're going to use this sample 10 billion tokens subsample of it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11628" target="_blank">03:13:48.640</a></span> | <span class="t">Because we're not going to be training on trillions of tokens.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11631" target="_blank">03:13:51.040</a></span> | <span class="t">We're just going to train on a 10 billion sample of the FineWebEDU.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11636" target="_blank">03:13:56.160</a></span> | <span class="t">Because empirically, in my previous few experiments,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11638" target="_blank">03:13:58.800</a></span> | <span class="t">this actually suffices to really get close to GPT-2 performance.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11642" target="_blank">03:14:02.400</a></span> | <span class="t">And it's simple enough to work with.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11644" target="_blank">03:14:04.480</a></span> | <span class="t">And so let's work with the sample 10 BT.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11647" target="_blank">03:14:07.600</a></span> | <span class="t">So our goal will be to download it, process it,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11651" target="_blank">03:14:11.440</a></span> | <span class="t">and make sure that our data loader can work with it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11653" target="_blank">03:14:13.840</a></span> | <span class="t">So let's get to that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11655" target="_blank">03:14:15.440</a></span> | <span class="t">Okay, so I introduced another file here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11659" target="_blank">03:14:19.440</a></span> | <span class="t">that will basically download FineWebEDU from Hugging Face datasets.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11663" target="_blank">03:14:23.920</a></span> | <span class="t">It will pre-process and pre-tokenize all of the data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11667" target="_blank">03:14:27.360</a></span> | <span class="t">And it will save data shards to a folder on a local disk.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11674" target="_blank">03:14:34.160</a></span> | <span class="t">And so while this is running, I just wanted to briefly mention</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11679" target="_blank">03:14:39.040</a></span> | <span class="t">that you can kind of look through the dataset viewer here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11681" target="_blank">03:14:41.760</a></span> | <span class="t">just to get a sense of what's in here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11683" target="_blank">03:14:43.440</a></span> | <span class="t">And it's kind of interesting.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11684" target="_blank">03:14:44.400</a></span> | <span class="t">I mean, it basically looks like it's working fairly well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11688" target="_blank">03:14:48.080</a></span> | <span class="t">Like it's talking about nuclear energy in France.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11690" target="_blank">03:14:50.080</a></span> | <span class="t">It's talking about Mexican America, some Mac Pi Js, et cetera.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11697" target="_blank">03:14:57.200</a></span> | <span class="t">So actually, it seems like their filters are working pretty well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11699" target="_blank">03:14:59.840</a></span> | <span class="t">The filters here, by the way, were applied automatically</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11703" target="_blank">03:15:03.280</a></span> | <span class="t">using LLAMA370B, I believe.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11706" target="_blank">03:15:06.320</a></span> | <span class="t">And so basically, LLMs are judging which content is educational</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11710" target="_blank">03:15:10.800</a></span> | <span class="t">and that ends up making it through the filter.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11712" target="_blank">03:15:12.480</a></span> | <span class="t">So that's pretty cool.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11714" target="_blank">03:15:14.320</a></span> | <span class="t">Now, in terms of the script itself,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11715" target="_blank">03:15:15.680</a></span> | <span class="t">I'm not going to go through the full script</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11717" target="_blank">03:15:17.840</a></span> | <span class="t">because it's not as interesting and not as LLM-centric.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11721" target="_blank">03:15:21.520</a></span> | <span class="t">But when you run this, basically, number one,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11723" target="_blank">03:15:23.840</a></span> | <span class="t">we're going to load the dataset,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11725" target="_blank">03:15:25.520</a></span> | <span class="t">which this is all Hugging Face code running this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11728" target="_blank">03:15:28.160</a></span> | <span class="t">You're going to need to pip install datasets.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11731" target="_blank">03:15:31.200</a></span> | <span class="t">So it's downloading the dataset.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11733" target="_blank">03:15:33.200</a></span> | <span class="t">Then it is tokenizing all of the documents inside this dataset.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11737" target="_blank">03:15:37.600</a></span> | <span class="t">Now, when we tokenize the documents,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11739" target="_blank">03:15:39.600</a></span> | <span class="t">you'll notice that to tokenize a single document,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11743" target="_blank">03:15:43.200</a></span> | <span class="t">we first start the tokens with the end of text token.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11748" target="_blank">03:15:48.480</a></span> | <span class="t">And this is a special token in the GPT-2 tokenizer, as you know.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11751" target="_blank">03:15:51.360</a></span> | <span class="t">So 50,256 is the ID of the end of text.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11755" target="_blank">03:15:55.440</a></span> | <span class="t">And this is what begins a document,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11757" target="_blank">03:15:57.040</a></span> | <span class="t">even though it's called end of text.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11758" target="_blank">03:15:58.640</a></span> | <span class="t">But this is the first token that begins a document.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11761" target="_blank">03:16:01.520</a></span> | <span class="t">Then we extend with all of the tokens of that document.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11765" target="_blank">03:16:05.360</a></span> | <span class="t">Then we create a NumPy array out of that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11767" target="_blank">03:16:07.840</a></span> | <span class="t">We make sure that all the tokens are between...</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11771" target="_blank">03:16:11.200</a></span> | <span class="t">Okay, let me debug this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11774" target="_blank">03:16:14.720</a></span> | <span class="t">Okay, so apologies for that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11776" target="_blank">03:16:16.720</a></span> | <span class="t">It just had to do with me using a float division in Python.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11779" target="_blank">03:16:19.600</a></span> | <span class="t">It must be integer division,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11780" target="_blank">03:16:20.960</a></span> | <span class="t">so that this is an int and everything is nice.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11785" target="_blank">03:16:25.520</a></span> | <span class="t">Okay, but basically, the tokenization here is relatively straightforward.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11789" target="_blank">03:16:29.200</a></span> | <span class="t">Returns tokens in mp.un16.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11791" target="_blank">03:16:31.840</a></span> | <span class="t">We're using un.16 to save a little bit of space</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11794" target="_blank">03:16:34.960</a></span> | <span class="t">because 2 to the 16 minus 1 is 65,000.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11799" target="_blank">03:16:39.120</a></span> | <span class="t">So the GPT-2 max token ID is well below that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11802" target="_blank">03:16:42.080</a></span> | <span class="t">And then here, there's a bunch of multiprocessing code.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11805" target="_blank">03:16:45.280</a></span> | <span class="t">And it's honestly not that exciting,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11806" target="_blank">03:16:46.640</a></span> | <span class="t">so I'm not gonna step through it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11808" target="_blank">03:16:48.320</a></span> | <span class="t">But we're loading the dataset, we're tokenizing it,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11811" target="_blank">03:16:51.360</a></span> | <span class="t">and we're saving everything to shards.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11813" target="_blank">03:16:53.760</a></span> | <span class="t">And the shards are NumPy files.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11815" target="_blank">03:16:55.600</a></span> | <span class="t">So just storing a NumPy array,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11818" target="_blank">03:16:58.640</a></span> | <span class="t">which is very, very similar to Torch tensors.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11822" target="_blank">03:17:02.000</a></span> | <span class="t">And the first shard, 000, is a validation shard.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11827" target="_blank">03:17:07.120</a></span> | <span class="t">And all the other shards are training shards.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11830" target="_blank">03:17:10.080</a></span> | <span class="t">And as I mentioned, they all have 100 million tokens in them exactly.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11833" target="_blank">03:17:13.760</a></span> | <span class="t">And that just makes it easier to work with, to shard the files.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11840" target="_blank">03:17:20.320</a></span> | <span class="t">Because if we just have a single massive file,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11842" target="_blank">03:17:22.080</a></span> | <span class="t">sometimes they can be hard to work with on the disk.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11844" target="_blank">03:17:24.720</a></span> | <span class="t">And so sharding it is just kind of a messier from that perspective.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11848" target="_blank">03:17:28.320</a></span> | <span class="t">And yeah, so we'll just let this run.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11851" target="_blank">03:17:31.840</a></span> | <span class="t">This will be probably 30-ish minutes or so.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11856" target="_blank">03:17:36.400</a></span> | <span class="t">And then we're gonna come back to actually train on this data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11859" target="_blank">03:17:39.040</a></span> | <span class="t">And we're gonna be actually doing some legit pre-training in this case.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11861" target="_blank">03:17:41.840</a></span> | <span class="t">This is a good dataset.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11863" target="_blank">03:17:43.680</a></span> | <span class="t">We're doing lots of tokens per second.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11865" target="_blank">03:17:45.840</a></span> | <span class="t">We have eight GPUs, the code is ready.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11868" target="_blank">03:17:48.080</a></span> | <span class="t">And so we're actually gonna be doing a serious training run.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11870" target="_blank">03:17:50.720</a></span> | <span class="t">So let's get back in a bit.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11872" target="_blank">03:17:52.320</a></span> | <span class="t">Okay, so we're back.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11874" target="_blank">03:17:54.000</a></span> | <span class="t">So if we ls edu find_web, we see that there's now 100 shards in it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11879" target="_blank">03:17:59.760</a></span> | <span class="t">And that makes sense because each shard is 100 million tokens.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11884" target="_blank">03:18:04.400</a></span> | <span class="t">So 100 shards of that is 10 billion tokens in total.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11887" target="_blank">03:18:07.360</a></span> | <span class="t">Now, swinging over to the main file,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11889" target="_blank">03:18:09.760</a></span> | <span class="t">I made some adjustments to our data loader again.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11892" target="_blank">03:18:12.480</a></span> | <span class="t">And that's because we're not running with Shakespeare anymore.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11896" target="_blank">03:18:16.000</a></span> | <span class="t">We want to use the find_web shards.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11898" target="_blank">03:18:18.640</a></span> | <span class="t">And so you'll see some code here that additionally basically can load these shards.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11902" target="_blank">03:18:22.640</a></span> | <span class="t">We load the UN16 numpy file.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11906" target="_blank">03:18:26.800</a></span> | <span class="t">We convert it to a torch.long tensor,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11909" target="_blank">03:18:29.520</a></span> | <span class="t">which is what a lot of the layers up top expect by default.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11913" target="_blank">03:18:33.040</a></span> | <span class="t">And then here, we're just enumerating all the shards.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11915" target="_blank">03:18:35.280</a></span> | <span class="t">I also added a split to data_loader_light.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11918" target="_blank">03:18:38.800</a></span> | <span class="t">So we can load the split train, but also the split val, the zero split.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11923" target="_blank">03:18:43.120</a></span> | <span class="t">And then we can load the shards.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11926" target="_blank">03:18:46.080</a></span> | <span class="t">And then here, we also have not just the current position now,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11929" target="_blank">03:18:49.440</a></span> | <span class="t">but also the current shard.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11931" target="_blank">03:18:51.520</a></span> | <span class="t">So we have a position inside a shard.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11933" target="_blank">03:18:53.680</a></span> | <span class="t">And then when we run out of tokens in a single shard,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11937" target="_blank">03:18:57.120</a></span> | <span class="t">we first advance the shard and loop if we need to.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11940" target="_blank">03:19:00.560</a></span> | <span class="t">And then we get the tokens and readjust the position.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11943" target="_blank">03:19:03.360</a></span> | <span class="t">So this data loader will now iterate all the shards as well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11947" target="_blank">03:19:07.520</a></span> | <span class="t">So I changed that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11949" target="_blank">03:19:09.600</a></span> | <span class="t">And then the other thing that I did while the data was processing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11953" target="_blank">03:19:13.520</a></span> | <span class="t">is our train loader now has split train, of course.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11956" target="_blank">03:19:16.560</a></span> | <span class="t">And down here, I set up some numbers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11960" target="_blank">03:19:20.240</a></span> | <span class="t">So we are doing 2 to the 19 tokens per step.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11968" target="_blank">03:19:28.960</a></span> | <span class="t">And we want to do roughly 10 billion tokens,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11973" target="_blank">03:19:33.440</a></span> | <span class="t">because that's how many unique tokens we have.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11976" target="_blank">03:19:36.400</a></span> | <span class="t">So if we did 10 billion tokens, then divide that by 2 to the 19,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11980" target="_blank">03:19:40.080</a></span> | <span class="t">we see that this is 19,073 steps.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11983" target="_blank">03:19:43.600</a></span> | <span class="t">So that's where that's from.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11984" target="_blank">03:19:44.560</a></span> | <span class="t">And then the GPT-3 paper says that they warm up the learning rate over 375 million tokens.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=11990" target="_blank">03:19:50.800</a></span> | <span class="t">So I came here and 375E6 tokens divide 2 to the 19 is 715 steps.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12000" target="_blank">03:20:00.320</a></span> | <span class="t">So that's why warm up steps is set to 715.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12003" target="_blank">03:20:03.040</a></span> | <span class="t">So this will exactly match the warm up schedule that GPT-3 used.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12008" target="_blank">03:20:08.400</a></span> | <span class="t">And I think 715, by the way, is very mild.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12011" target="_blank">03:20:11.600</a></span> | <span class="t">And this could be made significantly more aggressive.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12013" target="_blank">03:20:13.520</a></span> | <span class="t">Probably even like 100 is good enough.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12015" target="_blank">03:20:15.280</a></span> | <span class="t">But it's okay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12017" target="_blank">03:20:17.520</a></span> | <span class="t">Let's leave it for now so that we have the exact hyperparameters of GPT-3.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12020" target="_blank">03:20:20.880</a></span> | <span class="t">So I fixed that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12023" target="_blank">03:20:23.040</a></span> | <span class="t">And then that's pretty much it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12026" target="_blank">03:20:26.160</a></span> | <span class="t">We can run.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12027" target="_blank">03:20:27.840</a></span> | <span class="t">So we have our script here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12029" target="_blank">03:20:29.200</a></span> | <span class="t">And we can launch.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12032" target="_blank">03:20:32.000</a></span> | <span class="t">And actually, sorry, let me do one more thing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12038" target="_blank">03:20:38.000</a></span> | <span class="t">[COUGHS]</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12038" target="_blank">03:20:38.800</a></span> | <span class="t">Excuse me.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12039" target="_blank">03:20:39.360</a></span> | <span class="t">For my GPU, I can actually fit more batch size.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12044" target="_blank">03:20:44.240</a></span> | <span class="t">And I believe I can fit 64 on my GPU as a micro-batch size.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12049" target="_blank">03:20:49.840</a></span> | <span class="t">So let me try that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12051" target="_blank">03:20:51.040</a></span> | <span class="t">I could be misremembering.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12056" target="_blank">03:20:56.880</a></span> | <span class="t">But that means 64 times 124 per GPU.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12059" target="_blank">03:20:59.600</a></span> | <span class="t">And then we have 8 GPUs.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12061" target="_blank">03:21:01.280</a></span> | <span class="t">So that means we would not even be doing gradient accumulation if this fits.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12065" target="_blank">03:21:05.040</a></span> | <span class="t">Because this just multiplies out to the full total batch size.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12069" target="_blank">03:21:09.840</a></span> | <span class="t">So no gradient accumulation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12072" target="_blank">03:21:12.080</a></span> | <span class="t">And that would run pretty quickly if that fits.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12074" target="_blank">03:21:14.880</a></span> | <span class="t">Let's go.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12087" target="_blank">03:21:27.200</a></span> | <span class="t">Let's go.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12087" target="_blank">03:21:27.700</a></span> | <span class="t">I mean, if this works, then this is basically a serious pre-training run.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12091" target="_blank">03:21:31.840</a></span> | <span class="t">We're not logging.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12093" target="_blank">03:21:33.920</a></span> | <span class="t">We're not evaluating the validation split.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12095" target="_blank">03:21:35.680</a></span> | <span class="t">We're not running any evaluations yet.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12097" target="_blank">03:21:37.680</a></span> | <span class="t">So it's not-- we haven't crossed our Ts and dotted our Is.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12101" target="_blank">03:21:41.040</a></span> | <span class="t">But if we let this run for a while, we're going to actually get a pretty good model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12106" target="_blank">03:21:46.400</a></span> | <span class="t">And the model that might even be on par with or better than GPT-124M.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12111" target="_blank">03:21:51.280</a></span> | <span class="t">OK.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12111" target="_blank">03:21:51.780</a></span> | <span class="t">So it looks like everything is going great.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12115" target="_blank">03:21:55.360</a></span> | <span class="t">We're processing 1.5 million tokens per second.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12118" target="_blank">03:21:58.160</a></span> | <span class="t">Everything here looks good.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12123" target="_blank">03:22:03.360</a></span> | <span class="t">We're doing 330 milliseconds per iteration.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12126" target="_blank">03:22:06.880</a></span> | <span class="t">And we have to do a total of-- where are we printing that?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12131" target="_blank">03:22:11.440</a></span> | <span class="t">1973.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12132" target="_blank">03:22:12.800</a></span> | <span class="t">So 19073 times 0.33 is this many seconds, this many minutes.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12140" target="_blank">03:22:20.080</a></span> | <span class="t">So this will run for 1.7 hours.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12143" target="_blank">03:22:23.360</a></span> | <span class="t">So one and a half hour run like this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12148" target="_blank">03:22:28.400</a></span> | <span class="t">And we don't even have to use gradient accumulation, which is nice.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12151" target="_blank">03:22:31.760</a></span> | <span class="t">And you might not have that luxury in your GPU.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12154" target="_blank">03:22:34.160</a></span> | <span class="t">In that case, just start decreasing the batch size until things fit.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12157" target="_blank">03:22:37.520</a></span> | <span class="t">But keep it to nice numbers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12158" target="_blank">03:22:38.800</a></span> | <span class="t">So that's pretty exciting.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12162" target="_blank">03:22:42.240</a></span> | <span class="t">We're currently warming up the learning rate.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12163" target="_blank">03:22:43.760</a></span> | <span class="t">So you see that it's still very low, 1e-4.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12166" target="_blank">03:22:46.640</a></span> | <span class="t">So this will ramp up over the next few steps all the way to 6e-4 here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12173" target="_blank">03:22:53.120</a></span> | <span class="t">Very cool.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12175" target="_blank">03:22:55.280</a></span> | <span class="t">So now what I'd like to do is let's cross the Ts and dot our Is.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12178" target="_blank">03:22:58.640</a></span> | <span class="t">Let's evaluate on the validation split.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12180" target="_blank">03:23:00.880</a></span> | <span class="t">And let's try to figure out how we can run evals, how we can do logging,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12184" target="_blank">03:23:04.640</a></span> | <span class="t">how we can visualize our losses, and all the good stuff.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12187" target="_blank">03:23:07.840</a></span> | <span class="t">So let's get to that before we actually do the run.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12190" target="_blank">03:23:10.960</a></span> | <span class="t">OK, so I've adjusted the code so that we're evaluating on the validation split.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12194" target="_blank">03:23:14.720</a></span> | <span class="t">So creating the val loader just by passing in split equals val,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12198" target="_blank">03:23:18.320</a></span> | <span class="t">that will basically create a data loader just for the validation shard.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12201" target="_blank">03:23:21.920</a></span> | <span class="t">The other thing I did is in the data loader, I introduced a new function reset,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12207" target="_blank">03:23:27.920</a></span> | <span class="t">which is called at init.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12209" target="_blank">03:23:29.440</a></span> | <span class="t">And it basically resets the data loader.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12211" target="_blank">03:23:31.600</a></span> | <span class="t">And that is very useful because when we come to the main training loop now--</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12215" target="_blank">03:23:35.360</a></span> | <span class="t">so this is the code that I've added.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12217" target="_blank">03:23:37.920</a></span> | <span class="t">And basically, every 100th iteration, including the 0th iteration,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12222" target="_blank">03:23:42.640</a></span> | <span class="t">we put the model into evaluation mode.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12225" target="_blank">03:23:45.120</a></span> | <span class="t">We reset the val loader.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12226" target="_blank">03:23:46.480</a></span> | <span class="t">And then no gradients involved.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12230" target="_blank">03:23:50.400</a></span> | <span class="t">We're going to basically accumulate the gradients over, say, 20 steps.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12236" target="_blank">03:23:56.720</a></span> | <span class="t">And then average it all up and print out the validation loss.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12239" target="_blank">03:23:59.200</a></span> | <span class="t">And so that basically is the exact same logic as the training loop, roughly.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12245" target="_blank">03:24:05.680</a></span> | <span class="t">But there's no loss that backward.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12247" target="_blank">03:24:07.360</a></span> | <span class="t">It's only inference.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12248" target="_blank">03:24:08.240</a></span> | <span class="t">We're just measuring the loss.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12249" target="_blank">03:24:09.360</a></span> | <span class="t">We're adding it up.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12250" target="_blank">03:24:10.400</a></span> | <span class="t">Everything else otherwise applies.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12252" target="_blank">03:24:12.160</a></span> | <span class="t">And it's exactly as we've seen it before.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12254" target="_blank">03:24:14.320</a></span> | <span class="t">And so this will print the validation loss every 100th iteration,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12258" target="_blank">03:24:18.560</a></span> | <span class="t">including the very first iteration.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12260" target="_blank">03:24:20.080</a></span> | <span class="t">So that's nice.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12262" target="_blank">03:24:22.160</a></span> | <span class="t">That will tell us a little bit about how much we're overfitting.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12266" target="_blank">03:24:26.560</a></span> | <span class="t">That said, we have roughly infinity data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12269" target="_blank">03:24:29.760</a></span> | <span class="t">So we're mostly expecting our train and val loss to be about the same.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12272" target="_blank">03:24:32.880</a></span> | <span class="t">But the other reason I'm interested in this is because we can take the GPT-2-124M</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12277" target="_blank">03:24:37.760</a></span> | <span class="t">as OpenAI released it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12279" target="_blank">03:24:39.280</a></span> | <span class="t">We can initialize from it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12280" target="_blank">03:24:40.800</a></span> | <span class="t">And we can basically see what kind of loss it achieves on the validation loss as well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12284" target="_blank">03:24:44.480</a></span> | <span class="t">And that gives us an indication as to how much that model would generalize to 124M.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12289" target="_blank">03:24:49.840</a></span> | <span class="t">But it's not-- sorry, to fine web EDU validation split.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12294" target="_blank">03:24:54.080</a></span> | <span class="t">That said, it's not a super fair comparison to GPT-2</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12296" target="_blank">03:24:56.640</a></span> | <span class="t">because it was trained on a very different data distribution.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12298" target="_blank">03:24:58.960</a></span> | <span class="t">But it's still kind of like an interesting data point.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12300" target="_blank">03:25:00.960</a></span> | <span class="t">And in any case, you would always want to have a validation split in a training run like this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12306" target="_blank">03:25:06.800</a></span> | <span class="t">so that you can make sure that you are not overfitting.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12310" target="_blank">03:25:10.960</a></span> | <span class="t">And this is especially a concern if we were to make more epochs in our training data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12315" target="_blank">03:25:15.440</a></span> | <span class="t">So for example, right now, we're just doing a single epoch.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12319" target="_blank">03:25:19.120</a></span> | <span class="t">But if we get to a point where we want to train on 10 epochs or something like that,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12322" target="_blank">03:25:22.640</a></span> | <span class="t">we would be really careful with-- maybe we are memorizing that data too much</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12327" target="_blank">03:25:27.360</a></span> | <span class="t">if we have a big enough model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12328" target="_blank">03:25:28.560</a></span> | <span class="t">And our validation split would be one way to tell whether that is happening.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12332" target="_blank">03:25:32.800</a></span> | <span class="t">OK, and in addition to that, if you remember, at the bottom of our script,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12336" target="_blank">03:25:36.000</a></span> | <span class="t">we had all of this orphaned code for sampling from way back when.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12339" target="_blank">03:25:39.440</a></span> | <span class="t">So I deleted that code.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12340" target="_blank">03:25:40.720</a></span> | <span class="t">And I moved it up to here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12343" target="_blank">03:25:43.520</a></span> | <span class="t">So once in a while, we sample a validation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12346" target="_blank">03:25:46.640</a></span> | <span class="t">Once in a while, we sample-- we generate samples.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12350" target="_blank">03:25:50.640</a></span> | <span class="t">And then we do that only every 100 steps.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12353" target="_blank">03:25:53.920</a></span> | <span class="t">And we train on every single step.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12355" target="_blank">03:25:55.920</a></span> | <span class="t">So that's how I have a structure right now.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12357" target="_blank">03:25:57.360</a></span> | <span class="t">And I've been running this for 1,000 iterations.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12360" target="_blank">03:26:00.000</a></span> | <span class="t">So here are some samples on iteration 1,000.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12361" target="_blank">03:26:01.920</a></span> | <span class="t">Hello, I'm a language model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12366" target="_blank">03:26:06.800</a></span> | <span class="t">And I'm not able to get more creative.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12368" target="_blank">03:26:08.320</a></span> | <span class="t">I'm a language model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12370" target="_blank">03:26:10.640</a></span> | <span class="t">And languages file you're learning about here is-- or is the beginning of a computer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12374" target="_blank">03:26:14.480</a></span> | <span class="t">OK, so this is all pretty-- there's still a garble.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12380" target="_blank">03:26:20.640</a></span> | <span class="t">But we're only at iteration 1,000.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12382" target="_blank">03:26:22.800</a></span> | <span class="t">And we've only just barely reached the maximum learning rate.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12385" target="_blank">03:26:25.840</a></span> | <span class="t">So this is still learning.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12387" target="_blank">03:26:27.280</a></span> | <span class="t">We're about to get some more samples coming up in 1,100.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12391" target="_blank">03:26:31.280</a></span> | <span class="t">OK, this is-- the model is still a young baby.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12399" target="_blank">03:26:39.680</a></span> | <span class="t">OK, so basically, all of this sampling code that I've put here,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12405" target="_blank">03:26:45.280</a></span> | <span class="t">everything should be familiar to you and came from before.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12408" target="_blank">03:26:48.080</a></span> | <span class="t">The only thing that I did is I created a generator object in PyTorch</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12411" target="_blank">03:26:51.840</a></span> | <span class="t">so that I have a direct control over the sampling of the random numbers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12415" target="_blank">03:26:55.920</a></span> | <span class="t">Because I don't want to impact the RNG state of the random number generator</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12420" target="_blank">03:27:00.320</a></span> | <span class="t">that is the global one used for training.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12422" target="_blank">03:27:02.800</a></span> | <span class="t">I want this to be completely outside of the training loop.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12425" target="_blank">03:27:05.040</a></span> | <span class="t">And so I'm using a special sampling RNG.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12428" target="_blank">03:27:08.240</a></span> | <span class="t">And then I make sure to seed it, that every single rank has a different seed.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12433" target="_blank">03:27:13.280</a></span> | <span class="t">And then I pass in here, where we sort of consume random numbers in multinomial,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12438" target="_blank">03:27:18.240</a></span> | <span class="t">where the sampling happens.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12439" target="_blank">03:27:19.760</a></span> | <span class="t">I make sure to pass in the generator object there.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12442" target="_blank">03:27:22.240</a></span> | <span class="t">Otherwise, this is identical.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12443" target="_blank">03:27:23.440</a></span> | <span class="t">Now, the other thing is you'll notice that we're running a bit slower.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12448" target="_blank">03:27:28.160</a></span> | <span class="t">That's because I actually had to disable torch.compile to get this to sample.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12452" target="_blank">03:27:32.240</a></span> | <span class="t">And so we're running a bit slower.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12455" target="_blank">03:27:35.120</a></span> | <span class="t">So for some reason, it works with no torch.compile.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12457" target="_blank">03:27:37.040</a></span> | <span class="t">But when I torch.compile my model, I get a really scary error from PyTorch.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12460" target="_blank">03:27:40.800</a></span> | <span class="t">And I have no idea how to resolve it right now.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12462" target="_blank">03:27:42.800</a></span> | <span class="t">So probably by the time you see this code released or something like that, maybe it's fixed.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12467" target="_blank">03:27:47.120</a></span> | <span class="t">But for now, I'm just going to do end false.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12469" target="_blank">03:27:49.280</a></span> | <span class="t">And I'm going to bring back torch.compile.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12472" target="_blank">03:27:52.400</a></span> | <span class="t">And you're not going to get samples.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12473" target="_blank">03:27:53.760</a></span> | <span class="t">And I think I'll fix this later.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12476" target="_blank">03:27:56.720</a></span> | <span class="t">By the way, I will be releasing all this code.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12480" target="_blank">03:28:00.480</a></span> | <span class="t">And actually, I've been very careful about making git commits every time we add something.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12484" target="_blank">03:28:04.960</a></span> | <span class="t">And so I'm going to release the entire repo that starts completely from scratch,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12488" target="_blank">03:28:08.960</a></span> | <span class="t">all the way to now and after this as well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12492" target="_blank">03:28:12.560</a></span> | <span class="t">And so everything should be exactly documented in the git commit history.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12495" target="_blank">03:28:15.440</a></span> | <span class="t">And so I think that will be nice.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12498" target="_blank">03:28:18.720</a></span> | <span class="t">So hopefully, by the time you go to GitHub, this is removed and it's working.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12502" target="_blank">03:28:22.160</a></span> | <span class="t">And I will have fixed the bug.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12503" target="_blank">03:28:23.840</a></span> | <span class="t">OK, so I have the optimization running here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12505" target="_blank">03:28:25.600</a></span> | <span class="t">And it's stepping and we're on step 6,000 or so.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12508" target="_blank">03:28:28.800</a></span> | <span class="t">So we're about 30% through training.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12510" target="_blank">03:28:30.960</a></span> | <span class="t">Now, while this is training, I would like to introduce one evaluation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12514" target="_blank">03:28:34.000</a></span> | <span class="t">that we're going to use to supplement the validation set.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12516" target="_blank">03:28:36.480</a></span> | <span class="t">And that is the Hellaswag eval.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12519" target="_blank">03:28:39.840</a></span> | <span class="t">So Hellaswag comes from this paper back in 2019.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12523" target="_blank">03:28:43.360</a></span> | <span class="t">So it's a five-year-old eval now.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12524" target="_blank">03:28:44.800</a></span> | <span class="t">And the way Hellaswag works is there's basically a sentence completion data set.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12529" target="_blank">03:28:49.680</a></span> | <span class="t">So it's a multiple choice.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12531" target="_blank">03:28:51.520</a></span> | <span class="t">For every one of these questions, we have basically a shared context,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12536" target="_blank">03:28:56.080</a></span> | <span class="t">like a woman is outside with a bucket and a dog.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12538" target="_blank">03:28:58.960</a></span> | <span class="t">The dog is running around trying to avoid bath.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12541" target="_blank">03:29:01.600</a></span> | <span class="t">She, A, rinses the bucket off with soap and blow dry the dog's head.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12547" target="_blank">03:29:07.360</a></span> | <span class="t">B, uses a hose to keep it from getting soapy.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12549" target="_blank">03:29:09.760</a></span> | <span class="t">C, gets the dog wet and it runs away again.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12552" target="_blank">03:29:12.880</a></span> | <span class="t">Or D, gets into a bathtub with the dog.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12555" target="_blank">03:29:15.920</a></span> | <span class="t">And so basically, the idea is that these multiple choice are constructed</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12561" target="_blank">03:29:21.040</a></span> | <span class="t">so that one of them is a natural continuation of the sentence and the others are not.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12569" target="_blank">03:29:29.120</a></span> | <span class="t">And the others might not make sense, like uses the hose to keep it from getting soapy.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12574" target="_blank">03:29:34.640</a></span> | <span class="t">That makes no sense.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12575" target="_blank">03:29:35.840</a></span> | <span class="t">And so what happens is that models that are not trained very well</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12579" target="_blank">03:29:39.360</a></span> | <span class="t">are not able to tell these apart.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12581" target="_blank">03:29:41.520</a></span> | <span class="t">But models that have a lot of world knowledge and can tell a lot about the world</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12588" target="_blank">03:29:48.400</a></span> | <span class="t">will be able to create these completions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12590" target="_blank">03:29:50.960</a></span> | <span class="t">And these sentences are sourced from ActivityNet and from Wikihow.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12595" target="_blank">03:29:55.760</a></span> | <span class="t">And at the bottom of the paper, there's kind of like a cool chart</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12603" target="_blank">03:30:03.200</a></span> | <span class="t">of the kinds of domains in Wikihow.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12605" target="_blank">03:30:05.280</a></span> | <span class="t">So there's a lot of sentences from computers and electronics and homes and garden.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12609" target="_blank">03:30:09.840</a></span> | <span class="t">And it has kind of a broad coverage of the kinds of things</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12613" target="_blank">03:30:13.040</a></span> | <span class="t">you need to know about the world in order to find the most likely completion</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12617" target="_blank">03:30:17.120</a></span> | <span class="t">and the identity of that completion.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12621" target="_blank">03:30:21.120</a></span> | <span class="t">One more thing that's kind of interesting about Hellaswag is the way it was constructed</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12625" target="_blank">03:30:25.920</a></span> | <span class="t">is that the incorrect options are deliberately adversarially sourced.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12634" target="_blank">03:30:34.240</a></span> | <span class="t">So they're not just random sentences.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12636" target="_blank">03:30:36.400</a></span> | <span class="t">They're actually sentences generated by language models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12639" target="_blank">03:30:39.120</a></span> | <span class="t">And they're generated in such a way that language models basically find them difficult,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12643" target="_blank">03:30:43.040</a></span> | <span class="t">but humans find them easy.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12645" target="_blank">03:30:45.040</a></span> | <span class="t">And so they mentioned that humans have a 95% accuracy on this set.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12648" target="_blank">03:30:48.800</a></span> | <span class="t">But at the time, the state-of-the-art language models had only 48%.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12652" target="_blank">03:30:52.000</a></span> | <span class="t">And so at the time, this was a good benchmark.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12654" target="_blank">03:30:54.800</a></span> | <span class="t">Now, you can read the details of this paper to learn more.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12659" target="_blank">03:30:59.200</a></span> | <span class="t">The thing to point out, though, is that this is five years ago.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12662" target="_blank">03:31:02.880</a></span> | <span class="t">And since then, what happened to Hellaswag is that it's been totally just solved.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12670" target="_blank">03:31:10.080</a></span> | <span class="t">And so now the language models here are 96%.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12673" target="_blank">03:31:13.040</a></span> | <span class="t">So basically, the last 4% is probably errors in the data set,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12677" target="_blank">03:31:17.120</a></span> | <span class="t">or the questions are really, really hard.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12679" target="_blank">03:31:19.360</a></span> | <span class="t">And so basically, this data set is kind of crushed with respect to language models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12682" target="_blank">03:31:22.560</a></span> | <span class="t">But back then, the best language model was only at about 50%.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12684" target="_blank">03:31:24.960</a></span> | <span class="t">But this is how far things got.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12689" target="_blank">03:31:29.440</a></span> | <span class="t">But still, the reason people like Hellaswag, and it's not used, by the way, in GPT-2,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12695" target="_blank">03:31:35.360</a></span> | <span class="t">but in GPT-3, there is Hellaswag eval.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12698" target="_blank">03:31:38.800</a></span> | <span class="t">And lots of people use Hellaswag.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12700" target="_blank">03:31:40.480</a></span> | <span class="t">And so for GPT-3, we have results here that are cited.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12707" target="_blank">03:31:47.440</a></span> | <span class="t">So we know what percent accuracies GPT-3 attains</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12711" target="_blank">03:31:51.200</a></span> | <span class="t">at all these different model checkpoints for Hellaswag eval.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12714" target="_blank">03:31:54.320</a></span> | <span class="t">And the reason people like it is because Hellaswag is a smooth eval.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12719" target="_blank">03:31:59.360</a></span> | <span class="t">And it is an eval that offers, quote, unquote, early signal.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12722" target="_blank">03:32:02.640</a></span> | <span class="t">So early signal means that even small language models</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12726" target="_blank">03:32:06.320</a></span> | <span class="t">are going to start at the random chance of 25%.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12729" target="_blank">03:32:09.120</a></span> | <span class="t">But they're going to slowly improve.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12731" target="_blank">03:32:11.120</a></span> | <span class="t">And you're going to see 25, 26, 27, et cetera.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12733" target="_blank">03:32:13.920</a></span> | <span class="t">And you can see slow improvement, even when the models are very small, and it's very early.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12740" target="_blank">03:32:20.160</a></span> | <span class="t">So it's smooth.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12741" target="_blank">03:32:21.200</a></span> | <span class="t">It has early signal.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12744" target="_blank">03:32:24.080</a></span> | <span class="t">And it's been around for a long time.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12746" target="_blank">03:32:26.800</a></span> | <span class="t">So that's why people kind of like this eval.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12749" target="_blank">03:32:29.440</a></span> | <span class="t">Now, the way that we're going to evaluate this is as follows.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12754" target="_blank">03:32:34.240</a></span> | <span class="t">As I mentioned, we have a shared context.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12758" target="_blank">03:32:38.240</a></span> | <span class="t">And this is kind of like a multiple choice task.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12760" target="_blank">03:32:40.560</a></span> | <span class="t">But instead of giving the model a multiple choice question</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12763" target="_blank">03:32:43.280</a></span> | <span class="t">and asking it for A, B, C, or D, we can't do that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12766" target="_blank">03:32:46.960</a></span> | <span class="t">Because these models, when they are so small, as we are seeing here,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12770" target="_blank">03:32:50.320</a></span> | <span class="t">the models can't actually do multiple choice.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12772" target="_blank">03:32:52.320</a></span> | <span class="t">They don't understand the concept of associating a label</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12775" target="_blank">03:32:55.520</a></span> | <span class="t">to one of the options of multiple choice.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12777" target="_blank">03:32:57.360</a></span> | <span class="t">They don't understand that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12779" target="_blank">03:32:59.120</a></span> | <span class="t">So we have to give it to them in a native form.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12781" target="_blank">03:33:01.360</a></span> | <span class="t">And the native form is a token completion.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12783" target="_blank">03:33:03.920</a></span> | <span class="t">So here's what we do.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12785" target="_blank">03:33:05.520</a></span> | <span class="t">We construct a batch of four rows and T tokens, whatever that T happens to be.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12791" target="_blank">03:33:11.440</a></span> | <span class="t">Then the shared context, that is basically the context for the four choices,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12796" target="_blank">03:33:16.400</a></span> | <span class="t">the tokens of that are shared across all of the rows.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12800" target="_blank">03:33:20.080</a></span> | <span class="t">And then we have the four options.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12802" target="_blank">03:33:22.240</a></span> | <span class="t">So we kind of like lay them out.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12804" target="_blank">03:33:24.400</a></span> | <span class="t">And then only one of the options is correct.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12806" target="_blank">03:33:26.000</a></span> | <span class="t">In this case, label 3, option 3.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12808" target="_blank">03:33:28.000</a></span> | <span class="t">And so this is the correct option.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12811" target="_blank">03:33:31.360</a></span> | <span class="t">And option 1, 2 are incorrect.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12813" target="_blank">03:33:33.040</a></span> | <span class="t">Now, these options might be of different lengths.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12817" target="_blank">03:33:37.200</a></span> | <span class="t">So what we do is we sort of like take the longest length.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12819" target="_blank">03:33:39.760</a></span> | <span class="t">And that's the size of the batch, B by T.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12822" target="_blank">03:33:42.400</a></span> | <span class="t">And then some of these here are going to be padded dimensions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12826" target="_blank">03:33:46.800</a></span> | <span class="t">So they're going to be unused.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12828" target="_blank">03:33:48.400</a></span> | <span class="t">And so we need the tokens.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12831" target="_blank">03:33:51.280</a></span> | <span class="t">We need the correct label.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12832" target="_blank">03:33:52.560</a></span> | <span class="t">And we need a mask that tells us which tokens are active.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12836" target="_blank">03:33:56.480</a></span> | <span class="t">And the mask is then 0 for these padded areas.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12839" target="_blank">03:33:59.920</a></span> | <span class="t">So that's how we construct these batches.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12842" target="_blank">03:34:02.960</a></span> | <span class="t">And then in order to get the language model to predict A, B, C, or D,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12847" target="_blank">03:34:07.280</a></span> | <span class="t">the way this works is basically we're just going to look at the tokens,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12850" target="_blank">03:34:10.880</a></span> | <span class="t">their probabilities.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12852" target="_blank">03:34:12.320</a></span> | <span class="t">And we're going to pick the option that gets the lowest</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12856" target="_blank">03:34:16.080</a></span> | <span class="t">or the highest average probability for the token.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12861" target="_blank">03:34:21.120</a></span> | <span class="t">So for the tokens, because that is the most likely completion</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12865" target="_blank">03:34:25.920</a></span> | <span class="t">according to the language model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12867" target="_blank">03:34:27.200</a></span> | <span class="t">So we're just going to look at the probabilities here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12871" target="_blank">03:34:31.440</a></span> | <span class="t">and average them up across the options</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12875" target="_blank">03:34:35.040</a></span> | <span class="t">and pick the one with the highest probability, roughly speaking.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12878" target="_blank">03:34:38.000</a></span> | <span class="t">So this is how we're going to do Hellaswag.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12880" target="_blank">03:34:40.960</a></span> | <span class="t">And this is, I believe, also how GPT-3 did it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12889" target="_blank">03:34:49.200</a></span> | <span class="t">This is how GPT-3 did it, as far as I know.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12891" target="_blank">03:34:51.680</a></span> | <span class="t">But you should note that some of the other evals</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12893" target="_blank">03:34:53.920</a></span> | <span class="t">where you might see Hellaswag may not do it this way.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12896" target="_blank">03:34:56.880</a></span> | <span class="t">They may do it in a multiple choice format</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12898" target="_blank">03:34:58.560</a></span> | <span class="t">where you sort of give the context a single time</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12902" target="_blank">03:35:02.080</a></span> | <span class="t">and then the four completions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12903" target="_blank">03:35:03.680</a></span> | <span class="t">And so the model is able to see all the four options</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12906" target="_blank">03:35:06.160</a></span> | <span class="t">before it picks the best possible option.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12908" target="_blank">03:35:08.480</a></span> | <span class="t">And that's actually an easier task for a model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12910" target="_blank">03:35:10.880</a></span> | <span class="t">because you get to see the other options when you're picking your choice.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12914" target="_blank">03:35:14.240</a></span> | <span class="t">But unfortunately, models at our size can't do that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12917" target="_blank">03:35:17.760</a></span> | <span class="t">Only models at a bigger size are able to do that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12920" target="_blank">03:35:20.640</a></span> | <span class="t">And so our models are actually slightly handicapped in this way</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12924" target="_blank">03:35:24.240</a></span> | <span class="t">that they are not going to see the other options.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12926" target="_blank">03:35:26.160</a></span> | <span class="t">They're only going to see one option at a time</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12928" target="_blank">03:35:28.880</a></span> | <span class="t">and they just have to assign probabilities</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12930" target="_blank">03:35:30.880</a></span> | <span class="t">and the correct option has to win out in this metric.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12933" target="_blank">03:35:33.200</a></span> | <span class="t">All right, so let's now implement this very briefly</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12936" target="_blank">03:35:36.800</a></span> | <span class="t">and incorporate it into our script.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12938" target="_blank">03:35:38.400</a></span> | <span class="t">Okay, so what I've done here is I've introduced a new file</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12941" target="_blank">03:35:41.600</a></span> | <span class="t">called Hellaswag.py that you can take a look into.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12944" target="_blank">03:35:44.880</a></span> | <span class="t">And I'm not going to step through all of it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12946" target="_blank">03:35:46.560</a></span> | <span class="t">because this is not exactly like deep code.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12950" target="_blank">03:35:50.880</a></span> | <span class="t">It's kind of like a little bit tedious, honestly,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12952" target="_blank">03:35:52.880</a></span> | <span class="t">because what's happening is I'm downloading Hellaswag from GitHub</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12956" target="_blank">03:35:56.400</a></span> | <span class="t">and I'm rendering all of its examples.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12958" target="_blank">03:35:58.160</a></span> | <span class="t">And there are a total of 10,000 examples.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12960" target="_blank">03:36:00.160</a></span> | <span class="t">I am rendering them into this format.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12962" target="_blank">03:36:02.640</a></span> | <span class="t">And so here at the end of this render example function,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12968" target="_blank">03:36:08.800</a></span> | <span class="t">you can see that I'm returning the tokens.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12972" target="_blank">03:36:12.080</a></span> | <span class="t">The tokens of this four by T array of tokens,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12977" target="_blank">03:36:17.920</a></span> | <span class="t">the mask, which tells us which parts are the options</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12980" target="_blank">03:36:20.800</a></span> | <span class="t">and everything else is zero,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12982" target="_blank">03:36:22.480</a></span> | <span class="t">and the label that is the correct label.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12985" target="_blank">03:36:25.360</a></span> | <span class="t">And so that allows us to then iterate the examples</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12988" target="_blank">03:36:28.240</a></span> | <span class="t">and render them.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12989" target="_blank">03:36:29.120</a></span> | <span class="t">And I have an evaluate function here,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12990" target="_blank">03:36:30.720</a></span> | <span class="t">which can load a GPT-2 from HuggingFace</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12994" target="_blank">03:36:34.960</a></span> | <span class="t">and it runs the eval here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=12996" target="_blank">03:36:36.480</a></span> | <span class="t">And basically just calculates, just as I described,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13001" target="_blank">03:36:41.840</a></span> | <span class="t">it predicts the option that has the lowest</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13004" target="_blank">03:36:44.720</a></span> | <span class="t">or the highest probability.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13005" target="_blank">03:36:45.840</a></span> | <span class="t">And the way to do that actually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13008" target="_blank">03:36:48.080</a></span> | <span class="t">is we can basically evaluate the cross entropy loss.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13010" target="_blank">03:36:50.560</a></span> | <span class="t">So we're basically evaluating the loss</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13013" target="_blank">03:36:53.120</a></span> | <span class="t">of predicting the next token in a sequence.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13015" target="_blank">03:36:55.280</a></span> | <span class="t">And then we're looking at the row</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13017" target="_blank">03:36:57.040</a></span> | <span class="t">that has the lowest average loss.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13019" target="_blank">03:36:59.200</a></span> | <span class="t">And that's the option that we pick as the prediction.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13024" target="_blank">03:37:04.960</a></span> | <span class="t">And then we do some stats and prints and stuff like that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13027" target="_blank">03:37:07.520</a></span> | <span class="t">So that is a way to evaluate Hellaswag.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13029" target="_blank">03:37:09.840</a></span> | <span class="t">Now, if you go up here, I'm showing that for GPT-2-124m,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13033" target="_blank">03:37:13.920</a></span> | <span class="t">if you run this script,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13035" target="_blank">03:37:15.520</a></span> | <span class="t">you're going to see that Hellaswag gets 29.55%.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13038" target="_blank">03:37:18.560</a></span> | <span class="t">So that's the performance we get here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13042" target="_blank">03:37:22.480</a></span> | <span class="t">Now, remember that random chance is 25%.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13044" target="_blank">03:37:24.320</a></span> | <span class="t">So we haven't gone too far.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13046" target="_blank">03:37:26.480</a></span> | <span class="t">And GPT-2-XL, which is the biggest, VGPT-2,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13050" target="_blank">03:37:30.640</a></span> | <span class="t">gets all the way up to 49% roughly.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13053" target="_blank">03:37:33.600</a></span> | <span class="t">So these are pretty low values,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13055" target="_blank">03:37:35.840</a></span> | <span class="t">considering that today's state of the art</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13057" target="_blank">03:37:37.520</a></span> | <span class="t">is more like 95%.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13059" target="_blank">03:37:39.040</a></span> | <span class="t">So these are definitely older models by now.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13060" target="_blank">03:37:40.960</a></span> | <span class="t">And then there's one more thing called Eleuther Harness,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13064" target="_blank">03:37:44.000</a></span> | <span class="t">which is a very common piece of infrastructure</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13066" target="_blank">03:37:46.240</a></span> | <span class="t">for running evals for language models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13068" target="_blank">03:37:48.080</a></span> | <span class="t">And they get slightly different numbers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13070" target="_blank">03:37:50.160</a></span> | <span class="t">And I'm not 100% sure what the discrepancy is for these.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13072" target="_blank">03:37:52.720</a></span> | <span class="t">It could be that they actually do the multiple choice</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13076" target="_blank">03:37:56.320</a></span> | <span class="t">instead of just the completions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13078" target="_blank">03:37:58.720</a></span> | <span class="t">And that could be the discrepancy.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13082" target="_blank">03:38:02.080</a></span> | <span class="t">But I'm not 100% sure about that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13083" target="_blank">03:38:03.760</a></span> | <span class="t">I'd have to take a look.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13084" target="_blank">03:38:04.880</a></span> | <span class="t">But for now, our script reports 29.55.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13087" target="_blank">03:38:07.920</a></span> | <span class="t">And so that is the number that we'd like to beat</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13090" target="_blank">03:38:10.000</a></span> | <span class="t">if we were training AGP-2124M from scratch in ourselves.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13093" target="_blank">03:38:13.600</a></span> | <span class="t">So now I'm going to go into actually incorporating</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13100" target="_blank">03:38:20.480</a></span> | <span class="t">this eval into our main training script.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13103" target="_blank">03:38:23.600</a></span> | <span class="t">And basically, because we want to evaluate it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13107" target="_blank">03:38:27.600</a></span> | <span class="t">in a periodic manner</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13108" target="_blank">03:38:28.880</a></span> | <span class="t">so that we can track Hellaswag and how it evolves over time</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13112" target="_blank">03:38:32.000</a></span> | <span class="t">and see when and if we cross this 29.55 region.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13119" target="_blank">03:38:39.840</a></span> | <span class="t">So let's now walk through some of the changes</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13122" target="_blank">03:38:42.000</a></span> | <span class="t">to train GPT-2.py.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13123" target="_blank">03:38:43.280</a></span> | <span class="t">The first thing I did here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13124" target="_blank">03:38:44.960</a></span> | <span class="t">is I actually made useCompile optional, kind of.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13128" target="_blank">03:38:48.000</a></span> | <span class="t">And I disabled it by default.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13129" target="_blank">03:38:49.920</a></span> | <span class="t">And the problem with compile</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13134" target="_blank">03:38:54.080</a></span> | <span class="t">is that unfortunately, it does make our code faster.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13136" target="_blank">03:38:56.400</a></span> | <span class="t">But it actually breaks the evaluation code</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13138" target="_blank">03:38:58.320</a></span> | <span class="t">and the sampling code.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13139" target="_blank">03:38:59.360</a></span> | <span class="t">It gives me a very gnarly message.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13140" target="_blank">03:39:00.720</a></span> | <span class="t">And I don't know why.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13141" target="_blank">03:39:01.840</a></span> | <span class="t">So hopefully, by the time you get to the code base</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13144" target="_blank">03:39:04.560</a></span> | <span class="t">when I put it up on GitHub,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13145" target="_blank">03:39:05.600</a></span> | <span class="t">we're going to fix that by then.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13147" target="_blank">03:39:07.360</a></span> | <span class="t">But for now, I'm running without TorchCompile,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13149" target="_blank">03:39:09.280</a></span> | <span class="t">which is why you see this be a bit slower.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13151" target="_blank">03:39:11.280</a></span> | <span class="t">So we're running without TorchCompile.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13153" target="_blank">03:39:13.760</a></span> | <span class="t">I also created a log directory, log,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13156" target="_blank">03:39:16.800</a></span> | <span class="t">where we can place our log.txt,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13159" target="_blank">03:39:19.520</a></span> | <span class="t">which will record the train loss, validation loss,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13162" target="_blank">03:39:22.720</a></span> | <span class="t">and the Hellaswag accuracies.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13164" target="_blank">03:39:24.480</a></span> | <span class="t">So a very simple text file.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13165" target="_blank">03:39:25.760</a></span> | <span class="t">And we're going to open for writing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13168" target="_blank">03:39:28.240</a></span> | <span class="t">so that it sort of starts empty.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13170" target="_blank">03:39:30.240</a></span> | <span class="t">And then we're going to append to it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13171" target="_blank">03:39:31.520</a></span> | <span class="t">I created a simple variable that helps tell us</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13176" target="_blank">03:39:36.640</a></span> | <span class="t">when we have a last step.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13177" target="_blank">03:39:37.920</a></span> | <span class="t">And then basically, periodically inside this loop,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13181" target="_blank">03:39:41.360</a></span> | <span class="t">every 250th iteration or at the last step,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13185" target="_blank">03:39:45.280</a></span> | <span class="t">we're going to evaluate the validation loss.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13187" target="_blank">03:39:47.040</a></span> | <span class="t">And then every 250th iteration,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13190" target="_blank">03:39:50.320</a></span> | <span class="t">we are going to evaluate Hellaswag.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13194" target="_blank">03:39:54.560</a></span> | <span class="t">But only if we are not using compile</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13197" target="_blank">03:39:57.360</a></span> | <span class="t">because compile breaks it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13199" target="_blank">03:39:59.360</a></span> | <span class="t">So I'm going to come back to this code</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13201" target="_blank">03:40:01.040</a></span> | <span class="t">for evaluating Hellaswag in a second.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13202" target="_blank">03:40:02.640</a></span> | <span class="t">And then every 250th iteration as well,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13206" target="_blank">03:40:06.000</a></span> | <span class="t">we're also going to sample from the model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13207" target="_blank">03:40:07.920</a></span> | <span class="t">And so you should recognize this as our ancient code</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13210" target="_blank">03:40:10.480</a></span> | <span class="t">from way back when we started the video.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13212" target="_blank">03:40:12.720</a></span> | <span class="t">And we're just sampling from the model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13214" target="_blank">03:40:14.080</a></span> | <span class="t">And then finally here, these are, if we're not,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13218" target="_blank">03:40:18.720</a></span> | <span class="t">after we validate, sample, and evaluate Hellaswag,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13222" target="_blank">03:40:22.720</a></span> | <span class="t">we actually do a training step here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13225" target="_blank">03:40:25.040</a></span> | <span class="t">And so this is one step of training.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13227" target="_blank">03:40:27.760</a></span> | <span class="t">And you should be pretty familiar with all of what this does.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13230" target="_blank">03:40:30.320</a></span> | <span class="t">And at the end here, once we get our training loss,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13233" target="_blank">03:40:33.440</a></span> | <span class="t">we write it to the file.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13234" target="_blank">03:40:34.480</a></span> | <span class="t">So the only thing that changed that I really added</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13237" target="_blank">03:40:37.440</a></span> | <span class="t">is this entire section for Hellaswag eval.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13239" target="_blank">03:40:39.360</a></span> | <span class="t">And the way this works is I'm trying to get</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13242" target="_blank">03:40:42.240</a></span> | <span class="t">all the GPUs to collaborate on the Hellaswag.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13244" target="_blank">03:40:44.400</a></span> | <span class="t">And so we're iterating on the examples.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13246" target="_blank">03:40:46.640</a></span> | <span class="t">And then each process only picks the examples</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13251" target="_blank">03:40:51.200</a></span> | <span class="t">that assigned to it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13253" target="_blank">03:40:53.200</a></span> | <span class="t">So we sort of take i and mod it by the world size.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13255" target="_blank">03:40:55.680</a></span> | <span class="t">And we have to make it equal to rank.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13257" target="_blank">03:40:57.520</a></span> | <span class="t">Otherwise, we continue.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13258" target="_blank">03:40:58.480</a></span> | <span class="t">And then we render an example, put it on a GPU.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13261" target="_blank">03:41:01.920</a></span> | <span class="t">We get the logits.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13263" target="_blank">03:41:03.920</a></span> | <span class="t">Then I create a helper function that helps us basically</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13266" target="_blank">03:41:06.560</a></span> | <span class="t">predict the option with the lowest loss.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13268" target="_blank">03:41:08.880</a></span> | <span class="t">So this comes here, the prediction.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13271" target="_blank">03:41:11.120</a></span> | <span class="t">And then if it's correct, we sort of keep count.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13273" target="_blank">03:41:13.840</a></span> | <span class="t">And then if multiple processes were collaborating</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13277" target="_blank">03:41:17.040</a></span> | <span class="t">on all of this, then we need to synchronize their stats.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13279" target="_blank">03:41:19.920</a></span> | <span class="t">And so the one way to do that is to package up</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13282" target="_blank">03:41:22.480</a></span> | <span class="t">our statistics here into tensors.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13285" target="_blank">03:41:25.600</a></span> | <span class="t">Which we can then call this.allReduceOn and sum.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13288" target="_blank">03:41:28.640</a></span> | <span class="t">And then here we sort of unwrap them from tensors</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13293" target="_blank">03:41:33.920</a></span> | <span class="t">so that we just have ints.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13295" target="_blank">03:41:35.040</a></span> | <span class="t">And then here, the master process will print</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13297" target="_blank">03:41:37.920</a></span> | <span class="t">and log the Hellaswag accuracy.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13299" target="_blank">03:41:39.440</a></span> | <span class="t">So that's kind of it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13304" target="_blank">03:41:44.800</a></span> | <span class="t">And that's what I'm running right here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13307" target="_blank">03:41:47.120</a></span> | <span class="t">So you see this optimization here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13308" target="_blank">03:41:48.640</a></span> | <span class="t">And we just had a generation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13312" target="_blank">03:41:52.240</a></span> | <span class="t">And this is step 10,000 out of about 20,000, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13315" target="_blank">03:41:55.200</a></span> | <span class="t">So we are halfway done.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13316" target="_blank">03:41:56.800</a></span> | <span class="t">And these are the kinds of samples that we are getting</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13319" target="_blank">03:41:59.680</a></span> | <span class="t">at this stage.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13320" target="_blank">03:42:00.320</a></span> | <span class="t">So let's take a look.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13321" target="_blank">03:42:01.040</a></span> | <span class="t">Hello, I'm a language model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13323" target="_blank">03:42:03.840</a></span> | <span class="t">So I'd like to use it to generate some kinds of output.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13326" target="_blank">03:42:06.160</a></span> | <span class="t">Hello, I'm a language model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13328" target="_blank">03:42:08.160</a></span> | <span class="t">And I'm a developer for a lot of companies.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13329" target="_blank">03:42:09.920</a></span> | <span class="t">Hello, I'm a language model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13332" target="_blank">03:42:12.160</a></span> | <span class="t">Let's see if I can find any fun one.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13336" target="_blank">03:42:16.320</a></span> | <span class="t">I don't know.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13336" target="_blank">03:42:16.880</a></span> | <span class="t">You can go through this yourself.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13338" target="_blank">03:42:18.080</a></span> | <span class="t">But certainly, the predictions are getting less and less random.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13340" target="_blank">03:42:20.960</a></span> | <span class="t">It seems like the model is a little bit more self-aware</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13344" target="_blank">03:42:24.000</a></span> | <span class="t">and using language that is a bit more specific to it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13349" target="_blank">03:42:29.120</a></span> | <span class="t">being a language model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13350" target="_blank">03:42:30.080</a></span> | <span class="t">Hello, I'm a language model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13352" target="_blank">03:42:32.560</a></span> | <span class="t">And like the model, I'm going to use it to generate</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13354" target="_blank">03:42:34.800</a></span> | <span class="t">some kind of output.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13356" target="_blank">03:42:36.160</a></span> | <span class="t">So let's see if I can find any fun one.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13357" target="_blank">03:42:37.760</a></span> | <span class="t">Hello, I'm a language model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13358" target="_blank">03:42:38.800</a></span> | <span class="t">And I'm a developer for a lot of companies.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13360" target="_blank">03:42:40.800</a></span> | <span class="t">Let's see if I can find any fun one.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13361" target="_blank">03:42:41.840</a></span> | <span class="t">Hello, I'm a language model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13362" target="_blank">03:42:42.960</a></span> | <span class="t">And I'm a developer for a lot of companies.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13364" target="_blank">03:42:44.160</a></span> | <span class="t">Hello, I'm a language model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13365" target="_blank">03:42:45.200</a></span> | <span class="t">And like how the language is used to communicate,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13367" target="_blank">03:42:47.600</a></span> | <span class="t">I'm a language model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13368" target="_blank">03:42:48.560</a></span> | <span class="t">And I'm going to be speaking English and German.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13371" target="_blank">03:42:51.520</a></span> | <span class="t">Okay, I don't know.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13372" target="_blank">03:42:52.960</a></span> | <span class="t">So let's just wait until this optimization finishes.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13375" target="_blank">03:42:55.680</a></span> | <span class="t">And we'll see what kind of samples we get.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13377" target="_blank">03:42:57.760</a></span> | <span class="t">And we're also going to look at the train, val,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13381" target="_blank">03:43:01.360</a></span> | <span class="t">and the hellosquare accuracy</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13383" target="_blank">03:43:03.120</a></span> | <span class="t">and see how we're doing with respect to GPT-2.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13385" target="_blank">03:43:05.040</a></span> | <span class="t">Okay, good morning.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13387" target="_blank">03:43:07.840</a></span> | <span class="t">So focusing for a moment on the Jupyter Notebook</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13390" target="_blank">03:43:10.880</a></span> | <span class="t">here on the right,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13392" target="_blank">03:43:12.000</a></span> | <span class="t">I created a new cell that basically allows us</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13394" target="_blank">03:43:14.480</a></span> | <span class="t">to visualize the train, val, and the hellosquare.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13399" target="_blank">03:43:19.280</a></span> | <span class="t">And you can step through this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13400" target="_blank">03:43:20.960</a></span> | <span class="t">It basically like parses the log file that we are writing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13403" target="_blank">03:43:23.520</a></span> | <span class="t">And a lot of this is just like boring matplotlib code.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13407" target="_blank">03:43:27.840</a></span> | <span class="t">But basically, this is what our optimization looks like.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13410" target="_blank">03:43:30.480</a></span> | <span class="t">So we ran for 19,073 steps,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13416" target="_blank">03:43:36.720</a></span> | <span class="t">which is roughly 10 billion tokens,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13420" target="_blank">03:43:40.160</a></span> | <span class="t">which is, whoops, oh my gosh,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13422" target="_blank">03:43:42.160</a></span> | <span class="t">which is one epoch of the sample 10B of FineWebEDU.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13425" target="_blank">03:43:45.600</a></span> | <span class="t">On the left, we have the loss.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13427" target="_blank">03:43:47.680</a></span> | <span class="t">And in the blue, we have the training loss.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13431" target="_blank">03:43:51.040</a></span> | <span class="t">In orange, we have the validation loss.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13433" target="_blank">03:43:53.120</a></span> | <span class="t">And in red, as a horizontal line,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13435" target="_blank">03:43:55.440</a></span> | <span class="t">we have the opening IGPT-2 124M model checkpoint,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13439" target="_blank">03:43:59.360</a></span> | <span class="t">when it's just evaluated on the validation set</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13441" target="_blank">03:44:01.520</a></span> | <span class="t">of this FineWebEDU.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13444" target="_blank">03:44:04.640</a></span> | <span class="t">So you can see that we are surpassing,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13447" target="_blank">03:44:07.760</a></span> | <span class="t">this orange is below the red.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13449" target="_blank">03:44:09.200</a></span> | <span class="t">So we're surpassing the validation set of this dataset.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13452" target="_blank">03:44:12.560</a></span> | <span class="t">And like I mentioned, the dataset distribution</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13454" target="_blank">03:44:14.640</a></span> | <span class="t">is very different from what GPT-2 trained on.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13456" target="_blank">03:44:16.640</a></span> | <span class="t">So this is not an exactly fair comparison,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13458" target="_blank">03:44:18.880</a></span> | <span class="t">but it's a good cross-check to look at.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13462" target="_blank">03:44:22.640</a></span> | <span class="t">Now, we would ideally like something</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13465" target="_blank">03:44:25.200</a></span> | <span class="t">that is withheld and comparable and somewhat standard.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13468" target="_blank">03:44:28.960</a></span> | <span class="t">And so for us, that is helloswag.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13472" target="_blank">03:44:32.320</a></span> | <span class="t">And so on here, we see the helloswag progress</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13474" target="_blank">03:44:34.800</a></span> | <span class="t">we made from 25% all the way here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13478" target="_blank">03:44:38.080</a></span> | <span class="t">In red, we see the opening IGPT-2 124M model in red.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13483" target="_blank">03:44:43.200</a></span> | <span class="t">So it achieves this helloswag here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13485" target="_blank">03:44:45.360</a></span> | <span class="t">And the GPT-3 model 124M,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13489" target="_blank">03:44:49.360</a></span> | <span class="t">which was trained on 300 billion tokens, achieves green.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13493" target="_blank">03:44:53.040</a></span> | <span class="t">So that's over here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13495" target="_blank">03:44:55.520</a></span> | <span class="t">So you see that we basically surpassed</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13497" target="_blank">03:44:57.280</a></span> | <span class="t">the GPT-2 124M model right here, which is really nice.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13503" target="_blank">03:45:03.680</a></span> | <span class="t">Now, interestingly, we were able to do so</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13507" target="_blank">03:45:07.280</a></span> | <span class="t">with only training on 10 billion tokens,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13509" target="_blank">03:45:09.280</a></span> | <span class="t">while GPT-2 was trained on 100 billion tokens.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13512" target="_blank">03:45:12.160</a></span> | <span class="t">So for some reason, we were able to get away</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13515" target="_blank">03:45:15.360</a></span> | <span class="t">with significantly fewer tokens for training.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13517" target="_blank">03:45:17.760</a></span> | <span class="t">There are many possibilities as to why we could match</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13521" target="_blank">03:45:21.440</a></span> | <span class="t">or surpass this accuracy with only 10 billion training.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13525" target="_blank">03:45:25.760</a></span> | <span class="t">So number one, it could be that OpenAI GPT-2</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13529" target="_blank">03:45:29.840</a></span> | <span class="t">was trained on a much wider data distribution.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13532" target="_blank">03:45:32.800</a></span> | <span class="t">So in particular, FindWebEDU is all English.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13536" target="_blank">03:45:36.400</a></span> | <span class="t">It's not multilingual.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13538" target="_blank">03:45:38.080</a></span> | <span class="t">And there's not that much math and code.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13540" target="_blank">03:45:40.000</a></span> | <span class="t">And so math and code and multilingual could have been</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13544" target="_blank">03:45:44.240</a></span> | <span class="t">stealing capacity from the original GPT-2 model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13548" target="_blank">03:45:48.080</a></span> | <span class="t">And basically, that could be partially the reason</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13552" target="_blank">03:45:52.000</a></span> | <span class="t">why this is not working out.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13554" target="_blank">03:45:54.080</a></span> | <span class="t">There's many other reasons.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13555" target="_blank">03:45:55.120</a></span> | <span class="t">So for example, the helloswag eval is fairly old,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13558" target="_blank">03:45:58.560</a></span> | <span class="t">maybe five years or so.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13559" target="_blank">03:45:59.920</a></span> | <span class="t">It is possible that aspects of helloswag in some way,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13563" target="_blank">03:46:03.200</a></span> | <span class="t">or even identically, have made it into the training set.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13566" target="_blank">03:46:06.960</a></span> | <span class="t">Or FindWeb, we don't know for sure.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13569" target="_blank">03:46:09.680</a></span> | <span class="t">But if that was the case, then we are basically looking</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13571" target="_blank">03:46:11.600</a></span> | <span class="t">at the training curve instead of the validation curve.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13573" target="_blank">03:46:13.440</a></span> | <span class="t">So long story short, this is not a perfect eval.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13576" target="_blank">03:46:16.320</a></span> | <span class="t">And there's some caveats here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13577" target="_blank">03:46:17.440</a></span> | <span class="t">But at least we have some confidence</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13579" target="_blank">03:46:19.920</a></span> | <span class="t">that we're not doing something completely wrong.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13581" target="_blank">03:46:21.840</a></span> | <span class="t">And it's probably the case that when people try</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13586" target="_blank">03:46:26.960</a></span> | <span class="t">to create these data sets, they try to make sure</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13588" target="_blank">03:46:28.640</a></span> | <span class="t">that test sets that are very common</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13590" target="_blank">03:46:30.960</a></span> | <span class="t">are not part of the training set.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13592" target="_blank">03:46:32.720</a></span> | <span class="t">For example, when HuggingFace created the FindWebEDU,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13595" target="_blank">03:46:35.520</a></span> | <span class="t">they use helloswag as an eval.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13597" target="_blank">03:46:37.120</a></span> | <span class="t">So I would hope that they make sure that they deduplicate</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13600" target="_blank">03:46:40.080</a></span> | <span class="t">and that there's no helloswag in the training set.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13602" target="_blank">03:46:42.640</a></span> | <span class="t">But we can't be sure.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13603" target="_blank">03:46:43.680</a></span> | <span class="t">The other thing I wanted to address briefly is,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13607" target="_blank">03:46:47.040</a></span> | <span class="t">look at this loss curve.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13608" target="_blank">03:46:48.160</a></span> | <span class="t">This looks really wrong here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13610" target="_blank">03:46:50.880</a></span> | <span class="t">I don't actually know 100% what this is.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13612" target="_blank">03:46:52.960</a></span> | <span class="t">And I suspect it's because the 10 billion sample</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13616" target="_blank">03:46:56.320</a></span> | <span class="t">of FindWebEDU was not properly shuffled.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13619" target="_blank">03:46:59.760</a></span> | <span class="t">And there's some issue here with the data</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13624" target="_blank">03:47:04.320</a></span> | <span class="t">that I don't fully understand yet.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13625" target="_blank">03:47:05.680</a></span> | <span class="t">And there's some weird periodicity to it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13627" target="_blank">03:47:07.520</a></span> | <span class="t">And because we are in a very lazy way,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13630" target="_blank">03:47:10.320</a></span> | <span class="t">sort of serializing all the tokens</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13631" target="_blank">03:47:11.840</a></span> | <span class="t">and just iterating on them from scratch</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13633" target="_blank">03:47:13.600</a></span> | <span class="t">without doing any permutations</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13635" target="_blank">03:47:15.040</a></span> | <span class="t">or any random sampling ourselves,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13637" target="_blank">03:47:17.200</a></span> | <span class="t">I think we're inheriting some of the ordering</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13640" target="_blank">03:47:20.560</a></span> | <span class="t">that they have in the data set.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13642" target="_blank">03:47:22.000</a></span> | <span class="t">So this is not ideal.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13644" target="_blank">03:47:24.800</a></span> | <span class="t">But hopefully by the time you get to this repo,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13647" target="_blank">03:47:27.840</a></span> | <span class="t">some of these things, by the way,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13649" target="_blank">03:47:29.280</a></span> | <span class="t">will hopefully be fixed.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13651" target="_blank">03:47:31.040</a></span> | <span class="t">And I will release this BuildNanoGPT repo.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13654" target="_blank">03:47:34.800</a></span> | <span class="t">And right now it looks a little ugly and preliminary.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13657" target="_blank">03:47:37.840</a></span> | <span class="t">So hopefully by the time you get here, it's nicer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13660" target="_blank">03:47:40.640</a></span> | <span class="t">But down here, I'm going to show errata.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13662" target="_blank">03:47:42.960</a></span> | <span class="t">And I'm going to talk about some of the things</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13665" target="_blank">03:47:45.520</a></span> | <span class="t">that happened after the video.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13667" target="_blank">03:47:47.200</a></span> | <span class="t">And I expect that we will have fixed the small issue.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13670" target="_blank">03:47:50.160</a></span> | <span class="t">But for now, basically, this shows that our training</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13673" target="_blank">03:47:53.920</a></span> | <span class="t">is not completely wrong.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13675" target="_blank">03:47:55.840</a></span> | <span class="t">And it shows that we're able to surpass the accuracy</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13679" target="_blank">03:47:59.840</a></span> | <span class="t">with only 10x the token budget.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13681" target="_blank">03:48:01.440</a></span> | <span class="t">And possibly it could be also that the data set</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13685" target="_blank">03:48:05.840</a></span> | <span class="t">may have improved.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13687" target="_blank">03:48:07.200</a></span> | <span class="t">So the original GPT-2 data set was WebText.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13690" target="_blank">03:48:10.880</a></span> | <span class="t">It's possible that not a lot of care and attention</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13693" target="_blank">03:48:13.120</a></span> | <span class="t">went into the data set.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13694" target="_blank">03:48:14.320</a></span> | <span class="t">This was very early in LLMs.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13696" target="_blank">03:48:16.400</a></span> | <span class="t">Whereas now there's a lot more scrutiny</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13698" target="_blank">03:48:18.160</a></span> | <span class="t">on good practices around deduplication, filtering,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13701" target="_blank">03:48:21.920</a></span> | <span class="t">quality filtering, and so on.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13703" target="_blank">03:48:23.360</a></span> | <span class="t">And it's possible that the data set we're training on</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13705" target="_blank">03:48:25.120</a></span> | <span class="t">is just of higher quality per token.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13707" target="_blank">03:48:27.120</a></span> | <span class="t">And that could be giving us a boost as well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13709" target="_blank">03:48:29.600</a></span> | <span class="t">So a number of caveats to think about.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13711" target="_blank">03:48:31.200</a></span> | <span class="t">But for now, we're pretty happy with this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13713" target="_blank">03:48:33.280</a></span> | <span class="t">And yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13715" target="_blank">03:48:35.360</a></span> | <span class="t">Now, the next thing I was interested in is,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13717" target="_blank">03:48:37.600</a></span> | <span class="t">as you see, it's a morning now.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13719" target="_blank">03:48:39.200</a></span> | <span class="t">So there was an overnight.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13720" target="_blank">03:48:40.720</a></span> | <span class="t">And I wanted to basically see how far</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13722" target="_blank">03:48:42.480</a></span> | <span class="t">I could push the result.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13723" target="_blank">03:48:43.840</a></span> | <span class="t">So to do an overnight run, I basically did,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13727" target="_blank">03:48:47.360</a></span> | <span class="t">instead of one epoch, which took roughly two hours,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13730" target="_blank">03:48:50.000</a></span> | <span class="t">I just did it times four.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13731" target="_blank">03:48:51.280</a></span> | <span class="t">So that that would take eight hours while I was sleeping.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13733" target="_blank">03:48:53.680</a></span> | <span class="t">And so we did four epochs or roughly 40 billion</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13736" target="_blank">03:48:56.800</a></span> | <span class="t">tokens of training.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13738" target="_blank">03:48:58.320</a></span> | <span class="t">And I was trying to see how far we could get.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13740" target="_blank">03:49:00.320</a></span> | <span class="t">And so this was the only change.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13742" target="_blank">03:49:02.560</a></span> | <span class="t">And I re-ran the script.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13743" target="_blank">03:49:03.920</a></span> | <span class="t">And when I point and read the log file at the 40B,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13747" target="_blank">03:49:07.680</a></span> | <span class="t">this is what the curve looked like.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13749" target="_blank">03:49:09.520</a></span> | <span class="t">OK.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13752" target="_blank">03:49:12.000</a></span> | <span class="t">So to narrate this, number one,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13753" target="_blank">03:49:13.520</a></span> | <span class="t">we are seeing this issue here with the periodicity</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13756" target="_blank">03:49:16.560</a></span> | <span class="t">through the different epochs and something really weird</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13758" target="_blank">03:49:18.800</a></span> | <span class="t">with the FindWebEDU data set.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13761" target="_blank">03:49:21.120</a></span> | <span class="t">And that is to be determined.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13762" target="_blank">03:49:22.720</a></span> | <span class="t">But otherwise, we are seeing that the Hellaswag</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13766" target="_blank">03:49:26.560</a></span> | <span class="t">actually went up by a lot.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13768" target="_blank">03:49:28.640</a></span> | <span class="t">And we almost made it to the GPT-3 124M accuracy up here,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13774" target="_blank">03:49:34.880</a></span> | <span class="t">but not quite.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13776" target="_blank">03:49:36.320</a></span> | <span class="t">So it's too bad that I didn't sleep slightly longer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13779" target="_blank">03:49:39.120</a></span> | <span class="t">And I think if this was a five epoch run,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13784" target="_blank">03:49:44.320</a></span> | <span class="t">we may have gotten here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13785" target="_blank">03:49:45.680</a></span> | <span class="t">Now, one thing to point out is that if you're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13788" target="_blank">03:49:48.240</a></span> | <span class="t">doing multi-epoch runs, we're not actually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13791" target="_blank">03:49:51.200</a></span> | <span class="t">being very careful in our data loader.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13792" target="_blank">03:49:52.800</a></span> | <span class="t">And this data loader goes through the data</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13797" target="_blank">03:49:57.360</a></span> | <span class="t">in exactly the same format and exactly the same order.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13801" target="_blank">03:50:01.600</a></span> | <span class="t">And this is kind of suboptimal.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13803" target="_blank">03:50:03.120</a></span> | <span class="t">And you would want to look into extensions</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13804" target="_blank">03:50:04.880</a></span> | <span class="t">where you actually permute the data randomly.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13807" target="_blank">03:50:07.920</a></span> | <span class="t">You permute the documents around in every single shard</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13810" target="_blank">03:50:10.960</a></span> | <span class="t">on every single new epoch and potentially even permute</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13815" target="_blank">03:50:15.280</a></span> | <span class="t">the shards.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13815" target="_blank">03:50:15.840</a></span> | <span class="t">And that would go a long way into decreasing the periodicity.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13819" target="_blank">03:50:19.520</a></span> | <span class="t">And it's also better for the optimization</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13821" target="_blank">03:50:21.600</a></span> | <span class="t">so that you're not seeing things in the identical format.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13824" target="_blank">03:50:24.960</a></span> | <span class="t">And you're introducing some of the randomness</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13827" target="_blank">03:50:27.680</a></span> | <span class="t">in how the documents follow each other.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13829" target="_blank">03:50:29.600</a></span> | <span class="t">Because you have to remember that in every single row,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13832" target="_blank">03:50:32.000</a></span> | <span class="t">these documents follow each other.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13833" target="_blank">03:50:33.440</a></span> | <span class="t">And then there's the end of text token</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13834" target="_blank">03:50:34.880</a></span> | <span class="t">and then the next document.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13836" target="_blank">03:50:36.240</a></span> | <span class="t">So the documents are currently glued together</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13838" target="_blank">03:50:38.960</a></span> | <span class="t">in the exact same identical manner.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13841" target="_blank">03:50:41.280</a></span> | <span class="t">But we actually want to break up the documents</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13843" target="_blank">03:50:43.680</a></span> | <span class="t">and shuffle them around.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13845" target="_blank">03:50:45.040</a></span> | <span class="t">Because the order of the documents shouldn't matter.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13847" target="_blank">03:50:47.280</a></span> | <span class="t">And they shouldn't-- basically, we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13849" target="_blank">03:50:49.360</a></span> | <span class="t">want to break up that dependence.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13850" target="_blank">03:50:50.800</a></span> | <span class="t">Because it's kind of a spurious correlation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13852" target="_blank">03:50:52.720</a></span> | <span class="t">And so our data letter is not currently doing that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13855" target="_blank">03:50:55.440</a></span> | <span class="t">And that's one improvement you could think of making.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13857" target="_blank">03:50:57.920</a></span> | <span class="t">The other thing to point out is we're almost matching</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13862" target="_blank">03:51:02.080</a></span> | <span class="t">GPT-3 accuracy with only 40 billion tokens.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13864" target="_blank">03:51:04.880</a></span> | <span class="t">GPT-3 trained on 300 billion tokens.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13867" target="_blank">03:51:07.840</a></span> | <span class="t">So again, we're seeing about a 10x improvement here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13871" target="_blank">03:51:11.360</a></span> | <span class="t">with respect to learning efficiency.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13873" target="_blank">03:51:13.360</a></span> | <span class="t">The other thing I wanted to-- and I don't actually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13876" target="_blank">03:51:16.880</a></span> | <span class="t">know exactly what to attribute this to other than some</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13879" target="_blank">03:51:19.120</a></span> | <span class="t">of the things that I already mentioned previously</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13881" target="_blank">03:51:21.200</a></span> | <span class="t">for the previous run.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13881" target="_blank">03:51:21.920</a></span> | <span class="t">The other thing I wanted to briefly mention</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13884" target="_blank">03:51:24.480</a></span> | <span class="t">is the max LR here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13887" target="_blank">03:51:27.600</a></span> | <span class="t">I saw some people already play with this a little bit</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13890" target="_blank">03:51:30.160</a></span> | <span class="t">in a previous related repository.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13892" target="_blank">03:51:32.000</a></span> | <span class="t">And it turns out that you can actually almost 3x this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13896" target="_blank">03:51:36.000</a></span> | <span class="t">So it's possible that the maximum learning rate</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13897" target="_blank">03:51:37.600</a></span> | <span class="t">can be a lot higher.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13898" target="_blank">03:51:38.800</a></span> | <span class="t">And for some reason, the GPT-3 hyperparameters</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13900" target="_blank">03:51:40.880</a></span> | <span class="t">that we are inheriting are actually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13902" target="_blank">03:51:42.480</a></span> | <span class="t">extremely conservative.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13903" target="_blank">03:51:43.760</a></span> | <span class="t">And you can actually get away with a higher learning rate.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13905" target="_blank">03:51:45.680</a></span> | <span class="t">And it would train faster.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13907" target="_blank">03:51:47.360</a></span> | <span class="t">So a lot of these hyperparameters are quite tunable.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13911" target="_blank">03:51:51.360</a></span> | <span class="t">And feel free to play with them.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13912" target="_blank">03:51:52.800</a></span> | <span class="t">And they're probably not set precisely correctly.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13915" target="_blank">03:51:55.840</a></span> | <span class="t">And it's possible that you can get away</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13919" target="_blank">03:51:59.600</a></span> | <span class="t">with doing this, basically.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13920" target="_blank">03:52:00.800</a></span> | <span class="t">And if you wanted to exactly be faithful to GPT-3,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13925" target="_blank">03:52:05.200</a></span> | <span class="t">you would also want to make the following difference.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13929" target="_blank">03:52:09.760</a></span> | <span class="t">You'd want to come here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13931" target="_blank">03:52:11.120</a></span> | <span class="t">And the sequence length of GPT-3 is 2x.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13933" target="_blank">03:52:13.760</a></span> | <span class="t">It's 2,048 instead of 1,024.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13936" target="_blank">03:52:16.240</a></span> | <span class="t">So you would come here, change this to 2,048 for t.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13939" target="_blank">03:52:19.600</a></span> | <span class="t">And then if you want the exact same number of tokens,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13941" target="_blank">03:52:21.520</a></span> | <span class="t">half a million per iteration or per step,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13945" target="_blank">03:52:25.440</a></span> | <span class="t">you want to then decrease this to 32.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13947" target="_blank">03:52:27.200</a></span> | <span class="t">So they still multiply to half a mil.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13949" target="_blank">03:52:29.440</a></span> | <span class="t">So that would give your model sequence length</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13953" target="_blank">03:52:33.120</a></span> | <span class="t">equal to that of GPT-3.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13955" target="_blank">03:52:35.280</a></span> | <span class="t">And in that case, basically, the models</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13958" target="_blank">03:52:38.800</a></span> | <span class="t">would be roughly identical as far as I'm aware.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13962" target="_blank">03:52:42.560</a></span> | <span class="t">Because again, GPT-2 and GPT-3 are very, very similar models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13966" target="_blank">03:52:46.240</a></span> | <span class="t">Now, we can also look at some of the samples here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13968" target="_blank">03:52:48.080</a></span> | <span class="t">from the model that was trained overnight.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13970" target="_blank">03:52:50.720</a></span> | <span class="t">So this is the optimization.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13974" target="_blank">03:52:54.640</a></span> | <span class="t">And you see that here, we stepped all the way</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13976" target="_blank">03:52:56.320</a></span> | <span class="t">to 76,290 or so.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13979" target="_blank">03:52:59.440</a></span> | <span class="t">And these are-- the Hellas spike we achieved was 33.24.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13984" target="_blank">03:53:04.400</a></span> | <span class="t">And these are some of the samples from the model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13987" target="_blank">03:53:07.680</a></span> | <span class="t">And you can see that if you read through this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13990" target="_blank">03:53:10.240</a></span> | <span class="t">and pause the video briefly, you can see</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13991" target="_blank">03:53:11.840</a></span> | <span class="t">that there are a lot more coherent.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13994" target="_blank">03:53:14.160</a></span> | <span class="t">So-- and they're actually addressing the fact</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13997" target="_blank">03:53:17.440</a></span> | <span class="t">that it's a language model, almost.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=13999" target="_blank">03:53:19.760</a></span> | <span class="t">So hello, I'm a language model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=14004" target="_blank">03:53:24.400</a></span> | <span class="t">And I try to be as accurate as possible.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=14005" target="_blank">03:53:25.920</a></span> | <span class="t">I'm a language model, not a programming language.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=14010" target="_blank">03:53:30.400</a></span> | <span class="t">I know how to communicate.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=14013" target="_blank">03:53:33.760</a></span> | <span class="t">I use Python.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=14015" target="_blank">03:53:35.360</a></span> | <span class="t">I don't know.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=14019" target="_blank">03:53:39.200</a></span> | <span class="t">If you pause this and look at it and then compare it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=14021" target="_blank">03:53:41.280</a></span> | <span class="t">to the one-- to the model that was only trained</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=14023" target="_blank">03:53:43.440</a></span> | <span class="t">for 10 billion, you will see that these</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=14025" target="_blank">03:53:45.600</a></span> | <span class="t">are a lot more coherent.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=14026" target="_blank">03:53:46.720</a></span> | <span class="t">And you can play with this yourself.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=14028" target="_blank">03:53:48.240</a></span> | <span class="t">One more thing I added to the code, by the way,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=14031" target="_blank">03:53:51.040</a></span> | <span class="t">is this chunk of code here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=14032" target="_blank">03:53:52.720</a></span> | <span class="t">So basically, right after we evaluate the validation loss,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=14036" target="_blank">03:53:56.240</a></span> | <span class="t">if we are the master process, in addition</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=14038" target="_blank">03:53:58.640</a></span> | <span class="t">to logging the validation loss, every 5,000 steps,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=14041" target="_blank">03:54:01.520</a></span> | <span class="t">we're also going to save the checkpoint,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=14043" target="_blank">03:54:03.440</a></span> | <span class="t">which is really just the state dictionary of the model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=14046" target="_blank">03:54:06.640</a></span> | <span class="t">And so checkpointing is nice just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=14048" target="_blank">03:54:08.240</a></span> | <span class="t">because you can save the model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=14050" target="_blank">03:54:10.000</a></span> | <span class="t">And later, you can use it in some way.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=14052" target="_blank">03:54:12.320</a></span> | <span class="t">If you wanted to resume the optimization,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=14054" target="_blank">03:54:14.960</a></span> | <span class="t">then in addition to saving the model,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=14056" target="_blank">03:54:16.880</a></span> | <span class="t">we have to also save the optimizer state dict.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=14060" target="_blank">03:54:20.320</a></span> | <span class="t">Because remember that the optimizer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=14061" target="_blank">03:54:21.680</a></span> | <span class="t">has a few additional buffers because of atom.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=14064" target="_blank">03:54:24.400</a></span> | <span class="t">So it's got the m and v.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=14066" target="_blank">03:54:26.400</a></span> | <span class="t">And you need to also resume the optimizer properly.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=14070" target="_blank">03:54:30.240</a></span> | <span class="t">You have to be careful with the RNG seeds, random number</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=14072" target="_blank">03:54:32.800</a></span> | <span class="t">generators, and so on.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=14074" target="_blank">03:54:34.080</a></span> | <span class="t">So if you wanted to exactly be able to resume optimization,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=14077" target="_blank">03:54:37.040</a></span> | <span class="t">you have to think through the state of the training process.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=14080" target="_blank">03:54:40.800</a></span> | <span class="t">But if you just want to save the model,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=14082" target="_blank">03:54:42.080</a></span> | <span class="t">this is how you would do it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=14083" target="_blank">03:54:43.440</a></span> | <span class="t">And one nice reason why you might want to do this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=14086" target="_blank">03:54:46.160</a></span> | <span class="t">is because you may want to evaluate the model a lot more</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=14088" target="_blank">03:54:48.960</a></span> | <span class="t">carefully.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=14089" target="_blank">03:54:49.460</a></span> | <span class="t">So here, we are only kind of like winging the LSWG eval.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=14094" target="_blank">03:54:54.080</a></span> | <span class="t">But you may want to use something nicer,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=14097" target="_blank">03:54:57.040</a></span> | <span class="t">like, for example, the Luther evaluation hardness.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=14101" target="_blank">03:55:01.280</a></span> | <span class="t">Evaluation harness?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=14102" target="_blank">03:55:02.960</a></span> | <span class="t">Hardness.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=14105" target="_blank">03:55:05.600</a></span> | <span class="t">So this is a way to also evaluate language models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=14109" target="_blank">03:55:09.360</a></span> | <span class="t">And so it's possible that you may</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=14113" target="_blank">03:55:13.840</a></span> | <span class="t">want to use basically different infrastructure</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=14115" target="_blank">03:55:15.760</a></span> | <span class="t">to more thoroughly evaluate the models</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=14118" target="_blank">03:55:18.320</a></span> | <span class="t">on different evaluations and compare it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=14121" target="_blank">03:55:21.120</a></span> | <span class="t">to the OpenAI GPT-2 model on many other tasks,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=14125" target="_blank">03:55:25.280</a></span> | <span class="t">like, for example, that involve math, code,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=14127" target="_blank">03:55:27.040</a></span> | <span class="t">or different languages, and so on.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=14128" target="_blank">03:55:28.320</a></span> | <span class="t">So this is a nice functionality to have as well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=14130" target="_blank">03:55:30.640</a></span> | <span class="t">And then the other thing I wanted to mention</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=14135" target="_blank">03:55:35.040</a></span> | <span class="t">is that everything we've built here,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=14136" target="_blank">03:55:36.960</a></span> | <span class="t">this is only the pre-training step.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=14139" target="_blank">03:55:39.280</a></span> | <span class="t">So the GPT here is a--</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=14142" target="_blank">03:55:42.080</a></span> | <span class="t">it dreams documents.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=14143" target="_blank">03:55:43.200</a></span> | <span class="t">It just predicts the next token.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=14144" target="_blank">03:55:44.720</a></span> | <span class="t">You can't talk to it like you can talk to chat GPT.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=14148" target="_blank">03:55:48.080</a></span> | <span class="t">If you wanted to talk to the model,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=14150" target="_blank">03:55:50.480</a></span> | <span class="t">we have to fine-tune it into the chat format.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=14153" target="_blank">03:55:53.440</a></span> | <span class="t">And it's not actually that complicated.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=14155" target="_blank">03:55:55.120</a></span> | <span class="t">If you're looking at supervised fine-tuning or SFT,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=14158" target="_blank">03:55:58.000</a></span> | <span class="t">really what that means is we're just swapping out the data set</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=14160" target="_blank">03:56:00.720</a></span> | <span class="t">into a data set that is a lot more conversational.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=14162" target="_blank">03:56:02.960</a></span> | <span class="t">And there's a user-assistant, user-assistant kind</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=14164" target="_blank">03:56:04.960</a></span> | <span class="t">of structure.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=14165" target="_blank">03:56:05.840</a></span> | <span class="t">And we just fine-tune on it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=14167" target="_blank">03:56:07.200</a></span> | <span class="t">And then we basically fill in the user tokens,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=14170" target="_blank">03:56:10.560</a></span> | <span class="t">and we sample the assistant tokens.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=14172" target="_blank">03:56:12.880</a></span> | <span class="t">It's not a lot more deeper than that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=14174" target="_blank">03:56:14.480</a></span> | <span class="t">But basically, we swap out the data set</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=14176" target="_blank">03:56:16.560</a></span> | <span class="t">and continue training.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=14177" target="_blank">03:56:17.360</a></span> | <span class="t">But for now, we're going to stop at pre-training.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=14180" target="_blank">03:56:20.720</a></span> | <span class="t">One more thing that I wanted to briefly show you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=14183" target="_blank">03:56:23.040</a></span> | <span class="t">is that, of course, what we've built up today</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=14185" target="_blank">03:56:25.760</a></span> | <span class="t">was building towards NanoGPT,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=14187" target="_blank">03:56:27.520</a></span> | <span class="t">which is this repository from earlier.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=14190" target="_blank">03:56:30.080</a></span> | <span class="t">But also, there's actually another NanoGPT implementation,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=14192" target="_blank">03:56:32.880</a></span> | <span class="t">and it's hiding in a more recent project</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=14195" target="_blank">03:56:35.200</a></span> | <span class="t">that I've been working on called llm.c.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=14197" target="_blank">03:56:37.360</a></span> | <span class="t">And llm.c is a pure C CUDA implementation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=14202" target="_blank">03:56:42.160</a></span> | <span class="t">of GPT-2 or GPT-3 training.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=14204" target="_blank">03:56:44.080</a></span> | <span class="t">And it just directly uses CUDA and is written as C CUDA.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=14209" target="_blank">03:56:49.040</a></span> | <span class="t">Now, the NanoGPT here acts as reference code in PyTorch</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=14213" target="_blank">03:56:53.200</a></span> | <span class="t">to the C implementation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=14214" target="_blank">03:56:54.560</a></span> | <span class="t">So we're trying to exactly match up the two,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=14216" target="_blank">03:56:56.800</a></span> | <span class="t">but we're hoping that the C CUDA is faster</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=14219" target="_blank">03:56:59.440</a></span> | <span class="t">and, of course, currently that seems to be the case</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=14221" target="_blank">03:57:01.280</a></span> | <span class="t">because it is a direct optimized implementation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=14224" target="_blank">03:57:04.400</a></span> | <span class="t">So train gpt2.py in llm.c is basically the NanoGPT.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=14229" target="_blank">03:57:09.600</a></span> | <span class="t">And when you scroll through this file,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=14232" target="_blank">03:57:12.000</a></span> | <span class="t">you'll find a lot of things that very much look like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=14235" target="_blank">03:57:15.200</a></span> | <span class="t">things that we've built up in this lecture.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=14239" target="_blank">03:57:19.360</a></span> | <span class="t">And then when you look at train gpt2.cu,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=14242" target="_blank">03:57:22.480</a></span> | <span class="t">this is the C CUDA implementation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=14246" target="_blank">03:57:26.080</a></span> | <span class="t">So there's a lot of MPI, NICL, GPU, CUDA, C, C++.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=14251" target="_blank">03:57:31.040</a></span> | <span class="t">And you have to be familiar with that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=14253" target="_blank">03:57:33.040</a></span> | <span class="t">But when this is built up,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=14257" target="_blank">03:57:37.120</a></span> | <span class="t">we can actually run the two side by side</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=14259" target="_blank">03:57:39.440</a></span> | <span class="t">and they're going to produce the exact same results,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=14261" target="_blank">03:57:41.600</a></span> | <span class="t">but llm.c actually runs faster.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=14263" target="_blank">03:57:43.760</a></span> | <span class="t">So let's see that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=14264" target="_blank">03:57:44.480</a></span> | <span class="t">So on the left, I have PyTorch, a NanoGPT looking thing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=14269" target="_blank">03:57:49.680</a></span> | <span class="t">On the right, I have the llm.c call.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=14271" target="_blank">03:57:51.840</a></span> | <span class="t">And here I'm gonna launch the two.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=14275" target="_blank">03:57:55.040</a></span> | <span class="t">Both of these are gonna be running on a single GPU.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=14277" target="_blank">03:57:57.120</a></span> | <span class="t">And here I'm putting the llm.c on GPU one,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=14279" target="_blank">03:57:59.680</a></span> | <span class="t">and this one will grab GPU zero by default.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=14282" target="_blank">03:58:02.800</a></span> | <span class="t">And then we can see here that llm.c compiled</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=14288" target="_blank">03:58:08.320</a></span> | <span class="t">and then allocate space and it's stepping.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=14292" target="_blank">03:58:12.240</a></span> | <span class="t">So basically, meanwhile, PyTorch is still compiling</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=14298" target="_blank">03:58:18.320</a></span> | <span class="t">because Torch compile is a bit slower here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=14301" target="_blank">03:58:21.120</a></span> | <span class="t">than the llm.c NVCC C CUDA compile.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=14305" target="_blank">03:58:25.280</a></span> | <span class="t">And so this program has already started running</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=14307" target="_blank">03:58:27.520</a></span> | <span class="t">and we're still waiting here for Torch compile.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=14310" target="_blank">03:58:30.400</a></span> | <span class="t">Now, of course, this is a very specific implementation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=14313" target="_blank">03:58:33.440</a></span> | <span class="t">to GPT-2 and 3.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=14315" target="_blank">03:58:35.040</a></span> | <span class="t">PyTorch is a very general neural network framework,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=14317" target="_blank">03:58:37.440</a></span> | <span class="t">so they're not exactly comparable.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=14318" target="_blank">03:58:38.960</a></span> | <span class="t">But if you're only interested in training GPT-2 and 3,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=14321" target="_blank">03:58:41.280</a></span> | <span class="t">llm.c is very fast, it takes less space,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=14325" target="_blank">03:58:45.520</a></span> | <span class="t">it's faster to start, and it's faster per step.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=14329" target="_blank">03:58:49.360</a></span> | <span class="t">And so PyTorch started stepping here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=14333" target="_blank">03:58:53.120</a></span> | <span class="t">And as you can see, we're running</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=14334" target="_blank">03:58:54.560</a></span> | <span class="t">at about 223,000 tokens per second here,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=14337" target="_blank">03:58:57.520</a></span> | <span class="t">and about 185,000 tokens per second here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=14340" target="_blank">03:59:00.480</a></span> | <span class="t">So quite a bit slower, but I don't have full confidence</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=14345" target="_blank">03:59:05.680</a></span> | <span class="t">that I exactly squeezed out all the juice</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=14348" target="_blank">03:59:08.640</a></span> | <span class="t">from the PyTorch implementation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=14350" target="_blank">03:59:10.240</a></span> | <span class="t">But the important thing here is notice</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=14352" target="_blank">03:59:12.320</a></span> | <span class="t">that if I align up the steps,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=14354" target="_blank">03:59:14.800</a></span> | <span class="t">you will see that the losses and the norms</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=14356" target="_blank">03:59:16.880</a></span> | <span class="t">that are printed between these two are identical.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=14359" target="_blank">03:59:19.200</a></span> | <span class="t">So on the left, we have the PyTorch,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=14361" target="_blank">03:59:21.920</a></span> | <span class="t">and on the right, this C code implementation,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=14364" target="_blank">03:59:24.640</a></span> | <span class="t">and they're the same, except this one runs faster.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=14367" target="_blank">03:59:27.600</a></span> | <span class="t">I wanted to show you also briefly llm.c,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=14372" target="_blank">03:59:32.000</a></span> | <span class="t">and this is a parallel implementation,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=14374" target="_blank">03:59:34.000</a></span> | <span class="t">and it's also something that you may want</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=14375" target="_blank">03:59:35.600</a></span> | <span class="t">to play with or look at, and it's kind of interesting.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=14379" target="_blank">03:59:39.520</a></span> | <span class="t">Okay, so at this point, I should probably start</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=14381" target="_blank">03:59:41.280</a></span> | <span class="t">wrapping up the video, because I think</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=14382" target="_blank">03:59:42.800</a></span> | <span class="t">it's getting way longer than anticipated.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=14385" target="_blank">03:59:45.280</a></span> | <span class="t">But we did cover a lot of ground,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=14387" target="_blank">03:59:47.040</a></span> | <span class="t">and we built everything from scratch.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=14388" target="_blank">03:59:48.720</a></span> | <span class="t">So as a brief summary, we were looking</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=14391" target="_blank">03:59:51.280</a></span> | <span class="t">at the GPT-2 and GPT-3 papers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=14394" target="_blank">03:59:54.560</a></span> | <span class="t">We were looking at how you set up these training runs,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=14398" target="_blank">03:59:58.240</a></span> | <span class="t">and all the considerations involved.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=14400" target="_blank">04:00:00.640</a></span> | <span class="t">We wrote everything from scratch,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=14402" target="_blank">04:00:02.560</a></span> | <span class="t">and then we saw that over the duration</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=14404" target="_blank">04:00:04.160</a></span> | <span class="t">of either a two-hour training run or an overnight run,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=14407" target="_blank">04:00:07.280</a></span> | <span class="t">we can actually match the 124 million parameter checkpoints</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=14410" target="_blank">04:00:10.800</a></span> | <span class="t">of GPT-2 and GPT-3 to a very large extent.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=14413" target="_blank">04:00:13.760</a></span> | <span class="t">In principle, the code that we wrote</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=14416" target="_blank">04:00:16.560</a></span> | <span class="t">would be able to train even bigger models</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=14418" target="_blank">04:00:18.480</a></span> | <span class="t">if you have the patience or the computing resources,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=14421" target="_blank">04:00:21.120</a></span> | <span class="t">and so you could potentially think about training</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=14423" target="_blank">04:00:23.200</a></span> | <span class="t">some of the bigger checkpoints as well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=14424" target="_blank">04:00:24.480</a></span> | <span class="t">There are a few remaining issues to address.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=14428" target="_blank">04:00:28.480</a></span> | <span class="t">What's happening with the loss here,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=14430" target="_blank">04:00:30.080</a></span> | <span class="t">which I suspect has to do</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=14431" target="_blank">04:00:31.280</a></span> | <span class="t">with the fine web EDU data sampling.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=14433" target="_blank">04:00:33.440</a></span> | <span class="t">Why can't we turn on Torch Compile?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=14436" target="_blank">04:00:36.400</a></span> | <span class="t">It currently breaks generation and Hellaswag.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=14439" target="_blank">04:00:39.040</a></span> | <span class="t">What's up with that?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=14440" target="_blank">04:00:40.240</a></span> | <span class="t">In the data loader, we should probably be permuting our data</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=14442" target="_blank">04:00:42.640</a></span> | <span class="t">when we reach epoch boundaries.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=14444" target="_blank">04:00:44.800</a></span> | <span class="t">So there's a few more issues like that,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=14446" target="_blank">04:00:46.400</a></span> | <span class="t">and I expect to be documenting some of those over time</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=14449" target="_blank">04:00:49.040</a></span> | <span class="t">in the Build NanoGPT repository here,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=14451" target="_blank">04:00:51.920</a></span> | <span class="t">which I'm going to be releasing with this video.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=14455" target="_blank">04:00:55.120</a></span> | <span class="t">If you have any questions</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=14457" target="_blank">04:00:57.200</a></span> | <span class="t">or would like to talk about anything that we covered,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=14459" target="_blank">04:00:59.600</a></span> | <span class="t">please go to discussions tab so we can talk here,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=14462" target="_blank">04:01:02.640</a></span> | <span class="t">or please go to issues or pull requests</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=14466" target="_blank">04:01:06.400</a></span> | <span class="t">depending on what you'd like to contribute,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=14468" target="_blank">04:01:08.720</a></span> | <span class="t">or also have a look at the Zero2Hero Discord,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=14473" target="_blank">04:01:13.120</a></span> | <span class="t">and I'm going to be hanging out here on NanoGPT.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=14478" target="_blank">04:01:18.000</a></span> | <span class="t">Otherwise, for now, I'm pretty happy about where we got,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=14480" target="_blank">04:01:20.960</a></span> | <span class="t">and I hope you enjoyed the video,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU&t=14484" target="_blank">04:01:24.160</a></span> | <span class="t">and I will see you later.</span></div></div></body></html>