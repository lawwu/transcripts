<html><head><title>Accelerating Mixture of Experts Training With Rail Optimized InfiniBand Networking in Crusoe Cloud</title>
<style>
    body {
        font-family: Arial, sans-serif;
        margin: 0;
        padding: 0;
        background-color: #f4f4f4;
        color: #333;
    }
    .container {
        width: 95%;  /* Increased width to use more space */
        margin: auto;
        overflow: auto;  /* Added to handle overflow by adding a scrollbar if necessary */
    }
    h2, h3 {
        color: #333;
        text-align: center;
    }
    a {
        color: #0000FF;  /* Traditional blue color for links */
        text-decoration: none;
    }
    a:hover {
        text-decoration: underline;
    }
    img {
        display: block;
        margin: auto;
        max-width: 100%;
    }
    .c {
        margin: 10px 0;
    }
    .s, .t {
        display: inline-block;
        margin-right: 5px;
    }
    .max-width {
        max-width: 800px;
        margin: auto;
        padding-left: 20px;
    }
    table {
        width: 100%;
        border-collapse: collapse;
    }
    th, td {
        border: 1px solid #ddd;
        padding: 8px;
        text-align: left;  /* Ensure text alignment is consistent */
    }
    tr:nth-child(even) {
        background-color: #f2f2f2;
    }
    tr:nth-child(odd) {
        background-color: #e6e6e6;
    }
</style>

    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-69VLBMTTP0"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-69VLBMTTP0');
    </script>
    </head><body><div class='container'><a href="index.html">back to index</a><h2>Accelerating Mixture of Experts Training With Rail Optimized InfiniBand Networking in Crusoe Cloud</h2><a href="https://www.youtube.com/watch?v=tQTB4MU_z8w"><img src="https://i.ytimg.com/vi_webp/tQTB4MU_z8w/maxresdefault.webp" style="width:50%;"></a><div><br></div><div style="text-align: left;"><a href="./tQTB4MU_z8w.html">Whisper Transcript</a> | <a href="./transcript_tQTB4MU_z8w.html">Transcript Only Page</a></div><br><div style="max-width: 800px;"><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tQTB4MU_z8w&t=0" target="_blank">00:00:00.000</a></span> | <span class="t">thank you for coming over to our session today a lots of really interesting stuff is happening on</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tQTB4MU_z8w&t=18" target="_blank">00:00:18.900</a></span> | <span class="t">the AI world these days right with all the recent model developments in the GPU developments it is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tQTB4MU_z8w&t=26" target="_blank">00:00:26.520</a></span> | <span class="t">really cool to see all the use cases however here I want to talk now a little bit about the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tQTB4MU_z8w&t=34" target="_blank">00:00:34.280</a></span> | <span class="t">infrastructure and the way how we can support the newest models of the GPUs and the newest the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tQTB4MU_z8w&t=42" target="_blank">00:00:42.360</a></span> | <span class="t">newest models the machine learning models and how we can help that everything is working smoothly and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tQTB4MU_z8w&t=47" target="_blank">00:00:47.940</a></span> | <span class="t">fast and and productive so my name is Evgeny Bakulinko I'm a product manager at Crusoe my</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tQTB4MU_z8w&t=56" target="_blank">00:00:56.100</a></span> | <span class="t">main responsibility is is the infrastructure and specifically GPU networking infrastructure and we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tQTB4MU_z8w&t=64" target="_blank">00:01:04.200</a></span> | <span class="t">are always looking for a way how we can increase the performance of that network because as we will see</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tQTB4MU_z8w&t=70" target="_blank">00:01:10.500</a></span> | <span class="t">later in the presentation it is really important to do that now a little bit about the Crusoe Crusoe is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tQTB4MU_z8w&t=78" target="_blank">00:01:18.000</a></span> | <span class="t">an AI cloud platform which has one I think very important mission for all of us it's to align the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tQTB4MU_z8w&t=84" target="_blank">00:01:24.780</a></span> | <span class="t">future of computing with the future of climate there is a really strong demand right now for the computing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tQTB4MU_z8w&t=90" target="_blank">00:01:30.420</a></span> | <span class="t">power the GPUs are really energy hungry there is a lot of investments being done in the data center area</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tQTB4MU_z8w&t=97" target="_blank">00:01:37.140</a></span> | <span class="t">and of course that puts an additional pressure on the grid and on the energy sources what we are trying</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tQTB4MU_z8w&t=103" target="_blank">00:01:43.620</a></span> | <span class="t">to do here at Crusoe we are trying to utilize the stranded energy sources wasted energy sources and renewables</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tQTB4MU_z8w&t=110" target="_blank">00:01:50.980</a></span> | <span class="t">to power our data centers we want really to be able to make sure that every time when you train your model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tQTB4MU_z8w&t=117" target="_blank">00:01:57.780</a></span> | <span class="t">every time when you're using GPU for inference you're not causing any negative impact on the climate now</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tQTB4MU_z8w&t=126" target="_blank">00:02:06.180</a></span> | <span class="t">whenever we are building the cloud right the AI cloud we are building it based on three important pillars</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tQTB4MU_z8w&t=134" target="_blank">00:02:14.660</a></span> | <span class="t">first of all there is a high performance pillar as the customers are buying our services and procuring you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tQTB4MU_z8w&t=142" target="_blank">00:02:22.260</a></span> | <span class="t">you know the GPU times and training their models we have to ensure that all the infrastructure is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tQTB4MU_z8w&t=147" target="_blank">00:02:27.860</a></span> | <span class="t">optimized for this training every time when it's not optimized every time when there is a delay or a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tQTB4MU_z8w&t=153" target="_blank">00:02:33.380</a></span> | <span class="t">glitch or any sort of outage or simply not that great performance it causes the direct impact on the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tQTB4MU_z8w&t=161" target="_blank">00:02:41.620</a></span> | <span class="t">customer's bottom line it causes a direct impact on the time to train and kind of raises the cost to train</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tQTB4MU_z8w&t=168" target="_blank">00:02:48.420</a></span> | <span class="t">the model now the second one which i think is very important for everybody around here is the easy to use</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tQTB4MU_z8w&t=175" target="_blank">00:02:55.140</a></span> | <span class="t">we want really to separate ourselves from the general purpose clouds</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tQTB4MU_z8w&t=181" target="_blank">00:03:01.140</a></span> | <span class="t">we do know all of them the hyperscalers are building the great infrastructure and are trying to support</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tQTB4MU_z8w&t=186" target="_blank">00:03:06.980</a></span> | <span class="t">each and every use case the customers might have for the cloud computing however in our case we really</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tQTB4MU_z8w&t=193" target="_blank">00:03:13.060</a></span> | <span class="t">want to focus on the experience of the AI engineers so we want to make sure that we are providing a simpler</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tQTB4MU_z8w&t=200" target="_blank">00:03:20.180</a></span> | <span class="t">user interface that allows developers to spin up the compute resources to deploy the models to train them to use</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tQTB4MU_z8w&t=207" target="_blank">00:03:27.380</a></span> | <span class="t">them to in for inference and and so on uh all the underlying complexity of the infrastructure</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tQTB4MU_z8w&t=214" target="_blank">00:03:34.580</a></span> | <span class="t">is being hidden by us and i believe that's our job to make sure that that is that stays the case</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tQTB4MU_z8w&t=223" target="_blank">00:03:43.060</a></span> | <span class="t">and now as i mentioned we are as i mentioned before we are climate aligned which means uh we as a company</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tQTB4MU_z8w&t=229" target="_blank">00:03:49.620</a></span> | <span class="t">really aiming to power 100 percent of our data centers with the renewable wasted energy sources</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tQTB4MU_z8w&t=236" target="_blank">00:03:56.820</a></span> | <span class="t">with some some some form of stranded energy sources to ensure that we are uh we are being net zero</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tQTB4MU_z8w&t=246" target="_blank">00:04:06.260</a></span> | <span class="t">emission net new zero emissions from the carbon perspective we have a big story around that feel</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tQTB4MU_z8w&t=252" target="_blank">00:04:12.580</a></span> | <span class="t">free to check it on our website or come over to our booth on the on the show floor and the team will happy</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tQTB4MU_z8w&t=259" target="_blank">00:04:19.060</a></span> | <span class="t">to talk about that now where are we present right now we have a number of the data centers located across</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tQTB4MU_z8w&t=266" target="_blank">00:04:26.740</a></span> | <span class="t">the u.s uh as you see three of them in the continental united states and they are generally located close to the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tQTB4MU_z8w&t=276" target="_blank">00:04:36.420</a></span> | <span class="t">energy sources i was mentioning before so we have the one in texas we have uh the one in the northern</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tQTB4MU_z8w&t=283" target="_blank">00:04:43.300</a></span> | <span class="t">central part of the country and on the east we are also building right now one big data center in iceland</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tQTB4MU_z8w&t=290" target="_blank">00:04:50.900</a></span> | <span class="t">that will be powered by the gerothermal energy i mean again a way amazing way to use the constrained energy</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tQTB4MU_z8w&t=299" target="_blank">00:04:59.220</a></span> | <span class="t">resources or the renewables to power the data center we are trying to follow that model hence we are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tQTB4MU_z8w&t=305" target="_blank">00:05:05.300</a></span> | <span class="t">placing our data center strategically the placement of the data center in iceland though will be also very</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tQTB4MU_z8w&t=311" target="_blank">00:05:11.380</a></span> | <span class="t">important for our emir customers given the latency and and the general connectivity to the europe that is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tQTB4MU_z8w&t=318" target="_blank">00:05:18.740</a></span> | <span class="t">something i think uh might be helpful for them as well now what is our platform right i say</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tQTB4MU_z8w&t=329" target="_blank">00:05:29.060</a></span> | <span class="t">cruzo cloud but generally whenever we are talking about any cloud we are talking about three general</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tQTB4MU_z8w&t=335" target="_blank">00:05:35.140</a></span> | <span class="t">types of the products first and foremost we have the compute we are offering the vms with uh with gpus</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tQTB4MU_z8w&t=342" target="_blank">00:05:42.740</a></span> | <span class="t">attached to them so every time when customer wants to spin up when customer wants to get access to the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tQTB4MU_z8w&t=348" target="_blank">00:05:48.660</a></span> | <span class="t">gpus they're able to get it through the vm they can get a bunch of vm connected together and use them as a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tQTB4MU_z8w&t=357" target="_blank">00:05:57.060</a></span> | <span class="t">one single training cluster we also offer cpu instances for any potential data pre-processing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tQTB4MU_z8w&t=363" target="_blank">00:06:03.700</a></span> | <span class="t">or any general purpose compute tasks you might have for the data preparation for the offload</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tQTB4MU_z8w&t=369" target="_blank">00:06:09.700</a></span> | <span class="t">whatever you have uh from the storage perspective we are offering ephemeral and persistent disks on the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tQTB4MU_z8w&t=377" target="_blank">00:06:17.860</a></span> | <span class="t">node so those are delivered from the nvme on the local server where your vms are being placed we also have the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tQTB4MU_z8w&t=385" target="_blank">00:06:25.940</a></span> | <span class="t">persistent block storage storage solution available for our customers and we are working on providing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tQTB4MU_z8w&t=392" target="_blank">00:06:32.180</a></span> | <span class="t">and delivering the managed file system the network file systems for the customers on the networking</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tQTB4MU_z8w&t=398" target="_blank">00:06:38.100</a></span> | <span class="t">side of course more traditional more typical vpc networking that's the network sometimes we call it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tQTB4MU_z8w&t=405" target="_blank">00:06:45.620</a></span> | <span class="t">front-end network that is used to deliver the customer traffic from the internet or from the customer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tQTB4MU_z8w&t=411" target="_blank">00:06:51.860</a></span> | <span class="t">environment wherever the customer might have the data sources to deliver that towards the vm so that's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tQTB4MU_z8w&t=418" target="_blank">00:06:58.500</a></span> | <span class="t">your kind of main connectivity uh path to the outside world now uh we do offer a number of the additional</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tQTB4MU_z8w&t=426" target="_blank">00:07:06.660</a></span> | <span class="t">services on that that's not simply connectivity we also have the firewalls we will be offering the load</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tQTB4MU_z8w&t=432" target="_blank">00:07:12.340</a></span> | <span class="t">balancers soon but generally we are trying to follow more traditional paths for the vpc networking and and the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tQTB4MU_z8w&t=439" target="_blank">00:07:19.940</a></span> | <span class="t">requirements the customers usually have there now what is more interesting and what we will be talking a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tQTB4MU_z8w&t=445" target="_blank">00:07:25.860</a></span> | <span class="t">little bit later today in greater details is our rail optimized infiniband cluster networking so for those</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tQTB4MU_z8w&t=453" target="_blank">00:07:33.140</a></span> | <span class="t">of you who don't know typically customers typically providers the gpu providers are separating their network</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tQTB4MU_z8w&t=460" target="_blank">00:07:40.020</a></span> | <span class="t">they have the front-end network which is used for general purpose traffic but then all the communication</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tQTB4MU_z8w&t=465" target="_blank">00:07:45.220</a></span> | <span class="t">between the gpus is happening on the stand-alone separate network that is really high performance low</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tQTB4MU_z8w&t=473" target="_blank">00:07:53.700</a></span> | <span class="t">latency and how bandwidth and the whole topology is optimized for the gpu to gpu communication</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tQTB4MU_z8w&t=479" target="_blank">00:07:59.300</a></span> | <span class="t">now last but not least the user experience as i mentioned before we are our main customers our main</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tQTB4MU_z8w&t=487" target="_blank">00:08:07.780</a></span> | <span class="t">persona the people who are using cruiser cloud are the ai developers and machine learning engineers so we want to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tQTB4MU_z8w&t=494" target="_blank">00:08:14.980</a></span> | <span class="t">make sure they have what they need in order you know to be successful and not to think too much about</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tQTB4MU_z8w&t=502" target="_blank">00:08:22.340</a></span> | <span class="t">infrastructure we also offer cli we have apis we have guis so everything can be automated everything can be</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tQTB4MU_z8w&t=509" target="_blank">00:08:29.540</a></span> | <span class="t">can be consumed and configured in the way you like it more uh we do have a lot of customers already and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tQTB4MU_z8w&t=519" target="_blank">00:08:39.140</a></span> | <span class="t">it was very fun for me to see on the floor that some of them are there and some of them are talking about their solutions</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tQTB4MU_z8w&t=526" target="_blank">00:08:46.020</a></span> | <span class="t">probably this is the first time in my</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tQTB4MU_z8w&t=529" target="_blank">00:08:49.380</a></span> | <span class="t">life whenever i'm attending a conference and standing at the booth i don't have to compete with all the people around us</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tQTB4MU_z8w&t=536" target="_blank">00:08:56.980</a></span> | <span class="t">so we do see all the companies that are presenting their solutions right now as our partner partners</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tQTB4MU_z8w&t=543" target="_blank">00:09:03.620</a></span> | <span class="t">we do partner with a bunch of them already we have the together ai here we have the boson ai and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tQTB4MU_z8w&t=550" target="_blank">00:09:10.900</a></span> | <span class="t">all of them are using our infrastructure for different purposes so together ai for example</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tQTB4MU_z8w&t=556" target="_blank">00:09:16.260</a></span> | <span class="t">they're really into using cruiser infrastructure for the ml training for the fine tuning their models and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tQTB4MU_z8w&t=563" target="_blank">00:09:23.220</a></span> | <span class="t">some sometimes for some sometimes for inference the c dot ai is uh they're trade they're using our compute</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tQTB4MU_z8w&t=570" target="_blank">00:09:30.820</a></span> | <span class="t">infrastructure to train the new foundational models this is really great i mean if you're the customer of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tQTB4MU_z8w&t=577" target="_blank">00:09:37.060</a></span> | <span class="t">together ai for example or codium or whatnot it is likely that you have been somehow exposed to the cruiser</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tQTB4MU_z8w&t=584" target="_blank">00:09:44.660</a></span> | <span class="t">infrastructure now the distributed training has a very specific set of problems or issues right</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tQTB4MU_z8w&t=595" target="_blank">00:09:55.140</a></span> | <span class="t">there is a compute part of it when the computation is being done on the gpus but since we're talking</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tQTB4MU_z8w&t=601" target="_blank">00:10:01.860</a></span> | <span class="t">about a distributed training which means there are a lot of gpus at certain stages whenever there is a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tQTB4MU_z8w&t=608" target="_blank">00:10:08.660</a></span> | <span class="t">whenever there is a training step being completed all the gpus have to exchange the information have to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tQTB4MU_z8w&t=615" target="_blank">00:10:15.620</a></span> | <span class="t">exchange the data that they calculated on their own this is typically done through the all reduce or</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tQTB4MU_z8w&t=621" target="_blank">00:10:21.540</a></span> | <span class="t">or all all all get through the only reduce process and the protocols and it contains a forward path the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tQTB4MU_z8w&t=632" target="_blank">00:10:32.020</a></span> | <span class="t">backward path but then the networking part takes without any optimization about</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tQTB4MU_z8w&t=638" target="_blank">00:10:38.180</a></span> | <span class="t">25 30 of the network of the time of the training time now this is the time where when your gpus are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tQTB4MU_z8w&t=647" target="_blank">00:10:47.220</a></span> | <span class="t">staying idle they're not being able to compute anything because they have to wait for all the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tQTB4MU_z8w&t=652" target="_blank">00:10:52.580</a></span> | <span class="t">information to be gathered uh together this is kind of a bad thing for everybody right this is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tQTB4MU_z8w&t=659" target="_blank">00:10:59.540</a></span> | <span class="t">bad thing for the customers because they still pay for that infrastructure they still have to wait it delays the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tQTB4MU_z8w&t=666" target="_blank">00:11:06.020</a></span> | <span class="t">the model model training but it also bad for us because we have the infrastructure that is not being</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tQTB4MU_z8w&t=671" target="_blank">00:11:11.620</a></span> | <span class="t">performing enough there are a couple of tricks we can do first of all the computation and communication</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tQTB4MU_z8w&t=677" target="_blank">00:11:17.460</a></span> | <span class="t">overlap allows you to start the network exchange or the data exchange when the computation is still ongoing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tQTB4MU_z8w&t=686" target="_blank">00:11:26.420</a></span> | <span class="t">but even with that when we were working with the customers we saw just the reduction uh of about 10</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tQTB4MU_z8w&t=694" target="_blank">00:11:34.580</a></span> | <span class="t">percent so about 25 percent of the training time was still spent on the network me as a product manager</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tQTB4MU_z8w&t=701" target="_blank">00:11:41.700</a></span> | <span class="t">on the infrastructure side are constantly being asked like how can we reduce that how can we use the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tQTB4MU_z8w&t=707" target="_blank">00:11:47.940</a></span> | <span class="t">network as much as possible and reduce that gap so we we have been looking into that and we were trying to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tQTB4MU_z8w&t=715" target="_blank">00:11:55.060</a></span> | <span class="t">figure out what would be the right cluster networking topology how can we make sure that our data fabric</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tQTB4MU_z8w&t=722" target="_blank">00:12:02.260</a></span> | <span class="t">that is used for connecting the gpus is being fully optimized and is being is able to provide the bandwidth</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tQTB4MU_z8w&t=730" target="_blank">00:12:10.740</a></span> | <span class="t">needed and the latency needed the standard fat tree those of you who have been working in the data center</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tQTB4MU_z8w&t=736" target="_blank">00:12:16.660</a></span> | <span class="t">infrastructure before that is something that we were traditionally doing for years that's a great way to build</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tQTB4MU_z8w&t=743" target="_blank">00:12:23.220</a></span> | <span class="t">a scalable maybe non-blocking fabric right but there are a bunch of issues with that first of all if</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tQTB4MU_z8w&t=751" target="_blank">00:12:31.460</a></span> | <span class="t">we will be connecting our servers that are shown below to a single leaf that introduces the single choke</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tQTB4MU_z8w&t=758" target="_blank">00:12:38.420</a></span> | <span class="t">point as well as the single fault domain right if we are losing the leaf we are losing all the gpus that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tQTB4MU_z8w&t=765" target="_blank">00:12:45.380</a></span> | <span class="t">are connected to that now what else we were thinking about is like look we have that switch we have that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tQTB4MU_z8w&t=775" target="_blank">00:12:55.140</a></span> | <span class="t">switch sorry what is it the time okay so we have that switch that can be used for the back-end traffic</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tQTB4MU_z8w&t=783" target="_blank">00:13:03.140</a></span> | <span class="t">propagation and why don't we use that switch for from the bandwidth perspective and kind of you know have an</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tQTB4MU_z8w&t=790" target="_blank">00:13:10.020</a></span> | <span class="t">additional path let me just use the simple two node uh example to explain the topology and to explain how we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tQTB4MU_z8w&t=798" target="_blank">00:13:18.020</a></span> | <span class="t">are using it so first of all whenever we have the gpus that want to communicate within one server they can</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tQTB4MU_z8w&t=804" target="_blank">00:13:24.420</a></span> | <span class="t">use their embedded and vlink and we switch and that provides a good communication they don't have to go to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tQTB4MU_z8w&t=811" target="_blank">00:13:31.140</a></span> | <span class="t">the outside fabric anywhere and whatnot now whenever we have the data communication between the gpus on</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tQTB4MU_z8w&t=820" target="_blank">00:13:40.180</a></span> | <span class="t">the different nodes if they collect if they are connected to the single leaf that's something we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tQTB4MU_z8w&t=824" target="_blank">00:13:44.980</a></span> | <span class="t">called one single rail that means that the traffic communication will be passing through the uh through</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tQTB4MU_z8w&t=831" target="_blank">00:13:51.220</a></span> | <span class="t">the one single leaf just one hop away and you will get the to the destination now what is interesting here is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tQTB4MU_z8w&t=838" target="_blank">00:13:58.820</a></span> | <span class="t">when we want to talk to the different trails right we have to go all the way to the spine and that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tQTB4MU_z8w&t=844" target="_blank">00:14:04.900</a></span> | <span class="t">introduces the additional hop besides the bandwidth saturation problems that may lead to the additional</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tQTB4MU_z8w&t=851" target="_blank">00:14:11.460</a></span> | <span class="t">latency which will be really important for all for your uh all reduce all reduce operations but luckily for us</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tQTB4MU_z8w&t=862" target="_blank">00:14:22.100</a></span> | <span class="t">and video with the recent version of nickel introduced the feature called pxn which allows you to use</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tQTB4MU_z8w&t=868" target="_blank">00:14:28.740</a></span> | <span class="t">the internal and we switch inside the host to communicate across the rails so whenever we want</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tQTB4MU_z8w&t=875" target="_blank">00:14:35.460</a></span> | <span class="t">to have the gpu zero to communicate with the gpu 8 on the another host we can use an internal switch</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tQTB4MU_z8w&t=883" target="_blank">00:14:43.380</a></span> | <span class="t">to do the traffic hub between the gpus and then send it to the leaf where it is connected to so it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tQTB4MU_z8w&t=888" target="_blank">00:14:48.820</a></span> | <span class="t">still allows us to use one single hop and have access across the different rails of the gpus now</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tQTB4MU_z8w&t=898" target="_blank">00:14:58.660</a></span> | <span class="t">we did some nickel test results uh and we saw quite a significant improvement 50 for the small messages</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tQTB4MU_z8w&t=906" target="_blank">00:15:06.580</a></span> | <span class="t">and 50 of the large messages now those numbers here are of course for the smaller uh for the smaller</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tQTB4MU_z8w&t=912" target="_blank">00:15:12.500</a></span> | <span class="t">uh for the smaller messages are about latency for larger ones we care more about bandwidth because</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tQTB4MU_z8w&t=918" target="_blank">00:15:18.100</a></span> | <span class="t">latency tends to stand to stay roughly the same uh those numbers are great right everybody everybody would love them but not the customers and it does make sense because</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tQTB4MU_z8w&t=928" target="_blank">00:15:28.580</a></span> | <span class="t">those numbers are synthetic and more are showing you the workload that is applied to your network what</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tQTB4MU_z8w&t=935" target="_blank">00:15:35.140</a></span> | <span class="t">customers care about is the time to train the particular model so we use the sparse mixture of expert</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tQTB4MU_z8w&t=942" target="_blank">00:15:42.500</a></span> | <span class="t">as an example and uh i mean i'm not going to dive into the details how how it works but essentially</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tQTB4MU_z8w&t=950" target="_blank">00:15:50.740</a></span> | <span class="t">the sparse network the the sparse mixture of experts shows you gives you a different layers of the experts and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tQTB4MU_z8w&t=958" target="_blank">00:15:58.500</a></span> | <span class="t">the network that allows the traffic between them whenever you're deploying that on the li really</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tQTB4MU_z8w&t=962" target="_blank">00:16:02.900</a></span> | <span class="t">large gpu cluster that makes uh that creates a ton of traffic like all the gpus have to send the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tQTB4MU_z8w&t=971" target="_blank">00:16:11.380</a></span> | <span class="t">traffic to each other they have to extend the information the workload on the network is pretty significant</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tQTB4MU_z8w&t=976" target="_blank">00:16:16.820</a></span> | <span class="t">so we use the mixture model the open source uh sparse mixture of experts which is contained of eight feed forward blocks</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tQTB4MU_z8w&t=988" target="_blank">00:16:28.420</a></span> | <span class="t">eight seven billions of parameters and we use the fine tuning to use this model to fine tune it on 240 h100 gpus</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tQTB4MU_z8w&t=997" target="_blank">00:16:37.780</a></span> | <span class="t">and we did a quite significant we saw a quite significant improvement when we had the pxn enabled and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tQTB4MU_z8w&t=1004" target="_blank">00:16:44.500</a></span> | <span class="t">without it the 14 percent of improvement is something that can be directly connected to the time to train the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tQTB4MU_z8w&t=1011" target="_blank">00:16:51.940</a></span> | <span class="t">model that can be directly connected to cost of train the model and that is something that everybody really</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tQTB4MU_z8w&t=1018" target="_blank">00:16:58.340</a></span> | <span class="t">uh really got excited i definitely got excited and and our customers as well because that shows them</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tQTB4MU_z8w&t=1024" target="_blank">00:17:04.500</a></span> | <span class="t">some real value numbers they can get with a model now that was it from my side sorry for uh going through</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tQTB4MU_z8w&t=1032" target="_blank">00:17:12.100</a></span> | <span class="t">that it's so fast it's a very you know large topic it's it's hard to talk about that but i'm happy to answer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tQTB4MU_z8w&t=1039" target="_blank">00:17:19.220</a></span> | <span class="t">all the additional questions anything you guys might have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tQTB4MU_z8w&t=1056" target="_blank">00:17:36.420</a></span> | <span class="t">you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=tQTB4MU_z8w&t=1060" target="_blank">00:17:40.260</a></span> | <span class="t">We'll see you next time.</span></div></div></body></html>