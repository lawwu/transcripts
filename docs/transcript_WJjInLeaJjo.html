<html><head><title>Building Agents at Cloud Scale — Antje Barth, AWS</title>
<style>
    body {
        font-family: Arial, sans-serif;
        margin: 0;
        padding: 0;
        background-color: #f4f4f4;
        color: #333;
    }
    .container {
        width: 95%;  /* Increased width to use more space */
        margin: auto;
        overflow: auto;  /* Added to handle overflow by adding a scrollbar if necessary */
    }
    h2, h3 {
        color: #333;
        text-align: center;
    }
    a {
        color: #0000FF;  /* Traditional blue color for links */
        text-decoration: none;
    }
    a:hover {
        text-decoration: underline;
    }
    img {
        display: block;
        margin: auto;
        max-width: 100%;
    }
    .c {
        margin: 10px 0;
    }
    .s, .t {
        display: inline-block;
        margin-right: 5px;
    }
    .max-width {
        max-width: 800px;
        margin: auto;
        padding-left: 20px;
    }
    table {
        width: 100%;
        border-collapse: collapse;
    }
    th, td {
        border: 1px solid #ddd;
        padding: 8px;
        text-align: left;  /* Ensure text alignment is consistent */
    }
    tr:nth-child(even) {
        background-color: #f2f2f2;
    }
    tr:nth-child(odd) {
        background-color: #e6e6e6;
    }
</style>

    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-69VLBMTTP0"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-69VLBMTTP0');
    </script>
    </head><body><div class='container'><a href="index.html">Back to Index</a><h2>Building Agents at Cloud Scale — Antje Barth, AWS</h2><a href="https://www.youtube.com/watch?v=WJjInLeaJjo" target="_blank"><img src="https://i.ytimg.com/vi_webp/WJjInLeaJjo/maxresdefault.webp" style="width:50%;"></a><div><br></div><h3>Transcript</h3><div class='max-width'><p>Hi everyone, I'm thrilled to be back on stage here again at the AI Engineer World's Fair, and it's amazing to see this community grow. So today, I'm going to speak about how we can build agents at CloudScale. Now, at Amazon and AWS, we truly believe that virtually every customer experience we know of will be reinvented with AI.</p><p>And not just the existing experiences, but there will also be brand new experiences we are now able to build the help of AI agents. And we're not just theorizing about this, right? We're all here together to actually build the future. Now, I want to start just with a little bit of what that means internally across Amazon as a business.</p><p>At Amazon, we have over 1,000 and we're talking about generative AI applications that are either built or in development transforming everything from how we forecast inventory to how we optimize delivery routes to how customers shop and how they interact with their homes. And one of the most ambitious deployments of AI agents is the complete reimagining of Alexa.</p><p>And I know many of us have been waiting for this for a long time. So what you're about to see here represents the largest integration of services, agentic capabilities, and LLMs that we know of anywhere. So let's have a brief look. Oh, hey there. So we can just like talk now.</p><p>I'm all ears, figuratively speaking. Do you know how to manage my kids' schedules? I noticed a birthday party conflicts with picking up grandma at the airport. Want me to book her a ride? Billie Eilish is in town soon. No way. I can share when tickets are available in your city.</p><p>Yes, please. Got any spring break ideas? Somewhere not too far. Only if there's a beach. And nice weather. Santa Barbara is great for everyone. I found a restaurant downtown I think you'd like. What is Santa Barbara known for? It has great upscale shops and oceanfront dining. Can you go whale watching?</p><p>Absolutely. Want me to book a catamaran tour? What's the next step? Remove the nut holding the cartridge. Should I get things? You might only love them for a little while. You're probably right. Make a slideshow of baby T-neck. Mom. What part am I looking for again? Two-inch washers. Your Uber is two minutes away.</p><p>For real? Wait, did someone let the dog out today? I checked the cameras. And yes, in fact, Mozart was just out. Wow. Wow. Look at my style. I know you ain't seen it like this in a while. Wow. Wow. I love sharing this video because it shows really the power of agents at scale.</p><p>And just to have a quick look what that means in terms of numbers. We have over 600 million Alexa devices now out in the world. And with the help of the latest advancements in AI, we were able to really reimagine this experience. Alexa Plus works through hundreds of specialized expert systems.</p><p>That's what the Alexa team calls groups of capabilities, APIs, and instructions to accomplish a specific task for you. And all of these experts also orchestrate across tens of thousands of partner services and devices to get the things done. Which you just see in a glimpse of this here in this video.</p><p>And we truly believe that the future will be full of those specialized agents. Each with their own unique capabilities and working together seamlessly with other AI agents. Now, this example shows what's possible at this massive scale. But how do we get there? How do we operate at this scale?</p><p>Or said differently, how do we move from web services that we've built for many years now into developing those agentic services? And luckily, many of the underlying principles remain the same. Whether you're building for millions of devices. Whether you're reimagining and integrating AI experiences into your enterprise applications. Or you're a startup and you're really just looking to kind of scale your idea to the next level.</p><p>Now, another example I want to show you is an agentic service that we built at AWS. You might have heard about Amazon Q Developer, which is our code assistant that helps you really kind of across the software development lifecycle. And just a few months ago, we released an queue developer agent for your CLI.</p><p>So it brings the agentic chat experience into the terminal. It helps you to debug issues. You can ask natural questions. It can read and write files. And really kind of help to make your day-to-day in the terminal more productive. So let's have a quick look how this looks. Here is Amazon Q in the CLI.</p><p>And I'll just ask a good question here. In this case, hey, what do you know about Amazon Bedrock? CLI is integrated with MCP. So what it does, it actually figures out there is a tool. Our AWS documentation team has released an MCP server. It's connecting to it. You see the tool is happening.</p><p>And it's asking for permissions. So I give it the permissions. And then it comes back with a response that is grounded in the official AWS documentation. Now, I don't want to talk much more about queue, but I do want to ask for you just to quickly think about how long did it take for the AWS internal teams to build and ship this agentic service.</p><p>And let's just do it with a quick raise of hands. Who think it took two months to develop and ship this? A few hands. Who thinks three weeks? All right. It's a bunch of more hands. Who do you think it took half a year? Almost none. Wow. You folks are great.</p><p>We built and ship this within three weeks. And to me, this is just almost insane, right? Like the speed. And we heard it earlier, like the mode of AI, one of the keynote speakers call it out, is execution, right? And I think three weeks is super impressive. Now, how do we enable teams, and not just internally at AWS, but in general, to build and ship production-ready AI agents this quickly?</p><p>What we did internally, our teams, we needed to fundamentally rethink how to build agents. And what we did is we developed a model-driven approach that really kind of taps into the power of LLMs these days and models that are so much more capable in deciding, planning, reasoning, taking actions.</p><p>And let the developers focus on what their agents should do, rather than telling it exactly how to do it. And the great news is, we made it available for all of you to use as well. So just a few weeks ago, we released Strands Agents. It's an open source Python SDK, which you can check out and start building and running AI agents in just a few lines of code.</p><p>So let me show you quickly how this looks like. And before I go in here, just a fun fact, if you wonder, why did they call it Strands Agents? Well, this is what happens if you let AI pick its own name. All right. So the reasoning behind, because, again, the AI agent is capable of reasoning, it came up with, like, think about the two strands of DNA.</p><p>And just like the two strands of DNA, Strands Agents connects the two core pieces of an agent together, the model and the tools. And it helps you building agents. It simplifies it by really relying on those state-of-the-art models to reason, to plan, and take action. You can simply start with defining a prompt and your tools in code, and then test it out locally.</p><p>And then once you're ready, deploy it, for example, in the cloud. And this is how simple it is. Again, just a couple of lines should look pretty familiar. You install Strands Agents, you import it, and then it comes with pre-built tools, which I talk about a little bit more in detail.</p><p>And basically, you just add the tools to your agent, and then you can start asking questions or building more complex workflows with it. Now, by default, Strands Agents integrates with Amazon Bedrock as the model provider. So you can check the model config here. It's using Cloud 3.7 Sonnet. But, of course, it's not just limited to AWS.</p><p>You can use Strands Agents across multiple providers. For example, we have integrations with the Llama, so you can start developing locally, testing it out. We have integrations, entropic-edit integrations, meta-edit integrations to the Llama API. You can use OpenAI models and any other providers available through the integration with Lite LLM.</p><p>And, of course, you can also develop your own custom model provider. Now, quickly on the tools. As I said, Strands Agents comes with over 20 pre-built tools. So anything from simple tasks like, hey, I just want to do some file manipulation, some API calls, obviously integrate with AWS services, but then also more complex use cases.</p><p>And I just want to call out a couple of them. So there's a whole group of integrated tools from memory and RAC. One tool specifically called Retrieve, which lets you do a semantic search over a knowledge base. And just to show you the power of this, we have an internal agent at AWS that manages over 6,000 tools.</p><p>Now, 6,000 is a hard number of tools to put into a single context window and give one model to decide. So what we did is we put the descriptions of those tools in a knowledge base and use the retrieve tool here. So the agent can find the most relevant tools for the task at hand and only pull those tools back into the model context for the model to decide which one to take.</p><p>So that's just one use case how we're leveraging that. Also, there is support for multi-modality across images, video and audio with strands. There is a tool to kind of prompt for more thinking and deep reasoning. And it also comes with pre-built tools to implement multi-agent workflows, whether it's graph-based workflows or a swarm of sub-agents working together.</p><p>Now, you cannot talk about tools without mentioning MCP, right? So obviously, we integrated MCP here natively within strands. So you can just use this also to connect to thousands of available MCP servers and make them available as tools for your agent. Support for A2A is also coming soon. But let's start and talk a little bit about MCP first.</p><p>If you're building on AWS already, make sure to bookmark this GitHub repo. It's .slab/mcp. And here you can find a very long list, much longer than you would see here on this slide, of a growing number of the MCP server implementation, specifically if you're working and building on AWS.</p><p>Now, one of the challenges stems from the fact that once we all started building MCP servers, what we had was standard IO, right? So it started out to help locally connect your systems, your clients, to respective tools. And here's just a quick example, which is important for a demo I'll show in a little bit.</p><p>This is just a standard IO implementation of an MCP server. It should look familiar to most of you working with MCP using the Python SDK, using Fast MCP. All I'm doing here is set up my server and using the decorator to define a tool. In this case, my tool is to roll a dice.</p><p>And you might see in the code here, it has an input to define the number of sites. And I had to put a picture here because I have to admit, I just learned this myself. Do we have D&D fans in the room? Woo-hoo! All right, a few of them, so you all know what I'm talking about.</p><p>For the rest of us, I just learned there are dices, and I have one here. I'm not sure if the camera can catch this. It's just one of them here on the slide. A dice that has, for example, this one has 20 sites. Something very normal in the D&D world to start, I think, your game.</p><p>Don't ask me questions about D&D. My colleague Mike Chambers, who is either here or in the expo right now, he built the demo, so kudos to him. And he can answer all of the D&D questions. All right, just keep that in mind. I'll come back to this in just a second.</p><p>Now, what we want to do here is to decouple and kind of connect to remote MCP servers, because the topic is to scale, right? And the way to do this is, in the AWS world, as easy as just deploying it as a Lambda function. So, we can do this now with streamable HTTP, and the same concepts apply.</p><p>You put your Lambda functions, as you would have before, behind an MCP gateway, and then connect. And because we care about security and authorization, in the quick demo I'm going to show you, I'm using an authorizer. You can also plug in a Cognito framework for this part. And I'm also going to store session data in a DynamoDB table.</p><p>So, let's roll this quick demo here. So, what you see here is an MCP Lambda handler that we developed. It's available on the GitHub repo, which makes it really easy to kind of set up your MCP server in Lambda. Here's a very simple Hello World example. The tool is just, again, defined with a tool decorator in here.</p><p>And then, in the Lambda handler function, you can reference the input here, the invoke function, and pass it to that MCP server. Now, if we're looking at the server implementation, and here we're doing a little bit more, you can see how we're adding session table support, which is a DynamoDB table.</p><p>So, we're defining the tool. This is the rolling dice tool that I just pointed out, but this time it's hosted as a Lambda function. You can write all the code you want to have there as well. And then, at the very end, it's the same single line that basically, when you call the Lambda function, passes this on to the MCP server.</p><p>Let's deploy this, and again, we're using the existing tools to deploy Lambda functions as we have before. So, this one is using AWS SAM to just deploy that to the cloud. And then, we will receive the API gateway URL as well. Now, from the client side here, I'm using strands agents, as you can see.</p><p>And then, I am using the MCP integration. I'm passing here my API gateway URL to connect. For authorization, I have a bearer token. Again, this is a simple concept demo, but you can build more robust integrations here as well. I'm calling the list tool, and then I'm passing those tools to my agent, as we've seen before.</p><p>This time, it's the MCP available tools. And then, if we run this here, we can quickly see this in action and basically going to ask it here to roll a dice. And we're asking it to roll a D20. So, again, 20 sides. And it's coming back. What did we roll?</p><p>You can see the tool use kicking in here. We rolled a seven. Great. So, this is just really a quick example. The good news is, once you're in the AWS world and you're working on Lambda, everything you can build with Lambda, you can integrate there. So, basically, you have access, again, to all of the great features, capabilities, applications you might have already built on AWS.</p><p>Now, the next step here is, how do we make agents talk to each other, right? That's kind of the next frontier. And we're super excited about all the open protocols that are emerging right now. With MCP, for example, we joined the steering committee. We're an active part of the community, contributing code, and helping to further evolve MCP.</p><p>If you want to learn more about this, here is the QR code. We have a whole block series started on our open source block. Feel free to check that out as we continue to help evolve those protocols. Now, what's next? We all are aware that this is just the beginning, right?</p><p>There will be so much more coming. And if you had a chance to check out my colleague Danielle's talk yesterday on useful general intelligence, I just want to quote her a little bit. She said, "The atomic unit of all digital interactions will be an agent call." So we can imagine a future here where you might just have a personal agent shown like this, connecting to an agent store and really kind of having agents together accomplish tasks for you.</p><p>And some of you here in the room might already be building this, right? So let's go and build this future together. Thanks so much. Check out the additional sessions we have. My colleague, Mike, is going much more into the rolling dice demo, everything MCP and strands. And my colleague, Sue Montemara, will also have a deep dive on strands.</p><p>And with that, thank you very much. Check us out in the expo hall and grab your own D20. Thank you. Thank you. Thank you. Thank you. Thank you. We'll see you next week.</p></div></div></body></html>