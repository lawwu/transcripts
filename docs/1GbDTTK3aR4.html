<html><head><title>Stanford CS25: V3 I How I Learned to Stop Worrying and Love the Transformer</title>
<style>
    body {
        font-family: Arial, sans-serif;
        margin: 0;
        padding: 0;
        background-color: #f4f4f4;
        color: #333;
    }
    .container {
        width: 95%;  /* Increased width to use more space */
        margin: auto;
        overflow: auto;  /* Added to handle overflow by adding a scrollbar if necessary */
    }
    h2, h3 {
        color: #333;
        text-align: center;
    }
    a {
        color: #0000FF;  /* Traditional blue color for links */
        text-decoration: none;
    }
    a:hover {
        text-decoration: underline;
    }
    img {
        display: block;
        margin: auto;
        max-width: 100%;
    }
    .c {
        margin: 10px 0;
    }
    .s, .t {
        display: inline-block;
        margin-right: 5px;
    }
    .max-width {
        max-width: 800px;
        margin: auto;
        padding-left: 20px;
    }
    table {
        width: 100%;
        border-collapse: collapse;
    }
    th, td {
        border: 1px solid #ddd;
        padding: 8px;
        text-align: left;  /* Ensure text alignment is consistent */
    }
    tr:nth-child(even) {
        background-color: #f2f2f2;
    }
    tr:nth-child(odd) {
        background-color: #e6e6e6;
    }
</style>

    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-69VLBMTTP0"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-69VLBMTTP0');
    </script>
    </head><body><div class='container'><a href="index.html">back to index</a><h2>Stanford CS25: V3 I How I Learned to Stop Worrying and Love the Transformer</h2><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4"><img src="https://i.ytimg.com/vi/1GbDTTK3aR4/maxresdefault.jpg" style="width:50%;"></a><div><br></div><div style="text-align: left;"><a href="./1GbDTTK3aR4.html">Whisper Transcript</a> | <a href="./transcript_1GbDTTK3aR4.html">Transcript Only Page</a></div><br><div style="max-width: 800px;"><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=0" target="_blank">00:00:00.000</a></span> | <span class="t">[BLANK_AUDIO]</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=6" target="_blank">00:00:06.980</a></span> | <span class="t">Do folks still have, what is this?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=8" target="_blank">00:00:08.740</a></span> | <span class="t">[BLANK_AUDIO]</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=10" target="_blank">00:00:10.860</a></span> | <span class="t">There's a Stanford, that's a Stanford location.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=13" target="_blank">00:00:13.560</a></span> | <span class="t">[BLANK_AUDIO]</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=15" target="_blank">00:00:15.820</a></span> | <span class="t">You know which one?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=16" target="_blank">00:00:16.960</a></span> | <span class="t">Well, first, what is this?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=18" target="_blank">00:00:18.480</a></span> | <span class="t">[BLANK_AUDIO]</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=20" target="_blank">00:00:20.500</a></span> | <span class="t">What was going on here?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=21" target="_blank">00:00:21.200</a></span> | <span class="t">>> It's the first Dartmouth in Alabama.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=23" target="_blank">00:00:23.740</a></span> | <span class="t">>> That's right, yeah, and then what does the association to Stanford get?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=27" target="_blank">00:00:27.420</a></span> | <span class="t">[BLANK_AUDIO]</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=30" target="_blank">00:00:30.300</a></span> | <span class="t">>> I believe this is the McCarthy, yeah, who started at sale, if I understand</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=35" target="_blank">00:00:35.580</a></span> | <span class="t">correctly, is that right, he started at sale?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=38" target="_blank">00:00:38.900</a></span> | <span class="t">Yeah, I think he did, but anyways, so what's interesting is,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=43" target="_blank">00:00:43.900</a></span> | <span class="t">so it's amusing to actually look at what they wrote in their,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=48" target="_blank">00:00:48.780</a></span> | <span class="t">I don't know, is it brochure or what they wrote in their goals, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=54" target="_blank">00:00:54.900</a></span> | <span class="t">So, this font is a bit small.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=57" target="_blank">00:00:57.700</a></span> | <span class="t">Okay, so the study is to proceed on the basis of the conjecture that every aspect</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=62" target="_blank">00:01:02.460</a></span> | <span class="t">of learning or any other feature of intelligence can in principle be so</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=66" target="_blank">00:01:06.660</a></span> | <span class="t">precisely described that a machine can be made to simulate it, right, fantastic.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=71" target="_blank">00:01:11.540</a></span> | <span class="t">So single machine, you wanna simulate all of human intelligence, okay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=76" target="_blank">00:01:16.300</a></span> | <span class="t">And carefully selected group of scientists, and we think that we can make,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=80" target="_blank">00:01:20.960</a></span> | <span class="t">actually, the paragraph right before the second set of red underline,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=86" target="_blank">00:01:26.040</a></span> | <span class="t">is we think that a significant advance can be made in one or two of these problems.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=91" target="_blank">00:01:31.840</a></span> | <span class="t">If a carefully selected group of scientists work on together for a summer, okay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=98" target="_blank">00:01:38.080</a></span> | <span class="t">I don't think they knew of AI winters then actually, they didn't know of it then.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=102" target="_blank">00:01:42.560</a></span> | <span class="t">But, and the third thing is amusing is, but</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=106" target="_blank">00:01:46.440</a></span> | <span class="t">the major obstacle is not lack of machine capacity, but</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=110" target="_blank">00:01:50.360</a></span> | <span class="t">our inability to write programs taking full advantage of what we have.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=113" target="_blank">00:01:53.880</a></span> | <span class="t">>> So, while the goals are noble, it's surprising how wrong you can be with some</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=118" target="_blank">00:01:58.280</a></span> | <span class="t">of the smartest people in the room, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=120" target="_blank">00:02:00.120</a></span> | <span class="t">So Selfridge, a neural network OG that were the original pandemoniums,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=125" target="_blank">00:02:05.200</a></span> | <span class="t">I think he got everything basically set for path problems in black box optimization.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=129" target="_blank">00:02:09.320</a></span> | <span class="t">Then Minsky, of course, Shannon, Solomonoff, I think it was Solomonoff, MDL.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=136" target="_blank">00:02:16.720</a></span> | <span class="t">In many ways, you can argue that's the underpinning of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=141" target="_blank">00:02:21.160</a></span> | <span class="t">self-supervised learning today.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=144" target="_blank">00:02:24.320</a></span> | <span class="t">But it's really amusing to see the first, I mean, at least I don't know if we'll</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=150" target="_blank">00:02:30.160</a></span> | <span class="t">be able to characterize or write down all the rules for intelligence.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=155" target="_blank">00:02:35.680</a></span> | <span class="t">So you can imagine that the approaches they were taking were all these rule-based</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=159" target="_blank">00:02:39.160</a></span> | <span class="t">systems, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=159" target="_blank">00:02:39.960</a></span> | <span class="t">And they couldn't be more wrong on machine capacity.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=164" target="_blank">00:02:44.240</a></span> | <span class="t">Today's transformers, they don't, they're data centers, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=168" target="_blank">00:02:48.440</a></span> | <span class="t">And I guess they needed a really, really long summer to solve this one.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=175" target="_blank">00:02:55.440</a></span> | <span class="t">But yeah, so it's 1955, so yeah, like about 60 years.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=183" target="_blank">00:03:03.960</a></span> | <span class="t">No, not even, I'm getting close to 70, 70 years, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=186" target="_blank">00:03:06.600</a></span> | <span class="t">So, and we're basically talking about the same problems again,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=191" target="_blank">00:03:11.920</a></span> | <span class="t">except maybe some things work, some things don't work.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=196" target="_blank">00:03:16.840</a></span> | <span class="t">And this talk is about some of the, one of the pieces that has made this larger</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=202" target="_blank">00:03:22.920</a></span> | <span class="t">enterprise work, and we're getting closer to the original goals of the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=207" target="_blank">00:03:27.800</a></span> | <span class="t">Dartmouth conference, yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=209" target="_blank">00:03:29.760</a></span> | <span class="t">Again, okay, so this is like the big gaps.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=212" target="_blank">00:03:32.760</a></span> | <span class="t">I mean, so what eventually happened in the field was that their goal of having a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=216" target="_blank">00:03:36.720</a></span> | <span class="t">single system that explained most of, that was able to mimic our cognitive</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=222" target="_blank">00:03:42.960</a></span> | <span class="t">abilities, which would definitely mean like image processing or image</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=226" target="_blank">00:03:46.480</a></span> | <span class="t">understanding and language processing as well, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=228" target="_blank">00:03:48.800</a></span> | <span class="t">That, I mean, the field got, I mean, a single model or a single approach to do</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=234" target="_blank">00:03:54.560</a></span> | <span class="t">all these things was shattered by like thousands of like different research</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=238" target="_blank">00:03:58.640</a></span> | <span class="t">products.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=239" target="_blank">00:03:59.040</a></span> | <span class="t">So, I mean, there was no consolidation, but here's another, here's another,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=242" target="_blank">00:04:02.760</a></span> | <span class="t">here's another, this is going to be a harder one.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=246" target="_blank">00:04:06.240</a></span> | <span class="t">Can you tell what is a, this is, this is 2009, and this is a, and this is not a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=250" target="_blank">00:04:10.760</a></span> | <span class="t">single system.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=251" target="_blank">00:04:11.440</a></span> | <span class="t">This is a complicated machine translation system.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=253" target="_blank">00:04:13.760</a></span> | <span class="t">So when I started my PhD, our machine translation systems used to be a bit more</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=257" target="_blank">00:04:17.040</a></span> | <span class="t">complicated, complicated than this, actually.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=259" target="_blank">00:04:19.640</a></span> | <span class="t">Thousands of pipeline systems, you had to first extract, you had to first do word</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=263" target="_blank">00:04:23.880</a></span> | <span class="t">alignments that actually looked like attention as like art.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=267" target="_blank">00:04:27.000</a></span> | <span class="t">You think about it as hard attention, then based on that, we extracted like all</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=270" target="_blank">00:04:30.120</a></span> | <span class="t">larger phrases aligned with other phrases.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=272" target="_blank">00:04:32.320</a></span> | <span class="t">Then you had to figure out how they then had to, then you had to teach, there was</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=276" target="_blank">00:04:36.240</a></span> | <span class="t">some machine learning there, you had to teach the model how to score them</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=278" target="_blank">00:04:38.840</a></span> | <span class="t">connecting with each other.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=280" target="_blank">00:04:40.040</a></span> | <span class="t">So can you tell, can you, does anybody know where a neural network is in this?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=291" target="_blank">00:04:51.280</a></span> | <span class="t">All right.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=291" target="_blank">00:04:51.880</a></span> | <span class="t">So CS, so this is the, this is a machine translation system from 2009, and CSM is a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=298" target="_blank">00:04:58.200</a></span> | <span class="t">continuous state language model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=300" target="_blank">00:05:00.840</a></span> | <span class="t">That's used for rescoring, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=303" target="_blank">00:05:03.480</a></span> | <span class="t">So the world was so discreet then that he had to call these models like continuous</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=307" target="_blank">00:05:07.160</a></span> | <span class="t">state language models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=308" target="_blank">00:05:08.240</a></span> | <span class="t">And, I mean, it was a lot, it was largely inspired by the neural probabilistic</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=311" target="_blank">00:05:11.800</a></span> | <span class="t">language model by, oh, it doesn't appear.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=315" target="_blank">00:05:15.240</a></span> | <span class="t">Huh.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=317" target="_blank">00:05:17.920</a></span> | <span class="t">Sorry.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=320" target="_blank">00:05:20.200</a></span> | <span class="t">Ah, there.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=320" target="_blank">00:05:20.880</a></span> | <span class="t">The neural probabilistic language model by Benjy, I think it was in 2003.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=326" target="_blank">00:05:26.040</a></span> | <span class="t">And so we were, even in 2013, when I published a paper on neural network language</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=333" target="_blank">00:05:33.880</a></span> | <span class="t">models, these models were still being put into the fee for neural network language</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=340" target="_blank">00:05:40.280</a></span> | <span class="t">models was still, you know, rescoring.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=342" target="_blank">00:05:42.240</a></span> | <span class="t">And now it's incredible if you think about it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=345" target="_blank">00:05:45.360</a></span> | <span class="t">So just in terms of consolidation, how all of these complicated systems that have now</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=350" target="_blank">00:05:50.360</a></span> | <span class="t">been replaced by just neurons that talk to each other, and you just learn the rules</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=353" target="_blank">00:05:53.840</a></span> | <span class="t">from, you just learn the rules from data automatically.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=356" target="_blank">00:05:56.640</a></span> | <span class="t">So it's fun to, it's interesting to see.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=362" target="_blank">00:06:02.400</a></span> | <span class="t">And so since then, you know, like, so this is what the EMLB 2013 conference was like.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=370" target="_blank">00:06:10.200</a></span> | <span class="t">You see these different, like these, you can call it verticalized NLP, these</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=375" target="_blank">00:06:15.360</a></span> | <span class="t">different areas like morphology, dialogue, and discourse.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=379" target="_blank">00:06:19.080</a></span> | <span class="t">I mean, I don't even know if people talk about dialogue and discourse.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=382" target="_blank">00:06:22.560</a></span> | <span class="t">There's talk to models now.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=383" target="_blank">00:06:23.680</a></span> | <span class="t">There's, I don't know if there's a research track anymore.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=385" target="_blank">00:06:25.760</a></span> | <span class="t">Then there is like a machine translation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=387" target="_blank">00:06:27.360</a></span> | <span class="t">So there's opinion mining and sentiment analysis.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=390" target="_blank">00:06:30.080</a></span> | <span class="t">Now models make you angry or upset.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=392" target="_blank">00:06:32.960</a></span> | <span class="t">So it's, and so you could see that just in 2013, the field, even research was divided</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=399" target="_blank">00:06:39.440</a></span> | <span class="t">into these smaller tracks and everybody had their own specific, they were bringing their</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=403" target="_blank">00:06:43.200</a></span> | <span class="t">own specific domain information.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=406" target="_blank">00:06:46.880</a></span> | <span class="t">And they had to specialize in a domain in order to solve some tasks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=410" target="_blank">00:06:50.160</a></span> | <span class="t">And we solved tasks to some degree.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=411" target="_blank">00:06:51.800</a></span> | <span class="t">Machine translation, because, I mean, probably because of a lot of government funding as</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=416" target="_blank">00:06:56.280</a></span> | <span class="t">well, we had made a lot of progress and we were making practical translation systems</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=419" target="_blank">00:06:59.760</a></span> | <span class="t">that were being deployed in the wild.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=421" target="_blank">00:07:01.840</a></span> | <span class="t">Google Translate was a great example of that, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=425" target="_blank">00:07:05.600</a></span> | <span class="t">And so since then, you're like, you have this, you know, we started to, through first, first</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=432" target="_blank">00:07:12.040</a></span> | <span class="t">we all agree, we need distributed, we need distributed word representations.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=435" target="_blank">00:07:15.400</a></span> | <span class="t">And you saw this, like, people probably don't know this funky, this funky embedding algebra</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=440" target="_blank">00:07:20.800</a></span> | <span class="t">of king minus man plus woman equals, equals queen from word2vec.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=447" target="_blank">00:07:27.000</a></span> | <span class="t">And we had a, we had a, and there was a, there was a, there was a big industry of models</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=454" target="_blank">00:07:34.000</a></span> | <span class="t">that actually, that just, that learned word representations and the word representations</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=458" target="_blank">00:07:38.160</a></span> | <span class="t">are actually useful in downstream tasks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=461" target="_blank">00:07:41.040</a></span> | <span class="t">And then, then came like, you know, another step in this process.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=465" target="_blank">00:07:45.380</a></span> | <span class="t">Another step in this process where now we started saying, okay, these representations</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=469" target="_blank">00:07:49.600</a></span> | <span class="t">are like in there, but they're, they're, they're only helpful if they're learned in context,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=474" target="_blank">00:07:54.120</a></span> | <span class="t">right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=475" target="_blank">00:07:55.120</a></span> | <span class="t">So the king should change based on context, like the, the, the, the king of Persia, or</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=480" target="_blank">00:08:00.000</a></span> | <span class="t">the king has no clothes, or the emperor has no clothes, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=483" target="_blank">00:08:03.840</a></span> | <span class="t">And so, so, so that, so we saw these, we saw approaches like sequence to sequence, sequence</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=489" target="_blank">00:08:09.120</a></span> | <span class="t">learning where we started to like formulate, we started to create these general formulations</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=494" target="_blank">00:08:14.860</a></span> | <span class="t">of how to solve any task in NLP, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=498" target="_blank">00:08:18.360</a></span> | <span class="t">So sequence to sequence formulation, if you can, you can, you can, you can formulate many</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=502" target="_blank">00:08:22.040</a></span> | <span class="t">tasks in language of sequence to sequence, question answering, machine translation, dialogue.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=507" target="_blank">00:08:27.400</a></span> | <span class="t">So, and then, and then of course we had, then we, then we developed attention, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=511" target="_blank">00:08:31.680</a></span> | <span class="t">Which was a, which was a very effective content based way to summarize information.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=517" target="_blank">00:08:37.000</a></span> | <span class="t">If you were a, typically you have these encoder decoder architectures, everybody has probably,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=521" target="_blank">00:08:41.560</a></span> | <span class="t">I'm guessing, familiar with encoder decoder architectures, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=524" target="_blank">00:08:44.300</a></span> | <span class="t">So yeah, encoder decoder architecture and a, and a, and a position on the decoder side</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=528" target="_blank">00:08:48.540</a></span> | <span class="t">would summarize based on its content, all the information on the, on the source sentence,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=532" target="_blank">00:08:52.740</a></span> | <span class="t">right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=533" target="_blank">00:08:53.740</a></span> | <span class="t">And this was really effective content-based way of summarizing information.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=536" target="_blank">00:08:56.580</a></span> | <span class="t">And what, what started happening was we started these, these general, these general paradigms</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=542" target="_blank">00:09:02.060</a></span> | <span class="t">started coming up.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=543" target="_blank">00:09:03.860</a></span> | <span class="t">Sequence to sequence learning can solve, it can install most language problems because</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=548" target="_blank">00:09:08.220</a></span> | <span class="t">most language problems have to deal with learning representations of variable length.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=552" target="_blank">00:09:12.100</a></span> | <span class="t">The goal is to learn representations of variable length sequences.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=554" target="_blank">00:09:14.740</a></span> | <span class="t">And if you do that successfully, you can then potentially solve that problem.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=558" target="_blank">00:09:18.280</a></span> | <span class="t">And then attention was an excellent way, a content-based way to actually summarize information</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=563" target="_blank">00:09:23.220</a></span> | <span class="t">from some neighborhood.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=565" target="_blank">00:09:25.060</a></span> | <span class="t">And and, and, and, and so, so, so, so, and the, and the major workhorse until then were</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=570" target="_blank">00:09:30.500</a></span> | <span class="t">these recurrent models or LSTMs, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=573" target="_blank">00:09:33.780</a></span> | <span class="t">Where basically the, the, the, the method was typically the same.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=577" target="_blank">00:09:37.820</a></span> | <span class="t">You had a, you had a sentence and you crushed the sentence into a, into a set of, into a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=581" target="_blank">00:09:41.980</a></span> | <span class="t">set of vectors, set of representations, one typically, typically one for each position,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=586" target="_blank">00:09:46.860</a></span> | <span class="t">right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=587" target="_blank">00:09:47.860</a></span> | <span class="t">And the way LSTMs did it was where they walked along the sentence, they ate up a word, and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=592" target="_blank">00:09:52.260</a></span> | <span class="t">then they summarized, they summarized the entire history into one fixed bottleneck.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=597" target="_blank">00:09:57.500</a></span> | <span class="t">And that bottleneck was then transmitted, was updated based on the next word.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=601" target="_blank">00:10:01.020</a></span> | <span class="t">So, so, so now, and, and, and, and if we, if you were successfully able to learn representations,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=607" target="_blank">00:10:07.360</a></span> | <span class="t">then we could solve these tasks, translation, summarization, dialogue.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=609" target="_blank">00:10:09.620</a></span> | <span class="t">So it's an important movement and, and, and, and like the 20, 20, I, I, 20, I guess when</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=614" target="_blank">00:10:14.580</a></span> | <span class="t">was the sequence to sequence learning papers, 2015, NeurIPS, then we saw, then we saw the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=619" target="_blank">00:10:19.140</a></span> | <span class="t">attention paper in around 2015, 2016, and the machine translation community was kind</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=623" target="_blank">00:10:23.440</a></span> | <span class="t">of the first to respond and say, hey, yeah, you know, machine translation is a classic</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=627" target="_blank">00:10:27.660</a></span> | <span class="t">sequence to sequence learning problem.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=629" target="_blank">00:10:29.540</a></span> | <span class="t">Like why don't we now first start rescoring?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=631" target="_blank">00:10:31.860</a></span> | <span class="t">And then can we still build native, greeny, rethink machine translation with the sequence</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=635" target="_blank">00:10:35.780</a></span> | <span class="t">to sequence models, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=638" target="_blank">00:10:38.500</a></span> | <span class="t">And these are fantastic models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=639" target="_blank">00:10:39.780</a></span> | <span class="t">I don't know if you guys have ever done these exercises on LSTMs can, can count, like if</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=645" target="_blank">00:10:45.260</a></span> | <span class="t">you, if you, for example, if you, if you train an encoder decoder on, if you, like on A,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=650" target="_blank">00:10:50.980</a></span> | <span class="t">to model A to the N, B to the N. So you feed in NAs and you ask the decoder to predict</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=655" target="_blank">00:10:55.020</a></span> | <span class="t">N, NBs, and you actually, just a single cell LSTM, if you know the structure of an LSTM,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=661" target="_blank">00:11:01.380</a></span> | <span class="t">there's a cell that basically keeps, so it's a, it's a notion of state, and just a single</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=665" target="_blank">00:11:05.700</a></span> | <span class="t">cell is able to actually just do trivial counting.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=668" target="_blank">00:11:08.980</a></span> | <span class="t">It counts how many A's you consumed, and then it decrements it, and then when you consume</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=673" target="_blank">00:11:13.820</a></span> | <span class="t">all the, exactly the same number of B's as the number of A's, something lights up and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=677" target="_blank">00:11:17.620</a></span> | <span class="t">says, I'm done, I've recognized this language, so you can train trivial A to the N, B to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=680" target="_blank">00:11:20.860</a></span> | <span class="t">the N.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=681" target="_blank">00:11:21.860</a></span> | <span class="t">And here, you have a, I'm sorry, this is not clear, but you have somewhat of a, you have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=686" target="_blank">00:11:26.140</a></span> | <span class="t">a grammar here, and you can see that these are different cells, there's about eight cells</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=689" target="_blank">00:11:29.740</a></span> | <span class="t">here, and each one of these cells actually increments its counter once it feeds a particular</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=694" target="_blank">00:11:34.060</a></span> | <span class="t">symbol, and it's able to actually track how deep you are in this, how deep you are in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=697" target="_blank">00:11:37.980</a></span> | <span class="t">this hierarchy, in this grammar.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=700" target="_blank">00:11:40.020</a></span> | <span class="t">And Google, of course, the crowning achievement, perhaps, of sequence-to-sequence models, which</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=707" target="_blank">00:11:47.740</a></span> | <span class="t">I was actually, right, I was fortunate to be in the same cuticle as this work was being</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=715" target="_blank">00:11:55.340</a></span> | <span class="t">done, was the Google neural machine translation system, where they took LSTMs, I mean, they</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=719" target="_blank">00:11:59.940</a></span> | <span class="t">added many advancements, of course, a lot of systems improvements, a lot of data that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=724" target="_blank">00:12:04.700</a></span> | <span class="t">Google had, and they produced what you might, at that time, the state-of-the-art neural</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=729" target="_blank">00:12:09.540</a></span> | <span class="t">machine translation system, sequence-to-sequence models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=732" target="_blank">00:12:12.020</a></span> | <span class="t">So now, this big consolidated, this big complicated system, which looked much, which looked much</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=737" target="_blank">00:12:17.380</a></span> | <span class="t">more complicated, and now become a homogenous, just as a single homogenous neural network,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=742" target="_blank">00:12:22.820</a></span> | <span class="t">right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=743" target="_blank">00:12:23.820</a></span> | <span class="t">So at the time, the biggest frustration we had was, this was, I mean, these, the LSTMs</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=749" target="_blank">00:12:29.620</a></span> | <span class="t">were the primary workforce, and the biggest, the biggest frustration we had was, I mean,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=756" target="_blank">00:12:36.100</a></span> | <span class="t">not only were we producing, not only were we, did we produce the output order aggressively,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=761" target="_blank">00:12:41.420</a></span> | <span class="t">we were sequentially decoding the output, left to right, but also, we were reading the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=765" target="_blank">00:12:45.500</a></span> | <span class="t">input sequentially.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=766" target="_blank">00:12:46.500</a></span> | <span class="t">So you had to kind of, in order to produce that, in order to produce that representation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=769" target="_blank">00:12:49.980</a></span> | <span class="t">for the 10th word, you had to eat up, you had to, the first word, the second word, the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=773" target="_blank">00:12:53.820</a></span> | <span class="t">third word.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=774" target="_blank">00:12:54.820</a></span> | <span class="t">So that was, that was really slow, and, and, and, and, and, and, and, and not the whole,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=779" target="_blank">00:12:59.580</a></span> | <span class="t">and another big problem with LSTMs were that you have this bottleneck that basically, that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=785" target="_blank">00:13:05.740</a></span> | <span class="t">contains all the information about your past.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=788" target="_blank">00:13:08.340</a></span> | <span class="t">So you have to now, you have to now crush, you have to, you have to pack both long distance</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=792" target="_blank">00:13:12.820</a></span> | <span class="t">interactions that you might have, and local interactions through the single, single fixed</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=797" target="_blank">00:13:17.100</a></span> | <span class="t">vector that you need to transmit, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=799" target="_blank">00:13:19.200</a></span> | <span class="t">And, and sequentiality, it doesn't, inhibits parallelism, which means that you couldn't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=803" target="_blank">00:13:23.940</a></span> | <span class="t">even read, like the encoder couldn't even read the sentence in parallel, and of course</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=808" target="_blank">00:13:28.220</a></span> | <span class="t">decoding was autoregressive, so you couldn't even write in parallel, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=812" target="_blank">00:13:32.620</a></span> | <span class="t">And convolutions, they were starting to emerge as a solution largely. I mean, they had been</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=819" target="_blank">00:13:39.100</a></span> | <span class="t">very successful in-- they had been very successful in computer vision. They had also figured</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=823" target="_blank">00:13:43.220</a></span> | <span class="t">out how to optimize them well, how to make them really fast on GPUs, because they're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=830" target="_blank">00:13:50.340</a></span> | <span class="t">just basically matrix multiplications. And matrix multiplication is largely-- it's parallelizable.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=835" target="_blank">00:13:55.980</a></span> | <span class="t">So convolutions were a solution to this problem of not being able to read in parallel, because</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=843" target="_blank">00:14:03.300</a></span> | <span class="t">you could-- in parallel, every word could basically produce its representation by looking</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=848" target="_blank">00:14:08.340</a></span> | <span class="t">at its neighbors, its local neighbors. And there were some breakthrough papers, such</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=856" target="_blank">00:14:16.380</a></span> | <span class="t">as Bitenet for machine translation, the convolutional sequence-to-sequence model that was contemporaneous</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=862" target="_blank">00:14:22.020</a></span> | <span class="t">to the transformer, actually, probably predated by a few months, where they used convolutions</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=866" target="_blank">00:14:26.260</a></span> | <span class="t">both in the encoder and decoder to get good scores on machine translation that were better</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=871" target="_blank">00:14:31.180</a></span> | <span class="t">than the Google neural machine translation system. And of course, probably the most successful</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=879" target="_blank">00:14:39.780</a></span> | <span class="t">was Bitenet, which was a text-to-speech system that was state-of-the-art at the time.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=885" target="_blank">00:14:45.260</a></span> | <span class="t">And again, so convolutions still have this problem that, one, I guess they were parallelizable,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=893" target="_blank">00:14:53.940</a></span> | <span class="t">but the issue was that you still-- you couldn't directly capture long-distance interactions</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=899" target="_blank">00:14:59.880</a></span> | <span class="t">between-- you couldn't directly capture long-distance interactions between words. So if you're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=904" target="_blank">00:15:04.860</a></span> | <span class="t">basically a receptive field, if it's like a 3 by 3, if it's a 1 by 3, then it basically</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=910" target="_blank">00:15:10.620</a></span> | <span class="t">grows linearly, either with the factor of-- it grows linearly with the number of layers</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=915" target="_blank">00:15:15.860</a></span> | <span class="t">each time it expands by 3. So you still needed a linear number of layers to capture these</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=922" target="_blank">00:15:22.020</a></span> | <span class="t">long-distance relationships. But attention, on the other hand, was this really effective</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=926" target="_blank">00:15:26.500</a></span> | <span class="t">mechanism that we knew was-- that could actually get-- in one, it could actually capture all</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=934" target="_blank">00:15:34.660</a></span> | <span class="t">the interactions between one word and every other word using content-based addressing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=940" target="_blank">00:15:40.780</a></span> | <span class="t">Because convolutions basically match-- convolutions match weights with parameters. Attention was</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=945" target="_blank">00:15:45.540</a></span> | <span class="t">actually able to use content with content. So based on how similar I am to my neighborhood,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=949" target="_blank">00:15:49.820</a></span> | <span class="t">based on how similar I am to my neighbors, I'm going to absorb that information. And</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=954" target="_blank">00:15:54.420</a></span> | <span class="t">this motif actually appears everywhere, even in computer vision.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=958" target="_blank">00:15:58.340</a></span> | <span class="t">So maybe, actually, I can go there. So here's a-- in vision, there is this approach-- do</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=965" target="_blank">00:16:05.460</a></span> | <span class="t">people here know non-local means? So in computer vision, there's an approach called non-local</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=971" target="_blank">00:16:11.940</a></span> | <span class="t">means that's basically-- it was originally developed for image denoising. So if you want</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=978" target="_blank">00:16:18.380</a></span> | <span class="t">to denoise an image patch, you look at all your neighbors, and you see which patch is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=983" target="_blank">00:16:23.460</a></span> | <span class="t">very similar to you. And based on the similarity, you actually pull in that information. And</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=987" target="_blank">00:16:27.980</a></span> | <span class="t">this largely works in images because images are very self-similar. This starts sounding</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=991" target="_blank">00:16:31.980</a></span> | <span class="t">like, hey, based on content, I want to pull in information. And again, there were similar--</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=996" target="_blank">00:16:36.740</a></span> | <span class="t">there were approaches like texture synthesis by EFROS, where if you wanted to-- if you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1001" target="_blank">00:16:41.960</a></span> | <span class="t">wanted to do painting, or if you wanted to generate an image, then you would look at</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1005" target="_blank">00:16:45.640</a></span> | <span class="t">a patch that's similar to this rectangle in some other-- in your dictionary, or in a database</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1011" target="_blank">00:16:51.740</a></span> | <span class="t">that you have of patches. And then based on what's closest to it, you actually bring it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1015" target="_blank">00:16:55.940</a></span> | <span class="t">So you'll bring that patch, and then you'll paste it there. So these approaches that looked</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1019" target="_blank">00:16:59.580</a></span> | <span class="t">like attention were already prevalent. It's a very natural formulation. And the Baden-Auwe</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1028" target="_blank">00:17:08.460</a></span> | <span class="t">paper had shown that this actually works really well for language as well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1032" target="_blank">00:17:12.180</a></span> | <span class="t">So the question then was, OK, why can't we then learn representations? Instead of being</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1037" target="_blank">00:17:17.220</a></span> | <span class="t">this source target, why can't we actually learn representations by the sentence attending</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1041" target="_blank">00:17:21.740</a></span> | <span class="t">onto itself? So now you basically use-- instead of attending a source sentence, attending</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1046" target="_blank">00:17:26.900</a></span> | <span class="t">to a target sentence, can it just attend to itself?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1049" target="_blank">00:17:29.260</a></span> | <span class="t">And the original goal of actually when we wanted to actually do parallel decoding--</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1056" target="_blank">00:17:36.420</a></span> | <span class="t">so attention by construction is parallelizable, because each token can basically construct</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1064" target="_blank">00:17:44.340</a></span> | <span class="t">its representations from its neighbors in parallel, right? And it directly captures</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1069" target="_blank">00:17:49.900</a></span> | <span class="t">token-to-token interactions, because now, of course, we'll run into complexities of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1074" target="_blank">00:17:54.420</a></span> | <span class="t">length, but we can-- and we'll discuss how to solve some of these things later, how to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1079" target="_blank">00:17:59.580</a></span> | <span class="t">overcome them. But you can direct-- instead of having this sort of linear growth in receptive</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1083" target="_blank">00:18:03.220</a></span> | <span class="t">field, you can directly capture these interactions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1085" target="_blank">00:18:05.620</a></span> | <span class="t">Because convolutions, if you have a very, very large receptive field, it gets computationally</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1088" target="_blank">00:18:08.660</a></span> | <span class="t">very expensive. And it also had these explicit gating and multiplicative interactions, which</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1092" target="_blank">00:18:12.740</a></span> | <span class="t">we've often seen, like, in gated-pixel CNN or GeLUs. These explicit gated-multiplicative</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1100" target="_blank">00:18:20.220</a></span> | <span class="t">interactions have typically helped training and have led to better accuracies.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1106" target="_blank">00:18:26.420</a></span> | <span class="t">And as I mentioned, the original motivation of why we actually wanted to do this was,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1111" target="_blank">00:18:31.300</a></span> | <span class="t">we said, hey, OK, so the LSTMs are-- we have good translation systems, but the problem</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1117" target="_blank">00:18:37.340</a></span> | <span class="t">is that actually, both reading and writing sequentially, can we actually do both in parallel?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1122" target="_blank">00:18:42.820</a></span> | <span class="t">So we wanted to read-- we wanted to read the German sentence in parallel and then translate</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1127" target="_blank">00:18:47.540</a></span> | <span class="t">it in-- and then also write in parallel by that, instead of actually decoding it sort</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1132" target="_blank">00:18:52.180</a></span> | <span class="t">of autoregressively, can you decode it-- instead of decoding in time, can you decode it in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1136" target="_blank">00:18:56.500</a></span> | <span class="t">height?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1137" target="_blank">00:18:57.500</a></span> | <span class="t">So, like, you first spit out one word, or you spit out all the words, and you iteratively</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1141" target="_blank">00:19:01.000</a></span> | <span class="t">define them, right? And this was-- this turned out to be very, very challenging and hasn't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1147" target="_blank">00:19:07.260</a></span> | <span class="t">been solved successfully until today. Because the biggest challenge, essentially, is when</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1151" target="_blank">00:19:11.580</a></span> | <span class="t">you-- whenever you're decoding, right, essentially, as you predict a word, you kind of bend the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1155" target="_blank">00:19:15.100</a></span> | <span class="t">probability distribution that then nails down-- narrows down what you're going to predict</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1159" target="_blank">00:19:19.540</a></span> | <span class="t">later on. And the ordering that allows you, basically-- the ordering that allows you to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1165" target="_blank">00:19:25.340</a></span> | <span class="t">nail these modes was very hard to learn. So imposing a left-to-right ordering is much</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1170" target="_blank">00:19:30.500</a></span> | <span class="t">easier than actually not having one and having to learn it as you're decoding.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1174" target="_blank">00:19:34.740</a></span> | <span class="t">So the original approaches didn't work, but then we still had-- we still had-- we still</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1180" target="_blank">00:19:40.140</a></span> | <span class="t">had our salvation in being able to read it parallelly. So we said, all right, let's take</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1183" target="_blank">00:19:43.700</a></span> | <span class="t">this back to the encoder-decoder models. And unlike-- at that time, there were a few formulations,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1190" target="_blank">00:19:50.700</a></span> | <span class="t">right? So we had this sort of-- the original formulation of attention from graves, then</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1195" target="_blank">00:19:55.780</a></span> | <span class="t">we had the additive attention formulation, and we took the-- and we took the dot product</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1200" target="_blank">00:20:00.020</a></span> | <span class="t">attention formulation, largely because it allowed us to do-- it-- because it allowed</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1205" target="_blank">00:20:05.940</a></span> | <span class="t">us to actually do attention as a matrix multiplication. And oftentimes, some of the biggest constraints</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1211" target="_blank">00:20:11.340</a></span> | <span class="t">that actually-- physics is such a big constraint in neural networks that if you can-- if you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1217" target="_blank">00:20:17.220</a></span> | <span class="t">can make your-- if you can make your architecture amenable to modern accelerators, you have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1222" target="_blank">00:20:22.660</a></span> | <span class="t">a much better chance of-- you have a much better chance of succeeding. And dot product</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1226" target="_blank">00:20:26.820</a></span> | <span class="t">attention could be expressed as a matrix multiplication, and it's-- and there are already sub-- there</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1231" target="_blank">00:20:31.260</a></span> | <span class="t">are already kernels for being able to do matrix multiplication very effectively on the GPA.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1236" target="_blank">00:20:36.300</a></span> | <span class="t">So we had-- so the formulation was, all right, so now we have-- similar to the dot product</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1240" target="_blank">00:20:40.500</a></span> | <span class="t">attention, we had a scaling factor, simply because if the dot product actually becomes</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1245" target="_blank">00:20:45.140</a></span> | <span class="t">too big and you can solve it under certain assumptions of mean and variance in the representations,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1250" target="_blank">00:20:50.860</a></span> | <span class="t">you can-- it hasn't updated, actually. Yeah, so our formulation is basically you have--</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1258" target="_blank">00:20:58.420</a></span> | <span class="t">you now have your queries, which-- what you end up doing is if you have a-- if you have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1264" target="_blank">00:21:04.740</a></span> | <span class="t">a position, you first project it into queries, and then the same-- the same token-- the same--</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1270" target="_blank">00:21:10.500</a></span> | <span class="t">the representation of the same token gets projected into-- to also keys and values.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1274" target="_blank">00:21:14.740</a></span> | <span class="t">And the first-- the query determines how much-- how much you're actually going to pull from</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1280" target="_blank">00:21:20.780</a></span> | <span class="t">all these keys. So you first do a dot product of the query with every key, and then based</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1285" target="_blank">00:21:25.380</a></span> | <span class="t">on that, you combine or you pool the content of-- in all these positions based on-- based</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1290" target="_blank">00:21:30.820</a></span> | <span class="t">on what the-- based on what the score was after-- after normalizing and using a softmax.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1294" target="_blank">00:21:34.980</a></span> | <span class="t">So in some sense, you can think of self-attention also as kind of a content-based pooling mechanism,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1301" target="_blank">00:21:41.860</a></span> | <span class="t">right? And the scaling factor basically avoids you-- avoids you-- like, it saved us from</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1307" target="_blank">00:21:47.260</a></span> | <span class="t">these logits actually blowing up and training becoming unstable. And on the decoder side,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1312" target="_blank">00:21:52.820</a></span> | <span class="t">you could trivially-- you can trivially implement causality by just adding an-- adding an attention--</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1318" target="_blank">00:21:58.260</a></span> | <span class="t">adding an attention mask. And what this-- where this-- where this brings us is that--</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1323" target="_blank">00:22:03.620</a></span> | <span class="t">all right, so-- so now we've-- we've solved-- now there's-- it's-- so a caveat on the flops.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1329" target="_blank">00:22:09.260</a></span> | <span class="t">We'll actually cover this later. But now what we have is a mechanism that-- that's parallelizable.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1334" target="_blank">00:22:14.340</a></span> | <span class="t">It gives you direct-- it gives you direct content-- it gives you direct token interactions</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1339" target="_blank">00:22:19.500</a></span> | <span class="t">that will-- and that-- that we-- that we assume-- that we believe is going to help you actually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1342" target="_blank">00:22:22.940</a></span> | <span class="t">learn-- model these relationships between the words better. And it's-- and it's-- and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1346" target="_blank">00:22:26.500</a></span> | <span class="t">the complexity of self-attention is faster than convolutions, right? Because it was--</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1350" target="_blank">00:22:30.100</a></span> | <span class="t">because convolutions are quadratic in the number-- they're quadratic in the number of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1354" target="_blank">00:22:34.420</a></span> | <span class="t">channels and the number of-- in the hidden dimension, but a self-attention is quadratic</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1357" target="_blank">00:22:37.660</a></span> | <span class="t">in the length. So if your length is not much more than a hidden dimension, you've actually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1360" target="_blank">00:22:40.500</a></span> | <span class="t">saved on flops. Now this is a-- not-- not quite a complete picture because not all flops</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1365" target="_blank">00:22:45.860</a></span> | <span class="t">are equal, and we'll talk about this later on. And-- and-- and-- and now when you put</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1372" target="_blank">00:22:52.060</a></span> | <span class="t">it-- when you put everything together, what we-- what-- basically, we-- we kind of took</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1376" target="_blank">00:22:56.060</a></span> | <span class="t">the-- the-- the-- the-- the basis-- this has a very strong similarity to the-- to the ResNet</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1381" target="_blank">00:23:01.260</a></span> | <span class="t">architecture, actually. So if we look at ResNets, right? So in ResNets, you have contraction,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1386" target="_blank">00:23:06.260</a></span> | <span class="t">you have spatial mixing with convolutions, and then you have the expansion again, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1390" target="_blank">00:23:10.380</a></span> | <span class="t">If you just-- the transformer, if you just adjust, if you just move it one-- one step</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1394" target="_blank">00:23:14.580</a></span> | <span class="t">down, it's very-- it's analogous. You have-- you have attention, then you have expansion</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1397" target="_blank">00:23:17.980</a></span> | <span class="t">and contraction, but it is a-- and-- and the difference in where the residual connections</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1401" target="_blank">00:23:21.940</a></span> | <span class="t">are, but it's a-- it's a very similar-- it's a very similar sort of basic building block</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1405" target="_blank">00:23:25.940</a></span> | <span class="t">with, say, the residual-- with the residual connections, and you have these contractions</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1409" target="_blank">00:23:29.540</a></span> | <span class="t">and expansions. And in the transformer, those were-- there was multi-head attention with</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1414" target="_blank">00:23:34.660</a></span> | <span class="t">expansion and contraction, which was in the feed-forward layers. And with-- and-- and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1419" target="_blank">00:23:39.020</a></span> | <span class="t">then one-- one-- one challenge with the tension, we loo-- LSTMs can count, they can impact,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1424" target="_blank">00:23:44.220</a></span> | <span class="t">they can-- they can-- they can-- they can count-- they can learn interesting temporal</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1429" target="_blank">00:23:49.100</a></span> | <span class="t">patterns, but attention is permutation-invariant, so we had to actually add position-- we had</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1435" target="_blank">00:23:55.940</a></span> | <span class="t">to add position information so that we could-- we could learn ordering. So we add position</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1439" target="_blank">00:23:59.860</a></span> | <span class="t">information at the input, which trans-- gets transmitted to the other layers through--</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1444" target="_blank">00:24:04.580</a></span> | <span class="t">through the-- through the residual connections. And the-- the original paper, we had those--</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1449" target="_blank">00:24:09.500</a></span> | <span class="t">we had post-layer norm, but later on, we realized that as we actually make the model deeper,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1454" target="_blank">00:24:14.660</a></span> | <span class="t">post-layer norm is-- doesn't-- doesn't allow you to train effectively, so we have to--</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1458" target="_blank">00:24:18.620</a></span> | <span class="t">then we did-- then we used a pre-layer norm formulation, which was also observed in the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1462" target="_blank">00:24:22.380</a></span> | <span class="t">original ResNet papers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1464" target="_blank">00:24:24.780</a></span> | <span class="t">And so the model is basically, all right, you've got your input, well, you have spatial</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1469" target="_blank">00:24:29.940</a></span> | <span class="t">mixing-- spatial mixing through attention, three, four layers, and this sort of repeats.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1474" target="_blank">00:24:34.900</a></span> | <span class="t">And the-- the difference in-- on the decoder side is that you also now have encoder-decoder</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1479" target="_blank">00:24:39.780</a></span> | <span class="t">attention and encoder-decoder attention at every-- at every-- at every layer. If there's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1486" target="_blank">00:24:46.380</a></span> | <span class="t">any questions, yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1487" target="_blank">00:24:47.380</a></span> | <span class="t">Yes, what was your question behind the [INAUDIBLE] post-layer norm?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1491" target="_blank">00:24:51.500</a></span> | <span class="t">Oh, so-- so it ended up-- so if you do post-layer norm, then-- then--</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1497" target="_blank">00:24:57.860</a></span> | <span class="t">actually, Liz-- Liz, do I have that slide? Let me check. Probably I've deleted it. But</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1502" target="_blank">00:25:02.380</a></span> | <span class="t">if you do post-layer norm, then you are basically squashing both the residual and the additive</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1509" target="_blank">00:25:09.060</a></span> | <span class="t">parts. So when you-- so your activations from the lower layers keep getting-- keep going</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1513" target="_blank">00:25:13.340</a></span> | <span class="t">through layer norms. But in pre-layer norm, you're only-- you're only-- a residual path</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1517" target="_blank">00:25:17.660</a></span> | <span class="t">has a layer norm, which means your-- your activations all the way from the bottom of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1521" target="_blank">00:25:21.340</a></span> | <span class="t">the model are free. They're untouched, and they can pass through the-- yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1527" target="_blank">00:25:27.820</a></span> | <span class="t">Yes, OK. OK, so now-- so now-- I mean, so until this point, we haven't discussed why</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1534" target="_blank">00:25:34.180</a></span> | <span class="t">did we-- you know, we haven't discussed multi-head attention, which ended up being very important.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1540" target="_blank">00:25:40.220</a></span> | <span class="t">So one of the problems with attention is that imagine if you wanted to-- I mean, so oftentimes</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1548" target="_blank">00:25:48.900</a></span> | <span class="t">language is about understanding who did what to whom. So in this case, the cat licked the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1554" target="_blank">00:25:54.340</a></span> | <span class="t">owner's hand. So licked-- who licked what? Like, the cat licked the owner, right? So</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1558" target="_blank">00:25:58.620</a></span> | <span class="t">now if you actually want to combine information from these two slots, these positions, these</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1563" target="_blank">00:26:03.940</a></span> | <span class="t">vectors, then the best you could do with attention is 0.5, 0.5 to the single layer, right? Half</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1568" target="_blank">00:26:08.700</a></span> | <span class="t">probability, half probability. But then they get mushed together, right? But now imagine</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1572" target="_blank">00:26:12.140</a></span> | <span class="t">the-- imagine the strength that a convolution has. It can actually have-- that actually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1578" target="_blank">00:26:18.940</a></span> | <span class="t">should have-- well, OK, well, I think the point will still come across. So now what</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1585" target="_blank">00:26:25.300</a></span> | <span class="t">a convolution can do is because it has-- it basically applies-- essentially, a convolution,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1590" target="_blank">00:26:30.460</a></span> | <span class="t">in this case, it's a 5 by 1. All it really does is it just applies a different linear</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1596" target="_blank">00:26:36.540</a></span> | <span class="t">transformation at each position, right? So it can take any-- and because these linear</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1601" target="_blank">00:26:41.740</a></span> | <span class="t">transformations are different, it can-- the first linear transformation can learn, I'm</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1606" target="_blank">00:26:46.100</a></span> | <span class="t">going to take a little bit of information from here. I'm going to take a little bit</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1609" target="_blank">00:26:49.140</a></span> | <span class="t">of information from here. And I'm going to put them together, right? And the attention,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1613" target="_blank">00:26:53.460</a></span> | <span class="t">the best way that you could actually just do this is best by averaging. That would mush</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1616" target="_blank">00:26:56.300</a></span> | <span class="t">all these things.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1617" target="_blank">00:26:57.300</a></span> | <span class="t">But having different linear transformations allows you to take a part of the embedding</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1620" target="_blank">00:27:00.660</a></span> | <span class="t">here, a part of the embedding here, mix it up, and then maybe put it together without</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1624" target="_blank">00:27:04.300</a></span> | <span class="t">actually then interfering with each other. And multi-head attention, which is a bit like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1628" target="_blank">00:27:08.500</a></span> | <span class="t">basically a multi-tape, multi-head of a multi-head Turing machine with different read-write</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1636" target="_blank">00:27:16.300</a></span> | <span class="t">heads, essentially allows you-- starts getting you that property back, where now what you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1642" target="_blank">00:27:22.600</a></span> | <span class="t">do is you essentially-- you now-- you bring back the ability to select different parts</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1648" target="_blank">00:27:28.580</a></span> | <span class="t">of the input. So you chop up the hidden dimension into independent pieces. And then each one</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1653" target="_blank">00:27:33.580</a></span> | <span class="t">of them is now able to do attention. So now you can have probability 1 in this place and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1657" target="_blank">00:27:37.980</a></span> | <span class="t">probability 1 in this other subspace, instead of having 0.5, 0.5. So now you don't have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1662" target="_blank">00:27:42.460</a></span> | <span class="t">to-- you don't have to get these averaging effects. You can actually be selective, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1668" target="_blank">00:27:48.340</a></span> | <span class="t">And also, for computational reasons, instead of actually having eight attention layers</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1673" target="_blank">00:27:53.420</a></span> | <span class="t">of like-- or six attention heads of d dimensions, we had-- or eight attention heads of d dimensions,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1678" target="_blank">00:27:58.780</a></span> | <span class="t">we had eight attention heads of d by 8 dimensions, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1683" target="_blank">00:28:03.260</a></span> | <span class="t">So we wouldn't incur any more-- we wouldn't incur any more flops, for the same amount</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1690" target="_blank">00:28:10.540</a></span> | <span class="t">of flops. But that's only half the story, because the attention heads themselves turn</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1694" target="_blank">00:28:14.180</a></span> | <span class="t">out to be quite expensive, which then later on had to be-- they were doing improvements</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1697" target="_blank">00:28:17.620</a></span> | <span class="t">that needed to be made, right? And the most important part-- probably the most important</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1706" target="_blank">00:28:26.260</a></span> | <span class="t">result was that, with the transformer, we were able to outperform previous ensembled</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1713" target="_blank">00:28:33.860</a></span> | <span class="t">models as well. And that was very, very exciting, that, hey, this single model actually is able</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1718" target="_blank">00:28:38.500</a></span> | <span class="t">to outperform previous ensembled models. And not only that-- and this was machine translation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1724" target="_blank">00:28:44.580</a></span> | <span class="t">in WMT 2014, English, German, and English, French machine translation tasks. And not</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1731" target="_blank">00:28:51.780</a></span> | <span class="t">only were we able to do it in less flops, but also these-- it was very clear that this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1741" target="_blank">00:29:01.660</a></span> | <span class="t">was a very general model, as we immediately applied it to parsing, and we were able to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1746" target="_blank">00:29:06.220</a></span> | <span class="t">get-- we were able to get, with a small model, excellent results.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1750" target="_blank">00:29:10.980</a></span> | <span class="t">So in some sense, this was very exciting, because this meant that, all right, now this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1758" target="_blank">00:29:18.900</a></span> | <span class="t">consolidation that we're trying to go for in machine learning, we probably have a model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1762" target="_blank">00:29:22.460</a></span> | <span class="t">that's more general than what we had before, and we can now throw it at different-- maybe</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1767" target="_blank">00:29:27.420</a></span> | <span class="t">we can now throw it at different problems, right? And ultimately, why? Because it would</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1772" target="_blank">00:29:32.580</a></span> | <span class="t">be helpful to have a single model that's able to combine representations from speech, images,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1780" target="_blank">00:29:40.420</a></span> | <span class="t">and language. And if you had a general substrate that worked well in all tasks, then potentially</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1785" target="_blank">00:29:45.940</a></span> | <span class="t">you could get to the single multimodal model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1791" target="_blank">00:29:51.180</a></span> | <span class="t">Sometimes interpretability is like tea leaves. It's like reading tea leaves, so one should</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1797" target="_blank">00:29:57.660</a></span> | <span class="t">be careful. But it was nice that the attention by itself can give you some interpretability,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1803" target="_blank">00:30:03.180</a></span> | <span class="t">and we were able to kind of see how some of these attention heads, or some of these attention</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1809" target="_blank">00:30:09.140</a></span> | <span class="t">mechanisms were actually able to learn long-distance relationships. Some actually learned to be</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1814" target="_blank">00:30:14.100</a></span> | <span class="t">kind of early on in the transformer. We saw this generally invariant pattern, where some</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1820" target="_blank">00:30:20.340</a></span> | <span class="t">of the attention heads basically turned out to just look like convolutions. They were</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1823" target="_blank">00:30:23.740</a></span> | <span class="t">just putting in local information. There's, of course, now being much more advanced work</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1827" target="_blank">00:30:27.860</a></span> | <span class="t">with some of the mechanistic interpretability stuff with grokking and the stuff that's happening</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1834" target="_blank">00:30:34.060</a></span> | <span class="t">in entropic, which is where they're learning now that actually learning how to interpret</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1840" target="_blank">00:30:40.300</a></span> | <span class="t">these induction heads. So it's interesting. But we were able to see some anecdotal evidence</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1846" target="_blank">00:30:46.900</a></span> | <span class="t">of these heads actually performing very, very distinct and clear actions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1851" target="_blank">00:30:51.060</a></span> | <span class="t">OK, so if there's any more questions, then I'll pause for a second.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1857" target="_blank">00:30:57.740</a></span> | <span class="t">Do you, by the research, find that it's the induction heads that are causing the in-context</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1863" target="_blank">00:31:03.180</a></span> | <span class="t">learning?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1864" target="_blank">00:31:04.180</a></span> | <span class="t">Yeah, it's hard to tell. So from what I haven't looked at the most recent work, but they have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1870" target="_blank">00:31:10.220</a></span> | <span class="t">solved this issue of superposition. Is that right? So now, with having solved that, they're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1874" target="_blank">00:31:14.180</a></span> | <span class="t">able to-- does that roughly mean that now they'll be able to assign distinguishing features</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1879" target="_blank">00:31:19.260</a></span> | <span class="t">to each one of these heads and be able to explain it, from what I understand? Or the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1885" target="_blank">00:31:25.140</a></span> | <span class="t">in-context learning part is that-- is it that they have to show it, or is it that they're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1890" target="_blank">00:31:30.660</a></span> | <span class="t">saying that in-context learning happens because of induction heads?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1893" target="_blank">00:31:33.340</a></span> | <span class="t">Yeah, the latter.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1894" target="_blank">00:31:34.340</a></span> | <span class="t">Yeah, it's the latter. Yeah, it's not clear, because-- yeah, I think there's probably many,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1902" target="_blank">00:31:42.860</a></span> | <span class="t">many kinds of-- in-context learning is shown to work in so many different tasks that--</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1909" target="_blank">00:31:49.140</a></span> | <span class="t">and actually, I haven't followed this quite well. I don't know specifically-- what are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1913" target="_blank">00:31:53.300</a></span> | <span class="t">the induction heads typically-- what kinds of properties do they have? Do you know what</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1917" target="_blank">00:31:57.860</a></span> | <span class="t">kinds of mechanisms they have?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1919" target="_blank">00:31:59.660</a></span> | <span class="t">OK, so yeah, so then-- so since both of us don't know this really, really well, we won't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1925" target="_blank">00:32:05.420</a></span> | <span class="t">be able to go very far here. But I'm not sure if they've gotten to the point where they're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1930" target="_blank">00:32:10.580</a></span> | <span class="t">able to explain most of the in-context learning because of induction heads, from what I understand.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1934" target="_blank">00:32:14.420</a></span> | <span class="t">They might have, yeah. Does anybody know about the induction heads? OK, so now, over the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1945" target="_blank">00:32:25.780</a></span> | <span class="t">years, so there have been a few-- there have been many papers, but there have been a few</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1953" target="_blank">00:32:33.340</a></span> | <span class="t">changes that have been important. There have been a few changes that have stuck, and the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1959" target="_blank">00:32:39.060</a></span> | <span class="t">new transformers typically have these improvements, right? And we'll go from bottom to top with</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1967" target="_blank">00:32:47.500</a></span> | <span class="t">some of them and see which ones have actually stuck, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1971" target="_blank">00:32:51.260</a></span> | <span class="t">So we started with the first-- one of the biggest problems with self-attention was that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1975" target="_blank">00:32:55.140</a></span> | <span class="t">it was-- that self-attention itself is permutation invariant, right? You need to dope position</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1984" target="_blank">00:33:04.260</a></span> | <span class="t">information in order for it to learn some kind of temporal structure. And in the original</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1989" target="_blank">00:33:09.260</a></span> | <span class="t">transformer, we used these sinusoids, and we had hoped that it would actually learn</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1993" target="_blank">00:33:13.540</a></span> | <span class="t">relative position encodings because you could decompose the position encoding of another--</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=1999" target="_blank">00:33:19.660</a></span> | <span class="t">you could decompose the position embedding of another position as some linear function</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=2004" target="_blank">00:33:24.060</a></span> | <span class="t">of the previous one. And we had-- and some-- and another factor, which depends on the relative</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=2010" target="_blank">00:33:30.500</a></span> | <span class="t">distance between the two. But that didn't happen. Learned position encodings in the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=2014" target="_blank">00:33:34.900</a></span> | <span class="t">original paper did as well, and so we were not quite able to get-- we were not quite</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=2023" target="_blank">00:33:43.620</a></span> | <span class="t">able to get these model relative distances using the sinusoids.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=2026" target="_blank">00:33:46.980</a></span> | <span class="t">So then a couple of important-- and this is a very biased sample, but I think it generally</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=2032" target="_blank">00:33:52.820</a></span> | <span class="t">covers a large category of these-- it covers a large set of papers. There's roughly sort</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=2039" target="_blank">00:33:59.820</a></span> | <span class="t">of three categories, right? So there's-- and all of them are kind of now explicitly learning</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=2045" target="_blank">00:34:05.700</a></span> | <span class="t">relative-- explicitly learning relative embeddings. So there's-- so in the relative position transformer,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=2053" target="_blank">00:34:13.340</a></span> | <span class="t">we had an embedding for every pair of relative positions. And using that, we basically then</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=2058" target="_blank">00:34:18.300</a></span> | <span class="t">dot-- we did a dot product of that embedding with a query that produced a logit that modulated</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=2063" target="_blank">00:34:23.060</a></span> | <span class="t">according to the relative distance. And we found this to be extremely-- we found this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=2067" target="_blank">00:34:27.900</a></span> | <span class="t">to be extremely useful for translation, but I'll show also in music.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=2074" target="_blank">00:34:34.180</a></span> | <span class="t">Another sort of-- maybe a simplification, this is the alibi paper where-- this is non-parametric.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=2080" target="_blank">00:34:40.100</a></span> | <span class="t">These are not learned, where instead of an embedding for every pair of positions, you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=2084" target="_blank">00:34:44.740</a></span> | <span class="t">actually have a single bias, right? So you just add a single bias to the logit, and you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=2090" target="_blank">00:34:50.220</a></span> | <span class="t">can either learn it, or you can use a heuristic, which Alibi did. And one other advantage about</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=2098" target="_blank">00:34:58.300</a></span> | <span class="t">relative position encodings is that they could potentially allow you to extrapolate to new</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=2102" target="_blank">00:35:02.500</a></span> | <span class="t">to longer sequence lengths, which you couldn't do with absolute position encodings.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=2108" target="_blank">00:35:08.340</a></span> | <span class="t">I'm curious about the room-- about what the room thinks here, but I believe that the latest</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=2115" target="_blank">00:35:15.040</a></span> | <span class="t">in partition relative position encodings where this is-- I believe it's called the row former,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=2120" target="_blank">00:35:20.740</a></span> | <span class="t">where they basically just rotate the embedding with every pair of dimensions a little bit.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=2128" target="_blank">00:35:28.600</a></span> | <span class="t">And the angle of rotation depends on your actual absolute distance. But what ends up</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=2133" target="_blank">00:35:33.060</a></span> | <span class="t">happening is, when you do the attention operation, you end up getting relative-- you end up basically</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=2138" target="_blank">00:35:38.940</a></span> | <span class="t">getting an effect where you're modulating the logit based on relative distance.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=2143" target="_blank">00:35:43.140</a></span> | <span class="t">So now what's remarkable about this approach, what's-- it combines the best of both worlds,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=2148" target="_blank">00:35:48.180</a></span> | <span class="t">right? It actually-- it's absolute position encodings-- relative position encodings had</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=2152" target="_blank">00:35:52.420</a></span> | <span class="t">a couple of challenges in that you have to maintain an extra logit for-- or an embedding</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=2157" target="_blank">00:35:57.700</a></span> | <span class="t">for every pair. So there was a lot of-- so it ended up increasing your memory. Here,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=2162" target="_blank">00:36:02.860</a></span> | <span class="t">these are actually absolute position encodings, but they gave you-- they ended up giving you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=2167" target="_blank">00:36:07.060</a></span> | <span class="t">the relative modulation in the attention operation that you needed.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=2170" target="_blank">00:36:10.900</a></span> | <span class="t">And I believe the consensus is that this is the most successful-- this is the most successful</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=2175" target="_blank">00:36:15.300</a></span> | <span class="t">position encoding. Is that correct, or are there-- is that-- are there others that are--</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=2179" target="_blank">00:36:19.780</a></span> | <span class="t">that people-- is that the consensus? OK. So it looks like-- so I would say that the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=2187" target="_blank">00:36:27.620</a></span> | <span class="t">the-- these relative rotations are from-- or the approach that's in the reformer is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=2193" target="_blank">00:36:33.940</a></span> | <span class="t">likely-- is basically an actual new genuine improvement that is now going to stay with</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=2199" target="_blank">00:36:39.260</a></span> | <span class="t">the transformer. And it has all the-- it has all the great properties of what you would</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=2202" target="_blank">00:36:42.980</a></span> | <span class="t">want. It has-- it's an absolute position encoding that gives you relative effects, which is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=2206" target="_blank">00:36:46.940</a></span> | <span class="t">what we originally wanted. And one-- and to emphasize that we needed relative-- like that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=2216" target="_blank">00:36:56.580</a></span> | <span class="t">being-- emphasize two things. One, that modeling, like, interesting temporal relationships,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=2224" target="_blank">00:37:04.100</a></span> | <span class="t">which is-- which are really important in music, requires a good position representation. We</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=2229" target="_blank">00:37:09.660</a></span> | <span class="t">actually found significant improvements in the music transformer. Is it-- is it possible</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=2233" target="_blank">00:37:13.820</a></span> | <span class="t">to play this? OK. So here is a-- like, here's a priming sequence. This is-- this is work</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=2241" target="_blank">00:37:21.740</a></span> | <span class="t">by-- work by Anna Huang, by the way. So this is a in-context learning in music, because</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=2256" target="_blank">00:37:36.380</a></span> | <span class="t">you actually see this prompt and you ask the model to complete it. OK. So now this is the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=2261" target="_blank">00:37:41.180</a></span> | <span class="t">vanilla transformer. And you can already-- so you can see that these were using-- I mean,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=2273" target="_blank">00:37:53.140</a></span> | <span class="t">we tried both learned and sinusoids. And you can see that it starts off peppy and happy,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=2277" target="_blank">00:37:57.660</a></span> | <span class="t">but then just sort of languishes into something really sad and confused, right? So it's not</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=2282" target="_blank">00:38:02.260</a></span> | <span class="t">able to capture these-- because music has these interesting motifs where-- well, there's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=2287" target="_blank">00:38:07.620</a></span> | <span class="t">motifs at different levels, because there's some repetition locally, but there's a repetition</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=2292" target="_blank">00:38:12.860</a></span> | <span class="t">across the entire piece as well. So now here, this is with the relative transformer. And</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=2300" target="_blank">00:38:20.980</a></span> | <span class="t">this is with the first approach where we had relative embeddings. And we had to-- we had</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=2306" target="_blank">00:38:26.060</a></span> | <span class="t">to-- we had to develop a compute-efficient approach to actually with-- by using some</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=2312" target="_blank">00:38:32.260</a></span> | <span class="t">matrix calisthenics to actually put the logits in the right place. So you can read the papers</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=2317" target="_blank">00:38:37.600</a></span> | <span class="t">here. It's fun. So here's the same prime sequence. And let's see the completion here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=2332" target="_blank">00:38:52.140</a></span> | <span class="t">So Anna, who is the first author of this paper, and also a musician, tells me this actually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=2347" target="_blank">00:39:07.720</a></span> | <span class="t">captures a lot of structure in music. It sounds nicer than the previous one, but maybe-- depends</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=2352" target="_blank">00:39:12.880</a></span> | <span class="t">on what people's tastes are. Like maybe some avant-garde jazz fan would like the second--</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=2358" target="_blank">00:39:18.120</a></span> | <span class="t">would like the first piece. But the point here was that the difference is pretty clear</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=2363" target="_blank">00:39:23.840</a></span> | <span class="t">between not working and working. And I think people-- it'd be fun to try this out with</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=2368" target="_blank">00:39:28.680</a></span> | <span class="t">the new rotary position encodings. All right. OK. So walking up, now that we have a good</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=2377" target="_blank">00:39:37.920</a></span> | <span class="t">mechanism-- a better mechanism than we originally had for modeling relative distances. And there's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=2385" target="_blank">00:39:45.520</a></span> | <span class="t">advancements on top of the rotary position encodings where, by adjusting the base frequencies,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=2389" target="_blank">00:39:49.840</a></span> | <span class="t">you can-- when you encounter longer sequences, you can just adjust the base frequencies.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=2394" target="_blank">00:39:54.720</a></span> | <span class="t">And then the model's not going to-- the model's not going to degrade. So that has good properties.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=2401" target="_blank">00:40:01.480</a></span> | <span class="t">Probably there's been several, several important contributions to the attention piece itself,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=2409" target="_blank">00:40:09.400</a></span> | <span class="t">which is the primary workhorse here. It's the one that you can think of it as-- it's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=2413" target="_blank">00:40:13.920</a></span> | <span class="t">either-- there's induction heads that are learning how to copy. Or maybe all it's really</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=2419" target="_blank">00:40:19.640</a></span> | <span class="t">doing is just routing information so that the giant feed-forward layers can actually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=2423" target="_blank">00:40:23.600</a></span> | <span class="t">learn the important features. But there's broadly two classes of problems. There are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=2428" target="_blank">00:40:28.440</a></span> | <span class="t">two classes of issues with the attention mechanism. One that was brought up today that's very</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=2432" target="_blank">00:40:32.600</a></span> | <span class="t">evident is long context itself. So the complexity, as we remember, was quadratic in the length</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=2440" target="_blank">00:40:40.560</a></span> | <span class="t">of the sequence. And once your sequences get very, very long-- once your sequences get</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=2444" target="_blank">00:40:44.560</a></span> | <span class="t">very, very long, then not only-- I mean, there's one problem that's going to-- it's going to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=2451" target="_blank">00:40:51.040</a></span> | <span class="t">become very-- it's going to become computationally expensive. But it's also the logics that are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=2454" target="_blank">00:40:54.920</a></span> | <span class="t">going to become infeasible, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=2456" target="_blank">00:40:56.760</a></span> | <span class="t">So there's just generally a few groups of papers. One is restricting attention windows.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=2462" target="_blank">00:41:02.160</a></span> | <span class="t">And we did this for images where they had local 1D and 2D attention for images. And</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=2469" target="_blank">00:41:09.440</a></span> | <span class="t">in the first one, we actually just rasterized the image. And we had local 1D attention,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=2473" target="_blank">00:41:13.760</a></span> | <span class="t">which is very similar to the sliding window attention in the recent Mistral paper. And</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=2480" target="_blank">00:41:20.000</a></span> | <span class="t">then in the 2D case, we have a spatial 2D attention. Then there was these sparse versions</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=2488" target="_blank">00:41:28.960</a></span> | <span class="t">where you actually-- you had these specific patterns that over many layers-- I mean, you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=2494" target="_blank">00:41:34.200</a></span> | <span class="t">can think about it as, if you have these sparse matrices, how many of them do you have to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=2499" target="_blank">00:41:39.800</a></span> | <span class="t">multiply with each other until you get a really dense matrix, right? So roughly, this kind</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=2503" target="_blank">00:41:43.640</a></span> | <span class="t">of turns out to be-- so here, you can get connectivity-- is that for me? No, OK. You</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=2514" target="_blank">00:41:54.040</a></span> | <span class="t">can get connectivity between distant pixels or distant notes in a musical tune or words</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=2522" target="_blank">00:42:02.840</a></span> | <span class="t">pretty quickly. And then there's a second one, which there hasn't been enough work.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=2528" target="_blank">00:42:08.360</a></span> | <span class="t">And there's some challenges there. But it's these unstructured sparse attention approaches.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=2533" target="_blank">00:42:13.400</a></span> | <span class="t">And they're typically-- they're essentially-- at a higher level, what they're really trying</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=2538" target="_blank">00:42:18.120</a></span> | <span class="t">to do is imagine that I walked up to you and I told you that, hey, these are the bunches</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=2545" target="_blank">00:42:25.600</a></span> | <span class="t">of tokens that just have very high inter-similarity. Like, they're likely to tend to each other.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=2553" target="_blank">00:42:33.080</a></span> | <span class="t">How quickly can I approximate it without actually having to do the whole computation, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=2557" target="_blank">00:42:37.480</a></span> | <span class="t">Two approaches. And in routing attention, you use vector quantization. And in the LSH</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=2562" target="_blank">00:42:42.320</a></span> | <span class="t">or the-- I forget what-- I think I forget the name of the paper. But in this paper,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=2568" target="_blank">00:42:48.720</a></span> | <span class="t">they used LSH. And in the routing transformer, most layers were actually local. The final</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=2578" target="_blank">00:42:58.960</a></span> | <span class="t">layers, which typically are the ones that end up do modeling, that end up modeling these</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=2583" target="_blank">00:43:03.640</a></span> | <span class="t">long-distance relationships, were the ones that actually used this kind of content-based</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=2587" target="_blank">00:43:07.680</a></span> | <span class="t">unstructured sparse attention. And the results were generally better. And it's also interesting</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=2593" target="_blank">00:43:13.240</a></span> | <span class="t">that maybe we can build models on very long sequences, where most layers are fairly local.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=2600" target="_blank">00:43:20.120</a></span> | <span class="t">And you have only a few layers that are actually doing these long-distance attentions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=2603" target="_blank">00:43:23.400</a></span> | <span class="t">Now, one of the bigger challenges there, actually, even though it ended up being-- even though</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=2608" target="_blank">00:43:28.720</a></span> | <span class="t">you end up nullifying a lot of the flops that you would do if you did full attention, the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=2614" target="_blank">00:43:34.320</a></span> | <span class="t">problem always ends up being memory movement. Always ends up being memory movement. And</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=2619" target="_blank">00:43:39.720</a></span> | <span class="t">there's still more innovation to be done here, also, with memory bandwidth improving. Maybe</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=2623" target="_blank">00:43:43.960</a></span> | <span class="t">some of these approaches become more feasible today than they were when we wrote these papers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=2630" target="_blank">00:43:50.000</a></span> | <span class="t">But this is an interesting approach, where you're essentially trying to approximate the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=2632" target="_blank">00:43:52.820</a></span> | <span class="t">original attention matrix.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=2633" target="_blank">00:43:53.820</a></span> | <span class="t">Sorry. This is kind of a silly thing, but a clarification. How is this unstructured</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=2637" target="_blank">00:43:57.920</a></span> | <span class="t">sparse attention scheme very different from just convolutions that are sparse, in the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=2642" target="_blank">00:44:02.440</a></span> | <span class="t">sense that you're losing a lot of the long-distance or unrelated context from any arbitrary comparison</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=2648" target="_blank">00:44:08.160</a></span> | <span class="t">elements?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=2649" target="_blank">00:44:09.160</a></span> | <span class="t">Right. So I would say that this is similar to the convolution there. If you did this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=2655" target="_blank">00:44:15.120</a></span> | <span class="t">perfectly, then what you didn't attend to would have very little attention in itself.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=2662" target="_blank">00:44:22.720</a></span> | <span class="t">So you're essentially trying to guess, as best as you can, what would have attended</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=2667" target="_blank">00:44:27.840</a></span> | <span class="t">to each other. And so it uses content based unstructured sparsity.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=2675" target="_blank">00:44:35.200</a></span> | <span class="t">And there's probably more interesting work to be done there. Maybe instead of actually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=2679" target="_blank">00:44:39.320</a></span> | <span class="t">just doing a token at a time, you end up doing a lot of memory movement. You end up deciding</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=2683" target="_blank">00:44:43.800</a></span> | <span class="t">which chunks want to self-attend to which chunks. So then you just move entire chunks</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=2687" target="_blank">00:44:47.160</a></span> | <span class="t">at a time.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=2688" target="_blank">00:44:48.160</a></span> | <span class="t">Right. So I think there's some interesting directions here. And frankly, the ones that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=2696" target="_blank">00:44:56.400</a></span> | <span class="t">ended up sticking are the simplest ones. And because structure sparsity is easy, you're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=2703" target="_blank">00:45:03.700</a></span> | <span class="t">able to optimize easily in modern accelerators. So again, you should make physics your friend.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=2712" target="_blank">00:45:12.400</a></span> | <span class="t">And so typically, local attention or sliding into attention, we're still seeing it often</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=2717" target="_blank">00:45:17.320</a></span> | <span class="t">appear and do well. These other sort of really wild but very expressive unstructured sparse</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=2724" target="_blank">00:45:24.320</a></span> | <span class="t">attention approaches typically haven't quite succeeded.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=2727" target="_blank">00:45:27.160</a></span> | <span class="t">There's, of course, linear attention variance that I don't think today are in any of the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=2732" target="_blank">00:45:32.360</a></span> | <span class="t">[INAUDIBLE] architectures. There were other approaches that, hey, instead of actually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=2735" target="_blank">00:45:35.560</a></span> | <span class="t">doing n squared, you do n squared d, where you learn new k embeddings, where you do nkd</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=2745" target="_blank">00:45:45.080</a></span> | <span class="t">and then you do ndk. So you basically factor it, right? Just like an analog matrix factorization.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=2751" target="_blank">00:45:51.400</a></span> | <span class="t">Something that's-- one other approach that's interesting that I would like myself to actually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=2755" target="_blank">00:45:55.660</a></span> | <span class="t">investigate is we are seeing, in general, using retrieval as a tool. So why don't you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=2760" target="_blank">00:46:00.640</a></span> | <span class="t">just pretend that your memories, your memories themselves were documents and use retrieval</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=2765" target="_blank">00:46:05.320</a></span> | <span class="t">as a tool there. So the memorizing transformer, basically, it essentially does a mix of local</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=2772" target="_blank">00:46:12.000</a></span> | <span class="t">and it then retrieves from very, very long memories. And they find that you don't need</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=2776" target="_blank">00:46:16.120</a></span> | <span class="t">to train the model from scratch. All you need to do is adapt with this approach on some</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=2782" target="_blank">00:46:22.400</a></span> | <span class="t">small amount of data. And you're able to learn a good retrieval mechanism. I think it's quite</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=2785" target="_blank">00:46:25.880</a></span> | <span class="t">interesting.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=2786" target="_blank">00:46:26.880</a></span> | <span class="t">So it still comes in this content-based decision of what I should attend to. But I like the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=2794" target="_blank">00:46:34.200</a></span> | <span class="t">fact that it just makes retrieval a tool that you can use either on your own memories or</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=2798" target="_blank">00:46:38.960</a></span> | <span class="t">you could use it on documents. It's a nice general view of looking at things.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=2804" target="_blank">00:46:44.600</a></span> | <span class="t">OK, so now the second piece, which you basically run into-- you run into the issue that not</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=2812" target="_blank">00:46:52.080</a></span> | <span class="t">all flops are equal, right? So if you look at the memory hierarchy, a lot of your activations</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=2820" target="_blank">00:47:00.120</a></span> | <span class="t">that are stored in the GPU-HPU, which today in the H100 is about 80 gigabytes. But the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=2828" target="_blank">00:47:08.980</a></span> | <span class="t">H100 is 80 gigabytes, and the A100 is 40 gigabytes, right? So it's a limited amount of high-bandwidth</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=2836" target="_blank">00:47:16.120</a></span> | <span class="t">memory. And so you have to first go from high-bandwidth memory to the SRAM. And then you have to go</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=2841" target="_blank">00:47:21.160</a></span> | <span class="t">to the compute elements and then back, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=2843" target="_blank">00:47:23.240</a></span> | <span class="t">So every single time-- and this is-- I mean, it probably-- whenever-- if interested, you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=2852" target="_blank">00:47:32.400</a></span> | <span class="t">look at roofline analysis. The roofline analysis actually gives you a nice picture to characterize</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=2859" target="_blank">00:47:39.920</a></span> | <span class="t">for any device where you would need-- where your workload or operation needs to be so</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=2868" target="_blank">00:47:48.320</a></span> | <span class="t">that you can actually effectively utilize the compute as much. You want to be compute-bound,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=2872" target="_blank">00:47:52.460</a></span> | <span class="t">because ultimately, if you don't calculate representations, if you don't calculate, you're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=2875" target="_blank">00:47:55.920</a></span> | <span class="t">not going to get any output. But if you spend a lot of time moving things around and spend</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=2879" target="_blank">00:47:59.640</a></span> | <span class="t">less relative time calculating, then you're actually-- you're kind of wasting effort,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=2885" target="_blank">00:48:05.680</a></span> | <span class="t">right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=2886" target="_blank">00:48:06.680</a></span> | <span class="t">So one of the-- so if you look at standard attention mechanism, right, one of the issues</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=2890" target="_blank">00:48:10.520</a></span> | <span class="t">is that-- OK, so imagine you have your queries, keys, and values all in your memory. But then</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=2895" target="_blank">00:48:15.600</a></span> | <span class="t">you need to then-- your standard approach would be you move it from HBM. You do the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=2901" target="_blank">00:48:21.120</a></span> | <span class="t">calculations. You compute the attention. You compute the logits. You move logits back into</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=2905" target="_blank">00:48:25.640</a></span> | <span class="t">HBM. And then you compute softmax, right, the softmax back into HBM. And then you basically</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=2911" target="_blank">00:48:31.840</a></span> | <span class="t">load the probabilities and the values then to then finally compute the outputs, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=2918" target="_blank">00:48:38.320</a></span> | <span class="t">So the arithmetic intensity or the arithmetic intensity or operational intensity, which</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=2923" target="_blank">00:48:43.880</a></span> | <span class="t">is the amount of flops that you do per byte on attention, even though it's less flops</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=2929" target="_blank">00:48:49.360</a></span> | <span class="t">than, say, a one-by-one convolution, it has more-- it is lower, because it typically has</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=2933" target="_blank">00:48:53.800</a></span> | <span class="t">more memory movement. Whereas one-by-one convolutions have less memory movement. You just move the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=2938" target="_blank">00:48:58.240</a></span> | <span class="t">weights, move the activations, you do the calculations, and you bring them back, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=2941" target="_blank">00:49:01.440</a></span> | <span class="t">And same goes for convolutions, too. And convolutions have a very high arithmetic intensity. It's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=2944" target="_blank">00:49:04.960</a></span> | <span class="t">not that you just want the highest arithmetic intensity or operational intensity operations,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=2948" target="_blank">00:49:08.800</a></span> | <span class="t">because you still want to have useful parameters, right? So it's a trade-off.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=2953" target="_blank">00:49:13.640</a></span> | <span class="t">So a lot of-- so there's been a bunch of improvements that will stick. I mean, they're almost certain</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=2959" target="_blank">00:49:19.680</a></span> | <span class="t">likely to stay, that try to combat this issue both in training time, because your logits</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=2964" target="_blank">00:49:24.640</a></span> | <span class="t">can get really big, but also inference time or your KB. When you're doing inference, then</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=2969" target="_blank">00:49:29.560</a></span> | <span class="t">you have a single query. But your KB cache, right, you have to maintain your keys and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=2975" target="_blank">00:49:35.000</a></span> | <span class="t">values that can grow quite a bit. So you have to move that around.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=2977" target="_blank">00:49:37.800</a></span> | <span class="t">And so the first step of the day is simple. Let's just decrease the activation memory.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=2982" target="_blank">00:49:42.840</a></span> | <span class="t">So the multi-query approach, where it's basically in a multiple-- so you reduce-- you have multiple</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=2990" target="_blank">00:49:50.160</a></span> | <span class="t">queries, but just you reduce the number of read heads to just one. So you have just one</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=2995" target="_blank">00:49:55.000</a></span> | <span class="t">key and one value. That does reduce your expressivity.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=2997" target="_blank">00:49:57.920</a></span> | <span class="t">So grouped query, which is now a simple balance, that basically says, hey, let's not take the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3002" target="_blank">00:50:02.680</a></span> | <span class="t">extreme of having all this temporary activation memory. Let's actually group it to a different</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3007" target="_blank">00:50:07.800</a></span> | <span class="t">query. So a bunch of queries will attend to the same keys and values.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3012" target="_blank">00:50:12.480</a></span> | <span class="t">And then what ends up happening is-- another point to note here is that all of this is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3018" target="_blank">00:50:18.200</a></span> | <span class="t">relative, because most of the work in these very, very-- oh, but a third approach, actually,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3022" target="_blank">00:50:22.920</a></span> | <span class="t">that I should say of not worrying about your attention is just to make it more of a debate.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3029" target="_blank">00:50:29.160</a></span> | <span class="t">But then you just get about your three-fold computations and your attention computations</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3033" target="_blank">00:50:33.000</a></span> | <span class="t">just like a small slice of that. So you don't worry about it, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3036" target="_blank">00:50:36.000</a></span> | <span class="t">So typically, these larger models, even though grouped query attention has more activation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3042" target="_blank">00:50:42.320</a></span> | <span class="t">memory than multi-query, when with these large models, it's still not a much larger-- it's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3046" target="_blank">00:50:46.680</a></span> | <span class="t">not a much larger-- it's still a smaller proportion of what you're doing in the feedforce or your</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3050" target="_blank">00:50:50.480</a></span> | <span class="t">certified, right? So I guess three things, like ignore, make it really big. Second is,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3056" target="_blank">00:50:56.800</a></span> | <span class="t">I guess, you-- but even with prolonged context, you can do some of these approaches that we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3064" target="_blank">00:51:04.720</a></span> | <span class="t">talked about. But then you also have these system optimizations, which are pretty cool.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3070" target="_blank">00:51:10.600</a></span> | <span class="t">So the softmax has an interesting property that you can compute it in an online fashion.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3075" target="_blank">00:51:15.400</a></span> | <span class="t">You can compute it incrementally. So if you've got a bunch of logits, so you're kind of streaming</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3080" target="_blank">00:51:20.000</a></span> | <span class="t">them, if you've got a partial softmax and a new logit comes in, you can update it in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3084" target="_blank">00:51:24.920</a></span> | <span class="t">an online fashion, right? So what does that mean? That means that now you never needed</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3091" target="_blank">00:51:31.320</a></span> | <span class="t">to write logits or the p's into the HBM. So you save a lot, right? If there's an extremely</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3096" target="_blank">00:51:36.280</a></span> | <span class="t">long sequence, you end up writing a lot. So you save on that. And both these approaches</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3101" target="_blank">00:51:41.600</a></span> | <span class="t">end up-- in one case, the first paper was on TPUs that introduced this property or took</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3108" target="_blank">00:51:48.640</a></span> | <span class="t">advantage of this property, the property to be able to compute the softmax in an online</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3113" target="_blank">00:51:53.160</a></span> | <span class="t">fashion. And the second paper, which is now flash attention today, they've had many advancements.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3120" target="_blank">00:52:00.000</a></span> | <span class="t">They actually had some systems-level optimization where now you can actually have very, very</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3124" target="_blank">00:52:04.600</a></span> | <span class="t">long sequences on GPUs, the optimizations for GPUs, by basically not moving the logits</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3132" target="_blank">00:52:12.280</a></span> | <span class="t">back into HBM, using this online-- using this property and also writing the right columns</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3136" target="_blank">00:52:16.280</a></span> | <span class="t">that use the SRAM and everything-- use the GPU. With any questions? What's the time?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3147" target="_blank">00:52:27.600</a></span> | <span class="t">So we are basically 20 minutes. I'll finish in 10. So I just covered these two. There's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3153" target="_blank">00:52:33.680</a></span> | <span class="t">many, many-- there's, I guess, there's other important improvements. I'd say this to the--</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3160" target="_blank">00:52:40.520</a></span> | <span class="t">we talked about the pre- and post-versus post-layer norm. There's been some changes of the feed-forward</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3166" target="_blank">00:52:46.440</a></span> | <span class="t">layers themselves. You can stare at the feed-forward layers. I mean, you can stare at anything</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3171" target="_blank">00:52:51.360</a></span> | <span class="t">long enough, everything becomes attention. But it's true in the feed-forward case that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3174" target="_blank">00:52:54.640</a></span> | <span class="t">if you look at it, you can think about them as-- it looks like attention. And there was</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3178" target="_blank">00:52:58.880</a></span> | <span class="t">a paper that sort of turned that into a bit of a-- turned those into memories. It was</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3186" target="_blank">00:53:06.000</a></span> | <span class="t">originally by Facebook. I actually forget what it was. But it didn't-- and the feed-forward</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3190" target="_blank">00:53:10.520</a></span> | <span class="t">layers just stayed-- I mean, we typically haven't seen a lot of improvements on them.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3196" target="_blank">00:53:16.280</a></span> | <span class="t">There have been some efforts on higher-order attention right now. Attention, if you think</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3201" target="_blank">00:53:21.720</a></span> | <span class="t">about it, is a third-order interaction. You have queries, keys, and values. But-- and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3205" target="_blank">00:53:25.800</a></span> | <span class="t">right now-- but you could imagine actually having four-order interactions where you're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3209" target="_blank">00:53:29.800</a></span> | <span class="t">actually computing logits of pairs of things against all pairs of things, right? So these</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3214" target="_blank">00:53:34.240</a></span> | <span class="t">are now higher-order interactions where now you can have complicated geometries that you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3219" target="_blank">00:53:39.040</a></span> | <span class="t">actually include in your attention computation. And maybe it's important for, say, biology</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3224" target="_blank">00:53:44.320</a></span> | <span class="t">or some biology, but it's not been explored much.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3227" target="_blank">00:53:47.840</a></span> | <span class="t">What has actually worked and is likely to now stay is some approaches on password decoding.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3233" target="_blank">00:53:53.040</a></span> | <span class="t">Not quite the original, less or non-order-regressive aspirations that we had, but these more speculative</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3238" target="_blank">00:53:58.960</a></span> | <span class="t">decoding where-- the heuristic there is pretty simple. You score-- if you want-- instead</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3244" target="_blank">00:54:04.440</a></span> | <span class="t">of generating from a heavy model, generate from a really light model that captures the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3249" target="_blank">00:54:09.040</a></span> | <span class="t">diversity and then score with a heavy model. So then you re-rank the list. And that ends</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3252" target="_blank">00:54:12.800</a></span> | <span class="t">up working quite well. And most production deployments likely use speculative decoding.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3259" target="_blank">00:54:19.240</a></span> | <span class="t">OK. So now switching gears, I guess we started this-- or we started by coding the Dartmouth</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3271" target="_blank">00:54:31.760</a></span> | <span class="t">conference where they wanted to build a single machine. And the question now is, with large</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3275" target="_blank">00:54:35.240</a></span> | <span class="t">language models that are now eating up most of the internet, are we quite getting there?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3281" target="_blank">00:54:41.440</a></span> | <span class="t">And we are seeing some remarkable-- we're finally seeing self-supervised learning work</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3285" target="_blank">00:54:45.360</a></span> | <span class="t">at a scale that-- work at an unprecedented scale where now by digesting carefully curated</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3294" target="_blank">00:54:54.480</a></span> | <span class="t">and colossal amounts of text with very, very large models, you're able to-- they're able</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3298" target="_blank">00:54:58.720</a></span> | <span class="t">to perform, presumably, or it's still waiting to be confirmed, tasks that are-- or they're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3306" target="_blank">00:55:06.560</a></span> | <span class="t">able to actually perform at least a large-- a broad variety of tasks by just specifying</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3312" target="_blank">00:55:12.200</a></span> | <span class="t">them in the prompt. And it's now-- it's almost like now you have-- now you have a new computer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3318" target="_blank">00:55:18.120</a></span> | <span class="t">And for people who are really excited about the future of agents, now they can program</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3321" target="_blank">00:55:21.600</a></span> | <span class="t">thousands of agents with the same computer. Oh, maybe you-- now they have-- now they have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3327" target="_blank">00:55:27.040</a></span> | <span class="t">agents that they can-- several agents that they can program with the same computer that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3331" target="_blank">00:55:31.400</a></span> | <span class="t">then coordinate to solve problems. So we're getting much closer to the single model, not</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3337" target="_blank">00:55:37.200</a></span> | <span class="t">quite being able to specify all the rules of intelligence, but at least learning all</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3340" target="_blank">00:55:40.960</a></span> | <span class="t">the rules from data. We're very close to-- we're much closer than we were before. Now,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3346" target="_blank">00:55:46.600</a></span> | <span class="t">this doesn't include all the important thing-- all the important specialization that has</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3351" target="_blank">00:55:51.720</a></span> | <span class="t">to happen after, like, RLHF or the alignment that you have to do to make a model more steerable.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3359" target="_blank">00:55:59.440</a></span> | <span class="t">But it's-- and as it stands today, the scaling laws that the transformer exhibits are better</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3368" target="_blank">00:56:08.000</a></span> | <span class="t">than any other existing model, right? And there's an interesting question of, you know,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3374" target="_blank">00:56:14.000</a></span> | <span class="t">which-- can we build a better model? And there are efforts-- there's, I guess, from the Stanford,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3378" target="_blank">00:56:18.640</a></span> | <span class="t">from Chris Rea's lab, there have been a couple of efforts. There's been some revival of RNNs.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3383" target="_blank">00:56:23.840</a></span> | <span class="t">But I think the only-- the only-- the only thing I'll say that is that the attention</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3388" target="_blank">00:56:28.640</a></span> | <span class="t">operation itself, this operation of actually moving information around or routing information</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3393" target="_blank">00:56:33.040</a></span> | <span class="t">based on content, is very, very useful. And it's maybe not a surprise that this general</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3399" target="_blank">00:56:39.400</a></span> | <span class="t">sort of spatial mixing of sampling, downsampling architecture has kind of stayed both in cognition,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3404" target="_blank">00:56:44.720</a></span> | <span class="t">computer vision, and language, now with the transformer. So there are some invariants</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3408" target="_blank">00:56:48.320</a></span> | <span class="t">that are likely to stay, but I do think that maybe that it-- and there is certainly much</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3412" target="_blank">00:56:52.880</a></span> | <span class="t">more room there to improve, I mean, not just in the architecture, but on data itself. Like,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3418" target="_blank">00:56:58.680</a></span> | <span class="t">there's probably 2x improvements on data. But I wouldn't say that there's-- there aren't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3424" target="_blank">00:57:04.160</a></span> | <span class="t">architectures in the future that will get better scaling loss. They might, but there</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3428" target="_blank">00:57:08.600</a></span> | <span class="t">are properties about the transformer, such as self-attention and its general structuring,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3432" target="_blank">00:57:12.880</a></span> | <span class="t">that is likely-- that we're likely to see in future architectures to come. Also, it's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3439" target="_blank">00:57:19.320</a></span> | <span class="t">hard to really think of a modern-- like, if somebody really, really wanted to study large-scale</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3445" target="_blank">00:57:25.200</a></span> | <span class="t">modern transformers, you'd have to study, like, all-reduces, InfiniBand, Rocky, and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3451" target="_blank">00:57:31.720</a></span> | <span class="t">what are-- like, well, but they get congestion, and they have very, very large clusters. So</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3457" target="_blank">00:57:37.640</a></span> | <span class="t">the computer is no-- the computer-- the transformer is now, in some sense, a data center, because</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3462" target="_blank">00:57:42.320</a></span> | <span class="t">it's not split up. These large transformers are with tens of-- potentially tens of thousands</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3466" target="_blank">00:57:46.360</a></span> | <span class="t">of GPUs. So-- and so if you-- so now you actually have to really focus on several parts, the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3476" target="_blank">00:57:56.720</a></span> | <span class="t">infrastructures and the model itself. But what's really interesting, I think, is-- you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3481" target="_blank">00:58:01.560</a></span> | <span class="t">know, I was just thinking of the smallest model that has exhibited emergent phenomena.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3485" target="_blank">00:58:05.560</a></span> | <span class="t">Well, so we certainly know that GPT-4, which is likely-- I don't know if you're allowed</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3490" target="_blank">00:58:10.480</a></span> | <span class="t">to say it's some big-- like, trillion parameters. Yeah, I think you're allowed to say it, yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3496" target="_blank">00:58:16.400</a></span> | <span class="t">So it's a trillion-parameter size model. That's what everybody says. Size model. And then</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3499" target="_blank">00:58:19.600</a></span> | <span class="t">you have Brocking, which is a two-layer transformer that has this weird emergent behavior that,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3506" target="_blank">00:58:26.280</a></span> | <span class="t">when you just keep training it on just-- on some amount of data, suddenly it just exhibits</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3510" target="_blank">00:58:30.400</a></span> | <span class="t">a space shift, right? So we're lucky. There are these, like, really-- there's strange--</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3515" target="_blank">00:58:35.840</a></span> | <span class="t">there's weirdness everywhere. There's weirdness in small models and large models. And maybe</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3520" target="_blank">00:58:40.240</a></span> | <span class="t">we can learn something about large models by studying these small models, one would</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3524" target="_blank">00:58:44.720</a></span> | <span class="t">hope. But it's funny. There's still unexplained phenomena in very, very large models and very,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3531" target="_blank">00:58:51.160</a></span> | <span class="t">very small models. But large transformers are no more just, you know, like a cola. There's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3537" target="_blank">00:58:57.480</a></span> | <span class="t">just-- I mean, it could still be, but it's-- you have to-- there's so many-- there's so</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3542" target="_blank">00:59:02.360</a></span> | <span class="t">much that you have to keep in your stack in order to really optimize this entire-- this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3547" target="_blank">00:59:07.640</a></span> | <span class="t">model. Of course, some of the very exciting directions are LLMs using tools. Yeah, that's--</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3554" target="_blank">00:59:14.640</a></span> | <span class="t">so now the benefits of-- now language models or transformers are actually starting to use</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3559" target="_blank">00:59:19.800</a></span> | <span class="t">external entities. So they're connecting with the rest of the world. And I guess that's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3564" target="_blank">00:59:24.000</a></span> | <span class="t">a good-- that's a good pitch for-- it makes a lot of sense to actually build products</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3568" target="_blank">00:59:28.820</a></span> | <span class="t">today because it's through interactions with-- like, if you want to get to the next tranche</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3573" target="_blank">00:59:33.520</a></span> | <span class="t">of capabilities, where will they come from? And likely, with a lot of usage, you will</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3578" target="_blank">00:59:38.840</a></span> | <span class="t">learn much more about how to guide these models and how to train them without-- than in vacuum.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3583" target="_blank">00:59:43.320</a></span> | <span class="t">Now, you can definitely do very, very important work still in-- by even with a smaller model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3589" target="_blank">00:59:49.200</a></span> | <span class="t">or even without building a product, without building a product because there's so many</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3592" target="_blank">00:59:52.360</a></span> | <span class="t">important unsolved problems. And maybe you shouldn't even work on the transformer because</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3596" target="_blank">00:59:56.880</a></span> | <span class="t">it's like Burning Man right now. Everybody's going to the same party. But I think that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3603" target="_blank">01:00:03.320</a></span> | <span class="t">you will be able to build new capabilities once these-- with this human-machine collaboration.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3609" target="_blank">01:00:09.800</a></span> | <span class="t">Of course, teaching models or models being able to express what they don't know, how</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3615" target="_blank">01:00:15.120</a></span> | <span class="t">do you learn new skills in infants' time, important for-- there's some interesting work,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3618" target="_blank">01:00:18.640</a></span> | <span class="t">I think, on Minecraft that showed some evidence of this is also important for agents. And</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3623" target="_blank">01:00:23.760</a></span> | <span class="t">another-- a great property that some of these diffusion models have is the more compute</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3628" target="_blank">01:00:28.720</a></span> | <span class="t">you spend, the potentially better the quality of the image gets. But we don't exactly quite</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3632" target="_blank">01:00:32.720</a></span> | <span class="t">have that for language. And what does that mean? So today, the best-- the models that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3637" target="_blank">01:00:37.240</a></span> | <span class="t">can reason-- that have the most proficient reasoning and planning are also the largest</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3642" target="_blank">01:00:42.600</a></span> | <span class="t">ones. Can we separate it out? Can we have smaller models that do some adaptive thinking</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3647" target="_blank">01:00:47.600</a></span> | <span class="t">and are able to match the capabilities of potentially larger models and reasoning and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3652" target="_blank">01:00:52.080</a></span> | <span class="t">planning? And maybe the answer is going to come by connecting to external planners and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3656" target="_blank">01:00:56.280</a></span> | <span class="t">planners or maybe with better representations of data, you can actually reason better on</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3662" target="_blank">01:01:02.000</a></span> | <span class="t">it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3663" target="_blank">01:01:03.000</a></span> | <span class="t">Also, this is, again, a more systems piece, but it's fascinating how low you can actually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3669" target="_blank">01:01:09.040</a></span> | <span class="t">get on your-- how low you can-- how few bits you can actually use and still get something</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3675" target="_blank">01:01:15.320</a></span> | <span class="t">useful out. We already went from-- the original transformer was trained on 32-bit precision.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3679" target="_blank">01:01:19.600</a></span> | <span class="t">Then we went to BFLOAT16. And now there's good signs that INT8 and FP8 would also work.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3685" target="_blank">01:01:25.040</a></span> | <span class="t">And I think there's useful work to be done there. Again, going back to the same-- this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3689" target="_blank">01:01:29.360</a></span> | <span class="t">argument about if you're actually-- if you're vector-- if you're using fewer bits to represent</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3696" target="_blank">01:01:36.000</a></span> | <span class="t">a number, you're actually transmitting fewer bits to the-- from HPM. So actually, you can</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3700" target="_blank">01:01:40.400</a></span> | <span class="t">get faster. You can utilize your matrix multipliers much more effectively.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3705" target="_blank">01:01:45.240</a></span> | <span class="t">That was it. So there's many topics, but hopefully, we covered something fun. Thank you.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3711" target="_blank">01:01:51.880</a></span> | <span class="t">Yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3712" target="_blank">01:01:52.880</a></span> | <span class="t">Could you talk about what you're working on now and what you're working on?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3723" target="_blank">01:02:03.880</a></span> | <span class="t">Yeah. So I'm a co-founder of a startup with my transformer co-author, Nikki. And we're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3732" target="_blank">01:02:12.680</a></span> | <span class="t">working on building models that will ultimately automate workflows. And we're starting with</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3741" target="_blank">01:02:21.080</a></span> | <span class="t">data. So it's very puzzling what happens in a company. Companies are just basically just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3746" target="_blank">01:02:26.320</a></span> | <span class="t">masses of dark knowledge, right? And there's very few people that have both the technical</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3751" target="_blank">01:02:31.200</a></span> | <span class="t">privilege and the understanding to ask questions, like typically analysts. But the less you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3756" target="_blank">01:02:36.400</a></span> | <span class="t">understand, the less effective your company can be. So how can you eventually help anyone</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3761" target="_blank">01:02:41.320</a></span> | <span class="t">become an effective analyst, in some sense, right? So help them ask the right question,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3766" target="_blank">01:02:46.120</a></span> | <span class="t">help them figure out, eventually, the whys, which then requires some kind of counterfactual</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3770" target="_blank">01:02:50.760</a></span> | <span class="t">reasoning that's very complicated. But start with data, since it's so important, and companies</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3775" target="_blank">01:02:55.280</a></span> | <span class="t">are essentially drowning in it. And then be spread out from there, and then try to automate</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3780" target="_blank">01:03:00.320</a></span> | <span class="t">other workflows and be impressed. But we believe that some of the early signs that we're seeing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3786" target="_blank">01:03:06.440</a></span> | <span class="t">and our position is that I believe that this is going to require a full stack approach.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3792" target="_blank">01:03:12.600</a></span> | <span class="t">So not just building the model, because you can then control what feedback you get. And</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3798" target="_blank">01:03:18.920</a></span> | <span class="t">so if you have a gap in the model, you ask for that. You start to get that feedback,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3803" target="_blank">01:03:23.040</a></span> | <span class="t">so then you can improve the model. That's what we're doing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3806" target="_blank">01:03:26.720</a></span> | <span class="t">Please talk to us after we've done it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3809" target="_blank">01:03:29.880</a></span> | <span class="t">Yes?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3810" target="_blank">01:03:30.880</a></span> | <span class="t">I'm surprised to hear that you're fairly bullish about tools in the end, like in our</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3814" target="_blank">01:03:34.680</a></span> | <span class="t">transparency control and third-party things. We talked about in the beginning that your</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3817" target="_blank">01:03:37.840</a></span> | <span class="t">motivation was transformers that enabled us to get rid of pipelines. But I feel like the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3821" target="_blank">01:03:41.040</a></span> | <span class="t">rule was against pipelines again. So I'm surprised at this. Can you talk about that and where</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3825" target="_blank">01:03:45.160</a></span> | <span class="t">do you think that's going to go?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3827" target="_blank">01:03:47.680</a></span> | <span class="t">Right. So until we get to the point where it's like, you know, we're turtles all the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3832" target="_blank">01:03:52.880</a></span> | <span class="t">way down, it's like transformers all the way down. No, I think that tools just allows you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3837" target="_blank">01:03:57.480</a></span> | <span class="t">to-- so it's kind of like, how do you interface with a machine that can think, right? You</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3845" target="_blank">01:04:05.120</a></span> | <span class="t">have to build some kind of interface. And if you build a useful functionality, you want</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3848" target="_blank">01:04:08.240</a></span> | <span class="t">the machine to be able to take your functionality and do generally useful things with it, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3852" target="_blank">01:04:12.840</a></span> | <span class="t">And I think that using tools is just a way of leveraging things that people have built</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3858" target="_blank">01:04:18.160</a></span> | <span class="t">and software out there. Certain tools will probably get absorbed in the model, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3863" target="_blank">01:04:23.520</a></span> | <span class="t">Some others won't. And that still gives us the ability to-- yeah, it still gives us the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3869" target="_blank">01:04:29.120</a></span> | <span class="t">ability to-- and certain things that transformers shouldn't even do, sorry. I mean, like you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3875" target="_blank">01:04:35.640</a></span> | <span class="t">don't want to spend a billion flops per position to calculate two numbers, right? You don't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3880" target="_blank">01:04:40.800</a></span> | <span class="t">want to spend more flops to do an operation that required like 1 billion flops, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3885" target="_blank">01:04:45.240</a></span> | <span class="t">So there's certain things that the model should not do. It should use external tools. And</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3890" target="_blank">01:04:50.960</a></span> | <span class="t">there's certain things that the-- certain kind of thinking that the model should do.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3895" target="_blank">01:04:55.880</a></span> | <span class="t">So even from a capability perspective, there's an important question of what all the capability</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3900" target="_blank">01:05:00.560</a></span> | <span class="t">should be in this neural network, right? But then also being able to utilize the work that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3904" target="_blank">01:05:04.680</a></span> | <span class="t">others have done, software that other people have built. Yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3911" target="_blank">01:05:11.120</a></span> | <span class="t">It talks more about why like the original approach of decoding parallely and then integratively</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3915" target="_blank">01:05:15.440</a></span> | <span class="t">refining it. Yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3916" target="_blank">01:05:16.440</a></span> | <span class="t">Why that didn't work and what-- Yeah, so sometimes if you know exactly why</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3920" target="_blank">01:05:20.520</a></span> | <span class="t">things work, maybe you can make it work. But it ended up being-- so you're able to do silly</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3925" target="_blank">01:05:25.360</a></span> | <span class="t">things like randomly sort, which means that if somebody walks up to you with a sequence</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3931" target="_blank">01:05:31.160</a></span> | <span class="t">and you can-- I mean, you can break two modes. Like you can say ascending or descending.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3936" target="_blank">01:05:36.080</a></span> | <span class="t">So how do I say this? So typically, when you decode, right, imagine that when you give</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3942" target="_blank">01:05:42.580</a></span> | <span class="t">a prompt, you have many possible computations, right? And each time you make a choice, you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3949" target="_blank">01:05:49.600</a></span> | <span class="t">narrow that space. And each time another choice, you narrow that space, right? And you have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3954" target="_blank">01:05:54.720</a></span> | <span class="t">a very-- and you've learned to narrow the set of all possible, in some sense, paths</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3960" target="_blank">01:06:00.840</a></span> | <span class="t">in a way. The model doesn't have to decide what's the order in which you have to go.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3965" target="_blank">01:06:05.520</a></span> | <span class="t">When you're doing this less or non-autoregressive generation, you have to do both, right? And</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3971" target="_blank">01:06:11.880</a></span> | <span class="t">doing learning both simultaneously is hard. I mean, but eventually, I think that if for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3977" target="_blank">01:06:17.880</a></span> | <span class="t">a particular-- I think this is probably true, right? If an oracle walked up to me and said,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3985" target="_blank">01:06:25.840</a></span> | <span class="t">this is the order in which all these sentences should be generated. First, you should generate</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3990" target="_blank">01:06:30.120</a></span> | <span class="t">these three words. Then you should generate these other two. Then these other two. If</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3993" target="_blank">01:06:33.200</a></span> | <span class="t">somebody walked up to you and gave you this oracle ordering for all of human language,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=3996" target="_blank">01:06:36.880</a></span> | <span class="t">I think you would have a much better chance. And you could actually get this less non-autoregressive</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=4000" target="_blank">01:06:40.440</a></span> | <span class="t">generation. So one thing was basically the ordering itself. And I think it kind of has</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=4010" target="_blank">01:06:50.000</a></span> | <span class="t">to do that, because the ordering helps you then lock down the modes. It narrows down</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=4013" target="_blank">01:06:53.880</a></span> | <span class="t">what you're going to generate next. So ultimately, I think it does boil down to what's the right</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=4018" target="_blank">01:06:58.640</a></span> | <span class="t">non-autoregressive ordering. And that could be either you're still generating one word</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=4022" target="_blank">01:07:02.640</a></span> | <span class="t">at a time, but not autoregressively, or you're generating a few. And then based on that,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=4026" target="_blank">01:07:06.280</a></span> | <span class="t">you're generating the other few. So the words that you can generate all at once should be</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=4031" target="_blank">01:07:11.200</a></span> | <span class="t">conditionally independent of each other, right? What you've generated so far should have completely</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=4035" target="_blank">01:07:15.000</a></span> | <span class="t">explained them. And then what you generate after should again be-- they should be conditionally</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=4040" target="_blank">01:07:20.720</a></span> | <span class="t">independent, right? So how do you learn these conditional independences? Yeah. And if somebody</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=4044" target="_blank">01:07:24.400</a></span> | <span class="t">walked up to me and gave them to me, I think they'd probably learn them. Yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=4048" target="_blank">01:07:28.880</a></span> | <span class="t">Christian?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=4049" target="_blank">01:07:29.880</a></span> | <span class="t">[INAUDIBLE]</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=4050" target="_blank">01:07:30.880</a></span> | <span class="t">Yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=4051" target="_blank">01:07:31.880</a></span> | <span class="t">[INAUDIBLE]</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=4052" target="_blank">01:07:32.880</a></span> | <span class="t">Yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=4053" target="_blank">01:07:33.880</a></span> | <span class="t">[INAUDIBLE]</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=4054" target="_blank">01:07:34.880</a></span> | <span class="t">Yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=4055" target="_blank">01:07:35.880</a></span> | <span class="t">I think more of his thinking is that only scaling small and small doesn't help them</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=4066" target="_blank">01:07:46.880</a></span> | <span class="t">to actually learn how the real world actually works. And we have a good idea of truth and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=4077" target="_blank">01:07:57.380</a></span> | <span class="t">real world now. And do you agree with him? Do you think that [INAUDIBLE]</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=4088" target="_blank">01:08:08.760</a></span> | <span class="t">So yeah, I think it's interesting. You can't learn a word model with just language, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=4096" target="_blank">01:08:16.680</a></span> | <span class="t">So I mean, some of these models are not exactly being learned that way. You're doing RLHFs.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=4100" target="_blank">01:08:20.400</a></span> | <span class="t">You're getting some feedback, which means there's some-- you're applying some-- they</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=4106" target="_blank">01:08:26.680</a></span> | <span class="t">are modifying themselves to some preference, right? So it's not just a pure language model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=4113" target="_blank">01:08:33.240</a></span> | <span class="t">But it's interesting. So you've seen some of the work where robotics is now potentially</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=4117" target="_blank">01:08:37.840</a></span> | <span class="t">starting to flourish because they're able to use these large models as planners, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=4123" target="_blank">01:08:43.040</a></span> | <span class="t">And so I think that it's surprising how much of the world-- how much information about</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=4127" target="_blank">01:08:47.400</a></span> | <span class="t">the world that they carry. And if I understand, is that right that the SACAN were basically</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=4131" target="_blank">01:08:51.320</a></span> | <span class="t">used a language model now as a planner, right? And then they left the rest of it to just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=4135" target="_blank">01:08:55.960</a></span> | <span class="t">the standard perception and the classical tasks of even solving the robotics. So that's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=4141" target="_blank">01:09:01.240</a></span> | <span class="t">a-- I mean, that's-- no, while Jan is probably still right, but the usefulness of it is evident</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=4147" target="_blank">01:09:07.920</a></span> | <span class="t">in something that needs world knowledge, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=4151" target="_blank">01:09:11.240</a></span> | <span class="t">So I think you can do a lot with what you have. I mean, they're probably-- yeah, I mean,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=4161" target="_blank">01:09:21.500</a></span> | <span class="t">we still haven't quite extracted all the usefulness out of these models as well. And you might</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=4167" target="_blank">01:09:27.560</a></span> | <span class="t">be right in some things. But there's still a lot more to be gained. Yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=4175" target="_blank">01:09:35.520</a></span> | <span class="t">So I'm similar to the previous question, and you're also talking about immersion, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=4181" target="_blank">01:09:41.480</a></span> | <span class="t">I'm just curious to know what your thoughts are more on generalizability and immersion,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=4187" target="_blank">01:09:47.920</a></span> | <span class="t">especially in the-- I know there was a paper from DeepMind about the science-- yeah, I</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=4194" target="_blank">01:09:54.040</a></span> | <span class="t">think-- yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=4195" target="_blank">01:09:55.040</a></span> | <span class="t">Yeah, yeah, yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=4196" target="_blank">01:09:56.040</a></span> | <span class="t">Like, they can't really generalize outside of what they've been trained on as-- especially</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=4199" target="_blank">01:09:59.600</a></span> | <span class="t">because these large models now that they're just trained on everything. Is there truly</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=4203" target="_blank">01:10:03.560</a></span> | <span class="t">anything left that's out of distribution that you could really sort of benchmark it on?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=4208" target="_blank">01:10:08.600</a></span> | <span class="t">So I have been caught saying that if I had all my test data in my training, I'd make</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=4212" target="_blank">01:10:12.520</a></span> | <span class="t">a billion dollars. Yeah. So I don't have a problem with it. But I still think-- so OK,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=4219" target="_blank">01:10:19.320</a></span> | <span class="t">so correct me if I'm wrong, but the general argument is that these models have learned</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=4225" target="_blank">01:10:25.400</a></span> | <span class="t">such a vast set of distributions and phenomena that typically, when you interrogate them,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=4232" target="_blank">01:10:32.360</a></span> | <span class="t">they're often very cleverly blending or bringing information from what they've learned, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=4240" target="_blank">01:10:40.720</a></span> | <span class="t">It might, yes. And then they have these algorithmic tasks where the models fail to generalize,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=4246" target="_blank">01:10:46.640</a></span> | <span class="t">right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=4247" target="_blank">01:10:47.640</a></span> | <span class="t">So I'll focus on the former. I think that that's an incredibly useful property. It might</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=4254" target="_blank">01:10:54.680</a></span> | <span class="t">be that-- so I think maybe the feeling is that we actually don't quite understand how</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=4259" target="_blank">01:10:59.720</a></span> | <span class="t">much we could-- how much is even represented in text. And second, how much-- how far we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=4265" target="_blank">01:11:05.240</a></span> | <span class="t">could go if we were able to blend information from different-- like, certainly being able</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=4271" target="_blank">01:11:11.560</a></span> | <span class="t">to write about the Stanford-- this lecture in the rhyme meter and words of Chaucer, not</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=4277" target="_blank">01:11:17.840</a></span> | <span class="t">possible because nobody did it, right? But I think that you could do it, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=4282" target="_blank">01:11:22.160</a></span> | <span class="t">Now, is that blending information from what you already have? If so, that's-- that means</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=4287" target="_blank">01:11:27.160</a></span> | <span class="t">you can-- that's an incredible skill, right? Yeah, I haven't read it. It's very recent,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=4295" target="_blank">01:11:35.560</a></span> | <span class="t">but I believe the work. I think you can show that in these [INAUDIBLE] but I think there's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=4300" target="_blank">01:11:40.080</a></span> | <span class="t">a surprising amount of new-- seemingly new things you could do by just blending information</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=4307" target="_blank">01:11:47.120</a></span> | <span class="t">from what you've already learned. And yeah, it largely probably has to do with-- there's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=4312" target="_blank">01:11:52.080</a></span> | <span class="t">so much of it. Yeah, yeah. So you have a question? Yeah, I have two questions to go. [INAUDIBLE]</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=4320" target="_blank">01:12:00.960</a></span> | <span class="t">I think I had an ordering in mind and then I came back to you. Sorry. But [INAUDIBLE]</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=4328" target="_blank">01:12:08.800</a></span> | <span class="t">Give me a second. [INAUDIBLE] I was wondering if you might have insights into connecting</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=4335" target="_blank">01:12:15.120</a></span> | <span class="t">different agents, transformers, or whatnot. Neurons is a great-- I feel like transformers</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=4341" target="_blank">01:12:21.920</a></span> | <span class="t">essentially like a great connection of neurons in a specific way and it's awesome, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=4347" target="_blank">01:12:27.120</a></span> | <span class="t">So you figured out the best way to connect them so far.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=4350" target="_blank">01:12:30.040</a></span> | <span class="t">The agents? No, the neurons. Oh, the neurons. You're talking about-- do</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=4353" target="_blank">01:12:33.520</a></span> | <span class="t">I know somehow to do this in the brain? No, the neurons in the transformer, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=4358" target="_blank">01:12:38.120</a></span> | <span class="t">The transformer is the way you connect different pieces together. And then when you connect</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=4363" target="_blank">01:12:43.880</a></span> | <span class="t">them together, it works. Yeah. [INAUDIBLE] I was wondering if you have some insights</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=4368" target="_blank">01:12:48.240</a></span> | <span class="t">in the building system that can actually go perform the best together.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=4372" target="_blank">01:12:52.480</a></span> | <span class="t">Yeah. [INAUDIBLE] I like to make this joke that the best agents are actually just the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=4378" target="_blank">01:12:58.840</a></span> | <span class="t">neurons because they can communicate with each other. They can update themselves really,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=4382" target="_blank">01:13:02.960</a></span> | <span class="t">really well by what the other agents are doing. What is the fundamental problem by making--</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=4389" target="_blank">01:13:09.840</a></span> | <span class="t">what is the fundamental issue in making a bunch of-- I'm trying to understand what are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=4396" target="_blank">01:13:16.560</a></span> | <span class="t">the fundamental problems in trying to make a bunch of systems work together, if that's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=4399" target="_blank">01:13:19.760</a></span> | <span class="t">what you're asking. One is goal decomposition, right? And one is the second big one is coordination,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=4407" target="_blank">01:13:27.200</a></span> | <span class="t">and third one is verification. If you solved a successful decomposition of the goals based</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=4412" target="_blank">01:13:32.160</a></span> | <span class="t">on what your estimate of the skills of these agents are, if you're able to do what they've</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=4416" target="_blank">01:13:36.920</a></span> | <span class="t">done, and if you're able to coordinate, then I think you could make a lot of progress,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=4420" target="_blank">01:13:40.840</a></span> | <span class="t">right? So while I didn't answer your question, I don't know in general how much progress</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=4425" target="_blank">01:13:45.320</a></span> | <span class="t">you've made in all these three areas. But does somebody have any input here?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=4430" target="_blank">01:13:50.360</a></span> | <span class="t">[INAUDIBLE] and you have something that's [INAUDIBLE] and you want to verify this [INAUDIBLE]</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=4440" target="_blank">01:14:00.120</a></span> | <span class="t">and make sure [INAUDIBLE] and verify everything and make it big enough. You can see how this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=4452" target="_blank">01:14:12.480</a></span> | <span class="t">is almost [INAUDIBLE] everything and making it efficient over time. And it's a lot of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=4458" target="_blank">01:14:18.800</a></span> | <span class="t">time [INAUDIBLE] how do you break the stuff, how do you [INAUDIBLE]</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=4465" target="_blank">01:14:25.800</a></span> | <span class="t">Yeah, right. But I think these [INAUDIBLE] are probably maybe to some degree [INAUDIBLE]</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=4472" target="_blank">01:14:32.360</a></span> | <span class="t">What's on mind? [INAUDIBLE]</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=4474" target="_blank">01:14:34.720</a></span> | <span class="t">It's actually one question. So [INAUDIBLE] now we have a [INAUDIBLE] but the human brain</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=4484" target="_blank">01:14:44.400</a></span> | <span class="t">is very modular. So it's modularity like the emergence phenomena, you need some spatial</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=4493" target="_blank">01:14:53.280</a></span> | <span class="t">space to make that happen. Yeah, and by modularity here you mean that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=4498" target="_blank">01:14:58.440</a></span> | <span class="t">is it modularity in that they have this vision, has this responsibility, or even is the composition</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=4506" target="_blank">01:15:06.000</a></span> | <span class="t">different, the construction different? What do you mean by that? Because you could have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=4511" target="_blank">01:15:11.440</a></span> | <span class="t">both, right? You could argue that there's no-- the responsibility is diffused across</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=4515" target="_blank">01:15:15.360</a></span> | <span class="t">the model. And it's just that experts try to go in the opposite direction, which I should</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=4520" target="_blank">01:15:20.040</a></span> | <span class="t">probably mention. That's another really exciting direction, which certainly has happened in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=4523" target="_blank">01:15:23.800</a></span> | <span class="t">a few folders, and it's going to stick. I totally missed it. That tries to get the specialization,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=4529" target="_blank">01:15:29.680</a></span> | <span class="t">right? So maybe that is some kind of modularity, right? Learn modularity. The rest of responsibility</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=4536" target="_blank">01:15:36.440</a></span> | <span class="t">for performing the task is likely distributed. But if now you're going to these subsystems</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=4541" target="_blank">01:15:41.520</a></span> | <span class="t">themselves of different composition, then you get back to-- and I know that this was</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=4547" target="_blank">01:15:47.200</a></span> | <span class="t">a goal with the Pathways Project at Google, where you wanted to have these really modular</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=4552" target="_blank">01:15:52.360</a></span> | <span class="t">systems communicate with each other. And I think there's-- it's just taken so long to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=4557" target="_blank">01:15:57.640</a></span> | <span class="t">get gradient descent. In fact, sometimes I think that rigid building architectures deserve</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=4562" target="_blank">01:16:02.360</a></span> | <span class="t">gradient descent. And I feel like if you can learn with gradient descent, it's very useful.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=4571" target="_blank">01:16:11.040</a></span> | <span class="t">Maybe it's actually possible to make these modular systems work. We have some of the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=4574" target="_blank">01:16:14.080</a></span> | <span class="t">three experts, and I imagine some of these problems that we discussed before. Does that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=4581" target="_blank">01:16:21.880</a></span> | <span class="t">make sense?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=4582" target="_blank">01:16:22.880</a></span> | <span class="t">Sorry, circling back to whatever seven questions ago, you mentioned that the problem with decoding</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=4589" target="_blank">01:16:29.400</a></span> | <span class="t">all at once was one of the things that code generating all at once has this assumption</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=4593" target="_blank">01:16:33.960</a></span> | <span class="t">that the outputs are conditionally independent. But aren't they, in a sense that if you have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=4598" target="_blank">01:16:38.280</a></span> | <span class="t">a latent space-- if you're given the latent space as your prior, then your posterior</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=4602" target="_blank">01:16:42.720</a></span> | <span class="t">outputs should be conditionally independent of each other, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=4605" target="_blank">01:16:45.520</a></span> | <span class="t">So great point. And where do you get the latent space from?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=4608" target="_blank">01:16:48.920</a></span> | <span class="t">Well, from the encoder, or whatever, in the beginning.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=4611" target="_blank">01:16:51.840</a></span> | <span class="t">Right, but there might be quite a few ways to translate something, right? Yeah, there's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=4617" target="_blank">01:16:57.280</a></span> | <span class="t">a multiple-- so if there's only one mode, then yeah, it's probably [INAUDIBLE] right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=4623" target="_blank">01:17:03.160</a></span> | <span class="t">But if there's multiple ways of-- well, actually, there's two things. How much does the latent</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=4627" target="_blank">01:17:07.760</a></span> | <span class="t">space actually carry? That was an important thing to ask, right? How much does it actually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=4631" target="_blank">01:17:11.880</a></span> | <span class="t">carry? Because it's not just the one latent vector that you're transmitting every-- you're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=4636" target="_blank">01:17:16.720</a></span> | <span class="t">doing attention again and again. But we took this approach, where we did precisely this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=4645" target="_blank">01:17:25.000</a></span> | <span class="t">We autoregressively generated tokens in a new vocabulary using vector quantization.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=4653" target="_blank">01:17:33.920</a></span> | <span class="t">So the conditional dependence was modeled in a latent space, where we discretized using</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=4660" target="_blank">01:17:40.480</a></span> | <span class="t">vector quantization. And then, based on that, we generated everything conditionally independent.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=4665" target="_blank">01:17:45.800</a></span> | <span class="t">And that didn't work. But again, so that didn't work in translations. The issue-- there were</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=4672" target="_blank">01:17:52.600</a></span> | <span class="t">some funky issues there, where the latent-- the latent sequence of latent vectors were</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=4680" target="_blank">01:18:00.280</a></span> | <span class="t">only effective-- were not effective if you can learn directly on the original data. You</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=4683" target="_blank">01:18:03.960</a></span> | <span class="t">have to do something like distillation. Because distillation itself throws away, potentially,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=4688" target="_blank">01:18:08.360</a></span> | <span class="t">some of the modes. So generally, lower entropy data was-- we had to train on it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=4692" target="_blank">01:18:12.640</a></span> | <span class="t">The second piece was, for practical systems, you have to make the whole thing really, really</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=4697" target="_blank">01:18:17.080</a></span> | <span class="t">fast. But this was a good research exercise. But ultimately, it didn't have the right practical</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=4703" target="_blank">01:18:23.040</a></span> | <span class="t">impact. Because speculative decoding, practically, with what we have right now didn't work well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=4707" target="_blank">01:18:27.440</a></span> | <span class="t">[INAUDIBLE]</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=4708" target="_blank">01:18:28.800</a></span> | <span class="t">Yeah, exactly. Yeah. But you're right. I think if you can generate a sufficiently-- if you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=4713" target="_blank">01:18:33.520</a></span> | <span class="t">can generate a good, sufficient latency, then yes, you're right. We can assume-- that makes</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=4718" target="_blank">01:18:38.560</a></span> | <span class="t">everything conditionally independent. Yeah. And we managed to do that a bit. But it wasn't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=4723" target="_blank">01:18:43.800</a></span> | <span class="t">quite good, I think.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=4728" target="_blank">01:18:48.160</a></span> | <span class="t">I guess this is the last question, now? Or are we already done now?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=4732" target="_blank">01:18:52.120</a></span> | <span class="t">[INAUDIBLE]</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=4740" target="_blank">01:19:00.240</a></span> | <span class="t">Oh, wow. That's too personal.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=4741" target="_blank">01:19:01.760</a></span> | <span class="t">[INAUDIBLE]</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=4745" target="_blank">01:19:05.280</a></span> | <span class="t">And I have friends there. They're all really great. They're doing terrible things. I think</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=4753" target="_blank">01:19:13.080</a></span> | <span class="t">that there's-- we'll be surprised how much there is to do. And if-- so first, the motivation,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=4760" target="_blank">01:19:20.560</a></span> | <span class="t">right? That is an entire new-- there's an entire new bucket of-- or like a new tranche</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=4768" target="_blank">01:19:28.960</a></span> | <span class="t">of capabilities that you will get with human-computer interaction. So you can make a product. People</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=4773" target="_blank">01:19:33.160</a></span> | <span class="t">use it. They give you feedback. Models get smarter. And this closed-loop system can really</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=4778" target="_blank">01:19:38.680</a></span> | <span class="t">bring-- can really advance models. And then bring value, right? That's one.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=4785" target="_blank">01:19:45.160</a></span> | <span class="t">And I think it's helpful to have some deep learning benefit. It's so much from a diversity</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=4792" target="_blank">01:19:52.720</a></span> | <span class="t">of ideas and people pursuing important directions. And I would say the same about building company</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=4802" target="_blank">01:20:02.800</a></span> | <span class="t">products, as well, or building companies that are building new kinds of products with these</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=4810" target="_blank">01:20:10.160</a></span> | <span class="t">models, right? So I would say that we have-- there's so much surface area that we could</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=4816" target="_blank">01:20:16.160</a></span> | <span class="t">build something incredible. So that's the second piece. Third, yeah. Maybe that's the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=4823" target="_blank">01:20:23.360</a></span> | <span class="t">more personal direction I want to bring on, right? Yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=4831" target="_blank">01:20:31.320</a></span> | <span class="t">[END PLAYBACK]</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=1GbDTTK3aR4&t=4832" target="_blank">01:20:32.880</a></span> | <span class="t">[BLANK_AUDIO]</span></div></div></body></html>