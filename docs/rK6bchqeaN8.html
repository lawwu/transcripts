<html><head><title>Foundations of Unsupervised Deep Learning (Ruslan Salakhutdinov, CMU)</title>
<style>
    body {
        font-family: Arial, sans-serif;
        margin: 0;
        padding: 0;
        background-color: #f4f4f4;
        color: #333;
    }
    .container {
        width: 80%;
        margin: auto;
        overflow: hidden;
    }
    h2, h3 {
        color: #333;
        text-align: center;
    }
    a {
        color: #0000FF;  /* Traditional blue color for links */
        text-decoration: none;
    }
    a:hover {
        text-decoration: underline;
    }
    img {
        display: block;
        margin: auto;
        max-width: 100%;
    }
    .c {
        margin: 10px 0;
    }
    .s, .t {
        display: inline-block;
        margin-right: 5px;
    }
    .max-width {
        max-width: 800px;
        margin: auto;
        padding-left: 20px;
    }
    table {
        width: 100%;
        border-collapse: collapse;
    }
    th, td {
        border: 1px solid #ddd;
        padding: 8px;
    }
    tr:nth-child(even) {
        background-color: #f2f2f2;
    }
    tr:nth-child(odd) {
        background-color: #e6e6e6;
    }
</style>

    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-69VLBMTTP0"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-69VLBMTTP0');
    </script>
    </head><body><div class='container'><a href="index.html">back to index</a><h2>Foundations of Unsupervised Deep Learning (Ruslan Salakhutdinov, CMU)</h2><a href="https://www.youtube.com/watch?v=rK6bchqeaN8"><img src="https://i.ytimg.com/vi_webp/rK6bchqeaN8/maxresdefault.webp" style="width:50%;"></a><div><br></div><h3>Chapters</h3><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=0">0:0</a> Deep Unsupervised Learning<br><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=87">1:27</a> Deep Autoencoder Model<br><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=242">4:2</a> Talk Roadmap<br><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=301">5:1</a> Learning Feature Representations<br><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=340">5:40</a> Traditional Approaches<br><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=362">6:2</a> Computer Vision Features<br><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=377">6:17</a> Audio Features<br><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=517">8:37</a> Sparse Coding: Training<br><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=619">10:19</a> Sparse Coding: Testing Time<br><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=651">10:51</a> Image Classification Evaluated on Caltech101 object category dataset<br><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=725">12:5</a> Interpreting Sparse Coding<br><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=972">16:12</a> Another Autoencoder Model<br><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=997">16:37</a> Predictive Sparse Decomposition<br><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1052">17:32</a> Stacked Autoencoders<br><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1123">18:43</a> Deep Autoencoders<br><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1220">20:20</a> Information Retrieval<br><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1265">21:5</a> Semantic Hashing<br><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1361">22:41</a> Deep Generative Model<br><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1688">28:8</a> Learning Features<br><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1744">29:4</a> Model Learning<br><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1982">33:2</a> Contrastive Divergence<br><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2085">34:45</a> RBMs for Word Counts<br><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2193">36:33</a> Collaborative Filtering<br><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2269">37:49</a> Product of Experts<br><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2372">39:32</a> Local vs. Distributed Representations<br><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2455">40:55</a> Deep Boltzmann Machines<br><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2484">41:24</a> Model Formulation<br><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2665">44:25</a> Good Generative Model?<br><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2754">45:54</a> Generative Model of 3-D Objects<br><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2812">46:52</a> 3-D Object Recognition<br><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2829">47:9</a> Data - Collection of Modalities<br><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2860">47:40</a> Challenges - 11<br><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2917">48:37</a> A Simple Multimodal Model<br><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2963">49:23</a> Text Generated from Images<br><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3071">51:11</a> Multimodal Linguistic Regularities<br><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3214">53:34</a> Helmholtz Machines vs. DBMS<br><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3260">54:20</a> Variational Autoencoders (VAE) The VAE defines a generative process in terms of ancestral sampling through a cascade of hidden stochastic layers<br><br><div style="text-align: left;"><a href="./rK6bchqeaN8.html">Whisper Transcript</a> | <a href="./transcript_rK6bchqeaN8.html">Transcript Only Page</a></div><br><div style="max-width: 800px;"><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=0" target="_blank">00:00:00.000</a></span> | <span class="t">Sound is good?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1" target="_blank">00:00:01.000</a></span> | <span class="t">Okay, great.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2" target="_blank">00:00:02.000</a></span> | <span class="t">So I wanted to talk to you about unsupervised learning, and that's the area where there's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=6" target="_blank">00:00:06.360</a></span> | <span class="t">been a lot of research.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=9" target="_blank">00:00:09.020</a></span> | <span class="t">But compared to supervised learning that you've heard about today, like convolutional networks,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=14" target="_blank">00:00:14.680</a></span> | <span class="t">unsupervised learning is not there yet.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=15" target="_blank">00:00:15.920</a></span> | <span class="t">So I'm going to show you lots of areas.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=20" target="_blank">00:00:20.560</a></span> | <span class="t">Parts of the talk are going to be a little bit more mathematical.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=23" target="_blank">00:00:23.840</a></span> | <span class="t">I apologize for that, but I'll try to give you a gist of the foundations, the math behind</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=28" target="_blank">00:00:28.840</a></span> | <span class="t">these models, as well as try to highlight some of the application areas.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=34" target="_blank">00:00:34.640</a></span> | <span class="t">What's the motivation?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=35" target="_blank">00:00:35.640</a></span> | <span class="t">Well, the motivation is that the space of data that we have today is just growing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=42" target="_blank">00:00:42.200</a></span> | <span class="t">If you look at the space of images, speech, if you look at social network data, if you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=47" target="_blank">00:00:47.720</a></span> | <span class="t">look at scientific data, I would argue that most of the data that we see today is unlabeled.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=56" target="_blank">00:00:56.440</a></span> | <span class="t">So how can we develop statistical models, models that can discover interesting kind</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=60" target="_blank">00:01:00.480</a></span> | <span class="t">of structure in unsupervised way or semi-supervised way?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=64" target="_blank">00:01:04.640</a></span> | <span class="t">And that's what I'm interested in, as well as how can we apply these models across multiple</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=71" target="_blank">00:01:11.320</a></span> | <span class="t">different domains.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=73" target="_blank">00:01:13.360</a></span> | <span class="t">And one particular framework of doing that is the framework of deep learning, where you're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=77" target="_blank">00:01:17.380</a></span> | <span class="t">trying to learn hierarchical representations of data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=81" target="_blank">00:01:21.240</a></span> | <span class="t">And again, as I go through the talk, I'm going to show you some examples.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=87" target="_blank">00:01:27.480</a></span> | <span class="t">So here's one example.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=90" target="_blank">00:01:30.320</a></span> | <span class="t">You can take a simple bag-of-words representation of an article or a newspaper.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=96" target="_blank">00:01:36.220</a></span> | <span class="t">You can use something that's called an autoencoder, just multiple levels.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=101" target="_blank">00:01:41.400</a></span> | <span class="t">You extract some latent code, and then you get some representation out of it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=106" target="_blank">00:01:46.640</a></span> | <span class="t">This is done completely in unsupervised way.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=108" target="_blank">00:01:48.520</a></span> | <span class="t">You don't provide any labels.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=109" target="_blank">00:01:49.920</a></span> | <span class="t">And if you look at the kind of structure that the model is discovering, it could be useful</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=113" target="_blank">00:01:53.280</a></span> | <span class="t">for visualization, for example, to see what kind of structure you see in your data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=120" target="_blank">00:02:00.480</a></span> | <span class="t">This was done on the Reuters dataset.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=123" target="_blank">00:02:03.760</a></span> | <span class="t">I've tried to kind of cluster together lots of different unsupervised learning techniques,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=129" target="_blank">00:02:09.520</a></span> | <span class="t">and I'll touch on some of them.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=131" target="_blank">00:02:11.640</a></span> | <span class="t">It's a little bit-- it's not a full set.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=135" target="_blank">00:02:15.100</a></span> | <span class="t">But the way that I typically think about these models is that there's a class of what I would</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=139" target="_blank">00:02:19.640</a></span> | <span class="t">call non-probabilistic models, models like sparse coding, autoencoders, clustering-based</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=146" target="_blank">00:02:26.560</a></span> | <span class="t">methods.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=147" target="_blank">00:02:27.560</a></span> | <span class="t">And these are all very, very powerful techniques, and I'll cover some of them in that talk as</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=152" target="_blank">00:02:32.880</a></span> | <span class="t">well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=153" target="_blank">00:02:33.880</a></span> | <span class="t">And then there is sort of a space of probabilistic models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=158" target="_blank">00:02:38.160</a></span> | <span class="t">And within probabilistic models, you have tractable models, things like fully observed</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=163" target="_blank">00:02:43.440</a></span> | <span class="t">belief networks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=165" target="_blank">00:02:45.440</a></span> | <span class="t">There's a beautiful class of models called neural autoregressive density estimators.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=170" target="_blank">00:02:50.200</a></span> | <span class="t">More recently, we've seen some successes of so-called pixel recurrent neural network models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=178" target="_blank">00:02:58.640</a></span> | <span class="t">And I'll show you some examples of that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=180" target="_blank">00:03:00.280</a></span> | <span class="t">There is a class of so-called intractable models, where you are looking at models like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=185" target="_blank">00:03:05.640</a></span> | <span class="t">Boltzmann machines and models like variational autoencoders, something that's been quite--</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=190" target="_blank">00:03:10.560</a></span> | <span class="t">there's been a lot of development in our community, in deep learning community in that space.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=195" target="_blank">00:03:15.400</a></span> | <span class="t">From Holtz machines, I'll tell you a little bit about what these models are, and a whole</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=199" target="_blank">00:03:19.960</a></span> | <span class="t">bunch of others as well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=202" target="_blank">00:03:22.920</a></span> | <span class="t">One particular structure within these models is that when you're building these generative</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=207" target="_blank">00:03:27.480</a></span> | <span class="t">models of data, you typically have to specify what the distributions you're looking at.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=213" target="_blank">00:03:33.160</a></span> | <span class="t">So you have to specify what the probability of the data, and generally doing some kind</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=217" target="_blank">00:03:37.020</a></span> | <span class="t">of approximate maximum likelihood estimation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=219" target="_blank">00:03:39.680</a></span> | <span class="t">And then more recently, we've seen some very exciting models coming out.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=224" target="_blank">00:03:44.120</a></span> | <span class="t">These are generative adversarial networks, moment matching networks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=228" target="_blank">00:03:48.640</a></span> | <span class="t">And this is a slightly different class of models, where you don't really have to specify</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=233" target="_blank">00:03:53.440</a></span> | <span class="t">what the density is.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=235" target="_blank">00:03:55.120</a></span> | <span class="t">You just need to be able to sample from those models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=237" target="_blank">00:03:57.480</a></span> | <span class="t">And I'm going to show you some examples of that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=241" target="_blank">00:04:01.800</a></span> | <span class="t">So my talk is going to be structured.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=244" target="_blank">00:04:04.120</a></span> | <span class="t">I'd like to introduce you to the basic building blocks, models like sparse coding models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=249" target="_blank">00:04:09.720</a></span> | <span class="t">Because I think that these are very important classes of models, particularly for folks</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=253" target="_blank">00:04:13.680</a></span> | <span class="t">who are working in industry and looking for simpler models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=258" target="_blank">00:04:18.840</a></span> | <span class="t">Autoencoder is a beautiful class of models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=261" target="_blank">00:04:21.200</a></span> | <span class="t">And then the second part of the talk, I'll focus more on generative models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=265" target="_blank">00:04:25.440</a></span> | <span class="t">I'll give you an introduction into restricted Boltz machines and deep Boltz machines.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=269" target="_blank">00:04:29.320</a></span> | <span class="t">These are statistical models that can model complicated data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=278" target="_blank">00:04:38.280</a></span> | <span class="t">And I'll spend some time showing you some examples, some recent developments in our</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=282" target="_blank">00:04:42.480</a></span> | <span class="t">community, specifically in the case of variational autoencoders, which I view them as a subclass</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=287" target="_blank">00:04:47.280</a></span> | <span class="t">of Helmholtz machines.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=289" target="_blank">00:04:49.360</a></span> | <span class="t">And I'll finish off by giving you an intuition about a slightly different class of models,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=294" target="_blank">00:04:54.440</a></span> | <span class="t">which would be these generative adversarial networks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=297" target="_blank">00:04:57.440</a></span> | <span class="t">OK, so let's jump into the first part.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=300" target="_blank">00:05:00.880</a></span> | <span class="t">But before I do that, let me just give you a little bit of motivation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=305" target="_blank">00:05:05.360</a></span> | <span class="t">I know Andre's done a great job, and Richard alluded to that as well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=310" target="_blank">00:05:10.640</a></span> | <span class="t">But the idea is, if I'm trying to classify a particular image, and if I say, if I'm looking</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=316" target="_blank">00:05:16.760</a></span> | <span class="t">at specific pixel representation, it might be difficult for me to classify what I'm seeing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=322" target="_blank">00:05:22.040</a></span> | <span class="t">On the other hand, if I can find the right representations, the right representations</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=327" target="_blank">00:05:27.500</a></span> | <span class="t">for these images, and then I get the right features, or get the right structure from</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=332" target="_blank">00:05:32.640</a></span> | <span class="t">the data, then it might be easier for me to see what's going on with my data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=338" target="_blank">00:05:38.920</a></span> | <span class="t">So how do I find these representations?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=340" target="_blank">00:05:40.760</a></span> | <span class="t">And this is one of traditional approaches that we've seen for a long time, is that you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=348" target="_blank">00:05:48.120</a></span> | <span class="t">have a data, you're creating some features, and then you're running your learning algorithm.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=353" target="_blank">00:05:53.120</a></span> | <span class="t">And for the longest time, in object recognition or in audio classification, you typically</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=357" target="_blank">00:05:57.500</a></span> | <span class="t">use some kind of hand-designed features, and then you start classifying what you have.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=364" target="_blank">00:06:04.000</a></span> | <span class="t">And like Andre was saying, in the space of vision, there's been a lot of different features,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=371" target="_blank">00:06:11.120</a></span> | <span class="t">designs of what's the right structure we should see in the data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=375" target="_blank">00:06:15.600</a></span> | <span class="t">In the space of audio, same thing is happening.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=379" target="_blank">00:06:19.960</a></span> | <span class="t">How can you find these right representations for your data?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=385" target="_blank">00:06:25.380</a></span> | <span class="t">And the idea behind representation learning, in particular in deep learning, is can we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=392" target="_blank">00:06:32.200</a></span> | <span class="t">actually learn these representations automatically?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=395" target="_blank">00:06:35.160</a></span> | <span class="t">And more importantly, can we actually learn these representations in an unsupervised way,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=399" target="_blank">00:06:39.000</a></span> | <span class="t">by just seeing lots and lots of unlabeled data?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=401" target="_blank">00:06:41.600</a></span> | <span class="t">Can we achieve that?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=403" target="_blank">00:06:43.480</a></span> | <span class="t">And there's been a lot of work done in that space, but we're not there yet.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=407" target="_blank">00:06:47.960</a></span> | <span class="t">So I wanted to lower your expectations as I show you some of the results.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=413" target="_blank">00:06:53.920</a></span> | <span class="t">OK, sparse coding.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=416" target="_blank">00:06:56.400</a></span> | <span class="t">This is one of the models that I think that everybody should know what it is.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=421" target="_blank">00:07:01.000</a></span> | <span class="t">It was actually first has its roots in '96, and it was originally developed to explain</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=428" target="_blank">00:07:08.320</a></span> | <span class="t">early visual processing in the brain.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=430" target="_blank">00:07:10.200</a></span> | <span class="t">I think of it as an edge detector.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=433" target="_blank">00:07:13.160</a></span> | <span class="t">And the objective here is the following.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=434" target="_blank">00:07:14.800</a></span> | <span class="t">Well, if I give you a set of data points, x1 up to xn, you'd want to learn a dictionary</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=439" target="_blank">00:07:19.520</a></span> | <span class="t">of bases, phi 1 up to phi k, so that every single data point can be written as a linear</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=445" target="_blank">00:07:25.760</a></span> | <span class="t">combination of the bases.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=447" target="_blank">00:07:27.500</a></span> | <span class="t">That's fairly simple.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=449" target="_blank">00:07:29.000</a></span> | <span class="t">There is one constraint in that you'd want your coefficients to be sparse.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=455" target="_blank">00:07:35.480</a></span> | <span class="t">You'd want them to be mostly zero.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=458" target="_blank">00:07:38.780</a></span> | <span class="t">So every data point is represented as a sparse linear combination of bases.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=463" target="_blank">00:07:43.960</a></span> | <span class="t">So if you apply sparse coding to natural images, and this was originally has been a lot of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=473" target="_blank">00:07:53.040</a></span> | <span class="t">work developed at Stanford with Andrew Ng's group.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=476" target="_blank">00:07:56.120</a></span> | <span class="t">So if you apply sparse coding to take little patches of images and learn these bases, these</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=482" target="_blank">00:08:02.400</a></span> | <span class="t">dictionaries, this is how they look like.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=484" target="_blank">00:08:04.480</a></span> | <span class="t">And they look really nice in terms of finding edge-like structure.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=489" target="_blank">00:08:09.720</a></span> | <span class="t">So if given a new example, I can say, well, this new example can be written as a linear</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=494" target="_blank">00:08:14.420</a></span> | <span class="t">combination of a few of these bases.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=498" target="_blank">00:08:18.040</a></span> | <span class="t">And taking that representation, it turns out that particular representation, a sparse representation,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=503" target="_blank">00:08:23.640</a></span> | <span class="t">is quite useful as a feature representation of your data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=507" target="_blank">00:08:27.760</a></span> | <span class="t">So it's quite useful to have it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=509" target="_blank">00:08:29.680</a></span> | <span class="t">And in general, how do we fit these models?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=516" target="_blank">00:08:36.760</a></span> | <span class="t">Well, if I give you a whole bunch of image patches, but these don't necessarily have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=521" target="_blank">00:08:41.440</a></span> | <span class="t">to be image patches.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=522" target="_blank">00:08:42.520</a></span> | <span class="t">This could be little speech signals or any kind of data you're working with.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=527" target="_blank">00:08:47.920</a></span> | <span class="t">You'd want to learn a dictionary of bases.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=529" target="_blank">00:08:49.320</a></span> | <span class="t">You have to solve this optimization problem.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=533" target="_blank">00:08:53.200</a></span> | <span class="t">So the first term here, you can think of it as a reconstruction error, which is to say,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=537" target="_blank">00:08:57.480</a></span> | <span class="t">well, I take a linear combination of my bases.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=540" target="_blank">00:09:00.760</a></span> | <span class="t">I want them to match my data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=543" target="_blank">00:09:03.920</a></span> | <span class="t">And then there's a second term, which is, you can think of it as a sparse penalty term,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=548" target="_blank">00:09:08.160</a></span> | <span class="t">which essentially says, try to penalize my coefficients so that most of them are zero.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=555" target="_blank">00:09:15.640</a></span> | <span class="t">That way, every single data point can be written as just a linear combination, sparse linear</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=559" target="_blank">00:09:19.400</a></span> | <span class="t">combination of the bases.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=562" target="_blank">00:09:22.180</a></span> | <span class="t">And it turns out there is an easy optimization for doing that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=566" target="_blank">00:09:26.720</a></span> | <span class="t">If you fix your dictionary of bases, 5, 1 up to 5k, and you solve for the activations,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=574" target="_blank">00:09:34.200</a></span> | <span class="t">that becomes a standard lasso problem.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=576" target="_blank">00:09:36.840</a></span> | <span class="t">There's a lot of solvers for solving that particular problem.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=580" target="_blank">00:09:40.720</a></span> | <span class="t">That's a general, it's a lasso problem, which is fairly easy to optimize.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=587" target="_blank">00:09:47.440</a></span> | <span class="t">And then if you fix the activations and you optimize for dictionary of bases, then it's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=591" target="_blank">00:09:51.800</a></span> | <span class="t">a well-known quadratic programming problem.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=595" target="_blank">00:09:55.440</a></span> | <span class="t">Each problem is convex, so you can alternate between finding coefficients, finding bases,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=600" target="_blank">00:10:00.560</a></span> | <span class="t">and so forth, so you can optimize this function.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=602" target="_blank">00:10:02.840</a></span> | <span class="t">And there's been a lot of recent work in the last 10 years of doing these things online</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=607" target="_blank">00:10:07.800</a></span> | <span class="t">and doing it more efficiently and so forth.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=613" target="_blank">00:10:13.300</a></span> | <span class="t">At test time, given a new input or a new image patch, and given a set of learned bases, once</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=618" target="_blank">00:10:18.520</a></span> | <span class="t">you have your dictionary, you can then just solve a lasso problem to find the right coefficients.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=625" target="_blank">00:10:25.280</a></span> | <span class="t">So in this case, given a test sample or a test patch, you can find, well, it's written</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=630" target="_blank">00:10:30.480</a></span> | <span class="t">as a linear combination of a subset of the bases.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=635" target="_blank">00:10:35.840</a></span> | <span class="t">And it turns out, again, that that particular representation is very useful, particularly</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=639" target="_blank">00:10:39.680</a></span> | <span class="t">if you're interested in classifying what you see in images.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=643" target="_blank">00:10:43.180</a></span> | <span class="t">And this is done in a completely unsupervised way.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=645" target="_blank">00:10:45.560</a></span> | <span class="t">There is no class labels.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=646" target="_blank">00:10:46.560</a></span> | <span class="t">There is no specific supervisory signal that's here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=652" target="_blank">00:10:52.280</a></span> | <span class="t">So back in 2006, there was work done, again, at Stanford that basically showed a very interesting</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=660" target="_blank">00:11:00.240</a></span> | <span class="t">result.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=661" target="_blank">00:11:01.240</a></span> | <span class="t">So if I give you an input like this, and these are my learned bases, remember these little</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=665" target="_blank">00:11:05.040</a></span> | <span class="t">edges, what happens is that you just convolve these bases.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=669" target="_blank">00:11:09.480</a></span> | <span class="t">You can get these different feature maps, much like the feature maps that we've seen</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=673" target="_blank">00:11:13.220</a></span> | <span class="t">in convolutional neural networks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=675" target="_blank">00:11:15.440</a></span> | <span class="t">And then you take these feature maps, and you can just do a classification.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=680" target="_blank">00:11:20.000</a></span> | <span class="t">This was done on one of the older data sets, the Caltech 101, which is a data set that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=685" target="_blank">00:11:25.160</a></span> | <span class="t">predates ImageNet.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=687" target="_blank">00:11:27.880</a></span> | <span class="t">And if you look at some of the competing algorithms, if you do a simple logistic regression versus</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=695" target="_blank">00:11:35.240</a></span> | <span class="t">if you do PCA and then do logistic regression versus finding these features using sparse</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=701" target="_blank">00:11:41.400</a></span> | <span class="t">coding, you can get substantial improvements.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=704" target="_blank">00:11:44.960</a></span> | <span class="t">So that's, again, that's-- and you see sparse coding popping up in a lot of different areas,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=711" target="_blank">00:11:51.280</a></span> | <span class="t">not just in deep learning, but folks who are using-- looking at the medical imaging domain,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=717" target="_blank">00:11:57.240</a></span> | <span class="t">in neuroscience, these are very popular models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=720" target="_blank">00:12:00.000</a></span> | <span class="t">Because they're easy, they're easy to fit, they're easy to deal with.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=725" target="_blank">00:12:05.400</a></span> | <span class="t">So what's the interpretation of the sparse coding?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=729" target="_blank">00:12:09.280</a></span> | <span class="t">Well, let's look at this equation again.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=731" target="_blank">00:12:11.440</a></span> | <span class="t">And we can think of sparse coding as finding an overcomplete representation of your data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=737" target="_blank">00:12:17.880</a></span> | <span class="t">Now the encoding function, we can think of this encoding function, which is, well, I</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=743" target="_blank">00:12:23.160</a></span> | <span class="t">give you an input, find me the features or sparse coefficients or bases that make up</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=748" target="_blank">00:12:28.900</a></span> | <span class="t">my image.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=749" target="_blank">00:12:29.900</a></span> | <span class="t">We can think of encoding as an implicit and a very nonlinear function of x.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=753" target="_blank">00:12:33.720</a></span> | <span class="t">But it's an implicit function.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=755" target="_blank">00:12:35.120</a></span> | <span class="t">We don't really specify it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=756" target="_blank">00:12:36.920</a></span> | <span class="t">And the decoder, or the reconstruction, is just a simple linear function.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=762" target="_blank">00:12:42.400</a></span> | <span class="t">And it's very explicit.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=764" target="_blank">00:12:44.000</a></span> | <span class="t">You just take your coefficients and then multiply it by-- find the right basis and get back</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=772" target="_blank">00:12:52.240</a></span> | <span class="t">the image or the data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=776" target="_blank">00:12:56.420</a></span> | <span class="t">And that sort of flows naturally into the ideas of autoencoders.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=781" target="_blank">00:13:01.200</a></span> | <span class="t">The autoencoder is a general framework where if I give you an input data, let's say it's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=785" target="_blank">00:13:05.720</a></span> | <span class="t">an input image, you encode it, you get some representation, some feature representation,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=791" target="_blank">00:13:11.560</a></span> | <span class="t">and then you have a decoder given that representation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=794" target="_blank">00:13:14.360</a></span> | <span class="t">You're decoding it back into the image.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=796" target="_blank">00:13:16.880</a></span> | <span class="t">So you can think of encoder as a feedforward, bottom-up pass, much like in a convolutional</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=803" target="_blank">00:13:23.800</a></span> | <span class="t">neural network, given the image, you're doing a forward pass.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=807" target="_blank">00:13:27.200</a></span> | <span class="t">And then there is also feedback and generative or top-down pass.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=811" target="_blank">00:13:31.920</a></span> | <span class="t">And the features, you're reconstructing back the input image.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=815" target="_blank">00:13:35.880</a></span> | <span class="t">And the details of what's going inside the encoder, decoder, they matter a lot.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=820" target="_blank">00:13:40.480</a></span> | <span class="t">And obviously, you need some form of constraints.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=822" target="_blank">00:13:42.320</a></span> | <span class="t">You need some of constraints to avoid learning an identity.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=825" target="_blank">00:13:45.840</a></span> | <span class="t">Because if you don't put these constraints, what you could do is just take your input,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=830" target="_blank">00:13:50.600</a></span> | <span class="t">copy it to your features, and then reconstruct back.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=833" target="_blank">00:13:53.440</a></span> | <span class="t">And that would be a trivial solution.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=835" target="_blank">00:13:55.560</a></span> | <span class="t">So we need to introduce some additional constraints.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=839" target="_blank">00:13:59.740</a></span> | <span class="t">If you're dealing with binary features, if you want to extract binary features, for example,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=845" target="_blank">00:14:05.440</a></span> | <span class="t">I'm going to show you later why you'd want to do that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=847" target="_blank">00:14:07.920</a></span> | <span class="t">You can pass your encoder through sigmoid nonlinearity, much like in the neural network.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=853" target="_blank">00:14:13.920</a></span> | <span class="t">And then you have a linear decoder that reconstructs back the input.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=857" target="_blank">00:14:17.640</a></span> | <span class="t">And the way we optimize these little building blocks or these little blocks is we can just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=864" target="_blank">00:14:24.720</a></span> | <span class="t">have an encoder, which takes your input, takes a linear combination, passes it through some</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=870" target="_blank">00:14:30.520</a></span> | <span class="t">nonlinearity, the sigmoid nonlinearity.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=872" target="_blank">00:14:32.300</a></span> | <span class="t">It could be rectified linear units.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=874" target="_blank">00:14:34.180</a></span> | <span class="t">It could be 10H nonlinearity.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=876" target="_blank">00:14:36.220</a></span> | <span class="t">And then there is a decoder where you reconstruct back your original input.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=881" target="_blank">00:14:41.020</a></span> | <span class="t">So this is nothing more than a neural network with one hidden layer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=884" target="_blank">00:14:44.240</a></span> | <span class="t">And typically, that hidden layer would have a small dimensionality than the input.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=887" target="_blank">00:14:47.960</a></span> | <span class="t">So we can think of it as a bottleneck layer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=890" target="_blank">00:14:50.540</a></span> | <span class="t">We can determine the network parameters, the parameters of the encoder and the parameters</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=894" target="_blank">00:14:54.500</a></span> | <span class="t">of the decoder by writing down the reconstruction error.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=898" target="_blank">00:14:58.480</a></span> | <span class="t">And that's what the reconstruction error would look like.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=900" target="_blank">00:15:00.860</a></span> | <span class="t">Given the input, encode, decode, and make sure whatever you're decoding is as close</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=904" target="_blank">00:15:04.900</a></span> | <span class="t">as possible to the original input.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=908" target="_blank">00:15:08.060</a></span> | <span class="t">All right.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=909" target="_blank">00:15:09.060</a></span> | <span class="t">Then we can use backpropagation algorithm to train.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=914" target="_blank">00:15:14.140</a></span> | <span class="t">There is an interesting sort of relationship between autoencoders and principal component</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=918" target="_blank">00:15:18.940</a></span> | <span class="t">analysis.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=920" target="_blank">00:15:20.140</a></span> | <span class="t">Many of you have probably heard about PCA.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=922" target="_blank">00:15:22.400</a></span> | <span class="t">As a practitioner, if you're dealing with large data and you want to see what's going</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=926" target="_blank">00:15:26.180</a></span> | <span class="t">on, PCA is the first thing to use, much like logistic regression.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=932" target="_blank">00:15:32.460</a></span> | <span class="t">And the idea here is that if the parameters of encoder and decoder are shared and you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=936" target="_blank">00:15:36.780</a></span> | <span class="t">actually have the hidden layer, which is a linear layer, so you don't introduce any nonlinearities,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=942" target="_blank">00:15:42.180</a></span> | <span class="t">then it turns out that the latent space that the model will discover is going to be the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=946" target="_blank">00:15:46.940</a></span> | <span class="t">same space as the space discovered by PCA.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=949" target="_blank">00:15:49.780</a></span> | <span class="t">It effectively will collapse the principal component analysis, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=952" target="_blank">00:15:52.940</a></span> | <span class="t">We're doing PCA, which is sort of a nice connection because it basically says that autoencoders,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=960" target="_blank">00:16:00.100</a></span> | <span class="t">you can think of them as nonlinear extensions of PCA.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=962" target="_blank">00:16:02.700</a></span> | <span class="t">So you can learn a little richer features if you are using autoencoders.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=973" target="_blank">00:16:13.180</a></span> | <span class="t">So here's another model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=974" target="_blank">00:16:14.180</a></span> | <span class="t">If you're dealing with binary input, sometimes we're dealing with like MNIST, for example.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=979" target="_blank">00:16:19.140</a></span> | <span class="t">Again, your encoder and decoder could use sigmoid nonlinearities.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=982" target="_blank">00:16:22.900</a></span> | <span class="t">So given an input, you extract some binary features.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=985" target="_blank">00:16:25.020</a></span> | <span class="t">Give binary features, you reconstruct back the binary input.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=989" target="_blank">00:16:29.100</a></span> | <span class="t">And that actually relates to a model called the restricted Boltz machine, something that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=993" target="_blank">00:16:33.860</a></span> | <span class="t">I'm going to tell you about later in the talk.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=997" target="_blank">00:16:37.860</a></span> | <span class="t">There's also other classes of models where you can say, well, I can also introduce some</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1002" target="_blank">00:16:42.100</a></span> | <span class="t">sparsity, much like in sparse coding, to say that I need to constrain my latent features</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1007" target="_blank">00:16:47.820</a></span> | <span class="t">or my latent space to be sparse.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1010" target="_blank">00:16:50.420</a></span> | <span class="t">And that actually allows you to learn quite reasonable features, nice features.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1016" target="_blank">00:16:56.780</a></span> | <span class="t">Here's one particular model called predictive sparse decomposition, where you effectively,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1022" target="_blank">00:17:02.300</a></span> | <span class="t">if you look at the first part of the equation here, the decoder part, that pretty much looks</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1026" target="_blank">00:17:06.580</a></span> | <span class="t">like a sparse coding model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1029" target="_blank">00:17:09.140</a></span> | <span class="t">But in addition, you have an encoding part that essentially says train an encoder such</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1034" target="_blank">00:17:14.380</a></span> | <span class="t">that it actually approximates what my latent code should be.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1039" target="_blank">00:17:19.980</a></span> | <span class="t">So effectively, you can think of this model as there is an encoder, there is a decoder,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1043" target="_blank">00:17:23.700</a></span> | <span class="t">but then you put the sparsity constraint on your latent representation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1046" target="_blank">00:17:26.300</a></span> | <span class="t">And you can optimize for that model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1052" target="_blank">00:17:32.400</a></span> | <span class="t">And obviously, the other thing that we've been doing in the last seven, eight, and ten</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1057" target="_blank">00:17:37.340</a></span> | <span class="t">years is, well, what you can do is you can actually stack these things together.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1062" target="_blank">00:17:42.060</a></span> | <span class="t">So you can learn low-level features, try to learn high-level features, and so forth.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1067" target="_blank">00:17:47.220</a></span> | <span class="t">So you're just building these blocks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1070" target="_blank">00:17:50.900</a></span> | <span class="t">And perhaps at the top level, if you're trying to solve a classification problem, you can</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1074" target="_blank">00:17:54.620</a></span> | <span class="t">do that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1077" target="_blank">00:17:57.140</a></span> | <span class="t">And this is sometimes known as a greedy layer-wise learning.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1080" target="_blank">00:18:00.900</a></span> | <span class="t">And this is sometimes useful whenever you have lots and lots of unlabeled data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1085" target="_blank">00:18:05.460</a></span> | <span class="t">And when you have a little labeled data, a small sample of labeled data, typically these</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1090" target="_blank">00:18:10.340</a></span> | <span class="t">models help you find meaningful representations such that you don't need a lot of labeled</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1095" target="_blank">00:18:15.620</a></span> | <span class="t">data to solve a particular task that you're trying to solve.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1099" target="_blank">00:18:19.420</a></span> | <span class="t">And this is, again, you can remove the decoding part, and then you end up with a standard</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1103" target="_blank">00:18:23.900</a></span> | <span class="t">or a convolutional architecture.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1105" target="_blank">00:18:25.660</a></span> | <span class="t">Again, your encoder and decoder could be convolutional.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1110" target="_blank">00:18:30.020</a></span> | <span class="t">And it depends on what problem you're tackling.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1114" target="_blank">00:18:34.060</a></span> | <span class="t">And typically, you can stack these things together and optimize for a particular task</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1118" target="_blank">00:18:38.740</a></span> | <span class="t">that you're trying to solve.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1123" target="_blank">00:18:43.100</a></span> | <span class="t">Here's an example of-- just wanted to show you some examples, some early examples.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1126" target="_blank">00:18:46.940</a></span> | <span class="t">Back in 2006, this was a way of trying to build these nonlinear autoencoders.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1133" target="_blank">00:18:53.900</a></span> | <span class="t">And you can sort of pre-train these models using restricted-bolt machines or autoencoders</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1138" target="_blank">00:18:58.180</a></span> | <span class="t">generally.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1139" target="_blank">00:18:59.700</a></span> | <span class="t">And then you can stitch them together into this deep autoencoder and backpropagate through</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1145" target="_blank">00:19:05.900</a></span> | <span class="t">reconstruction loss.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1148" target="_blank">00:19:08.460</a></span> | <span class="t">One thing I want to point out is that-- here's one particular example.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1152" target="_blank">00:19:12.740</a></span> | <span class="t">The top row, I show you real faces.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1155" target="_blank">00:19:15.780</a></span> | <span class="t">The second row, you're seeing faces reconstructed from a bottleneck of 30-dimensional real-value</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1162" target="_blank">00:19:22.420</a></span> | <span class="t">bottlenecks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1163" target="_blank">00:19:23.420</a></span> | <span class="t">You can think of it as just a compression mechanism.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1165" target="_blank">00:19:25.580</a></span> | <span class="t">Given the data, high-dimensional data, you're compressing it down to 30-dimensional code.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1170" target="_blank">00:19:30.000</a></span> | <span class="t">And then from that 30-dimensional code, you're reconstructing back the original data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1174" target="_blank">00:19:34.260</a></span> | <span class="t">So if you look at the first row, this is the data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1176" target="_blank">00:19:36.260</a></span> | <span class="t">The second row shows you reconstructed data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1179" target="_blank">00:19:39.420</a></span> | <span class="t">And the last row shows you PCA solution.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1183" target="_blank">00:19:43.060</a></span> | <span class="t">One thing I want to point out is that the solution here, you have a much sharper representation,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1187" target="_blank">00:19:47.940</a></span> | <span class="t">which means that it's capturing a little bit more structure in the data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1190" target="_blank">00:19:50.780</a></span> | <span class="t">It's also kind of interesting to see that sometimes these models tend to-- how should</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1195" target="_blank">00:19:55.820</a></span> | <span class="t">I say it?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1196" target="_blank">00:19:56.820</a></span> | <span class="t">They tend to regularize your data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1198" target="_blank">00:19:58.780</a></span> | <span class="t">For example, if you see this person with glasses, removes the glasses.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1202" target="_blank">00:20:02.580</a></span> | <span class="t">And that generally has to do with the fact that there is only one person with glasses.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1205" target="_blank">00:20:05.820</a></span> | <span class="t">So the model just basically says, that's noise.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1207" target="_blank">00:20:07.820</a></span> | <span class="t">Get rid of it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1208" target="_blank">00:20:08.820</a></span> | <span class="t">Or it sort of gets rid of mustaches.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1211" target="_blank">00:20:11.020</a></span> | <span class="t">Like if you see this, there's no mustache.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1213" target="_blank">00:20:13.340</a></span> | <span class="t">And then again, that has to do with the fact that there's enough capacity.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1216" target="_blank">00:20:16.300</a></span> | <span class="t">So the model might think that that's just a noise.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1220" target="_blank">00:20:20.860</a></span> | <span class="t">And if you're dealing with text type of data, this was done using a Reuters data set.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1227" target="_blank">00:20:27.900</a></span> | <span class="t">You have about 800,000 stories.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1230" target="_blank">00:20:30.780</a></span> | <span class="t">You take bag of words representation, something very simple.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1233" target="_blank">00:20:33.020</a></span> | <span class="t">You can press it down to two-dimensional space.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1234" target="_blank">00:20:34.980</a></span> | <span class="t">And then you see what that space looks like.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1237" target="_blank">00:20:37.940</a></span> | <span class="t">And I always like to joke that the model basically discovers that European community economic</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1243" target="_blank">00:20:43.180</a></span> | <span class="t">policies are just next to disasters and accidents.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1246" target="_blank">00:20:46.740</a></span> | <span class="t">This was back in-- I think the data was collected in '96.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1250" target="_blank">00:20:50.780</a></span> | <span class="t">I think today it's probably going to become closer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1255" target="_blank">00:20:55.980</a></span> | <span class="t">But again, this is just a way-- typically, autoencoder is a way of compression or trying</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1260" target="_blank">00:21:00.780</a></span> | <span class="t">to do dimensionality reduction.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1262" target="_blank">00:21:02.460</a></span> | <span class="t">But we'll see later that they don't have to be.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1265" target="_blank">00:21:05.820</a></span> | <span class="t">There's another class of algorithm called semantic hashing, which is to say, well, what</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1269" target="_blank">00:21:09.860</a></span> | <span class="t">if you take your data and compress it down to binary representation?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1274" target="_blank">00:21:14.540</a></span> | <span class="t">Wouldn't that be nice?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1276" target="_blank">00:21:16.180</a></span> | <span class="t">Because if you have binary representation, you can search in the binary space very efficiently.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1282" target="_blank">00:21:22.540</a></span> | <span class="t">In fact, if you can compress your data down to 20 dimension, 20-dimensional binary code,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1288" target="_blank">00:21:28.460</a></span> | <span class="t">2 to the 20 is about 4 gigabytes.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1290" target="_blank">00:21:30.460</a></span> | <span class="t">So you can just store everything in memory.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1293" target="_blank">00:21:33.980</a></span> | <span class="t">And you can look at the-- just do memory lookups without actually doing any search at all.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1302" target="_blank">00:21:42.020</a></span> | <span class="t">So this sort of representation sometimes have been used successfully in computer vision,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1306" target="_blank">00:21:46.260</a></span> | <span class="t">where you take your images, and then you learn these binary representations, 30-dimensional</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1312" target="_blank">00:21:52.340</a></span> | <span class="t">codes, 200-dimensional codes.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1315" target="_blank">00:21:55.540</a></span> | <span class="t">And it turns out it's very efficient to search through large volumes of data using binary</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1320" target="_blank">00:22:00.380</a></span> | <span class="t">representation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1321" target="_blank">00:22:01.380</a></span> | <span class="t">So you can-- it takes a fraction of a millisecond to retrieve images from a set of millions</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1327" target="_blank">00:22:07.420</a></span> | <span class="t">and millions of images.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1329" target="_blank">00:22:09.700</a></span> | <span class="t">And again, this is also an active area of research right now, because people are trying</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1333" target="_blank">00:22:13.240</a></span> | <span class="t">to figure out, we have these large databases.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1335" target="_blank">00:22:15.460</a></span> | <span class="t">How can you search through them efficiently?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1337" target="_blank">00:22:17.220</a></span> | <span class="t">And learning a semantic hashing function that maps your data to the binary representation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1342" target="_blank">00:22:22.520</a></span> | <span class="t">turns out to be quite useful.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1345" target="_blank">00:22:25.540</a></span> | <span class="t">OK, now let's step back a little bit and say, let's now look at generative models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1351" target="_blank">00:22:31.500</a></span> | <span class="t">Let's look at probabilistic models and how different they are.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1354" target="_blank">00:22:34.420</a></span> | <span class="t">And I'm going to show you some examples of where they're applicable.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1359" target="_blank">00:22:39.420</a></span> | <span class="t">Here's one example of a simple model trying to learn a distribution of these handwritten</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1366" target="_blank">00:22:46.260</a></span> | <span class="t">characters.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1367" target="_blank">00:22:47.260</a></span> | <span class="t">So we have Sanskrit.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1369" target="_blank">00:22:49.460</a></span> | <span class="t">We have Arabic.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1370" target="_blank">00:22:50.460</a></span> | <span class="t">We have Cyrillic.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1373" target="_blank">00:22:53.180</a></span> | <span class="t">And now we can build a model that says, well, can you actually generate me what a Sanskrit</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1378" target="_blank">00:22:58.700</a></span> | <span class="t">should look like?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1380" target="_blank">00:23:00.220</a></span> | <span class="t">The flickering you see at the top, these are neurons.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1382" target="_blank">00:23:02.780</a></span> | <span class="t">You can think of them as neurons firing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1385" target="_blank">00:23:05.300</a></span> | <span class="t">And what you're seeing at the bottom is you're seeing what the model generates, what it believes</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1389" target="_blank">00:23:09.660</a></span> | <span class="t">Sanskrit should look like.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1391" target="_blank">00:23:11.140</a></span> | <span class="t">So in some sense, when you think about generative models, you think about models that can generate</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1395" target="_blank">00:23:15.860</a></span> | <span class="t">or they can sample the distribution or they can sample the data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1401" target="_blank">00:23:21.900</a></span> | <span class="t">This is a fairly simple model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1403" target="_blank">00:23:23.180</a></span> | <span class="t">We have about 25,000 characters coming from 50 different alphabets around the world.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1408" target="_blank">00:23:28.380</a></span> | <span class="t">You have about 2 million parameters.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1409" target="_blank">00:23:29.660</a></span> | <span class="t">This is one of the older models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1411" target="_blank">00:23:31.860</a></span> | <span class="t">But this is what the model believes Sanskrit should look like.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1415" target="_blank">00:23:35.100</a></span> | <span class="t">And I think that I've asked a couple of people to say that, does that really look like Sanskrit?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1420" target="_blank">00:23:40.380</a></span> | <span class="t">Yes.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1421" target="_blank">00:23:41.380</a></span> | <span class="t">OK, great.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1423" target="_blank">00:23:43.140</a></span> | <span class="t">Which can mean two things.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1425" target="_blank">00:23:45.020</a></span> | <span class="t">It can mean that the model is actually generalizing or the model is overfitting, meaning that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1430" target="_blank">00:23:50.700</a></span> | <span class="t">it's just memorizing what the training data looks like.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1432" target="_blank">00:23:52.620</a></span> | <span class="t">And I'm just showing you examples from the training data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1435" target="_blank">00:23:55.380</a></span> | <span class="t">We'll come back to that point as we go through the talk.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1439" target="_blank">00:23:59.820</a></span> | <span class="t">You can also do conditional simulation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1442" target="_blank">00:24:02.180</a></span> | <span class="t">Given half of the image, can you complete the remaining half?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1446" target="_blank">00:24:06.020</a></span> | <span class="t">And more recently, there's been a lot of advances, especially in the last couple of years, for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1452" target="_blank">00:24:12.140</a></span> | <span class="t">the conditional generations.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1453" target="_blank">00:24:13.580</a></span> | <span class="t">And it's pretty amazing what you can do in terms of in-painting, given half of the image,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1459" target="_blank">00:24:19.020</a></span> | <span class="t">what the other half of the image should look like.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1461" target="_blank">00:24:21.300</a></span> | <span class="t">This is sort of a simple example, but it does show you that it's trying to be consistent</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1465" target="_blank">00:24:25.820</a></span> | <span class="t">with what different strokes look like.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1469" target="_blank">00:24:29.640</a></span> | <span class="t">So why is it so difficult?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1472" target="_blank">00:24:32.820</a></span> | <span class="t">In the space of so-called undirected graphical models of Bolsom machines, the difficulty</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1476" target="_blank">00:24:36.820</a></span> | <span class="t">really comes from the following fact.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1478" target="_blank">00:24:38.680</a></span> | <span class="t">If I show you this image, which is a 28 by 28 image, it's a binary image.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1483" target="_blank">00:24:43.560</a></span> | <span class="t">So some pixels are on, some pixels are off.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1486" target="_blank">00:24:46.060</a></span> | <span class="t">There are 2 to the 28 by 28 possible images.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1489" target="_blank">00:24:49.620</a></span> | <span class="t">So in fact, there are 2 to the 784 possible configurations.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1493" target="_blank">00:24:53.580</a></span> | <span class="t">And that space is exponential.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1496" target="_blank">00:24:56.000</a></span> | <span class="t">So how can you build models that figure out-- in the space of characters, there's only a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1500" target="_blank">00:25:00.620</a></span> | <span class="t">little tiny subspace in that space.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1503" target="_blank">00:25:03.680</a></span> | <span class="t">If you start generating 200 by 200 images, that space is huge.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1511" target="_blank">00:25:11.580</a></span> | <span class="t">In the space of real images, it's really, really tiny.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1515" target="_blank">00:25:15.120</a></span> | <span class="t">So how do you find that space?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1516" target="_blank">00:25:16.420</a></span> | <span class="t">How do you generalize to new images?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1518" target="_blank">00:25:18.480</a></span> | <span class="t">That's a very difficult question in general to answer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1523" target="_blank">00:25:23.640</a></span> | <span class="t">One class of models is so-called fully observed models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1527" target="_blank">00:25:27.940</a></span> | <span class="t">There's been a stream of learning generative models that are tractable.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1533" target="_blank">00:25:33.000</a></span> | <span class="t">And they have very nice properties, like you can compute the probabilities, you can do</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1536" target="_blank">00:25:36.780</a></span> | <span class="t">maximum likelihood estimation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1538" target="_blank">00:25:38.760</a></span> | <span class="t">Here's one example where I can, if I try to model the image, I can write it down as taking</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1543" target="_blank">00:25:43.840</a></span> | <span class="t">the first pixel, modeling the first pixel, then modeling the second pixel, giving the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1547" target="_blank">00:25:47.280</a></span> | <span class="t">first pixel, and just writing it down in terms of the conditional probabilities.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1553" target="_blank">00:25:53.960</a></span> | <span class="t">And each conditional probability can take a very complicated form.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1556" target="_blank">00:25:56.880</a></span> | <span class="t">It could be a complicated neural network.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1563" target="_blank">00:26:03.200</a></span> | <span class="t">So there's been a number of successful models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1568" target="_blank">00:26:08.280</a></span> | <span class="t">One of the early models called Neural Autoregressive Density Estimator, actually developed by Hugo,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1574" target="_blank">00:26:14.880</a></span> | <span class="t">real valid extension of these models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1576" target="_blank">00:26:16.520</a></span> | <span class="t">And more recently, we start seeing these flavors of models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1579" target="_blank">00:26:19.680</a></span> | <span class="t">There were a couple of papers popped up, actually this year, from DeepMind, where they make</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1587" target="_blank">00:26:27.680</a></span> | <span class="t">these conditionals to be sophisticated RNNs, LSTMs, or convolutional models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1592" target="_blank">00:26:32.800</a></span> | <span class="t">And they can actually generate remarkable images.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1595" target="_blank">00:26:35.600</a></span> | <span class="t">And so this is just a pixel CNN generating, I guess, elephants.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1599" target="_blank">00:26:39.360</a></span> | <span class="t">Yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1600" target="_blank">00:26:40.360</a></span> | <span class="t">And actually, it looks pretty interesting.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1605" target="_blank">00:26:45.520</a></span> | <span class="t">The drawback of these models is that we yet have to see how good of representations these</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1609" target="_blank">00:26:49.480</a></span> | <span class="t">models are learning, so that we can use these representations for other tasks, like classifying</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1614" target="_blank">00:26:54.320</a></span> | <span class="t">images or find similar images and such.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1619" target="_blank">00:26:59.080</a></span> | <span class="t">Now let me jump into a class of models called Restricted Bulse Machines.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1623" target="_blank">00:27:03.680</a></span> | <span class="t">So this is the class of models where we're actually trying to learn some latent structure,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1627" target="_blank">00:27:07.520</a></span> | <span class="t">some latent representation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1630" target="_blank">00:27:10.000</a></span> | <span class="t">These models belong to the class of so-called graphical models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1632" target="_blank">00:27:12.480</a></span> | <span class="t">And graphical models are a very powerful framework for representing dependency structure between</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1637" target="_blank">00:27:17.260</a></span> | <span class="t">random variables.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1639" target="_blank">00:27:19.320</a></span> | <span class="t">This is an example where we have-- you can think of this particular model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1644" target="_blank">00:27:24.600</a></span> | <span class="t">You have some pixels.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1645" target="_blank">00:27:25.600</a></span> | <span class="t">These are stochastic binary, so-called visible variables.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1648" target="_blank">00:27:28.480</a></span> | <span class="t">You can think of pixels in your image.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1650" target="_blank">00:27:30.680</a></span> | <span class="t">And you have stochastic binary hidden variables.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1652" target="_blank">00:27:32.480</a></span> | <span class="t">You can think of them as feature detectors, so detecting certain patterns that you see</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1655" target="_blank">00:27:35.600</a></span> | <span class="t">in the data, much like sparse coding models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1658" target="_blank">00:27:38.040</a></span> | <span class="t">This has a bipartite structure.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1660" target="_blank">00:27:40.280</a></span> | <span class="t">You can write down the probability, the joint distribution over all of these variables.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1665" target="_blank">00:27:45.760</a></span> | <span class="t">You sort of have pairwise term.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1667" target="_blank">00:27:47.120</a></span> | <span class="t">You have unitary term.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1668" target="_blank">00:27:48.120</a></span> | <span class="t">But it's not really important what they look like.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1669" target="_blank">00:27:49.960</a></span> | <span class="t">The important thing here is that if I look at this conditional probability of the data</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1673" target="_blank">00:27:53.920</a></span> | <span class="t">given the features, I can actually write down explicitly what it looks like.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1678" target="_blank">00:27:58.600</a></span> | <span class="t">What does that mean?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1679" target="_blank">00:27:59.600</a></span> | <span class="t">That basically means that if you tell me what features you see in the image, I can generate</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1683" target="_blank">00:28:03.480</a></span> | <span class="t">the data for you, or I can generate the corresponding input.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1688" target="_blank">00:28:08.320</a></span> | <span class="t">In terms of learning features, so what do these models learn?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1691" target="_blank">00:28:11.960</a></span> | <span class="t">They sort of learn something similar that we've seen in sparse coding.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1696" target="_blank">00:28:16.240</a></span> | <span class="t">And so these classes of models are very similar to each other.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1700" target="_blank">00:28:20.120</a></span> | <span class="t">So given a new image, I can say, well, this new image is made up by some combination of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1704" target="_blank">00:28:24.960</a></span> | <span class="t">these learned weights or these learned bases.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1708" target="_blank">00:28:28.480</a></span> | <span class="t">And the numbers here are given by the probabilities that each particular edge is present in the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1712" target="_blank">00:28:32.920</a></span> | <span class="t">data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1715" target="_blank">00:28:35.080</a></span> | <span class="t">In terms of how we learn these models, one thing I want to make-- another point I should</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1721" target="_blank">00:28:41.200</a></span> | <span class="t">make here is that given an input, I can actually quickly infer what features I'm seeing in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1727" target="_blank">00:28:47.720</a></span> | <span class="t">the image.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1728" target="_blank">00:28:48.720</a></span> | <span class="t">So that operation is very easy to do, unlike in sparse coding models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1732" target="_blank">00:28:52.640</a></span> | <span class="t">It's a little bit more closer to an autoencoder.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1734" target="_blank">00:28:54.300</a></span> | <span class="t">Given the data, I can actually tell you what features are present in my input, which is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1738" target="_blank">00:28:58.480</a></span> | <span class="t">very important for things like information retrieval or classifying images, because you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1742" target="_blank">00:29:02.560</a></span> | <span class="t">need to do it fast.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1745" target="_blank">00:29:05.280</a></span> | <span class="t">How do we learn these models?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1746" target="_blank">00:29:06.280</a></span> | <span class="t">Let me just give you an intuition, maybe a little bit of math behind how we learn these</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1751" target="_blank">00:29:11.000</a></span> | <span class="t">models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1752" target="_blank">00:29:12.000</a></span> | <span class="t">If I give you a set of training examples, and I want to learn model parameters, I can</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1756" target="_blank">00:29:16.520</a></span> | <span class="t">maximize the log-likelihood objective.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1758" target="_blank">00:29:18.840</a></span> | <span class="t">And you've probably seen that in these tutorials, the maximum likelihood objective is essentially</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1764" target="_blank">00:29:24.280</a></span> | <span class="t">nothing more than saying, I want to make sure that the probability of observing these images</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1769" target="_blank">00:29:29.680</a></span> | <span class="t">is as high as possible.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1771" target="_blank">00:29:31.400</a></span> | <span class="t">So finding the parameters of the probability of observing what I'm seeing is high.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1776" target="_blank">00:29:36.480</a></span> | <span class="t">And that's why you're maximizing the likelihood objective for the log of the likelihood objective,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1781" target="_blank">00:29:41.960</a></span> | <span class="t">which is take a product into the sum.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1784" target="_blank">00:29:44.960</a></span> | <span class="t">You take the derivative.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1785" target="_blank">00:29:45.960</a></span> | <span class="t">There's a little bit of algebra.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1787" target="_blank">00:29:47.000</a></span> | <span class="t">I promise you it's not very difficult.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1789" target="_blank">00:29:49.640</a></span> | <span class="t">It's like second-year college algebra.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1794" target="_blank">00:29:54.140</a></span> | <span class="t">You differentiate.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1795" target="_blank">00:29:55.140</a></span> | <span class="t">And you basically have this learning rule, which is the difference between two terms.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1801" target="_blank">00:30:01.800</a></span> | <span class="t">The first term, you can think of it as looking at sufficient statistics, so-called sufficient</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1807" target="_blank">00:30:07.360</a></span> | <span class="t">statistics driven by the data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1809" target="_blank">00:30:09.700</a></span> | <span class="t">And the second term is the sufficient statistics driven by the model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1814" target="_blank">00:30:14.120</a></span> | <span class="t">Maybe I can parse it out.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1815" target="_blank">00:30:15.240</a></span> | <span class="t">What does that mean?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1816" target="_blank">00:30:16.240</a></span> | <span class="t">Intuitively, what that means is that you look at the correlations you see in the data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1821" target="_blank">00:30:21.720</a></span> | <span class="t">And then you look at the correlations that the model is telling you it should be.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1825" target="_blank">00:30:25.800</a></span> | <span class="t">And you're trying to match the two.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1828" target="_blank">00:30:28.160</a></span> | <span class="t">That's what the learning is trying to do.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1830" target="_blank">00:30:30.560</a></span> | <span class="t">It's trying to match the correlations that you see in the data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1834" target="_blank">00:30:34.280</a></span> | <span class="t">So the model is actually respecting the statistics that you see in the data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1838" target="_blank">00:30:38.440</a></span> | <span class="t">But it turns out that the second term is very difficult to compute.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1841" target="_blank">00:30:41.380</a></span> | <span class="t">And it's precisely because the space of all possible images is so high dimensional that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1846" target="_blank">00:30:46.640</a></span> | <span class="t">you need to figure out or use some kind of approximate learning algorithms to do that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1852" target="_blank">00:30:52.080</a></span> | <span class="t">So you have these difference between these two terms.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1854" target="_blank">00:30:54.000</a></span> | <span class="t">The first term is easy to compute, it turns out, because of a particular structure of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1857" target="_blank">00:30:57.280</a></span> | <span class="t">the model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1858" target="_blank">00:30:58.280</a></span> | <span class="t">And we can actually do it explicitly.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1862" target="_blank">00:31:02.560</a></span> | <span class="t">The second term is the difficult one to compute.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1865" target="_blank">00:31:05.320</a></span> | <span class="t">So it sort of requires summing over all possible configurations, all possible images that you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1871" target="_blank">00:31:11.680</a></span> | <span class="t">could possibly see.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1873" target="_blank">00:31:13.600</a></span> | <span class="t">So this term is intractable.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1875" target="_blank">00:31:15.880</a></span> | <span class="t">And what a lot of different algorithms are doing-- and we'll see that over and over again--</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1880" target="_blank">00:31:20.320</a></span> | <span class="t">is using so-called Monte Carlo sampling, or Markov chain Monte Carlo sampling, or Monte</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1884" target="_blank">00:31:24.600</a></span> | <span class="t">Carlo estimation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1886" target="_blank">00:31:26.680</a></span> | <span class="t">So let me give you an intuition of what this term is doing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1889" target="_blank">00:31:29.160</a></span> | <span class="t">And that's a general trick for approximating exponential sums.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1893" target="_blank">00:31:33.760</a></span> | <span class="t">There's a whole subfield in statistics that's basically dedicated to how do we approximate</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1902" target="_blank">00:31:42.520</a></span> | <span class="t">exponential sums.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1903" target="_blank">00:31:43.600</a></span> | <span class="t">In fact, if you could do that, if you could solve that problem, you could solve a lot</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1906" target="_blank">00:31:46.680</a></span> | <span class="t">of problems in machine learning.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1910" target="_blank">00:31:50.160</a></span> | <span class="t">And the idea is very simple, actually.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1912" target="_blank">00:31:52.080</a></span> | <span class="t">The idea is to say, well, you're going to be replacing the average by sampling.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1918" target="_blank">00:31:58.000</a></span> | <span class="t">And there's something that's called Gibbs sampling, Markov chain Monte Carlo, which</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1922" target="_blank">00:32:02.040</a></span> | <span class="t">essentially does something very simple.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1924" target="_blank">00:32:04.200</a></span> | <span class="t">It basically says, well, start with the data, sample the states of the latent variables,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1930" target="_blank">00:32:10.560</a></span> | <span class="t">sample the data, sample the states of the latent data, sample the data from these conditional</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1933" target="_blank">00:32:13.880</a></span> | <span class="t">distributions, something that you can compute explicitly.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1937" target="_blank">00:32:17.440</a></span> | <span class="t">And that's a general trick.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1939" target="_blank">00:32:19.760</a></span> | <span class="t">Much like in sparse coding, we're optimizing for the basis when we're optimizing for the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1943" target="_blank">00:32:23.680</a></span> | <span class="t">coefficients.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1944" target="_blank">00:32:24.680</a></span> | <span class="t">Here, you're inferring the coefficients, then you're inferring what the data should look</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1948" target="_blank">00:32:28.960</a></span> | <span class="t">like and so forth.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1950" target="_blank">00:32:30.760</a></span> | <span class="t">And then you can just run a Markov chain and approximate this exponential sum.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1958" target="_blank">00:32:38.400</a></span> | <span class="t">So you start with the data, you sample the states of the hidden variables, you resample</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1962" target="_blank">00:32:42.560</a></span> | <span class="t">the data and so forth.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1964" target="_blank">00:32:44.280</a></span> | <span class="t">And the only problem with a lot of these methods is that you need to run them up to infinity</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1972" target="_blank">00:32:52.120</a></span> | <span class="t">to guarantee that you're getting the right thing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1975" target="_blank">00:32:55.620</a></span> | <span class="t">And so obviously, you will never run them infinite.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1980" target="_blank">00:33:00.640</a></span> | <span class="t">You don't have time to do that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1982" target="_blank">00:33:02.120</a></span> | <span class="t">So there's a very clever algorithm, a contrastive divergent algorithm that was developed by</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1986" target="_blank">00:33:06.840</a></span> | <span class="t">Hinton back in 2002.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1989" target="_blank">00:33:09.040</a></span> | <span class="t">And it was very clever.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1990" target="_blank">00:33:10.400</a></span> | <span class="t">It basically said, well, instead of running this thing up to infinity, run it for one</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1994" target="_blank">00:33:14.520</a></span> | <span class="t">step.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=1998" target="_blank">00:33:18.600</a></span> | <span class="t">And so you're just running it for one step.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2000" target="_blank">00:33:20.360</a></span> | <span class="t">You start with a training vector, you update the hidden units, you update all the visible</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2005" target="_blank">00:33:25.760</a></span> | <span class="t">units again.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2006" target="_blank">00:33:26.760</a></span> | <span class="t">So that's your reconstruction.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2007" target="_blank">00:33:27.960</a></span> | <span class="t">Much like in autoencoder, you reconstruct your data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2011" target="_blank">00:33:31.120</a></span> | <span class="t">You update the hidden units again, and then you just update the model parameters, which</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2014" target="_blank">00:33:34.440</a></span> | <span class="t">is just looking at empirically the statistics between the data and the model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2019" target="_blank">00:33:39.920</a></span> | <span class="t">Very similar to what the autoencoder is doing, but slight, slight differences.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2024" target="_blank">00:33:44.640</a></span> | <span class="t">And implementation is basically takes about 10 lines of MATLAB code.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2028" target="_blank">00:33:48.840</a></span> | <span class="t">I suspect it's going to be two lines in TensorFlow, although I don't think TensorFlow folks implemented</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2034" target="_blank">00:33:54.360</a></span> | <span class="t">Boltzmann machines yet.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2036" target="_blank">00:33:56.320</a></span> | <span class="t">That would be my request.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2040" target="_blank">00:34:00.360</a></span> | <span class="t">But you can extend these models to dealing with real value data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2044" target="_blank">00:34:04.640</a></span> | <span class="t">So whenever you're dealing with images, for example.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2046" target="_blank">00:34:06.840</a></span> | <span class="t">And it's just a little change to the definition of the model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2051" target="_blank">00:34:11.400</a></span> | <span class="t">And your conditional probabilities here are just going to be a bunch of Gaussians.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2054" target="_blank">00:34:14.760</a></span> | <span class="t">So that basically means that given the features, sample me the space of images, and I can sample</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2060" target="_blank">00:34:20.000</a></span> | <span class="t">you, give you real, real valued images.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2063" target="_blank">00:34:23.520</a></span> | <span class="t">The structure of the model remains the same.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2065" target="_blank">00:34:25.840</a></span> | <span class="t">If you train this model on these images, you tend to find edges, something similar, again,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2073" target="_blank">00:34:33.160</a></span> | <span class="t">to what you'd see in sparse coding, in ICA, independent component analysis model, autoencoders</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2078" target="_blank">00:34:38.040</a></span> | <span class="t">and such.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2079" target="_blank">00:34:39.640</a></span> | <span class="t">And again, you can say, well, every single image is made up by some linear combination</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2083" target="_blank">00:34:43.980</a></span> | <span class="t">of these basis functions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2085" target="_blank">00:34:45.800</a></span> | <span class="t">You can also extend these models to dealing with count data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2088" target="_blank">00:34:48.840</a></span> | <span class="t">If you're dealing with documents, in this case, again, a slight change to the model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2095" target="_blank">00:34:55.360</a></span> | <span class="t">K here denotes your vocabulary size.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2098" target="_blank">00:34:58.560</a></span> | <span class="t">And D here denotes number of words that you're seeing in your document.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2103" target="_blank">00:35:03.120</a></span> | <span class="t">It's a bag of words representation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2105" target="_blank">00:35:05.600</a></span> | <span class="t">And the conditional here is given by so-called softmax distribution, much like what you've</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2109" target="_blank">00:35:09.040</a></span> | <span class="t">seen in the previous classes, when the distribution of possible words.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2115" target="_blank">00:35:15.920</a></span> | <span class="t">And the parameters here, Ws, you can think of them as something similar to what word</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2120" target="_blank">00:35:20.840</a></span> | <span class="t">to vacuum bedding would do.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2124" target="_blank">00:35:24.200</a></span> | <span class="t">And so if you apply it to, again, some of data sets, you tend to find reasonable features.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2131" target="_blank">00:35:31.760</a></span> | <span class="t">So you tend to find features about Russia, about US, about computers, and so forth.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2137" target="_blank">00:35:37.320</a></span> | <span class="t">So much like you found these representations, little edges, every image is made up by some</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2142" target="_blank">00:35:42.280</a></span> | <span class="t">combination of these edges.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2145" target="_blank">00:35:45.000</a></span> | <span class="t">In case of documents or web pages, you're saying it's the same thing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2149" target="_blank">00:35:49.280</a></span> | <span class="t">It's just made up some linear combination of these learned topics.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2153" target="_blank">00:35:53.200</a></span> | <span class="t">Every single document is made up by some combination of these topics.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2157" target="_blank">00:35:57.080</a></span> | <span class="t">You can also look at one-step reconstruction.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2159" target="_blank">00:35:59.240</a></span> | <span class="t">So you can basically say, well, how can I find similarity between the words?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2163" target="_blank">00:36:03.080</a></span> | <span class="t">So if I show you chocolate cake and further states of hidden units, and then I reconstruct</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2167" target="_blank">00:36:07.960</a></span> | <span class="t">back the distribution of possible words, it tells me chocolate cake, cake chocolate sweet</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2173" target="_blank">00:36:13.760</a></span> | <span class="t">dessert cupcake food sugar, and so forth.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2176" target="_blank">00:36:16.960</a></span> | <span class="t">I particularly like the one about the flower high, and then there is a Japanese sign.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2182" target="_blank">00:36:22.520</a></span> | <span class="t">And the model sort of generates flower, Japan, sakura, blossom, Tokyo.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2187" target="_blank">00:36:27.800</a></span> | <span class="t">So it sort of picks up again on low-level correlations that you see in your data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2193" target="_blank">00:36:33.720</a></span> | <span class="t">You can also apply these kinds of models to collaborative filtering, where every single</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2198" target="_blank">00:36:38.560</a></span> | <span class="t">observed variable you can model, can represent a user rating for a particular movie.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2206" target="_blank">00:36:46.980</a></span> | <span class="t">So every single user would rate a certain subset of movies.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2210" target="_blank">00:36:50.880</a></span> | <span class="t">And so you can represent it as the state of visible vector.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2213" target="_blank">00:36:53.560</a></span> | <span class="t">And your hidden states can represent user preferences, what they are.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2218" target="_blank">00:36:58.680</a></span> | <span class="t">And on the Netflix data set, if you look at the latent space that the model is learning,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2224" target="_blank">00:37:04.240</a></span> | <span class="t">some of these hidden variables are capturing specific movie genre.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2228" target="_blank">00:37:08.960</a></span> | <span class="t">So for example, there is actually one hidden unit dedicated to Michael Moore's movies.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2234" target="_blank">00:37:14.520</a></span> | <span class="t">So it's sort of very strong.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2236" target="_blank">00:37:16.960</a></span> | <span class="t">I think it's sort of either people like it or hate it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2239" target="_blank">00:37:19.280</a></span> | <span class="t">So there are a few hidden units specifically dedicated to that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2242" target="_blank">00:37:22.560</a></span> | <span class="t">But it also finds interesting things like action movies and so forth.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2246" target="_blank">00:37:26.080</a></span> | <span class="t">So it finds that particular structure in the data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2248" target="_blank">00:37:28.840</a></span> | <span class="t">So you can model different kinds of modality, real value data, you can model count data,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2254" target="_blank">00:37:34.880</a></span> | <span class="t">multinomials.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2256" target="_blank">00:37:36.280</a></span> | <span class="t">And it's very easy to infer the states of the hidden variables.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2259" target="_blank">00:37:39.020</a></span> | <span class="t">So that's given just the product of logistic functions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2261" target="_blank">00:37:41.400</a></span> | <span class="t">And that's very important in a lot of different applications.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2264" target="_blank">00:37:44.380</a></span> | <span class="t">Given the input, I can quickly tell you what topics I see in the data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2269" target="_blank">00:37:49.200</a></span> | <span class="t">One thing that I want to point out, and that's an important point, is a lot of these models</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2273" target="_blank">00:37:53.360</a></span> | <span class="t">can be viewed as product models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2276" target="_blank">00:37:56.120</a></span> | <span class="t">Sometimes people call them product of experts.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2278" target="_blank">00:37:58.960</a></span> | <span class="t">And this is because of the following intuition.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2283" target="_blank">00:38:03.680</a></span> | <span class="t">If I write down the joint distribution of my hidden observed variables, I can write</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2287" target="_blank">00:38:07.520</a></span> | <span class="t">it down in this sort of log linear form.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2290" target="_blank">00:38:10.360</a></span> | <span class="t">But if I sum out or integrate out the states of the hidden variables, I have a product</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2297" target="_blank">00:38:17.800</a></span> | <span class="t">of a whole bunch of functions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2300" target="_blank">00:38:20.680</a></span> | <span class="t">So what does it mean?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2302" target="_blank">00:38:22.640</a></span> | <span class="t">What's the intuition here?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2304" target="_blank">00:38:24.240</a></span> | <span class="t">So let me show you an example.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2306" target="_blank">00:38:26.040</a></span> | <span class="t">Suppose the model finds these specific topics.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2309" target="_blank">00:38:29.800</a></span> | <span class="t">And suppose I'm going to be telling you that the document contains topic government, corruption,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2314" target="_blank">00:38:34.240</a></span> | <span class="t">and mafia.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2315" target="_blank">00:38:35.540</a></span> | <span class="t">Then the word Silvio Berlusconi will have very high probability.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2319" target="_blank">00:38:39.360</a></span> | <span class="t">I guess, does anybody know?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2322" target="_blank">00:38:42.000</a></span> | <span class="t">Everybody knows who Silvio is?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2323" target="_blank">00:38:43.000</a></span> | <span class="t">Silvio Berlusconi?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2324" target="_blank">00:38:44.200</a></span> | <span class="t">He's in head of the government.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2326" target="_blank">00:38:46.480</a></span> | <span class="t">He's connected to mafia.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2329" target="_blank">00:38:49.040</a></span> | <span class="t">He's very corrupt, was corrupt.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2330" target="_blank">00:38:50.680</a></span> | <span class="t">And I guess I should add a bunga bunga parties here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2333" target="_blank">00:38:53.800</a></span> | <span class="t">Then it will become completely clear what I'm talking about.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2337" target="_blank">00:38:57.520</a></span> | <span class="t">But then one point I want to make here is that you can think of these models as a product.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2345" target="_blank">00:39:05.040</a></span> | <span class="t">Each hidden variable defines a distribution of possible words, of possible topics.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2350" target="_blank">00:39:10.800</a></span> | <span class="t">And once you take the intersection of these distributions, you can be very precise about</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2355" target="_blank">00:39:15.200</a></span> | <span class="t">what is it that you're modeling.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2357" target="_blank">00:39:17.360</a></span> | <span class="t">So that's unlike generally topic models or latent directory allocation models, models</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2362" target="_blank">00:39:22.560</a></span> | <span class="t">where you're actually using mixture-like approach.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2368" target="_blank">00:39:28.280</a></span> | <span class="t">And then typically, these models do perform far better than traditional mixture-based</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2372" target="_blank">00:39:32.560</a></span> | <span class="t">models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2373" target="_blank">00:39:33.560</a></span> | <span class="t">And this comes to the point of local versus distributed representations.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2379" target="_blank">00:39:39.280</a></span> | <span class="t">In a lot of different algorithms, even unsupervised learning algorithms, such as clustering, you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2384" target="_blank">00:39:44.640</a></span> | <span class="t">typically have some, you're partitioning the space, and you're finding local prototypes.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2392" target="_blank">00:39:52.120</a></span> | <span class="t">And the number of parameters for each, you have basically parameters for each region,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2395" target="_blank">00:39:55.720</a></span> | <span class="t">the number of regions typically grow linearly with the number of parameters.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2400" target="_blank">00:40:00.280</a></span> | <span class="t">But in models like factor models, PCA, restricted Boltzmann machines, deep models, you typically</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2407" target="_blank">00:40:07.460</a></span> | <span class="t">have distributed representations.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2408" target="_blank">00:40:08.460</a></span> | <span class="t">And what's the idea here?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2410" target="_blank">00:40:10.520</a></span> | <span class="t">The idea here is that if I show you the two inputs, each particular neuron can differentiate</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2417" target="_blank">00:40:17.060</a></span> | <span class="t">between two parts of the plane.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2419" target="_blank">00:40:19.440</a></span> | <span class="t">Given the second one, I can partition it again.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2423" target="_blank">00:40:23.040</a></span> | <span class="t">Given the third hidden variable, you can partition it again.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2425" target="_blank">00:40:25.520</a></span> | <span class="t">So you can see that every single neuron will be affecting lots of different regions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2431" target="_blank">00:40:31.240</a></span> | <span class="t">And that's the idea behind distributed representations, because every single parameter is affecting</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2435" target="_blank">00:40:35.520</a></span> | <span class="t">many, many regions, not just the local region.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2438" target="_blank">00:40:38.080</a></span> | <span class="t">And so the number of regions grow roughly exponentially with the number of parameters.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2442" target="_blank">00:40:42.820</a></span> | <span class="t">So that's the differences between these two classes of models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2446" target="_blank">00:40:46.720</a></span> | <span class="t">It's important to know about them.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2448" target="_blank">00:40:48.880</a></span> | <span class="t">Now let me jump and quickly tell you a little bit of inspiration behind what can we build</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2453" target="_blank">00:40:53.800</a></span> | <span class="t">with these models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2455" target="_blank">00:40:55.840</a></span> | <span class="t">As we've seen with convolutional networks, the first layer, we typically learn some low-level</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2461" target="_blank">00:41:01.080</a></span> | <span class="t">features, like edges.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2464" target="_blank">00:41:04.000</a></span> | <span class="t">If you're working with a word table, typically we'll learn some low-level structure.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2469" target="_blank">00:41:09.600</a></span> | <span class="t">And the hope is that the high-level features will start picking up some high-level structure</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2473" target="_blank">00:41:13.520</a></span> | <span class="t">as you are building.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2475" target="_blank">00:41:15.960</a></span> | <span class="t">And these kinds of models can be built in a completely unsupervised way, because what</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2479" target="_blank">00:41:19.960</a></span> | <span class="t">you're trying to do is you're trying to model the data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2481" target="_blank">00:41:21.840</a></span> | <span class="t">You're trying to model the distribution of the data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2485" target="_blank">00:41:25.120</a></span> | <span class="t">You can write down the probability distribution for these models, known as a Bolson machine</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2491" target="_blank">00:41:31.600</a></span> | <span class="t">model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2492" target="_blank">00:41:32.760</a></span> | <span class="t">You have dependencies between hidden variables.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2494" target="_blank">00:41:34.560</a></span> | <span class="t">So now introducing some extra layers and dependencies between those layers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2502" target="_blank">00:41:42.960</a></span> | <span class="t">And if we look at the equation, the first part of the equation is basically the same</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2506" target="_blank">00:41:46.560</a></span> | <span class="t">as what we had with restricted Bolson machine.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2509" target="_blank">00:41:49.560</a></span> | <span class="t">And then the second and third part of the equation is essentially modeling dependencies</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2513" target="_blank">00:41:53.200</a></span> | <span class="t">between the first and the second hidden layer, and the second hidden layer and the third</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2517" target="_blank">00:41:57.160</a></span> | <span class="t">hidden layer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2518" target="_blank">00:41:58.160</a></span> | <span class="t">There is also a very natural notion of bottom-up and top-down.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2521" target="_blank">00:42:01.560</a></span> | <span class="t">So if I want to see what's the probability of a particular unit taking value 1, it's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2526" target="_blank">00:42:06.840</a></span> | <span class="t">really dependent on what's coming from below and what's coming from above.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2530" target="_blank">00:42:10.760</a></span> | <span class="t">So there has to be some consensus in the model to say, ah, yes, what I'm seeing in the image</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2536" target="_blank">00:42:16.080</a></span> | <span class="t">and what my model believes the overall structure should be should be in agreement.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2541" target="_blank">00:42:21.880</a></span> | <span class="t">And so in this case, of course, in this case, hidden variables become dependent even when</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2545" target="_blank">00:42:25.320</a></span> | <span class="t">you condition on the data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2547" target="_blank">00:42:27.200</a></span> | <span class="t">So these kinds of models we'll see a lot is you're introducing more flexibility, you're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2552" target="_blank">00:42:32.440</a></span> | <span class="t">introducing more structure, but then learning becomes much more difficult.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2557" target="_blank">00:42:37.240</a></span> | <span class="t">You have to deal-- how do you inference in these models?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2562" target="_blank">00:42:42.680</a></span> | <span class="t">Now let me give you an intuition of how can we learn these models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2567" target="_blank">00:42:47.200</a></span> | <span class="t">What's the maximum likelihood estimator doing here?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2570" target="_blank">00:42:50.560</a></span> | <span class="t">Well, if I differentiate this model with respect to parameters, I basically run into the same</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2575" target="_blank">00:42:55.040</a></span> | <span class="t">learning rule.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2576" target="_blank">00:42:56.040</a></span> | <span class="t">And it's the same learning rule you see whenever you're working with undirected graphical models,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2579" target="_blank">00:42:59.640</a></span> | <span class="t">factor graphs, conditional random fields.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2581" target="_blank">00:43:01.360</a></span> | <span class="t">You might have heard about those ones.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2583" target="_blank">00:43:03.840</a></span> | <span class="t">It really is just trying to look at the statistics driven by the data, correlations that you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2587" target="_blank">00:43:07.840</a></span> | <span class="t">see in the data, and the correlations that the model is telling you it's seeing in the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2591" target="_blank">00:43:11.400</a></span> | <span class="t">data, and you're just trying to match the two.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2593" target="_blank">00:43:13.680</a></span> | <span class="t">That's exactly what's happening in that particular equation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2598" target="_blank">00:43:18.460</a></span> | <span class="t">But the first term is no longer factorial, so you have to do some approximation with</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2602" target="_blank">00:43:22.200</a></span> | <span class="t">these models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2603" target="_blank">00:43:23.360</a></span> | <span class="t">But let me give you an intuition what each term is doing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2606" target="_blank">00:43:26.800</a></span> | <span class="t">Suppose I have some data, and I get to observe these characters.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2610" target="_blank">00:43:30.480</a></span> | <span class="t">Well, what I can do is I really want to tell the model, this is real.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2616" target="_blank">00:43:36.160</a></span> | <span class="t">These are real characters.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2617" target="_blank">00:43:37.160</a></span> | <span class="t">So I want to put some probability mass around them and say, these are real.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2621" target="_blank">00:43:41.200</a></span> | <span class="t">And then there is some sort of a data point that looks like this, just a bunch of pixels</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2626" target="_blank">00:43:46.000</a></span> | <span class="t">on and off.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2627" target="_blank">00:43:47.000</a></span> | <span class="t">And I really want to tell my model that put almost zero probability on this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2632" target="_blank">00:43:52.520</a></span> | <span class="t">This is not real.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2635" target="_blank">00:43:55.440</a></span> | <span class="t">And so the first term is exactly trying to do that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2637" target="_blank">00:43:57.920</a></span> | <span class="t">The first term is just trying to say, put the probability mass where you see the data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2642" target="_blank">00:44:02.000</a></span> | <span class="t">And the second term is effectively trying to say, well, look at this entire exponential</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2645" target="_blank">00:44:05.280</a></span> | <span class="t">space and just say, no, everything else is not real.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2648" target="_blank">00:44:08.960</a></span> | <span class="t">Just the real thing is what I'm seeing in my data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2651" target="_blank">00:44:11.960</a></span> | <span class="t">And so you can use advanced techniques for doing that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2654" target="_blank">00:44:14.480</a></span> | <span class="t">There's a class of algorithms called variational inference.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2657" target="_blank">00:44:17.600</a></span> | <span class="t">There's something that's called stochastic approximation, which is Monte Carlo-based</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2661" target="_blank">00:44:21.080</a></span> | <span class="t">inference.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2662" target="_blank">00:44:22.080</a></span> | <span class="t">And I'm not going to go into these techniques.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2663" target="_blank">00:44:23.080</a></span> | <span class="t">But in general, you can train these models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2666" target="_blank">00:44:26.400</a></span> | <span class="t">So one question is, how good are they?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2669" target="_blank">00:44:29.080</a></span> | <span class="t">Because a lot of approximations that go into these models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2672" target="_blank">00:44:32.740</a></span> | <span class="t">So what I'm going to do is, if you haven't seen it, I'm going to show you two panels.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2677" target="_blank">00:44:37.720</a></span> | <span class="t">On one panel, you will see the real data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2680" target="_blank">00:44:40.640</a></span> | <span class="t">On another panel, you'll see data simulated by the model or the fake data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2684" target="_blank">00:44:44.240</a></span> | <span class="t">And you have to tell me which one is which.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2687" target="_blank">00:44:47.400</a></span> | <span class="t">So again, these are handwritten characters coming from alphabets around the world.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2691" target="_blank">00:44:51.820</a></span> | <span class="t">How many of you think this is simulated and the other part was real?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2695" target="_blank">00:44:55.640</a></span> | <span class="t">Honestly.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2696" target="_blank">00:44:56.640</a></span> | <span class="t">OK, some.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2698" target="_blank">00:44:58.040</a></span> | <span class="t">What about the other way around?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2701" target="_blank">00:45:01.320</a></span> | <span class="t">I get half and half, which is great.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2705" target="_blank">00:45:05.160</a></span> | <span class="t">If you look at these images a little bit more carefully, you will see the difference.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2710" target="_blank">00:45:10.840</a></span> | <span class="t">So you will see that this is simulated and this is real.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2716" target="_blank">00:45:16.320</a></span> | <span class="t">Because if you look at the real data, it's much crisper.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2718" target="_blank">00:45:18.440</a></span> | <span class="t">There's more diversity.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2720" target="_blank">00:45:20.600</a></span> | <span class="t">When you're simulating the data, there's a lot of structure in the simulated characters,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2724" target="_blank">00:45:24.200</a></span> | <span class="t">but sometimes they look a little bit fuzzy and there isn't as much diversity.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2729" target="_blank">00:45:29.760</a></span> | <span class="t">And I've learned that trick from my neuroscience friends.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2733" target="_blank">00:45:33.480</a></span> | <span class="t">If I show you quickly enough, you won't see the difference.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2738" target="_blank">00:45:38.840</a></span> | <span class="t">And if you're using these models for classifying, you can do proper analysis, which is to say,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2745" target="_blank">00:45:45.880</a></span> | <span class="t">given a new character, you find further states of the latent variables, hidden variables.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2749" target="_blank">00:45:49.960</a></span> | <span class="t">If I classify based on that, how good are they?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2752" target="_blank">00:45:52.560</a></span> | <span class="t">And they are much better than some of the existing techniques.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2757" target="_blank">00:45:57.220</a></span> | <span class="t">This is another example.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2758" target="_blank">00:45:58.480</a></span> | <span class="t">Trying to generate 3D objects.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2760" target="_blank">00:46:00.520</a></span> | <span class="t">This is sort of a toy datasets.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2762" target="_blank">00:46:02.120</a></span> | <span class="t">And later on, I'll show you some bigger advances that's been happening in the last few years.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2766" target="_blank">00:46:06.720</a></span> | <span class="t">This was done a few years ago.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2768" target="_blank">00:46:08.600</a></span> | <span class="t">If you look at the space of generated samples, they sort of, obviously you can see the difference.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2778" target="_blank">00:46:18.040</a></span> | <span class="t">Look at this particular image.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2780" target="_blank">00:46:20.400</a></span> | <span class="t">This image looks like a car with wings, don't you think?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2784" target="_blank">00:46:24.280</a></span> | <span class="t">So sometimes it can sort of simulate things that are not necessarily realistic.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2789" target="_blank">00:46:29.820</a></span> | <span class="t">And for some reason, it just doesn't generate donkeys and elephants too often, but it generates</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2794" target="_blank">00:46:34.120</a></span> | <span class="t">people with guns more often.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2795" target="_blank">00:46:35.600</a></span> | <span class="t">Like if you look at here and here and here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2798" target="_blank">00:46:38.400</a></span> | <span class="t">And that, again, has to do with the fact that you're exploring this exponential space of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2803" target="_blank">00:46:43.480</a></span> | <span class="t">possible images, and sometimes it's very hard to assign the right probabilities to different</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2808" target="_blank">00:46:48.880</a></span> | <span class="t">parts of the space.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2812" target="_blank">00:46:52.200</a></span> | <span class="t">And then obviously you can do things like pattern completion.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2814" target="_blank">00:46:54.360</a></span> | <span class="t">So given half of the image, can you complete the remaining half?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2817" target="_blank">00:46:57.360</a></span> | <span class="t">So the second one shows what the completions look like, and the last one is what the truth</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2820" target="_blank">00:47:00.760</a></span> | <span class="t">is.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2821" target="_blank">00:47:01.760</a></span> | <span class="t">So you can do these things.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2824" target="_blank">00:47:04.060</a></span> | <span class="t">So where else can we use these models?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2825" target="_blank">00:47:05.640</a></span> | <span class="t">These are sort of toyish examples, but where else?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2828" target="_blank">00:47:08.080</a></span> | <span class="t">Let me show you one example where these models can potentially succeed, which is trying to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2833" target="_blank">00:47:13.680</a></span> | <span class="t">model the space of the multimodal space, which is the space of images and text.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2840" target="_blank">00:47:20.240</a></span> | <span class="t">Or generally, if you look at the data, it's not just single sources.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2843" target="_blank">00:47:23.600</a></span> | <span class="t">It's a collection of different modalities.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2846" target="_blank">00:47:26.560</a></span> | <span class="t">So how can we take all of these modalities into account?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2850" target="_blank">00:47:30.100</a></span> | <span class="t">And this is really just the idea of given images and text.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2853" target="_blank">00:47:33.360</a></span> | <span class="t">And you actually find a concept that relates these two different sources of data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2860" target="_blank">00:47:40.120</a></span> | <span class="t">And there are a few challenges, and that's why models like generative models, sometimes</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2864" target="_blank">00:47:44.840</a></span> | <span class="t">probabilistic models, could be useful.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2866" target="_blank">00:47:46.720</a></span> | <span class="t">In general, one of the biggest challenges we've seen is that typically when you're working</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2870" target="_blank">00:47:50.700</a></span> | <span class="t">with images and text, these are very different modalities.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2874" target="_blank">00:47:54.160</a></span> | <span class="t">If you think about images and pixel representation, they're very dense.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2878" target="_blank">00:47:58.260</a></span> | <span class="t">If you're looking at text, it's typically very sparse.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2881" target="_blank">00:48:01.960</a></span> | <span class="t">It's very difficult to learn these cross-modal features from low-level representation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2886" target="_blank">00:48:06.920</a></span> | <span class="t">Perhaps a bigger challenge is that a lot of times we see data that's very noisy.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2892" target="_blank">00:48:12.700</a></span> | <span class="t">Sometimes it's just non-existent.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2893" target="_blank">00:48:13.700</a></span> | <span class="t">Given an image, there is no text.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2895" target="_blank">00:48:15.880</a></span> | <span class="t">Or if you look at the first image, a lot of the tags about is what kind of camera was</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2900" target="_blank">00:48:20.120</a></span> | <span class="t">used to describe that particular image, which doesn't really tell us anything about the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2905" target="_blank">00:48:25.240</a></span> | <span class="t">image itself.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2906" target="_blank">00:48:26.740</a></span> | <span class="t">And these would be the text generated by a version of a Boltzmann machine model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2912" target="_blank">00:48:32.120</a></span> | <span class="t">It sort of does samples of what the text should look like.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2917" target="_blank">00:48:37.000</a></span> | <span class="t">And the idea, again, is very simple.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2920" target="_blank">00:48:40.040</a></span> | <span class="t">If you just build a simple representation, given images and given text, you just try</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2923" target="_blank">00:48:43.760</a></span> | <span class="t">to find what the common representation is, it's very difficult to learn these cross-modal</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2928" target="_blank">00:48:48.440</a></span> | <span class="t">features.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2929" target="_blank">00:48:49.560</a></span> | <span class="t">But if you actually build a hierarchical model, so you start with representation, you can</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2934" target="_blank">00:48:54.520</a></span> | <span class="t">build a Gaussian model, replicate a softmax model, you can build up that representation,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2938" target="_blank">00:48:58.880</a></span> | <span class="t">then it turns out it's much more, it gives you much richer representation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2944" target="_blank">00:49:04.080</a></span> | <span class="t">There's also a notion of bottom-up and top-down, which means that low-level images or tags</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2952" target="_blank">00:49:12.480</a></span> | <span class="t">can effectively affect low-level representation of images and the other way around.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2956" target="_blank">00:49:16.480</a></span> | <span class="t">So information flows between images and text and gets into some stable state.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2962" target="_blank">00:49:22.680</a></span> | <span class="t">And this is what the text generated from images looks like, some of the examples.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2968" target="_blank">00:49:28.160</a></span> | <span class="t">A lot of them look reasonable, but more recently, with the advances of CovNets, this is probably</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2973" target="_blank">00:49:33.840</a></span> | <span class="t">not that surprising.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2977" target="_blank">00:49:37.480</a></span> | <span class="t">Here's some examples of the model that's not quite doing the right thing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2982" target="_blank">00:49:42.360</a></span> | <span class="t">I particularly like the second one.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2984" target="_blank">00:49:44.560</a></span> | <span class="t">For some reason, it sort of correlates with Barack Obama and such.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2988" target="_blank">00:49:48.760</a></span> | <span class="t">And the features, when we were using this model, we didn't have, at that time, image</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2994" target="_blank">00:49:54.320</a></span> | <span class="t">net features.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2995" target="_blank">00:49:55.320</a></span> | <span class="t">Right now, I don't think we'd be making these mistakes.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=2997" target="_blank">00:49:57.320</a></span> | <span class="t">But generally speaking, what we found in a lot of the data is that there are a lot of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3000" target="_blank">00:50:00.800</a></span> | <span class="t">images of animals, which brings us to the next problem, is that if you don't see images</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3005" target="_blank">00:50:05.200</a></span> | <span class="t">of animals, then the model is confused because it sees a lot of Obama signs, and these are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3008" target="_blank">00:50:08.800</a></span> | <span class="t">black and white and blue signs that are appearing a lot.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3014" target="_blank">00:50:14.180</a></span> | <span class="t">You can also do images from text, given text, or tags can retrieve relevant images.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3021" target="_blank">00:50:21.240</a></span> | <span class="t">This is the dataset itself, about a million images.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3023" target="_blank">00:50:23.240</a></span> | <span class="t">It's a nice dataset, and you have very noisy tags.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3027" target="_blank">00:50:27.960</a></span> | <span class="t">The question is, can you actually learn some representation from those images?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3032" target="_blank">00:50:32.120</a></span> | <span class="t">One thing that I want to highlight here is, we've tried, there's 25,000 labeled images.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3038" target="_blank">00:50:38.040</a></span> | <span class="t">Somebody went and labeled what's going on in those images, what classes we see in those</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3041" target="_blank">00:50:41.440</a></span> | <span class="t">images, and you get some numbers, which is mean average precision.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3045" target="_blank">00:50:45.360</a></span> | <span class="t">What's important here is that we found that if we actually use unlabeled data, and we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3049" target="_blank">00:50:49.560</a></span> | <span class="t">pre-train these channels separately, using a million unlabeled data points, then we can</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3056" target="_blank">00:50:56.220</a></span> | <span class="t">actually get some performance improvements.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3058" target="_blank">00:50:58.320</a></span> | <span class="t">At least that was a little bit of a happy sign for us to say that unlabeled data can</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3063" target="_blank">00:51:03.280</a></span> | <span class="t">help in the situations where you don't have a lot of labeled examples.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3067" target="_blank">00:51:07.920</a></span> | <span class="t">Here it was helping us, it was helping us a lot.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3071" target="_blank">00:51:11.680</a></span> | <span class="t">And then once you get into these representations, dealing with text and images, this is one</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3076" target="_blank">00:51:16.760</a></span> | <span class="t">particular thing you can do.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3078" target="_blank">00:51:18.120</a></span> | <span class="t">I think Richard pointed out what happens in the space of linguistic regularities.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3085" target="_blank">00:51:25.800</a></span> | <span class="t">You can do the same thing with images, which is kind of fun to do.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3089" target="_blank">00:51:29.320</a></span> | <span class="t">They sometimes work, they don't work all the time.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3091" target="_blank">00:51:31.520</a></span> | <span class="t">But here's one example.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3092" target="_blank">00:51:32.520</a></span> | <span class="t">I take that particular image at the top, and I say get the representation of this image,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3097" target="_blank">00:51:37.680</a></span> | <span class="t">subtract the representation of day, add the night, and then find closest images, you get</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3101" target="_blank">00:51:41.680</a></span> | <span class="t">these images.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3103" target="_blank">00:51:43.800</a></span> | <span class="t">And then you can do some interesting things, like take these kittens and say minus ball</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3107" target="_blank">00:51:47.520</a></span> | <span class="t">plus box, you get kittens in the box.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3110" target="_blank">00:51:50.640</a></span> | <span class="t">If you take this particular image and say minus box plus ball, you get kittens in the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3113" target="_blank">00:51:53.760</a></span> | <span class="t">ball.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3115" target="_blank">00:51:55.840</a></span> | <span class="t">Except for this thing, that's a duck.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3118" target="_blank">00:51:58.840</a></span> | <span class="t">So you can get these interesting representations.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3123" target="_blank">00:52:03.840</a></span> | <span class="t">Of course, these are all fun things to look at, but they don't really mean much, because</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3127" target="_blank">00:52:07.800</a></span> | <span class="t">we're not specifically optimizing for those things.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3131" target="_blank">00:52:11.840</a></span> | <span class="t">Now let me spend some time also talking about another class of models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3138" target="_blank">00:52:18.280</a></span> | <span class="t">These are known as Helmholtz machines and variational autoencoders.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3141" target="_blank">00:52:21.560</a></span> | <span class="t">These are the models that have been popping up in our community in the last two years.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3147" target="_blank">00:52:27.240</a></span> | <span class="t">So what is a Helmholtz machine?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3149" target="_blank">00:52:29.320</a></span> | <span class="t">A Helmholtz machine was developed back in '95, and it was developed by Hinton and Peter Dayan</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3155" target="_blank">00:52:35.280</a></span> | <span class="t">and Brendan Frey and Radford Neal.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3159" target="_blank">00:52:39.200</a></span> | <span class="t">And it has this particular architecture.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3162" target="_blank">00:52:42.200</a></span> | <span class="t">You have a generative process, so given some latent state, you just-- it's a neural network,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3168" target="_blank">00:52:48.120</a></span> | <span class="t">it's a stochastic neural network that generates the input data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3172" target="_blank">00:52:52.520</a></span> | <span class="t">And then you have so-called approximate inference step, which is to say, given the data, infer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3177" target="_blank">00:52:57.800</a></span> | <span class="t">approximately what the latent states should look like.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3183" target="_blank">00:53:03.120</a></span> | <span class="t">And again, it was developed in '95.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3185" target="_blank">00:53:05.200</a></span> | <span class="t">There's something that's called wake-sleep algorithm, and it never worked.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3189" target="_blank">00:53:09.200</a></span> | <span class="t">Basically, people just said, it just doesn't work.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3192" target="_blank">00:53:12.800</a></span> | <span class="t">And then we started looking at restricted-bolt machines and Boltz machines, because they're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3196" target="_blank">00:53:16.840</a></span> | <span class="t">working a little bit better.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3198" target="_blank">00:53:18.440</a></span> | <span class="t">And then two years ago, people figured out how to make them work.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3202" target="_blank">00:53:22.080</a></span> | <span class="t">And so now, 10 years later, I'm going to show you the trick.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3204" target="_blank">00:53:24.560</a></span> | <span class="t">Now, these models are actually working pretty well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3207" target="_blank">00:53:27.520</a></span> | <span class="t">The difference between Helmholtz machines and deep-bolt machines is very subtle.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3211" target="_blank">00:53:31.400</a></span> | <span class="t">They almost look identical.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3213" target="_blank">00:53:33.280</a></span> | <span class="t">The big difference between the two is that in Helmholtz machines, you have a generative</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3218" target="_blank">00:53:38.040</a></span> | <span class="t">process that generates the data, and you have a separate recognition model that tries to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3222" target="_blank">00:53:42.400</a></span> | <span class="t">recognize what you're seeing in the data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3224" target="_blank">00:53:44.240</a></span> | <span class="t">So you can think of this Q function as a convolutional neural network, given the data, tries to figure</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3229" target="_blank">00:53:49.200</a></span> | <span class="t">out what the features should look like.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3231" target="_blank">00:53:51.400</a></span> | <span class="t">And then there's a generative model, given the features, it generates the data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3234" target="_blank">00:53:54.840</a></span> | <span class="t">Boltzmann machine is sort of similar class of models, but it has undirected connections.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3239" target="_blank">00:53:59.120</a></span> | <span class="t">So you can think of it as generative and recognition connections are the same.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3243" target="_blank">00:54:03.160</a></span> | <span class="t">So it's sort of a system that tries to reach some equilibrium state when you're running</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3249" target="_blank">00:54:09.040</a></span> | <span class="t">it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3250" target="_blank">00:54:10.040</a></span> | <span class="t">So the semantics is a little bit different between these two models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3254" target="_blank">00:54:14.120</a></span> | <span class="t">So what is a variational autoencoder?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3255" target="_blank">00:54:15.480</a></span> | <span class="t">A variational encoder is a Helmholtz machine.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3257" target="_blank">00:54:17.960</a></span> | <span class="t">It defines a generative process in terms of sampling through cascades of stochastic layers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3264" target="_blank">00:54:24.080</a></span> | <span class="t">And if you look at it, there's just a bunch of conditional probability distributions that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3268" target="_blank">00:54:28.040</a></span> | <span class="t">you're defining, so you can generate the data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3270" target="_blank">00:54:30.400</a></span> | <span class="t">So theta here will denote the parameters of the variational autoencoders.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3273" target="_blank">00:54:33.920</a></span> | <span class="t">You have a number of stochastic layers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3276" target="_blank">00:54:36.960</a></span> | <span class="t">And sampling from these conditional probability distributions, we're assuming that we can</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3281" target="_blank">00:54:41.800</a></span> | <span class="t">do it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3282" target="_blank">00:54:42.800</a></span> | <span class="t">It's attractable.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3283" target="_blank">00:54:43.800</a></span> | <span class="t">It has to be attractable.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3285" target="_blank">00:54:45.680</a></span> | <span class="t">But the innovation here is that every single conditional probability can actually be a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3293" target="_blank">00:54:53.680</a></span> | <span class="t">very complicated function.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3294" target="_blank">00:54:54.680</a></span> | <span class="t">It can denote a nonlinear-- you can model nonlinear relationships.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3298" target="_blank">00:54:58.000</a></span> | <span class="t">It can be a multilayer nonlinear neural network, deterministic neural network.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3302" target="_blank">00:55:02.240</a></span> | <span class="t">So it becomes fairly powerful.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3305" target="_blank">00:55:05.400</a></span> | <span class="t">Here's an example of I have a stochastic layer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3307" target="_blank">00:55:07.640</a></span> | <span class="t">You have a deterministic layer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3308" target="_blank">00:55:08.640</a></span> | <span class="t">You have a stochastic layer, and then you generate the data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3312" target="_blank">00:55:12.040</a></span> | <span class="t">So you can introduce these nonlinearities into these models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3316" target="_blank">00:55:16.880</a></span> | <span class="t">And this conditional probability would denote a one-layer neural network.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3321" target="_blank">00:55:21.960</a></span> | <span class="t">Now I'll show you some examples, but maybe I can just give you a little intuition behind</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3327" target="_blank">00:55:27.600</a></span> | <span class="t">what these equations do.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3331" target="_blank">00:55:31.480</a></span> | <span class="t">In a lot of these kinds of models, learning is very hard to do.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3336" target="_blank">00:55:36.800</a></span> | <span class="t">And there's a class of models called variational learning.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3339" target="_blank">00:55:39.000</a></span> | <span class="t">And what the variational learning is trying to do is basically trying to do the following.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3342" target="_blank">00:55:42.440</a></span> | <span class="t">Well, I want to maximize the probability of the data that I observe, but I cannot do it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3347" target="_blank">00:55:47.080</a></span> | <span class="t">directly.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3348" target="_blank">00:55:48.080</a></span> | <span class="t">So instead, what I'm going to do is I'm going to maximize the so-called variational low</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3350" target="_blank">00:55:50.920</a></span> | <span class="t">bound, which is this term here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3354" target="_blank">00:55:54.080</a></span> | <span class="t">And it's effectively saying, well, if I take the log of expectation, I can take the log</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3358" target="_blank">00:55:58.960</a></span> | <span class="t">and push it inside.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3362" target="_blank">00:56:02.240</a></span> | <span class="t">And it turns out just logistically, working in this representation is much easier than</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3366" target="_blank">00:56:06.760</a></span> | <span class="t">working in this representation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3368" target="_blank">00:56:08.680</a></span> | <span class="t">If you go a little bit through the math, it turns out that you can actually optimize this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3373" target="_blank">00:56:13.520</a></span> | <span class="t">variational bound, but you can't really optimize this particular likelihood objective.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3379" target="_blank">00:56:19.200</a></span> | <span class="t">It's a little bit surprising for those of you who haven't seen variational learning</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3383" target="_blank">00:56:23.280</a></span> | <span class="t">how it's done.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3384" target="_blank">00:56:24.840</a></span> | <span class="t">But this one little trick, this one little so-called Jensen's inequality actually allows</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3389" target="_blank">00:56:29.100</a></span> | <span class="t">you to solve a lot of problems.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3393" target="_blank">00:56:33.080</a></span> | <span class="t">And the other way to write the lower bound is to say, well, there is a log likelihood</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3397" target="_blank">00:56:37.360</a></span> | <span class="t">function and something that's called KL divergence, which is the distance between your approximating</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3402" target="_blank">00:56:42.080</a></span> | <span class="t">distribution Q, which is your recognition model, and the truth.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3405" target="_blank">00:56:45.880</a></span> | <span class="t">The truth in these models would be the true posterior according to your model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3411" target="_blank">00:56:51.000</a></span> | <span class="t">And it's hard to optimize these kinds of models in general.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3414" target="_blank">00:56:54.560</a></span> | <span class="t">You're trying to optimize your generative model, you're trying to optimize your recognition</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3417" target="_blank">00:56:57.800</a></span> | <span class="t">model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3418" target="_blank">00:56:58.800</a></span> | <span class="t">And back in '95, Hinton and his students basically, they developed this wake-sleep algorithm that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3425" target="_blank">00:57:05.200</a></span> | <span class="t">was a bunch of different things put together, but it was never quite the right algorithm</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3429" target="_blank">00:57:09.280</a></span> | <span class="t">because it wasn't really optimizing anything.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3430" target="_blank">00:57:10.840</a></span> | <span class="t">It was just a bunch of things alternating.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3434" target="_blank">00:57:14.560</a></span> | <span class="t">But in 2014, there was a beautiful trick introduced by Kingman and Welling, and there was a few</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3439" target="_blank">00:57:19.880</a></span> | <span class="t">other groups that came up with the same trick called reparameterization trick.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3444" target="_blank">00:57:24.060</a></span> | <span class="t">So let me show you what reparameterization trick does intuitively.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3447" target="_blank">00:57:27.960</a></span> | <span class="t">So let's say your recognition distribution is a Gaussian.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3452" target="_blank">00:57:32.160</a></span> | <span class="t">So a Gaussian, I can write it as a mean and a variance.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3455" target="_blank">00:57:35.700</a></span> | <span class="t">So this is the mean, this is the variance.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3457" target="_blank">00:57:37.160</a></span> | <span class="t">Notice that my mean depends on the layer below.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3461" target="_blank">00:57:41.200</a></span> | <span class="t">It could be a very nonlinear function.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3463" target="_blank">00:57:43.720</a></span> | <span class="t">The variance also depends on the layer below, so it could also be a nonlinear function.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3469" target="_blank">00:57:49.840</a></span> | <span class="t">But what I can do is I can actually do the following.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3472" target="_blank">00:57:52.080</a></span> | <span class="t">I can express this particular Gaussian in terms of auxiliary variables.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3476" target="_blank">00:57:56.880</a></span> | <span class="t">I can say, well, if I sample this epsilon from normal 0, 1, a Gaussian distribution,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3482" target="_blank">00:58:02.240</a></span> | <span class="t">then I can write this particular h, my state, in a deterministic way.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3489" target="_blank">00:58:09.680</a></span> | <span class="t">It's just mean plus essentially standard deviation or variance, square root of the variance,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3496" target="_blank">00:58:16.440</a></span> | <span class="t">times this epsilon.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3497" target="_blank">00:58:17.440</a></span> | <span class="t">So this is just a simple parameterization of the Gaussians.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3501" target="_blank">00:58:21.920</a></span> | <span class="t">I'm just pulling out the mean and the variance.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3503" target="_blank">00:58:23.960</a></span> | <span class="t">There's no surprises here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3507" target="_blank">00:58:27.040</a></span> | <span class="t">So I can write my recognition model as this Gaussian, or I can write it in terms of noise</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3512" target="_blank">00:58:32.720</a></span> | <span class="t">plus the deterministic part.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3514" target="_blank">00:58:34.860</a></span> | <span class="t">So the recognition distribution can be represented as a deterministic mapping.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3518" target="_blank">00:58:38.400</a></span> | <span class="t">And that's the beauty, because it turns out that you can collapse these complicated models</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3523" target="_blank">00:58:43.960</a></span> | <span class="t">effectively into autoencoders.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3526" target="_blank">00:58:46.160</a></span> | <span class="t">And we know how to deal with autoencoders.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3527" target="_blank">00:58:47.520</a></span> | <span class="t">We can back propagate through the entire model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3531" target="_blank">00:58:51.380</a></span> | <span class="t">So we have a deterministic encoder.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3533" target="_blank">00:58:53.320</a></span> | <span class="t">And then the distribution of these auxiliary variables really don't depend on parameters.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3538" target="_blank">00:58:58.960</a></span> | <span class="t">So it's almost like taking a stochastic system and separating the stochastic part and deterministic</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3544" target="_blank">00:59:04.560</a></span> | <span class="t">part.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3545" target="_blank">00:59:05.560</a></span> | <span class="t">In deterministic part, you can do back propagation, so you can do learning.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3548" target="_blank">00:59:08.420</a></span> | <span class="t">And the stochastic part, you can do sampling.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3550" target="_blank">00:59:10.720</a></span> | <span class="t">So just think of it as a separation between the two pieces.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3556" target="_blank">00:59:16.280</a></span> | <span class="t">So now, if I take the gradient of the variational bound or the variational objective with respect</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3561" target="_blank">00:59:21.820</a></span> | <span class="t">to parameters, this is something that we couldn't do back in '95, and we couldn't do it in the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3565" target="_blank">00:59:25.780</a></span> | <span class="t">last 10 years.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3567" target="_blank">00:59:27.800</a></span> | <span class="t">People have tried using reinforce algorithm or some approximations to it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3570" target="_blank">00:59:30.860</a></span> | <span class="t">It never worked.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3572" target="_blank">00:59:32.500</a></span> | <span class="t">But here what we can do is we can do the following.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3574" target="_blank">00:59:34.060</a></span> | <span class="t">We can say, well, I can write this expression, because it's a Gaussian, as sampling a bunch</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3579" target="_blank">00:59:39.660</a></span> | <span class="t">of these auxiliary variables.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3581" target="_blank">00:59:41.780</a></span> | <span class="t">And then this log, I can just inject the noise in here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3584" target="_blank">00:59:44.520</a></span> | <span class="t">The whole thing here becomes deterministic.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3587" target="_blank">00:59:47.340</a></span> | <span class="t">And that's where the beauty comes in.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3588" target="_blank">00:59:48.780</a></span> | <span class="t">You take this gradient here, and you push it inside the expectation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3595" target="_blank">00:59:55.020</a></span> | <span class="t">So before, if you take the gradient of expectations, like taking the gradient of averages, like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3600" target="_blank">01:00:00.940</a></span> | <span class="t">you compute a bunch of averages, and you're taking the gradient.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3603" target="_blank">01:00:03.460</a></span> | <span class="t">What you're doing now with reparameterization trick is you're taking the gradients and then</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3607" target="_blank">01:00:07.780</a></span> | <span class="t">taking the average.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3609" target="_blank">01:00:09.620</a></span> | <span class="t">It turns out that hugely reduces the variance in your training.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3614" target="_blank">01:00:14.020</a></span> | <span class="t">It actually allows you to learn these models quite efficiently.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3618" target="_blank">01:00:18.140</a></span> | <span class="t">So the mapping edge here is completely deterministic.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3621" target="_blank">01:00:21.020</a></span> | <span class="t">And gradients here can be computed by back propagation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3623" target="_blank">01:00:23.580</a></span> | <span class="t">It's a deterministic system.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3625" target="_blank">01:00:25.420</a></span> | <span class="t">And you can think of this thing inside as just an autoencoder that you are optimizing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3633" target="_blank">01:00:33.080</a></span> | <span class="t">And obviously, there are other extensions of these models that we've looked at and a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3636" target="_blank">01:00:36.900</a></span> | <span class="t">bunch of other teams looked at where you can say, well, maybe we can improve these models</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3640" target="_blank">01:00:40.220</a></span> | <span class="t">by drawing multiple samples.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3642" target="_blank">01:00:42.180</a></span> | <span class="t">These are so-called case samples, importance weighting bounds.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3644" target="_blank">01:00:44.980</a></span> | <span class="t">And so you can make them a little bit better, a little bit more precise.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3648" target="_blank">01:00:48.860</a></span> | <span class="t">You can model a little bit more complicated distributions over the posteriors.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3654" target="_blank">01:00:54.780</a></span> | <span class="t">But now, let me step back a little bit and say, why am I telling you about this?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3658" target="_blank">01:00:58.900</a></span> | <span class="t">What's the point?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3659" target="_blank">01:00:59.900</a></span> | <span class="t">There's a bunch of equations.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3660" target="_blank">01:01:00.900</a></span> | <span class="t">You're injecting noise.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3661" target="_blank">01:01:01.900</a></span> | <span class="t">Why do we need noise?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3662" target="_blank">01:01:02.900</a></span> | <span class="t">Why do we need stochastic systems in general?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3666" target="_blank">01:01:06.380</a></span> | <span class="t">Here's a motivating example.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3669" target="_blank">01:01:09.120</a></span> | <span class="t">We wanted to build a model that, given captions, we want to generate the image.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3675" target="_blank">01:01:15.140</a></span> | <span class="t">And my student was very ambitious and basically said, I want to be able to just give you any</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3679" target="_blank">01:01:19.820</a></span> | <span class="t">sentence and I want to be able to generate image, kind of like an artificial paint.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3684" target="_blank">01:01:24.540</a></span> | <span class="t">I want to paint what's in my caption in the most general way.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3691" target="_blank">01:01:31.120</a></span> | <span class="t">So this is one example of a Helmholtz machine where you have a generative model, which is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3694" target="_blank">01:01:34.500</a></span> | <span class="t">a stochastic recurrent network.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3695" target="_blank">01:01:35.500</a></span> | <span class="t">It's just a chain sequence of variational autoencoders.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3698" target="_blank">01:01:38.500</a></span> | <span class="t">And there's a recognition model, which you can think of as a deterministic system, like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3702" target="_blank">01:01:42.260</a></span> | <span class="t">a convolutional system that tries to approximate what the latent states are.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3707" target="_blank">01:01:47.060</a></span> | <span class="t">But why do I need stochasticity here?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3709" target="_blank">01:01:49.620</a></span> | <span class="t">Why do I need variational autoencoders here?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3711" target="_blank">01:01:51.500</a></span> | <span class="t">And the reason is very simple.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3713" target="_blank">01:01:53.620</a></span> | <span class="t">Suppose I give you the following task.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3717" target="_blank">01:01:57.580</a></span> | <span class="t">I say a stop sign is flying in blue skies.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3721" target="_blank">01:02:01.780</a></span> | <span class="t">Now if you were using a deterministic system, like an autoencoder, you would generate one</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3726" target="_blank">01:02:06.580</a></span> | <span class="t">image because it's a deterministic system.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3728" target="_blank">01:02:08.940</a></span> | <span class="t">Given input, I give you output.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3731" target="_blank">01:02:11.940</a></span> | <span class="t">Once you have stochastic system, you inject this noise, this latent noise, that allows</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3736" target="_blank">01:02:16.880</a></span> | <span class="t">you to actually generate the whole space of possible images.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3739" target="_blank">01:02:19.860</a></span> | <span class="t">So for example, it tends to generate this stop sign and this stop sign.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3742" target="_blank">01:02:22.900</a></span> | <span class="t">They look very different.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3743" target="_blank">01:02:23.900</a></span> | <span class="t">And there's a car here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3746" target="_blank">01:02:26.140</a></span> | <span class="t">So maybe it's not really flying.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3747" target="_blank">01:02:27.140</a></span> | <span class="t">It just can't draw the pole here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3750" target="_blank">01:02:30.380</a></span> | <span class="t">This one looks like there are clouds.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3753" target="_blank">01:02:33.060</a></span> | <span class="t">Here is this yellow school bus is flying in blue skies.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3755" target="_blank">01:02:35.660</a></span> | <span class="t">So here we wanted to test the system to see does it understand something about what's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3761" target="_blank">01:02:41.380</a></span> | <span class="t">in the sentence.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3762" target="_blank">01:02:42.380</a></span> | <span class="t">Here is a herd of elephants is flying in blue skies.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3765" target="_blank">01:02:45.500</a></span> | <span class="t">Now we cannot generate elephants, although there are now techniques that are getting</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3768" target="_blank">01:02:48.820</a></span> | <span class="t">better.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3769" target="_blank">01:02:49.820</a></span> | <span class="t">But sometimes it generates two of them.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3772" target="_blank">01:02:52.140</a></span> | <span class="t">And it's a commercial plane flying in blue skies.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3774" target="_blank">01:02:54.940</a></span> | <span class="t">But this is where we need stochasticity because we want to be able to generate the whole distribution</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3778" target="_blank">01:02:58.780</a></span> | <span class="t">of possible outcomes, not necessarily just one particular point.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3784" target="_blank">01:03:04.940</a></span> | <span class="t">We can basically do things like a yellow school bus parked in the parking lot versus a red</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3789" target="_blank">01:03:09.380</a></span> | <span class="t">school bus parked in the parking lot versus a green school bus parked in the parking lot.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3793" target="_blank">01:03:13.940</a></span> | <span class="t">It's sort of a blue school bus.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3797" target="_blank">01:03:17.020</a></span> | <span class="t">We can't quite generate blue school buses, but we've seen blue cars and we've seen blue</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3801" target="_blank">01:03:21.100</a></span> | <span class="t">buses.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3802" target="_blank">01:03:22.100</a></span> | <span class="t">So it can make an association to draw these different things.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3805" target="_blank">01:03:25.700</a></span> | <span class="t">They look a little bit fuzzy.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3808" target="_blank">01:03:28.180</a></span> | <span class="t">But in terms of comparing to different models, if I give you a group of people on the beach</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3813" target="_blank">01:03:33.860</a></span> | <span class="t">with surfboards, this is what we can generate.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3817" target="_blank">01:03:37.260</a></span> | <span class="t">There is another model called LabGap model, which is a model based on adversarial neural</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3821" target="_blank">01:03:41.340</a></span> | <span class="t">networks, something I'll talk as the last part of this talk.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3825" target="_blank">01:03:45.580</a></span> | <span class="t">And there is these models, convolutional and deconvolutional variation autoencoders, which</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3830" target="_blank">01:03:50.140</a></span> | <span class="t">is again convolutional deconvolutional autoencoders just with some noise.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3834" target="_blank">01:03:54.460</a></span> | <span class="t">And you can certainly see that it's generally we found it's very hard to be able to generate</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3839" target="_blank">01:03:59.700</a></span> | <span class="t">scenes with arbitrary inputs as a text.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3844" target="_blank">01:04:04.660</a></span> | <span class="t">Here's my favorite one.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3846" target="_blank">01:04:06.020</a></span> | <span class="t">A toilet seat sits open in the bathroom.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3848" target="_blank">01:04:08.980</a></span> | <span class="t">I don't know if you can see toilet seats here, maybe, but you can see a toilet seat sits</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3853" target="_blank">01:04:13.100</a></span> | <span class="t">open in the grass field.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3854" target="_blank">01:04:14.140</a></span> | <span class="t">That was a little bit better.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3855" target="_blank">01:04:15.860</a></span> | <span class="t">At least the colors were quite right.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3858" target="_blank">01:04:18.100</a></span> | <span class="t">And when we put this paper on archive, one of the students basically came to me and said,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3866" target="_blank">01:04:26.260</a></span> | <span class="t">"This is really bad because you can always ask Google."</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3870" target="_blank">01:04:30.700</a></span> | <span class="t">If you type that particular query into Google search, it gives you that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3877" target="_blank">01:04:37.420</a></span> | <span class="t">Which was a little bit disappointing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3880" target="_blank">01:04:40.460</a></span> | <span class="t">But now if you actually Google or if you actually put this query into Google, this image comes</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3886" target="_blank">01:04:46.300</a></span> | <span class="t">before this image.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3889" target="_blank">01:04:49.500</a></span> | <span class="t">And generally because what's happening is that people are just clicking on that image</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3892" target="_blank">01:04:52.840</a></span> | <span class="t">all the time to figure out what's going on in that image.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3895" target="_blank">01:04:55.760</a></span> | <span class="t">So we got bumped up before that other image.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3899" target="_blank">01:04:59.560</a></span> | <span class="t">So now I can say that according to Google, this is a much better representation for that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3904" target="_blank">01:05:04.180</a></span> | <span class="t">sentence than this one.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3907" target="_blank">01:05:07.780</a></span> | <span class="t">Here's another sort of interesting model, which is a model where you're trying to build</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3914" target="_blank">01:05:14.380</a></span> | <span class="t">a recurrent neural network.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3915" target="_blank">01:05:15.380</a></span> | <span class="t">Again, it's a generative model, but it's a generative model of text.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3919" target="_blank">01:05:19.400</a></span> | <span class="t">This model was trained on about 7,000 romance novels.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3925" target="_blank">01:05:25.180</a></span> | <span class="t">And you take a caption model and you hook it up to the caption generation system.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3930" target="_blank">01:05:30.620</a></span> | <span class="t">So you're basically saying the model, here's an image, generate me in the style of romantic</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3936" target="_blank">01:05:36.940</a></span> | <span class="t">books what you'd see here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3939" target="_blank">01:05:39.900</a></span> | <span class="t">And it generates something interesting.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3942" target="_blank">01:05:42.220</a></span> | <span class="t">We're barely able to catch the breeze on the beach and so forth.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3945" target="_blank">01:05:45.980</a></span> | <span class="t">She's beautiful, but the truth is I don't know what to do.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3949" target="_blank">01:05:49.040</a></span> | <span class="t">The sun was just starting to fade away, leaving people scattered around the Atlantic Ocean.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3956" target="_blank">01:05:56.580</a></span> | <span class="t">And there are a bunch of different things that you can do.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3958" target="_blank">01:05:58.660</a></span> | <span class="t">Obviously, we're not there yet in terms of generating romantic stories.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3962" target="_blank">01:06:02.960</a></span> | <span class="t">But here's one example where it's a generative model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3965" target="_blank">01:06:05.900</a></span> | <span class="t">It seems like syntactically we can actually generate reasonable things.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3971" target="_blank">01:06:11.660</a></span> | <span class="t">Semantically, we're not there yet.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3974" target="_blank">01:06:14.860</a></span> | <span class="t">And actually, that particular work was inspired a little bit by Baidu's system that would</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3980" target="_blank">01:06:20.820</a></span> | <span class="t">give an image.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3981" target="_blank">01:06:21.820</a></span> | <span class="t">I think it would generate poems.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3985" target="_blank">01:06:25.320</a></span> | <span class="t">But the poems were predefined.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3987" target="_blank">01:06:27.020</a></span> | <span class="t">It was mostly selecting the right poem for the image.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3990" target="_blank">01:06:30.700</a></span> | <span class="t">Here we actually were trying to generate something.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3995" target="_blank">01:06:35.900</a></span> | <span class="t">So there's still a lot of work to do in that space.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3997" target="_blank">01:06:37.880</a></span> | <span class="t">Because syntactically we can get there.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=3999" target="_blank">01:06:39.900</a></span> | <span class="t">Semantically, we are nowhere near getting the right structure.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4004" target="_blank">01:06:44.580</a></span> | <span class="t">Here's another last example that I want to show you.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4008" target="_blank">01:06:48.300</a></span> | <span class="t">This was done in the case of one-shot learning, which is can you build generative model of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4012" target="_blank">01:06:52.260</a></span> | <span class="t">characters?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4013" target="_blank">01:06:53.260</a></span> | <span class="t">That's a very defined domain, very well-defined domain.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4017" target="_blank">01:06:57.300</a></span> | <span class="t">It's a very simple domain, but it's also very hard.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4021" target="_blank">01:07:01.140</a></span> | <span class="t">Here's one example.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4022" target="_blank">01:07:02.140</a></span> | <span class="t">We've shown this example to people and to the algorithm.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4026" target="_blank">01:07:06.300</a></span> | <span class="t">And we can say, well, can you draw me this example?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4029" target="_blank">01:07:09.060</a></span> | <span class="t">And on one panel, humans would draw how they believe this example should look like.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4034" target="_blank">01:07:14.700</a></span> | <span class="t">And then on the other panel, we have machines drawing it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4037" target="_blank">01:07:17.420</a></span> | <span class="t">So this is really just a generative model based on a single example.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4042" target="_blank">01:07:22.060</a></span> | <span class="t">We're showing you an example, and you're trying to generate what it is.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4045" target="_blank">01:07:25.260</a></span> | <span class="t">And so quick question for you.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4046" target="_blank">01:07:26.840</a></span> | <span class="t">How many of you think this was machine-generated and this was human-generated?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4052" target="_blank">01:07:32.980</a></span> | <span class="t">What about the other way around?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4054" target="_blank">01:07:34.660</a></span> | <span class="t">More, more.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4056" target="_blank">01:07:36.860</a></span> | <span class="t">So there's a vote.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4058" target="_blank">01:07:38.260</a></span> | <span class="t">What about this one?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4059" target="_blank">01:07:39.260</a></span> | <span class="t">How many of you think this is machine-generated and this is human-generated?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4062" target="_blank">01:07:42.860</a></span> | <span class="t">A few.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4063" target="_blank">01:07:43.860</a></span> | <span class="t">What about the other way around?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4064" target="_blank">01:07:44.860</a></span> | <span class="t">Ah, great, great.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4065" target="_blank">01:07:45.860</a></span> | <span class="t">Well, the truth is I don't really know which one was generated by which machine.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4072" target="_blank">01:07:52.660</a></span> | <span class="t">Because that was done, I should actually ask Brendan Lake, who designed the experiments</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4076" target="_blank">01:07:56.820</a></span> | <span class="t">for this particular model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4078" target="_blank">01:07:58.380</a></span> | <span class="t">But I can tell you that there's been a lot of studies.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4081" target="_blank">01:08:01.580</a></span> | <span class="t">He's done a lot of studies, and it's almost 50/50.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4085" target="_blank">01:08:05.480</a></span> | <span class="t">So in sort of this kind of small, carved domain, we can actually compete with people trying</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4091" target="_blank">01:08:11.940</a></span> | <span class="t">to generate these characters.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4096" target="_blank">01:08:16.220</a></span> | <span class="t">Now let me step back a little bit and tell you about a different class of models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4101" target="_blank">01:08:21.580</a></span> | <span class="t">These are models known as generative adversarial networks, and they've been gaining a lot of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4108" target="_blank">01:08:28.540</a></span> | <span class="t">attraction in our community because they seem to produce remarkable results.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4114" target="_blank">01:08:34.220</a></span> | <span class="t">So here's the idea.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4116" target="_blank">01:08:36.940</a></span> | <span class="t">We're not going to be really defining explicitly the density, but we need to be able to sample</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4121" target="_blank">01:08:41.700</a></span> | <span class="t">from the model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4123" target="_blank">01:08:43.780</a></span> | <span class="t">And the interesting thing is that there's no variation learning, there's no maximum</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4126" target="_blank">01:08:46.460</a></span> | <span class="t">likelihood estimation, there's no Markov chain Monte Carlo, there's no sampling.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4130" target="_blank">01:08:50.380</a></span> | <span class="t">How do you do that?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4131" target="_blank">01:08:51.660</a></span> | <span class="t">How do you learn these models?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4133" target="_blank">01:08:53.520</a></span> | <span class="t">And it turns out that you can learn these models by playing a game.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4136" target="_blank">01:08:56.140</a></span> | <span class="t">And that's a very clever strategy.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4138" target="_blank">01:08:58.980</a></span> | <span class="t">And the idea is the following.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4140" target="_blank">01:09:00.660</a></span> | <span class="t">You're going to be setting up a game between two players.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4143" target="_blank">01:09:03.020</a></span> | <span class="t">You're going to have a discriminator, D, think of it as a convolutional neural network, and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4148" target="_blank">01:09:08.620</a></span> | <span class="t">then you're going to have a generator, G. Maybe you can think of it as a variation learning</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4152" target="_blank">01:09:12.540</a></span> | <span class="t">core or a Helmholtz machine or something that gives you samples from the data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4157" target="_blank">01:09:17.980</a></span> | <span class="t">The discriminator, D, is going to be discriminating between a sample from the data distribution</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4164" target="_blank">01:09:24.380</a></span> | <span class="t">and a sample from the generator.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4166" target="_blank">01:09:26.780</a></span> | <span class="t">So the goal of the discriminator is to basically say, is this a fake sample or is this a real</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4172" target="_blank">01:09:32.020</a></span> | <span class="t">sample?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4173" target="_blank">01:09:33.020</a></span> | <span class="t">A fake sample is a sample generated by the model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4176" target="_blank">01:09:36.260</a></span> | <span class="t">A real sample is what you see in your data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4179" target="_blank">01:09:39.060</a></span> | <span class="t">Can you tell the difference between the two?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4181" target="_blank">01:09:41.860</a></span> | <span class="t">And the generator is going to be trying to fool the discriminator by trying to generate</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4187" target="_blank">01:09:47.100</a></span> | <span class="t">samples that are hard for the discriminator to discriminate.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4190" target="_blank">01:09:50.820</a></span> | <span class="t">So my goal as a generator would be to generate really nice looking digits so that the discriminator</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4196" target="_blank">01:09:56.300</a></span> | <span class="t">wouldn't be able to tell the difference between the simulated and the real.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4200" target="_blank">01:10:00.540</a></span> | <span class="t">That's the key idea.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4202" target="_blank">01:10:02.940</a></span> | <span class="t">And so here is intuitively what that looks like.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4208" target="_blank">01:10:08.540</a></span> | <span class="t">Let's say you have some data, so images of faces.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4213" target="_blank">01:10:13.180</a></span> | <span class="t">I give you an image of a face, and now I have a discriminator that basically says, well,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4217" target="_blank">01:10:17.900</a></span> | <span class="t">if I get a real face, I push it through some function, some differentiable function.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4223" target="_blank">01:10:23.000</a></span> | <span class="t">Think of it as a convolutional neural network or another differentiable function.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4227" target="_blank">01:10:27.140</a></span> | <span class="t">And here I'm outputting one.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4229" target="_blank">01:10:29.260</a></span> | <span class="t">So I want to output one if it's a real sample.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4232" target="_blank">01:10:32.820</a></span> | <span class="t">Then you have a generator, and generator is you have some noise, so input noise.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4237" target="_blank">01:10:37.460</a></span> | <span class="t">Think of it as a Gaussian distribution.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4238" target="_blank">01:10:38.780</a></span> | <span class="t">Think about Helmholtz machines.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4241" target="_blank">01:10:41.220</a></span> | <span class="t">Given some noise, I go through differentiable function, which is your generator, and I generate</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4246" target="_blank">01:10:46.100</a></span> | <span class="t">a sample.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4247" target="_blank">01:10:47.100</a></span> | <span class="t">This is how my sample might look like.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4249" target="_blank">01:10:49.980</a></span> | <span class="t">And then on top of it, I take this sample, I put it into my discriminator, and I say,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4255" target="_blank">01:10:55.260</a></span> | <span class="t">for my discriminator, I want to output zero.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4259" target="_blank">01:10:59.260</a></span> | <span class="t">Because my discriminator will have to say, well, this is fake, and this is real.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4265" target="_blank">01:11:05.140</a></span> | <span class="t">That's the goal.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4266" target="_blank">01:11:06.140</a></span> | <span class="t">And the generator basically says, well, how can I get a sample such that my discriminator</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4272" target="_blank">01:11:12.260</a></span> | <span class="t">is going to be confused, such that the discriminator always outputs one here, because it believes</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4277" target="_blank">01:11:17.260</a></span> | <span class="t">it's a true sample, believes it's coming from the true data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4281" target="_blank">01:11:21.960</a></span> | <span class="t">So now you have these systems.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4283" target="_blank">01:11:23.960</a></span> | <span class="t">So what's the objective?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4286" target="_blank">01:11:26.660</a></span> | <span class="t">The objective is a min-max value function.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4289" target="_blank">01:11:29.740</a></span> | <span class="t">It's a very intuitive objective function that has the following structure.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4295" target="_blank">01:11:35.940</a></span> | <span class="t">You have a discriminator that says, well, this is an expectation with respect to distribution,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4300" target="_blank">01:11:40.740</a></span> | <span class="t">data distribution.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4301" target="_blank">01:11:41.740</a></span> | <span class="t">So this is basically saying, I want to classify any data points that I get from my data as</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4306" target="_blank">01:11:46.420</a></span> | <span class="t">being real.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4308" target="_blank">01:11:48.140</a></span> | <span class="t">So I want this output to be one, because if it's one, the whole thing is going to be zero.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4312" target="_blank">01:11:52.340</a></span> | <span class="t">If it's less than one, it's going to be negative.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4315" target="_blank">01:11:55.780</a></span> | <span class="t">And I really want to maximize it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4317" target="_blank">01:11:57.960</a></span> | <span class="t">And then discriminator is saying, well, any time I generate a sample, whatever samples</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4321" target="_blank">01:12:01.920</a></span> | <span class="t">comes out from my generator, I want to classify it as being fake.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4327" target="_blank">01:12:07.560</a></span> | <span class="t">That's the goal of the discriminator.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4330" target="_blank">01:12:10.600</a></span> | <span class="t">And then there's a generator.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4331" target="_blank">01:12:11.600</a></span> | <span class="t">The generator is sort of the other-- you try to minimize this function, which essentially</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4335" target="_blank">01:12:15.560</a></span> | <span class="t">says, well, generate samples that discriminator would classify as real.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4340" target="_blank">01:12:20.920</a></span> | <span class="t">So I really am going to try to change the parameters of my generator such that this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4346" target="_blank">01:12:26.080</a></span> | <span class="t">would produce zero.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4347" target="_blank">01:12:27.880</a></span> | <span class="t">Oh, sorry.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4349" target="_blank">01:12:29.240</a></span> | <span class="t">So the discriminator would produce one.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4352" target="_blank">01:12:32.280</a></span> | <span class="t">So trying to fool the discriminator.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4356" target="_blank">01:12:36.480</a></span> | <span class="t">And it turns out the optimal strategy for discriminator is this ratio, which is probability</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4360" target="_blank">01:12:40.800</a></span> | <span class="t">of the data divided by the probability of the data plus probability of the model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4364" target="_blank">01:12:44.740</a></span> | <span class="t">And in general, if you succeed in building a good generative model, then probability</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4368" target="_blank">01:12:48.940</a></span> | <span class="t">of the data would be the same as probability of the model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4370" target="_blank">01:12:50.920</a></span> | <span class="t">So discriminator will always be confused to one half.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4376" target="_blank">01:12:56.720</a></span> | <span class="t">And here's one particular-- it seems like a simple idea, but it turns out to work remarkably</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4381" target="_blank">01:13:01.680</a></span> | <span class="t">well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4382" target="_blank">01:13:02.680</a></span> | <span class="t">Here's an architecture called deconvolutional generative adversarial network architecture</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4388" target="_blank">01:13:08.480</a></span> | <span class="t">that takes the code-- this is a random code.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4390" target="_blank">01:13:10.960</a></span> | <span class="t">It's a Gaussian code.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4392" target="_blank">01:13:12.320</a></span> | <span class="t">It passes through a sequence of convolutions, a sequence of deconvolutions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4396" target="_blank">01:13:16.480</a></span> | <span class="t">So given the code, you sort of deconvolve it back to high dimensional image.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4403" target="_blank">01:13:23.080</a></span> | <span class="t">And you train it using adversarial setting.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4405" target="_blank">01:13:25.900</a></span> | <span class="t">This is your sampling.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4407" target="_blank">01:13:27.320</a></span> | <span class="t">You generate the image.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4408" target="_blank">01:13:28.760</a></span> | <span class="t">And then there is a discriminator, which is just a convolutional neural network that's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4411" target="_blank">01:13:31.720</a></span> | <span class="t">trying to say, is that real?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4413" target="_blank">01:13:33.040</a></span> | <span class="t">Is that a fake?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4414" target="_blank">01:13:34.200</a></span> | <span class="t">And if you train these models on bedrooms-- these are called L-SUN data sets, a bunch</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4419" target="_blank">01:13:39.820</a></span> | <span class="t">of bedrooms-- this is how samples from the model would look like, which is pretty impressive.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4426" target="_blank">01:13:46.200</a></span> | <span class="t">And in fact, when I look at these samples, I'm also sort of thinking, well, maybe the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4429" target="_blank">01:13:49.840</a></span> | <span class="t">model is memorizing the data, because these samples look remarkably impressive.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4435" target="_blank">01:13:55.840</a></span> | <span class="t">Then there was a follow up work.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4437" target="_blank">01:13:57.900</a></span> | <span class="t">These are samples from the CFAR data set.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4441" target="_blank">01:14:01.320</a></span> | <span class="t">So here you're seeing training samples.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4444" target="_blank">01:14:04.040</a></span> | <span class="t">And here you're seeing samples generated from the model, which is, again, very impressive.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4449" target="_blank">01:14:09.400</a></span> | <span class="t">If you look at the structure in these samples, it's quite remarkable that you can generate</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4454" target="_blank">01:14:14.000</a></span> | <span class="t">samples that look very realistic, actually.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4460" target="_blank">01:14:20.840</a></span> | <span class="t">This is what's done-- again, this was done by Tim Salomon and his collaborators.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4466" target="_blank">01:14:26.580</a></span> | <span class="t">If you look at the ImageNet and you look at the training data on the ImageNet and looking</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4471" target="_blank">01:14:31.040</a></span> | <span class="t">at the samples, again, you look-- this is a horse.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4473" target="_blank">01:14:33.800</a></span> | <span class="t">This is like-- there's some animal that is an airplane and so forth.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4478" target="_blank">01:14:38.000</a></span> | <span class="t">There's like some kind of a truck and such.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4481" target="_blank">01:14:41.520</a></span> | <span class="t">So it looks-- when I look at these images, I was very impressed by the quality of these</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4487" target="_blank">01:14:47.800</a></span> | <span class="t">images, because generally, it's very, very hard to generate realistic looking images.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4492" target="_blank">01:14:52.120</a></span> | <span class="t">And the last thing I want to point out-- this was picked up by Ian Goodfellow.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4498" target="_blank">01:14:58.100</a></span> | <span class="t">If you cherry pick some of the examples, this is what generated images look like.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4502" target="_blank">01:15:02.920</a></span> | <span class="t">So you can sort of see there is a little bit of interesting structure that you're seeing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4509" target="_blank">01:15:09.280</a></span> | <span class="t">in these samples.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4512" target="_blank">01:15:12.040</a></span> | <span class="t">And one question still remains with these models is, how can we evaluate these models</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4517" target="_blank">01:15:17.600</a></span> | <span class="t">properly?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4518" target="_blank">01:15:18.600</a></span> | <span class="t">Is the model really learning a space of all possible images and how images-- what's the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4524" target="_blank">01:15:24.640</a></span> | <span class="t">coherency in those images?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4526" target="_blank">01:15:26.280</a></span> | <span class="t">Or is the model mostly kind of like blurring things around and just making some small changes</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4532" target="_blank">01:15:32.040</a></span> | <span class="t">to the data?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4533" target="_blank">01:15:33.040</a></span> | <span class="t">So the question that I would really want-- would like to answer-- to get an answer to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4537" target="_blank">01:15:37.200</a></span> | <span class="t">is that, if I show you a new example, a new test image, a new kind of a horse, would the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4542" target="_blank">01:15:42.480</a></span> | <span class="t">model say, yes, this is a likely image?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4545" target="_blank">01:15:45.480</a></span> | <span class="t">This is very probable images.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4547" target="_blank">01:15:47.120</a></span> | <span class="t">I've seen similar images before or something like that or not.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4551" target="_blank">01:15:51.760</a></span> | <span class="t">So that still remains an open question.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4554" target="_blank">01:15:54.600</a></span> | <span class="t">But again, this is the class of models which steps away from maximum likelihood estimation,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4558" target="_blank">01:15:58.960</a></span> | <span class="t">sort of sets it up in a game theoretic framework, which is a really nice set of work.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4565" target="_blank">01:16:05.800</a></span> | <span class="t">And in the computer vision community, a lot of people are showing a lot of progress in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4568" target="_blank">01:16:08.920</a></span> | <span class="t">using these kinds of models because they tend to generate much more realistic-looking images.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4575" target="_blank">01:16:15.760</a></span> | <span class="t">So let me just summarize to say that I've shown you, hopefully, a set of learning algorithms</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4581" target="_blank">01:16:21.160</a></span> | <span class="t">for deep unsupervised models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4583" target="_blank">01:16:23.560</a></span> | <span class="t">There's a lot of space in these models, a lot of excitement in that space.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4587" target="_blank">01:16:27.640</a></span> | <span class="t">And I just wanted to point out that these models, the deep models, they improve upon</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4591" target="_blank">01:16:31.120</a></span> | <span class="t">current state of the art in a lot of different application domains.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4594" target="_blank">01:16:34.400</a></span> | <span class="t">And as I mentioned before, there's been a lot of progress in discriminative models,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4598" target="_blank">01:16:38.440</a></span> | <span class="t">convolutional models, using recurrent neural networks for solving action recognition models,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4603" target="_blank">01:16:43.680</a></span> | <span class="t">dealing with videos.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4605" target="_blank">01:16:45.280</a></span> | <span class="t">And unsupervised learning still remains a field where we've made some progress, but</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4613" target="_blank">01:16:53.320</a></span> | <span class="t">there's still a lot of progress to be made.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4616" target="_blank">01:16:56.560</a></span> | <span class="t">And let me stop there.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4618" target="_blank">01:16:58.400</a></span> | <span class="t">So thank you.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4619" target="_blank">01:16:59.400</a></span> | <span class="t">[APPLAUSE]</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4619" target="_blank">01:16:59.400</a></span> | <span class="t">Go to the mics.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4641" target="_blank">01:17:21.880</a></span> | <span class="t">So as a Bayesian guy, I'm pretty depressed by the fact that GAN can generate a clearer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4648" target="_blank">01:17:28.760</a></span> | <span class="t">image than the variational autoencoder.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4651" target="_blank">01:17:31.160</a></span> | <span class="t">So my question is, do you think there could be an energy-based framework or a probabilistic</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4657" target="_blank">01:17:37.640</a></span> | <span class="t">interpretation of why GAN is so successful, other than it's just a MiMAX game?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4663" target="_blank">01:17:43.240</a></span> | <span class="t">I think that generally, if you look at-- I sort of go back and forth between variational</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4667" target="_blank">01:17:47.520</a></span> | <span class="t">autoencoders, because some of my friends at OpenAI are saying that they can actually generate</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4672" target="_blank">01:17:52.960</a></span> | <span class="t">really nice-looking images using variational autoencoders.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4677" target="_blank">01:17:57.320</a></span> | <span class="t">I'm looking at Peter here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4679" target="_blank">01:17:59.440</a></span> | <span class="t">But I think that one of the problems with image generation today is that with variational</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4686" target="_blank">01:18:06.440</a></span> | <span class="t">autoencoders, there is this notion of Gaussian loss function.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4691" target="_blank">01:18:11.320</a></span> | <span class="t">And what it does is it basically says, well, never produce crystal-clear images, because</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4697" target="_blank">01:18:17.760</a></span> | <span class="t">if you're wrong, if you put the edge in the wrong place, you're going to be penalized</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4702" target="_blank">01:18:22.760</a></span> | <span class="t">a lot because of the L2 loss function.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4706" target="_blank">01:18:26.800</a></span> | <span class="t">What the GANs are doing, GANs are basically saying, well, I don't really care where I</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4710" target="_blank">01:18:30.720</a></span> | <span class="t">put the edge, as long as it looks realistic so that I can fool my classifier.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4715" target="_blank">01:18:35.000</a></span> | <span class="t">So what tends to happen in practice, and a lot of times, if you actually look at the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4718" target="_blank">01:18:38.880</a></span> | <span class="t">images generated by GANs, sometimes they have a lot of artifacts, like these specific things</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4723" target="_blank">01:18:43.920</a></span> | <span class="t">that pop up.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4727" target="_blank">01:18:47.240</a></span> | <span class="t">Whereas in variational autoencoders, you don't see that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4729" target="_blank">01:18:49.560</a></span> | <span class="t">But again, the problem with variational autoencoders is they tend to produce images that are much</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4732" target="_blank">01:18:52.840</a></span> | <span class="t">more diffused or not as sharp or not as clear as what GANs is doing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4738" target="_blank">01:18:58.080</a></span> | <span class="t">And there's been some work on trying to sharpen the images, which is you're using variational</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4742" target="_blank">01:19:02.120</a></span> | <span class="t">autoencoders to generate the globally coherent scene, and then you're using generative adversarialness</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4747" target="_blank">01:19:07.960</a></span> | <span class="t">to maybe sharpen it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4750" target="_blank">01:19:10.120</a></span> | <span class="t">Again, it depends what loss function you're using.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4753" target="_blank">01:19:13.400</a></span> | <span class="t">And GANs seem to be able to deal with that problem implicitly, because they don't really</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4758" target="_blank">01:19:18.240</a></span> | <span class="t">care whether you get the edge quite right or not, as long as it fools your classifier.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4765" target="_blank">01:19:25.400</a></span> | <span class="t">Thank you.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4766" target="_blank">01:19:26.400</a></span> | <span class="t">Hi.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4767" target="_blank">01:19:27.400</a></span> | <span class="t">Thank you very much for the interesting talk.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4771" target="_blank">01:19:31.440</a></span> | <span class="t">I have a question about the variational autoencoder.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4777" target="_blank">01:19:37.760</a></span> | <span class="t">For the more challenging data set, like the street view house number, I noticed that many</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4782" target="_blank">01:19:42.920</a></span> | <span class="t">implementation, they use a PCA to preprocess the data before they train the model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4788" target="_blank">01:19:48.720</a></span> | <span class="t">What is your thought on that preprocessing step?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4792" target="_blank">01:19:52.120</a></span> | <span class="t">Why is it necessary to do that?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4794" target="_blank">01:19:54.080</a></span> | <span class="t">Why don't we just learn from the raw pixel?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4797" target="_blank">01:19:57.040</a></span> | <span class="t">I actually don't know.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4799" target="_blank">01:19:59.880</a></span> | <span class="t">My experience has been that we don't really do a lot of preprocessing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4803" target="_blank">01:20:03.640</a></span> | <span class="t">What you can do is you can do ZCA preprocessing, and you can take the mean, you can take the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4807" target="_blank">01:20:07.560</a></span> | <span class="t">second order covariance structure from the data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4810" target="_blank">01:20:10.680</a></span> | <span class="t">That sometimes helps, sometimes it doesn't.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4813" target="_blank">01:20:13.000</a></span> | <span class="t">But I don't see any particular reason why you'd want to do PCA preprocessing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4817" target="_blank">01:20:17.400</a></span> | <span class="t">It's just one of-- just like we've seen a lot in our field, people just doing x, y,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4824" target="_blank">01:20:24.760</a></span> | <span class="t">and then later on they figure out that they don't really need x and y.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4830" target="_blank">01:20:30.200</a></span> | <span class="t">Maybe it was working better for their implementation, for their particular task, but generally I</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4833" target="_blank">01:20:33.760</a></span> | <span class="t">haven't seen people doing a lot of preprocessing using PCA for training variational timecodes.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4846" target="_blank">01:20:46.520</a></span> | <span class="t">Any more questions?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4847" target="_blank">01:20:47.520</a></span> | <span class="t">Yes, there's one.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4849" target="_blank">01:20:49.520</a></span> | <span class="t">This is regarding binary RBMs.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4855" target="_blank">01:20:55.240</a></span> | <span class="t">So if you look at the literature for, let us say, estimation of the partition function</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4860" target="_blank">01:21:00.780</a></span> | <span class="t">for Ising models, you will see that the literature is a lot more rich compared to the variational</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4866" target="_blank">01:21:06.520</a></span> | <span class="t">inference literature for restricted Boltzmann machines, especially in the binary context.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4870" target="_blank">01:21:10.600</a></span> | <span class="t">Is there a cultural reason for this?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4872" target="_blank">01:21:12.200</a></span> | <span class="t">Because specifically, you have for the strictly ferromagnetic case, you have a fully polynomial</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4878" target="_blank">01:21:18.680</a></span> | <span class="t">time approximation scheme for estimating the log partition function.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4884" target="_blank">01:21:24.080</a></span> | <span class="t">But then I don't see usage of these FPRAS algorithms in the RBM space.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4889" target="_blank">01:21:29.640</a></span> | <span class="t">So when you juxtapose the literature for the Ising models compared to binary RBMs, you'll</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4895" target="_blank">01:21:35.260</a></span> | <span class="t">find a very stark asymmetry.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4896" target="_blank">01:21:36.980</a></span> | <span class="t">Is there a reason for this?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4898" target="_blank">01:21:38.260</a></span> | <span class="t">Yeah, so the thing about Ising models is that if you're in a ferromagnetic case, or if you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4905" target="_blank">01:21:45.100</a></span> | <span class="t">have certain particular structure to the Ising models, you can use a lot of techniques.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4908" target="_blank">01:21:48.420</a></span> | <span class="t">Even if you use techniques like coupling from the past, you can draw exact samples from</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4911" target="_blank">01:21:51.220</a></span> | <span class="t">the models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4912" target="_blank">01:21:52.560</a></span> | <span class="t">You can compute the log partition function of polynomial time if you have a specific</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4915" target="_blank">01:21:55.460</a></span> | <span class="t">structure.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4916" target="_blank">01:21:56.460</a></span> | <span class="t">But the problem with RBMs is that generally those assumptions don't apply.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4920" target="_blank">01:22:00.360</a></span> | <span class="t">You cannot learn a model which is a ferromagnetic model with RBMs, just where all your weights</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4923" target="_blank">01:22:03.980</a></span> | <span class="t">are positive.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4924" target="_blank">01:22:04.980</a></span> | <span class="t">That's a lot of constraints to put on these class of models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4928" target="_blank">01:22:08.820</a></span> | <span class="t">So that's why-- and once you get outside of these assumptions, then the problem becomes</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4934" target="_blank">01:22:14.740</a></span> | <span class="t">NP-hard for estimating the partition function.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4937" target="_blank">01:22:17.980</a></span> | <span class="t">And obviously, for learning these systems, you need the gradient of the log of the partition</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4940" target="_blank">01:22:20.940</a></span> | <span class="t">function.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4942" target="_blank">01:22:22.060</a></span> | <span class="t">And that's where all the problems come in.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4943" target="_blank">01:22:23.380</a></span> | <span class="t">I don't think there is a solution for that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4947" target="_blank">01:22:27.300</a></span> | <span class="t">And unfortunately, variational methods are also not working as well as approximations</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4953" target="_blank">01:22:33.180</a></span> | <span class="t">like contrastive divergence, or something based on sampling.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4957" target="_blank">01:22:37.660</a></span> | <span class="t">People have looked at better approximations and using more sophisticated techniques, but</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4961" target="_blank">01:22:41.340</a></span> | <span class="t">it hasn't really popped up yet.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4963" target="_blank">01:22:43.620</a></span> | <span class="t">Practically, it just doesn't work as well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4966" target="_blank">01:22:46.580</a></span> | <span class="t">But it's a good question.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4969" target="_blank">01:22:49.580</a></span> | <span class="t">Hello.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4970" target="_blank">01:22:50.580</a></span> | <span class="t">I'm curious about using auto-coder to get semantic hash, especially in text.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4980" target="_blank">01:23:00.340</a></span> | <span class="t">Do we need any special representation, text representation, like word to vector as input</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4987" target="_blank">01:23:07.620</a></span> | <span class="t">for our text sequence?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4991" target="_blank">01:23:11.100</a></span> | <span class="t">So I've talked about the model, which is a very simple model, which is modeling bag of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4995" target="_blank">01:23:15.580</a></span> | <span class="t">words.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4996" target="_blank">01:23:16.580</a></span> | <span class="t">Yes.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=4997" target="_blank">01:23:17.580</a></span> | <span class="t">You can use word2vec and initialize the model, because it's a way of just taking your words</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=5002" target="_blank">01:23:22.100</a></span> | <span class="t">and projecting them into the semantic space.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=5005" target="_blank">01:23:25.460</a></span> | <span class="t">There has been a lot of recent techniques using, like Richard was mentioning, GRUs as</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=5011" target="_blank">01:23:31.300</a></span> | <span class="t">a way, if you want to work with sentences, or if you want to embed the entire document</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=5016" target="_blank">01:23:36.340</a></span> | <span class="t">into the semantic space, and if you want to make it binary, you can use GRUs, bidirectional</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=5021" target="_blank">01:23:41.780</a></span> | <span class="t">GRUs, to get the representation of the document.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=5024" target="_blank">01:23:44.580</a></span> | <span class="t">I think that would probably work better than using word2vec and then just adding things</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=5027" target="_blank">01:23:47.300</a></span> | <span class="t">up.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=5028" target="_blank">01:23:48.300</a></span> | <span class="t">And then based on that, you can learn a hashing function that maps that particular representation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=5032" target="_blank">01:23:52.140</a></span> | <span class="t">to the binary space, in which case you can do searching fairly efficiently.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=5037" target="_blank">01:23:57.340</a></span> | <span class="t">So as an input representation, there are lots of choices.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=5039" target="_blank">01:23:59.700</a></span> | <span class="t">You can use bidirectional GRUs, which is the method of choice right now.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=5046" target="_blank">01:24:06.940</a></span> | <span class="t">You can use GloVe, or you can use word2vec and sum up the representations of the words.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=5054" target="_blank">01:24:14.100</a></span> | <span class="t">Okay, so using only back of word, we use only normal network, that is no recurrence network,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=5060" target="_blank">01:24:20.620</a></span> | <span class="t">or just simple network?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=5062" target="_blank">01:24:22.300</a></span> | <span class="t">Yeah, that's right.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=5063" target="_blank">01:24:23.300</a></span> | <span class="t">But again, your representation can be whatever that representation is, as long as it's differentiable,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=5066" target="_blank">01:24:26.820</a></span> | <span class="t">right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=5067" target="_blank">01:24:27.820</a></span> | <span class="t">Because in this case, you can back propagate through the bidirectional GRUs and learn what</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=5074" target="_blank">01:24:34.900</a></span> | <span class="t">these representations should be.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=5075" target="_blank">01:24:35.900</a></span> | <span class="t">Okay, thank you so much.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=5076" target="_blank">01:24:36.900</a></span> | <span class="t">Okay, let's thank Russ again.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rK6bchqeaN8&t=5081" target="_blank">01:24:41.900</a></span> | <span class="t">(audience applauding)</span></div></div></body></html>