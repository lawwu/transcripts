<html><head><title>Nick Bostrom: Experience Machine | AI Podcast Clips</title></head><body><a href="index.html">back to index</a><h2>Nick Bostrom: Experience Machine | AI Podcast Clips</h2><a href="https://www.youtube.com/watch?v=Iy6he5RNXY0"><img src="https://i.ytimg.com/vi_webp/Iy6he5RNXY0/maxresdefault.webp" style="width:50%;"></a><div><br></div><div style="text-align: left;"><a href="./Iy6he5RNXY0.html">Whisper Transcript</a> | <a href="./transcript_Iy6he5RNXY0.html">Transcript Only Page</a></div><br><h3>Transcript</h3><div style="max-width: 600px;"><p>I mean, in philosophy, there's this experience machine, thought experiment. Have you come across this? So Robert Nozick had this thought experiment where you imagine some crazy, super-duper neuroscientist of the future have created a machine that could give you any experience you want if you step in there. And for the rest of your life, you can kind of pre-programmed it in different ways. So your fondest dreams could come true. You could, whatever you dream, you want to be a great artist, a great lover, like have a wonderful life, all of these things. If you step into the experience machine, will be your experiences constantly happy. But you would kind of disconnect from the rest of reality and you would float there in a tank. And so Nozick thought that most people would choose not to enter the experience machine. I mean, many might want to go there for a holiday, but they wouldn't want to sort of check out of existence permanently. And so he thought that was an argument against certain views of value, according to what we value is a function of what we experience. Because in the experience machine, you could have any experience you want, and yet many people would think that would not be much value. So therefore, what we value depends on other things than what we experience. So okay, can you take that argument further? What about the fact that maybe what we value is the up and down of life? You could have up and downs in the experience machine, right? But what can't you have in the experience machine? Well, I mean, that then becomes an interesting question to explore. But for example, real connection with other people, if the experience machine is a solo machine where it's only you, that's something you wouldn't have there. You would have this subjective experience that would be like fake people. But if you gave somebody flowers, that wouldn't be anybody there who actually got happy. It would just be a little simulation of somebody smiling. But the simulation would not be the kind of simulation I'm talking about in the simulation argument where the simulated creature is conscious. It would just be a kind of smiley face that would look perfectly real to you. So we're now drawing a distinction between appear to be perfectly real and actually being real. Yeah. So that could be one thing. I mean, like a big impact on history, maybe it's also something you won't have if you check into this experience machine. So some people might actually feel the life I want to have for me is one where I have a big positive impact on how history unfolds. So you could kind of explore these different possible explanations for why it is you wouldn't want to go into the experience machine if that's what you feel. And one interesting observation regarding this Nozick thought experiment and the conclusions he wanted to draw from it is how much is a kind of a status quo effect. So a lot of people might not want to get this on current reality to plug into this dream machine. But if they instead were told, well, what you've experienced up to this point was a dream now, do you want to disconnect from this and enter the real world when you have no idea maybe what the real world is? Or maybe you could say, well, you're actually a farmer in Peru, growing peanuts and you could live for the rest of your life in this. Or would you want to continue your dream life as Alex Friedman, going around the world, making podcasts and doing research? So if the status quo was that they were actually in the experience machine, I think a lot of people might then prefer to live the life that they are familiar with rather than sort of bail out into. So essentially the change itself, the leap. Yeah. So it might not be so much the reality itself that we are after, but it's more that we are maybe involved in certain projects and relationships. And we have a self-identity and these things that our values are kind of connected with carrying that forward. And then whether it's inside a tank or outside a tank in Peru, or whether inside a computer or outside a computer, that's kind of less important to what we ultimately care about. Yeah. But still, just to linger on it, it is interesting. I find maybe people are different, but I find myself quite willing to take the leap to the farmer in Peru, especially as the virtual reality system become more realistic. I find that possibility, and I think more people would take that leap. But in this thought experiment, just to make sure we are on the same, so in this case, the farmer in Peru would not be a virtual reality. That would be the real, your life, like before this whole experience machine started. Well, I kind of assumed from that description, you're being very specific, but that kind of idea just like washes away the concept of what's real. I'm still a little hesitant about your kind of distinction between real and illusion, because when you can have an illusion that feels, I mean, that looks real, I don't know how you can definitively say something is real or not, what's a good way to prove that something is real in that context? Well, so I guess in this case, it's more a stipulation. In one case, you're floating in a tank with these wires by the super duper neuroscientists plugging into your head, giving you like Friedman experiences. In the other, you're actually tilling the soil in Peru, growing peanuts, and then those peanuts are being eaten by other people all around the world who buy the exports. So there's two different possible situations in the one and the same real world that you could choose to occupy. Just to be clear, when you're in a vat with wires and the neuroscientists, you can still go farming in Peru, right? No, well, if you wanted to, you could have the experience of farming in Peru, but there wouldn't actually be any peanuts grown. Well, but what makes a peanut? So a peanut could be grown, and you could feed things with that peanut. And why can't all of that be done in a simulation? I hope, first of all, that they actually have peanut farms in Peru. I guess we'll get a lot of comments otherwise from Angry. I was with you up to the point when you started talking about Peru. You should know you can't grow peanuts in that climate. No, I mean, in the simulation, I think there's a sense, the important sense in which it would all be real. Nevertheless, there is a distinction between inside a simulation and outside a simulation, or in the case of NOCIC thought experiment, whether you're in the vat or outside the vat. And some of those differences may or may not be important. I mean, that comes down to your values and preferences. So if the experience machine only gives you the experience of growing peanuts, but you're the only one in the experience machines. No, but there's other, you can, within the experience machine, others can plug in. Well, there are versions of the experience machine. So in fact, you might want to have distinguished thought experiments, different versions of it. So in the original thought experiment, maybe it's only you, right? It's you. So, and you think, I wouldn't want to go in there. Well, that tells you something interesting about what you value and what you care about. Then you could say, well, what if you add the fact that there would be other people in there and you would interact with them? Well, it starts to make it more attractive, right? Then you could add in, well, what if you could also have important long-term effects on human history and the world, and you could actually do something useful, even though you were in there that makes it maybe even more attractive. Like you could actually have a life that had a purpose and consequences. So as you sort of add more into it, it becomes more similar to the baseline reality that you were comparing it to. Yeah, but I just think inside the experience machine, and without taking those steps you just mentioned, you still have an impact on long-term history of the creatures that live inside that, of the quote-unquote fake creatures that live inside that experience machine. And that, like at a certain point, if there's a person waiting for you inside that experience machine, maybe your newly found wife, and she dies, she has fear, she has hopes, and she exists in that machine. When you unplug yourself and plug back in, she's still there going on about her life and- Well, in that case, yeah, she starts to have more of an independent existence. Independent existence. But it depends, I think, on how she's implemented in the experience machine. Take one limit case where all she is is a static picture on the wall, a photograph. So you think, well, I can look at her, but that's it. There's no... But then you think, well, it doesn't really matter much what happens to that, any more than a normal photograph. If you tear it up, it means you can't see it anymore, but you haven't harmed the person whose picture you tore up. But if she's actually implemented, say, at a neural level of detail, so that she's a fully realized digital mind with the same behavioral repertoire as you have, then very possibly she would be a conscious person like you are. And then what you do in this experience machine would have real consequences for how this other mind felt. So you have to specify which of these experience machines you're talking about. I think it's not entirely obvious that it would be possible to have an experience machine that gave you a normal set of human experiences, which include experiences of interacting with other people, without that also generating consciousnesses corresponding to those other people. That is, if you create another entity that you perceive and interact with, that to you looks entirely realistic. Not just when you say hello, they say hello back, but you have a rich interaction, many days, deep conversations. It might be that the only possible way of implementing that would be one that also has a side effect, instantiated this other person in enough detail that you would have a second consciousness there. I think that's to some extent an open question. So you don't think it's possible to fake consciousness and fake intelligence? Well, it might be. I mean, I think you can certainly fake... If you have a very limited interaction with somebody, you could certainly fake that. If all you have to go on is somebody said hello to you, that's not enough for you to tell whether that was a real person there or a pre-recorded message or a very superficial simulation that has no consciousness. Because that's something easy to fake. We could already fake it now. You can record a voice recording. But if you have a richer set of interactions where you're allowed to ask open-ended questions and probe from different angles, you couldn't give canned answer to all of the possible ways that you could probe it, then it starts to become more plausible that the only way to realize this thing in such a way that you would get the right answer from any which angle you probed it would be a way of instantiating it where you also instantiated a conscious mind.</p></div></body></html>