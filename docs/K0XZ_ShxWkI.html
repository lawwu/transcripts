<html><head><title>GPT- 4.5 Gossip Crushed But a 100T Transformer Model Coming? Plus ByteDance + the Mixtral Price Drop</title>
<style>
    body {
        font-family: Arial, sans-serif;
        margin: 0;
        padding: 0;
        background-color: #f4f4f4;
        color: #333;
    }
    .container {
        width: 95%;  /* Increased width to use more space */
        margin: auto;
        overflow: auto;  /* Added to handle overflow by adding a scrollbar if necessary */
    }
    h2, h3 {
        color: #333;
        text-align: center;
    }
    a {
        color: #0000FF;  /* Traditional blue color for links */
        text-decoration: none;
    }
    a:hover {
        text-decoration: underline;
    }
    img {
        display: block;
        margin: auto;
        max-width: 100%;
    }
    .c {
        margin: 10px 0;
    }
    .s, .t {
        display: inline-block;
        margin-right: 5px;
    }
    .max-width {
        max-width: 800px;
        margin: auto;
        padding-left: 20px;
    }
    table {
        width: 100%;
        border-collapse: collapse;
    }
    th, td {
        border: 1px solid #ddd;
        padding: 8px;
        text-align: left;  /* Ensure text alignment is consistent */
    }
    tr:nth-child(even) {
        background-color: #f2f2f2;
    }
    tr:nth-child(odd) {
        background-color: #e6e6e6;
    }
</style>

    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-69VLBMTTP0"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-69VLBMTTP0');
    </script>
    </head><body><div class='container'><a href="index.html">back to index</a><h2>GPT- 4.5 Gossip Crushed But a 100T Transformer Model Coming? Plus ByteDance + the Mixtral Price Drop</h2><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI"><img src="https://i.ytimg.com/vi_webp/K0XZ_ShxWkI/maxresdefault.webp" style="width:50%;"></a><div><br></div><div style="text-align: left;"><a href="./K0XZ_ShxWkI.html">Whisper Transcript</a> | <a href="./transcript_K0XZ_ShxWkI.html">Transcript Only Page</a></div><br><div style="max-width: 800px;"><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=0" target="_blank">00:00:00.000</a></span> | <span class="t">With everyone listening to fruits and flowers these days on Twitter/X, it was hard to ignore</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=6" target="_blank">00:00:06.460</a></span> | <span class="t">the GPT 4.5 rumours, especially with those hallucinations in the model itself which I</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=11" target="_blank">00:00:11.800</a></span> | <span class="t">too experienced.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=12" target="_blank">00:00:12.800</a></span> | <span class="t">But now, with denials from 3 OpenAI employees, I was relieved to be able to focus instead</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=19" target="_blank">00:00:19.160</a></span> | <span class="t">on the real news.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=20" target="_blank">00:00:20.640</a></span> | <span class="t">This video is going to cover Etched In Transformers, the Mixed Trial Price Spiral, Mid-Journey</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=25" target="_blank">00:00:25.840</a></span> | <span class="t">V6, and the ByteDance saga with a guest appearance from none other than Sebastian Bubek.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=31" target="_blank">00:00:31.920</a></span> | <span class="t">He's one of the authors of Sparks of AGI and the PHY series of models and I interviewed</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=36" target="_blank">00:00:36.760</a></span> | <span class="t">him less than 36 hours ago.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=39" target="_blank">00:00:39.000</a></span> | <span class="t">But first, let's get to those GPT 4.5 denials.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=41" target="_blank">00:00:41.720</a></span> | <span class="t">Here's Will Depew, a senior member of OpenAI.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=45" target="_blank">00:00:45.120</a></span> | <span class="t">He was asked, "GPT 4.5 Turbo Discovery is legit or no?"</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=49" target="_blank">00:00:49.320</a></span> | <span class="t">He said, "No, it's a very weird and oddly consistent hallucination."</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=53" target="_blank">00:00:53.960</a></span> | <span class="t">Interestingly, someone else then speculated, "I wonder if putting UR GPT 4.5 Turbo in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=58" target="_blank">00:00:58.280</a></span> | <span class="t">the system prompt improves performance?"</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=60" target="_blank">00:01:00.400</a></span> | <span class="t">And he said, "Quite possible.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=62" target="_blank">00:01:02.240</a></span> | <span class="t">That would be quite funny if they've done that even though it's not GPT 4.5."</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=66" target="_blank">00:01:06.640</a></span> | <span class="t">By the way, I don't think they have.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=68" target="_blank">00:01:08.240</a></span> | <span class="t">Next, we have none other than Sam Altman.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=70" target="_blank">00:01:10.520</a></span> | <span class="t">He was asked, strangely by the same guy, "GPT 4.5 leak legit or no?"</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=76" target="_blank">00:01:16.360</a></span> | <span class="t">And he does seem to have an in with OpenAI because he got a response from Sam Altman</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=80" target="_blank">00:01:20.560</a></span> | <span class="t">saying, "Nah."</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=81" target="_blank">00:01:21.560</a></span> | <span class="t">I found that quite funny, all the hype bubble burst in a single three-letter word.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=86" target="_blank">00:01:26.360</a></span> | <span class="t">But just in case there was any doubt, we then get this from Roon.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=90" target="_blank">00:01:30.280</a></span> | <span class="t">He is an OpenAI employee but somewhat undercover.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=93" target="_blank">00:01:33.120</a></span> | <span class="t">Anyway, he said, "You guys need to develop more resistance to crazy AI hype bros.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=98" target="_blank">00:01:38.160</a></span> | <span class="t">There's no 4.5 and if there was, it wouldn't be released silently and if it was released</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=103" target="_blank">00:01:43.120</a></span> | <span class="t">silently, you wouldn't have the API string self-docs as 4.5."</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=107" target="_blank">00:01:47.440</a></span> | <span class="t">And another OpenAI employee replied, "The saddest thing about all of this is that people's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=111" target="_blank">00:01:51.180</a></span> | <span class="t">expectations for a GPT 4.5 are so low.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=114" target="_blank">00:01:54.160</a></span> | <span class="t">I have a suite of questions that I use myself to test every new model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=118" target="_blank">00:01:58.080</a></span> | <span class="t">Their questions mainly focus on mathematics and I tested GPT 4 during the height of the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=122" target="_blank">00:02:02.160</a></span> | <span class="t">hype bubble.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=123" target="_blank">00:02:03.160</a></span> | <span class="t">And no, nothing too significant had changed and that's why I agree with Adrian Ecovets.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=127" target="_blank">00:02:07.320</a></span> | <span class="t">I think we'd notice more of a difference with GPT 4.5."</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=130" target="_blank">00:02:10.560</a></span> | <span class="t">But moving on to real news, what is the Etch Transformer that I mentioned?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=134" target="_blank">00:02:14.440</a></span> | <span class="t">Well, there is very little publicly available information on this, but I've dug up what</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=138" target="_blank">00:02:18.400</a></span> | <span class="t">I could find.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=139" target="_blank">00:02:19.400</a></span> | <span class="t">Essentially, this new company, Etch.ai, claim to have the world's first transformer supercomputer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=145" target="_blank">00:02:25.000</a></span> | <span class="t">One designed from the ground up to run transformers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=147" target="_blank">00:02:27.960</a></span> | <span class="t">The transformer architecture is of course used in large language models, but it's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=151" target="_blank">00:02:31.520</a></span> | <span class="t">also used in computer vision and in audio and multimodal processing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=155" target="_blank">00:02:35.560</a></span> | <span class="t">Anyway, this company claims to have burned in the transformer architecture onto a chip.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=160" target="_blank">00:02:40.600</a></span> | <span class="t">As they say, it's transformers etched into silicon.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=163" target="_blank">00:02:43.920</a></span> | <span class="t">Their custom chip, codename Sohu, which I'll get to in a moment, as you can see, massively</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=168" target="_blank">00:02:48.040</a></span> | <span class="t">outperforms, apparently, NVIDIA's H100 on tokens per second inference.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=173" target="_blank">00:02:53.000</a></span> | <span class="t">Translated, that would allow real-time interaction.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=175" target="_blank">00:02:55.160</a></span> | <span class="t">What I'm going to do at this point, just before continuing with the technical specs,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=178" target="_blank">00:02:58.400</a></span> | <span class="t">is I'm going to give you a bit of background from an article that I think hardly anyone</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=182" target="_blank">00:03:02.080</a></span> | <span class="t">else has read.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=183" target="_blank">00:03:03.080</a></span> | <span class="t">The article describes a pair of 21-year-old Harvard dropouts raising multiple millions</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=189" target="_blank">00:03:09.240</a></span> | <span class="t">to design an AI accelerator chip dedicated to large language model acceleration.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=193" target="_blank">00:03:13.920</a></span> | <span class="t">Basically, a company betting everything on transformers and large language models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=198" target="_blank">00:03:18.520</a></span> | <span class="t">This article came out in May and gets especially interesting towards the middle.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=202" target="_blank">00:03:22.000</a></span> | <span class="t">The two co-founders, seen below, decided to start a chip company to design a more efficient</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=206" target="_blank">00:03:26.800</a></span> | <span class="t">inference architecture for large language models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=209" target="_blank">00:03:29.320</a></span> | <span class="t">Remember, inference isn't about the training of a large language model, it's about generating</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=213" target="_blank">00:03:33.220</a></span> | <span class="t">its outputs.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=214" target="_blank">00:03:34.220</a></span> | <span class="t">Anyway, here's the key quote.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=215" target="_blank">00:03:35.600</a></span> | <span class="t">You can't get the kind of improvements we're getting by being generalized.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=219" target="_blank">00:03:39.280</a></span> | <span class="t">You'll see more of the improvements in a moment, but they go on.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=222" target="_blank">00:03:42.040</a></span> | <span class="t">You have to bet hard on a single architecture.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=225" target="_blank">00:03:45.220</a></span> | <span class="t">Not just on general AI, but on something more specific.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=227" target="_blank">00:03:47.720</a></span> | <span class="t">We think eventually NVIDIA will do this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=229" target="_blank">00:03:49.860</a></span> | <span class="t">We think the opportunity is too big to ignore.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=232" target="_blank">00:03:52.400</a></span> | <span class="t">Later on, we learn that they're betting everything on a particular architecture.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=236" target="_blank">00:03:56.000</a></span> | <span class="t">There are others being tested like Mamba, but they're betting everything on transformers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=240" target="_blank">00:04:00.300</a></span> | <span class="t">The article goes on, "The rapid evolution of workloads in the AI space could spell disaster</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=244" target="_blank">00:04:04.960</a></span> | <span class="t">if etched AI specializes too much."</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=247" target="_blank">00:04:07.200</a></span> | <span class="t">And the co-founder admitted as much, "That's a real risk and I think it's turning off</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=250" target="_blank">00:04:10.760</a></span> | <span class="t">a lot of other people from going down this route, but transformers aren't changing,"</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=254" target="_blank">00:04:14.600</a></span> | <span class="t">he said.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=255" target="_blank">00:04:15.600</a></span> | <span class="t">But if the bet pays off, what does that mean?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=257" target="_blank">00:04:17.500</a></span> | <span class="t">Well, first of all, it could mean 140 times the throughput per dollar.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=261" target="_blank">00:04:21.600</a></span> | <span class="t">Think real-time interactions with models at a very cheap price.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=264" target="_blank">00:04:24.880</a></span> | <span class="t">That's as compared to the NVIDIA H100.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=267" target="_blank">00:04:27.480</a></span> | <span class="t">The website gives the example of real-time voice agents where models built on this etched</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=271" target="_blank">00:04:31.680</a></span> | <span class="t">in architecture could ingest thousands of words in milliseconds.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=275" target="_blank">00:04:35.640</a></span> | <span class="t">None of those awkward pauses between asking your model something using voice.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=279" target="_blank">00:04:39.520</a></span> | <span class="t">And of course, generating many more outputs much more quickly means that you can compare</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=283" target="_blank">00:04:43.640</a></span> | <span class="t">among them and pick the best, just like we do with self-consistency and just like Alphacode</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=288" target="_blank">00:04:48.520</a></span> | <span class="t">2 did.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=289" target="_blank">00:04:49.520</a></span> | <span class="t">And if you don't know about Alphacode 2, do check out my video on Gemini.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=293" target="_blank">00:04:53.040</a></span> | <span class="t">Just quickly though, what might it mean to burn the architecture onto a chip?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=296" target="_blank">00:04:56.680</a></span> | <span class="t">Well, here's the somewhat simplified version.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=299" target="_blank">00:04:59.160</a></span> | <span class="t">Transformers are typically run on general purpose GPUs, which could be used for other</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=303" target="_blank">00:05:03.280</a></span> | <span class="t">things.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=304" target="_blank">00:05:04.280</a></span> | <span class="t">And those GPUs are then optimized through software to run LLMs.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=308" target="_blank">00:05:08.160</a></span> | <span class="t">The etched supercomputers, in contrast, would potentially be dedicated hardware designed</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=313" target="_blank">00:05:13.220</a></span> | <span class="t">from the ground up to run transformers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=315" target="_blank">00:05:15.320</a></span> | <span class="t">Essentially, by etching the transformer architecture directly into the silicon, every transistor</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=319" target="_blank">00:05:19.800</a></span> | <span class="t">could be optimized specifically for transformer computations.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=323" target="_blank">00:05:23.420</a></span> | <span class="t">Like for example, matrix multiplication, which is the core calculation going on in large</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=327" target="_blank">00:05:27.840</a></span> | <span class="t">language models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=328" target="_blank">00:05:28.840</a></span> | <span class="t">So yes, alas, that poem on pomegranates was the result of a ton of multiplications and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=334" target="_blank">00:05:34.880</a></span> | <span class="t">additions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=335" target="_blank">00:05:35.880</a></span> | <span class="t">The plan apparently is to fully open source the software stack.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=339" target="_blank">00:05:39.240</a></span> | <span class="t">And open sourcing the software stack would be a strategic way, in my view, to draw people</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=344" target="_blank">00:05:44.560</a></span> | <span class="t">in to depend on that new hardware.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=346" target="_blank">00:05:46.900</a></span> | <span class="t">And specializing hardware like this could unlock 100x gains if architectures don't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=352" target="_blank">00:05:52.240</a></span> | <span class="t">radically change in the next year.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=353" target="_blank">00:05:53.960</a></span> | <span class="t">Look at the number that they promise.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=355" target="_blank">00:05:55.840</a></span> | <span class="t">It's expansible up to 100 trillion parameter models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=359" target="_blank">00:05:59.720</a></span> | <span class="t">That would be about 60 times the size of GPT-4.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=363" target="_blank">00:06:03.560</a></span> | <span class="t">Or to kind of summarize everything, it's designed from the ground up for GPT-5.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=368" target="_blank">00:06:08.460</a></span> | <span class="t">In terms of dates, it's potentially not that long away with the chip being slated</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=372" target="_blank">00:06:12.780</a></span> | <span class="t">to be available in 2024.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=374" target="_blank">00:06:14.800</a></span> | <span class="t">They say that they're doing a Series A at the beginning of next year, seeking funds.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=379" target="_blank">00:06:19.240</a></span> | <span class="t">They say most investors are skeptical and rightfully so because what they see is a pair</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=383" target="_blank">00:06:23.720</a></span> | <span class="t">of undergrads trying to tackle the semiconductor industry.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=387" target="_blank">00:06:27.680</a></span> | <span class="t">So if all of this is next year, why am I covering it now?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=390" target="_blank">00:06:30.600</a></span> | <span class="t">Well, firstly, because if it works, it would be crazy transformative for generative AI.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=396" target="_blank">00:06:36.040</a></span> | <span class="t">And secondly, let's be honest, if this is the thing that changes the industry, I want</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=400" target="_blank">00:06:40.000</a></span> | <span class="t">you to be able to say that you heard it here first.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=402" target="_blank">00:06:42.400</a></span> | <span class="t">But it's now time for something that's available today.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=405" target="_blank">00:06:45.400</a></span> | <span class="t">That's Mistrial's mixture of experts.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=407" target="_blank">00:06:47.560</a></span> | <span class="t">That's why it's called a Mistrial 8x7 billion parameter model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=411" target="_blank">00:06:51.480</a></span> | <span class="t">It's open sourced and matches or beats GPT-3.5 not only in benchmarks and not just in leaderboards</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=418" target="_blank">00:06:58.120</a></span> | <span class="t">matching GPT-3.5 and beating Gemini Pro, but also more significantly in price.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=423" target="_blank">00:07:03.620</a></span> | <span class="t">A week ago when the Mistrial model was announced, it was $2 per 1 million tokens.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=429" target="_blank">00:07:09.040</a></span> | <span class="t">Hours later, Together Compute dropped the pricing by 70%.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=432" target="_blank">00:07:12.560</a></span> | <span class="t">Days later, it was cut 50% further by Abacus AI to $0.30 per 1 million tokens.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=438" target="_blank">00:07:18.800</a></span> | <span class="t">Then just three days ago, Deep Infra went to $0.27 per million tokens.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=443" target="_blank">00:07:23.680</a></span> | <span class="t">And you can probably see where I'm going here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=445" target="_blank">00:07:25.560</a></span> | <span class="t">What happened?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=446" target="_blank">00:07:26.560</a></span> | <span class="t">Well, the current one provider was offering Mistrial for free for both input and output.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=452" target="_blank">00:07:32.160</a></span> | <span class="t">Models are not only getting more performance at a dramatic rate, they're getting cheaper</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=456" target="_blank">00:07:36.440</a></span> | <span class="t">at an even more dramatic rate.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=458" target="_blank">00:07:38.160</a></span> | <span class="t">Combine the two and it really makes you wonder where we'll be at the end of 2024 for intelligence</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=463" target="_blank">00:07:43.260</a></span> | <span class="t">per dollar.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=464" target="_blank">00:07:44.260</a></span> | <span class="t">How about, for example, GPT-4 level reasoning on a 13 billion parameter model?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=469" target="_blank">00:07:49.280</a></span> | <span class="t">Here's what Sebastian Bubek, one of the lead authors of Sparks of AGI and the PHY series</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=474" target="_blank">00:07:54.480</a></span> | <span class="t">of models, told me just 36 hours ago.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=477" target="_blank">00:07:57.440</a></span> | <span class="t">And it's completely an open question at the moment what kind of capabilities we're going</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=481" target="_blank">00:08:01.240</a></span> | <span class="t">to be able to achieve.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=482" target="_blank">00:08:02.360</a></span> | <span class="t">We don't know.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=483" target="_blank">00:08:03.360</a></span> | <span class="t">But from what I'm seeing in terms of the performance we're able to extract at 1 billion, at 3 billion,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=488" target="_blank">00:08:08.720</a></span> | <span class="t">and what I know of the big models like GPT-4, I think there is room, at least for the reasoning</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=494" target="_blank">00:08:14.180</a></span> | <span class="t">part, to be enabled already at 13 billion parameters.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=498" target="_blank">00:08:18.680</a></span> | <span class="t">He's so driven in this mission to solve reasoning that his eyes aren't even focused on getting</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=503" target="_blank">00:08:23.320</a></span> | <span class="t">LLMs onto a phone.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=505" target="_blank">00:08:25.000</a></span> | <span class="t">That's despite recent news that we can fit up to 10 billion parameters on device as Qualcomm</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=510" target="_blank">00:08:30.160</a></span> | <span class="t">have boasted.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=511" target="_blank">00:08:31.160</a></span> | <span class="t">I thought that you were deliberately targeting around 10 billion to get on a phone, but it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=515" target="_blank">00:08:35.080</a></span> | <span class="t">seems like not.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=516" target="_blank">00:08:36.080</a></span> | <span class="t">No, not necessarily.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=517" target="_blank">00:08:37.080</a></span> | <span class="t">I mean, the bar of being on the phone, I mean, it's a bar that I like.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=521" target="_blank">00:08:41.520</a></span> | <span class="t">But for me personally, it's really more about the scientific quest of what are the minimal</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=527" target="_blank">00:08:47.080</a></span> | <span class="t">ingredients that are needed to achieve a level of intelligence which is similar to something</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=532" target="_blank">00:08:52.200</a></span> | <span class="t">like GPT-4.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=533" target="_blank">00:08:53.200</a></span> | <span class="t">That's a real question to me.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=534" target="_blank">00:08:54.460</a></span> | <span class="t">If you're interested in learning more about the PHY2 series of models, I've done a video</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=538" target="_blank">00:08:58.200</a></span> | <span class="t">on it on my channel.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=539" target="_blank">00:08:59.520</a></span> | <span class="t">And if you're interested in the full Juicy interview, it's on AI Insiders.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=542" target="_blank">00:09:02.880</a></span> | <span class="t">You also get podcasts, exclusive tutorials, and a personal message from me.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=547" target="_blank">00:09:07.380</a></span> | <span class="t">Of course, I appreciate that not everyone can afford the $24 something I think it works</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=551" target="_blank">00:09:11.680</a></span> | <span class="t">out at for the annual sub, so I deeply appreciate you just watching these videos and leaving</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=556" target="_blank">00:09:16.480</a></span> | <span class="t">comments and likes.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=557" target="_blank">00:09:17.680</a></span> | <span class="t">And of course, all the research I do for AI Insiders massively benefits my analysis for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=562" target="_blank">00:09:22.840</a></span> | <span class="t">the main AI Explained channel.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=564" target="_blank">00:09:24.800</a></span> | <span class="t">Two more fun bits though before I go.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=566" target="_blank">00:09:26.800</a></span> | <span class="t">First, ByteDance, a multi-hundred billion dollar company, is apparently secretly using</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=572" target="_blank">00:09:32.320</a></span> | <span class="t">OpenAI's tech to build a competitor.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=574" target="_blank">00:09:34.740</a></span> | <span class="t">They really just don't want to get caught.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=576" target="_blank">00:09:36.920</a></span> | <span class="t">Of course, using the outputs of models like GPT-4 to improve other models has long been</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=582" target="_blank">00:09:42.440</a></span> | <span class="t">known about.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=583" target="_blank">00:09:43.440</a></span> | <span class="t">It's a key technique behind the Orca series of models and indeed the PHY series of models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=587" target="_blank">00:09:47.160</a></span> | <span class="t">Both of those were, of course, in partnership with Microsoft.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=590" target="_blank">00:09:50.120</a></span> | <span class="t">But it's actually against the terms and conditions for other companies to do that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=594" target="_blank">00:09:54.000</a></span> | <span class="t">But as the headline says, the frenzied race to win in generative AI means that even the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=598" target="_blank">00:09:58.520</a></span> | <span class="t">biggest players are cutting corners.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=600" target="_blank">00:10:00.520</a></span> | <span class="t">ByteDance, by the way, are behind TikTok and as the article restates, it's in direct</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=604" target="_blank">00:10:04.800</a></span> | <span class="t">violation of OpenAI's Terms of Service, which state that model output can't be used</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=609" target="_blank">00:10:09.840</a></span> | <span class="t">to "develop any AI models that compete with our products and services."</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=614" target="_blank">00:10:14.520</a></span> | <span class="t">Nevertheless, internal ByteDance documents confirm that the OpenAI API has been relied</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=619" target="_blank">00:10:19.820</a></span> | <span class="t">on to develop its foundational LLM, codenamed Project Seed, apparently during nearly every</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=625" target="_blank">00:10:25.280</a></span> | <span class="t">phase of development, including for training and evaluating the model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=629" target="_blank">00:10:29.600</a></span> | <span class="t">Employees apparently are well aware of the implications and they had plans to whitewash</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=634" target="_blank">00:10:34.280</a></span> | <span class="t">the evidence.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=635" target="_blank">00:10:35.280</a></span> | <span class="t">In response, about 36 hours ago, OpenAI banned ByteDance from ChatGPT due to, and here's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=641" target="_blank">00:10:41.360</a></span> | <span class="t">some irony, possible data theft.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=643" target="_blank">00:10:43.480</a></span> | <span class="t">I invite you to let me know in the comments what you think of all of that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=647" target="_blank">00:10:47.240</a></span> | <span class="t">Now, I did warn you at the start about Twitter rumors, but I'm going to make one slight</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=650" target="_blank">00:10:50.780</a></span> | <span class="t">exception for two reasons.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=652" target="_blank">00:10:52.480</a></span> | <span class="t">First, because it was more of a statement and second, because it comes from the head</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=656" target="_blank">00:10:56.360</a></span> | <span class="t">of research at ByteDance.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=658" target="_blank">00:10:58.120</a></span> | <span class="t">His name is Kuan Kuan Gu and he said this recently, "He's uncertain about GPT-5,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=662" target="_blank">00:11:02.360</a></span> | <span class="t">but a super strong model, more powerful than Gemini, is expected to arrive any time now."</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=667" target="_blank">00:11:07.520</a></span> | <span class="t">You might have thought he meant GPT 4.5, but no.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=670" target="_blank">00:11:10.240</a></span> | <span class="t">He was asked open source and he said, "Open model waits."</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=673" target="_blank">00:11:13.720</a></span> | <span class="t">Is he referring to Project Seed here?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=675" target="_blank">00:11:15.920</a></span> | <span class="t">Well, time will tell.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=677" target="_blank">00:11:17.120</a></span> | <span class="t">And when asked, "When open source catches GPT-4, do you think OpenAI will just wait</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=681" target="_blank">00:11:21.160</a></span> | <span class="t">for that to happen?"</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=682" target="_blank">00:11:22.240</a></span> | <span class="t">He said, "We don't settle for catching up with GPT-4.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=685" target="_blank">00:11:25.460</a></span> | <span class="t">We outpace GPT-5."</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=686" target="_blank">00:11:26.800</a></span> | <span class="t">I'm not holding my breath on Project Seed, but let me know what you think.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=691" target="_blank">00:11:31.280</a></span> | <span class="t">Let me end with this preview images for Midjourney V6.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=696" target="_blank">00:11:36.080</a></span> | <span class="t">Just as I observed with Imogen 2, the real breakthrough for me seems to be the added</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=700" target="_blank">00:11:40.920</a></span> | <span class="t">level of photo realism.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=702" target="_blank">00:11:42.880</a></span> | <span class="t">Of course, I'd love to hear what you think.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=705" target="_blank">00:11:45.080</a></span> | <span class="t">There is still a slight smoothness to them, but when you upscale them using Magnific,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=710" target="_blank">00:11:50.720</a></span> | <span class="t">then the woman, if not the text in the background, looks exceptionally realistic.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=716" target="_blank">00:11:56.060</a></span> | <span class="t">As always, let me know what you think.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=717" target="_blank">00:11:57.760</a></span> | <span class="t">Thank you so much for watching to the end and have a wonderful day.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=K0XZ_ShxWkI&t=721" target="_blank">00:12:01.680</a></span> | <span class="t">(upbeat music)</span></div></div></body></html>