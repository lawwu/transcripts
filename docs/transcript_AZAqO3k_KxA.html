<html><head><title>AI will bring pocket nukes but is still net positive – Tyler Cowen</title>
<style>
    body {
        font-family: Arial, sans-serif;
        margin: 0;
        padding: 0;
        background-color: #f4f4f4;
        color: #333;
    }
    .container {
        width: 95%;  /* Increased width to use more space */
        margin: auto;
        overflow: auto;  /* Added to handle overflow by adding a scrollbar if necessary */
    }
    h2, h3 {
        color: #333;
        text-align: center;
    }
    a {
        color: #0000FF;  /* Traditional blue color for links */
        text-decoration: none;
    }
    a:hover {
        text-decoration: underline;
    }
    img {
        display: block;
        margin: auto;
        max-width: 100%;
    }
    .c {
        margin: 10px 0;
    }
    .s, .t {
        display: inline-block;
        margin-right: 5px;
    }
    .max-width {
        max-width: 800px;
        margin: auto;
        padding-left: 20px;
    }
    table {
        width: 100%;
        border-collapse: collapse;
    }
    th, td {
        border: 1px solid #ddd;
        padding: 8px;
        text-align: left;  /* Ensure text alignment is consistent */
    }
    tr:nth-child(even) {
        background-color: #f2f2f2;
    }
    tr:nth-child(odd) {
        background-color: #e6e6e6;
    }
</style>

    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-69VLBMTTP0"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-69VLBMTTP0');
    </script>
    </head><body><div class='container'><a href="index.html">Back to Index</a><h2>AI will bring pocket nukes but is still net positive – Tyler Cowen</h2><a href="https://www.youtube.com/watch?v=AZAqO3k_KxA" target="_blank"><img src="https://i.ytimg.com/vi_webp/AZAqO3k_KxA/maxresdefault.webp" style="width:50%;"></a><div><br></div><h3>Transcript</h3><div class='max-width'><p>My worry is that energy becomes too cheap and people at very low cost can destroy things rather easily. So say if destroying a city with a nuclear weapon cost $50,000, what would the world look like? I'm just not sure. It might be more stable than we think, but I'm greatly worried and I could readily imagine it falling apart.</p><p>There's uncertainty about a lot of things and AI will help us with those other uncertainties. So Annette, do you think more intelligence is likely to be good or bad, including against x-risk? And I think it's more likely to be good. So if it were the only risk, I'd be more worried about it than if there's a whole multitude of risks.</p><p>But clearly there's a whole multitude of risks. But since people grew up in pretty stable times, they tend not to see that in emotionally vivid terms. And then this one monster comes along and they're all terrified. In this case, the reason the nuke got so cheap was because of intelligence.</p><p>Now that doesn't mean we should stop intelligence, but if that's the end result of intelligence over hundreds of years, that doesn't seem like intelligence is always a net good. Well, we're doing better than the other great apes, I would say, even though we face these really big risks. And in the meantime, we did incredible things.</p><p>So that's a gamble I would take. But I believe we should view it more self-consciously as a sort of gamble. And it's too late to turn back. The fundamental choice was one of decentralization. And that may have happened hundreds of millions or billions of years ago. And once you opt for decentralization, intelligence is going to have advantages and you're not going to be able to turn the clock back on it.</p><p>The risk, not that everyone dies, I think that's quite low, but that we retreat to some kind of pretty chaotic form of like medieval Balkans existence with a much lower population. That seems to me quite a high risk with or without AI. It's probably the default setting. Given that you think that's the default setting.</p><p>Why is that not a big part of your when you're thinking about how new technologies are coming about? Why not consciously think in terms of is this getting us to the outcome where we avoid this sort of pre-industrial state that would result from the $50,000 nukes? Well, if you think the risk is cheap energy more than AI per se, admittedly, AI could speed the path to cheap energy.</p><p>It seems very hard to control the strategy that's worked best so far is to have relatively benevolent nations become hegemons and establish dominance. So it does influence me. I want the US, UK, some other subset of nations to establish dominance in AI. It may not work forever, but in a decentralized world, it sure beats the alternative.</p><p>So a lot of the AI types, they're too rationalist and they don't start with the premise that we chose a decentralized world a very, very long time ago, even way before humans. What would have to be different for you to not be a doomer per se, but just one of these people who this is the main thing to be thinking about during this period of history or something like that?</p><p>Well, I think it is one of the main things we should be thinking about. But I would say if I thought international cooperation were very possible, I would at least possibly have very different views than I do now. Or if I thought no other country could make progress on AI, those seem unlikely to me, but they're not logically impossible.</p><p>So the fundamental premise where I differ from a lot of the doomers is my understanding of a decentralized world and its principles being primary. Their understanding is some kind of comparison, like here's the little people and here's the big monster and the big monster gets bigger. And even if the big monster does a lot of good things, it's just getting bigger and here are the little people.</p><p>That's a possible framework. But if you start with decentralization and competition, you don't just think you can wake up in the morning and like legislate safety. I think you made an interesting point when you were talking about Keynes in the book where you said one of his faults was that he assumed that people like him would always be in charge.</p><p>That's right. And I do see that also in the alignment discourse, like alignment is, you know, if it's just handing over to the government and just assuming the government does what you'd expect it to do. And I worry about this from my own point of view. So even if you think U.S.</p><p>is pretty benevolent today, which is a highly contested and mixed proposition, and I'm an American citizen, pretty patriotic, but I'm fully aware of the long history of my government in killing and slaving, doing other terrible things to people. And then you have to rethink that over a long period of time, it may be the worst time period that affects the final outcome, even if the average is pretty good.</p><p>And then if power corrupts and if government even indirectly controls AI systems, so U.S. government could become worse because it's a leader in AI, right? Yeah. But again, I've got to still take that over China or Russia or wherever else it might be. What's your sense of how the government reacts when the labs are doing, regardless of how they should react, how they will react when the labs are doing, like, I don't know, $10 billion training runs.</p><p>And if under the premise that, you know, these are powerful models, not human level, per se, but just they can do all kinds of crazy stuff. How do you think the government's going to, are they going to nationalize the labs or how are you staying in Washington? What's your sense?</p><p>My guess is until there's sort of an SBF-like incident, which might even not be significant, but a headlines incident, which SBF was, even if it doesn't affect the future evolution of crypto, which I guess is my view, it won't. Until there's that, we won't do much of anything. And then we'll have an SBF-like incident and we'll overreact.</p><p>That seems a very common pattern in American history. And the fact that it's AI, the stakes might be high or whatever, I doubt if it will change the recurrence of that pattern. Yeah. you</p></div></div></body></html>