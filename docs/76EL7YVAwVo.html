<html><head><title>Best of 2024 in Vision [LS Live @ NeurIPS]</title>
<style>
    body {
        font-family: Arial, sans-serif;
        margin: 0;
        padding: 0;
        background-color: #f4f4f4;
        color: #333;
    }
    .container {
        width: 95%;  /* Increased width to use more space */
        margin: auto;
        overflow: auto;  /* Added to handle overflow by adding a scrollbar if necessary */
    }
    h2, h3 {
        color: #333;
        text-align: center;
    }
    a {
        color: #0000FF;  /* Traditional blue color for links */
        text-decoration: none;
    }
    a:hover {
        text-decoration: underline;
    }
    img {
        display: block;
        margin: auto;
        max-width: 100%;
    }
    .c {
        margin: 10px 0;
    }
    .s, .t {
        display: inline-block;
        margin-right: 5px;
    }
    .max-width {
        max-width: 800px;
        margin: auto;
        padding-left: 20px;
    }
    table {
        width: 100%;
        border-collapse: collapse;
    }
    th, td {
        border: 1px solid #ddd;
        padding: 8px;
        text-align: left;  /* Ensure text alignment is consistent */
    }
    tr:nth-child(even) {
        background-color: #f2f2f2;
    }
    tr:nth-child(odd) {
        background-color: #e6e6e6;
    }
</style>

    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-69VLBMTTP0"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-69VLBMTTP0');
    </script>
    </head><body><div class='container'><a href="index.html">back to index</a><h2>Best of 2024 in Vision [LS Live @ NeurIPS]</h2><a href="https://www.youtube.com/watch?v=76EL7YVAwVo"><img src="https://i.ytimg.com/vi_webp/76EL7YVAwVo/maxresdefault.webp" style="width:50%;"></a><div><br></div><div style="text-align: left;"><a href="./76EL7YVAwVo.html">Whisper Transcript</a> | <a href="./transcript_76EL7YVAwVo.html">Transcript Only Page</a></div><br><div style="max-width: 800px;"><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=0" target="_blank">00:00:00.000</a></span> | <span class="t">(upbeat music)</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2" target="_blank">00:00:02.580</a></span> | <span class="t">- Hi, we're Isaac and Peter from Roboflow.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=8" target="_blank">00:00:08.720</a></span> | <span class="t">And we're gonna talk about the best papers</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=11" target="_blank">00:00:11.280</a></span> | <span class="t">of 2024 in computer vision.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=13" target="_blank">00:00:13.520</a></span> | <span class="t">So for us, we define best as what made the biggest shifts</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=19" target="_blank">00:00:19.680</a></span> | <span class="t">in the space.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=21" target="_blank">00:00:21.720</a></span> | <span class="t">And to determine that we looked at</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=23" target="_blank">00:00:23.840</a></span> | <span class="t">what are some major trends that happened</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=26" target="_blank">00:00:26.240</a></span> | <span class="t">and what papers most contributed to those trends.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=29" target="_blank">00:00:29.160</a></span> | <span class="t">So I'm gonna talk about a couple of trends.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=30" target="_blank">00:00:30.280</a></span> | <span class="t">Peter's gonna talk about a trend</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=31" target="_blank">00:00:31.340</a></span> | <span class="t">and then we're gonna hand it off to Moondream.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=34" target="_blank">00:00:34.400</a></span> | <span class="t">So the trends that I'm interested in talking about</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=39" target="_blank">00:00:39.720</a></span> | <span class="t">are a major transition from models</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=42" target="_blank">00:00:42.420</a></span> | <span class="t">that run on per image basis</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=44" target="_blank">00:00:44.080</a></span> | <span class="t">to models that run using the same basic ideas on video.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=48" target="_blank">00:00:48.720</a></span> | <span class="t">And then also how debtors are starting to take over</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=51" target="_blank">00:00:51.760</a></span> | <span class="t">the real-time object detection scene</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=56" target="_blank">00:00:56.360</a></span> | <span class="t">from the YOLOs, which have been dominant for years.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=58" target="_blank">00:00:58.960</a></span> | <span class="t">So as a highlight, we're gonna talk about Sora,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=64" target="_blank">00:01:04.620</a></span> | <span class="t">which from my perspective is the biggest paper of 2024,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=68" target="_blank">00:01:08.120</a></span> | <span class="t">even though it came out in February.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=69" target="_blank">00:01:09.920</a></span> | <span class="t">Yeah, yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=73" target="_blank">00:01:13.460</a></span> | <span class="t">So Sora is just a post.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=76" target="_blank">00:01:16.860</a></span> | <span class="t">So I'm going to fill it in with details</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=80" target="_blank">00:01:20.040</a></span> | <span class="t">from replication efforts, including open Sora</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=82" target="_blank">00:01:22.680</a></span> | <span class="t">and related work such as a stable diffusion video.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=86" target="_blank">00:01:26.600</a></span> | <span class="t">And then we're also gonna talk about SAM2,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=90" target="_blank">00:01:30.040</a></span> | <span class="t">which applies the SAM strategy to video.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=92" target="_blank">00:01:32.880</a></span> | <span class="t">And then how debtors are,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=96" target="_blank">00:01:36.240</a></span> | <span class="t">the improvements in 2024 to debtors</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=97" target="_blank">00:01:37.840</a></span> | <span class="t">that are making them a Pareto improvement</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=99" target="_blank">00:01:39.360</a></span> | <span class="t">to YOLO-based models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=101" target="_blank">00:01:41.120</a></span> | <span class="t">So to start this off,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=104" target="_blank">00:01:44.360</a></span> | <span class="t">we're gonna talk about the state-of-the-art</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=106" target="_blank">00:01:46.960</a></span> | <span class="t">of video generation at the end of 2023.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=110" target="_blank">00:01:50.040</a></span> | <span class="t">MagVIT is a discrete token model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=115" target="_blank">00:01:55.080</a></span> | <span class="t">discrete token video tokenizer akin to VQ, GAN,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=118" target="_blank">00:01:58.960</a></span> | <span class="t">but applied to video sequences.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=121" target="_blank">00:02:01.000</a></span> | <span class="t">And it actually outperforms state-of-the-art</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=125" target="_blank">00:02:05.760</a></span> | <span class="t">handcrafted video compression frameworks</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=128" target="_blank">00:02:08.840</a></span> | <span class="t">in terms of the bit rate versus human preference for quality</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=133" target="_blank">00:02:13.840</a></span> | <span class="t">and videos generated by autoregressing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=135" target="_blank">00:02:15.720</a></span> | <span class="t">on these discrete tokens.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=137" target="_blank">00:02:17.080</a></span> | <span class="t">Generates some pretty nice stuff,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=140" target="_blank">00:02:20.560</a></span> | <span class="t">but up to like five seconds length</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=142" target="_blank">00:02:22.000</a></span> | <span class="t">and you know, not super detailed.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=143" target="_blank">00:02:23.480</a></span> | <span class="t">And then suddenly a few months later, we have this,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=148" target="_blank">00:02:28.480</a></span> | <span class="t">which when I saw it, it was totally mind-blowing to me.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=152" target="_blank">00:02:32.120</a></span> | <span class="t">1080p, a whole minute long.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=154" target="_blank">00:02:34.440</a></span> | <span class="t">We've got light reflecting in puddles.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=156" target="_blank">00:02:36.000</a></span> | <span class="t">That's reflective, reminds me of those RTX demonstrations</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=161" target="_blank">00:02:41.000</a></span> | <span class="t">for next generation video games, such as Cyberpunk,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=164" target="_blank">00:02:44.160</a></span> | <span class="t">but with better graphics.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=166" target="_blank">00:02:46.760</a></span> | <span class="t">You can see some issues in the background</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=168" target="_blank">00:02:48.240</a></span> | <span class="t">if you look closely, but they're kind of,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=170" target="_blank">00:02:50.320</a></span> | <span class="t">as with a lot of these models,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=172" target="_blank">00:02:52.480</a></span> | <span class="t">the issues tend to be things</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=174" target="_blank">00:02:54.120</a></span> | <span class="t">that people aren't going to pay attention to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=175" target="_blank">00:02:55.880</a></span> | <span class="t">unless they're looking for.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=177" target="_blank">00:02:57.040</a></span> | <span class="t">In the same way that like six fingers on a hand,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=179" target="_blank">00:02:59.640</a></span> | <span class="t">you're not going to notice is a giveaway</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=182" target="_blank">00:03:02.320</a></span> | <span class="t">unless you're looking for it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=183" target="_blank">00:03:03.760</a></span> | <span class="t">So yeah, as we said, Sora does not have a paper.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=188" target="_blank">00:03:08.440</a></span> | <span class="t">So we're going to be filling it in with context</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=190" target="_blank">00:03:10.920</a></span> | <span class="t">from the rest of the computer vision scene</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=194" target="_blank">00:03:14.040</a></span> | <span class="t">attempting to replicate these efforts.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=196" target="_blank">00:03:16.440</a></span> | <span class="t">So the first step, you have an LLM caption,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=201" target="_blank">00:03:21.800</a></span> | <span class="t">a huge amount of videos.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=203" target="_blank">00:03:23.120</a></span> | <span class="t">This is a trick that they introduced in Dolly 3</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=208" target="_blank">00:03:28.520</a></span> | <span class="t">where they train a image captioning model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=212" target="_blank">00:03:32.240</a></span> | <span class="t">to just generate very high quality captions</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=214" target="_blank">00:03:34.240</a></span> | <span class="t">for a huge corpus</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=215" target="_blank">00:03:35.360</a></span> | <span class="t">and then train a diffusion model on that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=219" target="_blank">00:03:39.760</a></span> | <span class="t">Their Sora and the replication efforts</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=222" target="_blank">00:03:42.240</a></span> | <span class="t">also show a bunch of other steps</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=224" target="_blank">00:03:44.040</a></span> | <span class="t">that are necessary for good video generation,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=227" target="_blank">00:03:47.480</a></span> | <span class="t">including filtering by aesthetic score</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=230" target="_blank">00:03:50.360</a></span> | <span class="t">and filtering by making sure the videos have enough motion</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=233" target="_blank">00:03:53.320</a></span> | <span class="t">so they're not just like kind of the generators</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=235" target="_blank">00:03:55.960</a></span> | <span class="t">not learning to just generate static frames.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=238" target="_blank">00:03:58.160</a></span> | <span class="t">So then we encode our video</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=244" target="_blank">00:04:04.040</a></span> | <span class="t">into a series of space-time latency.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=246" target="_blank">00:04:06.600</a></span> | <span class="t">Once again, this were very sparse in details.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=249" target="_blank">00:04:09.840</a></span> | <span class="t">So the replication related works,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=253" target="_blank">00:04:13.680</a></span> | <span class="t">OpenSora actually uses a MagVIT V2 itself to do this,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=257" target="_blank">00:04:17.320</a></span> | <span class="t">but swapping out the discretization step</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=261" target="_blank">00:04:21.520</a></span> | <span class="t">with a classic VAE autoencoder framework.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=265" target="_blank">00:04:25.240</a></span> | <span class="t">They show that there's a lot of benefit</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=270" target="_blank">00:04:30.000</a></span> | <span class="t">from getting the temporal compression,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=271" target="_blank">00:04:31.520</a></span> | <span class="t">which makes a lot of sense as each sequential frames</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=275" target="_blank">00:04:35.400</a></span> | <span class="t">and videos have mostly redundant information.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=278" target="_blank">00:04:38.080</a></span> | <span class="t">So by compressing in the temporal space,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=283" target="_blank">00:04:43.640</a></span> | <span class="t">you allow the latent to hold a lot more semantic information</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=287" target="_blank">00:04:47.240</a></span> | <span class="t">while avoiding that duplicate.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=289" target="_blank">00:04:49.800</a></span> | <span class="t">So we've got our space-time latency possibly via,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=298" target="_blank">00:04:58.440</a></span> | <span class="t">there's some 3D VAE, presumably a MagVIT V2.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=302" target="_blank">00:05:02.560</a></span> | <span class="t">And then you throw it into a diffusion transformer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=307" target="_blank">00:05:07.440</a></span> | <span class="t">So I think it's personally interesting to note</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=311" target="_blank">00:05:11.800</a></span> | <span class="t">that OpenSora is using a MagVIT V2,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=314" target="_blank">00:05:14.960</a></span> | <span class="t">which originally used an autoregressive transformer decoder</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=318" target="_blank">00:05:18.680</a></span> | <span class="t">to model the latent space,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=320" target="_blank">00:05:20.200</a></span> | <span class="t">but is now using a diffusion transformer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=325" target="_blank">00:05:25.200</a></span> | <span class="t">So it's still a transformer happening.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=327" target="_blank">00:05:27.360</a></span> | <span class="t">Just the question is like,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=328" target="_blank">00:05:28.200</a></span> | <span class="t">is it parameterizing the stochastic differential equation?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=331" target="_blank">00:05:31.880</a></span> | <span class="t">Is it parameterizing a conditional distribution</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=334" target="_blank">00:05:34.480</a></span> | <span class="t">via autoregression?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=335" target="_blank">00:05:35.680</a></span> | <span class="t">It's also worth noting that most diffusion models today,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=344" target="_blank">00:05:44.520</a></span> | <span class="t">the very high performance ones are switching away</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=346" target="_blank">00:05:46.440</a></span> | <span class="t">from the classic like DDPM,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=348" target="_blank">00:05:48.640</a></span> | <span class="t">denoising diffusion probability modeling framework</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=351" target="_blank">00:05:51.240</a></span> | <span class="t">to rectified flows.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=352" target="_blank">00:05:52.560</a></span> | <span class="t">Rectified flows have a very interesting property</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=356" target="_blank">00:05:56.080</a></span> | <span class="t">that as they converge,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=358" target="_blank">00:05:58.520</a></span> | <span class="t">they actually get closer to being able to be sampled</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=361" target="_blank">00:06:01.480</a></span> | <span class="t">with a single step,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=362" target="_blank">00:06:02.880</a></span> | <span class="t">which means that in practice,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=365" target="_blank">00:06:05.480</a></span> | <span class="t">you can actually generate high quality samples much faster.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=368" target="_blank">00:06:08.440</a></span> | <span class="t">Major problem of DDPM and related models</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=373" target="_blank">00:06:13.640</a></span> | <span class="t">for the past four years is just that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=375" target="_blank">00:06:15.920</a></span> | <span class="t">they require many, many steps</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=378" target="_blank">00:06:18.000</a></span> | <span class="t">to generate high quality samples.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=380" target="_blank">00:06:20.040</a></span> | <span class="t">So, and naturally the third step</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=383" target="_blank">00:06:23.760</a></span> | <span class="t">is throwing lots of compute at the problem.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=386" target="_blank">00:06:26.080</a></span> | <span class="t">So I never figured out how to manage</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=390" target="_blank">00:06:30.520</a></span> | <span class="t">to get this video to loop,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=391" target="_blank">00:06:31.960</a></span> | <span class="t">but we see very little compute,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=396" target="_blank">00:06:36.080</a></span> | <span class="t">medium compute, lots of compute.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=399" target="_blank">00:06:39.120</a></span> | <span class="t">This is so interesting</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=400" target="_blank">00:06:40.000</a></span> | <span class="t">because the original diffusion transformer paper</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=402" target="_blank">00:06:42.480</a></span> | <span class="t">from Facebook actually showed that,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=405" target="_blank">00:06:45.000</a></span> | <span class="t">in fact, the specific hyperparameters of the transformer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=407" target="_blank">00:06:47.400</a></span> | <span class="t">didn't really matter that much.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=409" target="_blank">00:06:49.160</a></span> | <span class="t">What mattered was that you were just increasing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=411" target="_blank">00:06:51.760</a></span> | <span class="t">the amount of compute that the model had.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=414" target="_blank">00:06:54.480</a></span> | <span class="t">So I love how in the, once again, little blog posts,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=419" target="_blank">00:06:59.360</a></span> | <span class="t">they don't even talk about</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=420" target="_blank">00:07:00.200</a></span> | <span class="t">like the specific hyperparameters.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=421" target="_blank">00:07:01.160</a></span> | <span class="t">They say, we're using a diffusion transformer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=423" target="_blank">00:07:03.320</a></span> | <span class="t">and we're just throwing more compute at it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=424" target="_blank">00:07:04.520</a></span> | <span class="t">and this is what happens.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=425" target="_blank">00:07:05.760</a></span> | <span class="t">OpenSORA shows similar results.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=430" target="_blank">00:07:10.520</a></span> | <span class="t">The primary issue I think here is that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=433" target="_blank">00:07:13.920</a></span> | <span class="t">no one else has 32X compute budget.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=437" target="_blank">00:07:17.280</a></span> | <span class="t">So we end up with these,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=438" target="_blank">00:07:18.640</a></span> | <span class="t">we end up in the middle of the domain</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=442" target="_blank">00:07:22.400</a></span> | <span class="t">in most of the related work,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=444" target="_blank">00:07:24.920</a></span> | <span class="t">which is still super, super cool.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=447" target="_blank">00:07:27.400</a></span> | <span class="t">It's just a little disappointing considering the context.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=450" target="_blank">00:07:30.560</a></span> | <span class="t">So I think this is a beautiful extension</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=454" target="_blank">00:07:34.640</a></span> | <span class="t">of the framework that was introduced in '22 and '23</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=460" target="_blank">00:07:40.320</a></span> | <span class="t">for these very high quality per image generation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=463" target="_blank">00:07:43.280</a></span> | <span class="t">and then extending that to videos.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=465" target="_blank">00:07:45.000</a></span> | <span class="t">It's awesome.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=467" target="_blank">00:07:47.600</a></span> | <span class="t">And it's GA as of Monday,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=469" target="_blank">00:07:49.360</a></span> | <span class="t">except no one can seem to get access to it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=471" target="_blank">00:07:51.200</a></span> | <span class="t">because they keep shutting down the login.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=473" target="_blank">00:07:53.640</a></span> | <span class="t">The next, so next paper I wanted to talk about is SAM.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=479" target="_blank">00:07:59.320</a></span> | <span class="t">So we at RoboFlow allow users to label data</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=483" target="_blank">00:08:03.200</a></span> | <span class="t">and train models on that data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=484" target="_blank">00:08:04.680</a></span> | <span class="t">SAM for us has saved our users 75 years of labeling time.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=490" target="_blank">00:08:10.000</a></span> | <span class="t">We are the, to the best of my knowledge,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=491" target="_blank">00:08:11.760</a></span> | <span class="t">the largest SAM API that exists.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=496" target="_blank">00:08:16.320</a></span> | <span class="t">We also, SAM also allows us to have our users</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=499" target="_blank">00:08:19.320</a></span> | <span class="t">train just pure bounding box regression models</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=502" target="_blank">00:08:22.680</a></span> | <span class="t">and use those to generate high quality masks,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=505" target="_blank">00:08:25.600</a></span> | <span class="t">which has the great side effect</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=509" target="_blank">00:08:29.680</a></span> | <span class="t">of requiring less training data</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=511" target="_blank">00:08:31.400</a></span> | <span class="t">to have a meaningful convergence.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=513" target="_blank">00:08:33.160</a></span> | <span class="t">So most people are data limited in the real world.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=515" target="_blank">00:08:35.720</a></span> | <span class="t">So anything that requires less data</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=517" target="_blank">00:08:37.120</a></span> | <span class="t">to get to a useful thing is super useful.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=520" target="_blank">00:08:40.360</a></span> | <span class="t">Most of our users actually run their object,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=524" target="_blank">00:08:44.920</a></span> | <span class="t">per frame object detectors on every frame in a video,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=527" target="_blank">00:08:47.800</a></span> | <span class="t">or maybe not most, but many, many.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=529" target="_blank">00:08:49.600</a></span> | <span class="t">And so SAM follows into this category of taking,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=535" target="_blank">00:08:55.480</a></span> | <span class="t">SAM2 falls into this category of taking</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=537" target="_blank">00:08:57.280</a></span> | <span class="t">something that really, really works</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=539" target="_blank">00:08:59.080</a></span> | <span class="t">and applying it to a video,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=541" target="_blank">00:09:01.880</a></span> | <span class="t">which has the wonderful benefit of being plug and play</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=545" target="_blank">00:09:05.000</a></span> | <span class="t">with most of our, many of our users use cases.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=548" target="_blank">00:09:08.920</a></span> | <span class="t">We're still building out a sufficiently mature pipeline</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=552" target="_blank">00:09:12.800</a></span> | <span class="t">to take advantage of that, but it's in the works.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=555" target="_blank">00:09:15.800</a></span> | <span class="t">So here we've got a great example.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=560" target="_blank">00:09:20.040</a></span> | <span class="t">We can click on cells and then follow them.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=563" target="_blank">00:09:23.520</a></span> | <span class="t">You even notice the cell goes away and comes back</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=565" target="_blank">00:09:25.560</a></span> | <span class="t">and we can still keep track of it,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=568" target="_blank">00:09:28.120</a></span> | <span class="t">which is very challenging for existing object trackers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=576" target="_blank">00:09:36.920</a></span> | <span class="t">High-level overview of how SAM2 works.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=579" target="_blank">00:09:39.440</a></span> | <span class="t">There's a simple pipeline here where we can give,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=588" target="_blank">00:09:48.760</a></span> | <span class="t">provide some type of prompt and it fills out</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=591" target="_blank">00:09:51.440</a></span> | <span class="t">the rest of the likely masks for that object</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=595" target="_blank">00:09:55.240</a></span> | <span class="t">throughout the rest of the video.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=596" target="_blank">00:09:56.440</a></span> | <span class="t">So here we're giving a bounding box in the first frame,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=599" target="_blank">00:09:59.120</a></span> | <span class="t">a set of positive negative points,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=600" target="_blank">00:10:00.720</a></span> | <span class="t">or even just a simple mask.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=604" target="_blank">00:10:04.680</a></span> | <span class="t">I'm going to assume people are somewhat familiar with SAM.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=609" target="_blank">00:10:09.680</a></span> | <span class="t">So I'm going to just give a high-level overview</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=611" target="_blank">00:10:11.720</a></span> | <span class="t">of how SAM works.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=613" target="_blank">00:10:13.720</a></span> | <span class="t">You have an image encoder that runs on every frame.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=616" target="_blank">00:10:16.800</a></span> | <span class="t">SAM2 can be used on a single image,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=620" target="_blank">00:10:20.760</a></span> | <span class="t">in which case the only difference between SAM2 and SAM</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=623" target="_blank">00:10:23.400</a></span> | <span class="t">is that image encoder, which SAM used a standard VIT.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=631" target="_blank">00:10:31.360</a></span> | <span class="t">SAM2 replaced that with a Hera hierarchical encoder,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=636" target="_blank">00:10:36.360</a></span> | <span class="t">which gets approximately the same results,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=639" target="_blank">00:10:39.240</a></span> | <span class="t">but leads to a six times faster inference,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=642" target="_blank">00:10:42.280</a></span> | <span class="t">which is excellent, especially considering</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=644" target="_blank">00:10:44.560</a></span> | <span class="t">how in a trend of 23 was replacing the VIT</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=648" target="_blank">00:10:48.960</a></span> | <span class="t">with more efficient backbones.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=650" target="_blank">00:10:50.760</a></span> | <span class="t">In the case where you're doing video segmentation,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=656" target="_blank">00:10:56.080</a></span> | <span class="t">the difference is that you actually create a memory bank</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=658" target="_blank">00:10:58.920</a></span> | <span class="t">and you cross attend the features from the image encoder</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=662" target="_blank">00:11:02.800</a></span> | <span class="t">based on the memory bank.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=664" target="_blank">00:11:04.560</a></span> | <span class="t">So the feature set that is created is essentially,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=669" target="_blank">00:11:09.560</a></span> | <span class="t">well, I'll go more into it in a couple of slides,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=674" target="_blank">00:11:14.500</a></span> | <span class="t">but we take the features from the past couple frames</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=679" target="_blank">00:11:19.320</a></span> | <span class="t">plus a set of object pointers and the set of prompts</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=684" target="_blank">00:11:24.520</a></span> | <span class="t">and use that to generate our new masks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=688" target="_blank">00:11:28.920</a></span> | <span class="t">Then we then fuse the new masks for this frame</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=690" target="_blank">00:11:30.980</a></span> | <span class="t">with the image features and add that to the memory bank.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=695" target="_blank">00:11:35.980</a></span> | <span class="t">It's, well, I'll say more in a minute.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=699" target="_blank">00:11:39.720</a></span> | <span class="t">Just like SAM, SAM2 actually uses a data engine</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=704" target="_blank">00:11:44.440</a></span> | <span class="t">to create its data set in that people are,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=707" target="_blank">00:11:47.320</a></span> | <span class="t">they assembled a huge amount of reference data,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=710" target="_blank">00:11:50.020</a></span> | <span class="t">used people to label some of it and train the model,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=714" target="_blank">00:11:54.500</a></span> | <span class="t">used the model to label more of it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=717" target="_blank">00:11:57.340</a></span> | <span class="t">and asked people to refine the predictions of the model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=719" target="_blank">00:11:59.780</a></span> | <span class="t">And then ultimately the data set is just created</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=722" target="_blank">00:12:02.660</a></span> | <span class="t">from the final output of the model on the reference data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=726" target="_blank">00:12:06.960</a></span> | <span class="t">It's very interesting.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=728" target="_blank">00:12:08.740</a></span> | <span class="t">This paradigm is so interesting to me</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=729" target="_blank">00:12:09.980</a></span> | <span class="t">because it unifies a model in a data set</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=734" target="_blank">00:12:14.100</a></span> | <span class="t">in a way that is very unique.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=736" target="_blank">00:12:16.920</a></span> | <span class="t">It seems unlikely that another model could come in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=739" target="_blank">00:12:19.340</a></span> | <span class="t">and have such a tight relationship with the training set.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=742" target="_blank">00:12:22.340</a></span> | <span class="t">Yeah, so brief overview of how the memory bank works.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=750" target="_blank">00:12:30.460</a></span> | <span class="t">The paper did not have a great visual,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=753" target="_blank">00:12:33.740</a></span> | <span class="t">so I'm just, I'm going to fill in a bit more.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=755" target="_blank">00:12:35.940</a></span> | <span class="t">So we take the last couple of frames from our video</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=762" target="_blank">00:12:42.780</a></span> | <span class="t">and we take the last couple of frames from our video.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=769" target="_blank">00:12:49.700</a></span> | <span class="t">Attend that along with the set of prompts that we provided,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=774" target="_blank">00:12:54.700</a></span> | <span class="t">they could come from the future,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=776" target="_blank">00:12:56.420</a></span> | <span class="t">they could come from anywhere in the video,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=778" target="_blank">00:12:58.180</a></span> | <span class="t">as well as reference objects pointers saying,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=781" target="_blank">00:13:01.500</a></span> | <span class="t">by the way, here's what we've found so far.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=784" target="_blank">00:13:04.020</a></span> | <span class="t">Attending to the last few frames</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=785" target="_blank">00:13:05.980</a></span> | <span class="t">has the interesting benefit of allowing it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=788" target="_blank">00:13:08.780</a></span> | <span class="t">to model complex object motion without actually,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=797" target="_blank">00:13:17.220</a></span> | <span class="t">by limiting the amount of frames that you attend to,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=799" target="_blank">00:13:19.940</a></span> | <span class="t">you manage to keep the model running in real time.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=802" target="_blank">00:13:22.460</a></span> | <span class="t">This is such an interesting topic for me</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=804" target="_blank">00:13:24.600</a></span> | <span class="t">because one would assume that attending</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=807" target="_blank">00:13:27.540</a></span> | <span class="t">to all of the frames is super essential</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=810" target="_blank">00:13:30.140</a></span> | <span class="t">or having some type of summarization</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=811" target="_blank">00:13:31.380</a></span> | <span class="t">of all the frames is super essential for a high performance,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=815" target="_blank">00:13:35.060</a></span> | <span class="t">but we see in their later ablation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=817" target="_blank">00:13:37.300</a></span> | <span class="t">that that actually is not the case.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=819" target="_blank">00:13:39.060</a></span> | <span class="t">So here, just to make sure</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=823" target="_blank">00:13:43.200</a></span> | <span class="t">that there is some benchmarking happening,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=825" target="_blank">00:13:45.060</a></span> | <span class="t">we just compared to some of the stuff</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=826" target="_blank">00:13:46.700</a></span> | <span class="t">that's came out prior,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=829" target="_blank">00:13:49.700</a></span> | <span class="t">and indeed the SAM2 strategy does improve</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=832" target="_blank">00:13:52.380</a></span> | <span class="t">on the state of the art.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=833" target="_blank">00:13:53.740</a></span> | <span class="t">This ablation deep in their dependencies</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=839" target="_blank">00:13:59.620</a></span> | <span class="t">was super interesting to me.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=841" target="_blank">00:14:01.040</a></span> | <span class="t">We see in section C, the number of memories.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=845" target="_blank">00:14:05.660</a></span> | <span class="t">One would assume that increasing the count of memories</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=848" target="_blank">00:14:08.820</a></span> | <span class="t">would meaningfully increase performance.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=851" target="_blank">00:14:11.220</a></span> | <span class="t">And we see that it has some impact,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=852" target="_blank">00:14:12.660</a></span> | <span class="t">but not the type that you'd expect.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=855" target="_blank">00:14:15.700</a></span> | <span class="t">And that it meaningfully decreases speed,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=857" target="_blank">00:14:17.660</a></span> | <span class="t">which justifies in my mind,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=859" target="_blank">00:14:19.380</a></span> | <span class="t">just having this FIFO queue of memories.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=862" target="_blank">00:14:22.320</a></span> | <span class="t">Although in the future,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=865" target="_blank">00:14:25.620</a></span> | <span class="t">I'm super interested to see a more dedicated summarization</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=870" target="_blank">00:14:30.340</a></span> | <span class="t">of all of the last video,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=871" target="_blank">00:14:31.880</a></span> | <span class="t">not just a stacking of the last frames.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=875" target="_blank">00:14:35.340</a></span> | <span class="t">So that another extension of beautiful per frame work</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=884" target="_blank">00:14:44.180</a></span> | <span class="t">into the video domain.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=887" target="_blank">00:14:47.580</a></span> | <span class="t">The next trend I'm interested in talking about</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=889" target="_blank">00:14:49.320</a></span> | <span class="t">is this interesting at Roboflow,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=893" target="_blank">00:14:53.460</a></span> | <span class="t">we're super interested in training</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=894" target="_blank">00:14:54.660</a></span> | <span class="t">real-time object detectors.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=896" target="_blank">00:14:56.180</a></span> | <span class="t">Those are bread and butter.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=897" target="_blank">00:14:57.460</a></span> | <span class="t">And so we're doing a lot to keep track</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=898" target="_blank">00:14:58.860</a></span> | <span class="t">of what is actually happening in that space.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=901" target="_blank">00:15:01.820</a></span> | <span class="t">We are finally starting to see something change.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=907" target="_blank">00:15:07.160</a></span> | <span class="t">So for years, yellows have been the dominant way</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=910" target="_blank">00:15:10.940</a></span> | <span class="t">of doing real-time object detection.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=912" target="_blank">00:15:12.980</a></span> | <span class="t">And we can see here that they've essentially stagnated.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=916" target="_blank">00:15:16.320</a></span> | <span class="t">The performance between 10 and 11</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=918" target="_blank">00:15:18.500</a></span> | <span class="t">is not meaningfully different,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=921" target="_blank">00:15:21.260</a></span> | <span class="t">at least in this type of high-level chart.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=925" target="_blank">00:15:25.340</a></span> | <span class="t">And even from the last couple of series,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=926" target="_blank">00:15:26.860</a></span> | <span class="t">there's not a major change.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=928" target="_blank">00:15:28.900</a></span> | <span class="t">So yellows have hit a plateau.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=932" target="_blank">00:15:32.620</a></span> | <span class="t">Deaders have not.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=935" target="_blank">00:15:35.940</a></span> | <span class="t">So we can look here and see the yellow series</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=940" target="_blank">00:15:40.320</a></span> | <span class="t">has this plateau, and then these RT-deader,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=943" target="_blank">00:15:43.860</a></span> | <span class="t">LW-deader, and D-fine have meaningfully changed that plateau</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=947" target="_blank">00:15:47.540</a></span> | <span class="t">so that, in fact, the best D-fine models</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=950" target="_blank">00:15:50.040</a></span> | <span class="t">are plus 4.6 AP on COCO at the same latency.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=954" target="_blank">00:15:54.100</a></span> | <span class="t">So three major steps to accomplish this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=959" target="_blank">00:15:59.680</a></span> | <span class="t">The first RT-deader, which is technically</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=961" target="_blank">00:16:01.900</a></span> | <span class="t">a 2023 paper preprint, but published officially in '24,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=966" target="_blank">00:16:06.000</a></span> | <span class="t">so I'm going to include that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=967" target="_blank">00:16:07.440</a></span> | <span class="t">I hope that's okay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=969" target="_blank">00:16:09.820</a></span> | <span class="t">Deaders showed that, RT-deader showed that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=972" target="_blank">00:16:12.300</a></span> | <span class="t">we could actually match or out-speed yellows.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=974" target="_blank">00:16:14.600</a></span> | <span class="t">And then LW-deader showed that pre-training</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=978" target="_blank">00:16:18.540</a></span> | <span class="t">is hugely effective on deaders, and much less so on yellows.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=982" target="_blank">00:16:22.260</a></span> | <span class="t">And then D-fine added the types of bells and whistles</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=984" target="_blank">00:16:24.060</a></span> | <span class="t">that we expect from these types, this arena.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=988" target="_blank">00:16:28.260</a></span> | <span class="t">So the major improvements that RT-deader shows</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=993" target="_blank">00:16:33.540</a></span> | <span class="t">was taking the multiscale features</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=997" target="_blank">00:16:37.400</a></span> | <span class="t">that deaders typically pass into their encoder</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=999" target="_blank">00:16:39.980</a></span> | <span class="t">and decoupling them</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1001" target="_blank">00:16:41.060</a></span> | <span class="t">into a much more efficient transformer encoder.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1004" target="_blank">00:16:44.400</a></span> | <span class="t">The transformer is, of course, quadratic complexity,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1008" target="_blank">00:16:48.560</a></span> | <span class="t">so decreasing the amount of stuff that you pass in at once</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1012" target="_blank">00:16:52.100</a></span> | <span class="t">is super helpful for increasing your runtime,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1015" target="_blank">00:16:55.780</a></span> | <span class="t">or increasing your throughput.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1017" target="_blank">00:16:57.920</a></span> | <span class="t">So that change basically brought us up to yellow speed,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1021" target="_blank">00:17:01.980</a></span> | <span class="t">and then they do a hardcore analysis</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1024" target="_blank">00:17:04.180</a></span> | <span class="t">on benchmarking yellows, including the NMS step.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1029" target="_blank">00:17:09.180</a></span> | <span class="t">Once you include the NMS in the latency calculation,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1034" target="_blank">00:17:14.600</a></span> | <span class="t">you see that, in fact, these deaders are outperforming,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1038" target="_blank">00:17:18.600</a></span> | <span class="t">at least at this time, the yellows that existed.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1042" target="_blank">00:17:22.760</a></span> | <span class="t">Then LW-deader goes in and suggests that,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1046" target="_blank">00:17:26.660</a></span> | <span class="t">in fact, this frame, the huge boost here is from pre-training</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1052" target="_blank">00:17:32.000</a></span> | <span class="t">So this is the defined line,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1055" target="_blank">00:17:35.200</a></span> | <span class="t">and this is the defined line without pre-training.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1057" target="_blank">00:17:37.240</a></span> | <span class="t">It's within range, it's still an improvement</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1059" target="_blank">00:17:39.320</a></span> | <span class="t">over the yellows, but the really huge boost</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1062" target="_blank">00:17:42.200</a></span> | <span class="t">comes from the benefit of pre-training.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1064" target="_blank">00:17:44.160</a></span> | <span class="t">When YOLO-X came out in 2021,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1068" target="_blank">00:17:48.240</a></span> | <span class="t">they showed that they got much better results</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1071" target="_blank">00:17:51.080</a></span> | <span class="t">by having a much, much longer training time,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1074" target="_blank">00:17:54.040</a></span> | <span class="t">but they found that when they did that,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1077" target="_blank">00:17:57.240</a></span> | <span class="t">they actually did not benefit from pre-training.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1080" target="_blank">00:18:00.160</a></span> | <span class="t">So you see in this graph from LW-deader,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1084" target="_blank">00:18:04.040</a></span> | <span class="t">in fact, yellows do have a real benefit from pre-training,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1087" target="_blank">00:18:07.240</a></span> | <span class="t">but it goes away as we increase the training time.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1090" target="_blank">00:18:10.460</a></span> | <span class="t">Then the deaders converge much faster.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1093" target="_blank">00:18:13.240</a></span> | <span class="t">LW-deader trains for only 50 epochs,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1095" target="_blank">00:18:15.120</a></span> | <span class="t">RT-deaders, 60 epochs.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1097" target="_blank">00:18:17.460</a></span> | <span class="t">So one could assume that, in fact,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1099" target="_blank">00:18:19.460</a></span> | <span class="t">the entire extra gain from pre-training</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1102" target="_blank">00:18:22.960</a></span> | <span class="t">is that you're not destroying your original weights</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1105" target="_blank">00:18:25.700</a></span> | <span class="t">by relying on pre-training.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1107" target="_blank">00:18:27.460</a></span> | <span class="t">You're not destroying your original weights</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1109" target="_blank">00:18:29.460</a></span> | <span class="t">by relying on this long training cycle.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1111" target="_blank">00:18:31.460</a></span> | <span class="t">And then LW-deader also shows superior performance</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1117" target="_blank">00:18:37.660</a></span> | <span class="t">to our favorite data set, Roboflow 100,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1121" target="_blank">00:18:41.040</a></span> | <span class="t">which means that they do better on the real world,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1122" target="_blank">00:18:42.840</a></span> | <span class="t">not just on Cocoa.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1124" target="_blank">00:18:44.120</a></span> | <span class="t">Then Define throws all the bells and whistles at it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1129" target="_blank">00:18:49.500</a></span> | <span class="t">YOLO models tend to have a lot of very specific,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1133" target="_blank">00:18:53.880</a></span> | <span class="t">complicated loss functions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1136" target="_blank">00:18:56.500</a></span> | <span class="t">Define brings that into the deader world</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1139" target="_blank">00:18:59.840</a></span> | <span class="t">and shows consistent improvement</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1140" target="_blank">00:19:00.920</a></span> | <span class="t">on a variety of deader-based frameworks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1143" target="_blank">00:19:03.080</a></span> | <span class="t">So bring these all together,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1147" target="_blank">00:19:07.200</a></span> | <span class="t">and we see that suddenly we have almost 60 AP on Cocoa</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1151" target="_blank">00:19:11.120</a></span> | <span class="t">while running in like 10 milliseconds.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1153" target="_blank">00:19:13.280</a></span> | <span class="t">Huge, huge stuff.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1154" target="_blank">00:19:14.620</a></span> | <span class="t">So we're spending a lot of time trying to build models</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1159" target="_blank">00:19:19.960</a></span> | <span class="t">that work better with less data,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1161" target="_blank">00:19:21.880</a></span> | <span class="t">and deaders are clearly becoming a promising step</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1164" target="_blank">00:19:24.800</a></span> | <span class="t">in that direction.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1166" target="_blank">00:19:26.700</a></span> | <span class="t">What we're interested in seeing from the deaders</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1170" target="_blank">00:19:30.660</a></span> | <span class="t">in this trend to next is Codeader</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1173" target="_blank">00:19:33.280</a></span> | <span class="t">and the models that are currently sitting</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1175" target="_blank">00:19:35.360</a></span> | <span class="t">on the top of the leaderboard for large-scale inference</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1180" target="_blank">00:19:40.360</a></span> | <span class="t">scale really well as you switch out the backbone.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1184" target="_blank">00:19:44.620</a></span> | <span class="t">We're very interested in seeing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1186" target="_blank">00:19:46.400</a></span> | <span class="t">and having people publish a paper, potentially us,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1189" target="_blank">00:19:49.620</a></span> | <span class="t">on what happens if you take these real-time ones</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1192" target="_blank">00:19:52.040</a></span> | <span class="t">and then throw a Swing G at it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1193" target="_blank">00:19:53.360</a></span> | <span class="t">Like, do we have a Pareto curve that extends</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1196" target="_blank">00:19:56.040</a></span> | <span class="t">from the real-time domain all the way up</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1197" target="_blank">00:19:57.780</a></span> | <span class="t">to the super, super slow but high-performance domain?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1202" target="_blank">00:20:02.580</a></span> | <span class="t">We also wanna see people benchmarking an RF100 more</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1205" target="_blank">00:20:05.860</a></span> | <span class="t">because that type of data is what's relevant</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1208" target="_blank">00:20:08.460</a></span> | <span class="t">for most users.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1209" target="_blank">00:20:09.620</a></span> | <span class="t">And we wanna see more pre-training</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1213" target="_blank">00:20:13.200</a></span> | <span class="t">because pre-training works now.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1215" target="_blank">00:20:15.080</a></span> | <span class="t">It's super cool.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1215" target="_blank">00:20:15.960</a></span> | <span class="t">- All right, so, yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1221" target="_blank">00:20:21.660</a></span> | <span class="t">So, in that theme, one of the big things</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1224" target="_blank">00:20:24.420</a></span> | <span class="t">that we're focusing on is how do we get more</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1226" target="_blank">00:20:26.620</a></span> | <span class="t">out of our pre-trained models?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1228" target="_blank">00:20:28.380</a></span> | <span class="t">And one of the lenses to look at this is through</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1231" target="_blank">00:20:31.880</a></span> | <span class="t">sort of this new requirement for, like,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1234" target="_blank">00:20:34.620</a></span> | <span class="t">fine-grained visual details and your representations</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1237" target="_blank">00:20:37.880</a></span> | <span class="t">that are extracted from your foundation model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1240" target="_blank">00:20:40.700</a></span> | <span class="t">So, it's sort of a hook for this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1242" target="_blank">00:20:42.460</a></span> | <span class="t">Oh, yeah, this is just a list of all the papers</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1245" target="_blank">00:20:45.840</a></span> | <span class="t">that I'm gonna mention.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1246" target="_blank">00:20:46.700</a></span> | <span class="t">I just wanted to make sure I set an actual paper</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1248" target="_blank">00:20:48.380</a></span> | <span class="t">so you can find it later.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1250" target="_blank">00:20:50.660</a></span> | <span class="t">Yeah, so, sort of the big hook here is that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1254" target="_blank">00:20:54.080</a></span> | <span class="t">I make the claim that LLMs can't see.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1256" target="_blank">00:20:56.460</a></span> | <span class="t">If you go to Claude or ChatGPT,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1260" target="_blank">00:21:00.920</a></span> | <span class="t">you ask it to see this watch</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1264" target="_blank">00:21:04.840</a></span> | <span class="t">and tell me what time it is, it fails, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1267" target="_blank">00:21:07.120</a></span> | <span class="t">And so, you could say, like, maybe the,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1271" target="_blank">00:21:11.800</a></span> | <span class="t">like, this is, like, a very classic test of an LLM,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1274" target="_blank">00:21:14.840</a></span> | <span class="t">but you could say, okay, maybe this image</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1276" target="_blank">00:21:16.540</a></span> | <span class="t">is, like, too zoomed out and it just, like,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1279" target="_blank">00:21:19.500</a></span> | <span class="t">it'll do better if we increase the resolution</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1281" target="_blank">00:21:21.580</a></span> | <span class="t">and it has easier time finding these fine-grained features,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1284" target="_blank">00:21:24.540</a></span> | <span class="t">like where the watch hands are pointing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1286" target="_blank">00:21:26.340</a></span> | <span class="t">No dice.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1287" target="_blank">00:21:27.160</a></span> | <span class="t">And you could say, okay, well, maybe the model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1289" target="_blank">00:21:29.200</a></span> | <span class="t">just doesn't know how to tell time</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1290" target="_blank">00:21:30.700</a></span> | <span class="t">from knowing the position of the hands,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1292" target="_blank">00:21:32.660</a></span> | <span class="t">but if you actually prompt it textually,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1294" target="_blank">00:21:34.200</a></span> | <span class="t">it's very easy for it to tell the time.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1295" target="_blank">00:21:35.700</a></span> | <span class="t">So, this, to me, is proof that these LLMs</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1298" target="_blank">00:21:38.540</a></span> | <span class="t">literally cannot see the position of the watch hands</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1300" target="_blank">00:21:40.840</a></span> | <span class="t">and it can't see those details.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1301" target="_blank">00:21:41.960</a></span> | <span class="t">So, the question is, sort of, why?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1303" target="_blank">00:21:43.620</a></span> | <span class="t">And for you anthropic heads out there, Claude fails, too.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1308" target="_blank">00:21:48.880</a></span> | <span class="t">So, my first pick for Best Paper of 2024 Envision</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1313" target="_blank">00:21:53.880</a></span> | <span class="t">is this MMVP paper, which tries to investigate</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1317" target="_blank">00:21:57.260</a></span> | <span class="t">why do LLMs not have the ability to see fine-grained details?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1320" target="_blank">00:22:00.880</a></span> | <span class="t">And so, for instance, it comes up</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1323" target="_blank">00:22:03.040</a></span> | <span class="t">with a lot of images like this, where you ask it a question</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1325" target="_blank">00:22:05.760</a></span> | <span class="t">that seems very visually apparent to us,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1327" target="_blank">00:22:07.260</a></span> | <span class="t">like, which way is the school bus facing?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1328" target="_blank">00:22:08.620</a></span> | <span class="t">And it gets it wrong.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1329" target="_blank">00:22:09.460</a></span> | <span class="t">And then, of course, it makes up details</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1331" target="_blank">00:22:11.040</a></span> | <span class="t">to support its wrong claim.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1332" target="_blank">00:22:12.460</a></span> | <span class="t">And so, the process by which it finds these images</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1336" target="_blank">00:22:16.540</a></span> | <span class="t">is, sort of, contained in its hypothesis</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1338" target="_blank">00:22:18.920</a></span> | <span class="t">for why it can't see these details.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1341" target="_blank">00:22:21.240</a></span> | <span class="t">So, it hypothesizes that models</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1344" target="_blank">00:22:24.920</a></span> | <span class="t">that have been initialized with Clip</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1346" target="_blank">00:22:26.960</a></span> | <span class="t">as their vision encoder,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1348" target="_blank">00:22:28.540</a></span> | <span class="t">they don't have fine-grained details</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1351" target="_blank">00:22:31.080</a></span> | <span class="t">and the features extracted using Clip</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1353" target="_blank">00:22:33.080</a></span> | <span class="t">because Clip, sort of, doesn't need to find</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1356" target="_blank">00:22:36.920</a></span> | <span class="t">these fine-grained details to do its job correctly,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1358" target="_blank">00:22:38.840</a></span> | <span class="t">which is just to match captions and images, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1362" target="_blank">00:22:42.340</a></span> | <span class="t">And, sort of, at a high level,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1364" target="_blank">00:22:44.580</a></span> | <span class="t">even if ChatGPT wasn't initialized with Clip</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1366" target="_blank">00:22:46.800</a></span> | <span class="t">and wasn't trained contrastively,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1369" target="_blank">00:22:49.460</a></span> | <span class="t">the vision encoder wasn't trained contrastively at all,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1372" target="_blank">00:22:52.220</a></span> | <span class="t">still, in order to do its job of capturing the image,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1375" target="_blank">00:22:55.340</a></span> | <span class="t">it could do a pretty good job</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1376" target="_blank">00:22:56.800</a></span> | <span class="t">without actually finding the exact position</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1378" target="_blank">00:22:58.800</a></span> | <span class="t">of all the objects and visual features in the image, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1382" target="_blank">00:23:02.040</a></span> | <span class="t">So, this paper finds a set of difficult images</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1385" target="_blank">00:23:05.920</a></span> | <span class="t">for these types of models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1387" target="_blank">00:23:07.620</a></span> | <span class="t">And the way it does it is it looks for embeddings</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1390" target="_blank">00:23:10.000</a></span> | <span class="t">that are similar in Clip space, but far in DynaV2 space.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1393" target="_blank">00:23:13.300</a></span> | <span class="t">So, DynaV2 is a foundation model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1395" target="_blank">00:23:15.300</a></span> | <span class="t">that was trained self-supervised purely on image data,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1400" target="_blank">00:23:20.000</a></span> | <span class="t">and it, kind of, uses, like,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1401" target="_blank">00:23:21.420</a></span> | <span class="t">some complex student-teacher framework,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1403" target="_blank">00:23:23.960</a></span> | <span class="t">but, essentially, it patches out, like,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1406" target="_blank">00:23:26.220</a></span> | <span class="t">certain areas of the image</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1408" target="_blank">00:23:28.380</a></span> | <span class="t">or, like, crops at certain areas of the image</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1409" target="_blank">00:23:29.960</a></span> | <span class="t">and tries to make sure</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1410" target="_blank">00:23:30.840</a></span> | <span class="t">that those have consistent representations,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1412" target="_blank">00:23:32.420</a></span> | <span class="t">which is a way for it to learn</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1413" target="_blank">00:23:33.960</a></span> | <span class="t">very fine-grained visual features.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1416" target="_blank">00:23:36.600</a></span> | <span class="t">And so, if you take things that are very close in Clip space</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1419" target="_blank">00:23:39.300</a></span> | <span class="t">and very far in DynaV2 space,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1421" target="_blank">00:23:41.300</a></span> | <span class="t">you get a set of images that basically are pairs of images</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1425" target="_blank">00:23:45.840</a></span> | <span class="t">that are hard for a chat GPT</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1427" target="_blank">00:23:47.300</a></span> | <span class="t">and other big language models to distinguish.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1429" target="_blank">00:23:49.720</a></span> | <span class="t">So, if you then ask it questions about this image,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1432" target="_blank">00:23:52.600</a></span> | <span class="t">well, as you can see from this chart,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1434" target="_blank">00:23:54.880</a></span> | <span class="t">it's going to answer the same way for both images, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1438" target="_blank">00:23:58.600</a></span> | <span class="t">Because, from the perspective of the vision encoder,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1441" target="_blank">00:24:01.640</a></span> | <span class="t">they're the same image.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1443" target="_blank">00:24:03.000</a></span> | <span class="t">And so, if you ask a question, like,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1443" target="_blank">00:24:03.960</a></span> | <span class="t">"How many eyes does this animal have?"</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1445" target="_blank">00:24:05.540</a></span> | <span class="t">It answers the same for both.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1446" target="_blank">00:24:06.960</a></span> | <span class="t">And, like, all these other models, including Lava,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1449" target="_blank">00:24:09.880</a></span> | <span class="t">do the same thing, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1451" target="_blank">00:24:11.920</a></span> | <span class="t">And so, this is the benchmark that they create,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1454" target="_blank">00:24:14.080</a></span> | <span class="t">which is, like, finding, like, clip-blind pairs,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1457" target="_blank">00:24:17.760</a></span> | <span class="t">which is pairs of images that are similar in Clip space,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1459" target="_blank">00:24:19.680</a></span> | <span class="t">and creating a data set of multiple-choice questions</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1463" target="_blank">00:24:23.220</a></span> | <span class="t">based off of those.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1464" target="_blank">00:24:24.760</a></span> | <span class="t">And so, how do these models do?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1466" target="_blank">00:24:26.880</a></span> | <span class="t">Well, really bad.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1469" target="_blank">00:24:29.080</a></span> | <span class="t">Lava, I think...</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1470" target="_blank">00:24:30.500</a></span> | <span class="t">So, chat GPT and Jim and I do a little bit better</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1473" target="_blank">00:24:33.420</a></span> | <span class="t">than random guessing,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1474" target="_blank">00:24:34.340</a></span> | <span class="t">but, like, half of the performance of humans</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1476" target="_blank">00:24:36.220</a></span> | <span class="t">who find these problems to be very easy.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1479" target="_blank">00:24:39.040</a></span> | <span class="t">Lava is, interestingly,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1481" target="_blank">00:24:41.300</a></span> | <span class="t">extremely negatively correlated with this data set.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1484" target="_blank">00:24:44.720</a></span> | <span class="t">It does much, much, much, much worse than random guessing,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1487" target="_blank">00:24:47.640</a></span> | <span class="t">which means that this process has done a very good job</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1490" target="_blank">00:24:50.600</a></span> | <span class="t">of identifying hard images for Lava, specifically.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1494" target="_blank">00:24:54.680</a></span> | <span class="t">And that's because Lava is basically</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1497" target="_blank">00:24:57.040</a></span> | <span class="t">not trained for very long and is initialized from Clip.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1499" target="_blank">00:24:59.380</a></span> | <span class="t">And so, you would expect it to do poorly on this data set.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1503" target="_blank">00:25:03.160</a></span> | <span class="t">So, one of the proposed solutions that this paper attempts</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1508" target="_blank">00:25:08.040</a></span> | <span class="t">is by basically saying,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1509" target="_blank">00:25:09.300</a></span> | <span class="t">"Okay, well, if Clip features aren't enough,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1510" target="_blank">00:25:10.920</a></span> | <span class="t">"what if we train the visual encoder</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1512" target="_blank">00:25:12.800</a></span> | <span class="t">"of the language model also on Dyno features?"</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1515" target="_blank">00:25:15.040</a></span> | <span class="t">And so, it proposes two different ways of doing this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1519" target="_blank">00:25:19.080</a></span> | <span class="t">One, additively, which is basically interpolating</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1522" target="_blank">00:25:22.540</a></span> | <span class="t">between the two features.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1523" target="_blank">00:25:23.800</a></span> | <span class="t">And then, one is interleaving,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1525" target="_blank">00:25:25.640</a></span> | <span class="t">which is just kind of like training one</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1527" target="_blank">00:25:27.260</a></span> | <span class="t">on the combination of both features.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1530" target="_blank">00:25:30.180</a></span> | <span class="t">So, there's this really interesting trend</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1532" target="_blank">00:25:32.000</a></span> | <span class="t">when you do the additive mixture of features.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1534" target="_blank">00:25:34.720</a></span> | <span class="t">So, zero is all Clip features</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1538" target="_blank">00:25:38.480</a></span> | <span class="t">and one is all Dyno v2 features.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1540" target="_blank">00:25:40.900</a></span> | <span class="t">So, I think it's helpful</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1544" target="_blank">00:25:44.720</a></span> | <span class="t">to look at the rightmost chart first,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1546" target="_blank">00:25:46.380</a></span> | <span class="t">which is as you increase the number of Dyno v2 features,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1548" target="_blank">00:25:48.960</a></span> | <span class="t">your model does worse and worse and worse</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1550" target="_blank">00:25:50.600</a></span> | <span class="t">on the actual language modeling task.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1552" target="_blank">00:25:52.560</a></span> | <span class="t">And that's because Dyno v2 features</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1554" target="_blank">00:25:54.160</a></span> | <span class="t">were trained completely from a self-supervised manner</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1557" target="_blank">00:25:57.280</a></span> | <span class="t">and completely in image space.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1558" target="_blank">00:25:58.600</a></span> | <span class="t">It knows nothing about text.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1559" target="_blank">00:25:59.700</a></span> | <span class="t">These features aren't really compatible</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1561" target="_blank">00:26:01.520</a></span> | <span class="t">with these text models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1563" target="_blank">00:26:03.000</a></span> | <span class="t">And so, you can train an adapter all you want,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1565" target="_blank">00:26:05.280</a></span> | <span class="t">but it seems that it's in such an alien language</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1567" target="_blank">00:26:07.420</a></span> | <span class="t">that it's like a very hard optimization</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1569" target="_blank">00:26:09.080</a></span> | <span class="t">for these models to solve.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1571" target="_blank">00:26:11.560</a></span> | <span class="t">And so, that kind of supports what's happening on the left,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1574" target="_blank">00:26:14.880</a></span> | <span class="t">which is that, yeah, it gets better</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1576" target="_blank">00:26:16.680</a></span> | <span class="t">at answering these questions</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1579" target="_blank">00:26:19.640</a></span> | <span class="t">as you include more Dyno v2 features up to a point,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1583" target="_blank">00:26:23.140</a></span> | <span class="t">but then when you oversaturate,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1584" target="_blank">00:26:24.800</a></span> | <span class="t">it completely loses its ability to answer language</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1588" target="_blank">00:26:28.860</a></span> | <span class="t">and do language tasks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1591" target="_blank">00:26:31.640</a></span> | <span class="t">So, you can also see with the interleaving,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1595" target="_blank">00:26:35.520</a></span> | <span class="t">they essentially double the number of tokens</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1598" target="_blank">00:26:38.080</a></span> | <span class="t">that are going into these models and just train on both.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1601" target="_blank">00:26:41.640</a></span> | <span class="t">And it still doesn't really solve the MMVP task.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1603" target="_blank">00:26:43.960</a></span> | <span class="t">It gets Lava 1.5 above random guessing by a little bit,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1607" target="_blank">00:26:47.560</a></span> | <span class="t">but it's still not close to Chachapiti</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1610" target="_blank">00:26:50.600</a></span> | <span class="t">or any human performance, obviously.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1614" target="_blank">00:26:54.200</a></span> | <span class="t">So, clearly, this proposed solution</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1616" target="_blank">00:26:56.540</a></span> | <span class="t">of just using Dyno v2 features directly isn't gonna work.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1620" target="_blank">00:27:00.000</a></span> | <span class="t">And basically what that means is that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1621" target="_blank">00:27:01.920</a></span> | <span class="t">as a vision foundation model,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1626" target="_blank">00:27:06.040</a></span> | <span class="t">Dyno v2 is gonna be insufficient for language tasks, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1629" target="_blank">00:27:09.840</a></span> | <span class="t">So, my next pick for best paper of 2024</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1633" target="_blank">00:27:13.640</a></span> | <span class="t">would be Florence 2, which tries to solve this problem</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1636" target="_blank">00:27:16.000</a></span> | <span class="t">by incorporating not only this dimension</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1639" target="_blank">00:27:19.280</a></span> | <span class="t">of spatial hierarchy,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1640" target="_blank">00:27:20.420</a></span> | <span class="t">which is to say pixel level understanding,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1643" target="_blank">00:27:23.320</a></span> | <span class="t">but also in making sure to include</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1645" target="_blank">00:27:25.300</a></span> | <span class="t">what they call semantic granularity,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1647" target="_blank">00:27:27.000</a></span> | <span class="t">which ends up, the goal is basically to have features</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1650" target="_blank">00:27:30.720</a></span> | <span class="t">that are sufficient for finding objects in the image.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1654" target="_blank">00:27:34.000</a></span> | <span class="t">So, they have enough pixel information,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1657" target="_blank">00:27:37.520</a></span> | <span class="t">but also can be talked about and can be reasoned about.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1660" target="_blank">00:27:40.520</a></span> | <span class="t">And that's on the semantic granularity axis.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1664" target="_blank">00:27:44.880</a></span> | <span class="t">So, here's an example of basically three different</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1669" target="_blank">00:27:49.520</a></span> | <span class="t">paradigms of labeling that they do.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1671" target="_blank">00:27:51.680</a></span> | <span class="t">So, they create a big data set.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1674" target="_blank">00:27:54.160</a></span> | <span class="t">One is text, which is just captioning.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1676" target="_blank">00:27:56.800</a></span> | <span class="t">And you would expect a model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1677" target="_blank">00:27:57.920</a></span> | <span class="t">that's trained only on captioning</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1679" target="_blank">00:27:59.120</a></span> | <span class="t">to have similar performance like chat2BT</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1681" target="_blank">00:28:01.000</a></span> | <span class="t">and not have spatial hierarchy,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1683" target="_blank">00:28:03.920</a></span> | <span class="t">not have features that are meaningful at the pixel level.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1687" target="_blank">00:28:07.560</a></span> | <span class="t">And so, they add another type, which is region text pairs,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1691" target="_blank">00:28:11.080</a></span> | <span class="t">which is essentially either classifying a region</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1694" target="_blank">00:28:14.080</a></span> | <span class="t">or doing object detection</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1699" target="_blank">00:28:19.080</a></span> | <span class="t">or doing instant segmentation on that region</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1702" target="_blank">00:28:22.080</a></span> | <span class="t">or captioning that region.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1703" target="_blank">00:28:23.640</a></span> | <span class="t">And then they have text phrase region annotations,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1706" target="_blank">00:28:26.240</a></span> | <span class="t">which is essentially a triple.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1708" target="_blank">00:28:28.560</a></span> | <span class="t">And basically, not only do you have a region</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1711" target="_blank">00:28:31.040</a></span> | <span class="t">that you've described,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1712" target="_blank">00:28:32.160</a></span> | <span class="t">you also find its place in a descriptive paragraph</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1716" target="_blank">00:28:36.720</a></span> | <span class="t">about the image,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1717" target="_blank">00:28:37.560</a></span> | <span class="t">which is basically trying to introduce</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1719" target="_blank">00:28:39.760</a></span> | <span class="t">even more semantic understanding of these regions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1722" target="_blank">00:28:42.240</a></span> | <span class="t">And so, for instance,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1723" target="_blank">00:28:43.640</a></span> | <span class="t">if you're saying a woman riding on the road,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1726" target="_blank">00:28:46.040</a></span> | <span class="t">you have to know what a woman is and what the road is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1728" target="_blank">00:28:48.120</a></span> | <span class="t">and that she's on top of it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1729" target="_blank">00:28:49.120</a></span> | <span class="t">And that's basically composing a bunch of objects</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1732" target="_blank">00:28:52.040</a></span> | <span class="t">in this visual space,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1733" target="_blank">00:28:53.120</a></span> | <span class="t">but also thinking about it semantically.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1735" target="_blank">00:28:55.240</a></span> | <span class="t">Right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1736" target="_blank">00:28:56.280</a></span> | <span class="t">And so, the way that they do this is they take...</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1739" target="_blank">00:28:59.400</a></span> | <span class="t">Basically, they just dump features from a vision encoder</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1744" target="_blank">00:29:04.400</a></span> | <span class="t">straight into a encoder-decoder transformer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1748" target="_blank">00:29:08.440</a></span> | <span class="t">And then they train a bunch of different tasks</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1752" target="_blank">00:29:12.720</a></span> | <span class="t">like object detection and so on as a language task.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1756" target="_blank">00:29:16.240</a></span> | <span class="t">And I think that's one of the big things</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1757" target="_blank">00:29:17.520</a></span> | <span class="t">that we saw in 2024</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1759" target="_blank">00:29:19.760</a></span> | <span class="t">is these vision language models</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1763" target="_blank">00:29:23.480</a></span> | <span class="t">operating on pixel space linguistically.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1766" target="_blank">00:29:26.880</a></span> | <span class="t">So, they introduce a bunch of new tokens</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1768" target="_blank">00:29:28.360</a></span> | <span class="t">to point to locations in pixel space.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1773" target="_blank">00:29:33.080</a></span> | <span class="t">So, how does it work?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1775" target="_blank">00:29:35.520</a></span> | <span class="t">How does it actually do?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1777" target="_blank">00:29:37.280</a></span> | <span class="t">We can see, if you look at the graph on the right,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1780" target="_blank">00:29:40.200</a></span> | <span class="t">which is using the Dino framework,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1784" target="_blank">00:29:44.560</a></span> | <span class="t">your pre-trained Florence 2 models transfer very, very well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1790" target="_blank">00:29:50.400</a></span> | <span class="t">They get 60% map on Cocoa,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1793" target="_blank">00:29:53.000</a></span> | <span class="t">which is like approaching state-of-the-art.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1794" target="_blank">00:29:54.960</a></span> | <span class="t">And they train with...</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1795" target="_blank">00:29:55.800</a></span> | <span class="t">- Recording in progress.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1797" target="_blank">00:29:57.520</a></span> | <span class="t">- You're good.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1798" target="_blank">00:29:58.440</a></span> | <span class="t">And they train with much more efficiently.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1802" target="_blank">00:30:02.960</a></span> | <span class="t">So, they converge a lot faster,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1804" target="_blank">00:30:04.360</a></span> | <span class="t">which both of these things are pointing to the fact</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1806" target="_blank">00:30:06.720</a></span> | <span class="t">that they're actually leveraging</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1808" target="_blank">00:30:08.320</a></span> | <span class="t">their pre-trained weights effectively.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1810" target="_blank">00:30:10.240</a></span> | <span class="t">So, where is it falling short?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1814" target="_blank">00:30:14.200</a></span> | <span class="t">So, these models, I forgot to mention,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1816" target="_blank">00:30:16.520</a></span> | <span class="t">Florence is a 0.2 billion</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1818" target="_blank">00:30:18.040</a></span> | <span class="t">and a 0.7 billion parameter count.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1820" target="_blank">00:30:20.360</a></span> | <span class="t">So, they're very, very small</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1821" target="_blank">00:30:21.600</a></span> | <span class="t">in terms of being a language model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1824" target="_blank">00:30:24.240</a></span> | <span class="t">And I think that this framework, you can see saturation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1827" target="_blank">00:30:27.760</a></span> | <span class="t">So, what this graph is showing is that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1830" target="_blank">00:30:30.280</a></span> | <span class="t">if you train a Florence 2 model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1832" target="_blank">00:30:32.440</a></span> | <span class="t">purely on the image level and region level annotations</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1835" target="_blank">00:30:35.320</a></span> | <span class="t">and not including the pixel level annotations,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1838" target="_blank">00:30:38.040</a></span> | <span class="t">like segmentation,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1840" target="_blank">00:30:40.240</a></span> | <span class="t">it actually performs better as an object detector.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1843" target="_blank">00:30:43.960</a></span> | <span class="t">And what that means is that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1845" target="_blank">00:30:45.640</a></span> | <span class="t">it's not able to actually learn all the visual tasks</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1848" target="_blank">00:30:48.400</a></span> | <span class="t">that it's trying to learn</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1849" target="_blank">00:30:49.480</a></span> | <span class="t">because it doesn't have enough capacity.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1851" target="_blank">00:30:51.160</a></span> | <span class="t">So, I'd like to see this paper explore larger model sizes,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1854" target="_blank">00:30:54.440</a></span> | <span class="t">which brings us to our next big paper of 2024,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1858" target="_blank">00:30:58.880</a></span> | <span class="t">or two papers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1860" target="_blank">00:31:00.200</a></span> | <span class="t">So, PolyGemma came out earlier this year.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1862" target="_blank">00:31:02.160</a></span> | <span class="t">PolyGemma 2 was released, I think, like a week or two ago.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1865" target="_blank">00:31:05.040</a></span> | <span class="t">Oh, I forgot to mention, you can actually train</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1868" target="_blank">00:31:08.400</a></span> | <span class="t">like label text data sets on RoboFlow</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1870" target="_blank">00:31:10.720</a></span> | <span class="t">and you can train a Florence 2 model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1872" target="_blank">00:31:12.240</a></span> | <span class="t">and you can actually train a PolyGemma 2 model on RoboFlow,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1875" target="_blank">00:31:15.640</a></span> | <span class="t">which we got into the platform</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1876" target="_blank">00:31:16.840</a></span> | <span class="t">within like 14 hours of release,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1878" target="_blank">00:31:18.120</a></span> | <span class="t">which I was really excited about.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1879" target="_blank">00:31:19.800</a></span> | <span class="t">So, anyway, so PolyGemma 2...</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1881" target="_blank">00:31:21.920</a></span> | <span class="t">So, PolyGemma is essentially doing the same thing,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1884" target="_blank">00:31:24.560</a></span> | <span class="t">but instead of doing an encoder-decoder,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1886" target="_blank">00:31:26.280</a></span> | <span class="t">it just dumps everything</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1887" target="_blank">00:31:27.120</a></span> | <span class="t">into a decoder-only transformer model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1889" target="_blank">00:31:29.560</a></span> | <span class="t">But it also introduced the concept of location tokens</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1891" target="_blank">00:31:31.840</a></span> | <span class="t">to point to objects in pixel space.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1895" target="_blank">00:31:35.240</a></span> | <span class="t">PolyGemma 2...</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1896" target="_blank">00:31:36.560</a></span> | <span class="t">So, PolyGemma uses Gemma as the language encoder</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1898" target="_blank">00:31:38.680</a></span> | <span class="t">and it uses Gemma 2B.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1899" target="_blank">00:31:39.880</a></span> | <span class="t">PolyGemma 2 introduces using multiple different sizes</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1903" target="_blank">00:31:43.120</a></span> | <span class="t">of language encoders.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1904" target="_blank">00:31:44.160</a></span> | <span class="t">So, the way that they sort of get around</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1908" target="_blank">00:31:48.360</a></span> | <span class="t">having to do encoder-decoder</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1909" target="_blank">00:31:49.960</a></span> | <span class="t">is they use the concept of prefix loss,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1912" target="_blank">00:31:52.320</a></span> | <span class="t">which basically means that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1913" target="_blank">00:31:53.680</a></span> | <span class="t">when it's generating tokens autoregressively,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1918" target="_blank">00:31:58.360</a></span> | <span class="t">it's all those tokens in the prefix,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1921" target="_blank">00:32:01.160</a></span> | <span class="t">which is like the image that it's looking at</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1923" target="_blank">00:32:03.040</a></span> | <span class="t">and like a description of the task that it's trying to do,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1925" target="_blank">00:32:05.920</a></span> | <span class="t">they're attending to each other fully, full attention,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1929" target="_blank">00:32:09.320</a></span> | <span class="t">which means that it can sort of bind high level...</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1932" target="_blank">00:32:12.960</a></span> | <span class="t">It's easier for the prefix to color the output</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1937" target="_blank">00:32:17.760</a></span> | <span class="t">of the suffix</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1939" target="_blank">00:32:19.160</a></span> | <span class="t">and also to just find features easily.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1943" target="_blank">00:32:23.440</a></span> | <span class="t">So, this is sort of an example</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1945" target="_blank">00:32:25.920</a></span> | <span class="t">of one of the tasks that I was trained on,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1947" target="_blank">00:32:27.360</a></span> | <span class="t">which is you describe the task in English</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1949" target="_blank">00:32:29.800</a></span> | <span class="t">and then you give it all these...</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1954" target="_blank">00:32:34.520</a></span> | <span class="t">You're asking for it to segment these two classes of objects</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1958" target="_blank">00:32:38.960</a></span> | <span class="t">and then it finds their locations using these tokens</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1962" target="_blank">00:32:42.760</a></span> | <span class="t">and it finds their masks using some encoding</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1966" target="_blank">00:32:46.480</a></span> | <span class="t">of the masks into tokens.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1970" target="_blank">00:32:50.200</a></span> | <span class="t">And yeah, so one of my critiques,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1974" target="_blank">00:32:54.040</a></span> | <span class="t">I guess, of PolyGemma 1, at least,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1976" target="_blank">00:32:56.080</a></span> | <span class="t">is that you find that performance saturates</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1979" target="_blank">00:32:59.080</a></span> | <span class="t">as a pre-trained model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1979" target="_blank">00:32:59.960</a></span> | <span class="t">after only 300 million examples seen.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1982" target="_blank">00:33:02.400</a></span> | <span class="t">So, what this graph is representing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1986" target="_blank">00:33:06.000</a></span> | <span class="t">is each blue dot is a performance on some downstream task.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1989" target="_blank">00:33:09.560</a></span> | <span class="t">You can see that after seeing 300 million examples,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1992" target="_blank">00:33:12.520</a></span> | <span class="t">it sort of does equally well</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1995" target="_blank">00:33:15.440</a></span> | <span class="t">on all of the downstream tasks that they tried it on,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=1998" target="_blank">00:33:18.400</a></span> | <span class="t">which was a lot, as one billion examples,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2001" target="_blank">00:33:21.680</a></span> | <span class="t">which to me also kind of suggests</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2003" target="_blank">00:33:23.720</a></span> | <span class="t">a lack of capacity for this model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2005" target="_blank">00:33:25.560</a></span> | <span class="t">PolyGemma 2, you can see the results on object detection.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2011" target="_blank">00:33:31.520</a></span> | <span class="t">So, these were transferred to Coco.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2015" target="_blank">00:33:35.800</a></span> | <span class="t">And you can see that this sort of also points</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2019" target="_blank">00:33:39.200</a></span> | <span class="t">to an increase in capacity being helpful to the model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2021" target="_blank">00:33:41.280</a></span> | <span class="t">You can see as both the resolution increases</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2024" target="_blank">00:33:44.720</a></span> | <span class="t">and the parameter count of the language model increases,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2027" target="_blank">00:33:47.360</a></span> | <span class="t">performance increases.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2028" target="_blank">00:33:48.640</a></span> | <span class="t">So, resolution makes sense.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2029" target="_blank">00:33:49.640</a></span> | <span class="t">Obviously, it helps to find small images</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2031" target="_blank">00:33:51.960</a></span> | <span class="t">or small objects in the image,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2033" target="_blank">00:33:53.560</a></span> | <span class="t">but it also makes sense from another reason,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2035" target="_blank">00:33:55.080</a></span> | <span class="t">which is that it kind of gives the model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2036" target="_blank">00:33:56.880</a></span> | <span class="t">a thinking register and it gives it more tokens</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2038" target="_blank">00:33:58.800</a></span> | <span class="t">to process when making its predictions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2041" target="_blank">00:34:01.440</a></span> | <span class="t">But yeah, you could say, oh, 43.6, that's not that great.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2046" target="_blank">00:34:06.600</a></span> | <span class="t">Like Florence 2 got 60,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2048" target="_blank">00:34:08.960</a></span> | <span class="t">but this is not training a dino or a debtor</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2052" target="_blank">00:34:12.520</a></span> | <span class="t">on top of this language or this image encoder.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2056" target="_blank">00:34:16.240</a></span> | <span class="t">It's doing the raw language modeling task on Coco.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2060" target="_blank">00:34:20.520</a></span> | <span class="t">So, it doesn't have any of the bells and whistles.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2061" target="_blank">00:34:21.960</a></span> | <span class="t">It doesn't have any of the fancy losses.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2063" target="_blank">00:34:23.360</a></span> | <span class="t">It doesn't even have bipartite graph matching</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2065" target="_blank">00:34:25.600</a></span> | <span class="t">or anything like that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2067" target="_blank">00:34:27.400</a></span> | <span class="t">Okay, the big result and one of the reasons</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2070" target="_blank">00:34:30.360</a></span> | <span class="t">that I was really excited about this paper</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2072" target="_blank">00:34:32.920</a></span> | <span class="t">is that they blow everything else away on MMVP.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2075" target="_blank">00:34:35.520</a></span> | <span class="t">I mean, 47.3, sure, that's nowhere near human accuracy,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2079" target="_blank">00:34:39.400</a></span> | <span class="t">which again is 94%,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2080" target="_blank">00:34:40.680</a></span> | <span class="t">but for a 2 billion parameter language model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2084" target="_blank">00:34:44.600</a></span> | <span class="t">to be chat2bt, that's quite the achievement.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2087" target="_blank">00:34:47.120</a></span> | <span class="t">And that sort of brings us to our final pick</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2091" target="_blank">00:34:51.320</a></span> | <span class="t">for paper of the year, which is AIMV2.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2096" target="_blank">00:34:56.080</a></span> | <span class="t">So, AIMV2 sort of says, okay, maybe this language model,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2101" target="_blank">00:35:01.080</a></span> | <span class="t">like maybe coming up with all these specific annotations</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2104" target="_blank">00:35:04.760</a></span> | <span class="t">to find features and with high fidelity in pixel space</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2108" target="_blank">00:35:08.760</a></span> | <span class="t">isn't actually necessary.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2110" target="_blank">00:35:10.560</a></span> | <span class="t">And we can come up with an even simpler</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2112" target="_blank">00:35:12.920</a></span> | <span class="t">and more beautiful idea for combining image tokens</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2117" target="_blank">00:35:17.280</a></span> | <span class="t">and pixel tokens in a way that's interfaceable</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2119" target="_blank">00:35:19.640</a></span> | <span class="t">for language tasks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2121" target="_blank">00:35:21.120</a></span> | <span class="t">And this is nice because it can scale.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2123" target="_blank">00:35:23.680</a></span> | <span class="t">You can come up with lots more data</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2125" target="_blank">00:35:25.360</a></span> | <span class="t">if you don't have to come up</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2126" target="_blank">00:35:26.280</a></span> | <span class="t">with all these annotations, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2128" target="_blank">00:35:28.080</a></span> | <span class="t">So, the way that it works is it does something</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2130" target="_blank">00:35:30.160</a></span> | <span class="t">very, very similar to PolyGemo</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2131" target="_blank">00:35:31.680</a></span> | <span class="t">where you have a vision encoder</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2133" target="_blank">00:35:33.040</a></span> | <span class="t">that dumps image tokens into a decoder only transformer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2136" target="_blank">00:35:36.840</a></span> | <span class="t">But the interesting thing is that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2140" target="_blank">00:35:40.000</a></span> | <span class="t">it also autoregressively tries to learn</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2142" target="_blank">00:35:42.760</a></span> | <span class="t">the mean squared error of the image tokens.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2146" target="_blank">00:35:46.200</a></span> | <span class="t">So, instead of having to come up</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2147" target="_blank">00:35:47.320</a></span> | <span class="t">with fancy object detection or segmentation labels,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2151" target="_blank">00:35:51.520</a></span> | <span class="t">you can just try to reconstruct the image</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2153" target="_blank">00:35:53.240</a></span> | <span class="t">and have it learn fine-grained features that way.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2155" target="_blank">00:35:55.720</a></span> | <span class="t">And it does this in kind of, I think, a beautiful way</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2159" target="_blank">00:35:59.000</a></span> | <span class="t">that's kind of compatible</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2160" target="_blank">00:36:00.080</a></span> | <span class="t">with the PolyGemo line of thinking,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2161" target="_blank">00:36:01.400</a></span> | <span class="t">which is randomly sampling a prefix length</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2164" target="_blank">00:36:04.560</a></span> | <span class="t">and using only this number of image tokens as the prefix.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2168" target="_blank">00:36:08.480</a></span> | <span class="t">And so, doing a similar thing with the causal.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2173" target="_blank">00:36:13.320</a></span> | <span class="t">So, the causal prefix is the attention mask on the right.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2176" target="_blank">00:36:16.360</a></span> | <span class="t">So, it's doing full block attention</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2178" target="_blank">00:36:18.760</a></span> | <span class="t">with some randomly sampled number of image tokens</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2181" target="_blank">00:36:21.120</a></span> | <span class="t">to then reconstruct the rest of the image</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2182" target="_blank">00:36:22.600</a></span> | <span class="t">and the downstream caption for that image.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2186" target="_blank">00:36:26.160</a></span> | <span class="t">And so, this is the dataset that they train on.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2190" target="_blank">00:36:30.160</a></span> | <span class="t">It's internet-scale data, very high-quality data</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2194" target="_blank">00:36:34.000</a></span> | <span class="t">created by the Data Filtering Network's paper, essentially,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2198" target="_blank">00:36:38.320</a></span> | <span class="t">which is maybe the best clip data that exists.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2202" target="_blank">00:36:42.120</a></span> | <span class="t">And we can see that this is finally a model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2206" target="_blank">00:36:46.640</a></span> | <span class="t">that doesn't saturate.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2208" target="_blank">00:36:48.520</a></span> | <span class="t">It's even at the highest parameter count,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2211" target="_blank">00:36:51.360</a></span> | <span class="t">it appears to be, well, at the highest parameter count,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2215" target="_blank">00:36:55.160</a></span> | <span class="t">it appears to be improving in performance</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2219" target="_blank">00:36:59.160</a></span> | <span class="t">with more and more samples seen.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2220" target="_blank">00:37:00.880</a></span> | <span class="t">And so, you can sort of think that, you know,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2223" target="_blank">00:37:03.800</a></span> | <span class="t">if we just keep bumping the parameter count</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2225" target="_blank">00:37:05.920</a></span> | <span class="t">and increasing the example seen,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2227" target="_blank">00:37:07.280</a></span> | <span class="t">which is the line of thinking for language models,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2230" target="_blank">00:37:10.400</a></span> | <span class="t">then it'll keep getting better.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2232" target="_blank">00:37:12.320</a></span> | <span class="t">So, how does it actually do at finding...</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2234" target="_blank">00:37:14.080</a></span> | <span class="t">Oh, it also improves with resolution,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2236" target="_blank">00:37:16.400</a></span> | <span class="t">which you would expect for a model that...</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2240" target="_blank">00:37:20.440</a></span> | <span class="t">This is the ImageNet classification accuracy,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2242" target="_blank">00:37:22.680</a></span> | <span class="t">but yeah, it does better if you increase the resolution,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2245" target="_blank">00:37:25.480</a></span> | <span class="t">which means that it's actually leveraging</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2246" target="_blank">00:37:26.920</a></span> | <span class="t">and finding fine-grained visual features.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2249" target="_blank">00:37:29.760</a></span> | <span class="t">And so, how does it actually do compared to CLIP on COCO?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2254" target="_blank">00:37:34.800</a></span> | <span class="t">Well, you can see that if you slap</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2256" target="_blank">00:37:36.800</a></span> | <span class="t">a transformer detection head on it,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2259" target="_blank">00:37:39.400</a></span> | <span class="t">and train it on COCO, it gets to 60.2,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2261" target="_blank">00:37:41.280</a></span> | <span class="t">which is also within spitting distance of SODA,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2264" target="_blank">00:37:44.200</a></span> | <span class="t">which means that it does a very good job</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2265" target="_blank">00:37:45.680</a></span> | <span class="t">of finding visual features.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2268" target="_blank">00:37:48.480</a></span> | <span class="t">But you could say, okay, well, wait a second,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2271" target="_blank">00:37:51.760</a></span> | <span class="t">CLIP got to 59.1, so, like,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2275" target="_blank">00:37:55.600</a></span> | <span class="t">how does this prove your claim at all?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2277" target="_blank">00:37:57.040</a></span> | <span class="t">Because doesn't that mean, like,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2279" target="_blank">00:37:59.000</a></span> | <span class="t">CLIP, which is known to be CLIP-blind</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2280" target="_blank">00:38:00.920</a></span> | <span class="t">and do badly on MMVP,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2282" target="_blank">00:38:02.440</a></span> | <span class="t">it's able to achieve a very high performance</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2284" target="_blank">00:38:04.720</a></span> | <span class="t">on this fine-grained visual features task</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2287" target="_blank">00:38:07.560</a></span> | <span class="t">of object detection?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2288" target="_blank">00:38:08.800</a></span> | <span class="t">Well, they train on, like, tons of data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2291" target="_blank">00:38:11.800</a></span> | <span class="t">They train on, like, Objects 365, COCO, Flickr,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2295" target="_blank">00:38:15.720</a></span> | <span class="t">and everything else.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2297" target="_blank">00:38:17.120</a></span> | <span class="t">And so, I think that this benchmark</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2298" target="_blank">00:38:18.560</a></span> | <span class="t">doesn't do a great job of selling</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2299" target="_blank">00:38:19.800</a></span> | <span class="t">how good of a pre-trained model MV2 is.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2302" target="_blank">00:38:22.040</a></span> | <span class="t">And we would like to see performance</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2305" target="_blank">00:38:25.000</a></span> | <span class="t">on fewer data as examples</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2307" target="_blank">00:38:27.840</a></span> | <span class="t">and not train to convergence on object detection.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2309" target="_blank">00:38:29.760</a></span> | <span class="t">So, seeing it in the real world</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2311" target="_blank">00:38:31.640</a></span> | <span class="t">on, like, a dataset like RoboFlow 100,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2313" target="_blank">00:38:33.320</a></span> | <span class="t">I think would be quite interesting.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2315" target="_blank">00:38:35.760</a></span> | <span class="t">And our, I guess, our final, final pick</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2318" target="_blank">00:38:38.360</a></span> | <span class="t">for paper of 2024 would be Moondream.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2320" target="_blank">00:38:40.240</a></span> | <span class="t">So, introducing Vic to talk about that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2322" target="_blank">00:38:42.280</a></span> | <span class="t">- But overall, that was exactly what I was looking for.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2329" target="_blank">00:38:49.640</a></span> | <span class="t">Like, best of 2024, amazing job.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2331" target="_blank">00:38:51.800</a></span> | <span class="t">Yeah, you can.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2334" target="_blank">00:38:54.480</a></span> | <span class="t">Does anyone have questions</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2336" target="_blank">00:38:56.400</a></span> | <span class="t">while Vic gets set up, like, vision stuff?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2338" target="_blank">00:38:58.400</a></span> | <span class="t">Yeah?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2342" target="_blank">00:39:02.720</a></span> | <span class="t">Vic, go ahead. - Hi.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2346" target="_blank">00:39:06.520</a></span> | <span class="t">Well, while we're getting set up, hi, over here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2349" target="_blank">00:39:09.920</a></span> | <span class="t">Thanks for the really awesome talk.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2351" target="_blank">00:39:11.760</a></span> | <span class="t">One of the things that's been weird and surprising</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2353" target="_blank">00:39:13.760</a></span> | <span class="t">is that the foundation model companies</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2359" target="_blank">00:39:19.280</a></span> | <span class="t">and even these MLMs,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2362" target="_blank">00:39:22.560</a></span> | <span class="t">they're just, like, worse than RTTetter at detection still.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2367" target="_blank">00:39:27.200</a></span> | <span class="t">Like, if you wanted to pay a bunch of money</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2370" target="_blank">00:39:30.280</a></span> | <span class="t">to auto-label your detection dataset,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2372" target="_blank">00:39:32.080</a></span> | <span class="t">if you gave it to OpenAI or Cloud,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2373" target="_blank">00:39:33.920</a></span> | <span class="t">that would be, like, a big waste.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2376" target="_blank">00:39:36.440</a></span> | <span class="t">So, I'm curious, just, like,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2377" target="_blank">00:39:37.520</a></span> | <span class="t">even Palo Gemma 2, like, is worse.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2380" target="_blank">00:39:40.840</a></span> | <span class="t">So, I'm curious to hear your thoughts on, like,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2383" target="_blank">00:39:43.480</a></span> | <span class="t">how come nobody's cracked the code on, like,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2386" target="_blank">00:39:46.040</a></span> | <span class="t">a generalist that really, you know,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2390" target="_blank">00:39:50.320</a></span> | <span class="t">beats a specialist model in computer vision</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2393" target="_blank">00:39:53.360</a></span> | <span class="t">like they have in LM land?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2396" target="_blank">00:39:56.120</a></span> | <span class="t">- I can, can you hear me?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2401" target="_blank">00:40:01.080</a></span> | <span class="t">- Yeah, you gotta press the speak button.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2403" target="_blank">00:40:03.440</a></span> | <span class="t">- Okay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2404" target="_blank">00:40:04.320</a></span> | <span class="t">- Oh, yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2405" target="_blank">00:40:05.160</a></span> | <span class="t">(laughing)</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2407" target="_blank">00:40:07.560</a></span> | <span class="t">- It's a very, very interesting question.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2409" target="_blank">00:40:09.760</a></span> | <span class="t">I think it depends on the specific domain.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2413" target="_blank">00:40:13.360</a></span> | <span class="t">For image classification, it's basically there.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2416" target="_blank">00:40:16.600</a></span> | <span class="t">In the, AIMV2 showed a simple attentional probe</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2420" target="_blank">00:40:20.480</a></span> | <span class="t">on the pre-trained features gets, like, 90%,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2422" target="_blank">00:40:22.520</a></span> | <span class="t">which is as well as anyone does.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2424" target="_blank">00:40:24.960</a></span> | <span class="t">The bigger question, like,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2429" target="_blank">00:40:29.040</a></span> | <span class="t">why isn't it transferring to object detection,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2433" target="_blank">00:40:33.520</a></span> | <span class="t">especially, like, real-time object detection?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2435" target="_blank">00:40:35.760</a></span> | <span class="t">I think, in my mind, there are two answers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2439" target="_blank">00:40:39.240</a></span> | <span class="t">One is object detection is really, really, really,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2443" target="_blank">00:40:43.280</a></span> | <span class="t">the architectures are super domain-specific.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2446" target="_blank">00:40:46.480</a></span> | <span class="t">You know, we see these,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2447" target="_blank">00:40:47.320</a></span> | <span class="t">all these super, super complicated things,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2448" target="_blank">00:40:48.800</a></span> | <span class="t">and it's not super easy to build something</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2452" target="_blank">00:40:52.720</a></span> | <span class="t">that just transfers naturally like that,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2454" target="_blank">00:40:54.440</a></span> | <span class="t">whereas image classification, you know,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2456" target="_blank">00:40:56.440</a></span> | <span class="t">clip pre-training transfers super, super easily.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2459" target="_blank">00:40:59.640</a></span> | <span class="t">And the other thing is, until recently,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2464" target="_blank">00:41:04.240</a></span> | <span class="t">the real-time object detectors</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2466" target="_blank">00:41:06.000</a></span> | <span class="t">didn't even really benefit from pre-training.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2468" target="_blank">00:41:08.560</a></span> | <span class="t">Like, you see the YOLOs that are, like,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2470" target="_blank">00:41:10.200</a></span> | <span class="t">essentially saturated, showing very little difference</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2472" target="_blank">00:41:12.720</a></span> | <span class="t">with pre-training improvements,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2475" target="_blank">00:41:15.440</a></span> | <span class="t">with using pre-trained model at all,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2477" target="_blank">00:41:17.680</a></span> | <span class="t">it's not surprising, necessarily,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2479" target="_blank">00:41:19.640</a></span> | <span class="t">that people aren't looking at the effects</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2482" target="_blank">00:41:22.880</a></span> | <span class="t">of better and better pre-training on real-time detection.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2485" target="_blank">00:41:25.920</a></span> | <span class="t">Maybe that'll change in the next year.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2487" target="_blank">00:41:27.800</a></span> | <span class="t">Does that answer your question?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2489" target="_blank">00:41:29.480</a></span> | <span class="t">- Cool.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2490" target="_blank">00:41:30.320</a></span> | <span class="t">Can you guys hear me?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2493" target="_blank">00:41:33.320</a></span> | <span class="t">Yeah, one thing I want to add is just, like,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2495" target="_blank">00:41:35.040</a></span> | <span class="t">or just to summarize, basically, is that, like,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2497" target="_blank">00:41:37.520</a></span> | <span class="t">until 2024, you know,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2500" target="_blank">00:41:40.080</a></span> | <span class="t">we haven't really seen a combination</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2501" target="_blank">00:41:41.720</a></span> | <span class="t">of transformer-based object detectors and fancy losses,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2506" target="_blank">00:41:46.720</a></span> | <span class="t">and PolyGemma suffers from the same problem,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2509" target="_blank">00:41:49.120</a></span> | <span class="t">which is basically to say that these ResNet,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2512" target="_blank">00:41:52.360</a></span> | <span class="t">or, like, the convolutional models,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2514" target="_blank">00:41:54.280</a></span> | <span class="t">they have all these, like, extreme optimizations</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2518" target="_blank">00:41:58.200</a></span> | <span class="t">for doing object detection,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2520" target="_blank">00:42:00.160</a></span> | <span class="t">but essentially, I think it's kind of been shown now</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2522" target="_blank">00:42:02.840</a></span> | <span class="t">that convolutional models, like,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2524" target="_blank">00:42:04.200</a></span> | <span class="t">just don't benefit from pre-training</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2525" target="_blank">00:42:05.720</a></span> | <span class="t">and just don't, like, have the level of intelligence</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2527" target="_blank">00:42:07.440</a></span> | <span class="t">of transformer models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2528" target="_blank">00:42:08.560</a></span> | <span class="t">- Awesome.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2533" target="_blank">00:42:13.080</a></span> | <span class="t">Balundri.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2534" target="_blank">00:42:14.760</a></span> | <span class="t">- Hi, can you hear me?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2537" target="_blank">00:42:17.040</a></span> | <span class="t">- Cool.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2537" target="_blank">00:42:17.880</a></span> | <span class="t">- I can hear you, see you.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2539" target="_blank">00:42:19.000</a></span> | <span class="t">Are you sharing your screen?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2540" target="_blank">00:42:20.120</a></span> | <span class="t">- I might have forgotten to do that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2542" target="_blank">00:42:22.440</a></span> | <span class="t">Let me do that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2543" target="_blank">00:42:23.280</a></span> | <span class="t">- Sorry, you should've done that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2544" target="_blank">00:42:24.120</a></span> | <span class="t">- Okay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2544" target="_blank">00:42:24.960</a></span> | <span class="t">- Here's your screen.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2555" target="_blank">00:42:35.320</a></span> | <span class="t">- Uh-oh, classic.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2557" target="_blank">00:42:37.160</a></span> | <span class="t">You might have to quit Zoom and restart.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2560" target="_blank">00:42:40.640</a></span> | <span class="t">- What?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2561" target="_blank">00:42:41.480</a></span> | <span class="t">- It's fine.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2563" target="_blank">00:42:43.440</a></span> | <span class="t">Yeah, it's like, we have a capture of your screen.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2566" target="_blank">00:42:46.960</a></span> | <span class="t">I'll just make sure it's visible.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2569" target="_blank">00:42:49.120</a></span> | <span class="t">So let's get to your screen.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2572" target="_blank">00:42:52.440</a></span> | <span class="t">- Okay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2574" target="_blank">00:42:54.080</a></span> | <span class="t">Easy enough.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2574" target="_blank">00:42:54.920</a></span> | <span class="t">- How do you make it, like, wait for you?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2578" target="_blank">00:42:58.880</a></span> | <span class="t">- Quit Zoom.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2583" target="_blank">00:43:03.240</a></span> | <span class="t">No.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2584" target="_blank">00:43:04.080</a></span> | <span class="t">- Yeah, yeah, there you go.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2584" target="_blank">00:43:04.920</a></span> | <span class="t">Perfect.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2585" target="_blank">00:43:05.760</a></span> | <span class="t">- All right.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2587" target="_blank">00:43:07.480</a></span> | <span class="t">Hi, everyone.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2588" target="_blank">00:43:08.320</a></span> | <span class="t">My name is Vik.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2589" target="_blank">00:43:09.440</a></span> | <span class="t">I've been working on Moondream for almost a year now,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2592" target="_blank">00:43:12.560</a></span> | <span class="t">like Sean mentioned.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2593" target="_blank">00:43:13.440</a></span> | <span class="t">I just went and looked,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2594" target="_blank">00:43:14.440</a></span> | <span class="t">and it turns out the first version,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2596" target="_blank">00:43:16.280</a></span> | <span class="t">I released December 29, 2023.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2598" target="_blank">00:43:18.240</a></span> | <span class="t">It's been a fascinating journey.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2601" target="_blank">00:43:21.040</a></span> | <span class="t">So Moondream started off as a tiny vision language model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2605" target="_blank">00:43:25.720</a></span> | <span class="t">Since then, we've extended scope a little bit</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2607" target="_blank">00:43:27.360</a></span> | <span class="t">to also try and build some tooling,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2610" target="_blank">00:43:30.080</a></span> | <span class="t">client libraries, et cetera,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2611" target="_blank">00:43:31.120</a></span> | <span class="t">to help people really deploy it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2614" target="_blank">00:43:34.360</a></span> | <span class="t">Unlike traditional large models</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2617" target="_blank">00:43:37.680</a></span> | <span class="t">that are focused at assistant-type use cases,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2619" target="_blank">00:43:39.360</a></span> | <span class="t">we're laser-focused on building</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2621" target="_blank">00:43:41.480</a></span> | <span class="t">capabilities that developers can,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2626" target="_blank">00:43:46.680</a></span> | <span class="t">sorry, it's,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2629" target="_blank">00:43:49.680</a></span> | <span class="t">yeah, we're laser-focused on building capabilities</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2634" target="_blank">00:43:54.480</a></span> | <span class="t">that developers can use to build vision applications</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2638" target="_blank">00:43:58.200</a></span> | <span class="t">that can run anywhere.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2639" target="_blank">00:43:59.120</a></span> | <span class="t">So in a lot of cases for vision more so than for text,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2642" target="_blank">00:44:02.720</a></span> | <span class="t">you really care about being able to run on the edge,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2645" target="_blank">00:44:05.000</a></span> | <span class="t">run in real time, et cetera.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2646" target="_blank">00:44:06.000</a></span> | <span class="t">So that's really important.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2648" target="_blank">00:44:08.840</a></span> | <span class="t">We have different output modalities that we support.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2652" target="_blank">00:44:12.560</a></span> | <span class="t">There's query where you can ask</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2654" target="_blank">00:44:14.160</a></span> | <span class="t">general English questions about an image</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2655" target="_blank">00:44:15.960</a></span> | <span class="t">and get back human-like answers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2658" target="_blank">00:44:18.080</a></span> | <span class="t">There's captioning,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2659" target="_blank">00:44:19.280</a></span> | <span class="t">which a lot of our users use</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2661" target="_blank">00:44:21.040</a></span> | <span class="t">for generating synthetic datasets</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2663" target="_blank">00:44:23.480</a></span> | <span class="t">to then train diffusion models and whatnot.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2666" target="_blank">00:44:26.360</a></span> | <span class="t">We've done a lot of work to minimize hallucinations there.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2668" target="_blank">00:44:28.200</a></span> | <span class="t">So that's used a lot.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2671" target="_blank">00:44:31.080</a></span> | <span class="t">We have open vocabulary object detection built in,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2673" target="_blank">00:44:33.120</a></span> | <span class="t">similar to a couple of more recent models</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2674" target="_blank">00:44:34.560</a></span> | <span class="t">like Palagem, et cetera,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2675" target="_blank">00:44:35.480</a></span> | <span class="t">where rather than having to train a dedicated model,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2678" target="_blank">00:44:38.040</a></span> | <span class="t">you can just say, "Show me soccer balls in this image,"</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2681" target="_blank">00:44:41.000</a></span> | <span class="t">or, "Show me if there are any deer in this image."</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2682" target="_blank">00:44:42.640</a></span> | <span class="t">It'll detect it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2683" target="_blank">00:44:43.640</a></span> | <span class="t">More recently, earlier this month,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2686" target="_blank">00:44:46.520</a></span> | <span class="t">we released pointing capability</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2688" target="_blank">00:44:48.720</a></span> | <span class="t">where if all you're interested in is the center of an object,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2692" target="_blank">00:44:52.440</a></span> | <span class="t">you can just ask it to point out where that is.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2696" target="_blank">00:44:56.360</a></span> | <span class="t">This is very useful</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2697" target="_blank">00:44:57.200</a></span> | <span class="t">when you're doing EOI automation-type stuff.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2700" target="_blank">00:45:00.360</a></span> | <span class="t">Let's see.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2701" target="_blank">00:45:01.200</a></span> | <span class="t">We have two models out right now.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2705" target="_blank">00:45:05.840</a></span> | <span class="t">There's a general-purpose 2B paramodel,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2708" target="_blank">00:45:08.160</a></span> | <span class="t">which runs fairly...</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2711" target="_blank">00:45:11.080</a></span> | <span class="t">Like, it's fine if you're running on server.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2713" target="_blank">00:45:13.040</a></span> | <span class="t">It's good for our local Lama desktop friends,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2716" target="_blank">00:45:16.720</a></span> | <span class="t">and it can run on flagship mobile phones,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2718" target="_blank">00:45:18.800</a></span> | <span class="t">but it never really fulfilled the promise</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2721" target="_blank">00:45:21.000</a></span> | <span class="t">of being able to run anywhere.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2723" target="_blank">00:45:23.000</a></span> | <span class="t">Last week, we released a new 0.5B paramodel,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2725" target="_blank">00:45:25.880</a></span> | <span class="t">which should be seen more as a 2B paramodel</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2728" target="_blank">00:45:28.920</a></span> | <span class="t">and more as a distillation target</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2730" target="_blank">00:45:30.560</a></span> | <span class="t">as opposed to a general-purpose model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2732" target="_blank">00:45:32.400</a></span> | <span class="t">It's very good if you're running on older mobile phones</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2736" target="_blank">00:45:36.080</a></span> | <span class="t">or edge devices.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2737" target="_blank">00:45:37.760</a></span> | <span class="t">Uses less memory,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2739" target="_blank">00:45:39.400</a></span> | <span class="t">even with our not-yet-fully-optimized inference client.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2742" target="_blank">00:45:42.120</a></span> | <span class="t">So the way we built our 0.5B model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2747" target="_blank">00:45:47.960</a></span> | <span class="t">was to start with the 2B parameter model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2750" target="_blank">00:45:50.880</a></span> | <span class="t">and prune it while doing continual training</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2755" target="_blank">00:45:55.720</a></span> | <span class="t">to retain performance.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2757" target="_blank">00:45:57.400</a></span> | <span class="t">We...</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2758" target="_blank">00:45:58.880</a></span> | <span class="t">Our objective during the pruning</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2760" target="_blank">00:46:00.280</a></span> | <span class="t">was to preserve accuracy across a broad set of benchmarks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2764" target="_blank">00:46:04.760</a></span> | <span class="t">So the way we went about it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2765" target="_blank">00:46:05.840</a></span> | <span class="t">was to estimate the importance</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2767" target="_blank">00:46:07.400</a></span> | <span class="t">of different components of the model,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2768" target="_blank">00:46:08.640</a></span> | <span class="t">like attention heads, channels,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2770" target="_blank">00:46:10.360</a></span> | <span class="t">MLP rows and whatnot,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2774" target="_blank">00:46:14.440</a></span> | <span class="t">using basically a technique based on the gradient.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2777" target="_blank">00:46:17.520</a></span> | <span class="t">I'm not sure how much people want to know details.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2779" target="_blank">00:46:19.320</a></span> | <span class="t">We'll be writing a paper about this,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2780" target="_blank">00:46:20.560</a></span> | <span class="t">but feel free to grab me if you have more questions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2783" target="_blank">00:46:23.920</a></span> | <span class="t">Then we iteratively prune a small chunk</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2786" target="_blank">00:46:26.400</a></span> | <span class="t">that'll minimize loss in performance,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2788" target="_blank">00:46:28.360</a></span> | <span class="t">retrain the model to recover performance and bring it back.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2791" target="_blank">00:46:31.480</a></span> | <span class="t">The 0.5B we released is more of a proof of concept</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2795" target="_blank">00:46:35.040</a></span> | <span class="t">that this is possible.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2795" target="_blank">00:46:35.880</a></span> | <span class="t">I think the thing that's really exciting about this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2797" target="_blank">00:46:37.640</a></span> | <span class="t">is it makes it possible for...</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2799" target="_blank">00:46:39.440</a></span> | <span class="t">For developers to build using the 2B param model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2804" target="_blank">00:46:44.880</a></span> | <span class="t">and just explore, build their application.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2808" target="_blank">00:46:48.400</a></span> | <span class="t">And then once they're ready to deploy,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2810" target="_blank">00:46:50.680</a></span> | <span class="t">figure out what exactly they need out of the model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2812" target="_blank">00:46:52.560</a></span> | <span class="t">and prune those capabilities into a smaller form factor</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2814" target="_blank">00:46:54.680</a></span> | <span class="t">that makes sense for their deployment target.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2816" target="_blank">00:46:56.960</a></span> | <span class="t">So yeah, very excited about that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2820" target="_blank">00:47:00.680</a></span> | <span class="t">Let me talk to you folks a little bit about another problem</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2824" target="_blank">00:47:04.240</a></span> | <span class="t">I've been working on recently,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2825" target="_blank">00:47:05.160</a></span> | <span class="t">which is similar to the clocks example</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2827" target="_blank">00:47:07.040</a></span> | <span class="t">we've been talking about.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2827" target="_blank">00:47:07.880</a></span> | <span class="t">We had a customer reach out who was talking about,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2831" target="_blank">00:47:11.240</a></span> | <span class="t">who had a bunch of gauges out in the field.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2834" target="_blank">00:47:14.240</a></span> | <span class="t">This is very common in manufacturing and oil and gas</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2836" target="_blank">00:47:16.800</a></span> | <span class="t">where you have a bunch of analog devices</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2839" target="_blank">00:47:19.720</a></span> | <span class="t">that you need to monitor.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2840" target="_blank">00:47:20.960</a></span> | <span class="t">It's expensive to have humans look at that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2844" target="_blank">00:47:24.040</a></span> | <span class="t">and monitor stuff and make sure that the system</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2847" target="_blank">00:47:27.320</a></span> | <span class="t">gets shut down when the temperature goes over 80</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2849" target="_blank">00:47:29.440</a></span> | <span class="t">or something.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2850" target="_blank">00:47:30.360</a></span> | <span class="t">So I was like, yeah, this seems easy enough.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2852" target="_blank">00:47:32.240</a></span> | <span class="t">Happy to help you distill that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2854" target="_blank">00:47:34.680</a></span> | <span class="t">Let's get it going.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2856" target="_blank">00:47:36.480</a></span> | <span class="t">Turns out our model couldn't do it at all.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2858" target="_blank">00:47:38.560</a></span> | <span class="t">I went and looked at other open source models</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2860" target="_blank">00:47:40.760</a></span> | <span class="t">to see if I could just generate a bunch of data</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2863" target="_blank">00:47:43.120</a></span> | <span class="t">and learn from that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2863" target="_blank">00:47:43.960</a></span> | <span class="t">That did not work either.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2865" target="_blank">00:47:45.680</a></span> | <span class="t">So I was like, let's look at what the folks</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2867" target="_blank">00:47:47.240</a></span> | <span class="t">with hundreds of billions of dollars in market cap</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2871" target="_blank">00:47:51.000</a></span> | <span class="t">have to offer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2871" target="_blank">00:47:51.840</a></span> | <span class="t">And yeah, that doesn't work either.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2873" target="_blank">00:47:53.960</a></span> | <span class="t">My hypothesis is that the way these models are trained</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2880" target="_blank">00:48:00.040</a></span> | <span class="t">are using a large amount of image text data</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2883" target="_blank">00:48:03.200</a></span> | <span class="t">scraped from the internet.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2884" target="_blank">00:48:04.480</a></span> | <span class="t">And that can be biased.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2885" target="_blank">00:48:05.320</a></span> | <span class="t">In the case of gauges,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2886" target="_blank">00:48:06.640</a></span> | <span class="t">most gauge images aren't gauges in the wild.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2889" target="_blank">00:48:09.440</a></span> | <span class="t">They're product detail images like these,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2892" target="_blank">00:48:12.680</a></span> | <span class="t">where it's always set to zero.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2894" target="_blank">00:48:14.280</a></span> | <span class="t">It's paired with an alt text that says something like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2896" target="_blank">00:48:16.360</a></span> | <span class="t">G-I-V-T-O pressure sensor, PSI zero to 30 or something.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2901" target="_blank">00:48:21.360</a></span> | <span class="t">And so the models are fairly good</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2903" target="_blank">00:48:23.760</a></span> | <span class="t">at picking up those details.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2904" target="_blank">00:48:24.680</a></span> | <span class="t">It'll tell you that it's a pressure gauge.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2906" target="_blank">00:48:26.000</a></span> | <span class="t">It'll tell you what the brand is,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2906" target="_blank">00:48:26.840</a></span> | <span class="t">but it doesn't really learn to pay attention</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2908" target="_blank">00:48:28.680</a></span> | <span class="t">to the needle over there.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2910" target="_blank">00:48:30.880</a></span> | <span class="t">And so, yeah, that's a gap we need to address.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2916" target="_blank">00:48:36.480</a></span> | <span class="t">So naturally my mind goes to like,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2919" target="_blank">00:48:39.800</a></span> | <span class="t">let's use synthetic data to solve this problem.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2922" target="_blank">00:48:42.520</a></span> | <span class="t">That works, but it's problematic</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2926" target="_blank">00:48:46.160</a></span> | <span class="t">because it turned out we needed millions</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2927" target="_blank">00:48:47.760</a></span> | <span class="t">of synthetic gauge images to get to reasonable performance.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2930" target="_blank">00:48:50.920</a></span> | <span class="t">And thinking about it, reading a gauge is like not a one,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2935" target="_blank">00:48:55.480</a></span> | <span class="t">like it's not a zero short process in our minds, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2937" target="_blank">00:48:57.520</a></span> | <span class="t">Like if you had to tell me the reading in Celsius</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2940" target="_blank">00:49:00.440</a></span> | <span class="t">for this real world gauge, there's two dials on there.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2943" target="_blank">00:49:03.920</a></span> | <span class="t">So first you have to figure out which one</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2945" target="_blank">00:49:05.200</a></span> | <span class="t">you have to be paying attention to,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2946" target="_blank">00:49:06.160</a></span> | <span class="t">like the inner one or the outer one.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2947" target="_blank">00:49:07.920</a></span> | <span class="t">You look at the tip of the needle,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2951" target="_blank">00:49:11.080</a></span> | <span class="t">you look at what labels it's between,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2953" target="_blank">00:49:13.360</a></span> | <span class="t">and then you count how many and do some math</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2957" target="_blank">00:49:17.200</a></span> | <span class="t">to figure out what that probably is.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2959" target="_blank">00:49:19.360</a></span> | <span class="t">So what happens if we just add that as chain of thought</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2963" target="_blank">00:49:23.280</a></span> | <span class="t">to give the model a better understanding</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2967" target="_blank">00:49:27.600</a></span> | <span class="t">of the difference up,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2969" target="_blank">00:49:29.720</a></span> | <span class="t">to allow the model to better learn the subtasks</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2971" target="_blank">00:49:31.360</a></span> | <span class="t">it needs to perform to accomplish this goal?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2973" target="_blank">00:49:33.560</a></span> | <span class="t">So you can see in this example,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2976" target="_blank">00:49:36.640</a></span> | <span class="t">this was actually generated</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2977" target="_blank">00:49:37.560</a></span> | <span class="t">by the latest version of our model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2979" target="_blank">00:49:39.480</a></span> | <span class="t">It's like, okay, Celsius is the inner scale.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2982" target="_blank">00:49:42.120</a></span> | <span class="t">It's between 50 and 60.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2983" target="_blank">00:49:43.200</a></span> | <span class="t">There's 10 ticks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2984" target="_blank">00:49:44.280</a></span> | <span class="t">It's at the second tick.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2986" target="_blank">00:49:46.360</a></span> | <span class="t">It's a little debatable here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2987" target="_blank">00:49:47.440</a></span> | <span class="t">Like there's a weird shadow situation going on.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2989" target="_blank">00:49:49.400</a></span> | <span class="t">The dial is off.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2990" target="_blank">00:49:50.440</a></span> | <span class="t">So I don't know what the ground truth is,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2992" target="_blank">00:49:52.040</a></span> | <span class="t">but it works okay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2994" target="_blank">00:49:54.920</a></span> | <span class="t">There's points on there that are,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=2997" target="_blank">00:49:57.640</a></span> | <span class="t">the points over there are actually grounded.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=3000" target="_blank">00:50:00.040</a></span> | <span class="t">I don't know if this is easy to see,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=3001" target="_blank">00:50:01.880</a></span> | <span class="t">but when I click on those,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=3002" target="_blank">00:50:02.880</a></span> | <span class="t">there's a little red dot that moves around.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=3005" target="_blank">00:50:05.120</a></span> | <span class="t">On the image, the model actually has to predict</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=3007" target="_blank">00:50:07.000</a></span> | <span class="t">where those points are.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=3009" target="_blank">00:50:09.880</a></span> | <span class="t">I was originally trying to do this with bounding boxes,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=3011" target="_blank">00:50:11.920</a></span> | <span class="t">but then Malmo came out with pointing capabilities</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=3014" target="_blank">00:50:14.840</a></span> | <span class="t">and it's like pointing is a much better paradigm</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=3017" target="_blank">00:50:17.680</a></span> | <span class="t">to represent this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=3020" target="_blank">00:50:20.960</a></span> | <span class="t">We see pretty good results.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=3023" target="_blank">00:50:23.440</a></span> | <span class="t">This one's actually for clock reading.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=3024" target="_blank">00:50:24.800</a></span> | <span class="t">I couldn't find our chart for gauge reading</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=3027" target="_blank">00:50:27.560</a></span> | <span class="t">at the last minute.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=3028" target="_blank">00:50:28.400</a></span> | <span class="t">So the light blue chart is with our grounded chain of thought.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=3033" target="_blank">00:50:33.400</a></span> | <span class="t">This measures, we built a clock reading benchmark</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=3040" target="_blank">00:50:40.320</a></span> | <span class="t">about 500 images.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=3041" target="_blank">00:50:41.520</a></span> | <span class="t">This measures accuracy on that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=3044" target="_blank">00:50:44.240</a></span> | <span class="t">You can see it's a lot more sample efficient</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=3047" target="_blank">00:50:47.400</a></span> | <span class="t">when you're using the chain of thought to help the model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=3052" target="_blank">00:50:52.080</a></span> | <span class="t">Yep.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=3055" target="_blank">00:50:55.040</a></span> | <span class="t">Another big benefit from this approach</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=3059" target="_blank">00:50:59.040</a></span> | <span class="t">is you can kind of understand how the model is doing it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=3062" target="_blank">00:51:02.800</a></span> | <span class="t">and how it's feeling.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=3064" target="_blank">00:51:04.560</a></span> | <span class="t">So in this example,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=3065" target="_blank">00:51:05.880</a></span> | <span class="t">the actual correct reading is 54 Celsius,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=3068" target="_blank">00:51:08.480</a></span> | <span class="t">the model output 56.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=3070" target="_blank">00:51:10.440</a></span> | <span class="t">Not too bad, but you can actually go and see</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=3073" target="_blank">00:51:13.720</a></span> | <span class="t">where it messed up.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=3075" target="_blank">00:51:15.920</a></span> | <span class="t">Like it got a lot of these right,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=3077" target="_blank">00:51:17.280</a></span> | <span class="t">except instead of saying it was on the seventh tick,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=3082" target="_blank">00:51:22.120</a></span> | <span class="t">it actually predicted that it was the eighth tick</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=3084" target="_blank">00:51:24.600</a></span> | <span class="t">and that's why it went with 56.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=3086" target="_blank">00:51:26.360</a></span> | <span class="t">So now that you know that this is feeling in this way,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=3090" target="_blank">00:51:30.960</a></span> | <span class="t">you can adjust how you're doing the chain of thought</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=3092" target="_blank">00:51:32.760</a></span> | <span class="t">to maybe say like actually count out each tick from 40</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=3095" target="_blank">00:51:35.480</a></span> | <span class="t">instead of just trying to say it's the eighth tick.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=3097" target="_blank">00:51:37.880</a></span> | <span class="t">Or you might say like, okay,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=3098" target="_blank">00:51:38.960</a></span> | <span class="t">I see that there's that middle thing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=3100" target="_blank">00:51:40.320</a></span> | <span class="t">I'll count from there instead of all the way from 40.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=3103" target="_blank">00:51:43.160</a></span> | <span class="t">So it helps a ton.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=3106" target="_blank">00:51:46.080</a></span> | <span class="t">The other thing I'm excited about</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=3107" target="_blank">00:51:47.040</a></span> | <span class="t">is a few short prompting or test time training with this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=3110" target="_blank">00:51:50.480</a></span> | <span class="t">Like if a customer has a specific gauge</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=3112" target="_blank">00:51:52.720</a></span> | <span class="t">that we're seeing minor errors on,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=3115" target="_blank">00:51:55.680</a></span> | <span class="t">they can give us a couple of examples</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=3117" target="_blank">00:51:57.240</a></span> | <span class="t">where like if it's misdetecting the needle,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=3120" target="_blank">00:52:00.560</a></span> | <span class="t">they can go in and correct that in the chain of thought</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=3122" target="_blank">00:52:02.160</a></span> | <span class="t">and hopefully that works the next time.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=3124" target="_blank">00:52:04.120</a></span> | <span class="t">Now, exciting approach,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=3129" target="_blank">00:52:09.040</a></span> | <span class="t">we only apply it to clocks and gauges.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=3130" target="_blank">00:52:10.400</a></span> | <span class="t">The real question is, is it going to generalize?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=3133" target="_blank">00:52:13.320</a></span> | <span class="t">Probably like there's some science from text models</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=3135" target="_blank">00:52:15.760</a></span> | <span class="t">that when you train on a broad number of tasks,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=3137" target="_blank">00:52:17.400</a></span> | <span class="t">it does generalize.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=3138" target="_blank">00:52:18.240</a></span> | <span class="t">And I'm seeing some science with our model as well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=3141" target="_blank">00:52:21.720</a></span> | <span class="t">So in addition to the image-based chain of thought stuff,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=3145" target="_blank">00:52:25.680</a></span> | <span class="t">I also added some spelling-based chain of thought</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=3149" target="_blank">00:52:29.160</a></span> | <span class="t">to help it understand, better understand OCR, I guess.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=3153" target="_blank">00:52:33.600</a></span> | <span class="t">I don't understand why everyone doesn't do this by the way.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=3156" target="_blank">00:52:36.760</a></span> | <span class="t">Like it's trivial benchmark question.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=3158" target="_blank">00:52:38.760</a></span> | <span class="t">It's very, very easy to nail.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=3160" target="_blank">00:52:40.880</a></span> | <span class="t">But I also wanted to support it for stuff</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=3165" target="_blank">00:52:45.000</a></span> | <span class="t">like license plate partial matching,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=3166" target="_blank">00:52:46.640</a></span> | <span class="t">like hey, does any license plate in this image</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=3169" target="_blank">00:52:49.280</a></span> | <span class="t">start with WHA or whatever?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=3170" target="_blank">00:52:50.880</a></span> | <span class="t">So yeah, that sort of worked.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=3174" target="_blank">00:52:54.120</a></span> | <span class="t">All right, that ends my story about the gauges.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=3180" target="_blank">00:53:00.840</a></span> | <span class="t">If you think about what's going on over here,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=3183" target="_blank">00:53:03.800</a></span> | <span class="t">it's interesting that like LLMs</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=3185" target="_blank">00:53:05.880</a></span> | <span class="t">are showing enormous progress in reasoning,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=3190" target="_blank">00:53:10.880</a></span> | <span class="t">especially with the latest set of models that we've seen.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=3194" target="_blank">00:53:14.600</a></span> | <span class="t">But we're not really seeing,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=3197" target="_blank">00:53:17.000</a></span> | <span class="t">I have a feeling that VLMs are lagging behind</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=3200" target="_blank">00:53:20.680</a></span> | <span class="t">as we can see with these tasks</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=3203" target="_blank">00:53:23.440</a></span> | <span class="t">that should be very simple for a human to do</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=3205" target="_blank">00:53:25.080</a></span> | <span class="t">that are very easy to find VLMs failing at.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=3209" target="_blank">00:53:29.560</a></span> | <span class="t">My hypothesis on why this is the case</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=3211" target="_blank">00:53:31.280</a></span> | <span class="t">is because on the internet,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=3213" target="_blank">00:53:33.600</a></span> | <span class="t">there's a ton of data that talks about how to reason.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=3216" target="_blank">00:53:36.440</a></span> | <span class="t">There's books about how to solve problems.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=3218" target="_blank">00:53:38.760</a></span> | <span class="t">There's books critiquing the books</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=3220" target="_blank">00:53:40.240</a></span> | <span class="t">about how to solve problems.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=3221" target="_blank">00:53:41.720</a></span> | <span class="t">But humans are just so good at perception</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=3223" target="_blank">00:53:43.440</a></span> | <span class="t">that we never really talk about it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=3225" target="_blank">00:53:45.640</a></span> | <span class="t">Like maybe in art books where it's like,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=3227" target="_blank">00:53:47.440</a></span> | <span class="t">hey, to show that that mountain is further away,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=3229" target="_blank">00:53:49.880</a></span> | <span class="t">you need to desaturate it a bit or whatever,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=3231" target="_blank">00:53:51.880</a></span> | <span class="t">but the actual data on how to like look at images</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=3236" target="_blank">00:53:56.880</a></span> | <span class="t">isn't really present.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=3238" target="_blank">00:53:58.760</a></span> | <span class="t">Also the data we have is kind of sketched.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=3241" target="_blank">00:54:01.160</a></span> | <span class="t">The best source of data we have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=3242" target="_blank">00:54:02.280</a></span> | <span class="t">is like image all text pairs on the internet</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=3244" target="_blank">00:54:04.520</a></span> | <span class="t">and that's pretty low quality.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=3246" target="_blank">00:54:06.040</a></span> | <span class="t">So yeah, I think our solution here is really just,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=3249" target="_blank">00:54:09.800</a></span> | <span class="t">we need to teach them how to operate on individual tasks</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=3253" target="_blank">00:54:13.240</a></span> | <span class="t">and figure out how to scale that out.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=3255" target="_blank">00:54:15.640</a></span> | <span class="t">All right, yep.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=3259" target="_blank">00:54:19.480</a></span> | <span class="t">So conclusion, at Moondream we're trying</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=3263" target="_blank">00:54:23.200</a></span> | <span class="t">to build amazing VLMs that run everywhere.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=3265" target="_blank">00:54:25.560</a></span> | <span class="t">Very hard problem, much work ahead,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=3267" target="_blank">00:54:27.640</a></span> | <span class="t">but we're making a ton of progress</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=3269" target="_blank">00:54:29.240</a></span> | <span class="t">that I'm really excited about.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=3271" target="_blank">00:54:31.440</a></span> | <span class="t">If anyone wants to chat about more technical details</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=3275" target="_blank">00:54:35.280</a></span> | <span class="t">about how we're doing this or interested in collaborating,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=3277" target="_blank">00:54:37.360</a></span> | <span class="t">please hit me up.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=3278" target="_blank">00:54:38.760</a></span> | <span class="t">- Yeah, like I always, when people say multi-modality,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=3288" target="_blank">00:54:48.800</a></span> | <span class="t">I always think about vision as the first among equals</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=3292" target="_blank">00:54:52.000</a></span> | <span class="t">in all the modalities.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=3293" target="_blank">00:54:53.000</a></span> | <span class="t">So I really appreciate having the experts.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=3297" target="_blank">00:54:57.480</a></span> | <span class="t">- This is the year that vision language models</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=3299" target="_blank">00:54:59.440</a></span> | <span class="t">became mainstream with every model from GPT-40 to 1</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=3303" target="_blank">00:55:03.400</a></span> | <span class="t">to Claude 3 to Gemini 1 and 2 to Lama 3.2</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=3308" target="_blank">00:55:08.000</a></span> | <span class="t">to Mistral's Pixtrol to AI2's Pixmo going multi-modal.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=3313" target="_blank">00:55:13.000</a></span> | <span class="t">We asked Peter and Isaac to highlight the best work</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=3315" target="_blank">00:55:15.680</a></span> | <span class="t">in computer vision for 2024.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=3318" target="_blank">00:55:18.320</a></span> | <span class="t">And they blew us away with the complete overview.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=3321" target="_blank">00:55:21.720</a></span> | <span class="t">As a special bonus, we also got a bonus talk</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=3324" target="_blank">00:55:24.400</a></span> | <span class="t">from Vik Kaurapati at Moondream</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=3326" target="_blank">00:55:26.920</a></span> | <span class="t">who gave an incredible talk</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=3328" target="_blank">00:55:28.240</a></span> | <span class="t">at this year's AI Engineer World's Fair</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=3331" target="_blank">00:55:31.080</a></span> | <span class="t">on his tiny 0.5 billion parameter pruned</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=3334" target="_blank">00:55:34.080</a></span> | <span class="t">vision language model that absolutely slaps.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=3337" target="_blank">00:55:37.400</a></span> | <span class="t">As always, don't forget to check the show notes</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=3339" target="_blank">00:55:39.800</a></span> | <span class="t">for the YouTube link to their talk, as well as their slides.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=76EL7YVAwVo&t=3343" target="_blank">00:55:43.320</a></span> | <span class="t">Watch out and take care.</span></div></div></body></html>