<html><head><title>Generative AI and Long-Term Memory for LLMs (OpenAI, Cohere, OS, Pinecone)</title>
<style>
    body {
        font-family: Arial, sans-serif;
        margin: 0;
        padding: 0;
        background-color: #f4f4f4;
        color: #333;
    }
    .container {
        width: 95%;  /* Increased width to use more space */
        margin: auto;
        overflow: auto;  /* Added to handle overflow by adding a scrollbar if necessary */
    }
    h2, h3 {
        color: #333;
        text-align: center;
    }
    a {
        color: #0000FF;  /* Traditional blue color for links */
        text-decoration: none;
    }
    a:hover {
        text-decoration: underline;
    }
    img {
        display: block;
        margin: auto;
        max-width: 100%;
    }
    .c {
        margin: 10px 0;
    }
    .s, .t {
        display: inline-block;
        margin-right: 5px;
    }
    .max-width {
        max-width: 800px;
        margin: auto;
        padding-left: 20px;
    }
    table {
        width: 100%;
        border-collapse: collapse;
    }
    th, td {
        border: 1px solid #ddd;
        padding: 8px;
        text-align: left;  /* Ensure text alignment is consistent */
    }
    tr:nth-child(even) {
        background-color: #f2f2f2;
    }
    tr:nth-child(odd) {
        background-color: #e6e6e6;
    }
</style>

    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-69VLBMTTP0"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-69VLBMTTP0');
    </script>
    </head><body><div class='container'><a href="index.html">back to index</a><h2>Generative AI and Long-Term Memory for LLMs (OpenAI, Cohere, OS, Pinecone)</h2><a href="https://www.youtube.com/watch?v=rrAChpbwygE"><img src="https://i.ytimg.com/vi/rrAChpbwygE/maxresdefault.jpg" style="width:50%;"></a><div><br></div><h3>Chapters</h3><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=0">0:0</a> What is generative AI<br><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=100">1:40</a> Generative question answering<br><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=246">4:6</a> Two options for helping LLMs<br><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=333">5:33</a> Long-term memory in LLMs<br><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=421">7:1</a> OP stack for retrieval augmented GQA<br><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=528">8:48</a> Testing a few examples<br><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=776">12:56</a> Final thoughts on Generative AI<br><br><div style="text-align: left;"><a href="./rrAChpbwygE.html">Whisper Transcript</a> | <a href="./transcript_rrAChpbwygE.html">Transcript Only Page</a></div><br><div style="max-width: 800px;"><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=0" target="_blank">00:00:00.000</a></span> | <span class="t">Generative AI is what many expect to be the next big technology boom.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=6" target="_blank">00:00:06.760</a></span> | <span class="t">And being what it is, AI, it could have far-reaching implications that are beyond what we would</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=14" target="_blank">00:00:14.140</a></span> | <span class="t">imagine today.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=15" target="_blank">00:00:15.140</a></span> | <span class="t">That's not to say that we have entered the end game of AI with AGI or anything like that,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=21" target="_blank">00:00:21.920</a></span> | <span class="t">but I think that generative AI is a pretty big step forwards.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=27" target="_blank">00:00:27.300</a></span> | <span class="t">And it seems that investors are aware of this as well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=30" target="_blank">00:00:30.420</a></span> | <span class="t">We all know that the majority of industries had a very bad 2022, yet generative AI startups</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=38" target="_blank">00:00:38.320</a></span> | <span class="t">actually received $1.37 billion in funding.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=43" target="_blank">00:00:43.720</a></span> | <span class="t">According to New York Times, that's almost as much as they received in the past five</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=48" target="_blank">00:00:48.920</a></span> | <span class="t">years combined.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=50" target="_blank">00:00:50.440</a></span> | <span class="t">However, it's hardly surprising.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=53" target="_blank">00:00:53.000</a></span> | <span class="t">There were several wow moments that came from generative AI in 2022.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=58" target="_blank">00:00:58.940</a></span> | <span class="t">From generative art tools like OpenAI's DALI 2, Mid-Journey, and Sable Diffusion, to the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=66" target="_blank">00:01:06.360</a></span> | <span class="t">next generation of large language models from the likes of OpenAI with the GPT 3.5 models,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=74" target="_blank">00:01:14.180</a></span> | <span class="t">the Open Source Bloom project, and the chatbots like Goose Lambda, and of course, the chat</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=81" target="_blank">00:01:21.080</a></span> | <span class="t">GPT.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=82" target="_blank">00:01:22.220</a></span> | <span class="t">All of this together marks just the first year of the widespread adoption of generative</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=90" target="_blank">00:01:30.020</a></span> | <span class="t">AI.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=91" target="_blank">00:01:31.020</a></span> | <span class="t">We're still in the very early days of a technology that is poised to completely change the way</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=97" target="_blank">00:01:37.820</a></span> | <span class="t">that we interact with the machines.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=100" target="_blank">00:01:40.580</a></span> | <span class="t">And one of the most thought provoking use cases in how we interact with machines, I</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=106" target="_blank">00:01:46.000</a></span> | <span class="t">think belongs to generative question answering or GQA.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=110" target="_blank">00:01:50.220</a></span> | <span class="t">Now the most simple GQA pipeline consists of nothing more than a user's question or</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=115" target="_blank">00:01:55.980</a></span> | <span class="t">query and a large language model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=119" target="_blank">00:01:59.060</a></span> | <span class="t">The query is passed to the large language model and based on what the large language</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=123" target="_blank">00:02:03.460</a></span> | <span class="t">model has learned during its training, so the knowledge that's stored within the model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=129" target="_blank">00:02:09.100</a></span> | <span class="t">parameters, it will output an answer to your question.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=133" target="_blank">00:02:13.540</a></span> | <span class="t">And we can see that this works for general knowledge questions pretty well across the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=139" target="_blank">00:02:19.180</a></span> | <span class="t">board.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=140" target="_blank">00:02:20.180</a></span> | <span class="t">So if we take a look at OpenAI's DaVinci 003 model, Cohere's extra large model behind</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=146" target="_blank">00:02:26.700</a></span> | <span class="t">the generation endpoint, or even Open Source models that we can access through Hugging</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=151" target="_blank">00:02:31.380</a></span> | <span class="t">Face Transformers, we will get a good answer for general knowledge questions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=157" target="_blank">00:02:37.760</a></span> | <span class="t">So if we ask, "Who was the first person on the moon?" we will get across the board</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=162" target="_blank">00:02:42.780</a></span> | <span class="t">the answer, Neil Armstrong.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=164" target="_blank">00:02:44.600</a></span> | <span class="t">So we can see that this works incredibly well for things that are within the general knowledge</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=169" target="_blank">00:02:49.620</a></span> | <span class="t">base of these large language models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=171" target="_blank">00:02:51.780</a></span> | <span class="t">However, if we start asking more specific or advanced questions, these large language</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=177" target="_blank">00:02:57.020</a></span> | <span class="t">models will begin to fail.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=179" target="_blank">00:02:59.380</a></span> | <span class="t">So if we ask it a very specific question about machine learning methods and specifically</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=185" target="_blank">00:03:05.100</a></span> | <span class="t">NLP and semantic search training methods, like, "Which training method should I use</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=191" target="_blank">00:03:11.460</a></span> | <span class="t">for training sentence transformers when I have just pairs of positive sentences?"</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=197" target="_blank">00:03:17.380</a></span> | <span class="t">Now, you don't need to understand what that means if you don't, no problem.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=202" target="_blank">00:03:22.140</a></span> | <span class="t">One of the correct answers to this should be multiple noted ranking loss, or even just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=207" target="_blank">00:03:27.700</a></span> | <span class="t">ranking loss would be fine as well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=209" target="_blank">00:03:29.420</a></span> | <span class="t">Yeah, if we ask this question, and we'll go ahead and ask what I found to be the best</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=214" target="_blank">00:03:34.780</a></span> | <span class="t">performing of the large language models so far.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=218" target="_blank">00:03:38.540</a></span> | <span class="t">If we ask DaVinci 003 this question, it gives us this answer, and it says, "We need to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=224" target="_blank">00:03:44.020</a></span> | <span class="t">use a supervised training method," which, yes, that is correct, but it doesn't really</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=229" target="_blank">00:03:49.420</a></span> | <span class="t">answer the question.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=231" target="_blank">00:03:51.060</a></span> | <span class="t">It doesn't give us a specific method to use, and the reason it doesn't give us that is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=235" target="_blank">00:03:55.620</a></span> | <span class="t">because the model doesn't know.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=237" target="_blank">00:03:57.980</a></span> | <span class="t">This knowledge has not been encoded into the model weights or parameters during training,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=245" target="_blank">00:04:05.120</a></span> | <span class="t">so it can't answer the question.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=246" target="_blank">00:04:06.540</a></span> | <span class="t">Now, there are two options we can take in order to help the model answer this question.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=252" target="_blank">00:04:12.140</a></span> | <span class="t">The first is we can fine tune the large language model on the text data that would contain</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=259" target="_blank">00:04:19.660</a></span> | <span class="t">this information.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=260" target="_blank">00:04:20.660</a></span> | <span class="t">Now, this can be hard to do.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=262" target="_blank">00:04:22.180</a></span> | <span class="t">It can take a lot of computational resources or money, and it also requires a lot of text</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=268" target="_blank">00:04:28.820</a></span> | <span class="t">data as well, which is not always necessarily available.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=271" target="_blank">00:04:31.940</a></span> | <span class="t">If we just mention the answer once in a single sentence of a million sentences, the large</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=279" target="_blank">00:04:39.620</a></span> | <span class="t">language model might not pick up on that information, and when we ask the question again, it may</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=284" target="_blank">00:04:44.580</a></span> | <span class="t">not have learned the answer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=286" target="_blank">00:04:46.340</a></span> | <span class="t">We need a lot of text data that mentions this in multiple contexts in order for it to learn</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=292" target="_blank">00:04:52.300</a></span> | <span class="t">this information well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=294" target="_blank">00:04:54.780</a></span> | <span class="t">Considering that, our second option, which I think is probably the easier option, is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=299" target="_blank">00:04:59.740</a></span> | <span class="t">to use something called retrieval augmented generation, or in this case, retrieval augmented</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=306" target="_blank">00:05:06.260</a></span> | <span class="t">generative Q&A.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=308" target="_blank">00:05:08.460</a></span> | <span class="t">This simply means that we add what is called a retrieval component to our GQA pipeline.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=315" target="_blank">00:05:15.060</a></span> | <span class="t">Adding this retrieval component allows us to retrieve relevant information.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=321" target="_blank">00:05:21.500</a></span> | <span class="t">If we have that sentence within our million sentences, we can retrieve that sentence and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=325" target="_blank">00:05:25.700</a></span> | <span class="t">feed it into our large language model alongside our query.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=329" target="_blank">00:05:29.620</a></span> | <span class="t">We're essentially creating a secondary source of information.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=334" target="_blank">00:05:34.300</a></span> | <span class="t">Going ahead with this second option of retrieval augmented ML, when we apply it to large language</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=342" target="_blank">00:05:42.260</a></span> | <span class="t">models, we can actually think of it as a form of long-term memory.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=347" target="_blank">00:05:47.500</a></span> | <span class="t">To implement this long-term memory, we need to integrate a knowledge base into our GQA</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=352" target="_blank">00:05:52.980</a></span> | <span class="t">pipeline.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=353" target="_blank">00:05:53.980</a></span> | <span class="t">This knowledge base is the retrieval component that we're talking about, and it allows us</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=358" target="_blank">00:05:58.260</a></span> | <span class="t">to take our query and search through our sentences or paragraphs for relevant information and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=364" target="_blank">00:06:04.140</a></span> | <span class="t">return that relevant information that we can then pass to our larger language model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=369" target="_blank">00:06:09.640</a></span> | <span class="t">As you can see, using this approach, we get much better results.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=374" target="_blank">00:06:14.740</a></span> | <span class="t">Again, using DaVinci 003 for the generation model here, we get, "You should use natural</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=380" target="_blank">00:06:20.660</a></span> | <span class="t">language inference NLI with multiple negative ranking loss."</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=384" target="_blank">00:06:24.540</a></span> | <span class="t">Now, NLI is just one option for the format of the data, essentially, but the answer of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=391" target="_blank">00:06:31.880</a></span> | <span class="t">multiple negative ranking loss is definitely what we're looking for.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=396" target="_blank">00:06:36.060</a></span> | <span class="t">This much better answer is a direct result of adding more contextual information to our</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=402" target="_blank">00:06:42.780</a></span> | <span class="t">query, which we would refer to as source knowledge.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=407" target="_blank">00:06:47.560</a></span> | <span class="t">Source knowledge is basically any knowledge that gets passed through to the large language</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=412" target="_blank">00:06:52.940</a></span> | <span class="t">model within the input of whatever we're putting into the model at inference time, so when</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=418" target="_blank">00:06:58.940</a></span> | <span class="t">we're predicting or generating text.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=421" target="_blank">00:07:01.700</a></span> | <span class="t">In this example, what we use is OpenAI with both generation and actually embedding, which</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=429" target="_blank">00:07:09.820</a></span> | <span class="t">I'll explain in a moment, and also Pinecone Vector Database as our knowledge base.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=436" target="_blank">00:07:16.020</a></span> | <span class="t">Both these together are what we would refer to as the OP stack, so OpenAI, Pinecone.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=441" target="_blank">00:07:21.740</a></span> | <span class="t">This is a more recently popularized option for building very performant AI apps that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=449" target="_blank">00:07:29.100</a></span> | <span class="t">rely on a retrieval component like Retrieval Augmented GQA.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=454" target="_blank">00:07:34.660</a></span> | <span class="t">At query time in this scenario, the pipeline consisted of three main steps.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=460" target="_blank">00:07:40.020</a></span> | <span class="t">The first one, we use an OpenAI embedding endpoint to encode our query into what we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=468" target="_blank">00:07:48.020</a></span> | <span class="t">call dense vector, and step two, we took that encoded query, sent it to our knowledge base,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=475" target="_blank">00:07:55.020</a></span> | <span class="t">which returned relevant context or text passages back to us, which then we combined with our</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=482" target="_blank">00:08:02.700</a></span> | <span class="t">query, and that leads on to step three.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=485" target="_blank">00:08:05.700</a></span> | <span class="t">We take our query and that relevant information, relevant context, and push them into our large</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=492" target="_blank">00:08:12.720</a></span> | <span class="t">language model to generate a natural language answer, and as you can see, adding that extra</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=500" target="_blank">00:08:20.420</a></span> | <span class="t">context from Pinecone, our knowledge base, allowed the large language model to answer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=505" target="_blank">00:08:25.620</a></span> | <span class="t">the question much more accurately.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=508" target="_blank">00:08:28.860</a></span> | <span class="t">Even beyond providing more factual, accurate answers, the fact that we can retrieve the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=514" target="_blank">00:08:34.140</a></span> | <span class="t">sources of information and actually present them to users using this approach also instills</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=520" target="_blank">00:08:40.780</a></span> | <span class="t">user trust in the system, allowing users to confirm the reliability of the information</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=526" target="_blank">00:08:46.380</a></span> | <span class="t">that is being presented to them.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=528" target="_blank">00:08:48.180</a></span> | <span class="t">Let's go ahead and try a few more examples.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=530" target="_blank">00:08:50.180</a></span> | <span class="t">We're going to use the same pipeline that I've already described.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=534" target="_blank">00:08:54.340</a></span> | <span class="t">The knowledge base that we're going to be using, so the data source, is the James Callum</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=539" target="_blank">00:08:59.060</a></span> | <span class="t">YouTube Transcriptions dataset, which is hosted on Hockeying Face Datasets, which is just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=543" target="_blank">00:09:03.980</a></span> | <span class="t">a dataset of transcribed audio from various tech and ML YouTube channels.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=550" target="_blank">00:09:10.560</a></span> | <span class="t">If we ask questions around ML and tech, generally speaking, if it's within the knowledge base,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=555" target="_blank">00:09:15.820</a></span> | <span class="t">it should be able to answer those questions pretty accurately.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=558" target="_blank">00:09:18.060</a></span> | <span class="t">We're going to start with, what is NLI?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=561" target="_blank">00:09:21.020</a></span> | <span class="t">Our first answer is NLI stands for Natural Language Interface, which is wrong.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=567" target="_blank">00:09:27.300</a></span> | <span class="t">The second is correct, so we get Natural Language Inference, NLI is a test that requires pairs</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=572" target="_blank">00:09:32.560</a></span> | <span class="t">of sentences to be labeled as either contradictory, neutral, or entailing inferring each other,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=578" target="_blank">00:09:38.460</a></span> | <span class="t">which is perfect.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=579" target="_blank">00:09:39.900</a></span> | <span class="t">Let's try something else.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=581" target="_blank">00:09:41.260</a></span> | <span class="t">How can I use OpenAI's clip easily?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=589" target="_blank">00:09:49.060</a></span> | <span class="t">No augmentation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=590" target="_blank">00:09:50.060</a></span> | <span class="t">It looks like we're just getting a description of what clip is, which is, I mean, this is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=593" target="_blank">00:09:53.420</a></span> | <span class="t">correct.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=594" target="_blank">00:09:54.420</a></span> | <span class="t">It used to classify images and generate natural language descriptions of them, which is not</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=602" target="_blank">00:10:02.500</a></span> | <span class="t">how I would define it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=604" target="_blank">00:10:04.220</a></span> | <span class="t">In fact, I know that's not what I would go with.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=607" target="_blank">00:10:07.380</a></span> | <span class="t">To use clip, you need access to a GPU and the OpenAI clip repository.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=611" target="_blank">00:10:11.060</a></span> | <span class="t">Yes, you can do that, and you can use the provided scripts to train and evaluate the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=615" target="_blank">00:10:15.940</a></span> | <span class="t">model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=616" target="_blank">00:10:16.940</a></span> | <span class="t">Additionally, you can use a so on and so on.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=619" target="_blank">00:10:19.140</a></span> | <span class="t">Okay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=620" target="_blank">00:10:20.140</a></span> | <span class="t">It's mostly correct, except from the start, it's not really how I would describe clip,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=624" target="_blank">00:10:24.500</a></span> | <span class="t">but then the rest about using the clip repository is correct.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=627" target="_blank">00:10:27.340</a></span> | <span class="t">Now, I got a rate limit error, so let me try and comment this part out and try again.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=633" target="_blank">00:10:33.500</a></span> | <span class="t">Okay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=634" target="_blank">00:10:34.500</a></span> | <span class="t">And what I wanted to get is this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=637" target="_blank">00:10:37.460</a></span> | <span class="t">So you can use OpenAI's clip easily by using the Hugging Face Transformers library, which</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=642" target="_blank">00:10:42.660</a></span> | <span class="t">in my opinion is 100% the easiest way to use the model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=647" target="_blank">00:10:47.660</a></span> | <span class="t">And then we get this, which some library for doing anything with NLP and computer vision.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=652" target="_blank">00:10:52.860</a></span> | <span class="t">Not necessarily that standard with computer vision, but I think I know the source of information</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=657" target="_blank">00:10:57.180</a></span> | <span class="t">that's coming from, which is one of my videos.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=659" target="_blank">00:10:59.620</a></span> | <span class="t">And I probably do say something along those lines, because that is what we're using clip</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=663" target="_blank">00:11:03.180</a></span> | <span class="t">for in this instance.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=665" target="_blank">00:11:05.540</a></span> | <span class="t">And then to get started, you should install PyTorch and the Transformers and Datasets</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=670" target="_blank">00:11:10.460</a></span> | <span class="t">libraries, which is actually usually the case using a Dataset from Datasets.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=677" target="_blank">00:11:17.420</a></span> | <span class="t">And you do need to install PyTorch with Transformers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=680" target="_blank">00:11:20.460</a></span> | <span class="t">So that is really cool.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=681" target="_blank">00:11:21.980</a></span> | <span class="t">And let's ask one more question.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=683" target="_blank">00:11:23.620</a></span> | <span class="t">I want to know what is a good, what is a good de facto model or sentence transformer model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=691" target="_blank">00:11:31.620</a></span> | <span class="t">to use in semantic search?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=694" target="_blank">00:11:34.940</a></span> | <span class="t">And let's see what we get.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=696" target="_blank">00:11:36.660</a></span> | <span class="t">So in no augmentation, we get a popular de facto sentence transformer model for semantic</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=702" target="_blank">00:11:42.060</a></span> | <span class="t">search.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=703" target="_blank">00:11:43.060</a></span> | <span class="t">It's BERT.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=704" target="_blank">00:11:44.060</a></span> | <span class="t">It's a deep learning model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=705" target="_blank">00:11:45.060</a></span> | <span class="t">It's been pre-trained and so on and so on.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=706" target="_blank">00:11:46.980</a></span> | <span class="t">Not actually.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=707" target="_blank">00:11:47.980</a></span> | <span class="t">So here it seems like they're talking about the standard BERT model and not even the sentence</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=713" target="_blank">00:11:53.740</a></span> | <span class="t">transformer or bi-encoded version of BERT.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=716" target="_blank">00:11:56.840</a></span> | <span class="t">So I would say it's definitely wrong.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=718" target="_blank">00:11:58.980</a></span> | <span class="t">So I'm hitting a rate limit again.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=720" target="_blank">00:12:00.860</a></span> | <span class="t">So let me comment this out and run it again.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=724" target="_blank">00:12:04.700</a></span> | <span class="t">Okay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=725" target="_blank">00:12:05.700</a></span> | <span class="t">And here we go.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=726" target="_blank">00:12:06.700</a></span> | <span class="t">So the pre-trained universal sentence encoder model is a good de facto sentence transformer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=732" target="_blank">00:12:12.280</a></span> | <span class="t">model to use in semantic search.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=734" target="_blank">00:12:14.180</a></span> | <span class="t">Now I would disagree with that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=736" target="_blank">00:12:16.220</a></span> | <span class="t">I think there are better models to use, but that is actually, I think one of the most</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=741" target="_blank">00:12:21.740</a></span> | <span class="t">popular ones to use as the sort of first sentence transformer that people end up using or sentence</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=748" target="_blank">00:12:28.380</a></span> | <span class="t">encoding model that people end up using.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=751" target="_blank">00:12:31.420</a></span> | <span class="t">And this is a much more accurate answer than what we got before without the context, without</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=757" target="_blank">00:12:37.380</a></span> | <span class="t">the augmentation, which was BERT, which is not even a sentence transformer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=762" target="_blank">00:12:42.100</a></span> | <span class="t">So I think this is still a pretty good answer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=765" target="_blank">00:12:45.100</a></span> | <span class="t">Personally, I would like to see like an MPNet model or something on there, but that's actually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=770" target="_blank">00:12:50.020</a></span> | <span class="t">more my personal preference.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=771" target="_blank">00:12:51.820</a></span> | <span class="t">So I think this is probably a more broadly accepted answer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=775" target="_blank">00:12:55.940</a></span> | <span class="t">Okay, so as demonstrated, large language models do work incredibly well, particularly for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=781" target="_blank">00:13:01.940</a></span> | <span class="t">general knowledge questions, but they definitely struggle with more niche or more specific</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=787" target="_blank">00:13:07.900</a></span> | <span class="t">pointed questions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=789" target="_blank">00:13:09.820</a></span> | <span class="t">And this typically leads to what we call hallucinations, which is where the model is basically spewing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=796" target="_blank">00:13:16.340</a></span> | <span class="t">out things that are not true.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=799" target="_blank">00:13:19.240</a></span> | <span class="t">And it's really obvious to the user that these models are being inaccurate in what they are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=805" target="_blank">00:13:25.880</a></span> | <span class="t">saying because they can say very untruthful things very convincingly because these models,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=813" target="_blank">00:13:33.060</a></span> | <span class="t">we can think of them as essentially masters of linguistic patterns.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=817" target="_blank">00:13:37.740</a></span> | <span class="t">So they can say things that are completely false and say them in a way that makes them</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=822" target="_blank">00:13:42.980</a></span> | <span class="t">just seem true.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=824" target="_blank">00:13:44.500</a></span> | <span class="t">So to protect us from this issue, we can add what we call a long term memory component</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=832" target="_blank">00:13:52.220</a></span> | <span class="t">to our GQA systems.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=834" target="_blank">00:13:54.420</a></span> | <span class="t">And through this, we benefit from having an external knowledge base to improve system</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=839" target="_blank">00:13:59.260</a></span> | <span class="t">factuality and also improve user trust in the system.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=843" target="_blank">00:14:03.820</a></span> | <span class="t">Naturally, there is a very vast potential for this type of technology.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=850" target="_blank">00:14:10.340</a></span> | <span class="t">And despite being very new, there are already many people using it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=854" target="_blank">00:14:14.900</a></span> | <span class="t">I've seen that you.com have their new YouChat feature, which gives you natural language</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=862" target="_blank">00:14:22.220</a></span> | <span class="t">responses to your search queries.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=865" target="_blank">00:14:25.160</a></span> | <span class="t">I've seen many podcast search apps recently using this technology.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=870" target="_blank">00:14:30.300</a></span> | <span class="t">And there are even rumors of Microsoft with Bing using ChatGPT, which is another form</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=876" target="_blank">00:14:36.980</a></span> | <span class="t">of this technology as a challenger to Google itself.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=882" target="_blank">00:14:42.260</a></span> | <span class="t">So as I think we can all see, there's very big potential and opportunity here for disruption</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=889" target="_blank">00:14:49.620</a></span> | <span class="t">within the space of information retrieval.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=892" target="_blank">00:14:52.660</a></span> | <span class="t">Essentially any industry, any company that relies on information in some way and retrieving</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=900" target="_blank">00:15:00.000</a></span> | <span class="t">that information efficiently can benefit from the use of retrieval augmented generative</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=906" target="_blank">00:15:06.100</a></span> | <span class="t">question answering and other retrieval augmented generative AI technologies.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=911" target="_blank">00:15:11.580</a></span> | <span class="t">So this really represents an opportunity for replacing some of those outdated information</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=916" target="_blank">00:15:16.380</a></span> | <span class="t">retrieval technologies that we use today.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=919" target="_blank">00:15:19.900</a></span> | <span class="t">Now that's it for this video.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=922" target="_blank">00:15:22.180</a></span> | <span class="t">I hope all of this has been somewhat thought provoking, interesting, and useful, but that's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=929" target="_blank">00:15:29.140</a></span> | <span class="t">it for now.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=930" target="_blank">00:15:30.140</a></span> | <span class="t">So thank you very much for watching and I will see you again in the next one.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=935" target="_blank">00:15:35.140</a></span> | <span class="t">Bye.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=935" target="_blank">00:15:35.460</a></span> | <span class="t">Bye.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=936" target="_blank">00:15:36.280</a></span> | <span class="t">Bye.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=937" target="_blank">00:15:37.100</a></span> | <span class="t">Bye.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=937" target="_blank">00:15:37.920</a></span> | <span class="t">Bye.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=938" target="_blank">00:15:38.740</a></span> | <span class="t">Bye.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=939" target="_blank">00:15:39.560</a></span> | <span class="t">Bye.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=940" target="_blank">00:15:40.380</a></span> | <span class="t">Bye.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=941" target="_blank">00:15:41.200</a></span> | <span class="t">Bye.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=942" target="_blank">00:15:42.020</a></span> | <span class="t">Bye.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=943" target="_blank">00:15:43.020</a></span> | <span class="t">Bye.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=944" target="_blank">00:15:44.020</a></span> | <span class="t">Bye.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=945" target="_blank">00:15:45.020</a></span> | <span class="t">Bye.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=946" target="_blank">00:15:46.020</a></span> | <span class="t">Bye.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=947" target="_blank">00:15:47.020</a></span> | <span class="t">Bye.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=948" target="_blank">00:15:48.020</a></span> | <span class="t">Bye.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rrAChpbwygE&t=949" target="_blank">00:15:49.020</a></span> | <span class="t">Bye.</span></div></div></body></html>