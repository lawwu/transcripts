<html><head><title>Lesson 2: Practical Deep Learning for Coders 2022</title>
<style>
    body {
        font-family: Arial, sans-serif;
        margin: 0;
        padding: 0;
        background-color: #f4f4f4;
        color: #333;
    }
    .container {
        width: 80%;
        margin: auto;
        overflow: hidden;
    }
    h2, h3 {
        color: #333;
        text-align: center;
    }
    a {
        color: #0000FF;  /* Traditional blue color for links */
        text-decoration: none;
    }
    a:hover {
        text-decoration: underline;
    }
    img {
        display: block;
        margin: auto;
        max-width: 100%;
    }
    .c {
        margin: 10px 0;
    }
    .s, .t {
        display: inline-block;
        margin-right: 5px;
    }
    .max-width {
        max-width: 800px;
        margin: auto;
        padding-left: 20px;
    }
    table {
        width: 100%;
        border-collapse: collapse;
    }
    th, td {
        border: 1px solid #ddd;
        padding: 8px;
    }
    tr:nth-child(even) {
        background-color: #f2f2f2;
    }
    tr:nth-child(odd) {
        background-color: #e6e6e6;
    }
</style>

    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-69VLBMTTP0"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-69VLBMTTP0');
    </script>
    </head><body><div class='container'><a href="index.html">Back to Index</a><h2>Lesson 2: Practical Deep Learning for Coders 2022</h2><a href="https://www.youtube.com/watch?v=F4tvM4Vb3A0" target="_blank"><img src="https://i.ytimg.com/vi_webp/F4tvM4Vb3A0/maxresdefault.webp" style="width:50%;"></a><div><br></div><h3>Chapters</h3><a href="https://www.youtube.com/watch?v=F4tvM4Vb3A0&t=0 target="_blank"">0:0</a> Introduction<br><a href="https://www.youtube.com/watch?v=F4tvM4Vb3A0&t=55 target="_blank"">0:55</a> Reminder to use the fastai book as a companion to the course<br><a href="https://www.youtube.com/watch?v=F4tvM4Vb3A0&t=126 target="_blank"">2:6</a> aiquizzes.com for quizzes on the book<br><a href="https://www.youtube.com/watch?v=F4tvM4Vb3A0&t=156 target="_blank"">2:36</a> Reminder to use fastai forums for links, notebooks, questions, etc.<br><a href="https://www.youtube.com/watch?v=F4tvM4Vb3A0&t=222 target="_blank"">3:42</a> How to efficiently read the forum with summarizations<br><a href="https://www.youtube.com/watch?v=F4tvM4Vb3A0&t=253 target="_blank"">4:13</a> Showing what students have made since last week<br><a href="https://www.youtube.com/watch?v=F4tvM4Vb3A0&t=405 target="_blank"">6:45</a> Putting models into production<br><a href="https://www.youtube.com/watch?v=F4tvM4Vb3A0&t=490 target="_blank"">8:10</a> Jupyter Notebook extensions<br><a href="https://www.youtube.com/watch?v=F4tvM4Vb3A0&t=589 target="_blank"">9:49</a> Gathering images with the Bing/DuckDuckGo<br><a href="https://www.youtube.com/watch?v=F4tvM4Vb3A0&t=670 target="_blank"">11:10</a> How to find information & source code on Python/fastai functions<br><a href="https://www.youtube.com/watch?v=F4tvM4Vb3A0&t=765 target="_blank"">12:45</a> Cleaning the data that we gathered by training a model<br><a href="https://www.youtube.com/watch?v=F4tvM4Vb3A0&t=817 target="_blank"">13:37</a> Explaining various resizing methods<br><a href="https://www.youtube.com/watch?v=F4tvM4Vb3A0&t=890 target="_blank"">14:50</a> RandomResizedCrop explanation<br><a href="https://www.youtube.com/watch?v=F4tvM4Vb3A0&t=950 target="_blank"">15:50</a> Data augmentation<br><a href="https://www.youtube.com/watch?v=F4tvM4Vb3A0&t=1017 target="_blank"">16:57</a> Question: Does fastai's data augmentation copy the image multiple times?<br><a href="https://www.youtube.com/watch?v=F4tvM4Vb3A0&t=1110 target="_blank"">18:30</a> Training a model so you can clean your data<br><a href="https://www.youtube.com/watch?v=F4tvM4Vb3A0&t=1140 target="_blank"">19:0</a> Confusion matrix explanation<br><a href="https://www.youtube.com/watch?v=F4tvM4Vb3A0&t=1233 target="_blank"">20:33</a> plot_top_losses explanation<br><a href="https://www.youtube.com/watch?v=F4tvM4Vb3A0&t=1330 target="_blank"">22:10</a> ImageClassifierCleaner demonstration<br><a href="https://www.youtube.com/watch?v=F4tvM4Vb3A0&t=1528 target="_blank"">25:28</a> CPU RAM vs GPU RAM (VRAM)<br><a href="https://www.youtube.com/watch?v=F4tvM4Vb3A0&t=1638 target="_blank"">27:18</a> Putting your model into production<br><a href="https://www.youtube.com/watch?v=F4tvM4Vb3A0&t=1820 target="_blank"">30:20</a> Git & Github desktop<br><a href="https://www.youtube.com/watch?v=F4tvM4Vb3A0&t=1890 target="_blank"">31:30</a> For Windows users<br><a href="https://www.youtube.com/watch?v=F4tvM4Vb3A0&t=2220 target="_blank"">37:0</a> Deploying your deep learning model<br><a href="https://www.youtube.com/watch?v=F4tvM4Vb3A0&t=2258 target="_blank"">37:38</a> Dog/cat classifier on Kaggle<br><a href="https://www.youtube.com/watch?v=F4tvM4Vb3A0&t=2335 target="_blank"">38:55</a> Exporting your model with learn.export<br><a href="https://www.youtube.com/watch?v=F4tvM4Vb3A0&t=2380 target="_blank"">39:40</a> Downloading your model on Kaggle<br><a href="https://www.youtube.com/watch?v=F4tvM4Vb3A0&t=2490 target="_blank"">41:30</a> How to take a model you trained to make predictions<br><a href="https://www.youtube.com/watch?v=F4tvM4Vb3A0&t=2610 target="_blank"">43:30</a> learn.predict and timing<br><a href="https://www.youtube.com/watch?v=F4tvM4Vb3A0&t=2662 target="_blank"">44:22</a> Shaping the data to deploy to Gradio<br><a href="https://www.youtube.com/watch?v=F4tvM4Vb3A0&t=2747 target="_blank"">45:47</a> Creating a Gradio interface<br><a href="https://www.youtube.com/watch?v=F4tvM4Vb3A0&t=2905 target="_blank"">48:25</a> Creating a Python script from your notebook with #|export<br><a href="https://www.youtube.com/watch?v=F4tvM4Vb3A0&t=3047 target="_blank"">50:47</a> Hugging Face deployed model<br><a href="https://www.youtube.com/watch?v=F4tvM4Vb3A0&t=3132 target="_blank"">52:12</a> How many epochs do you train for?<br><a href="https://www.youtube.com/watch?v=F4tvM4Vb3A0&t=3196 target="_blank"">53:16</a> How to export and download your model in Google Colab<br><a href="https://www.youtube.com/watch?v=F4tvM4Vb3A0&t=3265 target="_blank"">54:25</a> Getting Python, Jupyter notebooks, and fastai running on your local machine<br><a href="https://www.youtube.com/watch?v=F4tvM4Vb3A0&t=3650 target="_blank"">60:50</a> Comparing deployment platforms: Hugging Face, Gradio, Streamlit<br><a href="https://www.youtube.com/watch?v=F4tvM4Vb3A0&t=3733 target="_blank"">62:13</a> Hugging Face API<br><a href="https://www.youtube.com/watch?v=F4tvM4Vb3A0&t=3900 target="_blank"">65:0</a> Jeremy's deployed website example - tinypets<br><a href="https://www.youtube.com/watch?v=F4tvM4Vb3A0&t=4103 target="_blank"">68:23</a> Get to know your pet example by aabdalla<br><a href="https://www.youtube.com/watch?v=F4tvM4Vb3A0&t=4184 target="_blank"">69:44</a> Source code explanation<br><a href="https://www.youtube.com/watch?v=F4tvM4Vb3A0&t=4268 target="_blank"">71:8</a> Github Pages<br><h3>Transcript</h3><div class='max-width'><p>Hi everybody, welcome to lesson two. Thanks for coming back. Slight change of environment here. We had a bit of an administrative issue at our university. Somebody booked our room, so I'm doing this from the study at home, so sorry about the lack of decorations behind me. I'm actually really, really pumped about this lesson.</p><p>It feels like going back to what things were like in the very early days, because we're doing like some really new, really cool stuff, which, you know, stuff that hasn't really been in courses like this before, so I'm super, super excited. So thanks a lot for coming back after lesson one, and I hope it's worth you coming back.</p><p>I think you're going to love it. I am, yeah, I'm really excited about this. Now remember that the course goes with the book, so be sure that you're not following along in the book because we're covering similar things in different directions, but read the book as well. And remember, the book is entirely available for free as well.</p><p>You can go to the Fast.ai Fastbook repo to see the notebooks, or through course.fast.ai. You can read it there, for example, through Colab. And also, remember that the book, I mean, the book's got a lot of stuff that we didn't cover in the course, like, you know, stuff I find pretty interesting about the history of neural networks, some of which has some really interesting personal stories, actually, as you'll read here.</p><p>And at the end of each chapter, there is a quiz. And remember, it's not a bad idea before you watch the video to read the quiz, so if you want to read the chapter 2 quiz, you know, and then come back, that's not a bad idea. And then make sure that you can do the quiz after you've watched the video and you've read chapter 2 of the book.</p><p>Something I didn't mention last week is there's also a very cool thing that Radak, who I mentioned last week, has written called aikwizzes.com, which is a site specifically for quizzes about the book. And it actually uses repetitive space learning techniques to make sure that you never forget. So do check out aikwizzes.com, it's all brand new questions, they're different to the ones in the book.</p><p>And they're really nicely curated and put together, so check out aikwizzes.com as well. However, as well as course.fast.ai, there's also forums.fast.ai. So course.fast.ai is where you want to go to get links to all the notebooks and Kaggle stuff and all that stuff. You'll also find on forums.fast.ai, every lesson has an official topic, you know, with all the information you'll need.</p><p>Generally there'll be a bit more info on the forums. We try to keep the course lean and mean, and the forums are a bit more detailed. So if you find, in this case, you'd want to look at the Lesson 2 official topic, but here's the Lesson 1 official topic so far.</p><p>So from the Lesson 1 official topic, already after just a few days since I recorded it, we haven't even launched the course, so it's just the people doing it live, there's already a lot of replies, and that can get pretty overwhelming. So be aware that there's a button at the bottom of my post that says summarize this topic.</p><p>And if you hit that, then you'll just see the most upvoted replies, and that's a really good way to just make sure that you hit on the main stuff. So there's the button, and here's what it looks like after you hit it, you'll just get the upvoted stuff from fast.ai legends like Sanyam and Tanishk.</p><p>So hopefully you'll find that a useful way to use the forum. So one of the cool things about this week is I, as promised, put up the Show Us What You've Made post, and already a lot of people have posted. I took the screenshot a few days ago, it's way above 39 replies already, if I remember correctly.</p><p>I had a lot of trouble deciding which ones to share, because they're also good. So I've actually decided to kind of, you know, went the easy route, and I just picked the first. So I'm just going to show you the first ones that were posted, because they're also good.</p><p>So the very, very first one to be posted is a damaged car classifier. So that worked out pretty well, it looks like. And I really liked what Matt the creator said about this is that, you know, wow, it's a bit uncomfortable to run this code, I don't really understand yet, but I'm just doing it.</p><p>And so I'm like, yeah, good on you, Matt, for just for just doing it. That's the way to get started. It's all going to make sense, don't worry. Very nice to see that the next one posted was actually a blog post in fast pages, very nice to see. They were describing some stuff, some experiments that they ran over the week.</p><p>And what did they find? Next one was the amazing beard detector, which if I understand correctly, was mainly because it's very easy to get from bird to beard by just changing one letter to two. And this is doing a very good job of finding gentlemen with beards. So very nice.</p><p>And then this one is another level again, it's a whole in production web app to classify food, which is kind of like extra credit. Apparently we're up to 80 replies now in that thread. Thank you, Sanyam. Very cool. So you know, obviously, so this was actually created by Suvash, who's been doing the courses for a few years now, I believe.</p><p>And so, you know, one day you too might be able to create your very own web app and put it in production. And when I say one day, more specifically today, I'm actually going to show you how to do this right now. So it's actually quite lucky coincidence that Suvash put this up there because it's exactly the topic that we're going to pick today.</p><p>So how do we go about putting a model in production? Step one is, well, you've kind of done step one, right? Step one is step one, two, three, four is figure out what problem you want to solve, figure out how to find the data for it, gather some data and so forth.</p><p>So what's the kind of first step after you've got your data? The next step is data cleaning. And if you go to chapter two of the book, which I'm going to go ahead and open up now. So here is the book, so you can open it in CoLab directly from the course, or if you've cloned it to your computer or whatever, you can do it there.</p><p>So remember, course.fast.ai will run you through exactly how to run these notebooks. And so you can see chapter two is all about putting stuff in production. And so here is chapter two. All right. And so remember, we hit Shift+Enter to run cells, okay, to execute them. And so we're going to go to the part of the book where we start cleaning the data.</p><p>So I'll click on navigate, and we'll go down here, gathering data, there we are. So we could do a quick bit of revision first. So by the way, I will mention a lot of people ask me what are the little tricks I use for getting around Jupyter Notebook so quickly and easily.</p><p>One of the really nice ones, as you'll see, is this navigate menu, which actually doesn't appear by default. So if you install something called Jupyter Notebook Extensions, Jupyter Notebook Extensions, and so you just pip install them, follow the instructions. And then restart Jupyter, obviously, Colab already has a table of contents, by the way.</p><p>This is just if you're using something local, for example. Then you'll see here that this nb extension thing will appear. And if you click on table of contents two, that gets you this handy navigation bar. The other thing I really like is this one here called collapsible headings. And that's the one which gives me these nice little things here to close and open up.</p><p>And actually, that's not even the best part. The best part for me is if I hit right arrow, it goes to the end of a section. And if I hit left arrow, it goes to the start of a section. So it's like if I want to move around sections, I just press up left, down right, down right.</p><p>Very handy. And if you hit left again, when you're here, it'll close it up. Hit right again here. Open it up. So that's collapsible headings. Anyway, a couple of really handy things. And we'll be talking a lot more about getting your notebook set up today at the moment. Okay.</p><p>So one thing you'll notice is in the book, we use the Bing API for searching images. I've just gone ahead and replaced Bing with DDG because the Bing API requires getting an SDK key, which honestly, it's like the hardest thing in deep learning is figuring out that the Bing Azure website and getting that sorted out, DDG doesn't.</p><p>So it's basically exactly the same. And you can, I'll share this notebook as well on the course website and the forum. But all I've basically done is I've replaced Bing with DDG and got rid of the key. So then just like we did last week, we can search for things.</p><p>And so in the book, we did a bear detector because at the time I wrote it, my then toddler was very interested in me helping identify teddy bears. And I certainly didn't want her accidentally cuddling a grizzly bear. So we show here how we can search for grizzly bears just like last week, something that loops through grizzly bears, black bears and teddy bears, just like last week, get rid of the ones that failed just like last week.</p><p>And one thing a few people have asked on the forum is how do I find out more information about basically any Python or fast AI or PyTorch thing? There's a few tips here in the book. One is that if you put a double question mark next to any function name, you'll actually get the whole source code for it.</p><p>And by the same token, if you put a single question mark, you'll get a brief, a little bit of information. If you've got nbdev installed, I think it's nbdev you need, then you can type doc and that'll give you, perhaps most importantly, a link straight to the documentation where you can find out more information.</p><p>And generally there'll be examples as well. And also a link here to the source code, if you want to, let's do that with a control. A link to the source code and that way you can jump around. Notice that in GitHub in the source code you can click on things and jump to their definition, so it's kind of a nice way of skipping around to understand exactly what's going on.</p><p>Okay, so lots of great ways of getting help. But what I promised you is that we're going to now clean the data. So I'm going to tell you something that you might find really surprising. Before you clean the data, you train a model. Now I know that's going to sound really backwards to what you've probably heard a thousand times, which is that first you train, you plane your data and then you train your model.</p><p>But I'm going to show you something really amazing. First we're going to train a model and you'll see why in a moment. So to train a model, just like before, we use a data block to grab our data loaders. There's lots of information here in the book about what's going on here.</p><p>There we go. And so then we can call show batch to see them as per usual. There's a little sidebar here in the book I'll quickly mention, which is about the different ways we can resize. I think we briefly mentioned it last week. We can squish. Last week I used a string.</p><p>You can use a string or this kind of enum-like thing that we have. You can see with a squish, you can end up with some very thin bears. Right? So this is the real site that's the shape of the bear. Here it's become thin. You can see now we've got all of its cubs.</p><p>Are they called cubs? Yeah, bear cubs. So it squished it to make sure we can see the whole picture. Same one here. This one was out of the picture. We squished it. This guy now looks weirdly thin, but we can see the whole thing. So that's squishing. Whereas this one here is cropping.</p><p>It's cropped out just the center of the image, so we get a better aspect ratio, but we lose some stuff. This is so we can get square images. And the other approach is we can use pad. And so you can pad with various different things if you pad with zeros, which is black.</p><p>You can see here now we've got the whole image and the correct aspect ratio. So that's another way we can do it. And you know, different situations, you know, result in different quality models. You can try them all. It doesn't normally make too big a difference, so I wouldn't worry about it too much.</p><p>I'll tell you one though that is very interesting is random resized crop. So instead of saying resize, we can say random resized crop. And if we do that, you'll see we get a different bit of an image every time. So during the week, this week, somebody asked on the forum, I'm trying to, this is a really interesting idea, which it turned out worked slightly, was they wanted to recognize pictures of French and German texts.</p><p>So obviously this is not the normal way you would do that, but just for a bit of experiment. And I love experiments. So they had very big scans of documents and they wanted to figure out whether it was French or German just by looking at images. And they said the pictures were too big.</p><p>What should I do? I said, use random resized crop and that way you would grab different bits of the image. And this is very nice because you could run lots and lots of epochs and get slightly different pictures each time. So this is a very good technique. And this idea of getting different pictures each time from the same image is called data augmentation.</p><p>And again, I'm not going to go into too much detail about data augmentation because it's in the book. But I'll just quickly point out here that if you use this thing called aug transforms, so augmentation transforms, and here I have multiplied them by two. So I've made them super big so you can see them more easily.</p><p>You can see that these teddies are getting turned and squished and warped and recolored and saturated, all this stuff to make every picture different. And generally speaking, if you're training for more than about five or 10 epochs, which you'll probably want to do most of the time, unless you've got a super easy problem to solve, you'll probably want to use random resized crop and these orb transforms.</p><p>Don't put them all equals two, just leave that empty. I'm just putting it there so you can see them more clearly. So I've got an interesting question here from Alex in our audience, which is, is this copying the image multiple times, doing something like this or something like this?</p><p>And the answer is no, we're not copying the image. What happens is that image, so each epoch, every image gets rid. And what happens here is though, is kind of in memory, in RAM, this, the image is being warped, right? It's being, we're cropping it and recoloring it and so forth.</p><p>So it's a real time process that's happening during model training. So there's no copies being stored on your computer, but effectively it's almost like there's infinitely slightly different copies, because that's what the model ends up seeing. So I hope that makes sense, Alex and everybody else. That's a great question.</p><p>Okay, so we've got, we're going to use random resized crop, we're going to use augmentation transforms so that we can get a data loaders from that and then we can go ahead and train our model. We've got about a minute. In this case, we only did four epochs of fine-tuning.</p><p>We'll talk about why there's five here later in the course, but four main epochs of fine-tuning. So we probably didn't really need random resized crop and aug transforms because there's so few epochs, but you know, if you want to run more epochs, this is a good approach. Under 3% error, that's good.</p><p>Okay, so remember I said we're going to train a model before we clean. Okay so let's go ahead and train it. So while that's training, so it's running on my laptop, which only has a 4 gigabyte GPU, it's pretty basic, but it's enough to get started. While that's training, we'll take a look at the next one.</p><p>So the first thing we're going to look at is the confusion matrix and the confusion matrix is something that it only is meaningful for when your labels are categories, right? And what it says is how, what category errors are you making? And so this is showing that the model that we've got at this point, there was two times when there was actually a grizzly bear and it thought it was a black bear.</p><p>And there was two times when there was actually a black bear and it thought it was a grizzly bear. And there was no times that it got teddies wrong, which makes sense, right? Because teddies do look quite different than both. In a lot of situations, when you look at this, it'll kind of give you a real sense of like, okay, well, what are the hard ones, right?</p><p>So for example, if you use the pets dataset that we quite often play within the book in the course, this classification metric matrix for different breeds of pet, you know, really shows you which ones are difficult to identify. And I've actually gone in and like read Wikipedia pages and pet breeding reports about how to identify these particular types because they're so difficult and even experts find it difficult.</p><p>And one of the things I've learned from doing the course actually is black bears and grizzly bears are much harder to pick apart than I had realized. So I'm not even going to try. But I'll show you the really interesting thing we can do with this model is that now we've created this classification interpretation object, which we use for confusion metrics.</p><p>We can say plot top losses. We can say plot top losses. And this is very interesting. What it does is it tells us the places where the loss is the highest. Now, if you remember from the last lesson, the loss is that measurement of how good our model is that we take after each time we run through an item of data.</p><p>A loss will be bad if we predict wrongly and we're very confident about that prediction. So here's an example where we predicted, here's the order here, prediction, actual loss probability, where we predicted grizzly and it was actually a black. And we were 96 percent sure, our model was, that it's a grizzly.</p><p>Now I don't know enough about bears to know whether the model made a mistake or whether this actually is a picture of a grizzly bear. But so an expert would obviously go back and check those out. Now you'll notice a couple here, it's got grizzly, grizzly, teddy, teddy. They're actually correct.</p><p>So why is this loss bad when it's correct? And the reason is because it wasn't very confident, it was only 66 percent confident, right? So here's a teddy, it's only 72 percent confident, right? So you can have a bad loss either by being wrong and confident or being right and unconfident.</p><p>Now the reason that's really helpful is that now we can use something called the FastAI image classifier cleaner to clean up the ones that are wrongly labeled in our data set. So when we use the image classifier cleaner, it actually runs our models, that's why we pass it learn, right?</p><p>And I mentioned that I don't know much about black bears and grizzly bears, but I do know a lot about teddy bears, so I picked teddy bears. And if I click teddy bears, it's now showing me all the things in the training set - you can pick training or valid - that were marked as teddy bears.</p><p>And here's what's really important, they're ordered by loss. So they're ordered by confidence, right? So I can scroll through just the first few and check they're correct, right? And oh, here's a mistake, right? So when I find one that was wrongly gathered, I can either put it if it's in the wrong category, I can choose the correct category, or if it shouldn't be there at all, I click delete.</p><p>So here I'll go ahead and click delete, right? So you can see some reasons that some of these are hard, like, for example, here's two teddies, which is just, I guess, confusing, so it doesn't see that often. This one here is a bit weird looking, it looks almost like a wombat.</p><p>This is an awful lot of teddies. This one maybe is just a bit hard to see from the background, but these other ways they are fine. Fine. So we just looked through the first few, and if you don't see any problem or problems in the first few, you're probably fine.</p><p>So that's cleaned up our training set. Let's clean up our validation set as well. So here's that one it had trouble with, I don't know why it had trouble with that one, but so be it, and we'll have a quick scroll through. Okay, I'm not really sure that's a bear, so I'm just going to go ahead and delete it.</p><p>So teddy something, but you know, it's a problem. Okay, that's not a teddy either. So you see the idea, right? So after we've done that, what that does is the cleaner has now stored a list of the ones that we changed and a list of the ones we deleted.</p><p>So we can now go ahead and run this cell, and so that's going to go through a list of all of the indexes that we said to delete, and it will delete those files, and it'll go through all the ones we said to change, and it will move them to the new folder.</p><p>There we go, done. So this is like not just something for image models, it's just, it's actually a really powerful technique that almost nobody knows about and uses, which is before you start data cleaning, always build a model to find out what things are difficult to recognize in your data, and to find the things that the model can help you find data problems.</p><p>And then as you see them, you'll kind of say, okay, I see the kinds of problems we're having, and you might find better ways to gather the next data set, or you might find ways to kind of automate some of the cleaning and so forth. Okay, so that is data cleaning, and since I only have a four gigabyte GPU, it's very important for me to close and halt, because that will free up the memory.</p><p>So it's important to know on your computer, your normal RAM doesn't really get filled up, because if you use up too much RAM, what will happen is that instead your computer will start, it's called swapping, which is basically to save that RAM onto the hard disk to use it later.</p><p>GPUs can't swap, GPUs when they run out of RAM, that's it, you're done. So you need to make sure that you close any notebooks that are using the GPU that you're not using, and really only use it one thing at a time on the GPU, otherwise you'll almost certainly run out of memory.</p><p>So we've got the first few reds starting to appear, so remember to ask. And in terms of the yellows, it's important to know, as you watch the video, I'm not asking you to run all this code, okay? The idea is to kind of watch it, and then go back and pause, you know, as you go along, or you can just stop, try, stop, try.</p><p>The approach I really like and a lot of students really like for watching these videos is to actually watch the entire thing without touching the keyboard to get a sense of what the video is about, and then go back to the start, and watch it again, and follow along.</p><p>That way, at every point, you know what it is you're doing, you know what's going to happen next, that can actually save you some time. It's a bit of an unusual way, because obviously, like, real life lectures, you can't do that, you can't rewind the professor and get them to say it again, but it's a good way to do it here.</p><p>So now that we've cleaned our data, how are we going to put it into production? Well, in the book, we use something called Voila. And it's pretty good, but there's actually something that I think most of you are probably going to find a lot more useful nowadays, which is something called Hugging Face Spaces, and there's a couple of things you can use with that.</p><p>We're going to look at something called Gradio today. And there isn't a chapter about this in the book, but that doesn't matter, because Tanishk Abraham, who's actually one of the TAs in the course, has written a fantastic blog post about really everything we're going to cover today. So there's a link to that from the forum and from the course page.</p><p>So this is like the equivalent of the chapter of the book, if you like. And I would be remiss if I didn't stop for a moment and call out Tanishk in a big way for two reasons. The first is, he is one of the most helpful people in the FAST AI community.</p><p>He's been around quite a few years, incredibly tenacious, thoughtful, and patient. And also, because I have this fantastic picture of him a few years ago with Conan when he was a famous child prodigy. So now you know what happens to famous child prodigies when they grow up. They became even more famous FAST AI community members and declining experts.</p><p>So you should definitely check out this video of him telling jokes to Conan. I think he's still only 18, actually. This is probably not that many years ago. So thank you very much, Tanishk, for all your help in the community. And sorry if you're embarrassing you with that picture of you as a nine-year-old.</p><p>I'm not really. Haha. Okay. Now, the thing is, for doing radio and hugging-face spaces, well, it's easy enough to start. Okay. We start over here on the hugging-face spaces page, which we've linked to from the forum in the course. And we're going to put a model in production where we're going to take the model we trained.</p><p>And we are going to basically copy it to this hugging-face spaces server and write a user interface for it. So, start, let's go. Create new space. Okay. So you can just go ahead and say, all right, so obviously you sign up. The whole thing's free. And basically everything I'm showing you in this entire course you can do for free.</p><p>That's the good news. Okay. So give it a name, just create something minimal. I always use the Apache license because it means other people can use your work really easily, but you don't have to worry too much about patents. As I say, there's a few different products you can use with it.</p><p>We're going to use radio, also free. If you make it public, then you can share it, which is always a good idea when you're a student, particularly to really be building up that portfolio. Okay. So we're done. We've created a space. Now what do we do next? Well, spaces works through Git.</p><p>Now most software developers will be very familiar with Git. Some data scientists might not be. And so Git's a very, very useful tool. I'm not going to talk about it in detail, but let's kind of quickly learn about how to use it, right? Now Git, you can use it through something called GitHub Desktop, which is actually pretty great.</p><p>And even people who use Git through the console should probably be considering using GitHub Desktop as well, because something's just much faster and easier in it. In fact, I was talking to my friend Hamill today and I was like, "Oh, help. I've accidentally committed this two things by mistake.</p><p>What's the easiest way to revert it?" And he used to work at GitHub, and I thought he was going to have some fancy console command and he was like, "Oh, you should use GitHub Desktop." And you can just click on it and say, "Oh, that's a great idea." So that's useful.</p><p>But most of the time we do use Git from the console, from the terminal. If you're a Linux user or a Mac user, you've already got a terminal. Very straightforward. No worries. If you're a Windows user, I've got good news. Nowadays, Windows has a terrific terminal. It's called Windows Terminal.</p><p>You get it from the Microsoft Store. So in fact, every time you see me using a terminal, I'm actually using that Windows Terminal. It works very well. God knows why I'd want it to have all these ridiculous colors, but there you go. Now what do you want to be running inside your terminal?</p><p>Obviously, if you're in Linux or Mac, you've already got a shell set up. In Windows, you almost certainly want to use Ubuntu. So Windows, believe it or not, can actually run a full Linux environment. And to do it is typing a single line, which is this. So if you go to just Google for WSL install, run PowerShell as administrator, paste that command, wait about five minutes, reboot, you're done.</p><p>You now have a complete Linux environment. Now, one of the reasons I'm mentioning this is I'm going to show you how to do stuff on your own machine now. And so this is like going to a bit of an extra level of geekery, which some data scientists may be less familiar with.</p><p>So don't be worried about the terminal. I think you're going to find it really helpful and much less scary than you expect. And I particularly say like for me, I choose to use Windows and that's because I get all the nice Windows GUI apps and I can draw on my screen and do presentations.</p><p>And I have a complete Linux environment as well. And that Linux environment uses my GPU and everything. So for me, my first choice is to use Windows. My second choice, not very much, really like it, would be to use Linux. Mac is a little bit harder, but it's still usable.</p><p>So some things are a little bit trickier on Mac, but you should be fine. Okay. So whatever you've got at this point, you've now got a terminal available. And so in your terminal, one of the really nice things about using a terminal is you don't have to follow lots of instructions about click here, click here, click here.</p><p>You just copy and paste things. So I'm just going to, you just copy this and you go over to your terminal and you paste it in and you run it. And after you do that, you'll find that you've now got a directory. And so that new directory initially is empty and they tell you, okay, go ahead and create a file with this in it.</p><p>Okay. So how do you create a file with that in it when we're in here in our Linux environment on Windows or in the terminal on Mac or whatever? Well, all you do in Windows, if you just type explorer.exe dot, it'll open up explorer here, or better still on either Mac or Linux or Windows.</p><p>So yeah, so regardless of what computer type of computer on, you can just type code dot and it will pop up official studio code and open up your folder. And so then you can just go ahead and if you haven't used VS code before, it's really well worth taking a few minutes to read the some tutorials.</p><p>It's a really great IDE and so you can go ahead and create an app dot py file like they tell you to, app dot py file containing what they told you to put in it. Here it is here. All right, we're nearly there. So you can now go ahead and save that and then you need to commit it to a radio.</p><p>It's a radio to hugging face bases. So one really easy way is just in Visual Studio itself. You can just click here and that'll give you a place where you type a message and you hit tick and it'll send it off to hacking face bases for you. So once you've done that, you can then go to back to the exact same website you run before, hugging space bases, JPHO minimal, and what you'll find now is that it'll take about a minute to build your website and the website it's building is going to have a radio interface with a text input, a text output, and it's going to run a function called greet on the input and my function called greet will return hello name.</p><p>So that's what it's going to do. There it goes. Let's try it. We'll say hello to Tanishk. I'm not always very good at remembering how to spell his name. I think it's like that. And there you go. So you can see it's put the output for our input. So not a very exciting app, but we now have, to be fair, an app running in production.</p><p>Now I told you we'd have a deep learning model running in production. So now we have to take the next step, which is to turn this into a deep learning model. All right, so first we're going to need a deep learning model, and there's a few different ways we can get ourselves a deep learning model, but basically we're going to have to train one.</p><p>So I've got a couple of examples. I've got a Kaggle example and a Colab example. Maybe I'll quickly show you both. They're going to do the same thing. And I'm just going to create a dog or a cat classifier. Okay, so here's our Kaggle model. I'll click on edit so you can actually see what it looks like in edit view.</p><p>Now Kaggle already has fast.ai installed, but I always put this first just to make sure we've got the latest version. And obviously import stuff. So we're going to grab the pets data set, a function to check whether it's a cat. That's our labeling function for our image data loaders.</p><p>Remember, this is just another way of doing data blocks. It's like a little shorthand. And we create our learner and we fine-tune it. Okay, so that's all stuff we've seen before. So in Kaggle, every notebook has an edit view, which is what you just saw, and a reader view.</p><p>And so you can share your notebook if you want to, and then anybody can read the reader view as you see. And so here you can see it shows you what happened when I ran it. And so I trained it, it took, you know, so that the GPUs on Kaggle are a bit slower than most modern GPUs, but this tool fast enough.</p><p>I mean, it takes five minutes. And there's one bit at the end here, which you haven't seen before, which is I go learn.export and I give it a name. Now that's going to create a file containing our trained model. And that's the only thing, creating this file is the only thing you need a GPU for, right?</p><p>So you do that on Kaggle or on Colab. So here's exactly the same thing on Colab. You can see pip install, here's cat, entire data, image data loaders. So I've got to show batch here as well just for fun, create my learner and then export. So while we wait, I might go ahead and just run that.</p><p>One nice thing about Kaggle is once you've run it and saved it, you can then go to the data tab. And here is basically anything you've saved. It's going to appear here. And here it is model.pickle, right? So now I can go ahead and download that. And that will then be downloaded to my downloads folder.</p><p>And then I need to copy it into the same directory that my Hugging Face Spaces apps in. Now my Hugging Face Spaces app is currently open in my terminal. On Mac you can type open. or in Windows you can type explorer.exe. And that'll bring up your finder or explorer in that directory.</p><p>And so then you can just paste that thing you downloaded into this directory. Something by the way in Windows I do, which I find really helpful, is I actually grab my home directory in Linux and I pin it to my Quick Access. And that way I can always jump in Windows straight to my Linux files.</p><p>Not really something you have to worry about on Mac because it's all kind of integrated. But on Windows they're like, kind of like two separate machines. Okay so let's do, so I created a space called testing and I downloaded my model.pickle and I pasted it into testing. So now we need to know how do we do predictions on a saved model.</p><p>So we've got a notebook for that. Okay so we've got a notebook for that. And so I'm going to take you through how we use a model that we've trained to make predictions. There's a few funny things with hash pipe which I'll explain in a moment, just ignore those for now.</p><p>So we import fast.ai as usual, we import radio as we did before, and we copy in the exact same iscat definition we had before. That's important. Any external functions that you used in your labeling need to be included here as well because that learner refers to those functions. It saves, that learner's saved everything about your model, but it doesn't have the source code to the function so you need to keep those with you.</p><p>So let's try running this. So for example, I just grabbed, as you might have seen in my explorer, I just popped a dog picture there. And so we can create a Python image library image from that dog, turn it into a slightly smaller one so it doesn't overwhelm our whole screen and there's a picture of a dog.</p><p>So how do we make predictions of whether that's a dog or a cat? Well, it's very simple. All we do is instead of training a learner, we use load_learner. We pass in the file name that we saved and that returns a learner. This learner is exactly the same as the learner you get when you finish training.</p><p>So here we are, here's Colab, right, we've just been training a learner. So at the end of that, there's a learner that's been trained. And so we kind of froze it in time, something called a pickle file, which is a Python concept. It's like a frozen object. We saved it to disk, we transferred it to our computer and we've now loaded it and we've now un-throughthought it.</p><p>Here's our unpickled learner. And we can now do whatever we like with that. So one of the things that the, one of the methods that a learner has is a .predict method. So if I run it, you can see even on my laptop, it's basically instance, instant. In fact, we can see how long it took.</p><p>If you, in Jupyter, things that start with percent are called magics, they're special Jupyter things. So for example, there's a thing to see how long something takes. There you go. Okay, so it took 54 milliseconds to figure out that this is not a cat. So it's returning two things.</p><p>Is it a cat as a string? Is it a cat as a zero or a one? And then the probability that it's a dog and the probability that it's a cat. So the probability of zero, false, and one, true of is it a cat? So definitely a dog. So we now want to create a Gradio interface, which basically has this information.</p><p>So Gradio requires us to give it a function that it's going to call, so here's our function. So we're going to call predict, and that returns, as we said, three things. The prediction is a string, the index of that, and the probabilities of whether it's a dog or a cat.</p><p>And what Gradio wants is it wants to get back a dictionary containing each of the possible categories, which in this case is dog or cat, and the probability of each one. So if you haven't done much Python before, a dict of a zip may be something you haven't seen.</p><p>Very handy little idiom. Well worth checking out. Ditto if you haven't seen map before. Anyway, here it is. One slightly annoying thing about Gradio at the moment is that it doesn't handle PyTorch tensors. As you can see here, PyTorch is not returning normal numbers, it's returning tensors, it's not even returning NumPy arrays.</p><p>In fact, Gradio can't handle NumPy either, so we have to change everything just to a normal float. So that's all that this is doing, is changing each one to a float. So for example, if I now call classify image with our doggy image, we get back a dictionary of a dog.</p><p>Yes, definitely cat, definitely not. So now we've got all that, we can go ahead and create a Gradio interface. So Gradio interface is something where we say, well, what function do you call to get the output? What is the input? In this case, we say, oh, the input is an image.</p><p>And so check out the Gradio dots, it can be all kinds of things like a webcam picture or a text or, you know, all kinds of things, give it a shape that it's going to put it into. The output's just going to be a label. So we're going to create very, very simple interface.</p><p>And we can also provide some examples. And so there's a dog, a cat and a don't know, which I'll talk about in a moment, which you'll see here, there's a dog and a cat and a don't know. So once they launch it, it says, okay, that's now running on this URL.</p><p>So if I open that up, you can see now we have just like a Sousvash, we have our own, not yet in production, but running on our own box, Classifier. So let's check, dog. So you can click and upload one or just choose the examples. Yeah, yeah, so it's running on my own laptop, basically instant.</p><p>And I really have to tell you the story about this guy here. This is the don't know, submit, wait, why is it saying a hundred? Normally this says like 50/50. That's a bummer. This model's got messed up my whole story. So last time I trained this model and I ran it on the don't know, it said, it said like, it's almost exactly 50/50.</p><p>And the way we found this picture is I showed my six year old daughter, she was like, what are you doing, dad? Like I'm coding. What are you coding? Oh, you know, dog cat classifier. She checks it out. And the first question is, can I take your keyboard for a moment?</p><p>And she goes to Google and she's like, what is a dog mixed with a cat called? Like, there's no such thing as a dog mix of the cat. Anyway, she goes to the images tab and finds this picture and she's like, look, there's a dog mixed with a cat.</p><p>She said, run it on that, dad, run it on that. And I ran it and it was like 50/50, it had no idea if it was a dog or a cat. Now this model I just retrained today, now I'm sure it's a cat. So there you go. I think I used a slightly different training schedule or something or gave it an extra epoch.</p><p>Anyway, so that's a dog cat, but apparently it's a cat. I guess it is a cat. It's probably right. Shouldn't have trained it for as long. Okay, so there's our interface. Now that's actually running. So you actually have to click the stop button to stop it running. So otherwise you won't be able to do anything else in your notebook.</p><p>Okay. So now we have to turn that into a Python script. So one way to turn it into a Python script would be to copy and paste into a Python script all the things that you need. It would be to copy and paste into a Python script all the parts of this that you need.</p><p>So for example, we wouldn't need this, it's just to check something out. We wouldn't need this, it was just experimenting. This was just experimenting, we'd need this, right? So what I did is I went through and I wrote hash pipe export at the top of each cell that contains information that I'm going to need in my final script.</p><p>And then, so there are the steps, right? And then at the very bottom here, I've imported something called notebook to script from nbdev. And if I run that and pass in the name of this notebook, that creates a file for me called app.py containing that script. So this is a nice, easy way to like when you're working with stuff that's expecting a script and not a notebook, like hugging face spaces does.</p><p>It's fine to just copy and paste into a text file if you like, but I really like this way of doing it because that way I can do all of my experimentation in a notebook. And when I'm done, I just have a cell at the bottom, I just run and export it.</p><p>How does it know to call it app.py? That's because there's a special thing at the top, default export, default x, which says what Python file name to create. So that's just a little trick that I use. So now we've got an app.py, we need to upload this to Gradio.</p><p>How do we do that? You just push it to get. So you can either do it with Visual Studio Code or you can type git commit and then git push. And once you've done that, if we change minimal to testing, I think this hopefully might still be running my previous model because I didn't push it and that way we can see our crazy dog cat.</p><p>All right. So here it is. You can see it running in production. So now this is something that anybody can, if you set it to public, anybody can go here and check out your model and so they can upload it. And so here's my doggy, yep, definitely a dog cat.</p><p>Yeah, I think I might have trained this for Epoch or two less, so it's less confident. Yeah, definitely a cat, dog cat, hey, dog cat, hmm, still thinks it's definitely a cat. Oh, well, so be it. Okay, so that is, okay, so that is an example of getting a simple model in production.</p><p>There's a couple of questions from the forum from the community. Okay, so one person's asking, what's the difference between a PyTorch model and a fast AI learner? Okay, that's fine. We will get to that shortly. Don't know if it'll be this lesson, it might be this lesson or the next lesson.</p><p>And then somebody else asked, basically is asking, how many Epochs do we train for? So as you train a model, your error rate, as you can see, it improves. And so the question is, should I run more? Should I increase the number of Epochs? This is doing three Epochs, right?</p><p>Here's my three Epochs plus one to get started. Look, it's up to you, right? I mean, this is here saying there's a 1% error, I'm okay with the 1% error. You know, if you want it to be better, then you could use more data augmentation and you could train it for longer.</p><p>If you train for long enough, as we'll learn about soon and then maybe the next lesson, if you train for long enough, your error rate actually starts getting worse. And you'll see, we'll learn about why. So basically, yeah, you can train until it's good enough or until you've run out of patience or time or run out of compute, or until the error rate starts getting worse.</p><p>Okay. Oh, and then in Colab, how do you grab your model? All you need to do in Colab is after you've exported it, is if you go into their file browser, you'll actually see it here, right? And you can click download. It's a bit weird. It doesn't like pop up a box saying, where do you want to download it to?</p><p>But instead, this kind of progress circle thing pops up. And so depending on how big it is and so forth, it can take a few minutes. And once that circle fills up, then the browser thing will finally pop up and say, okay, you can save it. Okay. So that's how you actually grab your model.</p><p>So as you can see that the step where you actually need a GPU, you can use these totally free resources, Colab, Kaggle, there are other ones we'll talk about in future lessons. And then you can do everything else on your own computer, including the predictions. The predictions are fast, right?</p><p>So you really don't need to use a GPU for that unless you're doing thousands of them. Okay. Here we go. So now it's asking me to save it. Okay. So now one big issue is we needed to run it on our computer. We needed Python and Jupyter notebooks running on our computer.</p><p>So how do you do that? Because this is where often people get in all kinds of trouble. I'm trying to figure out how to get this all working. So the good news is we've actually got something that makes it very, very straightforward. It's called fast setup. There's really only just one part of it you need.</p><p>So let me show you. It's actually a Git repository on GitHub. GitHub's the place where most Git repositories live. So if you go to GitHub fast.ai/fastsetup, you'll see it. And so what you can do is you can now grab this whole repository just by clicking here on code. And if you've got GitHub Desktop installed, click on open with GitHub Desktop.</p><p>And as you'll see, it brings this up saying, okay, I'm ready to save this for you. So I click clone, so it's making a copy of it. There we go. So basically once you've cloned it, you'll then find there's a file in there called setup-conda.sh, which you know, the details don't really matter, it's pretty short.</p><p>But that's the thing that's going to install Python for you. So at that point, you can just run ./setup-conda and it'll run this installer. Now if you've got Linux or Mac, you've already got Python on your machine. Don't use that Python. And the reason is because that Python, it's called the system Python, it's used by your computer to do computer-y stuff, right?</p><p>It's actually needed. You don't want to be messing with it, I promise you. It always leads to disaster, always. You want your own development version of Python. It's also going to make sure you've got the latest version and all the libraries you want. And by far the best one for you is almost certainly going to be these Conda-based Python distributions.</p><p>So if you run setup-conda, you'll get the one that we recommend. And the one we recommend at the moment is something called MambaForge. So basically once you run it, you'll find that you've now, and you close your terminal and reopen it, you'll find you've now got one extra command, which is called Mamba.</p><p>And Mamba lets you install stuff. So once you've run it, you'll be able to go Mamba, install fast.ai. And that's going to, actually we should probably, I should mention there's actually more, bit more detail about how to install it correctly. If we go to docs.fast.ai, installing, yeah, okay, we actually want to do conda install minus C fast-chain fast-ai, so let's just copy and paste.</p><p>Oh, sorry, not actually. And then the other thing I'll say is instead of using conda, replace conda with Mamba, because nowadays it's much faster, so Mamba install minus C fast-chain fast-ai. Now this is going to install everything you need. It's going to install PyTorch, it's going to install NumPy, it's going to install fast-ai, and so forth, right?</p><p>And so obviously I've already got it. And then the other thing you'll want to do is install nbdev, so you can do exactly the same thing for nbdev. You don't have to, right? It's just, but that'll install Jupyter for you, amongst other things. And so at that point you can now use Jupyter.</p><p>And so the way Jupyter works is, you can see it over here, this is my, I'll go ahead and close it so we can start again. So basically to use Jupyter, you just type Jupyter notebook, okay? And when you run it, it'll say, okay, we're now running a server for you.</p><p>And so if you click on that hyperlink, it'll pop up this, okay, which is exactly what you see me use all the time. Okay, so that hopefully is enough to kind of get you started with Python and with Jupyter notebook. The other way people tend to install software is using something called pip instead of mamba.</p><p>Pretty much anything you can do with mamba, you can also do with pip. But if you've got a GPU, pip isn't going to install things generally so that it works on your GPU. You have to install lots of other stuff, which is annoying. So that's why I kind of tell people to use mamba, but you can use pip otherwise.</p><p>Oh, a little bit of red. Please let us know how we can help you, gang. Okay, so let's see, how are we going with our steps? I forgot I had these steps here to remind myself. We created a space tick, we created a basic interface tick. Okay, we got get set up, we got condor and set up or mamba.</p><p>So mamba and condor are the same thing, mamba is just a much faster version. And we'll keep some notes on the course website, because at the moment, they're actually working on including the speed ups from mamba into condor. So at some point, maybe it'll be fine to use condor again.</p><p>At the moment, condor is way too slow, so don't use it. Okay, we've done dogs versus cats, no problem. Yeah, so we could also look at pet breeds, well, yeah, we'll briefly look at that. Okay, we've used exported learner, no problem, we've used nbdev, no problem, oh, okay, try the API.</p><p>All right, this is interesting. So I think we can all agree, hopefully, that this is pretty cool that we can provide to anybody who wants to use it for free, a real working model and, you know, with Gradio, there's actually, you know, a reasonable amount of flexibility around like how you can make your your website look, you know, using these various different widgets.</p><p>It's not amazingly flexible, but it's flexible enough to kind of, it really just for prototyping. So Gradio has lots of widgets and things that you can use. The other main platform at the moment that Hugging for Spaces supports is called Streamlit. Streamlit is more flexible, I would say, than Gradio.</p><p>Not quite as easy to get started with, but, you know, it's kind of that nice in-between, I guess. So also a very good thing, again, mainly for kind of building prototypes, but at some point you're going to want to build more than a prototype, you want to build an app, right?</p><p>And one of the things I really like about Gradio in Hugging for Spaces is there's a button down here, view the API. So we can actually create any app we want, and the key point is that the thing that does the actual model predictions for us is going to be handled by Hugging for Spaces, Gradio.</p><p>And then we can write a JavaScript application that then talks to that. Now there's going to be two reactions here. Anybody who's done some front-end engineering is going to be like, "Oh, great. I can now literally create anything in the world because I just write any code and I can do it." And they'll be excited.</p><p>And a lot of data scientists might be going, "Uh-oh, I have no idea how to use JavaScript. It's not in my, you know, inventory." So this is, again, where I'm going to say, "Look, don't be too afraid of JavaScript. I mean, obviously one option here is just to kind of say, 'Hey, I've got a model.</p><p>Throw it over the wall to your mate who does know JavaScript and so please create a JavaScript interface for me.'" But let me just give you a sense of like how really not hard this actually is. So there's an endpoint. There's now a URL that's running with our model on it.</p><p>And if you pass it some data, some image data to this URL, it's going to return back the dictionary. So it's going to do exactly the same thing that this UI does, but as an API, as a function we can call. And so it's got like examples here of how to call it.</p><p>So for example, I can actually, let me show you the API as an example using that minimal interface we had, because it's just going to be a bit simpler. So if I click curl, and I copy that, copy that, and paste. So you can see there, oh, that's not a great example passing in "Hello, world." But if I pass in "Tanishk" again, let's see how I'm going with his name, Tanishk.</p><p>Hey, it returns back "Hello, Tanishk." So this is how these APIs work, right? So we can use JavaScript to call the API, and we've got some examples. So I've created a website, and here is my website, Tiny Pets. And on this website, as you can see, it's not the most amazingly beautiful thing, but it's a website, it's a start, right?</p><p>And up here, I've got some examples, here you go, single file, click, choose file, click. And in this example, I'm actually doing full pet classification, so I actually trained a model to classify breed, which we'll talk about more next week, rather than just dog versus cat. So let's pick a particular breed, and we run it.</p><p>Oh, and there it is. Now, not very amazing, right? But the fact is that this is now a JavaScript app, means we have no restrictions about what we can do. And let's take a look at that HTML. That's it. It easily fits in a screen, right? And the basic steps are not crazy, right?</p><p>It's basically we create an import for our photo, we add an event listener that says when you change the photo, call the read function. The read function says create a file reader, read the file. And when you finished loading, call loaded, and then loaded says fetch that. Now that path there is that path there, right, except we're doing the full pets one.</p><p>So this is basically just copied and pasted from their sample. And then grab the JSON, and then grab from the data, the first thing, the confidences, the label, and then set the HTML. So as you can see, it's like, okay, if you haven't used JavaScript before, these are all new things, right?</p><p>But they're not, it's not harder than Python, right? It's just another, it's just another language to learn. And so from here you can start to build up, right? So for example, we've created a multi-file version. So with the multi-file version, let me show you, multi-file, choose, so we can now click a few, so we've got a new fee, a rag doll, a basset hound, and some kind of cat.</p><p>I'm not much of a cat person. So we chose four files, and bang, they've all been classified, apparently it's a Bengal, I wouldn't know. There's our new found one. So there's the multi-file version. And if you look at the code, it's not much more, right? It's now just doing, it's getting all the files and mapping them to read, and now appending each one.</p><p>So not much more code at all. And as you might have seen on our site here, there's a few more examples, which is some of the community during the week has created their own versions. So this one here is, I think this is the, yeah, this is from one of the gradio guys.</p><p>They called it get to know your pet. So if I choose a pet, I kind of, I really like this because it actually combines two models. So first of all, it says, oh, it's a basset hound, and then it lets me type in and ask things about it. So I could say, oh, what kind of tail does it have?</p><p>Search. And so that's now going to call an NLP model, which asks about this, oh, it's a curved saber tail. So what maintenance does it need? So again, like here, you can kind of see how, oh, basset hounds ears must be cleaned inside it out frequently. So this is like combining models.</p><p>So you can see this is something that you couldn't do with just a kind of a ready to go interface. And so the next thing I wanted to point out is, how did we create the website that showed you how to create an HTML file, but like, how do you create those and how do you make a website out of them?</p><p>Well, watch this, let's, here's, here's, here's a, here's the source code to our most basic version. Okay. So I could just save this. There we go. Okay. So we could open that with Visual Studio Code. And what we could actually do is we could just use an explorer or Mac and finder.</p><p>I could just double click on it and here it is, it's a working app. So you can see I don't need any software installed on my computer to use a JavaScript app, right? It's a single file. I just run it in a browser. A browser is our complete execution environment.</p><p>It's a, it's got a debugger. It's got the whole thing. So here you can, you know, here you can see it's, it's just calling out to this external hugging faces endpoint. So I can do it all sitting here on my computer. So once I've got my HTML file that's working fine on my computer in VS code, how do I then put it on the web so that other people can use it?</p><p>Again, the whole thing's free. There's a really cool thing called GitHub Pages, which basically will host your website for you. And because it's just JavaScript, it'll, it'll all work just fine. The easiest way to create a GitHub Pages site, in my opinion, is to use something called Fast Pages, which is a fast AI thing.</p><p>And basically all you do is you follow the setup process. So first it, let's just go through it. So it says generate a copy by clicking on this link. So I click the link. All right. Okay, give it a name. I try to make everything public. I always think it's good, good practice.</p><p>You don't have to create repo generating. Okay. And then there's basically two more steps takes about five minutes. We don't have five minutes. So I'll show you the one that I've already built, which is fast AI slash tiny pets. And so once it's done, you'll basically end up with this empty site, which again, you just go code, open with GitHub desktop or open with Visual Studio, whatever.</p><p>So open with GitHub desktop, or you can copy and paste this to your terminal. And so any one of those is going to get you this whole thing on your computer. You can save your HTML files there, push it back up to GitHub. And what you'll find is fast pages will show you the link to the website that is created for you.</p><p>Now the website that's created for you, you can make it look however you want using something called a theme. So you'll see it's created a file called config.yaml where you can pick a theme. So in this case, I picked a theme called alembic for no particular reason. So GitHub pages uses something called Jekyll.</p><p>And so any Jekyll theme will basically work. So I picked out this theme. And so as a result, when I now save things into this repo, they will automatically appear in this website. And the files automatically appear up here in this list. So if you look at my index, that's the homepage, the entire file is just this.</p><p>The only slightly weird thing is at the top of every GitHub page's file, you have to have three dashes, title and layout, and three dashes, it's called front-matter. And so once you do that and save it, it will appear in your website. So something else I did then I was like, okay, well, that's all very well that Fast.ai has created this website, but I don't really like what it looks like.</p><p>I would have created a different version. No worries. You can go to Fast.ai Tiny Pets and click fork. And when you click fork, it's going to create your own copy. So I did that under my personal account, which is jph00. And look, now I've got my own version of it.</p><p>And now I can make changes here. So I made a few changes. One change I made was I went to config.yaml and I changed the theme to pages themes hacker. So once you fork, one thing you have to do, which normally Fast pages does for you is you do have to go to settings and click pages and actually enable GitHub pages.</p><p>So you basically have to, by default it's turned off. So here you'll just have to turn it on. So use the master branch, root, save, and then it'll say, no worries. It's ready to be published. And so I changed the config.yaml file to point at a different theme. And so if you look at now the jph's tiny pets, it's different.</p><p>Okay. So it's got the same info, but it's much more hackerish because jph00 is a serious hacker, as you can tell from his website. So anyway, look, it's a very brief taste of this kind of world of JavaScript and websites and so forth. But I wanted to give you a sense of like, you know, you don't need any money.</p><p>You don't need any IDEs, you know, you don't really need much code to get started with writing your own web apps. And thanks to hugging face spaces, you know, they'll even host your model for you. And all you need to do is just have the magic string as a thing to call.</p><p>Okay. So signing out hacker Jeremy Howard, thanks very much for watching. And in the next lesson, we're going to be digging into some natural language processing. We're going to be doing some of the same stuff, but we're going to be doing it with language rather than pictures, and we're going to be diving under the hood to see how these models actually work.</p><p>We're going to learn about things like stochastic gradient descent, and we might even be having to brush off a little bit of calculus. I hope I haven't put you off by saying the C word. I will see you next time. Thanks all.</p></div></div></body></html>