<html><head><title>New GPU-Acceleration for PyTorch on M1 Macs! + using with BERT</title>
<style>
    body {
        font-family: Arial, sans-serif;
        margin: 0;
        padding: 0;
        background-color: #f4f4f4;
        color: #333;
    }
    .container {
        width: 80%;
        margin: auto;
        overflow: hidden;
    }
    h2, h3 {
        color: #333;
        text-align: center;
    }
    a {
        color: #0000FF;  /* Traditional blue color for links */
        text-decoration: none;
    }
    a:hover {
        text-decoration: underline;
    }
    img {
        display: block;
        margin: auto;
        max-width: 100%;
    }
    .c {
        margin: 10px 0;
    }
    .s, .t {
        display: inline-block;
        margin-right: 5px;
    }
    .max-width {
        max-width: 800px;
        margin: auto;
        padding-left: 20px;
    }
    table {
        width: 100%;
        border-collapse: collapse;
    }
    th, td {
        border: 1px solid #ddd;
        padding: 8px;
    }
    tr:nth-child(even) {
        background-color: #f2f2f2;
    }
    tr:nth-child(odd) {
        background-color: #e6e6e6;
    }
</style>

    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-69VLBMTTP0"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-69VLBMTTP0');
    </script>
    </head><body><div class='container'><a href="index.html">back to index</a><h2>New GPU-Acceleration for PyTorch on M1 Macs! + using with BERT</h2><a href="https://www.youtube.com/watch?v=uYas6ysyjgY"><img src="https://i.ytimg.com/vi_webp/uYas6ysyjgY/maxresdefault.webp" style="width:50%;"></a><div><br></div><h3>Chapters</h3><a href="https://www.youtube.com/watch?v=uYas6ysyjgY&t=0">0:0</a> Intro<br><a href="https://www.youtube.com/watch?v=uYas6ysyjgY&t=94">1:34</a> PyTorch MPS<br><a href="https://www.youtube.com/watch?v=uYas6ysyjgY&t=297">4:57</a> Installing ARM Python<br><a href="https://www.youtube.com/watch?v=uYas6ysyjgY&t=549">9:9</a> Using PyTorch with GPU<br><a href="https://www.youtube.com/watch?v=uYas6ysyjgY&t=734">12:14</a> BERT on PyTorch GPU<br><a href="https://www.youtube.com/watch?v=uYas6ysyjgY&t=831">13:51</a> Best way to train LLMs on Mac<br><a href="https://www.youtube.com/watch?v=uYas6ysyjgY&t=961">16:1</a> Buffer Size Bug<br><a href="https://www.youtube.com/watch?v=uYas6ysyjgY&t=1044">17:24</a> When we would use Mac M1 GPU<br><br><div style="text-align: left;"><a href="./uYas6ysyjgY.html">Whisper Transcript</a> | <a href="./transcript_uYas6ysyjgY.html">Transcript Only Page</a></div><br><div style="max-width: 800px;"><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uYas6ysyjgY&t=0" target="_blank">00:00:00.000</a></span> | <span class="t">In November 2020, Apple released their latest chips, the M1 chips, based solely on Apple Silicon.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uYas6ysyjgY&t=10" target="_blank">00:00:10.000</a></span> | <span class="t">Now, the M1 chips are incredibly powerful for what they are, but they were not particularly well supported for anyone doing deep learning.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uYas6ysyjgY&t=22" target="_blank">00:00:22.000</a></span> | <span class="t">Now, TensorFlow pretty much straight out of the gate supported GPU acceleration on the new M1 chips, but PyTorch have literally only just released it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uYas6ysyjgY&t=34" target="_blank">00:00:34.000</a></span> | <span class="t">Now, it's been a relatively long wait, and even longer because today's deep learning models rely very heavily on large model sizes and lots of data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uYas6ysyjgY&t=48" target="_blank">00:00:48.000</a></span> | <span class="t">And in order to process that, we can't really rely on CPUs, it's incredibly slow.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uYas6ysyjgY&t=58" target="_blank">00:00:58.000</a></span> | <span class="t">So, that has basically made deep learning very difficult with Macs, and practically no one is going to use a Mac for deep learning when they're using PyTorch, until now.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uYas6ysyjgY&t=72" target="_blank">00:01:12.000</a></span> | <span class="t">That being said, for at least the first generation M1 chips, we're probably not going to be training any large models with them anytime soon, but we can perform inference on them.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uYas6ysyjgY&t=88" target="_blank">00:01:28.000</a></span> | <span class="t">And I will also show you how we can run through training, but it's not going to be anything spectacular.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uYas6ysyjgY&t=95" target="_blank">00:01:35.000</a></span> | <span class="t">So, PyTorch's support for GPUs comes in version 1.12.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uYas6ysyjgY&t=102" target="_blank">00:01:42.000</a></span> | <span class="t">In the latest version of PyTorch, there comes a support for interaction between PyTorch and the lower-level Metal Performance Shaders, or MPS.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uYas6ysyjgY&t=115" target="_blank">00:01:55.000</a></span> | <span class="t">So, it's Metal Performance Shaders that interact with our GPU, almost like a layer between PyTorch and the GPU.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uYas6ysyjgY&t=123" target="_blank">00:02:03.000</a></span> | <span class="t">Another pretty interesting thing, or positive thing, about this integration is that PyTorch have collaborated directly with the Apple Metal team.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uYas6ysyjgY&t=133" target="_blank">00:02:13.000</a></span> | <span class="t">The Metal team deal with the new M1 chips, and the MPS layer has been fine-tuned for each particular M1 chip, or family of M1 chips.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uYas6ysyjgY&t=147" target="_blank">00:02:27.000</a></span> | <span class="t">So, that basically means the performance should be pretty optimal for what it is doing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uYas6ysyjgY&t=155" target="_blank">00:02:35.000</a></span> | <span class="t">So, if we take a look at the release announcement over on PyTorch, we can come down here, and the accelerated training and evaluation - this is on an M1 Ultra, so I believe that's the top M1 chip at the moment -</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uYas6ysyjgY&t=175" target="_blank">00:02:55.000</a></span> | <span class="t">it shows you pretty incredible speed-up. Now, I will say right now that this is not the same on my M1 chip, or it doesn't seem to be.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uYas6ysyjgY&t=189" target="_blank">00:03:09.000</a></span> | <span class="t">So, this is probably the most optimistic that you're going to get, and of course this is in their release, so they're not going to show you the average results, they're just showing you the best they've ever seen.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uYas6ysyjgY&t=203" target="_blank">00:03:23.000</a></span> | <span class="t">So, either way, this is actually pretty good.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uYas6ysyjgY&t=209" target="_blank">00:03:29.000</a></span> | <span class="t">So, the getting started on here is not that helpful, to be honest. This is not how you get started, so we need to go through a few steps to get everything organized and put together.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uYas6ysyjgY&t=229" target="_blank">00:03:49.000</a></span> | <span class="t">With the new MPS-enabled PyTorch, there are two key prerequisites that are not really mentioned in the announcements.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uYas6ysyjgY&t=239" target="_blank">00:03:59.000</a></span> | <span class="t">The first is that you need to have macOS version 12.3 or higher. So, if you don't have that, you'll need to upgrade.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uYas6ysyjgY&t=251" target="_blank">00:04:11.000</a></span> | <span class="t">And the other one is that we need to do everything via the ARM version of Python.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uYas6ysyjgY&t=258" target="_blank">00:04:18.000</a></span> | <span class="t">Now, we can check all of this within our Python environment using this code here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uYas6ysyjgY&t=264" target="_blank">00:04:24.000</a></span> | <span class="t">So, "import platform platform mac version", right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uYas6ysyjgY&t=267" target="_blank">00:04:27.000</a></span> | <span class="t">So, the first value that you get there is, in this case, you can see 12.4. That is the macOS version. That must be 12.3 or more.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uYas6ysyjgY&t=278" target="_blank">00:04:38.000</a></span> | <span class="t">And then the last thing you see here is ARM64. That tells me, okay, I've got the right version of Python running here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uYas6ysyjgY&t=285" target="_blank">00:04:45.000</a></span> | <span class="t">It's using the ARM architecture rather than the x86 architecture.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uYas6ysyjgY&t=291" target="_blank">00:04:51.000</a></span> | <span class="t">In that case, you need to install the new Python environment.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uYas6ysyjgY&t=297" target="_blank">00:04:57.000</a></span> | <span class="t">So, if you're using Anaconda, that's great because we're going to go through the installation of ARM Python with Anaconda.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uYas6ysyjgY&t=306" target="_blank">00:05:06.000</a></span> | <span class="t">So, the first thing we're doing here is specifying that we need to use the ARM64 version of macOS.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uYas6ysyjgY&t=318" target="_blank">00:05:18.000</a></span> | <span class="t">So, we do that here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uYas6ysyjgY&t=320" target="_blank">00:05:20.000</a></span> | <span class="t">We then say, okay, we want to create a new conda environment, call that environment "ml".</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uYas6ysyjgY&t=326" target="_blank">00:05:26.000</a></span> | <span class="t">We are going to use Python 3.9.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uYas6ysyjgY&t=329" target="_blank">00:05:29.000</a></span> | <span class="t">And Conda Forge is probably in your channel list anyway, but just in case, we're also specifying this,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uYas6ysyjgY&t=336" target="_blank">00:05:36.000</a></span> | <span class="t">which is just another repository where we're going to pull all of these versions of different packages from.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uYas6ysyjgY&t=344" target="_blank">00:05:44.000</a></span> | <span class="t">Okay, so once that has installed, we need to go into that environment.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uYas6ysyjgY&t=351" target="_blank">00:05:51.000</a></span> | <span class="t">So, conda activate ml, and then we need to permanently modify the conda subdirectory variable</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uYas6ysyjgY&t=361" target="_blank">00:06:01.000</a></span> | <span class="t">to make sure this is always going to be set to OSX ARM64.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uYas6ysyjgY&t=367" target="_blank">00:06:07.000</a></span> | <span class="t">So, this is to avoid later on when we start pip installing things in this environment,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uYas6ysyjgY&t=373" target="_blank">00:06:13.000</a></span> | <span class="t">this variable may switch back to x86, which we don't want.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uYas6ysyjgY&t=379" target="_blank">00:06:19.000</a></span> | <span class="t">So, we need to make sure it stays with the ARM environment architecture.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uYas6ysyjgY&t=384" target="_blank">00:06:24.000</a></span> | <span class="t">So, we add that in there.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uYas6ysyjgY&t=387" target="_blank">00:06:27.000</a></span> | <span class="t">And you'll probably see this where it says, "Please reactivate your environment."</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uYas6ysyjgY&t=392" target="_blank">00:06:32.000</a></span> | <span class="t">So, to do that, we just do conda activate and run that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uYas6ysyjgY&t=396" target="_blank">00:06:36.000</a></span> | <span class="t">That switches back to the base environment, and then we literally just activate ml again.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uYas6ysyjgY&t=402" target="_blank">00:06:42.000</a></span> | <span class="t">Now, the next step is to actually pip install PyTorch.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uYas6ysyjgY&t=407" target="_blank">00:06:47.000</a></span> | <span class="t">And to do that, we are doing what you can see here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uYas6ysyjgY&t=411" target="_blank">00:06:51.000</a></span> | <span class="t">So, I am running pip install upgrade.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uYas6ysyjgY&t=416" target="_blank">00:06:56.000</a></span> | <span class="t">You might not need the upgrade flag there, but just in case.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uYas6ysyjgY&t=420" target="_blank">00:07:00.000</a></span> | <span class="t">And we need to make sure we are going to install the nightly version of PyTorch</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uYas6ysyjgY&t=426" target="_blank">00:07:06.000</a></span> | <span class="t">because as of this moment, version 1.12 is only released in the nightly releases,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uYas6ysyjgY&t=433" target="_blank">00:07:13.000</a></span> | <span class="t">which is basically just a more frequent but slightly more unstable release.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uYas6ysyjgY&t=437" target="_blank">00:07:17.000</a></span> | <span class="t">It's like PyTorch releases.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uYas6ysyjgY&t=439" target="_blank">00:07:19.000</a></span> | <span class="t">So, you need all of this here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uYas6ysyjgY&t=442" target="_blank">00:07:22.000</a></span> | <span class="t">So, go across, and you'll be able to copy these from the notebook link that I have in the description below.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uYas6ysyjgY&t=453" target="_blank">00:07:33.000</a></span> | <span class="t">Okay, so we run that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uYas6ysyjgY&t=456" target="_blank">00:07:36.000</a></span> | <span class="t">And one thing to just be aware of here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uYas6ysyjgY&t=459" target="_blank">00:07:39.000</a></span> | <span class="t">So, if we have a look here, you'll know it's working and it's being installed in the correct version</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uYas6ysyjgY&t=466" target="_blank">00:07:46.000</a></span> | <span class="t">if you can see that it says ARM64 up here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uYas6ysyjgY&t=472" target="_blank">00:07:52.000</a></span> | <span class="t">Now, if you are just wanting to use PyTorch with NPS, that's ready.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uYas6ysyjgY&t=480" target="_blank">00:08:00.000</a></span> | <span class="t">You can go ahead and start using it, and I'll show you how in a moment.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uYas6ysyjgY&t=484" target="_blank">00:08:04.000</a></span> | <span class="t">But for those of you that are going to want to use home-based transformers, there is an extra step.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uYas6ysyjgY&t=489" target="_blank">00:08:09.000</a></span> | <span class="t">If we try and pip install transformers datasets, this will probably come up with an error for most of you.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uYas6ysyjgY&t=500" target="_blank">00:08:20.000</a></span> | <span class="t">For me, because I have already dealt with the error, it's not popping up.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uYas6ysyjgY&t=505" target="_blank">00:08:25.000</a></span> | <span class="t">And it would say something like, "Error, failed building wheels for tokenizers."</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uYas6ysyjgY&t=511" target="_blank">00:08:31.000</a></span> | <span class="t">So, the reason for that is transformers tokenizers have particular tokenizers that are faster than other tokenizers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uYas6ysyjgY&t=520" target="_blank">00:08:40.000</a></span> | <span class="t">And they are faster because they use Rust.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uYas6ysyjgY&t=523" target="_blank">00:08:43.000</a></span> | <span class="t">Now, Rust is not installed from the ARM distribution of Python that we have at the moment.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uYas6ysyjgY&t=530" target="_blank">00:08:50.000</a></span> | <span class="t">So, from within our new environment, all we need to do is install Rust like this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uYas6ysyjgY&t=538" target="_blank">00:08:58.000</a></span> | <span class="t">Once we execute that, we can just go ahead and pip install transformers and datasets like we did before.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uYas6ysyjgY&t=545" target="_blank">00:09:05.000</a></span> | <span class="t">And with that, we are ready to move on to our code.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uYas6ysyjgY&t=549" target="_blank">00:09:09.000</a></span> | <span class="t">So, for this example, all we need are these libraries here with Torch, transformers, datasets, which we already installed.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uYas6ysyjgY&t=557" target="_blank">00:09:17.000</a></span> | <span class="t">And we can check that our PyTorch installation has NPS using this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uYas6ysyjgY&t=564" target="_blank">00:09:24.000</a></span> | <span class="t">So, Torch has NPS. If you run that, you should see true.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uYas6ysyjgY&t=568" target="_blank">00:09:28.000</a></span> | <span class="t">And that means you're okay and you're ready to go with the rest of the code.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uYas6ysyjgY&t=572" target="_blank">00:09:32.000</a></span> | <span class="t">So, here I'm just pulling some data. I'm not really going to go into detail on this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uYas6ysyjgY&t=576" target="_blank">00:09:36.000</a></span> | <span class="t">I'm not pulling much data because it's a pretty low-spec M1 chip and I can't handle much.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uYas6ysyjgY&t=586" target="_blank">00:09:46.000</a></span> | <span class="t">So, here I'm initializing a tokenizer model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uYas6ysyjgY&t=590" target="_blank">00:09:50.000</a></span> | <span class="t">That doesn't really make sense to you. It doesn't really matter for the sake of trying to understand PyTorch here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uYas6ysyjgY&t=596" target="_blank">00:09:56.000</a></span> | <span class="t">I'm tokenizing my text and then this is being run on CPU.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uYas6ysyjgY&t=602" target="_blank">00:10:02.000</a></span> | <span class="t">This bit here. I have not moved anything to the NPS device yet or the GPU.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uYas6ysyjgY&t=611" target="_blank">00:10:11.000</a></span> | <span class="t">This is all being run on CPU and we get 547 milliseconds as an average time for this model processing our data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uYas6ysyjgY&t=622" target="_blank">00:10:22.000</a></span> | <span class="t">And this is a BERT model. BERT based on case from the HuggingFace library.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uYas6ysyjgY&t=628" target="_blank">00:10:28.000</a></span> | <span class="t">Now, that's CPU performance. If we want to test with NPS, there's a few things we do.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uYas6ysyjgY&t=634" target="_blank">00:10:34.000</a></span> | <span class="t">So, we have to move everything. The tensors and the model over to the NPS device.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uYas6ysyjgY&t=640" target="_blank">00:10:40.000</a></span> | <span class="t">So, we set that. So, Torch device NPS and then we just say model to device and tokens.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uYas6ysyjgY&t=647" target="_blank">00:10:47.000</a></span> | <span class="t">So, your tensors to device as well. And that's all that device is.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uYas6ysyjgY&t=654" target="_blank">00:10:54.000</a></span> | <span class="t">Now, if we rerun it, we see it's faster. So, we get 345 milliseconds.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uYas6ysyjgY&t=660" target="_blank">00:11:00.000</a></span> | <span class="t">So, a little bit better. Not a massive difference, but it is a little bit better.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uYas6ysyjgY&t=665" target="_blank">00:11:05.000</a></span> | <span class="t">Now, this is using a batch size of 64. I tested a few different batch sizes with this data set.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uYas6ysyjgY&t=672" target="_blank">00:11:12.000</a></span> | <span class="t">And I found that when it comes to larger batch sizes, at least for your inference and I imagine it's the same for training,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uYas6ysyjgY&t=684" target="_blank">00:11:24.000</a></span> | <span class="t">we get a more significant difference as we increase the number of values in each batch.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uYas6ysyjgY&t=694" target="_blank">00:11:34.000</a></span> | <span class="t">So, really at 64 there's very little difference and you can kind of see that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uYas6ysyjgY&t=700" target="_blank">00:11:40.000</a></span> | <span class="t">But then when we increase that, the difference is definitely more pronounced.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uYas6ysyjgY&t=706" target="_blank">00:11:46.000</a></span> | <span class="t">So, we're not using like A100 GPUs or anything here. We're just using the first generation MacBook Pro,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uYas6ysyjgY&t=716" target="_blank">00:11:56.000</a></span> | <span class="t">the almost base specs with the M1 chip. That's all we're using. So, it's not going to blow us away.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uYas6ysyjgY&t=725" target="_blank">00:12:05.000</a></span> | <span class="t">But nonetheless, just for the sake of moving our model and tensors to a different device, I think this is pretty cool.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uYas6ysyjgY&t=734" target="_blank">00:12:14.000</a></span> | <span class="t">Now, for those of you that are interested in using this with Hugging Face,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uYas6ysyjgY&t=739" target="_blank">00:12:19.000</a></span> | <span class="t">I will quickly go through the setup for that because there's a few things to just be aware of.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uYas6ysyjgY&t=745" target="_blank">00:12:25.000</a></span> | <span class="t">So, as before, I'm doing the same thing. We've got our device, it's NPS, using the same data set.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uYas6ysyjgY&t=751" target="_blank">00:12:31.000</a></span> | <span class="t">Nothing new here. And we go through everything.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uYas6ysyjgY&t=756" target="_blank">00:12:36.000</a></span> | <span class="t">And in this case, anything beyond the batch size of one. So, this is training the entire bare model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uYas6ysyjgY&t=767" target="_blank">00:12:47.000</a></span> | <span class="t">Anything beyond a batch size of one just doesn't work. So, you can see I'm here. Where's my batch?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uYas6ysyjgY&t=774" target="_blank">00:12:54.000</a></span> | <span class="t">So, I'm creating the batch size here or the data loader here, batch size of one.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uYas6ysyjgY&t=782" target="_blank">00:13:02.000</a></span> | <span class="t">We have our model to device because we're using NPS.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uYas6ysyjgY&t=787" target="_blank">00:13:07.000</a></span> | <span class="t">And when we're loading the different tensors for training in this training loop here,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uYas6ysyjgY&t=796" target="_blank">00:13:16.000</a></span> | <span class="t">I'm just moving them to the same NPS device. So, anything beyond a batch size of one, I even tried just two.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uYas6ysyjgY&t=804" target="_blank">00:13:24.000</a></span> | <span class="t">My kernel just died. So, yeah, you just have to be wary of that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uYas6ysyjgY&t=810" target="_blank">00:13:30.000</a></span> | <span class="t">But with one, this is actually showing a little bit lower than what I got in my other test, but I tried it a few times.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uYas6ysyjgY&t=817" target="_blank">00:13:37.000</a></span> | <span class="t">I got around 90 minutes to train that. Now, that's a full bare model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uYas6ysyjgY&t=824" target="_blank">00:13:44.000</a></span> | <span class="t">And we're probably not going to use MacBook or at least not this MacBook for training that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uYas6ysyjgY&t=830" target="_blank">00:13:50.000</a></span> | <span class="t">Now, moving on to maybe the way that we would actually use this on Mac is with these NLP models and so on,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uYas6ysyjgY&t=843" target="_blank">00:14:03.000</a></span> | <span class="t">we typically have two components. We have the larger core of the model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uYas6ysyjgY&t=848" target="_blank">00:14:08.000</a></span> | <span class="t">So, that would be BERT itself that has been pre-trained by Google or Microsoft or someone else.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uYas6ysyjgY&t=855" target="_blank">00:14:15.000</a></span> | <span class="t">That includes a lot of parameters. But then there's a smaller head on top of that, which is just like a couple of linear layers</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uYas6ysyjgY&t=862" target="_blank">00:14:22.000</a></span> | <span class="t">that does something with the output from that BERT model. So, for example, it might classify the text for you.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uYas6ysyjgY&t=869" target="_blank">00:14:29.000</a></span> | <span class="t">And, well, OK, we can't train a full BERT model, but we can train that head on top, which is called fine tuning.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uYas6ysyjgY&t=877" target="_blank">00:14:37.000</a></span> | <span class="t">So, let's go ahead and have a look at how we might do that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uYas6ysyjgY&t=883" target="_blank">00:14:43.000</a></span> | <span class="t">So, this is a little more complex because to do this, we need to initialize our entire model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uYas6ysyjgY&t=889" target="_blank">00:14:49.000</a></span> | <span class="t">So, the whole BERT model and the head, and then we need to freeze all of the BERT model parameters.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uYas6ysyjgY&t=897" target="_blank">00:14:57.000</a></span> | <span class="t">So, an extra step, although it's not anything complicated.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uYas6ysyjgY&t=910" target="_blank">00:15:10.000</a></span> | <span class="t">So, here I'm initializing my model again. I'm using BERT for sequence classification.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uYas6ysyjgY&t=918" target="_blank">00:15:18.000</a></span> | <span class="t">And this is all I'm doing. So, for param in model BERT parameters, I'm setting the parameter requires grad equal to false.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uYas6ysyjgY&t=928" target="_blank">00:15:28.000</a></span> | <span class="t">And taking a look at the model printout from PyTorch, we can see there's this BERT at the top,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uYas6ysyjgY&t=936" target="_blank">00:15:36.000</a></span> | <span class="t">and then there's this classification part at the bottom. Those are all the parameters in our model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uYas6ysyjgY&t=944" target="_blank">00:15:44.000</a></span> | <span class="t">And when we're saying model dot BERT dot parameters, we are accessing all the BERT parameters.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uYas6ysyjgY&t=950" target="_blank">00:15:50.000</a></span> | <span class="t">And we're leaving those classified parameters at the end there. So, that is how that works.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uYas6ysyjgY&t=957" target="_blank">00:15:57.000</a></span> | <span class="t">And then we just go down and we would run this again.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uYas6ysyjgY&t=961" target="_blank">00:16:01.000</a></span> | <span class="t">Okay. So, in this case, we have this error. And in order to get rid of that,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uYas6ysyjgY&t=967" target="_blank">00:16:07.000</a></span> | <span class="t">we actually need to downgrade to a slightly older version of the PyTorch nightly release,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uYas6ysyjgY&t=974" target="_blank">00:16:14.000</a></span> | <span class="t">because this is just a bug that's popped up in one of the more recent releases.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uYas6ysyjgY&t=979" target="_blank">00:16:19.000</a></span> | <span class="t">Hopefully, by the time you're watching this, it won't be a problem anymore, so you won't get this anyway.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uYas6ysyjgY&t=983" target="_blank">00:16:23.000</a></span> | <span class="t">But if you do, this is how we fix it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uYas6ysyjgY&t=986" target="_blank">00:16:26.000</a></span> | <span class="t">So, all we do is we pip install, make sure we upgrade, and we make sure that we do this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uYas6ysyjgY&t=992" target="_blank">00:16:32.000</a></span> | <span class="t">We don't actually need to include TorchVision and TorchAudio here, they're included anyway.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uYas6ysyjgY&t=996" target="_blank">00:16:36.000</a></span> | <span class="t">So, we just downgrade to this nightly release. Okay. That will fix the problem.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uYas6ysyjgY&t=1005" target="_blank">00:16:45.000</a></span> | <span class="t">And then we can go back to our code and rerun everything.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uYas6ysyjgY&t=1008" target="_blank">00:16:48.000</a></span> | <span class="t">Okay. So, in the little GPU usage history, we can see this peak now that the model is training.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uYas6ysyjgY&t=1017" target="_blank">00:16:57.000</a></span> | <span class="t">And that's just going to basically save the top for the next four or so minutes</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uYas6ysyjgY&t=1024" target="_blank">00:17:04.000</a></span> | <span class="t">and go back down once we finish training.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uYas6ysyjgY&t=1028" target="_blank">00:17:08.000</a></span> | <span class="t">So, let's skip ahead to this finishing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uYas6ysyjgY&t=1032" target="_blank">00:17:12.000</a></span> | <span class="t">Okay. So, that has just finished. You can see GPU usage ramps down straight away.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uYas6ysyjgY&t=1038" target="_blank">00:17:18.000</a></span> | <span class="t">And yeah, so it took pretty much one second shy of four minutes.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uYas6ysyjgY&t=1045" target="_blank">00:17:25.000</a></span> | <span class="t">So, it's relatively quick. Nothing special, but to say I'm just on the first generation M1</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uYas6ysyjgY&t=1053" target="_blank">00:17:33.000</a></span> | <span class="t">using the almost base level MacBook Pro, it's not bad.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uYas6ysyjgY&t=1058" target="_blank">00:17:38.000</a></span> | <span class="t">I think, realistically, you're probably not going to do much training on the M1 chips</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uYas6ysyjgY&t=1065" target="_blank">00:17:45.000</a></span> | <span class="t">unless you have maybe M1 Ultra. Maybe in that case, you would.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uYas6ysyjgY&t=1069" target="_blank">00:17:49.000</a></span> | <span class="t">But even then, I'm not sure the chips are really at that level yet.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uYas6ysyjgY&t=1076" target="_blank">00:17:56.000</a></span> | <span class="t">Nonetheless, I'm sure with the future iterations of NPS and NPS-enabled PyTorch in particular,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uYas6ysyjgY&t=1087" target="_blank">00:18:07.000</a></span> | <span class="t">it's probably going to improve.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uYas6ysyjgY&t=1089" target="_blank">00:18:09.000</a></span> | <span class="t">So, it's useful to be able to do this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uYas6ysyjgY&t=1093" target="_blank">00:18:13.000</a></span> | <span class="t">And even maybe just for a little bit of maybe fine-tuning or at least inference here and there,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uYas6ysyjgY&t=1100" target="_blank">00:18:20.000</a></span> | <span class="t">I think this is pretty useful.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uYas6ysyjgY&t=1102" target="_blank">00:18:22.000</a></span> | <span class="t">And it's exciting to see where this will actually go.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uYas6ysyjgY&t=1106" target="_blank">00:18:26.000</a></span> | <span class="t">Maybe in the future, deep learning is for -- or Macs are for deep learning.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uYas6ysyjgY&t=1112" target="_blank">00:18:32.000</a></span> | <span class="t">That would be interesting.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uYas6ysyjgY&t=1115" target="_blank">00:18:35.000</a></span> | <span class="t">So, yeah, it's pretty cool.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uYas6ysyjgY&t=1119" target="_blank">00:18:39.000</a></span> | <span class="t">I know the setup for this is kind of finicky.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uYas6ysyjgY&t=1124" target="_blank">00:18:44.000</a></span> | <span class="t">So, I hope this has at least helped you figure that out.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uYas6ysyjgY&t=1129" target="_blank">00:18:49.000</a></span> | <span class="t">So, I hope all this has been interesting.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uYas6ysyjgY&t=1132" target="_blank">00:18:52.000</a></span> | <span class="t">Thank you very much for watching, and I will see you again in the next one.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uYas6ysyjgY&t=1138" target="_blank">00:18:58.000</a></span> | <span class="t">Bye.</span></div></div></body></html>