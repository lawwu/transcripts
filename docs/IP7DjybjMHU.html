<html><head><title>GPT-4o Mini Arrives In Global IT Outage, But How ‘Mini’ Is Its Intelligence?</title>
<style>
    body {
        font-family: Arial, sans-serif;
        margin: 0;
        padding: 0;
        background-color: #f4f4f4;
        color: #333;
    }
    .container {
        width: 95%;  /* Increased width to use more space */
        margin: auto;
        overflow: auto;  /* Added to handle overflow by adding a scrollbar if necessary */
    }
    h2, h3 {
        color: #333;
        text-align: center;
    }
    a {
        color: #0000FF;  /* Traditional blue color for links */
        text-decoration: none;
    }
    a:hover {
        text-decoration: underline;
    }
    img {
        display: block;
        margin: auto;
        max-width: 100%;
    }
    .c {
        margin: 10px 0;
    }
    .s, .t {
        display: inline-block;
        margin-right: 5px;
    }
    .max-width {
        max-width: 800px;
        margin: auto;
        padding-left: 20px;
    }
    table {
        width: 100%;
        border-collapse: collapse;
    }
    th, td {
        border: 1px solid #ddd;
        padding: 8px;
        text-align: left;  /* Ensure text alignment is consistent */
    }
    tr:nth-child(even) {
        background-color: #f2f2f2;
    }
    tr:nth-child(odd) {
        background-color: #e6e6e6;
    }
</style>

    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-69VLBMTTP0"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-69VLBMTTP0');
    </script>
    </head><body><div class='container'><a href="index.html">back to index</a><h2>GPT-4o Mini Arrives In Global IT Outage, But How ‘Mini’ Is Its Intelligence?</h2><a href="https://www.youtube.com/watch?v=IP7DjybjMHU"><img src="https://i.ytimg.com/vi/IP7DjybjMHU/maxresdefault.jpg" style="width:50%;"></a><div><br></div><div style="text-align: left;"><a href="./IP7DjybjMHU.html">Whisper Transcript</a> | <a href="./transcript_IP7DjybjMHU.html">Transcript Only Page</a></div><br><div style="max-width: 800px;"><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=0" target="_blank">00:00:00.000</a></span> | <span class="t">The newest model from OpenAI is here and in a possible coincidence the world's IT infrastructure</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=7" target="_blank">00:00:07.600</a></span> | <span class="t">is now down. But seriously, I'm just glad your connection still works as you join me to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=12" target="_blank">00:00:12.720</a></span> | <span class="t">investigate the brand new GPT-40 mini which is quite a mouthful but is claimed to have superior</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=20" target="_blank">00:00:20.240</a></span> | <span class="t">intelligence for its size. Because millions of free users might soon be using it, I've been</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=26" target="_blank">00:00:26.480</a></span> | <span class="t">scrutinizing the model relentlessly since last night and will explain why OpenAI might need to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=31" target="_blank">00:00:31.760</a></span> | <span class="t">be a bit more honest about the trade-offs involved and where they might head next. So here is the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=38" target="_blank">00:00:38.320</a></span> | <span class="t">claim from Sam Altman, the CEO of OpenAI, that we're heading towards intelligence too cheap to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=44" target="_blank">00:00:44.400</a></span> | <span class="t">meter. He justifies this claim with the lower cost for those who pay per token and an increased score</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=51" target="_blank">00:00:51.760</a></span> | <span class="t">for a model of its size in the MMLU benchmark. Now, there is no doubt that models are getting</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=58" target="_blank">00:00:58.560</a></span> | <span class="t">cheaper for those who pay per token. Here is GPT-40 mini compared to Google's Gemini 1.5 Flash,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=66" target="_blank">00:01:06.560</a></span> | <span class="t">a comparable size, and Anthropic's Cloud 3 Haiku. At least on the MMLU benchmark, it scores higher</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=74" target="_blank">00:01:14.480</a></span> | <span class="t">while being cheaper. And there's no doubt that I and OpenAI could dazzle you with plenty more</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=80" target="_blank">00:01:20.640</a></span> | <span class="t">charts. Notice in particular the massive discrepancy in the math benchmark. GPT-40 mini</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=86" target="_blank">00:01:26.960</a></span> | <span class="t">scores 70.2% in that benchmark compared to scores in the low 40s for the comparable models. Just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=94" target="_blank">00:01:34.000</a></span> | <span class="t">quickly for any of you watching who wonder why we need these smaller models, it's because sometimes</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=99" target="_blank">00:01:39.040</a></span> | <span class="t">you need quicker, cheaper models to do a task that doesn't require frontier capabilities. Anyway,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=104" target="_blank">00:01:44.640</a></span> | <span class="t">I'm here to say that the picture is slightly more complicated than it first appears. And of course,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=110" target="_blank">00:01:50.560</a></span> | <span class="t">I and potentially you are slightly more interested in what GPT-40 mini tells us</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=115" target="_blank">00:01:55.680</a></span> | <span class="t">about the general state of progress in artificial intelligence. Just quickly though, the name. It's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=121" target="_blank">00:02:01.840</a></span> | <span class="t">a little bit butchered, isn't it? I mean, the O was supposed to stand for Omni, meaning all modalities,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=129" target="_blank">00:02:09.120</a></span> | <span class="t">but the GPT-40 mini that's now rolled out just supports text and vision, not video, not audio.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=136" target="_blank">00:02:16.480</a></span> | <span class="t">And yes, we still don't have a confirmed date for the GPT-40 audio capabilities that we all</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=143" target="_blank">00:02:23.040</a></span> | <span class="t">saw a few months ago. Plus, let's forgive those new to AI who look at this model name and think</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=148" target="_blank">00:02:28.640</a></span> | <span class="t">it's GPT-40 mini. I kind of feel sorry for those guys because they're thinking, where have I been</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=154" target="_blank">00:02:34.080</a></span> | <span class="t">for the last 39 versions? Anyway, audio inputs and outputs are apparently coming in the "future".</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=161" target="_blank">00:02:41.120</a></span> | <span class="t">They don't put dates these days, but there is some positive news. It supports up to 16,000 output</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=167" target="_blank">00:02:47.440</a></span> | <span class="t">tokens per request. Think of that as being around 12,000 words, which is pretty impressive. It has</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=172" target="_blank">00:02:52.640</a></span> | <span class="t">knowledge up to October of last year, which suggests to me that it is a checkpoint of the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=178" target="_blank">00:02:58.800</a></span> | <span class="t">GPT-40 model. Think of that like an early save during your progress through a video game. Indeed,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=184" target="_blank">00:03:04.880</a></span> | <span class="t">one OpenAI researcher hinted heavily that a much larger version of GPT-40 mini, bigger even than</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=192" target="_blank">00:03:12.160</a></span> | <span class="t">GPT-40, is out there. Just after the release of GPT-40 mini, Roon said, "People get mad at any</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=198" target="_blank">00:03:18.400</a></span> | <span class="t">model release that's not immediately AGI or a frontier capabilities improvement." But think for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=203" target="_blank">00:03:23.920</a></span> | <span class="t">a second, why was this GPT-40 mini made? How did this research artifact come to be? What is it on</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=211" target="_blank">00:03:31.040</a></span> | <span class="t">the path to? And again, hinting at a much better model being out there, he retweeted this, "Oh,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=217" target="_blank">00:03:37.600</a></span> | <span class="t">you made a much smaller, cheaper model, just as good," quotes, "as the top model from a few</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=222" target="_blank">00:03:42.720</a></span> | <span class="t">months ago. Hmm, wonder what you doing with those algorithmic improvements?" So even for those of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=228" target="_blank">00:03:48.160</a></span> | <span class="t">you who don't care about small, quick, or cheap models, OpenAI are at least claiming they know</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=233" target="_blank">00:03:53.920</a></span> | <span class="t">how to produce superior textual intelligence. But let's just say things get a lot more</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=239" target="_blank">00:03:59.280</a></span> | <span class="t">ungrounded from here on out. First, they describe the MMLU as a textual intelligence and reasoning</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=246" target="_blank">00:04:06.240</a></span> | <span class="t">benchmark. Well, let's just say for those of you new to the channel, it's much more of a flawed</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=252" target="_blank">00:04:12.480</a></span> | <span class="t">memorization, multiple choice challenge. But at this point, I know I might be losing a lot of you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=257" target="_blank">00:04:17.840</a></span> | <span class="t">who think, "Well, that's just one benchmark. The numbers across the board are going up.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=262" target="_blank">00:04:22.240</a></span> | <span class="t">What's the problem?" Well, I'm going to give you several examples to show you why benchmarks</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=266" target="_blank">00:04:26.640</a></span> | <span class="t">aren't all that matter. It's not only that there are sometimes mistakes in these benchmarks,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=271" target="_blank">00:04:31.200</a></span> | <span class="t">it's that prioritizing and optimizing for benchmark performance that you can announce</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=276" target="_blank">00:04:36.400</a></span> | <span class="t">in a blog post often comes to the detriment of performance in other areas. Like, for example,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=282" target="_blank">00:04:42.640</a></span> | <span class="t">common sense. Take this question that sounds a little bit like a common math challenge.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=287" target="_blank">00:04:47.440</a></span> | <span class="t">Chicken nuggets come in small, medium, or large boxes of five, six, or eight nuggets,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=294" target="_blank">00:04:54.080</a></span> | <span class="t">respectively. Phillip wants 40 nuggets and can only buy one size of box, so list all the sizes</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=300" target="_blank">00:05:00.640</a></span> | <span class="t">of box he cannot currently buy. So far, so good. But wait, assuming he has no access to any form</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=308" target="_blank">00:05:08.720</a></span> | <span class="t">of payment and is in a coma, so which sizes do you think he can't buy given all of these conditions</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=316" target="_blank">00:05:16.640</a></span> | <span class="t">and the fact that he has no access to any form of payment and is in a coma? If you train a model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=322" target="_blank">00:05:22.400</a></span> | <span class="t">relentlessly on math challenges, it's almost like a hammer seeing a nail everywhere. It will</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=328" target="_blank">00:05:28.960</a></span> | <span class="t">definitely get better at hammering or solving known math challenges, but sometimes with some</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=334" target="_blank">00:05:34.240</a></span> | <span class="t">trade-offs. The model at no point acknowledges the lack of access to payment or the coma and focuses</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=340" target="_blank">00:05:40.400</a></span> | <span class="t">on simple division. And remember those other models that perform worse in the benchmarks and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=345" target="_blank">00:05:45.200</a></span> | <span class="t">are slightly more expensive, like Gemini 1.5 Flash from Google? Its answer is a lot more simple,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=351" target="_blank">00:05:51.280</a></span> | <span class="t">directly addressing the obvious elephant in the room. And likewise, Claude 3 Haiku from Anthropic</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=358" target="_blank">00:05:58.080</a></span> | <span class="t">starts off thinking it's a math challenge, but quickly acknowledges the lack of payment and him</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=363" target="_blank">00:06:03.840</a></span> | <span class="t">being in a coma. The point I'm trying to make is that you can make your numbers on a chart like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=368" target="_blank">00:06:08.160</a></span> | <span class="t">math go up, but that doesn't always mean your model is universally better. I think OpenAI need</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=373" target="_blank">00:06:13.840</a></span> | <span class="t">to be more honest about the flaws in the benchmarks and what benchmarks cannot capture. Particularly</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=380" target="_blank">00:06:20.000</a></span> | <span class="t">as these models are used more and more in the real world, as we shall soon see. So after almost 18</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=385" target="_blank">00:06:25.440</a></span> | <span class="t">months of promises from OpenAI when it comes to smarter models, what's the update when it comes</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=390" target="_blank">00:06:30.960</a></span> | <span class="t">to reasoning prowess? Well, as is par for the course, we can only rely on leaks, hints and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=397" target="_blank">00:06:37.920</a></span> | <span class="t">promises. Bloomberg described an all-hands meeting last Tuesday at OpenAI in which a new reasoning</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=405" target="_blank">00:06:45.360</a></span> | <span class="t">system was demoed, as well as a new classification system. In terms of reasoning, company leadership</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=411" target="_blank">00:06:51.280</a></span> | <span class="t">they say, gave a demo of a research project involving its GPT-4 AI model that OpenAI thinks</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=418" target="_blank">00:06:58.640</a></span> | <span class="t">shows some new skills that rise to human-like reasoning, according to presumably a person at</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=425" target="_blank">00:07:05.200</a></span> | <span class="t">OpenAI. I'll give you more info about this meeting from Reuters, but first what's that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=430" target="_blank">00:07:10.000</a></span> | <span class="t">classification system they mentioned? Here is the chart and elsewhere in the article, OpenAI say</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=435" target="_blank">00:07:15.120</a></span> | <span class="t">that they are currently on level 1 and are on the cusp of level 2. That to me is the clearest</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=442" target="_blank">00:07:22.320</a></span> | <span class="t">admission though, that current models aren't reasoning engines, as Sam Altman once described</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=447" target="_blank">00:07:27.440</a></span> | <span class="t">them, or yet reasoners. Although again, they promise they're on the cusp of reasoning. And</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=453" target="_blank">00:07:33.920</a></span> | <span class="t">here is the report from Reuters, which may or may not be about the same demo. They describe a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=461" target="_blank">00:07:41.200</a></span> | <span class="t">strawberry project, which was formerly known as Q*, and is seen inside the company as a breakthrough.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=468" target="_blank">00:07:48.320</a></span> | <span class="t">Now this is not the video to get into Q*, and I did a separate video on that, but they did give</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=473" target="_blank">00:07:53.760</a></span> | <span class="t">a bit more detail. The reasoning breakthrough is proven by the fact that the model scored over 90%</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=480" target="_blank">00:08:00.720</a></span> | <span class="t">on the math data set. That's that same chart that GPT-40 mini got 70% that we saw earlier.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=488" target="_blank">00:08:08.480</a></span> | <span class="t">Well, if that's their proof of human-like reasoning, colour me sceptical. By the way,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=494" target="_blank">00:08:14.000</a></span> | <span class="t">if you want dozens more examples of the flaws of these kind of benchmarks, and just how hard it is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=499" target="_blank">00:08:19.680</a></span> | <span class="t">to pin down whether a model can do a task, check out one of my videos on AI Insiders on Patreon.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=505" target="_blank">00:08:25.680</a></span> | <span class="t">And I've actually just released my 30th video on the platform with this video on emergent</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=512" target="_blank">00:08:32.400</a></span> | <span class="t">behaviours. I'm biased of course, but I think it really does nail down this debate over whether</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=517" target="_blank">00:08:37.200</a></span> | <span class="t">models actually display emergent behaviours. Some people clearly think they do though,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=521" target="_blank">00:08:41.520</a></span> | <span class="t">with Stanford professor Noah Goodman telling Reuters, "I think it's both exciting and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=526" target="_blank">00:08:46.080</a></span> | <span class="t">terrifying." Describing his speculations about synthetic training data, Q*, and reasoning</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=531" target="_blank">00:08:51.520</a></span> | <span class="t">improvements, "If things keep going in that direction, we have some serious things to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=536" target="_blank">00:08:56.000</a></span> | <span class="t">think about as humans." The challenge of course, at its heart, is that these models rely, for their</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=541" target="_blank">00:09:01.600</a></span> | <span class="t">sources of truth, on human text, human images. Their goal, if they have any, is to model and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=548" target="_blank">00:09:08.560</a></span> | <span class="t">predict that text, not the real world. They're not trained on or in the real world, but only</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=555" target="_blank">00:09:15.440</a></span> | <span class="t">on descriptions of it. They might have textual intelligence and be able to model and predict</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=560" target="_blank">00:09:20.880</a></span> | <span class="t">words, but that's very different from social or spatial intelligence. As I've described before</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=566" target="_blank">00:09:26.160</a></span> | <span class="t">on the channel, people are working frantically to bring real-world embodied intelligence into models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=573" target="_blank">00:09:33.120</a></span> | <span class="t">A startup launched by Fei-Fei Li just four months ago is now worth $1 billion. Its goal is to train</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=580" target="_blank">00:09:40.800</a></span> | <span class="t">a machine capable of understanding the complex physical world and the interrelation of objects</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=586" target="_blank">00:09:46.080</a></span> | <span class="t">within it. At the same time, Google DeepMind is working frantically to do the same thing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=590" target="_blank">00:09:50.800</a></span> | <span class="t">How can we give large language models more physical intelligence? While text is their</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=595" target="_blank">00:09:55.920</a></span> | <span class="t">ground truth, they will always be limited. Humans can lie in text, audio, and image,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=602" target="_blank">00:10:02.000</a></span> | <span class="t">but the real world doesn't lie. Reality is reality. Of course, we would always need</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=607" target="_blank">00:10:07.040</a></span> | <span class="t">immense real-world data to conduct novel experiments, test new theories, iterate,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=612" target="_blank">00:10:12.960</a></span> | <span class="t">and invent new physics. Or less ambitiously, just have useful robot psychics. Just the other day,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=618" target="_blank">00:10:18.400</a></span> | <span class="t">Google DeepMind released results of them putting Gemini 1.5 Pro inside this robot. And the attached</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=624" target="_blank">00:10:24.960</a></span> | <span class="t">paper also contains some fascinating nuggets. To boil it down, though, for this video,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=629" target="_blank">00:10:29.680</a></span> | <span class="t">Gemini 1.5 Pro is incapable of navigating the robot zero shot without a topological graph.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=637" target="_blank">00:10:37.920</a></span> | <span class="t">Apparently, Gemini almost always outputs the move forward waypoint regardless of the current camera</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=644" target="_blank">00:10:44.320</a></span> | <span class="t">observation. As we've discussed, the models need to be grounded in some way, in this case with</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=649" target="_blank">00:10:49.440</a></span> | <span class="t">classical policies. And there is, of course, the amusing matter of lag. Apparently, the inference</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=655" target="_blank">00:10:55.040</a></span> | <span class="t">time of Gemini 1.5 Pro was around 10 to 30 seconds in video mode, resulting in users awkwardly waiting</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=662" target="_blank">00:11:02.800</a></span> | <span class="t">for the robot to respond. It might almost have been quite funny with them asking "where's the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=667" target="_blank">00:11:07.200</a></span> | <span class="t">toilet?" and the robot just standing there staring for 30 seconds before answering. And I don't know</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=672" target="_blank">00:11:12.320</a></span> | <span class="t">about you, but I can't wait to actually speak to my robot assistant and have it understand my</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=678" target="_blank">00:11:18.000</a></span> | <span class="t">British accent. I'm particularly proud to have this video sponsored by Assembly AI, whose universal</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=683" target="_blank">00:11:23.520</a></span> | <span class="t">one speech to text recognition model is the one that I rely on. Indeed, as I've said before on the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=689" target="_blank">00:11:29.600</a></span> | <span class="t">channel, I actually reached out to them, such was the performance discrepancy. In short, it recognizes</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=695" target="_blank">00:11:35.520</a></span> | <span class="t">my GPTs from my RTXs, which definitely helps when making transcriptions. The link will be in the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=701" target="_blank">00:11:41.680</a></span> | <span class="t">description to check them out. And I've actually had members of my Patreon thank me for alerting</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=707" target="_blank">00:11:47.280</a></span> | <span class="t">them to the existence of Assembly AI's universal one. But perhaps I can best illustrate the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=712" target="_blank">00:11:52.560</a></span> | <span class="t">deficiencies in spatial intelligence of current models with an example from a new benchmark that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=718" target="_blank">00:11:58.880</a></span> | <span class="t">I'm hoping to release soon. It's designed to clearly illustrate the difference between modeling</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=724" target="_blank">00:12:04.480</a></span> | <span class="t">language and the real world. It tests mathematics, spatial intelligence, social intelligence,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=730" target="_blank">00:12:10.000</a></span> | <span class="t">coding, and much more. What's even better is that the people I send these questions to typically</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=735" target="_blank">00:12:15.600</a></span> | <span class="t">crush the benchmark, but language models universally fail. Not every question,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=740" target="_blank">00:12:20.240</a></span> | <span class="t">but almost every question. Indeed, in this question, just for extra emphasis, I said at the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=745" target="_blank">00:12:25.280</a></span> | <span class="t">start, this is a trick question that's not actually about vegetables or fruit. I gave this question,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=750" target="_blank">00:12:30.080</a></span> | <span class="t">by the way, to Gemini 1.5 Flash from Google. A modified version of this question also tricks,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=755" target="_blank">00:12:35.520</a></span> | <span class="t">by the way, Gemini 1.5 Pro. You can, of course, let me know in the comments what you would pick.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=760" target="_blank">00:12:40.000</a></span> | <span class="t">Alone in the room, I asked one-armed Philip carefully balances a tomato, a potato, and a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=765" target="_blank">00:12:45.600</a></span> | <span class="t">cabbage on top of a plate. Philip meticulously inspects the three items before turning the silver</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=772" target="_blank">00:12:52.880</a></span> | <span class="t">plate completely upside down several times, shaking, indeed, the plate vigorously and spending</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=779" target="_blank">00:12:59.680</a></span> | <span class="t">a few minutes each time to inspect for any roots on the other side of the silver non-stick plate.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=786" target="_blank">00:13:06.560</a></span> | <span class="t">And finally, after all of this, counts only the vegetables that remain balanced on top of the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=794" target="_blank">00:13:14.000</a></span> | <span class="t">plate. How many vegetables does Philip likely then count? 3, 2, 1, or 0. Now, if you're like me,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=800" target="_blank">00:13:20.960</a></span> | <span class="t">you might be a little amused that the model didn't pick the answer 0. That's what I would pick.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=807" target="_blank">00:13:27.040</a></span> | <span class="t">And why do I pick 0? Because visualizing this situation in my mind, clearly all three objects</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=813" target="_blank">00:13:33.760</a></span> | <span class="t">would fall off the plate. In fact, I couldn't have made it more obvious that they would fall</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=817" target="_blank">00:13:37.920</a></span> | <span class="t">off. The plate is turned upside down. He's got one arm, so no means of balancing. It's a non-stick</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=823" target="_blank">00:13:43.840</a></span> | <span class="t">plate and he does it repeatedly for a few minutes each time. Even for those people who might think</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=828" target="_blank">00:13:48.320</a></span> | <span class="t">there might occasionally be a one in a billion instance of stickiness, I said, how many vegetables</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=833" target="_blank">00:13:53.280</a></span> | <span class="t">does Philip likely then count? So why does a model like Gemini 1.5 Flash still get this wrong?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=839" target="_blank">00:13:59.520</a></span> | <span class="t">It's because as I discussed in my video on the Arc AGI challenge from Francois Chollet,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=844" target="_blank">00:14:04.960</a></span> | <span class="t">models are retrieving certain programs. They're a bit like a search engine for text-based programs</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=851" target="_blank">00:14:11.120</a></span> | <span class="t">to apply to your prompt. And the model has picked up on the items I deliberately used in the second</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=856" target="_blank">00:14:16.800</a></span> | <span class="t">sentence, tomato, potato, and cabbage. It has been trained on hundreds or thousands of examples,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=863" target="_blank">00:14:23.040</a></span> | <span class="t">discussing how, for example, a tomato is a fruit, not a vegetable. So it's quote "textual</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=869" target="_blank">00:14:29.280</a></span> | <span class="t">intelligence" is prompting it to retrieve that program to give an output that discusses a tomato</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=876" target="_blank">00:14:36.080</a></span> | <span class="t">being a fruit, not a vegetable. And once it selects that program, almost nothing will shake</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=881" target="_blank">00:14:41.680</a></span> | <span class="t">it free from that decision. Now, as I say that, I remember that I'm actually recalling an interaction</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=887" target="_blank">00:14:47.040</a></span> | <span class="t">I had with Claude 3 Haiku, which I'll show you in a moment. What confused Gemini 1.5 Flash in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=892" target="_blank">00:14:52.720</a></span> | <span class="t">this instance was the shape of the vegetables and fruit. Retrieving the program that it's tomatoes</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=898" target="_blank">00:14:58.400</a></span> | <span class="t">that are the most round and smooth, it's sticking to that program, saying it's the tomato that will</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=904" target="_blank">00:15:04.000</a></span> | <span class="t">fall off. Notice how it says that potatoes and cabbages are likely to stay balanced, but then</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=909" target="_blank">00:15:09.200</a></span> | <span class="t">says only one vegetable will remain on the plate. It's completely confused, but so is Claude 3 Haiku,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=915" target="_blank">00:15:15.520</a></span> | <span class="t">which I was referring to earlier. It fixates on tomatoes and potatoes, which are quote "fruits,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=920" target="_blank">00:15:20.960</a></span> | <span class="t">not vegetables" because it is essentially retrieving relevant text. I will, at this point,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=926" target="_blank">00:15:26.240</a></span> | <span class="t">at long last, give credit to GPT 4.0 Mini, which actually gets this question correct.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=930" target="_blank">00:15:30.960</a></span> | <span class="t">I can envisage, though, in the future, models actually creating simulations of the question</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=936" target="_blank">00:15:36.240</a></span> | <span class="t">at hand, running those simulations and giving you a far more grounded answer. Simulations which</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=942" target="_blank">00:15:42.160</a></span> | <span class="t">could be based on billions of hours of real world data. So do try to bear this video in mind when</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=948" target="_blank">00:15:48.480</a></span> | <span class="t">you hear claims like this from the mainstream media. Benchmark performance does not always</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=953" target="_blank">00:15:53.680</a></span> | <span class="t">directly translate to real world applicability. I'll show you a quick medical example after this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=958" target="_blank">00:15:58.960</a></span> | <span class="t">30 second clip.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=960" target="_blank">00:16:00.000</a></span> | <span class="t">What we did was we fed 50 questions from the USMLE Step 3 medical licensing exam. It's the final step</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=965" target="_blank">00:16:05.760</a></span> | <span class="t">before getting your medical license. So we fed 50 questions from this exam to the top five large</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=971" target="_blank">00:16:11.040</a></span> | <span class="t">language models. We were expecting more separation, and quite frankly, I wasn't expecting the models</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=975" target="_blank">00:16:15.600</a></span> | <span class="t">to do as well as they did. The reason why we wanted to do this was a lot of consumers and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=979" target="_blank">00:16:19.360</a></span> | <span class="t">physicians are using these large language models to answer medical questions, and there really</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=983" target="_blank">00:16:23.280</a></span> | <span class="t">wasn't good evidence out there on which ones were better. It didn't just give you the answer,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=987" target="_blank">00:16:27.760</a></span> | <span class="t">but explained why it chose a particular answer, and then why it didn't choose other answers. So</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=992" target="_blank">00:16:32.560</a></span> | <span class="t">it was very descriptive and gave you a lot of good information. Now, as long as the language</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=996" target="_blank">00:16:36.960</a></span> | <span class="t">is in the exact format in which the model is expecting it, things will go smoothly.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=1002" target="_blank">00:16:42.160</a></span> | <span class="t">This is a sample question from that exact same medical test. I'm giving it to ChachiPT40 and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=1008" target="_blank">00:16:48.080</a></span> | <span class="t">have made just a couple of slight amendments. The question at the end of all of these details was,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=1014" target="_blank">00:16:54.000</a></span> | <span class="t">"Which of the following is the most appropriate initial statement by the physician?" Now,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=1018" target="_blank">00:16:58.400</a></span> | <span class="t">you don't need to read this example, but I'll show you the two amendments I made. First,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=1022" target="_blank">00:17:02.960</a></span> | <span class="t">I added to the sentence, "Physical examination shows no other abnormalities, open gunshot wound</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=1027" target="_blank">00:17:07.760</a></span> | <span class="t">to the head as the exception." Next, I tweaked the correct answer, which was A, adding in the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=1033" target="_blank">00:17:13.520</a></span> | <span class="t">pejorative, "wench." ChachiPT40 completely ignores the open gunshot wound to the head and still picks</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=1039" target="_blank">00:17:19.360</a></span> | <span class="t">A. It does, however, note that the use of wench is inappropriate, but still picks that answer as</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=1044" target="_blank">00:17:24.320</a></span> | <span class="t">the most appropriate answer. Oh, and I also changed answer E to, "We have a salient matter to attend to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=1050" target="_blank">00:17:30.080</a></span> | <span class="t">before conception." That, to me, would be the new correct answer in the light of the gunshot wound.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=1055" target="_blank">00:17:35.440</a></span> | <span class="t">Now, I could just say that the model has been trained on this question and so is somewhat</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=1060" target="_blank">00:17:40.160</a></span> | <span class="t">contaminated, hence explaining the 98% score. Obviously, it's more complex than that. The</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=1065" target="_blank">00:17:45.040</a></span> | <span class="t">model will still be immensely useful for many patients. This example is more to illustrate</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=1070" target="_blank">00:17:50.640</a></span> | <span class="t">the point that the real world is immensely messy. For as long as models are still trained on text,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=1077" target="_blank">00:17:57.520</a></span> | <span class="t">they can be fooled in text. They can make mistakes, hallucinate, confabulate in text.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=1082" target="_blank">00:18:02.560</a></span> | <span class="t">Grounding with real world data will mitigate that significantly. At that point, of course,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=1087" target="_blank">00:18:07.760</a></span> | <span class="t">it would be no longer appropriate to call them just language models. I've got so much more to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=1091" target="_blank">00:18:11.760</a></span> | <span class="t">say on that point, but that's perhaps for another video because one more use case, of course,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=1096" target="_blank">00:18:16.400</a></span> | <span class="t">that OpenAI gave was for customer support, so I can't resist one more cheeky example.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=1102" target="_blank">00:18:22.080</a></span> | <span class="t">I said to chatgpt40mini, based on today's events, "Role play as a customer service agent for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=1108" target="_blank">00:18:28.480</a></span> | <span class="t">Microsoft." Definitely a tough day to be such an agent for Microsoft. Agent, hi, how can I help?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=1114" target="_blank">00:18:34.720</a></span> | <span class="t">User, hey, just had a quick technical problem. I turned on my PC and got the blue screen of death</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=1120" target="_blank">00:18:40.320</a></span> | <span class="t">with no error code. I resolved this quickly and completely, and I've had the PC for three months</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=1125" target="_blank">00:18:45.200</a></span> | <span class="t">with no malware. I then removed peripherals, froze the PC in liquid nitrogen for decades,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=1132" target="_blank">00:18:52.480</a></span> | <span class="t">and double-checked the power supply. So why is it now not loading the home screen? Is it a new bug?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=1138" target="_blank">00:18:58.160</a></span> | <span class="t">Reply with the most likely underlying causes in order of likelihood. Hmm, I wonder if it's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=1144" target="_blank">00:19:04.640</a></span> | <span class="t">anything to do with freezing the PC in liquid nitrogen for decades. Well, not according to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=1151" target="_blank">00:19:11.040</a></span> | <span class="t">this customer service agent, which doesn't even list that in the top five reasons.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=1155" target="_blank">00:19:15.600</a></span> | <span class="t">Of course, I could go on. These quirks aren't just limited to language, but also vision.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=1160" target="_blank">00:19:20.320</a></span> | <span class="t">This paper from a few days ago describes vision language models as blind. At worst,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=1165" target="_blank">00:19:25.920</a></span> | <span class="t">they're like an intelligent person that is blind making educated guesses. On page eight,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=1171" target="_blank">00:19:31.440</a></span> | <span class="t">they give this vivid demonstration asking for how many intersections you can see for these two</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=1177" target="_blank">00:19:37.360</a></span> | <span class="t">lines. They gave it to four vision models from GPT 4.0, apparently the best, Gemini 1.5,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=1183" target="_blank">00:19:43.920</a></span> | <span class="t">SONNET 3, SONNET 3.5. You can count the intersections yourself if you'd like,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=1188" target="_blank">00:19:48.960</a></span> | <span class="t">but suffice to say the models perform terribly. Now to end positively, I will say that models</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=1194" target="_blank">00:19:54.480</a></span> | <span class="t">are getting better even before they're grounded in real world data. Claude 3.5 SONNET from</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=1199" target="_blank">00:19:59.600</a></span> | <span class="t">Anthropic was particularly hard to fool. I had to make these adversarial language questions far</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=1205" target="_blank">00:20:05.520</a></span> | <span class="t">more subtle to fool Claude 3.5 SONNET, and we haven't even got Claude 3.5 OPUS, the biggest</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=1211" target="_blank">00:20:11.360</a></span> | <span class="t">model. In fact, my go-to model is unambiguously now Claude 3.5 SONNET. So to end, I really do</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=1217" target="_blank">00:20:17.760</a></span> | <span class="t">hope you weren't too inconvenienced by that massive IT outage, and I hope you enjoyed the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=IP7DjybjMHU&t=1223" target="_blank">00:20:23.520</a></span> | <span class="t">video. Have an absolutely wonderful day.</span></div></div></body></html>