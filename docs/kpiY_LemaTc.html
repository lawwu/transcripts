<html><head><title>GPT-3 vs Human Brain</title></head><body>
    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-69VLBMTTP0"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-69VLBMTTP0');
    </script>
    <a href="index.html">back to index</a><h2>GPT-3 vs Human Brain</h2><a href="https://www.youtube.com/watch?v=kpiY_LemaTc"><img src="https://i.ytimg.com/vi_webp/kpiY_LemaTc/maxresdefault.webp" style="width:50%;"></a><div><br></div><div style="text-align: left;"><a href="./kpiY_LemaTc.html">Whisper Transcript</a> | <a href="./transcript_kpiY_LemaTc.html">Transcript Only Page</a></div><br><div style="max-width: 800px;"><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kpiY_LemaTc&t=0">00:00:00.000</a></span> | <span class="t">The human brain is at least 100 trillion synapses,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kpiY_LemaTc&t=3">00:00:03.440</a></span> | <span class="t">and it could be as high as 1,000 trillion.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kpiY_LemaTc&t=5">00:00:05.880</a></span> | <span class="t">And a synapse is a channel connected to neurons</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kpiY_LemaTc&t=8">00:00:08.500</a></span> | <span class="t">through which an electrical or chemical signal is transferred</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kpiY_LemaTc&t=12">00:00:12.000</a></span> | <span class="t">and is the loose inspiration for the synapses, weights,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kpiY_LemaTc&t=15">00:00:15.560</a></span> | <span class="t">parameters of an artificial neural network.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kpiY_LemaTc&t=18">00:00:18.640</a></span> | <span class="t">GPT-3, the recently released language model from OpenAI</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kpiY_LemaTc&t=23">00:00:23.280</a></span> | <span class="t">that has been captivating people's imagination</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kpiY_LemaTc&t=25">00:00:25.640</a></span> | <span class="t">with zero shot or few shot learning,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kpiY_LemaTc&t=28">00:00:28.400</a></span> | <span class="t">has 175 billion synapses or parameters.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kpiY_LemaTc&t=33">00:00:33.320</a></span> | <span class="t">As mentioned in the OpenAI paper,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kpiY_LemaTc&t=35">00:00:35.120</a></span> | <span class="t">the amount of compute that was used to train</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kpiY_LemaTc&t=37">00:00:37.240</a></span> | <span class="t">the final version of this network</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kpiY_LemaTc&t=38">00:00:38.680</a></span> | <span class="t">was 3.14 times 10 to the 23rd flops.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kpiY_LemaTc&t=43">00:00:43.520</a></span> | <span class="t">And if we use reasonable cost estimates</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kpiY_LemaTc&t=45">00:00:45.440</a></span> | <span class="t">based on Lambda's test of U100 cloud instance,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kpiY_LemaTc&t=48">00:00:48.640</a></span> | <span class="t">the cost of training this neural network is $4.6 million.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kpiY_LemaTc&t=52">00:00:52.320</a></span> | <span class="t">Now, the natural question I had is,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kpiY_LemaTc&t=55">00:00:55.420</a></span> | <span class="t">if the model with 175 billion parameters does very well,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kpiY_LemaTc&t=59">00:00:59.420</a></span> | <span class="t">how well will a model do that has the same number</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kpiY_LemaTc&t=62">00:01:02.620</a></span> | <span class="t">of parameters as our human brain?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kpiY_LemaTc&t=65">00:01:05.300</a></span> | <span class="t">Setting aside the fact that both our estimate</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kpiY_LemaTc&t=67">00:01:07.900</a></span> | <span class="t">of the number of synapses and the intricate structure</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kpiY_LemaTc&t=70">00:01:10.580</a></span> | <span class="t">of the brain might require a much, much larger</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kpiY_LemaTc&t=73">00:01:13.260</a></span> | <span class="t">neural network to approximate the brain.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kpiY_LemaTc&t=75">00:01:15.500</a></span> | <span class="t">But it's very possible that even just this 100 trillion</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kpiY_LemaTc&t=78">00:01:18.420</a></span> | <span class="t">synapse number will allow us to see</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kpiY_LemaTc&t=80">00:01:20.820</a></span> | <span class="t">some magical performance from these systems.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kpiY_LemaTc&t=83">00:01:23.700</a></span> | <span class="t">And one way of asking the question of how far away are we,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kpiY_LemaTc&t=87">00:01:27.500</a></span> | <span class="t">is how much does it approximately cost</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kpiY_LemaTc&t=89">00:01:29.340</a></span> | <span class="t">to train a model with 100 trillion parameters?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kpiY_LemaTc&t=92">00:01:32.880</a></span> | <span class="t">So GPT-3 is 175 billion parameters</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kpiY_LemaTc&t=96">00:01:36.540</a></span> | <span class="t">and $4.6 million in 2020.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kpiY_LemaTc&t=99">00:01:39.440</a></span> | <span class="t">Let's call it GPT-4HB with 100 trillion parameters.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kpiY_LemaTc&t=105">00:01:45.660</a></span> | <span class="t">Assuming linear scaling of compute requirements</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kpiY_LemaTc&t=108">00:01:48.780</a></span> | <span class="t">with respect to number of parameters,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kpiY_LemaTc&t=111">00:01:51.580</a></span> | <span class="t">the cost in 2020 for training this neural network</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kpiY_LemaTc&t=114">00:01:54.800</a></span> | <span class="t">is $2.6 billion.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kpiY_LemaTc&t=116">00:01:56.980</a></span> | <span class="t">Now, another interesting open AI paper</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kpiY_LemaTc&t=118">00:01:58.900</a></span> | <span class="t">that I've talked about in the past,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kpiY_LemaTc&t=120">00:02:00.420</a></span> | <span class="t">titled "Measuring the Algorithmic Efficiency</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kpiY_LemaTc&t=122">00:02:02.740</a></span> | <span class="t">of Neural Networks," indicates that for the past seven years</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kpiY_LemaTc&t=126">00:02:06.740</a></span> | <span class="t">the neural network training efficiency</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kpiY_LemaTc&t=129">00:02:09.480</a></span> | <span class="t">has been doubling every 16 months.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kpiY_LemaTc&t=132">00:02:12.180</a></span> | <span class="t">So if this trend continues, then in 2024,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kpiY_LemaTc&t=136">00:02:16.060</a></span> | <span class="t">the cost of training this GPT-HB network</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kpiY_LemaTc&t=140">00:02:20.740</a></span> | <span class="t">would be $325 million, decreasing to $40 million in 2028,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kpiY_LemaTc&t=145">00:02:25.740</a></span> | <span class="t">and in 2032, coming down to approximately the same price</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kpiY_LemaTc&t=149">00:02:29.860</a></span> | <span class="t">as the GPT-3 network today at $5 million.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kpiY_LemaTc&t=154">00:02:34.140</a></span> | <span class="t">Now, it's important to note, as the paper indicates,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kpiY_LemaTc&t=156">00:02:36.300</a></span> | <span class="t">that as the size of the network and the compute increases,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kpiY_LemaTc&t=159">00:02:39.460</a></span> | <span class="t">the improvement of the performance of the network</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kpiY_LemaTc&t=161">00:02:41.620</a></span> | <span class="t">follows a power law.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kpiY_LemaTc&t=163">00:02:43.380</a></span> | <span class="t">Still, given some of the impressive</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kpiY_LemaTc&t=165">00:02:45.620</a></span> | <span class="t">Turing test passing performances of GPT-3,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kpiY_LemaTc&t=169">00:02:49.700</a></span> | <span class="t">it's fascinating to think what a language model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kpiY_LemaTc&t=173">00:02:53.100</a></span> | <span class="t">with 100 trillion parameters might be able to accomplish.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kpiY_LemaTc&t=177">00:02:57.340</a></span> | <span class="t">I might make a few short videos like these,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kpiY_LemaTc&t=180">00:03:00.140</a></span> | <span class="t">focusing on a single, simple idea on the basics of GPT-3,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kpiY_LemaTc&t=184">00:03:04.540</a></span> | <span class="t">including technical, even philosophical implications,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kpiY_LemaTc&t=188">00:03:08.500</a></span> | <span class="t">along with highlighting how others are using it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kpiY_LemaTc&t=192">00:03:12.060</a></span> | <span class="t">So if you enjoy this kind of thing, subscribe,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kpiY_LemaTc&t=194">00:03:14.620</a></span> | <span class="t">and remember, try to learn something new every day.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kpiY_LemaTc&t=197">00:03:17.180</a></span> | <span class="t">(upbeat music)</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kpiY_LemaTc&t=199">00:03:19.760</a></span> | <span class="t">(upbeat music)</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kpiY_LemaTc&t=202">00:03:22.340</a></span> | <span class="t">(upbeat music)</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kpiY_LemaTc&t=204">00:03:24.920</a></span> | <span class="t">(upbeat music)</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kpiY_LemaTc&t=207">00:03:27.500</a></span> | <span class="t">[BLANK_AUDIO]</span></div></div></body></html>