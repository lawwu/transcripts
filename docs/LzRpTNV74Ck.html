<html><head><title>OpenAI Alternatives: Cohere Embed v3 and Open Source</title>
<style>
    body {
        font-family: Arial, sans-serif;
        margin: 0;
        padding: 0;
        background-color: #f4f4f4;
        color: #333;
    }
    .container {
        width: 80%;
        margin: auto;
        overflow: hidden;
    }
    h2, h3 {
        color: #333;
        text-align: center;
    }
    a {
        color: #0000FF;  /* Traditional blue color for links */
        text-decoration: none;
    }
    a:hover {
        text-decoration: underline;
    }
    img {
        display: block;
        margin: auto;
        max-width: 100%;
    }
    .c {
        margin: 10px 0;
    }
    .s, .t {
        display: inline-block;
        margin-right: 5px;
    }
    .max-width {
        max-width: 800px;
        margin: auto;
        padding-left: 20px;
    }
    table {
        width: 100%;
        border-collapse: collapse;
    }
    th, td {
        border: 1px solid #ddd;
        padding: 8px;
    }
    tr:nth-child(even) {
        background-color: #f2f2f2;
    }
    tr:nth-child(odd) {
        background-color: #e6e6e6;
    }
</style>

    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-69VLBMTTP0"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-69VLBMTTP0');
    </script>
    </head><body><div class='container'><a href="index.html">back to index</a><h2>OpenAI Alternatives: Cohere Embed v3 and Open Source</h2><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck"><img src="https://i.ytimg.com/vi/LzRpTNV74Ck/maxresdefault.jpg" style="width:50%;"></a><div><br></div><h3>Chapters</h3><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=0">0:0</a> <Untitled Chapter 1><br><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=45">0:45</a> MTEB Leaderboards<br><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=106">1:46</a> Starting with OpenAI, Cohere, and e5<br><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=275">4:35</a> Inference Speeds<br><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=366">6:6</a> Querying with Different Models<br><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=485">8:5</a> Results between models<br><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=575">9:35</a> Ada 002 vs Cohere v3<br><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=629">10:29</a> Another test for OpenAI, Cohere, and E5<br><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=923">15:23</a> More Questions and Final Thoughts<br><br><div style="text-align: left;"><a href="./LzRpTNV74Ck.html">Whisper Transcript</a> | <a href="./transcript_LzRpTNV74Ck.html">Transcript Only Page</a></div><br><div style="max-width: 800px;"><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=0" target="_blank">00:00:00.000</a></span> | <span class="t">Today, we're going to be taking a look at a few of the best embedding models that we can use when we're building retrieval pipelines.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=7" target="_blank">00:00:07.360</a></span> | <span class="t">At the moment, pretty much everyone uses OpenAI's Ardour 002.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=11" target="_blank">00:00:11.400</a></span> | <span class="t">But there are actually many other models out there and a few that are either sort of competitive or potentially even better than Ardour 002.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=22" target="_blank">00:00:22.000</a></span> | <span class="t">And if you go by leaderboards, there are many models that are significantly better.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=26" target="_blank">00:00:26.880</a></span> | <span class="t">But we'll see that not everything is about leaderboards, and when you're testing it on real life data, Ardour still works well, but it's comparable to many other models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=36" target="_blank">00:00:36.680</a></span> | <span class="t">So I'm going to start by taking a look at one of the most popular leaderboards for embedding models, which is the MTEB Benchmark.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=45" target="_blank">00:00:45.600</a></span> | <span class="t">MTEB is the Massive Text Embedding Benchmark, and this is hosted on Hungryface Spaces.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=52" target="_blank">00:00:52.000</a></span> | <span class="t">Now, I think it's literally today there is this new model that is now at the number one spot.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=59" target="_blank">00:00:59.120</a></span> | <span class="t">We are not going to be looking at that model in this video, although I will do very soon.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=63" target="_blank">00:01:03.760</a></span> | <span class="t">But we will be covering this other model from Gohere, which is very close, like very, very little difference, at least from the benchmark results here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=72" target="_blank">00:01:12.200</a></span> | <span class="t">And we're going to be taking a look at one of the small embedding models, our open source.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=78" target="_blank">00:01:18.000</a></span> | <span class="t">So there are many open source models here, but the one that I found to work best that isn't huge is actually down here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=87" target="_blank">00:01:27.280</a></span> | <span class="t">So E5 Base V1, and if model size isn't too much of an issue, you can actually upgrade this model to the E5 Large V2 model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=98" target="_blank">00:01:38.080</a></span> | <span class="t">And then we're also going to compare these to what is generally the most popular embedding model, which is Ardour 002.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=106" target="_blank">00:01:46.160</a></span> | <span class="t">Now, we're going to be taking a look at a few different things here, but I'm going to guide you through basically what you need to know to use each one of these three models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=116" target="_blank">00:01:56.240</a></span> | <span class="t">So to start with, we're going to obviously start with the installs.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=119" target="_blank">00:01:59.200</a></span> | <span class="t">So the pip install for each one of these is pretty straightforward.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=122" target="_blank">00:02:02.240</a></span> | <span class="t">We have OpenAI, Gohere, and Transformers over here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=125" target="_blank">00:02:05.920</a></span> | <span class="t">The datasets that you see at the top here is the dataset that we're going to use for this walkthrough, and that dataset is this one here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=133" target="_blank">00:02:13.040</a></span> | <span class="t">So you will have probably seen this before if you watch a few of my recent videos.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=137" target="_blank">00:02:17.040</a></span> | <span class="t">It's this AI Archive chunked dataset.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=139" target="_blank">00:02:19.600</a></span> | <span class="t">Now, we've installed this, as you can see here, and you'll be able to find this notebook in a link at the top of the video right now.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=147" target="_blank">00:02:27.840</a></span> | <span class="t">And then we want to come down to our embedding functions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=150" target="_blank">00:02:30.320</a></span> | <span class="t">Now, the embedding functions are what vary the most between each of these models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=154" target="_blank">00:02:34.720</a></span> | <span class="t">Obviously, the two API embedding models, Gohere and OpenAI, they're the most straightforward.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=162" target="_blank">00:02:42.240</a></span> | <span class="t">OpenAI in particular, there's not really anything you need to know.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=164" target="_blank">00:02:44.800</a></span> | <span class="t">You just input your documents, and you have your model here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=168" target="_blank">00:02:48.240</a></span> | <span class="t">With Gohere, you do need to be aware of using the correct import type here,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=173" target="_blank">00:02:53.840</a></span> | <span class="t">which is going to be SearchDocument when we're embedding our documents,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=177" target="_blank">00:02:57.600</a></span> | <span class="t">and when we're embedding a query, it is SearchQuery.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=181" target="_blank">00:03:01.200</a></span> | <span class="t">And we also have the model name down here as well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=184" target="_blank">00:03:04.000</a></span> | <span class="t">Otherwise, it's pretty straightforward.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=186" target="_blank">00:03:06.160</a></span> | <span class="t">Now, things get a little more complicated when we start looking at how to use our open source model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=191" target="_blank">00:03:11.760</a></span> | <span class="t">Now, this is normal. It's open source.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=193" target="_blank">00:03:13.840</a></span> | <span class="t">We're not hiding everything behind an API.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=197" target="_blank">00:03:17.200</a></span> | <span class="t">But in any case, it's still not really that complicated.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=201" target="_blank">00:03:21.440</a></span> | <span class="t">The only thing that we do need to be aware of is that if you're on fast speeds,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=205" target="_blank">00:03:25.760</a></span> | <span class="t">you're probably going to want a CUDA-enabled GPU.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=208" target="_blank">00:03:28.320</a></span> | <span class="t">I think you can also run this on NPS on Mac.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=211" target="_blank">00:03:31.680</a></span> | <span class="t">So you just need to be aware of that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=213" target="_blank">00:03:33.840</a></span> | <span class="t">When you're running on NPS, rather than using CUDA here, you would switch across to NPS.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=218" target="_blank">00:03:38.320</a></span> | <span class="t">And in this two device over here,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=222" target="_blank">00:03:42.000</a></span> | <span class="t">you want to make sure you're moving to your NPS device instead.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=225" target="_blank">00:03:45.280</a></span> | <span class="t">Now, we initialize the tokenizer and model, and then we do our embeddings.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=229" target="_blank">00:03:49.600</a></span> | <span class="t">So to create those embeddings,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=231" target="_blank">00:03:51.840</a></span> | <span class="t">one thing that we do need to do with this model, a little bit of a formatting thing,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=235" target="_blank">00:03:55.200</a></span> | <span class="t">is we need to prefix every input document or passage with the text passage.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=242" target="_blank">00:04:02.960</a></span> | <span class="t">This just tells the model, the embedding model,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=246" target="_blank">00:04:06.800</a></span> | <span class="t">that this is a passage of text and not a query of text.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=250" target="_blank">00:04:10.080</a></span> | <span class="t">Later on, you'll see that we replace this with query rather than passage</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=254" target="_blank">00:04:14.720</a></span> | <span class="t">when we're doing querying.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=256" target="_blank">00:04:16.240</a></span> | <span class="t">And we tokenize everything.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=258" target="_blank">00:04:18.160</a></span> | <span class="t">And then we process everything through a model,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=261" target="_blank">00:04:21.680</a></span> | <span class="t">extract the hidden state of the model,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=264" target="_blank">00:04:24.400</a></span> | <span class="t">and turn that all into a single embedding</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=269" target="_blank">00:04:29.280</a></span> | <span class="t">for each input document or passage that we have put in there.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=273" target="_blank">00:04:33.360</a></span> | <span class="t">So that's our embedding.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=274" target="_blank">00:04:34.720</a></span> | <span class="t">Then we move on to adding everything into our index.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=280" target="_blank">00:04:40.880</a></span> | <span class="t">It's where we're storing our vectors.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=283" target="_blank">00:04:43.040</a></span> | <span class="t">Here, we're just using a local NumPy array.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=285" target="_blank">00:04:45.200</a></span> | <span class="t">It's a very small data set.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=287" target="_blank">00:04:47.680</a></span> | <span class="t">And we're just doing this for like a walkthrough.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=290" target="_blank">00:04:50.720</a></span> | <span class="t">Obviously, if you want to do anything in production, don't do this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=294" target="_blank">00:04:54.720</a></span> | <span class="t">Use a vector database.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=296" target="_blank">00:04:56.720</a></span> | <span class="t">Unless you're happy you're handling all the data management stuff around it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=300" target="_blank">00:05:00.160</a></span> | <span class="t">Now, what I did here is for our APIs, I used a batch size of 128.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=306" target="_blank">00:05:06.720</a></span> | <span class="t">In reality, I probably could have moved this up to 256.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=310" target="_blank">00:05:10.160</a></span> | <span class="t">And that would speed things up a little more.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=312" target="_blank">00:05:12.720</a></span> | <span class="t">So OpenAI, it took like nine minutes to index all of these documents.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=316" target="_blank">00:05:16.880</a></span> | <span class="t">With Cohere, it took five and a half minutes.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=319" target="_blank">00:05:19.520</a></span> | <span class="t">So it seems like Cohere is a bit faster at ingestion and returning embeddings.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=325" target="_blank">00:05:25.600</a></span> | <span class="t">And then if we look at our open source model, E5, it's a pretty small model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=330" target="_blank">00:05:30.160</a></span> | <span class="t">So we can embed things pretty quickly.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=332" target="_blank">00:05:32.240</a></span> | <span class="t">For this, I was using a V100 GPU on Google Colab.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=337" target="_blank">00:05:37.040</a></span> | <span class="t">You can use a T5.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=339" target="_blank">00:05:39.360</a></span> | <span class="t">But if you're embedding this whole index in memory, which you probably shouldn't anyway,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=346" target="_blank">00:05:46.800</a></span> | <span class="t">your memory may -- you may run out of memory.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=349" target="_blank">00:05:49.360</a></span> | <span class="t">Like actual RAM memory where you're storing your NumPy array</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=353" target="_blank">00:05:53.040</a></span> | <span class="t">rather than the actual GPU embedding memory.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=356" target="_blank">00:05:56.000</a></span> | <span class="t">So, yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=358" target="_blank">00:05:58.000</a></span> | <span class="t">One thing is obviously we have a higher batch size here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=362" target="_blank">00:06:02.000</a></span> | <span class="t">So if we decrease that, we might get -- we'll probably see slower results.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=366" target="_blank">00:06:06.640</a></span> | <span class="t">Now, after that is done, our index is ready.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=370" target="_blank">00:06:10.000</a></span> | <span class="t">We are ready to query.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=371" target="_blank">00:06:11.200</a></span> | <span class="t">So we move on to our query function.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=373" target="_blank">00:06:13.760</a></span> | <span class="t">Now, the query function is basically the same as what we did before.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=377" target="_blank">00:06:17.280</a></span> | <span class="t">We are creating our embeddings.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=381" target="_blank">00:06:21.120</a></span> | <span class="t">And here I could have just used the embedding function from the OpenAI notebook.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=384" target="_blank">00:06:24.880</a></span> | <span class="t">Here I could not use the embedding function because I need</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=388" target="_blank">00:06:28.240</a></span> | <span class="t">to adjust the input type to query rather than document or passage.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=394" target="_blank">00:06:34.160</a></span> | <span class="t">And then for the E5 model, again, we would need to modify this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=399" target="_blank">00:06:39.760</a></span> | <span class="t">So here we have query instead of passage.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=402" target="_blank">00:06:42.160</a></span> | <span class="t">Okay?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=403" target="_blank">00:06:43.440</a></span> | <span class="t">Otherwise, there's not too much difference here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=405" target="_blank">00:06:45.920</a></span> | <span class="t">What we do after all of this is we calculate dot product similarity</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=410" target="_blank">00:06:50.240</a></span> | <span class="t">between our query vector and the index.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=413" target="_blank">00:06:53.360</a></span> | <span class="t">And we do the exact same thing for the cohere model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=416" target="_blank">00:06:56.000</a></span> | <span class="t">Both of these are normalized.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=417" target="_blank">00:06:57.120</a></span> | <span class="t">So we're just calculating the dot product.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=419" target="_blank">00:06:59.120</a></span> | <span class="t">I believe with E5, the output was not normalized.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=424" target="_blank">00:07:04.080</a></span> | <span class="t">So we could either normalize the vectors and then use dot product</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=427" target="_blank">00:07:07.440</a></span> | <span class="t">or we just use cosine similarity, which is just normalized dot product.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=432" target="_blank">00:07:12.480</a></span> | <span class="t">So, it's up to you.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=434" target="_blank">00:07:14.720</a></span> | <span class="t">And then one thing that we should be aware of here,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=437" target="_blank">00:07:17.520</a></span> | <span class="t">which is this is an important thing to take into consideration</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=442" target="_blank">00:07:22.880</a></span> | <span class="t">when you're storing these vectors, is every embedding model,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=445" target="_blank">00:07:25.920</a></span> | <span class="t">not every embedding model, but a lot of embedding models</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=448" target="_blank">00:07:28.000</a></span> | <span class="t">have different embedding dimensionalities.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=451" target="_blank">00:07:31.440</a></span> | <span class="t">So when using R002, the dimensionality that we output is this 1536.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=457" target="_blank">00:07:37.600</a></span> | <span class="t">All right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=457" target="_blank">00:07:37.840</a></span> | <span class="t">So 1536 dimensional vectors.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=461" target="_blank">00:07:41.760</a></span> | <span class="t">That means we're going to be using more storage</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=464" target="_blank">00:07:44.800</a></span> | <span class="t">than if we're using a cohere embedding model, which is just 1024.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=469" target="_blank">00:07:49.760</a></span> | <span class="t">And that is still going to be more than if we use the E5 embedding model,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=473" target="_blank">00:07:53.280</a></span> | <span class="t">which is 768.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=474" target="_blank">00:07:54.960</a></span> | <span class="t">So that's important to consider, especially sort of long-term.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=480" target="_blank">00:08:00.720</a></span> | <span class="t">It's going to cost more to store the higher dimensional vectors.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=485" target="_blank">00:08:05.200</a></span> | <span class="t">So now looking at the results between each one of these models,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=489" target="_blank">00:08:09.680</a></span> | <span class="t">which we'll see are pretty similar in terms of performance,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=493" target="_blank">00:08:13.520</a></span> | <span class="t">at least on the few queries I ran.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=495" target="_blank">00:08:15.920</a></span> | <span class="t">Now, this is not an easy dataset for a embedding model to understand.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=499" target="_blank">00:08:19.200</a></span> | <span class="t">It's very messy, but that's more representative of the real world</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=502" target="_blank">00:08:22.720</a></span> | <span class="t">rather than like clean benchmark data or anything like that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=506" target="_blank">00:08:26.320</a></span> | <span class="t">So I think this is a good example of what they can do and what they can't do.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=510" target="_blank">00:08:30.960</a></span> | <span class="t">So I asked, why should I use LLAMA2?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=513" target="_blank">00:08:33.120</a></span> | <span class="t">Pretty simple question.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=514" target="_blank">00:08:34.160</a></span> | <span class="t">I know that LLAMA2 paper is within this dataset.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=517" target="_blank">00:08:37.280</a></span> | <span class="t">So I know we should be able to come back with stuff.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=519" target="_blank">00:08:39.280</a></span> | <span class="t">Now, when you see this text here, this is actually LLAMA2.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=526" target="_blank">00:08:46.400</a></span> | <span class="t">It's just formatted weirdly.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=528" target="_blank">00:08:48.160</a></span> | <span class="t">So we see this first one, it's talking about LLAMA2.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=530" target="_blank">00:08:50.880</a></span> | <span class="t">And I'm asking, why should I use it?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=532" target="_blank">00:08:52.720</a></span> | <span class="t">It says intended for assistant-like chat and used for a variety of NL generation tests,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=539" target="_blank">00:08:59.920</a></span> | <span class="t">natural language generation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=541" target="_blank">00:09:01.280</a></span> | <span class="t">But I mean, that's pretty much it in the first document there.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=545" target="_blank">00:09:05.600</a></span> | <span class="t">Here, again, we're talking about LLAMA2.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=547" target="_blank">00:09:07.920</a></span> | <span class="t">You see that's optimized for dialogue use cases, outperform open source chat models</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=554" target="_blank">00:09:14.000</a></span> | <span class="t">on most benchmarks, and our human evaluations for helpfulness and safety</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=559" target="_blank">00:09:19.200</a></span> | <span class="t">may be a substitute for closed source models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=561" target="_blank">00:09:21.760</a></span> | <span class="t">So we can see, you know, it's a good answer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=565" target="_blank">00:09:25.600</a></span> | <span class="t">And then in the final one here, we get similar answers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=568" target="_blank">00:09:28.160</a></span> | <span class="t">So we can see perform better, open source, and on par with some closed source.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=574" target="_blank">00:09:34.880</a></span> | <span class="t">That's LLAMA2.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=576" target="_blank">00:09:36.320</a></span> | <span class="t">Let's see Cohere's model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=577" target="_blank">00:09:37.760</a></span> | <span class="t">So we can see we get some different results here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=580" target="_blank">00:09:40.400</a></span> | <span class="t">And unfortunately, the first one is actually talking about the first LLAMA model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=584" target="_blank">00:09:44.560</a></span> | <span class="t">So it's not quite right.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=586" target="_blank">00:09:46.400</a></span> | <span class="t">Come down to here, and we do get one of the same results that LLAMA2 got.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=591" target="_blank">00:09:51.280</a></span> | <span class="t">So optimized for dialogue, outperform open source chat models,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=597" target="_blank">00:09:57.600</a></span> | <span class="t">maybe a substitute for closed source models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=600" target="_blank">00:10:00.640</a></span> | <span class="t">Then we come back to here, and we get the same response that we got in the previous one as well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=606" target="_blank">00:10:06.160</a></span> | <span class="t">So perform better than open source, and on par with closed source.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=612" target="_blank">00:10:12.000</a></span> | <span class="t">Cool.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=613" target="_blank">00:10:13.440</a></span> | <span class="t">Then we come to E5.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=615" target="_blank">00:10:15.440</a></span> | <span class="t">The first one at the top here is kind of not relevant, so we can ignore that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=619" target="_blank">00:10:19.760</a></span> | <span class="t">But then the two here that we get, again,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=621" target="_blank">00:10:21.840</a></span> | <span class="t">they're the same as what we saw with the previous two models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=625" target="_blank">00:10:25.520</a></span> | <span class="t">Okay, cool.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=629" target="_blank">00:10:29.520</a></span> | <span class="t">So looking at another more specific question about red teaming for LLAMA2.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=634" target="_blank">00:10:34.800</a></span> | <span class="t">So it's like security testing or stress testing LLAMA2.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=638" target="_blank">00:10:38.080</a></span> | <span class="t">We can see, okay, this first one here is talking about red teaming, not specific to LLAMA2,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=645" target="_blank">00:10:45.280</a></span> | <span class="t">although we'll see that none of the models actually managed to find that information</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=650" target="_blank">00:10:50.080</a></span> | <span class="t">within the same chunk, which just makes me think, okay,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=653" target="_blank">00:10:53.840</a></span> | <span class="t">we don't have LLAMA2 and red teaming within the same chunk within the dataset.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=658" target="_blank">00:10:58.000</a></span> | <span class="t">But we can see, okay, this one is talking about jokes, insults based on physical characteristics,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=663" target="_blank">00:11:03.360</a></span> | <span class="t">racist language, so on and so on.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=665" target="_blank">00:11:05.040</a></span> | <span class="t">This is them testing the model with red teaming.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=667" target="_blank">00:11:07.440</a></span> | <span class="t">So, yeah, it's relevant.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=669" target="_blank">00:11:09.440</a></span> | <span class="t">Obviously, red team approach and results.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=671" target="_blank">00:11:11.600</a></span> | <span class="t">On the second one, we can see, okay, we have red team members here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=675" target="_blank">00:11:15.600</a></span> | <span class="t">Red team members enjoyed the task and did not experience significant negative emotions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=681" target="_blank">00:11:21.120</a></span> | <span class="t">This allows us to expedite the red team's ability to find vulnerabilities in our system,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=686" target="_blank">00:11:26.320</a></span> | <span class="t">so on and so on.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=688" target="_blank">00:11:28.080</a></span> | <span class="t">Okay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=688" target="_blank">00:11:28.960</a></span> | <span class="t">Kind of relevant, not great.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=690" target="_blank">00:11:30.640</a></span> | <span class="t">And then we have red teaming via jailbreaking.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=694" target="_blank">00:11:34.320</a></span> | <span class="t">I think this one's probably a bit more relevant, a bit more useful.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=697" target="_blank">00:11:37.920</a></span> | <span class="t">And all of this here is describing red teaming overall.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=702" target="_blank">00:11:42.400</a></span> | <span class="t">And then they describe, okay, this is a qualitative approach called red teaming at the end there.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=709" target="_blank">00:11:49.840</a></span> | <span class="t">So, okay, results, nothing special, in my opinion.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=714" target="_blank">00:11:54.240</a></span> | <span class="t">Okay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=714" target="_blank">00:11:54.720</a></span> | <span class="t">Now, with cohere, we can see aiding in disinformation campaigns, generating extremist text.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=719" target="_blank">00:11:59.760</a></span> | <span class="t">So, this is them talking about what they did for testing with red teaming.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=723" target="_blank">00:12:03.360</a></span> | <span class="t">Spreading falsehoods and more.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=727" target="_blank">00:12:07.760</a></span> | <span class="t">As AI systems improve, the scope of possible harm seems to grow.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=731" target="_blank">00:12:11.920</a></span> | <span class="t">One potential useful tool for addressing harm is red teaming using manual or automated methods</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=739" target="_blank">00:12:19.040</a></span> | <span class="t">to adversarially probe a language model for harmful outputs.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=743" target="_blank">00:12:23.680</a></span> | <span class="t">All right.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=743" target="_blank">00:12:23.920</a></span> | <span class="t">Already this one to me is explaining more about red teaming than any of the other ones from R002.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=750" target="_blank">00:12:30.400</a></span> | <span class="t">And we have the other one on red teaming via jailbreaking.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=754" target="_blank">00:12:34.400</a></span> | <span class="t">So, we already saw this one.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=755" target="_blank">00:12:35.760</a></span> | <span class="t">So, I'm not going to go through it again.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=757" target="_blank">00:12:37.040</a></span> | <span class="t">But it was okay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=758" target="_blank">00:12:38.480</a></span> | <span class="t">It's not a bad response.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=761" target="_blank">00:12:41.680</a></span> | <span class="t">Or document to retrieve.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=763" target="_blank">00:12:43.840</a></span> | <span class="t">And then here we have including limitations and risks that might be exploited by malicious actors.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=768" target="_blank">00:12:48.320</a></span> | <span class="t">So, that's another part of red teaming, like testing it, see if people can use these things</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=772" target="_blank">00:12:52.560</a></span> | <span class="t">maliciously.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=773" target="_blank">00:12:53.200</a></span> | <span class="t">Red teaming approaches are insufficient for addressing these in the AI context.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=780" target="_blank">00:13:00.640</a></span> | <span class="t">Processes such as red teaming exercises help organizations to discover their own</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=787" target="_blank">00:13:07.360</a></span> | <span class="t">limitations and vulnerabilities as well as those of the AI systems they develop.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=794" target="_blank">00:13:14.080</a></span> | <span class="t">And to approach them holistically.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=796" target="_blank">00:13:16.160</a></span> | <span class="t">A red team exercise is a structured effort to find flaws and vulnerabilities in a plan,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=802" target="_blank">00:13:22.960</a></span> | <span class="t">organization, or technical system.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=805" target="_blank">00:13:25.600</a></span> | <span class="t">Often performed by a dedicated red team that seeks to adopt an attacker's mindset and methods.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=812" target="_blank">00:13:32.160</a></span> | <span class="t">Okay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=812" target="_blank">00:13:32.480</a></span> | <span class="t">And it goes on and on.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=815" target="_blank">00:13:35.280</a></span> | <span class="t">There's a few, I think, good, insightful things in here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=818" target="_blank">00:13:38.960</a></span> | <span class="t">Flaws.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=820" target="_blank">00:13:40.240</a></span> | <span class="t">Allow organizations to improve security.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=824" target="_blank">00:13:44.000</a></span> | <span class="t">Yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=825" target="_blank">00:13:45.840</a></span> | <span class="t">And so on.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=826" target="_blank">00:13:46.320</a></span> | <span class="t">So, I think that's, in my opinion, better than the open AI responses.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=831" target="_blank">00:13:51.840</a></span> | <span class="t">Then we come to E5.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=833" target="_blank">00:13:53.200</a></span> | <span class="t">We get some good ones again.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=834" target="_blank">00:13:54.640</a></span> | <span class="t">So, here we're talking about publicly available red team data sets.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=838" target="_blank">00:13:58.880</a></span> | <span class="t">And red team attacks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=840" target="_blank">00:14:00.800</a></span> | <span class="t">It's a data set that they're obviously talking about here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=844" target="_blank">00:14:04.000</a></span> | <span class="t">Not too relevant.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=845" target="_blank">00:14:05.280</a></span> | <span class="t">Right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=845" target="_blank">00:14:05.520</a></span> | <span class="t">It's mentioned red teaming.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=847" target="_blank">00:14:07.520</a></span> | <span class="t">But it's not, it's not talking about, I don't know what red teaming is based on this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=853" target="_blank">00:14:13.440</a></span> | <span class="t">Then again, we're talking about red teaming here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=855" target="_blank">00:14:15.280</a></span> | <span class="t">A literature review on red teaming AI systems.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=859" target="_blank">00:14:19.600</a></span> | <span class="t">Informational interviews with experts in the field of trust and safety.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=862" target="_blank">00:14:22.960</a></span> | <span class="t">Or incorporate their best practices.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=865" target="_blank">00:14:25.840</a></span> | <span class="t">In general, we found that red teaming members enjoyed participating in our experiments and felt</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=871" target="_blank">00:14:31.760</a></span> | <span class="t">motivated by a mission to make AI systems less harmful.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=875" target="_blank">00:14:35.920</a></span> | <span class="t">Okay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=876" target="_blank">00:14:36.480</a></span> | <span class="t">So, kind of relevant, but it could be better.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=879" target="_blank">00:14:39.760</a></span> | <span class="t">And then this one at the bottom.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=882" target="_blank">00:14:42.400</a></span> | <span class="t">I mean, it says red teaming here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=884" target="_blank">00:14:44.160</a></span> | <span class="t">I have no idea what any of this means.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=886" target="_blank">00:14:46.480</a></span> | <span class="t">Maybe it's talking about red teaming.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=888" target="_blank">00:14:48.080</a></span> | <span class="t">Maybe it's a good response.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=889" target="_blank">00:14:49.040</a></span> | <span class="t">But I don't know.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=890" target="_blank">00:14:50.240</a></span> | <span class="t">I'm going to assume it isn't.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=891" target="_blank">00:14:51.520</a></span> | <span class="t">In any case, I think obviously clearly here, E5, the performance is not quite as good as</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=897" target="_blank">00:14:57.840</a></span> | <span class="t">Cohere or open AI.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=900" target="_blank">00:15:00.160</a></span> | <span class="t">And generally, I think the Cohere model outperformed both in this scenario.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=906" target="_blank">00:15:06.000</a></span> | <span class="t">But we should also note that this here is the base model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=909" target="_blank">00:15:09.440</a></span> | <span class="t">There's also a large model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=911" target="_blank">00:15:11.440</a></span> | <span class="t">And generally, what you'll find with these models is that the large model will perform</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=915" target="_blank">00:15:15.920</a></span> | <span class="t">much better than the base model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=917" target="_blank">00:15:17.680</a></span> | <span class="t">So, we might even be able to get comparable results with that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=922" target="_blank">00:15:22.080</a></span> | <span class="t">Now, I'm not going to go through all of these now.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=925" target="_blank">00:15:25.760</a></span> | <span class="t">Instead, I'll just leave these notebooks that you can go and check out.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=930" target="_blank">00:15:30.480</a></span> | <span class="t">But we asked a few questions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=932" target="_blank">00:15:32.800</a></span> | <span class="t">Mainly, you know, about LLAMA2 and other things that are within these papers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=937" target="_blank">00:15:37.200</a></span> | <span class="t">And generally speaking, OpenAI, Cohere, and E5 all got pretty good results.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=942" target="_blank">00:15:42.800</a></span> | <span class="t">E5 is probably the weakest of them.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=944" target="_blank">00:15:44.640</a></span> | <span class="t">And between Cohere and OpenAI, for me, Cohere seemed to perform slightly better.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=952" target="_blank">00:15:52.080</a></span> | <span class="t">But it's a pretty limited test set.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=954" target="_blank">00:15:54.000</a></span> | <span class="t">So, I feel like a lot of this will be down to personal preference to some degree.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=960" target="_blank">00:16:00.240</a></span> | <span class="t">But at some point, of course, I'll test these with more data and try and get a better feel</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=965" target="_blank">00:16:05.920</a></span> | <span class="t">for which one of these I prefer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=967" target="_blank">00:16:07.600</a></span> | <span class="t">But for now, yeah, leaning towards Cohere.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=970" target="_blank">00:16:10.640</a></span> | <span class="t">Now, that's it for this video.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=973" target="_blank">00:16:13.600</a></span> | <span class="t">I hope seeing a couple of these alternative embedding models has been useful and interesting.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=979" target="_blank">00:16:19.360</a></span> | <span class="t">So, thank you very much for watching.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=982" target="_blank">00:16:22.400</a></span> | <span class="t">And I will see you again in the next one.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=985" target="_blank">00:16:25.280</a></span> | <span class="t">Bye.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=LzRpTNV74Ck&t=986" target="_blank">00:16:26.320</a></span> | <span class="t">[Music]</span></div></div></body></html>