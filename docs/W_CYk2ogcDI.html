<html><head><title>RAG in 2025: State of the Art and the Road Forward — Tengyu Ma, MongoDB (acq. Voyage AI)</title>
<style>
    body {
        font-family: Arial, sans-serif;
        margin: 0;
        padding: 0;
        background-color: #f4f4f4;
        color: #333;
    }
    .container {
        width: 95%;  /* Increased width to use more space */
        margin: auto;
        overflow: auto;  /* Added to handle overflow by adding a scrollbar if necessary */
    }
    h2, h3 {
        color: #333;
        text-align: center;
    }
    a {
        color: #0000FF;  /* Traditional blue color for links */
        text-decoration: none;
    }
    a:hover {
        text-decoration: underline;
    }
    img {
        display: block;
        margin: auto;
        max-width: 100%;
    }
    .c {
        margin: 10px 0;
    }
    .s, .t {
        display: inline-block;
        margin-right: 5px;
    }
    .max-width {
        max-width: 800px;
        margin: auto;
        padding-left: 20px;
    }
    table {
        width: 100%;
        border-collapse: collapse;
    }
    th, td {
        border: 1px solid #ddd;
        padding: 8px;
        text-align: left;  /* Ensure text alignment is consistent */
    }
    tr:nth-child(even) {
        background-color: #f2f2f2;
    }
    tr:nth-child(odd) {
        background-color: #e6e6e6;
    }
</style>

    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-69VLBMTTP0"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-69VLBMTTP0');
    </script>
    </head><body><div class='container'><a href="index.html">back to index</a><h2>RAG in 2025: State of the Art and the Road Forward — Tengyu Ma, MongoDB (acq. Voyage AI)</h2><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI"><img src="https://i.ytimg.com/vi_webp/W_CYk2ogcDI/maxresdefault.webp" style="width:50%;"></a><div><br></div><div style="text-align: left;"><a href="./W_CYk2ogcDI.html">Whisper Transcript</a> | <a href="./transcript_W_CYk2ogcDI.html">Transcript Only Page</a></div><br><div style="max-width: 800px;"><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI&t=0" target="_blank">00:00:00.000</a></span> | <span class="t">Thanks for coming. Thanks for having me here. I'm Tang Yuma. I was the CEO and co-founder of 4H-AI.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI&t=22" target="_blank">00:00:22.480</a></span> | <span class="t">We just recently got acquired by MongoDB. I'm also teaching at Stanford as well. So this is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI&t=28" target="_blank">00:00:28.440</a></span> | <span class="t">about RAG, which is the main focus of 4H-AI, the startup who is focusing on how to make</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI&t=33" target="_blank">00:00:33.780</a></span> | <span class="t">retrieval better. But I will just generally talk about RAG, and we'll touch on some of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI&t=39" target="_blank">00:00:39.820</a></span> | <span class="t">the products we make as well very quickly. So I guess why we are doing RAG or anything</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI&t=45" target="_blank">00:00:45.000</a></span> | <span class="t">like that, right? So I guess the main reason is that large language model are these days</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI&t=49" target="_blank">00:00:49.100</a></span> | <span class="t">agents, which are using large language models as well. If they're out of the box, they cannot</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI&t=54" target="_blank">00:00:54.400</a></span> | <span class="t">just have priority information from any of the companies, right? Because if they know</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI&t=59" target="_blank">00:00:59.740</a></span> | <span class="t">anything about what MongoDB, for example, internally has, then the data was leaked. So that means</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI&t=66" target="_blank">00:01:06.660</a></span> | <span class="t">that if you want to apply any of this to enterprise, then you need to ingest a lot of data from the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI&t=72" target="_blank">00:01:12.740</a></span> | <span class="t">property information. So, and I'm going to discuss, you know, why, which kind of technologies to enable</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI&t=80" target="_blank">00:01:20.080</a></span> | <span class="t">us to ingest the data. I guess there are a few options: RAG, fine-tuning, and long contacts, which are always to ingest data and now focus on RAG for the rest of the talk.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI&t=90" target="_blank">00:01:30.080</a></span> | <span class="t">So I guess, you know, for this audience, probably most people knows these technologies, and they are all very simple on a high level.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI&t=96" target="_blank">00:01:36.740</a></span> | <span class="t">So for long contacts, it's just the most simple. You just dump all your documents onto a large language model's contacts, and maybe it's like 1 million tokens, maybe it's 1 billion tokens.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI&t=107" target="_blank">00:01:47.420</a></span> | <span class="t">And then you have a query, and you just get a response. Fine-tuning is like your first fine-tune a large English model. You update the parameters, and then you say, "I'm not going to look at the documents anymore."</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI&t=119" target="_blank">00:01:59.420</a></span> | <span class="t">When the query comes, I just use the updated parameters to generate response. And RAG is also pretty simple. So basically, what happens is that, on the fly, you use the query to retrieve some subset of the documents.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI&t=132" target="_blank">00:02:12.420</a></span> | <span class="t">You use the retrieval or search method, and then you get some relevant documents. You give this small set of relevant documents to the large language model, and then you generate response based on those contacts.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI&t=142" target="_blank">00:02:22.420</a></span> | <span class="t">So this is my one slide, kind of like a summary of how I think about the differences between these technologies. You know, some of these are inspired by some of the research at Stanford.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI&t=154" target="_blank">00:02:34.420</a></span> | <span class="t">When we kind of started to build Voyage, you know, we kind of like believe in RAG, and one of the reasons is that we don't believe that fine-tuning can work.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI&t=163" target="_blank">00:02:43.420</a></span> | <span class="t">And long contacts, I think, I also don't really believe that it can be cost-efficient in the long run.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI&t=169" target="_blank">00:02:49.420</a></span> | <span class="t">So basically, I think the way that I think about this is that I try to make an analogy to how humans are learning from or using the additional property information.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI&t=181" target="_blank">00:03:01.420</a></span> | <span class="t">So in some sense, long contacts, it's kind of like you scheme an entire library to answer any single question, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI&t=187" target="_blank">00:03:07.420</a></span> | <span class="t">Every time you answer a question, you need to go through the entire library, which has like probably one billion tokens.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI&t=193" target="_blank">00:03:13.420</a></span> | <span class="t">And fine-tuning is kind of like you read this library in advance, you must memorize them, you try to internalize them in your brain, in your neurons, in your synapses,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI&t=202" target="_blank">00:03:22.420</a></span> | <span class="t">and you update your brain, basically rewire your brain so that you really know all of those deeply.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI&t=207" target="_blank">00:03:27.420</a></span> | <span class="t">The challenge there is that, you know, it's very difficult and somewhat unnecessary because, you know, you cannot really memorize all the books in the world and memorizing a subset of them.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI&t=219" target="_blank">00:03:39.420</a></span> | <span class="t">Sometimes it's kind of like, you know, which subset you want to memorize is kind of tricky as well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI&t=224" target="_blank">00:03:44.420</a></span> | <span class="t">So and another thing is that it makes, you know, forgetting the knowledge also tricky because you don't know which part of the knowledge you should forget and how to clearly forget all of them.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI&t=234" target="_blank">00:03:54.420</a></span> | <span class="t">And also this makes the access, the data governance also kind of tricky because, you know, maybe there are so many libraries, so many books in the library and not everyone can access everything and how to organize those.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI&t=246" target="_blank">00:04:06.420</a></span> | <span class="t">And on the other hand, reg is very, very simple and modularized as I've shown, so and very reliable and, you know, and also kind of fast and cheap.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI&t=256" target="_blank">00:04:16.420</a></span> | <span class="t">So and it's kind of like similar to how humans actually are using the libraries, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI&t=261" target="_blank">00:04:21.420</a></span> | <span class="t">You achieve the most relevant, you know, book chapters or books or book chapters and then answer the question.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI&t=266" target="_blank">00:04:26.420</a></span> | <span class="t">It's kind of a hierarchical way to store information, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI&t=269" target="_blank">00:04:29.420</a></span> | <span class="t">You don't really put all of the information in your brain, you put them in a library and then use them when you need it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI&t=275" target="_blank">00:04:35.420</a></span> | <span class="t">So that's why I believe in reg and this is how you implement the retrieval part.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI&t=281" target="_blank">00:04:41.420</a></span> | <span class="t">So basically there is a breakdown of two components.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI&t=284" target="_blank">00:04:44.420</a></span> | <span class="t">Actually, there are three, you know, if you are advanced.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI&t=286" target="_blank">00:04:46.420</a></span> | <span class="t">So these embedding models which vectorize the documents and query into vectors and the vectors are representations of the content or the meanings of the documents and queries.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI&t=300" target="_blank">00:05:00.420</a></span> | <span class="t">And then you use a vector database to store the data and also search within the k-nearest neighbor search in the vector space.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI&t=306" target="_blank">00:05:06.420</a></span> | <span class="t">And then you get the relevant documents and then you can use large-generation model to generate answers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI&t=310" target="_blank">00:05:10.420</a></span> | <span class="t">So we have seen significant improvements over the retrieval accuracy in the last two years.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI&t=317" target="_blank">00:05:17.420</a></span> | <span class="t">when we started Voyage, you know, I think OpenAI v3 was not yet launched.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI&t=322" target="_blank">00:05:22.420</a></span> | <span class="t">I think OpenAI v3 was launched 1.5 years ago.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI&t=325" target="_blank">00:05:25.420</a></span> | <span class="t">And in the last 1.5 years, you know, Voyage, you know, has made significant progress.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI&t=330" target="_blank">00:05:30.420</a></span> | <span class="t">You know, Cohere also made some progress.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI&t=332" target="_blank">00:05:32.420</a></span> | <span class="t">So we can see that a new model has much better accuracy and with lower cost.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI&t=337" target="_blank">00:05:37.420</a></span> | <span class="t">And generally we have much better scaling law, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI&t=340" target="_blank">00:05:40.420</a></span> | <span class="t">So the same number of parameters, the quality becomes better.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI&t=343" target="_blank">00:05:43.420</a></span> | <span class="t">Or the same quality, the parameters become smaller and it becomes cheaper.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI&t=348" target="_blank">00:05:48.420</a></span> | <span class="t">And all of these are through kind of like, you know, optimizing the research stack, the tuning stack, you know, as much as possible.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI&t=356" target="_blank">00:05:56.420</a></span> | <span class="t">You know, all the way from like data curation, data selection, architecture, loss functions, you know, evaluation, so on and so forth.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI&t=363" target="_blank">00:06:03.420</a></span> | <span class="t">And we still, you know, believe that there's a big headroom here because, you know, right now you can see that in this plot, you know, we are averaging over about 100 data sets and accuracy is about 80%.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI&t=373" target="_blank">00:06:13.420</a></span> | <span class="t">So that means that you still have like probably 20% of the improvement on headroom.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI&t=379" target="_blank">00:06:19.420</a></span> | <span class="t">But that said, you know, just to be clear, it's not like for every data set, you only have 80% accuracy.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI&t=384" target="_blank">00:06:24.420</a></span> | <span class="t">For probably half of the data sets, the accuracy is probably 90% or even 95%.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI&t=388" target="_blank">00:06:28.420</a></span> | <span class="t">And for some of the other ones, it's kind of 60, sometimes 20, sometimes 30.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI&t=392" target="_blank">00:06:32.420</a></span> | <span class="t">So that's why your average is 80%.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI&t=394" target="_blank">00:06:34.420</a></span> | <span class="t">So basically I'm saying like for some of the tasks that are common, I think you can get already very high accuracy in the retrieval step.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI&t=402" target="_blank">00:06:42.420</a></span> | <span class="t">And another thing that Voyage and other companies has offered is this so-called matrix learning and also quantization of wire training.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI&t=413" target="_blank">00:06:53.420</a></span> | <span class="t">So basically these are two approaches to reduce the storage cost for the vectors.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI&t=418" target="_blank">00:06:58.420</a></span> | <span class="t">So basically matrix learning means that you make sure that even you have like a high dimensional embedding, right, you can use a subset of the coordinates.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI&t=429" target="_blank">00:07:09.420</a></span> | <span class="t">It's usually the first, let's say suppose you have a 2048 dimensional vectors and the first 256 dimensional sub vector is still a reasonable embedding.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI&t=441" target="_blank">00:07:21.420</a></span> | <span class="t">The accuracy wouldn't be as high as 2048, but it will be almost the same, maybe with a 1% or 2% loss.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI&t=449" target="_blank">00:07:29.420</a></span> | <span class="t">And quantization is kind of in a similar vein.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI&t=452" target="_blank">00:07:32.420</a></span> | <span class="t">So where you are, even you lower your precision of the vectors, you still get pretty high performance.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI&t=457" target="_blank">00:07:37.420</a></span> | <span class="t">And you can see the trade off on the right of the figure here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI&t=461" target="_blank">00:07:41.420</a></span> | <span class="t">So basically you can save, you know, 100x, you know, at least 10x without losing much.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI&t=467" target="_blank">00:07:47.420</a></span> | <span class="t">If you save 100x in the storage cost, then you start to lose probably 5 to 10%.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI&t=472" target="_blank">00:07:52.420</a></span> | <span class="t">But Voyage, you know, is doing a great job here because, you know, you can save 100x but still doing better than OpenEye.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI&t=478" target="_blank">00:07:58.420</a></span> | <span class="t">That's just because the parental front here is different.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI&t=481" target="_blank">00:08:01.420</a></span> | <span class="t">So, and you can actually see better trade off, you know, for domain specific models, which I'm going to discuss in a moment.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI&t=490" target="_blank">00:08:10.420</a></span> | <span class="t">I have nine minutes here, so I will probably just quickly go through some of the techniques that you can use.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI&t=497" target="_blank">00:08:17.420</a></span> | <span class="t">So basically the next question is how do you do better reg, you know, besides using better embedding models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI&t=502" target="_blank">00:08:22.420</a></span> | <span class="t">Using better embedding models is probably one of the simplest way.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI&t=505" target="_blank">00:08:25.420</a></span> | <span class="t">So I'm just going to go through it quickly.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI&t=507" target="_blank">00:08:27.420</a></span> | <span class="t">So one of them is to use hybrid search and re-rankers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI&t=510" target="_blank">00:08:30.420</a></span> | <span class="t">You can use, you know, lexical search and other kind of search and then combine them with a re-ranker.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI&t=515" target="_blank">00:08:35.420</a></span> | <span class="t">And Voyage provides a re-ranker as well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI&t=518" target="_blank">00:08:38.420</a></span> | <span class="t">And another one is you can enhance the queries and documents by the so-called query decomposition and document enrichment.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI&t=525" target="_blank">00:08:45.420</a></span> | <span class="t">So this is probably the most common one.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI&t=527" target="_blank">00:08:47.420</a></span> | <span class="t">Maybe there's one minute on it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI&t=528" target="_blank">00:08:48.420</a></span> | <span class="t">So it's actually very simple.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI&t=529" target="_blank">00:08:49.420</a></span> | <span class="t">You just say, if you have a query reg, then you try to improve the query by making it longer using a large language model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI&t=536" target="_blank">00:08:56.420</a></span> | <span class="t">You can also decompose the longer query into small sub-queries so that you can have, like, a few different queries and search for different subset of documents.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI&t=544" target="_blank">00:09:04.420</a></span> | <span class="t">And you can also enrich the document by adding additional matter information in it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI&t=549" target="_blank">00:09:09.420</a></span> | <span class="t">You can add titles, you know, hiders, you know, categories, author, states.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI&t=553" target="_blank">00:09:13.420</a></span> | <span class="t">Sometimes you trunk the document so that in the trunk you don't even have this information anymore.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI&t=557" target="_blank">00:09:17.420</a></span> | <span class="t">So that's why you have to add the global information into each of the trunks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI&t=560" target="_blank">00:09:20.420</a></span> | <span class="t">And some of this global information can be added by large language models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI&t=564" target="_blank">00:09:24.420</a></span> | <span class="t">Anthropik wrote a blog post which does achieve pretty good results.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI&t=568" target="_blank">00:09:28.420</a></span> | <span class="t">So basically they use large language models to generate additional contacts that you can add to the trunks so that you can make the trunks, you know, more informative and then it's easier to search through them.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI&t=579" target="_blank">00:09:39.420</a></span> | <span class="t">So another one is you can use domain-specific embeddings where you customize embeddings for certain kind of domains.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI&t=587" target="_blank">00:09:47.420</a></span> | <span class="t">You know, in MongoDB or Voyage, we customize it for code, for example.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI&t=591" target="_blank">00:09:51.420</a></span> | <span class="t">And you can see that, you know, you get much better performance and also it's a better trade-off in terms of the storage cost and accuracy.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI&t=600" target="_blank">00:10:00.420</a></span> | <span class="t">So basically you don't lose as much if you compress the vectors even further.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI&t=605" target="_blank">00:10:05.420</a></span> | <span class="t">So here we lose probably 5% by compressing for like about 100x.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI&t=611" target="_blank">00:10:11.420</a></span> | <span class="t">But before we lose probably 10% or 15%.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI&t=614" target="_blank">00:10:14.420</a></span> | <span class="t">Fine-tuning is another one.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI&t=616" target="_blank">00:10:16.420</a></span> | <span class="t">You can fine-tuning embedding models with your own data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI&t=618" target="_blank">00:10:18.420</a></span> | <span class="t">And you can also use other, sometimes I call them tricks on top of the embeddings, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI&t=623" target="_blank">00:10:23.420</a></span> | <span class="t">So these are different type of ways to retrieve using additional information like graph, you know, iterative retrieving.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI&t=629" target="_blank">00:10:29.420</a></span> | <span class="t">So on and so forth, they're all based on embeddings, but you can use the embeddings in many different ways as an additional layer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI&t=638" target="_blank">00:10:38.420</a></span> | <span class="t">So I guess I'll use the next probably five minutes to discuss some of my vision for how reg will go in the future.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI&t=648" target="_blank">00:10:48.420</a></span> | <span class="t">I do believe that reg will be there forever because this is, as I argued in the first set of slides,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI&t=654" target="_blank">00:10:54.420</a></span> | <span class="t">this is kind of like very similar to how humans are using additional large amount of data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI&t=660" target="_blank">00:11:00.420</a></span> | <span class="t">You retrieve, you hierarchically select some subset and then you use those to answer the questions or take some actions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI&t=668" target="_blank">00:11:08.420</a></span> | <span class="t">And this is very efficient because you only use a small subset of the data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI&t=673" target="_blank">00:11:13.420</a></span> | <span class="t">And as a, regarding how reg will evolve from a technical point of view, I'd like to draw some analogy from how the AI generally is evolving.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI&t=688" target="_blank">00:11:28.420</a></span> | <span class="t">So I think I was reflecting on when I was teaching at Stanford, you know, starting to teach at Stanford about seven years ago.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI&t=694" target="_blank">00:11:34.420</a></span> | <span class="t">I started to teach with Chris Ray on this machine learning course.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI&t=697" target="_blank">00:11:37.420</a></span> | <span class="t">And one of the slides literally have these seven steps on how do we build ML systems in enterprises.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI&t=703" target="_blank">00:11:43.420</a></span> | <span class="t">So this actually, this slide is still in the lecture notes.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI&t=707" target="_blank">00:11:47.420</a></span> | <span class="t">We still teach them, but just with more kind of like asterisks around it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI&t=712" target="_blank">00:11:52.420</a></span> | <span class="t">So you can see like you, you need to go through, you know, many steps, you know, tracking data, you know,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI&t=718" target="_blank">00:11:58.420</a></span> | <span class="t">define your loss functions, you know, build models and iterate and repeat.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI&t=722" target="_blank">00:12:02.420</a></span> | <span class="t">And then for the large language model world, it's kind of like this, where you don't need to do any of this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI&t=727" target="_blank">00:12:07.420</a></span> | <span class="t">You just take a large language model out of the box and just, you know, you can deploy it in enterprise in most of the cases.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI&t=734" target="_blank">00:12:14.420</a></span> | <span class="t">Of course, it's not going to be perfect, but this is already better than in the old days.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI&t=738" target="_blank">00:12:18.420</a></span> | <span class="t">You do all of these steps in the enterprise using all the enterprise data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI&t=741" target="_blank">00:12:21.420</a></span> | <span class="t">Just out of the box, you are doing already very, very well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI&t=744" target="_blank">00:12:24.420</a></span> | <span class="t">Of course, you still have this issue that you cannot, out of the box, large language model cannot access property information.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI&t=751" target="_blank">00:12:31.420</a></span> | <span class="t">Then you can use reg for it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI&t=754" target="_blank">00:12:34.420</a></span> | <span class="t">So, but I think the point here is that before all of these steps have to be done by the kind of like the users or the enterprise or the customers in some sense.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI&t=764" target="_blank">00:12:44.420</a></span> | <span class="t">And now you, largely speaking, just can take off the shelf components and connect them and build your AI applications very fast without going through these training steps.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI&t=774" target="_blank">00:12:54.420</a></span> | <span class="t">The trainings still have to be done, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI&t=776" target="_blank">00:12:56.420</a></span> | <span class="t">All of these steps still are done, but they are done by OpenAI, Anthropik or Voyage, MongoDB, the providers of the models, but not the users, the end users.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI&t=787" target="_blank">00:13:07.420</a></span> | <span class="t">So, and I think for reg, I would say probably the same kind of evolution which would happen.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI&t=793" target="_blank">00:13:13.420</a></span> | <span class="t">So, right now what happens is that we have the several different layers where you have the computing infrastructure layer about the GPUs, you know, or some of the KNs on the CPUs.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI&t=804" target="_blank">00:13:24.420</a></span> | <span class="t">And there's also a model layer where you have the embedding models, the revampers, the large language models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI&t=809" target="_blank">00:13:29.420</a></span> | <span class="t">And then on top of all of this, people use a lot of like, I call it tricks to make reg accuracy much better, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI&t=817" target="_blank">00:13:37.420</a></span> | <span class="t">You can use all kinds of parsing strategies, you can use all kinds of trunking strategies, you know, you can do some recursive search, you can do some contextual trunks, graph regs, so on and so forth.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI&t=830" target="_blank">00:13:50.420</a></span> | <span class="t">Right, that's what happens right now, and it's kind of necessary, these tricks are somewhat necessary because the embeddings and revampers and large language models, none of them are perfect yet.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI&t=839" target="_blank">00:13:59.420</a></span> | <span class="t">Right, so, and, but I do believe that in the future, I think this model layer will grow, and the tricks will be smaller.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI&t=847" target="_blank">00:14:07.420</a></span> | <span class="t">So, it's going to be fewer and fewer tricks, and the models can capture many of the performance gained by the tricks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI&t=855" target="_blank">00:14:15.420</a></span> | <span class="t">I think we have seen this in the large language model space as well, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI&t=858" target="_blank">00:14:18.420</a></span> | <span class="t">So, like, two years ago, I think you need to do a lot of things on top of the GPT-3 to make your application work.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI&t=865" target="_blank">00:14:25.420</a></span> | <span class="t">And now, even out of the box, you can get the same performance as before with all of the tricks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI&t=871" target="_blank">00:14:31.420</a></span> | <span class="t">Of course, you still probably need some kind of tricks because some information are not, some information the embedding models and revampers don't have just, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI&t=882" target="_blank">00:14:42.420</a></span> | <span class="t">So, the general purpose models or off-the-shelf models don't have certain information, and then you can incorporate those into your tricks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI&t=889" target="_blank">00:14:49.420</a></span> | <span class="t">For example, one thing that is that, you know, the definition of the similarity matrix could be something that you should customize in your prompt.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI&t=897" target="_blank">00:14:57.420</a></span> | <span class="t">And in this one, you know, I think there are several things that we are developing towards this vision, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI&t=904" target="_blank">00:15:04.420</a></span> | <span class="t">So, one of them is multi-model embedding.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI&t=906" target="_blank">00:15:06.420</a></span> | <span class="t">This is to dramatically simplify the workflow so that you don't have to do many things, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI&t=911" target="_blank">00:15:11.420</a></span> | <span class="t">So, these days, the multi-model embedding provided by Voyage can just take in screenshots, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI&t=916" target="_blank">00:15:16.420</a></span> | <span class="t">Before you take a PDF, you have to do the data extraction to turn them into image and text and then probably do some embeddings for the image and embedding for the text separately.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI&t=925" target="_blank">00:15:25.420</a></span> | <span class="t">And parsing this PDF is actually complex, you know, and for videos, you have to turn them into transcripts and then use the text embedding, so on and so forth.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI&t=935" target="_blank">00:15:35.420</a></span> | <span class="t">Right now, we have the multi-model embedding, which just takes in screenshots.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI&t=939" target="_blank">00:15:39.420</a></span> | <span class="t">You can deal with PDF, you know, PPT, PowerPoint, you know, any of the other kind of slide stack in the same way.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI&t=946" target="_blank">00:15:46.420</a></span> | <span class="t">Just take a screenshot and then use the multi-model embedding.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI&t=949" target="_blank">00:15:49.420</a></span> | <span class="t">We don't have the -- we can even do the same thing for video, not necessarily the perfect way, but, like, you just take screenshots of the frames, you know, consecutive frames,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI&t=957" target="_blank">00:15:57.420</a></span> | <span class="t">and you give it to the multi-model embedding, and you can turn them into vectors, and you can search over those documents or videos or slide stack.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI&t=965" target="_blank">00:16:05.420</a></span> | <span class="t">And these are some performance metrics that we have evaluated.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI&t=971" target="_blank">00:16:11.420</a></span> | <span class="t">You know, we have tried kind of like -- oh, by the way, another one application is tables, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI&t=975" target="_blank">00:16:15.420</a></span> | <span class="t">Now you can just take a screenshot of the tables.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI&t=977" target="_blank">00:16:17.420</a></span> | <span class="t">You don't have to think too much about what is the header, what is the row, so on and so forth.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI&t=981" target="_blank">00:16:21.420</a></span> | <span class="t">And we have done evaluations on many of these document screenshots, you know, table figures, and also text only.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI&t=987" target="_blank">00:16:27.420</a></span> | <span class="t">And you can see that it's improving across the board.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI&t=990" target="_blank">00:16:30.420</a></span> | <span class="t">So the final one I would like to mention, which is something that we're going to launch soon is that this context wire and auto-trunking embedding.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI&t=999" target="_blank">00:16:39.420</a></span> | <span class="t">So right now what happens is that when you have a long document, you do have to trunk the data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI&t=1005" target="_blank">00:16:45.420</a></span> | <span class="t">One of the reasons is that the context length of the embeddings is limited.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI&t=1010" target="_blank">00:16:50.420</a></span> | <span class="t">And if you have, like, 100K tokens, you do have to trunk it into three or four trunks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI&t=1014" target="_blank">00:16:54.420</a></span> | <span class="t">You know, even though Voyage AI has the -- probably -- I think we have the longest context window.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI&t=1020" target="_blank">00:17:00.420</a></span> | <span class="t">It's still like 32K.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI&t=1021" target="_blank">00:17:01.420</a></span> | <span class="t">So that's one reason to trunk.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI&t=1023" target="_blank">00:17:03.420</a></span> | <span class="t">And another reason to trunk is that sometimes the long document, even if you don't trunk, suppose you can have a way to put all of them in a context window.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI&t=1032" target="_blank">00:17:12.420</a></span> | <span class="t">Still, when you retrieve, you're going to retrieve on a document level.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI&t=1035" target="_blank">00:17:15.420</a></span> | <span class="t">Then you retrieve a very, very long document.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI&t=1037" target="_blank">00:17:17.420</a></span> | <span class="t">And then you should give this long document to a large language model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI&t=1040" target="_blank">00:17:20.420</a></span> | <span class="t">It's going to be very, very expensive, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI&t=1041" target="_blank">00:17:21.420</a></span> | <span class="t">If you give 100K tokens to a large language model, every time you answer any question, if you do some cost analysis, you'll find that that core is very, very expensive.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI&t=1050" target="_blank">00:17:30.420</a></span> | <span class="t">So that's why you do have to work on a smaller unit so that you can cut the cost and be also more focused, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI&t=1056" target="_blank">00:17:36.420</a></span> | <span class="t">So sometimes you give a long document to a large language model, it misses some of the context in the middle.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI&t=1061" target="_blank">00:17:41.420</a></span> | <span class="t">And you have to use the retrieval to focus on a paragraph, a page, so on and so forth.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI&t=1065" target="_blank">00:17:45.420</a></span> | <span class="t">So that's what happens right now with the trunking.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI&t=1068" target="_blank">00:17:48.420</a></span> | <span class="t">But all of these are done by the users.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI&t=1070" target="_blank">00:17:50.420</a></span> | <span class="t">And our vision is that we're going to do this for you.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI&t=1073" target="_blank">00:17:53.420</a></span> | <span class="t">And also we're going to get all the meta information from other trunks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI&t=1078" target="_blank">00:17:58.420</a></span> | <span class="t">So basically, in a nutshell, the interface will be that you give us a long document and we're going to trunk it for you.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI&t=1085" target="_blank">00:18:05.420</a></span> | <span class="t">And then also we return the trunks and also the vectors for each of the trunk.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI&t=1090" target="_blank">00:18:10.420</a></span> | <span class="t">And each of these vectors is not only representing that trunk, but also representing some of the global meta information from other trunks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI&t=1097" target="_blank">00:18:17.420</a></span> | <span class="t">So it has all the details of the corresponding trunk and also has some kind of like cross-grid information from other trunks so that you can get the best of the both worlds.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI&t=1107" target="_blank">00:18:27.420</a></span> | <span class="t">And that's what I'm going to launch soon.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI&t=1110" target="_blank">00:18:30.420</a></span> | <span class="t">And another one is that we're going to have some fine-tune API at some point to make you so that you can fine-tune with your own data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI&t=1118" target="_blank">00:18:38.420</a></span> | <span class="t">So I guess it's exactly time.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI&t=1120" target="_blank">00:18:40.420</a></span> | <span class="t">Thanks very much.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI&t=1121" target="_blank">00:18:41.420</a></span> | <span class="t">Thanks very much.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI&t=1122" target="_blank">00:18:42.420</a></span> | <span class="t">Thanks very much.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI&t=1123" target="_blank">00:18:43.420</a></span> | <span class="t">Thanks very much.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI&t=1123" target="_blank">00:18:43.420</a></span> | <span class="t">you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=W_CYk2ogcDI&t=1125" target="_blank">00:18:45.480</a></span> | <span class="t">We'll see you next time.</span></div></div></body></html>