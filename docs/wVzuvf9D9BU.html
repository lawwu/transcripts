<html><head><title>GPT 4 is Smarter than You Think: Introducing SmartGPT</title></head><body>
    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-69VLBMTTP0"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-69VLBMTTP0');
    </script>
    <a href="index.html">back to index</a><h2>GPT 4 is Smarter than You Think: Introducing SmartGPT</h2><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU"><img src="https://i.ytimg.com/vi/wVzuvf9D9BU/maxresdefault.jpg" style="width:50%;"></a><div><br></div><div style="text-align: left;"><a href="./wVzuvf9D9BU.html">Whisper Transcript</a> | <a href="./transcript_wVzuvf9D9BU.html">Transcript Only Page</a></div><br><div style="max-width: 800px;"><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=0">00:00:00.000</a></span> | <span class="t">I have three goals for this video. First, I want to show you a way of using GPT-4 to get smarter</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=6">00:00:06.120</a></span> | <span class="t">results. Second, I want to argue that the benchmark results we have for GPT-4 do not reflect its full</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=13">00:00:13.080</a></span> | <span class="t">abilities. And third, I want to show you a system that I am developing, somewhat cheekily called</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=18">00:00:18.080</a></span> | <span class="t">SmartGPT, that is already showing significant results on official benchmarks. It remains to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=24">00:00:24.420</a></span> | <span class="t">be fully optimized, which I think is exciting in itself. I have shown the system to people</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=29">00:00:29.520</a></span> | <span class="t">at OpenAI who have been quite impressed, and I'm going to end with some reflections on where</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=34">00:00:34.340</a></span> | <span class="t">that might leave us for GPT-5. But before I get into how it works, I just want to show you one</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=40">00:00:40.200</a></span> | <span class="t">example of it in action to whet your appetite. This example comes from a TED talk that was</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=45">00:00:45.380</a></span> | <span class="t">released this week. So suppose I left five clothes to dry out in the sun, and it took them five hours</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=52">00:00:52.120</a></span> | <span class="t">to dry completely. How long would it take to dry 30 clothes? GPT-4, the newest, greatest AI</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=59">00:00:59.040</a></span> | <span class="t">system says 30 hours. Not good. On the left, you can see GPT-4's original answer, and it gives this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=65">00:01:05.980</a></span> | <span class="t">answer pretty consistently whenever you prompt it with the question provided. On the right,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=70">00:01:10.680</a></span> | <span class="t">you can see the final answer from the SmartGPT model, which is correct, and it consistently</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=75">00:01:15.640</a></span> | <span class="t">gives that answer. I really like how it gives context as well, and it provides some of the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=80">00:01:20.260</a></span> | <span class="t">assumptions that it had in giving this correct answer. Now, don't you worry, there will be</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=84">00:01:24.620</a></span> | <span class="t">plenty more examples to go through in this video, including another one from that TED talk.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=88">00:01:28.560</a></span> | <span class="t">But first, I want to give you an overview of what is this SmartGPT model, where did I get my</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=93">00:01:33.920</a></span> | <span class="t">inspiration for it from, and how does it work? I'm going to keep it fairly simple because it's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=98">00:01:38.100</a></span> | <span class="t">the beginning of the video, and I know a lot of people won't really care about the inner details.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=102">00:01:42.280</a></span> | <span class="t">That will come later in the video. But the high-level overview is this. There are at least</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=107">00:01:47.700</a></span> | <span class="t">three things that have been proven to improve the outputs of GPT-4. What's called chain of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=113">00:01:53.480</a></span> | <span class="t">thought prompting, sometimes called step-by-step prompting, reflection, or finding its own</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=118">00:01:58.080</a></span> | <span class="t">errors. And I did an entire video on this called GPT-4 can self-improve. And dialoguing with itself,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=124">00:02:04.040</a></span> | <span class="t">entering into a back and forth on its own outputs and deciding which one is best. You can see the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=129">00:02:09.800</a></span> | <span class="t">title of the papers, which contain much more detailed results, of course, linked above. Now,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=134">00:02:14.480</a></span> | <span class="t">the first paper only came out a few days ago, midway through my testing. So my results don't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=139">00:02:19.400</a></span> | <span class="t">even reflect the full capacity of the model. And even if there's nothing else you take from this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=144">00:02:24.440</a></span> | <span class="t">video, the results from this paper can instantly improve the results of the model. So I'm going to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=147">00:02:27.600</a></span> | <span class="t">show you how to instantly improve the outputs you get from GPT-4. Many of you might remember that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=153">00:02:33.360</a></span> | <span class="t">prompting GPT-4 with let's think step-by-step improves its results. To give you a very quick</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=159">00:02:39.920</a></span> | <span class="t">reference point, just asking a question to GPT-4 gives you 81% accuracy. With that prompt, let's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=166">00:02:46.320</a></span> | <span class="t">think step-by-step, it goes up to 86%. But algorithmically, the paper found an improved</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=172">00:02:52.560</a></span> | <span class="t">prompt that can give you even better results, 89% accuracy.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=177">00:02:57.120</a></span> | <span class="t">So let's go back to the first part of SmartGPT, is we add answer. Let's work this out in a step-by-step</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=183">00:03:03.200</a></span> | <span class="t">way to be sure we have the right answer. Now, I have so much to say about why I think this works,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=189">00:03:09.600</a></span> | <span class="t">but I know many of you won't be that interested in my theories. So I'm going to save them to the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=194">00:03:14.240</a></span> | <span class="t">end for those who are interested. Some of you just want the results. So I'm going to get to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=198">00:03:18.120</a></span> | <span class="t">those first. So far, you might be thinking, well, thanks, Philip, that's a cool prompt. I'm going</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=202">00:03:22.040</a></span> | <span class="t">to use that. But what's this whole SmartGPT about? Is it just a single prompt? No, I'm going to use</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=206">00:03:26.640</a></span> | <span class="t">the answer. So I believe with evidence, there are ways of leveraging even better results than just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=211">00:03:31.480</a></span> | <span class="t">using a great chain of thought prompt. So let's move on to the next part of the system, these</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=216">00:03:36.920</a></span> | <span class="t">different outputs in the middle. For my tests, I typically did three outputs, but of course,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=220">00:03:40.840</a></span> | <span class="t">depending on the context window, it could be far more than that. And I'm going to talk about ways</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=225">00:03:45.080</a></span> | <span class="t">I could further improve this model, or we could, later on in the video. Just to restate, these</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=230">00:03:50.440</a></span> | <span class="t">outputs are when you take the user input and add the word question at the start, and then at the end,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=235">00:03:55.480</a></span> | <span class="t">add answer, and then add answer. So I'm going to use the answer, and then add answer, and then add</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=236">00:03:56.160</a></span> | <span class="t">answer. Let's work this out in a step-by-step way to make sure we have the right answer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=239">00:03:59.800</a></span> | <span class="t">And at this moment, many of you are thinking, what is the point of multiple outputs? It's GPT-4,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=244">00:04:04.900</a></span> | <span class="t">it's just going to give you the answer it thinks is best, and that's it. Well, actually, it doesn't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=248">00:04:08.580</a></span> | <span class="t">quite work like that. These models have a temperature between zero and one. I believe</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=252">00:04:12.860</a></span> | <span class="t">the default for GPT-4 might be around 0.5. And simplifying massively, this determines how creative</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=259">00:04:19.380</a></span> | <span class="t">or conservative the model is in giving its outputs. So given that GPT-4 tries to be fairly creative,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=265">00:04:25.680</a></span> | <span class="t">you don't get the same output every time. The output is randomly sampled according to an</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=270">00:04:30.760</a></span> | <span class="t">internal probability distribution. So you can get situations, and I face this hundreds of times,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=275">00:04:35.960</a></span> | <span class="t">where some of the outputs are correct, and others are incorrect. And this is where reflection comes</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=281">00:04:41.580</a></span> | <span class="t">in. Sometimes, definitely not always, but sometimes, quite often, GPT-4 can detect the errors in its</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=288">00:04:48.640</a></span> | <span class="t">own output. And many of you will notice at this point that the prompt that I used to elicit GPT-4</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=295">00:04:55.200</a></span> | <span class="t">to spot its own errors contains the same step-by-step prompt I used earlier that has been shown to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=302">00:05:02.200</a></span> | <span class="t">produce good results. So to summarize, sometimes at this stage, GPT-4 detects the errors that some</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=309">00:05:09.420</a></span> | <span class="t">of its outputs have made. Definitely not always. There are certain questions it just simply can't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=314">00:05:14.260</a></span> | <span class="t">spot the error. But sometimes it can, and then I get it to engage in a dialogue using a format</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=319">00:05:19.680</a></span> | <span class="t">similar to one in this paper published last month. It's a short dialogue, and this is the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=324">00:05:24.720</a></span> | <span class="t">step I believe that can be most optimized. In the future, I envision an entire council of advisors</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=330">00:05:30.660</a></span> | <span class="t">made up of GPT-4 imitating mathematicians, judges, etc. At the moment, it's just being a resolver and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=338">00:05:38.040</a></span> | <span class="t">printing a final improved output. Anyway, I'm going to get back to the theory later in the video,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=342">00:05:42.900</a></span> | <span class="t">because I know some of you will be getting bored at this stage and want to see more practical</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=346">00:05:46.640</a></span> | <span class="t">examples and the results from my benchmark tests. As I don't have the GPT-4 API key, yes, I had to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=354">00:05:54.240</a></span> | <span class="t">import each of these steps hundreds of times, waiting sometimes three hours between each go,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=359">00:05:59.740</a></span> | <span class="t">because you can only do 25 messages every three hours. On the left, you can see the three outputs</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=365">00:06:05.020</a></span> | <span class="t">when you ask it to think step by step. And then you have the researcher step in the middle and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=370">00:06:10.340</a></span> | <span class="t">at the top right. And finally, the resolver step. Notice here, I was using the original</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=374">00:06:14.680</a></span> | <span class="t">let's think step by step because the paper hadn't yet been published on improving that prompt.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=379">00:06:19.580</a></span> | <span class="t">It's time for the second example from that TED talk, and then I definitely will</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=383">00:06:23.760</a></span> | <span class="t">get on to the benchmarks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=385">00:06:25.420</a></span> | <span class="t">A different one. I have 12 liter jug and 6 liter jug and I want to measure 6 liters. How do I do it?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=391">00:06:31.860</a></span> | <span class="t">Just use the 6 liter jug, right? GPT-4 spits out some very elaborate nonsense.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=398">00:06:38.260</a></span> | <span class="t">Of course, I tested SmartGPT with that question, and you can see the difference between the original GPT-4,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=405">00:06:45.760</a></span> | <span class="t">which gives this incredibly convoluted bad answer, and SmartGPT, the final answer output.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=411">00:06:51.520</a></span> | <span class="t">Now, at this point, I know many of you will be impressed,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=413">00:06:53.280</a></span> | <span class="t">but you'll be thinking, I don't have time to input things five times.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=417">00:06:57.460</a></span> | <span class="t">Well, I'm developing a model where it can all be done automatically.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=421">00:07:01.340</a></span> | <span class="t">Here is a preview of how it works. But of course, at the moment, it has to use GPT-3.5 turbo</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=426">00:07:06.780</a></span> | <span class="t">because I don't have the API key of GPT-4. But the epic thing is this. You just ask a single question.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=432">00:07:12.840</a></span> | <span class="t">I've written, ask SmartGPT a question. And of course, it does take a little bit longer to respond</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=437">00:07:17.580</a></span> | <span class="t">because it's doing five or six calls via API. But it does output the final answer from the resolver.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=442">00:07:22.800</a></span> | <span class="t">I will be honest and say that GPT-3.5 isn't as good at reflecting or resolving.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=448">00:07:28.680</a></span> | <span class="t">But this is an example of a question where the original ChatGPT consistently gets it wrong,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=453">00:07:33.360</a></span> | <span class="t">and SmartGPT-3.5 gets it right using this program.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=457">00:07:37.900</a></span> | <span class="t">Remember, all you have to do as a user is type in a question as normal,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=461">00:07:41.700</a></span> | <span class="t">and it goes through this entire five or six step process behind the scenes.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=466">00:07:46.020</a></span> | <span class="t">By the way, this was a question from MMLU, which is a famous benchmark, which I'll get to in a second.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=471">00:07:51.300</a></span> | <span class="t">Here's one last practical example.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=472">00:07:52.320</a></span> | <span class="t">Before I get to that benchmark.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=474">00:07:54.820</a></span> | <span class="t">I know many teachers use ChatGPT and GPT-4 to create quizzes for their classes.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=479">00:07:59.760</a></span> | <span class="t">And here is the same question put through GPT-4 and SmartGPT.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=483">00:08:03.900</a></span> | <span class="t">The question is create a high school algebra quiz with five questions and answers and explanations at the end.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=489">00:08:09.760</a></span> | <span class="t">Now points for spotting the difference.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=491">00:08:11.520</a></span> | <span class="t">But if the teacher had handed out the original quiz, look at the answers for question five.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=496">00:08:16.780</a></span> | <span class="t">It says the answers are one and 1.5, but then in the explanation, it gives</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=501">00:08:21.840</a></span> | <span class="t">the final answers, which are correct, by the way, of three and 0.5.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=506">00:08:26.400</a></span> | <span class="t">So that would really confuse some students.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=508">00:08:28.800</a></span> | <span class="t">At the reflection stage, SmartGPT spotted that error and resolved it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=512">00:08:32.880</a></span> | <span class="t">And as you can see, the answer for question five has the correct answers straight away.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=517">00:08:37.920</a></span> | <span class="t">If at any point you're wondering if I completed the OpenAI ChatGPT prompt engineering course, the answer is yes,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=523">00:08:43.800</a></span> | <span class="t">but it didn't inform too much of my thinking.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=526">00:08:46.080</a></span> | <span class="t">It was more for beginners, and I had already factored in things like giving the model time to think and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=531">00:08:51.360</a></span> | <span class="t">writing clear instructions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=532">00:08:52.980</a></span> | <span class="t">The benchmark that I chose to test SmartGPT on was the famous MMLU, Massive Multitask Language Understanding benchmark.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=541">00:09:01.680</a></span> | <span class="t">As you can see, the state of the art is indeed GPT-4 with 86.4% accuracy.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=547">00:09:07.560</a></span> | <span class="t">And you know OpenAI think it's a big deal because it's the benchmark mentioned on the front page of their technical report.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=554">00:09:14.160</a></span> | <span class="t">Without boring you too much, I extracted the questions from the test set of the MMLU data file.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=560">00:09:20.220</a></span> | <span class="t">And I didn't pick the question.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=560">00:09:20.880</a></span> | <span class="t">I didn't pick the topics at random.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=562">00:09:22.800</a></span> | <span class="t">I went for those that I thought GPT-4 would find the hardest.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=566">00:09:26.940</a></span> | <span class="t">Delving into the original MMLU paper, you can see that GPT-3 found formal logic the hardest, scoring just over 25%, which is random chance.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=577">00:09:37.860</a></span> | <span class="t">It's a four question multiple choice test, so around 25 or 30% is pretty bad.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=583">00:09:43.620</a></span> | <span class="t">And notice they helped out GPT-3 here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=585">00:09:45.900</a></span> | <span class="t">They did it few shot, meaning they gave it five successful examples.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=590">00:09:50.400</a></span> | <span class="t">Before asking it a new question.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=592">00:09:52.400</a></span> | <span class="t">It's the same thing they did with GPT-4.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=594">00:09:54.400</a></span> | <span class="t">They did it five shot.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=596">00:09:56.400</a></span> | <span class="t">But just before I show you the results, there are three things I want to mention here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=598">00:09:58.400</a></span> | <span class="t">First, I was curious how SmartGPT would do without any help.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=604">00:10:04.400</a></span> | <span class="t">Zero shot.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=606">00:10:06.400</a></span> | <span class="t">Second, I wanted to do it zero shot because people using GPT-4 don't typically give five successful examples before asking GPT-4 a question.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=614">00:10:14.400</a></span> | <span class="t">They just want code or a quiz or a poem or an example.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=616">00:10:16.400</a></span> | <span class="t">They don't often provide five brilliant examples of code.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=618">00:10:18.400</a></span> | <span class="t">They just want a quiz or a poem or an example.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=618">00:10:18.400</a></span> | <span class="t">They don't often provide five brilliant examples of code.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=620">00:10:20.400</a></span> | <span class="t">Before asking their question.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=622">00:10:22.400</a></span> | <span class="t">And third, if I can prove it works zero shot, then of course future refinements can be made to push the results even further.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=628">00:10:28.400</a></span> | <span class="t">And here are the results from the first 25 questions from the formal logic test set of the MMLU.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=635">00:10:35.400</a></span> | <span class="t">I did many more tests after this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=637">00:10:37.400</a></span> | <span class="t">But you can see from this set, if you just ask the question, you get a lower overall accuracy.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=643">00:10:43.400</a></span> | <span class="t">But of course 68% for GPT-4 is still a huge improvement over GPT-3's around 25%.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=649">00:10:49.400</a></span> | <span class="t">What happens when you add "Let's think step by step" which as we know now isn't the fully optimized chain of thought prompt.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=657">00:10:57.400</a></span> | <span class="t">Well, on average you get around 74-75%.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=661">00:11:01.400</a></span> | <span class="t">That was 75 examples inputted manually and I still have all the tabs open.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=666">00:11:06.400</a></span> | <span class="t">I'm keeping them open because I'm compiling a spreadsheet with the actual outputs.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=670">00:11:10.400</a></span> | <span class="t">But what did the resolver get drawing upon GPT-4's ability to reflect and engage in dialogue with itself?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=676">00:11:16.400</a></span> | <span class="t">It got 84%.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=678">00:11:18.400</a></span> | <span class="t">Now notice something about that number.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=680">00:11:20.400</a></span> | <span class="t">GPT-4 zero shot got 32% of the questions wrong.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=684">00:11:24.400</a></span> | <span class="t">That was halved to 16% after putting it through the smart GPT system.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=689">00:11:29.400</a></span> | <span class="t">There was one question where the resolver model gave both a correct and incorrect answer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=694">00:11:34.400</a></span> | <span class="t">But I'm counting that as an incorrect answer for the purposes of this test.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=698">00:11:38.400</a></span> | <span class="t">Anyway, from 32% to 16% incorrect.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=702">00:11:42.400</a></span> | <span class="t">That is a pattern that stayed consistent throughout all my testing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=707">00:11:47.400</a></span> | <span class="t">Ultimately, half of the errors that GPT-4 makes can be rectified if you give it the optimized step by step prompt,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=715">00:11:55.400</a></span> | <span class="t">get it to reflect on its results and get it to engage in dialogue and decide on a final answer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=722">00:12:02.400</a></span> | <span class="t">At this point, for those people losing track of all the details, I want to put into context what resolving half of the errors on MMLU might mean in the context of the big picture.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=732">00:12:12.400</a></span> | <span class="t">Here's Lennart Heim, an AI governance researcher, suggesting a score of 95% of the errors in the big picture.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=736">00:12:16.400</a></span> | <span class="t">95% on the MMLU would be reflective of AGI-like abilities.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=742">00:12:22.400</a></span> | <span class="t">I do think I have like a 50% chance, like within the next 20 years or so, there might be something what we might call an AGI or transformative AI.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=750">00:12:30.400</a></span> | <span class="t">What do I mean by this? Well, maybe can measure it on benchmarks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=753">00:12:33.400</a></span> | <span class="t">There's like this famous MMLU benchmarks like, yeah, there's something which like scores like 95% on this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=759">00:12:39.400</a></span> | <span class="t">Going back to the results, if a smart GPT-like system can automatically resolve half of the errors</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=765">00:12:45.400</a></span> | <span class="t">that GPT-4 makes on the MMLU, that would increase its score from around 86.4% to around 93%, which is not far off 95%.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=776">00:12:56.400</a></span> | <span class="t">Remember, his prediction was a 50% chance in 20 years.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=780">00:13:00.400</a></span> | <span class="t">I'm talking about GPT-4 now.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=782">00:13:02.400</a></span> | <span class="t">For those who are still skeptical, I'm going to show you plenty more results now and then walk through the papers that give the theory as to why this works.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=790">00:13:10.400</a></span> | <span class="t">One thing that I forgot to mention earlier is that the human expert level on the MMLU,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=794">00:13:14.400</a></span> | <span class="t">is 89.8% and that's taking the 95th percentile of human test takers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=801">00:13:21.400</a></span> | <span class="t">And remember, those are domain experts in each of the subtopics.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=805">00:13:25.400</a></span> | <span class="t">What we're doing is testing GPT-4 or smart GPT on all of the topics simultaneously.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=812">00:13:32.400</a></span> | <span class="t">So even if smart GPT-like systems can't quite reach 95%, and I think honestly they'll get pretty close with all the refinements that I'm going to suggest,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=820">00:13:40.400</a></span> | <span class="t">I think they should almost certainly be 89.8%.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=823">00:13:43.400</a></span> | <span class="t">Which is the human expert test taker level.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=827">00:13:47.400</a></span> | <span class="t">Intrigued by these results, I then put it through the college math test from the MMLU.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=833">00:13:53.400</a></span> | <span class="t">And remember, this was before using the optimized version of the step-by-step prompt.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=837">00:13:57.400</a></span> | <span class="t">Obviously, I'm not going to go through all the questions here, but let's skip to the final results.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=844">00:14:04.400</a></span> | <span class="t">We have zero shot accuracy, 6 out of 15, which is 40%.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=848">00:14:08.400</a></span> | <span class="t">The average when you add let's think step-by-step was 53.5%.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=852">00:14:12.400</a></span> | <span class="t">And then the final output of the resolver model had a 60% accuracy.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=858">00:14:18.400</a></span> | <span class="t">So it couldn't quite resolve half of the errors, but the overall pattern held up.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=862">00:14:22.400</a></span> | <span class="t">In case anyone is wondering about methodology, I kept the formatting identical for every question.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=868">00:14:28.400</a></span> | <span class="t">I always opened a new tab for each question.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=871">00:14:31.400</a></span> | <span class="t">It wasn't looking at the context of what it had already put out.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=874">00:14:34.400</a></span> | <span class="t">Each attempt was fresh, aside from the resolver model, which looked at the context of the researcher's output.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=881">00:14:41.400</a></span> | <span class="t">And again, as you can see from example 14, it wasn't like the researcher could always spot the errors,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=887">00:14:47.400</a></span> | <span class="t">or that the resolver could always pick the right option.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=890">00:14:50.400</a></span> | <span class="t">Sometimes the let's think step-by-step prompt gave the right output, but the resolver couldn't quite distinguish it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=897">00:14:57.400</a></span> | <span class="t">The optimized prompt gets a slightly better output.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=900">00:15:00.400</a></span> | <span class="t">And upon reflection, the researcher can sometimes, but not always, spot the errors of those outputs.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=907">00:15:07.400</a></span> | <span class="t">And sometimes, but not always, the resolver can spot them.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=910">00:15:10.400</a></span> | <span class="t">But the researcher can spot the errors of those outputs.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=912">00:15:12.400</a></span> | <span class="t">And the resolver can spot based on those flaws, which answer is best.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=914">00:15:14.400</a></span> | <span class="t">These are incremental improvements.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=916">00:15:16.400</a></span> | <span class="t">Sometimes GPC4 simply can't get it right.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=918">00:15:18.400</a></span> | <span class="t">I have noticed a few themes in those questions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=921">00:15:21.400</a></span> | <span class="t">Anytime it comes to division, multiplication, characters, or counting in general,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=926">00:15:26.400</a></span> | <span class="t">GPC4 tends to make mistakes that neither the researcher nor resolver can spot.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=931">00:15:31.400</a></span> | <span class="t">Of course, integrating a few tools via API would likely solve those issues.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=936">00:15:36.400</a></span> | <span class="t">And I don't want to preempt the conclusion too much,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=939">00:15:39.400</a></span> | <span class="t">but I believe a smart GPT-like system with tools integrated could probably score around 95% right now on the MMLU.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=949">00:15:49.400</a></span> | <span class="t">Especially if it was helped out with few-shot prompting.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=953">00:15:53.400</a></span> | <span class="t">To add weight to that preliminary conclusion, I tested it on certain topics and had to stop because it simply got the questions right every single time.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=961">00:16:01.400</a></span> | <span class="t">For example, high school psychology from the MMLU.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=964">00:16:04.400</a></span> | <span class="t">I then tried prehistory, which it also aced, before finding machine learning.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=968">00:16:08.400</a></span> | <span class="t">Where I got more interesting results.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=970">00:16:10.400</a></span> | <span class="t">Zooming in, this time the raw score was 65%.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=974">00:16:14.400</a></span> | <span class="t">The chain of thought, let's think step-by-step average was 71.6%.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=978">00:16:18.400</a></span> | <span class="t">And the resolver model got 80%.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=981">00:16:21.400</a></span> | <span class="t">Let's now look a little deeper into why all of these steps might improve the end result.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=985">00:16:25.400</a></span> | <span class="t">In reply to the original let's think step-by-step paper, which was published around a year ago,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=991">00:16:31.400</a></span> | <span class="t">Andrej Karpathy said this:</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=993">00:16:33.400</a></span> | <span class="t">"Adding something like let's think step-by-step to the prompt is a way of using the idea that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=997">00:16:37.400</a></span> | <span class="t">the input space for computation is what you'd normally want in the hidden state of the model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=1003">00:16:43.400</a></span> | <span class="t">Instead of the workings out being done in the activations of the neural network,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=1007">00:16:47.400</a></span> | <span class="t">it's done in the discrete tokens of that input space."</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=1011">00:16:51.400</a></span> | <span class="t">And he adds:</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=1012">00:16:52.400</a></span> | <span class="t">"Did not super see this coming."</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=1014">00:16:54.400</a></span> | <span class="t">And here is the paper released three days ago that improves upon that original prompt.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=1019">00:16:59.400</a></span> | <span class="t">They also did their testing zero-shot like me.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=1022">00:17:02.400</a></span> | <span class="t">And they tested many prompts.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=1024">00:17:04.400</a></span> | <span class="t">Starting like I did with just direct prompting.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=1026">00:17:06.400</a></span> | <span class="t">Just asking the question like 99% of users would do of GPT-4.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=1032">00:17:12.400</a></span> | <span class="t">And then they tried like me the well-established let's think step-by-step prompt.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=1037">00:17:17.400</a></span> | <span class="t">They also iteratively tested seven original prompts as well as the prompt that I've now integrated into SmartGPT.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=1043">00:17:23.400</a></span> | <span class="t">The let's work this out in a step-by-step way, etc.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=1046">00:17:26.400</a></span> | <span class="t">They share my opinion that zero-shot prompting setups have the benefit of not requiring such task-dependent selection of exemplars.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=1055">00:17:35.400</a></span> | <span class="t">You don't have to find correct examples.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=1057">00:17:37.400</a></span> | <span class="t">It just does it all for you.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=1059">00:17:39.400</a></span> | <span class="t">Here are the end results for GPT-4 that we saw earlier.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=1062">00:17:42.400</a></span> | <span class="t">Showing the difference between asking directly your question and using these refined prompts.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=1067">00:17:47.400</a></span> | <span class="t">Notice that this technique is somewhat model dependent and it doesn't have the same effect on smaller or weaker models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=1074">00:17:54.400</a></span> | <span class="t">Before we move on to the next paper, there is one somewhat failed prompt that I want to pick up on.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=1079">00:17:59.400</a></span> | <span class="t">It's this self-critique prompt where they ask:</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=1081">00:18:01.400</a></span> | <span class="t">"Answer the question then critique the answer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=1083">00:18:03.400</a></span> | <span class="t">Based on the critique,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=1084">00:18:04.400</a></span> | <span class="t">reconsider the other answer options and give a single final answer."</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=1088">00:18:08.400</a></span> | <span class="t">And you might wonder why didn't that prompt perform best when we know that reflection and dialogue can work.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=1094">00:18:14.400</a></span> | <span class="t">My theory is because it's trying to do all of it in one prompt.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=1098">00:18:18.400</a></span> | <span class="t">Through my hundreds of experiments, I've noticed that GPT-4 can only handle so much in one go.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=1104">00:18:24.400</a></span> | <span class="t">It simply gets overwhelmed or confused if you ask it to do too much in one prompt.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=1109">00:18:29.400</a></span> | <span class="t">That's why I broke my model into stages to allow it to show off each of its abilities</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=1113">00:18:33.400</a></span> | <span class="t">one by one.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=1115">00:18:35.400</a></span> | <span class="t">And before we get to the other papers,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=1116">00:18:36.400</a></span> | <span class="t">what's my personal theory as to why this eliminates up to half of the errors that GPT-4 makes?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=1122">00:18:42.400</a></span> | <span class="t">Well, my guess is this:</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=1124">00:18:44.400</a></span> | <span class="t">Remember that GPT-4 is drawing on a vast dataset of internet text.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=1129">00:18:49.400</a></span> | <span class="t">And let me ask you,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=1130">00:18:50.400</a></span> | <span class="t">what kind of text has things like:</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=1132">00:18:52.400</a></span> | <span class="t">Question,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=1133">00:18:53.400</a></span> | <span class="t">Answer,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=1134">00:18:54.400</a></span> | <span class="t">Let's work this out.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=1135">00:18:55.400</a></span> | <span class="t">Be sure we have the right answer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=1137">00:18:57.400</a></span> | <span class="t">The kind of data that would have that text would be things like:</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=1140">00:19:00.400</a></span> | <span class="t">Tutorials</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=1141">00:19:01.400</a></span> | <span class="t">or Expert Breakdowns.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=1142">00:19:02.400</a></span> | <span class="t">So I believe you're triggering more of the weights inside GPT-4 that relate to things like Expert Tutorials.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=1150">00:19:10.400</a></span> | <span class="t">And so inevitably you're getting slightly better answers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=1153">00:19:13.400</a></span> | <span class="t">Next, I've already explained why you get different outputs when you give the exact same prompt.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=1158">00:19:18.400</a></span> | <span class="t">That's down to sampling and the temperature of the model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=1161">00:19:21.400</a></span> | <span class="t">But to simplify massively, sometimes GPT-4 will give you an output that it knows isn't the most probable.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=1167">00:19:27.400</a></span> | <span class="t">It introduces some randomness into its sampling.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=1170">00:19:30.400</a></span> | <span class="t">By generating multiple outputs,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=1171">00:19:31.400</a></span> | <span class="t">you're getting a larger sample size,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=1173">00:19:33.400</a></span> | <span class="t">reflecting the full range of probabilities that GPT-4 ascribes to its outputs.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=1179">00:19:39.400</a></span> | <span class="t">You're reducing a little bit some of the randomness that's inherent in GPT-4 outputs.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=1184">00:19:44.400</a></span> | <span class="t">Next, I believe that GPT-4 can sometimes spot its own errors through reflection.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=1189">00:19:49.400</a></span> | <span class="t">Because prompting like this triggers a different set of weights.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=1193">00:19:53.400</a></span> | <span class="t">You could almost think of it as a different mindset.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=1195">00:19:55.400</a></span> | <span class="t">One more focused on finding errors.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=1198">00:19:58.400</a></span> | <span class="t">Again, if the question is too hard or involves counter-checking,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=1200">00:20:00.400</a></span> | <span class="t">characters, division, multiplication, as I said earlier,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=1203">00:20:03.400</a></span> | <span class="t">this won't help.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=1204">00:20:04.400</a></span> | <span class="t">But a percentage of the time, it can spot its own errors and point them out.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=1208">00:20:08.400</a></span> | <span class="t">Notice this is a separate bit of inference not lumped into the original prompt.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=1212">00:20:12.400</a></span> | <span class="t">And when it does successfully point out the errors,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=1215">00:20:15.400</a></span> | <span class="t">it can often engage in this dialogue with itself.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=1218">00:20:18.400</a></span> | <span class="t">Notice in a meta kind of way, I'm using the step-by-step prompting to improve the reflection and dialogue.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=1225">00:20:25.400</a></span> | <span class="t">So those are my theories as to why it works.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=1227">00:20:27.400</a></span> | <span class="t">But at the end of the video,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=1228">00:20:28.400</a></span> | <span class="t">I'm going to show you at least five ways,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=1229">00:20:29.400</a></span> | <span class="t">I think the model can be further refined.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=1232">00:20:32.400</a></span> | <span class="t">Before we do though,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=1233">00:20:33.400</a></span> | <span class="t">I looked up the paper by Zhou,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=1235">00:20:35.400</a></span> | <span class="t">which produced that prompt that did the best in the previous paper.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=1239">00:20:39.400</a></span> | <span class="t">They came to that special prompt through automatic prompt engineering.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=1243">00:20:43.400</a></span> | <span class="t">But there's something interesting I want to point out though.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=1245">00:20:45.400</a></span> | <span class="t">On page seven, they say,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=1246">00:20:46.400</a></span> | <span class="t">we use automatic prompt engineering to find a prompt starting with lets,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=1251">00:20:51.400</a></span> | <span class="t">that maximizes the likelihood of correct reasoning steps.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=1255">00:20:55.400</a></span> | <span class="t">Then they found the best one that I integrated into SmartGPT,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=1258">00:20:58.400</a></span> | <span class="t">let's work this out in a step-by-step way to be sure we have the right answer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=1261">00:21:01.400</a></span> | <span class="t">That's the one I want you to use.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=1263">00:21:03.400</a></span> | <span class="t">And they ran their own benchmarks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=1265">00:21:05.400</a></span> | <span class="t">And of course it did improve the scores.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=1267">00:21:07.400</a></span> | <span class="t">But the interesting thing to me is they started with lets each time.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=1271">00:21:11.400</a></span> | <span class="t">So even that first stage for the model might not yet be fully optimized.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=1275">00:21:15.400</a></span> | <span class="t">Maybe there's a prompt that doesn't begin with lets that improves this initial result still further.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=1281">00:21:21.400</a></span> | <span class="t">Anyway, back to the papers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=1282">00:21:22.400</a></span> | <span class="t">I know many people watching this will wonder if I read the paper boosting theory of mind performance in the future.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=1287">00:21:27.400</a></span> | <span class="t">So I did a theory of mind performance in large language models via prompting.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=1290">00:21:30.400</a></span> | <span class="t">And yes, I did because they tested something similar for a theory of mind test.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=1294">00:21:34.400</a></span> | <span class="t">Using similar techniques, they were able to get theory of mind accuracy for GPT-4 from 80% to 100%.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=1301">00:21:41.400</a></span> | <span class="t">And they conclude that these results demonstrate that appropriate prompting enhances large language model theory of mind reasoning.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=1308">00:21:48.400</a></span> | <span class="t">And they underscore the context dependent nature of these models' cognitive capacities.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=1314">00:21:54.400</a></span> | <span class="t">They used that original prompt,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=1316">00:21:56.400</a></span> | <span class="t">and they used the same formula for the first two examples.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=1319">00:21:59.400</a></span> | <span class="t">So they did improve the results dramatically.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=1321">00:22:01.400</a></span> | <span class="t">And as I theorized earlier,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=1323">00:22:03.400</a></span> | <span class="t">adding few shot examples would push this still further.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=1326">00:22:06.400</a></span> | <span class="t">This is part of why I think that 95% barrier on the MMLU will be broken probably this year by GPT-4.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=1332">00:22:12.400</a></span> | <span class="t">A few other points from this paper.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=1334">00:22:14.400</a></span> | <span class="t">They admit that there is not currently a theoretical understanding of why these prompting methods are so important.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=1340">00:22:20.400</a></span> | <span class="t">And they also say that the results of the MMLU are not the same as the results of the GPT-4.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=1345">00:22:25.400</a></span> | <span class="t">So they are not sure why these prompting techniques are beneficial.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=1348">00:22:28.400</a></span> | <span class="t">I've given you my theory and Karpathy's,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=1350">00:22:30.400</a></span> | <span class="t">but no one quite knows for sure.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=1352">00:22:32.400</a></span> | <span class="t">Lastly from this paper,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=1353">00:22:33.400</a></span> | <span class="t">and I found this really interesting.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=1355">00:22:35.400</a></span> | <span class="t">Giving it generic few shot prompts that weren't directly theory of mind,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=1359">00:22:39.400</a></span> | <span class="t">actually improved the outputs slightly more than giving it direct theory of mind examples.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=1365">00:22:45.400</a></span> | <span class="t">This opens the door to the first of the five ways I anticipate smart GPT getting even smarter.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=1371">00:22:51.400</a></span> | <span class="t">It could be possible to come up with generic few shot prompts</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=1374">00:22:54.400</a></span> | <span class="t">that could be automatically integrated into the model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=1377">00:22:57.400</a></span> | <span class="t">that don't necessarily relate to the topic at hand.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=1380">00:23:00.400</a></span> | <span class="t">This graph shows the impact of adding few shot examples to GPT-3.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=1384">00:23:04.400</a></span> | <span class="t">And if this can be done in a generic way for GPT-4,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=1388">00:23:08.400</a></span> | <span class="t">results could be improved still further.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=1390">00:23:10.400</a></span> | <span class="t">Next, the boosting theory of mind paper speculates</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=1394">00:23:14.400</a></span> | <span class="t">that integrating some of these approaches</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=1396">00:23:16.400</a></span> | <span class="t">could boost the performance of weaker models to beyond the levels of GPT-4 zero shot accuracy.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=1403">00:23:23.400</a></span> | <span class="t">Next, here is the original DERA paper</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=1405">00:23:25.400</a></span> | <span class="t">that inspired me to have the researcher and resolver dialogue at the end of smart GPT.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=1410">00:23:30.400</a></span> | <span class="t">As they say, the DERA approach shows significant improvement over base GPT-4 performance.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=1416">00:23:36.400</a></span> | <span class="t">And these were open-ended questions by the way, not multiple choice.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=1419">00:23:39.400</a></span> | <span class="t">So this is more generally applicable than you might think.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=1422">00:23:42.400</a></span> | <span class="t">You can see from this table how results improved after engaging in this dialogue.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=1427">00:23:47.400</a></span> | <span class="t">And that brings me to the second way I anticipate smart GPT getting smarter in the future.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=1432">00:23:52.400</a></span> | <span class="t">A longer and more rich dialogue.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=1434">00:23:54.400</a></span> | <span class="t">At the moment we have this simple researcher and resolver, two-step dialogue.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=1439">00:23:59.400</a></span> | <span class="t">But I can imagine a council of advisors.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=1442">00:24:02.400</a></span> | <span class="t">You can imagine a mathematician chipping in, and a philosopher, and a professor.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=1446">00:24:06.400</a></span> | <span class="t">Each one tapping into slightly different weights of GPT-4.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=1450">00:24:10.400</a></span> | <span class="t">Extracting more hidden expertise.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=1453">00:24:13.400</a></span> | <span class="t">I'm not saying that would transform the results, but it might edge them another few percent higher.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=1458">00:24:18.400</a></span> | <span class="t">Next, even with longer dialogues and different experts,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=1461">00:24:21.400</a></span> | <span class="t">we could find ways of optimizing these prompts,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=1464">00:24:24.400</a></span> | <span class="t">just like we did with the original "Let's think step by step".</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=1467">00:24:27.400</a></span> | <span class="t">That's the third avenue of improvement that I envisage.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=1469">00:24:29.400</a></span> | <span class="t">Because I came up with these prompts, I'm sure they could be improved.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=1472">00:24:32.400</a></span> | <span class="t">Next, we could experiment with different temperatures.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=1475">00:24:35.400</a></span> | <span class="t">Remember, a lower temperature makes the model more conservative.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=1478">00:24:38.400</a></span> | <span class="t">A higher one, towards one, makes it more creative.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=1481">00:24:41.400</a></span> | <span class="t">We could experiment with a higher temperature to produce a more diverse range of outputs at this stage.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=1487">00:24:47.400</a></span> | <span class="t">And then perhaps a more conservative, deterministic temperature,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=1490">00:24:50.400</a></span> | <span class="t">for the final judge or resolver.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=1493">00:24:53.400</a></span> | <span class="t">It might not work, but it's worth trying.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=1495">00:24:55.400</a></span> | <span class="t">And the fifth improvement I know would work.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=1498">00:24:58.400</a></span> | <span class="t">Integrating APIs for character counting, calculators, code interpreters, etc.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=1503">00:25:03.400</a></span> | <span class="t">Spending these weeks manually sorting through the outputs of GPT-4 on these benchmarks,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=1508">00:25:08.400</a></span> | <span class="t">I can really see where it goes wrong.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=1511">00:25:11.400</a></span> | <span class="t">And it's often by getting letters in the wrong order,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=1514">00:25:14.400</a></span> | <span class="t">or making mistakes with division.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=1516">00:25:16.400</a></span> | <span class="t">It gets the high level logic right, and then makes quite simple errors.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=1519">00:25:19.400</a></span> | <span class="t">Basic tool integration would, I am sure, push the results still higher.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=1523">00:25:23.400</a></span> | <span class="t">Now I know this isn't my usual video, and trust me, I have been following the AI news,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=1528">00:25:28.400</a></span> | <span class="t">and we'll get back to that very soon.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=1530">00:25:30.400</a></span> | <span class="t">I'm determined to make those improvements and push SmartGPT even further,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=1534">00:25:34.400</a></span> | <span class="t">but of course that would be aided massively by getting access to the plugins and the GPT-4 API key.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=1541">00:25:41.400</a></span> | <span class="t">So far I've had to do all of this manually, which was a lot of work.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=1545">00:25:45.400</a></span> | <span class="t">Now as you saw earlier, I have drawn on GPT-4 to help me develop a project.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=1548">00:25:48.400</a></span> | <span class="t">I'm also working on a program in Replit to automate this process,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=1551">00:25:51.400</a></span> | <span class="t">but at the moment it's GPT-3.5, and honestly the context window really limits the ability.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=1557">00:25:57.400</a></span> | <span class="t">But I do look forward to the day when I can integrate GPT-4,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=1560">00:26:00.400</a></span> | <span class="t">and put this out as an automatic model for people to test and play about with.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=1565">00:26:05.400</a></span> | <span class="t">I am sure that something similar will ultimately be incorporated by OpenAI itself,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=1569">00:26:09.400</a></span> | <span class="t">maybe as a thoughtful mode, or smart mode,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=1572">00:26:12.400</a></span> | <span class="t">a bit like Bing has creative, precise, balanced, etc.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=1576">00:26:16.400</a></span> | <span class="t">Each response does take longer,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=1577">00:26:17.400</a></span> | <span class="t">but as you've seen the outputs are noticeably better.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=1580">00:26:20.400</a></span> | <span class="t">If the results of models like this one do officially exceed the 86.4%</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=1586">00:26:26.400</a></span> | <span class="t">that OpenAI talked about in the GPT-4 technical report,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=1590">00:26:30.400</a></span> | <span class="t">I do think that would reveal quite a few things.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=1592">00:26:32.400</a></span> | <span class="t">First, that OpenAI isn't even aware of the full capabilities of its own model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=1597">00:26:37.400</a></span> | <span class="t">I don't even know if they anticipated things like AutoGPT.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=1600">00:26:40.400</a></span> | <span class="t">I do think it would reveal that they need to do far more proper testing of their models before they release them.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=1606">00:26:46.400</a></span> | <span class="t">They should make falsifiable predictions about what their models won't be capable of.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=1611">00:26:51.400</a></span> | <span class="t">That way we would know just how much they know about their own models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=1615">00:26:55.400</a></span> | <span class="t">What we're trying to avoid is a situation where OpenAI say their model can only achieve X,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=1620">00:27:00.400</a></span> | <span class="t">and then when they release the model in the wild,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=1622">00:27:02.400</a></span> | <span class="t">someone comes along and achieves Y,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=1624">00:27:04.400</a></span> | <span class="t">where Y is much more impactful than X.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=1626">00:27:06.400</a></span> | <span class="t">So those were the goals of this video.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=1628">00:27:08.400</a></span> | <span class="t">To show you how to get more out of GPT-4,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=1631">00:27:11.400</a></span> | <span class="t">to run you through some of the fascinating papers that have been released in the last few days and weeks,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=1635">00:27:15.400</a></span> | <span class="t">the third goal was to show you what this model could do with some official benchmarks,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=1639">00:27:19.400</a></span> | <span class="t">and suggest ways it might get better in the near term future.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=1643">00:27:23.400</a></span> | <span class="t">Of course, if you have a GPT-4 API key,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=1645">00:27:25.400</a></span> | <span class="t">or are an expert in benchmarking systems like GPT-4,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=1648">00:27:28.400</a></span> | <span class="t">I'd love to hear from you.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=1650">00:27:30.400</a></span> | <span class="t">I guess the final goal was to perhaps suggest to you that OpenAI don't know as much about their own models</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=1655">00:27:35.400</a></span> | <span class="t">as they might lead you to believe.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=1657">00:27:37.400</a></span> | <span class="t">Thank you so much for watching to the end,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wVzuvf9D9BU&t=1659">00:27:39.400</a></span> | <span class="t">and have a wonderful day.</span></div></div></body></html>