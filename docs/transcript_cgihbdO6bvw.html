<html><head><title>8 Ways ChatGPT 4 [Is] Better Than ChatGPT</title></head><body><a href="index.html">back to index</a><h2>8 Ways ChatGPT 4 [Is] Better Than ChatGPT</h2><a href="https://www.youtube.com/watch?v=cgihbdO6bvw"><img src="https://i.ytimg.com/vi_webp/cgihbdO6bvw/maxresdefault.webp" style="width:50%;"></a><div><br></div><h3>Chapters</h3><a href="https://www.youtube.com/watch?v=cgihbdO6bvw&t=0">0:0</a> <Untitled Chapter 1><br><a href="https://www.youtube.com/watch?v=cgihbdO6bvw&t=123">2:3</a> Logical Reasoning<br><a href="https://www.youtube.com/watch?v=cgihbdO6bvw&t=262">4:22</a> Jokes<br><a href="https://www.youtube.com/watch?v=cgihbdO6bvw&t=326">5:26</a> Physics<br><a href="https://www.youtube.com/watch?v=cgihbdO6bvw&t=388">6:28</a> Quick Math<br><a href="https://www.youtube.com/watch?v=cgihbdO6bvw&t=577">9:37</a> Reading Comprehension<br><a href="https://www.youtube.com/watch?v=cgihbdO6bvw&t=643">10:43</a> Coding<br><a href="https://www.youtube.com/watch?v=cgihbdO6bvw&t=692">11:32</a> Speed of Output<br><div style="text-align: left;"><a href="./cgihbdO6bvw.html">Whisper Transcript</a> | <a href="./transcript_cgihbdO6bvw.html">Transcript Only Page</a></div><br><h3>Transcript</h3><div style="max-width: 600px;"><p>I would not blame you if you thought that all talk about GPT-4 or ChatGPT-4 is just that, talk. But we actually can have a surprising amount of confidence in the ways in which GPT-4 will improve on ChatGPT. By examining publicly accessible benchmarks, comparable large language models like Palm, and the latest research papers, which I've spent dozens of hours reading, we can discern at least eight clear ways in which GPT-4, integrated into Bing or otherwise, will beat ChatGPT. I'm going to show you how unreleased models already beat current ChatGPT. And all of this will give us a clearer insight into what even GPT-5 and future rival models from Google might well soon be able to achieve. There are numerous benchmarks that Palm, Google's large language model, and by extension, Google's large language model, will be able to achieve. And by extension, GPT-4 will beat ChatGPT on. But the largest and most impressive is the big bench set of tasks. More than 150 or now 200 language modeling tasks, and I've studied almost all of them. And you can see the approximate current state of affairs summarized in this graph, where the latest models are now beating the average human and showing dramatic improvement on previous models. ChatGPT would be somewhere around this point. Lower than what is actually... privately available, but better than previous models down here. But this just skims the surface. I want to show you in detail the eight ways that you can expect ChatGPT-4 or GPT-4 to beat the current ChatGPT. And no, that's not just because it's going to have more parameters off to the right of this graph, 10 to the 12, a trillion parameters. It's also because compute efficiency will improve. Chain of thought prompting will be integrated, and the number of tokens it's trained on might go up by an awful lot. This is a very important aspect of ChatGPT-4. And it's also very important to know that the output of your data will go up by an order of magnitude. Lots of reasons why GPT-4 will be better. Let's start with logic and logical inference. This example comes from Google's Palm Research paper. The question or input was this. Shelley is from Virginia, but is visiting that city with that famous market where they throw the fish. So vague. Going home next Tuesday. Question, is it likely that Shelley will be near the Pacific Ocean this weekend? And you can see how the improved model is able to deduce that the improved model is likely to be near the Pacific Ocean. And you can see how the improved model is able to deduce that the improved model is likely to be near the Pacific Ocean. And you can see how the improved model is able to deduce that the improved model is likely to be near the Pacific Ocean. And you can see how the improved model is able to deduce that the improved model is likely to be near the Pacific Ocean. And you can see how the improved model is likely to be near the Pacific Ocean. And you can see how the improved model is likely to be near the Pacific Ocean. Whereas if you ask current ChatGPT this question, what you get is, based on the information given, it's not possible to determine. Whereas if you ask current ChatGPT this question, what you get is, based on the information given, it's not possible to determine. Whereas if you ask current ChatGPT this question, what you get is, based on the information given, it's not possible to determine. The statement only mentions that Shelley is from Virginia and visiting a city with a famous market. The statement only mentions that Shelley is from Virginia and visiting a city with a famous market. The statement only mentions that Shelley is from Virginia and visiting a city with a famous market. It really can't handle it. It can't do that level of logical inference. It really can't handle it. It can't do that level of logical inference. Here is another great example. This test of critical reasoning and logic was designed again for the Big Bench benchmark. This test of critical reasoning and logic was designed again for the Big Bench benchmark. This test of critical reasoning and logic was designed again for the Big Bench benchmark. And it was tested on different language models. And most of them fail, including ChatGPT. And most of them fail, including ChatGPT. I gave it this question and it picked the wrong answer. I gave it this question and it picked the wrong answer. You can examine the question yourself, but C is not the correct answer. You can examine the question yourself, but C is not the correct answer. It gets it wrong. However, let's take a look at the graph beneath at other language models. However, let's take a look at the graph beneath at other language models. Ones to come. GPT-4 maybe. And look what happens. As the models increase in effective parameter count and other things like token size, As the models increase in effective parameter count and other things like token size, As the models increase in effective parameter count and other things like token size, look at the performance. We start to beat not only average raters but all previous models We start to beat not only average raters but all previous models and approximate the performance of the best human language. and approximate the performance of the best human language. and approximate the performance of the best human language. The top line is the best human rater. The blue line is the average human rater. These unreleased models, The three shot means it was given three examples of what was expected before being tested. The three shot means it was given three examples of what was expected before being tested. The three shot means it was given three examples of what was expected before being tested. These best models, and you can imagine GPT-4 would be around the same level, These best models, and you can imagine GPT-4 would be around the same level, crush what ChatGPT was capable of. crush what ChatGPT was capable of. You can imagine what this means in terms of GPT-4 giving more rigorous arguments. You can imagine what this means in terms of GPT-4 giving more rigorous arguments. You can imagine what this means in terms of GPT-4 giving more rigorous arguments. Or conversely, you can give vague inputs Or conversely, you can give vague inputs like this thing talking about a famous market where they throw the fish. like this thing talking about a famous market where they throw the fish. And GPT-4 might well be able to understand exactly what you mean. And GPT-4 might well be able to understand exactly what you mean. And to be honest, if you thought that's interesting, we are just getting started. Next, jokes. On the left you can see a computer science-y type of joke On the left you can see a computer science-y type of joke that it was able to explain. But I tested ChatGPT on a variety of jokes and some of them it could explain, others it couldn't. Let me show you what I mean. Here was the joke that I asked it to explain. One of the oddities of Wall Street is that it is the dealer and not the customer who is called "broker". The play on words being that the customer might well end up being "broke". The play on words being that the customer might well end up being "broke". It didn't really understand that wordplay and got it wrong. I don't think it got that "broke" was different from "broker". It couldn't separate off that word inside "broker". Now, it did get this second joke right and explain it well. This shows us why it's so important what GPT-4 might be capable of. As the Google paper showed, as the model improves, it does get better at explaining jokes and therefore, presumably, at telling them. Those comedy sketches that people are generating now with ChatGPT, they are about to get many times better. Think wordplays, puns, innuendos, all sorts. The next example comes from physics. Look at how the latest models, and by implication GPT-4, are answering basic questions in physics and teaching them. You can see how palm far exceeds GPT. And also, as you can see, beats the average human and is getting closer to the best human. But what kind of questions are we talking about? I looked into the research methodology for this big benchmark and I took some of the questions and tested them on ChatGPT. It couldn't get them. I asked them and both of them got wrong. But that's what might change with GPT-4. We're talking high school and beyond physics, you can imagine chemistry, biology, starting to get questions more and more right and therefore be able to explain them better and better. Now I won't pause for a physics lesson but you can see how ChatGPT fails by pausing the video if you want. But GPT-4 probably won't fail. Next is math. Here are a bunch of examples that Google produced in the research paper about the improvements that its current model can do on release to the public but that something like GPT would really struggle at. And you don't need me to show you ChatGPT failing at these because it's quite notoriously bad at math. These are quite nuanced questions though. How many keystrokes are needed to type the numbers from 1 to 500? Yes, ChatGPT fails. What about a word problem? Roger has 5 tennis balls. He buys 2 more cans of tennis balls. Each can has 3 tennis balls. What kind of balls does he now have? This uses something called chain of thought prompting which I'll talk about a bit later but either way it gets the answer right whereas previous models get it wrong. You don't need me to help you imagine the kind of implications that a GPT better at math would be for the world. Just think about finance assistants or math tutors available in your pocket. Before we move on to improvement number 5 please do leave a like and a comment if you're learning anything from this video. I really did put dozens of hours into reading academic papers to give you really clear examples of each improvement. For the 5th improvement I'm going to merge 2 benchmarks together. The first one is called implicatures quite hard to pronounce. It's one of those situations where people reply yes but don't use the word yes they say something like "Is the Pope a Catholic?" or "Is rain wet?" and the large language models struggle to interpret that as a yes. To give you an example look down here at my final interaction "Are the androids deployed?" Speaker 1 says. Speaker 2 "What do you think?" which most humans would interpret as "Yes of course, why are you asking?" and yet when I ask "Has speaker 2 likely confirmed or likely denied the deployment of androids or can we not tell?" ChatGPT says it's not clear where to most humans would be clear. However, as you might have guessed look at the improvements being made behind the scenes. As the parameter count goes up the number of tokens go up look at the graph. Suddenly, Palm can actually understand better than the average human whether a yes or no is being said approaching the performance of the best human. Leaving the original ChatGPT behind and showcasing how GPT-4 might be a massive improvement in the future. The next question I wanted to ask was about "Do we have sufficient information?" In other words, how about we just say "Don't know" if we don't know the answer or if you can't answer the question. Something like "How much water is in a cup with height of 10cm?" You can't answer that question. It depends on many factors the thickness, the radius and some models would hallucinate or let's say bullcrap their way into the chat. The sixth improvement will be in reading comprehension. That is understanding digesting, analyzing comprehending essentially large or long passages of text. You can just imagine the implications of this. Summarizing earning calls or transcribing and summarizing YouTube videos automatically. Condensing information down to a paragraph which might have been pages and pages of chapters. I think this graph is particularly stunning. How the latest models are now getting close to the performance of the best humans at understanding text. How long will it be until they can read Dostoevsky and summarize it in a thought out paragraph? ChatGPT definitely can't do this. Give it a reading comprehension question and it gets it wrong almost every time. In fact, quite hilariously when I gave it one question it picked the wrong answer and neglected both correct answers. But, GPT-4 with 99.9% certainty will be a lot better at doing that. The next big improvement will be in coding. I'm no expert but reading through the paper you can see significant improvements in capability. If we scroll down you can see that the improved model could compile at a rate of 82% versus the previous state of the art of 81.7%. And GPT-4 might be even an improvement on this. Of course, many of you may have read media reports of OpenAI drafting in hundreds of programmers to help it fine tune its code. Definitely there should be a real step change in its ability to code successfully. And as it says down here, opening up opportunities to fix more complex errors that arise during software development. The next big inevitable improvement that GPT-4 will bring will just be general efficiency and speed. Google Muse has demonstrated with text to image that the same process can be done 10 times faster with a bit more efficiency. And compute power is increasing all the time. These models were trained on A100 GPUs but H100 GPUs are already available from Nvidia. And model efficiency is improving over time. So just imagine this. Imagine what previously took 10 seconds to generate, which is still incredibly fast, now taking 1 second. Instant responses from GPT-4. Now it might not be 1 second, it might be 3 or 4, but it's going to be faster. And one iteration down the road, GPT-5, might be instantaneous. I have detailed quite a few areas where GPT-4 is very likely to improve on ChatGPT. But there are quite a few areas in which it will very likely still struggle. One is advanced math. Mathematical induction. Even the latest models really struggle. This area called navigation is an example where it will say something like if you move forward 3 steps, turn right go 3 steps, turn right again 90 degrees, go 3 steps. That kind of thing. Do you arrive back at the start? These models really struggle with that. But the final area that I find quite amusing and it comes from Winograd schema. As detailed in this other academic paper called Superglue. Which is kind of a rival benchmark to the Big Bench. And a Winograd schema is a situation in which we have an ambiguous pronoun like he, it or they. And the model has to predict not only who or what the pronoun is referring to but also why would it be that thing. And it really struggles these models and I'll show you the graph in a second. In fact here it is. Even the latest models struggle I think because it involves some common sense about the world and the universe that it just doesn't have. Let me show you ChatGPT failing at this task. Feel free to try this one yourself. Tom threw his school bag down to Ray after he reached the bottom of the stairs. Who reached the bottom of the stairs? Now it makes sense that it would be Ray. Because logically you can think of real life you're throwing it down the stairs like here take it before you go out. Whereas the model says Tom reached the bottom of the stairs. Wait why would he be throwing his school bag down if he's at the bottom of the stairs? So that's an example of an area in which ChatGPT fails and GPT-4 will also likely fail. And the why bit in the title is the fact that it will not only fail but not really be able to explain even when it succeeds why the pronoun is referring to the noun that it does. I find that really interesting like the merging of language and common sense. These large language models fundamentally don't have a model of the universe as I talked about in one of my other videos. It's the main critique that Jan LeCun has actually about large language models. This graph by the way gives a beautiful summary of what I think is the approximate current state of the art. So GPT-4 comparable to palm and how it does versus the average human. On the left all the different tasks part of the 150 big bench tasks that it can do better than humans and on the right those that it does worse than humans. So you can see a roughly even split but remember this is versus the average human not versus the best human. The link to all of these papers will be in the description if you want to check out the full list of tasks that it does better versus what it does worse at. I've actually scrolled through almost every single one of them and analyzed it. It's really interesting to do actually. All these different challenges that independent humans have come up with in order to test just how far language models are progressing. A very interesting endeavor that they're putting together. All the way from verbs to Python. As I draw to the end here I want to give you my two main conclusions. I think GPT-4 for commercial reasons and others will be yes a huge step up from ChatGPT but won't be game breaking. What I mean by that is we're talking better than the average human at quite a few tasks maybe half of those measured but still lagging behind the best human in almost every task. Roughly high school levels of achievement. So yes as I quoted Sam Altman saying in my previous video, Hype vs Reality ChatGPT-4. Yes it's going to be disappointing to those people expecting AGI. However what's coming down the road in the short to medium term it's hard to put an exact date but are we talking 2, 3, 4, 5 years? Somewhere in that range. The models that are coming are going to be pretty impressive/ overwhelming. That's not just by the way because the number of parameters are improving. As this abstract from DeepMind put it, it's not just about improving the number of parameters. It's also about using more data. 4 times more data. Palm by the way used 780 billion tokens. But there are up to 17 trillion tokens available on the internet. So roughly in order of magnitude more tokens, more data that these models can train on. And the number of parameters if they're increased in alignment would also go up by an order of magnitude. Not just that but the compute available to big tech like Google and Microsoft is increasing all the time. I hinted at the H100 GPUs but even just scaling up in size and compute efficiency should yield incredible improvements. There is also a whole academic paper on how chain of thought prompting, basically getting the models to break down and show they're working out really improves results. And I've seen that myself with ChatGPT. If you ask it to explain its steps it often gets to a right answer whereas previously it got to a wrong answer. So it's not just about compute and parameters and data. It's also refinements to the models themselves. Of course other improvements around the corner are a diversity of data inputs. Could be video, could be photos, could be audio from the microphone and these can be assimilated into the model so you can ask questions like "Will these boots be usable to hike Mount Fuji?" And this is an example from Google. That might not necessarily be in GPT-4 but it's coming and Google might be the one pioneering these diversity of data inputs. As the eerily powerful conclusion from this Google post put it, the vision that they have is to enable a single AI system to generalize across thousands or millions of tasks as we've seen to understand different types of data: photos, videos, audio, text and to do so with remarkable efficiency and speed. But this video wasn't designed to scare you. It was designed to show you the tangible ways in which GPT-4 and rival models from Google will improve on ChatGPT so you can be prepared. I genuinely do believe that the knowledge economy is about to be upended and the better prepared we can be the better for all of us. And I really hope this video has contributed to that. If you feel it has please do leave a like, leave a comment. I read them all. Much appreciated. See you soon.</p></div></body></html>