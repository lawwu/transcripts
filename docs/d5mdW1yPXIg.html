<html><head><title>AI Conquers Gravity: Robo-dog, Trained by GPT-4, Stays Balanced on Rolling, Deflating Yoga Ball</title>
<style>
    body {
        font-family: Arial, sans-serif;
        margin: 0;
        padding: 0;
        background-color: #f4f4f4;
        color: #333;
    }
    .container {
        width: 95%;  /* Increased width to use more space */
        margin: auto;
        overflow: auto;  /* Added to handle overflow by adding a scrollbar if necessary */
    }
    h2, h3 {
        color: #333;
        text-align: center;
    }
    a {
        color: #0000FF;  /* Traditional blue color for links */
        text-decoration: none;
    }
    a:hover {
        text-decoration: underline;
    }
    img {
        display: block;
        margin: auto;
        max-width: 100%;
    }
    .c {
        margin: 10px 0;
    }
    .s, .t {
        display: inline-block;
        margin-right: 5px;
    }
    .max-width {
        max-width: 800px;
        margin: auto;
        padding-left: 20px;
    }
    table {
        width: 100%;
        border-collapse: collapse;
    }
    th, td {
        border: 1px solid #ddd;
        padding: 8px;
        text-align: left;  /* Ensure text alignment is consistent */
    }
    tr:nth-child(even) {
        background-color: #f2f2f2;
    }
    tr:nth-child(odd) {
        background-color: #e6e6e6;
    }
</style>

    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-69VLBMTTP0"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-69VLBMTTP0');
    </script>
    </head><body><div class='container'><a href="index.html">back to index</a><h2>AI Conquers Gravity: Robo-dog, Trained by GPT-4, Stays Balanced on Rolling, Deflating Yoga Ball</h2><a href="https://www.youtube.com/watch?v=d5mdW1yPXIg"><img src="https://i.ytimg.com/vi/d5mdW1yPXIg/maxresdefault.jpg" style="width:50%;"></a><div><br></div><div style="text-align: left;"><a href="./d5mdW1yPXIg.html">Whisper Transcript</a> | <a href="./transcript_d5mdW1yPXIg.html">Transcript Only Page</a></div><br><div style="max-width: 800px;"><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=d5mdW1yPXIg&t=0" target="_blank">00:00:00.000</a></span> | <span class="t">If GPT-4 can train a robodog better than we can to balance on a rolling yoga ball that's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=d5mdW1yPXIg&t=8" target="_blank">00:00:08.360</a></span> | <span class="t">being kicked or deflated, what's next? Are we sure that changing a lightbulb or fixing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=d5mdW1yPXIg&t=14" target="_blank">00:00:14.800</a></span> | <span class="t">a plumbing leak is much more physically complex? And if it's a 2022 era language model, GPT-4,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=d5mdW1yPXIg&t=23" target="_blank">00:00:23.640</a></span> | <span class="t">that is doing the teaching, what does that say about the learning rates of robots taught</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=d5mdW1yPXIg&t=28" target="_blank">00:00:28.280</a></span> | <span class="t">by even 2024 era AI? This Dr. Eureka paper was released less than 48 hours ago, but I'll</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=d5mdW1yPXIg&t=36" target="_blank">00:00:36.720</a></span> | <span class="t">give you all the highlights and interview clips with two key figures behind the Eureka</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=d5mdW1yPXIg&t=42" target="_blank">00:00:42.140</a></span> | <span class="t">concept, Jim Fan and Guangzhe Wang. But first, what is the overall concept? What are they</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=d5mdW1yPXIg&t=48" target="_blank">00:00:48.240</a></span> | <span class="t">basically doing? They want to train a robot, in this case a quadruped robodog, in simulation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=d5mdW1yPXIg&t=54" target="_blank">00:00:54.920</a></span> | <span class="t">and see if they can transfer that to the real world. That's the sim to real part from simulation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=d5mdW1yPXIg&t=60" target="_blank">00:01:00.880</a></span> | <span class="t">to reality. And they want to use a language model, in this case GPT-4, to guide that process.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=d5mdW1yPXIg&t=67" target="_blank">00:01:07.360</a></span> | <span class="t">And why would it be helpful to use a language model? Well, if you have to go in as a human</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=d5mdW1yPXIg&t=72" target="_blank">00:01:12.760</a></span> | <span class="t">and tweak all the different parameters, which we'll see in a moment, that takes ages. As</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=d5mdW1yPXIg&t=78" target="_blank">00:01:18.160</a></span> | <span class="t">the paper says, that renders the process slow and human labor intensive. But this paper</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=d5mdW1yPXIg&t=83" target="_blank">00:01:23.840</a></span> | <span class="t">isn't just about saving time. The language model derived reward functions perform better</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=d5mdW1yPXIg&t=89" target="_blank">00:01:29.440</a></span> | <span class="t">than the human ones. In short, language models like GPT-4 are better teachers for robots.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=d5mdW1yPXIg&t=95" target="_blank">00:01:35.740</a></span> | <span class="t">So why do I think this is so much more significant than yoga balls? Language models like ChatGPT</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=d5mdW1yPXIg&t=102" target="_blank">00:01:42.360</a></span> | <span class="t">are brilliant at generating hypotheses, generating ideas, as the paper says. But as we all know,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=d5mdW1yPXIg&t=108" target="_blank">00:01:48.960</a></span> | <span class="t">their great Achilles heel is hallucinations or confabulations, making stuff up, making</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=d5mdW1yPXIg&t=114" target="_blank">00:01:54.280</a></span> | <span class="t">mistakes. But if those ideas, even tens of thousands of them, can be tested in simulation,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=d5mdW1yPXIg&t=119" target="_blank">00:01:59.700</a></span> | <span class="t">we can find just the good ones. Thankfully, language models are infinitely patient. And</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=d5mdW1yPXIg&t=124" target="_blank">00:02:04.800</a></span> | <span class="t">so what we end up with are better implementations, in this case for robot training, than humans</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=d5mdW1yPXIg&t=130" target="_blank">00:02:10.400</a></span> | <span class="t">can produce. And crucially, as the paper points out, this works for novel or new robot tasks,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=d5mdW1yPXIg&t=136" target="_blank">00:02:16.960</a></span> | <span class="t">ones not seen in the training data of the language model. And this approach isn't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=d5mdW1yPXIg&t=141" target="_blank">00:02:21.480</a></span> | <span class="t">just effective for new tasks, but for novel situations within existing tasks. We'll</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=d5mdW1yPXIg&t=147" target="_blank">00:02:27.320</a></span> | <span class="t">see how all of this is done in a moment, but here is the GPT-4 trained robo-dog reacting</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=d5mdW1yPXIg&t=152" target="_blank">00:02:32.120</a></span> | <span class="t">to the yoga ball being deflated. It overcomes that situation, despite not seeing that in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=d5mdW1yPXIg&t=158" target="_blank">00:02:38.400</a></span> | <span class="t">training. Before we get back to the paper, though, let's reiterate something in the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=d5mdW1yPXIg&t=161" target="_blank">00:02:41.440</a></span> | <span class="t">words of Dr. Jim Fan. Once derived in simulation, this policy is transferred zero shot to the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=d5mdW1yPXIg&t=168" target="_blank">00:02:48.240</a></span> | <span class="t">real world. Or translated, it's not relying on human demonstrations. The robo-dog doesn't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=d5mdW1yPXIg&t=173" target="_blank">00:02:53.520</a></span> | <span class="t">have to see a human or another robo-dog balancing on a yoga ball. No fine tuning, it just works.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=d5mdW1yPXIg&t=180" target="_blank">00:03:00.320</a></span> | <span class="t">Not every single time, admittedly, but we'll get to the blooper reel later on. I will need</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=d5mdW1yPXIg&t=186" target="_blank">00:03:06.260</a></span> | <span class="t">to give you a minute of background on the Eureka paper, which came out in October of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=d5mdW1yPXIg&t=191" target="_blank">00:03:11.640</a></span> | <span class="t">last year, before we can get to Dr. Eureka. And let me try to summarize the paper in less</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=d5mdW1yPXIg&t=197" target="_blank">00:03:17.360</a></span> | <span class="t">than 60 seconds. A reward function is a way of specifying, in code, how to measure success</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=d5mdW1yPXIg&t=203" target="_blank">00:03:23.880</a></span> | <span class="t">in a task. And language models are great at coming up with them and modifying them based</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=d5mdW1yPXIg&t=209" target="_blank">00:03:29.720</a></span> | <span class="t">on environmental feedback. So the NVIDIA team proposed a task, in this case spinning a pen</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=d5mdW1yPXIg&t=215" target="_blank">00:03:35.200</a></span> | <span class="t">in a robotic simulated hand. Then GPT-4 would propose a way of measuring success, a reward</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=d5mdW1yPXIg&t=221" target="_blank">00:03:41.480</a></span> | <span class="t">function. Of course, because it's infinitely patient, it could generate hundreds of these.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=d5mdW1yPXIg&t=226" target="_blank">00:03:46.220</a></span> | <span class="t">These would be tested in simulation in parallel, thanks to NVIDIA hardware. GPT-4 was then</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=d5mdW1yPXIg&t=232" target="_blank">00:03:52.360</a></span> | <span class="t">prompted to reflect on the results. Then, based on those reflections, it would iterate</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=d5mdW1yPXIg&t=237" target="_blank">00:03:57.880</a></span> | <span class="t">the reward functions. Spoiler alert, it got really good at spinning the pen, at least</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=d5mdW1yPXIg&t=243" target="_blank">00:04:03.680</a></span> | <span class="t">in simulation. Fast forward a month and we now have Dr. Eureka. And no, GPT-4 didn't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=d5mdW1yPXIg&t=249" target="_blank">00:04:09.520</a></span> | <span class="t">go off and get a PhD. We're still using vanilla GPT-4. The DR is domain randomization, which</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=d5mdW1yPXIg&t=255" target="_blank">00:04:15.960</a></span> | <span class="t">I'll get to in a moment. Now, some of you may immediately put your hands up and say,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=d5mdW1yPXIg&t=259" target="_blank">00:04:19.720</a></span> | <span class="t">what was wrong with Eureka? Couldn't that have just worked for real world deployment?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=d5mdW1yPXIg&t=263" target="_blank">00:04:23.960</a></span> | <span class="t">In a nutshell, the basic issue is that the world is kind of weird and nitty gritty. There's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=d5mdW1yPXIg&t=270" target="_blank">00:04:30.040</a></span> | <span class="t">a lot of physics you need to contend with and aspects of the domain or environment you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=d5mdW1yPXIg&t=275" target="_blank">00:04:35.880</a></span> | <span class="t">can't quite predict. How much power will be in the robot's motors and how much friction</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=d5mdW1yPXIg&t=280" target="_blank">00:04:40.480</a></span> | <span class="t">will the legs have on the ball? And then some of you might say, that's not a problem, just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=d5mdW1yPXIg&t=284" target="_blank">00:04:44.440</a></span> | <span class="t">test every single scenario. But the problem with that is that in the real world, people</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=d5mdW1yPXIg&t=290" target="_blank">00:04:50.320</a></span> | <span class="t">have a limited compute budget. It's not practical in 2024 to test every single possible scenario.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=d5mdW1yPXIg&t=298" target="_blank">00:04:58.120</a></span> | <span class="t">We need to give the variables a realistic range, but not with human intuition, with</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=d5mdW1yPXIg&t=303" target="_blank">00:05:03.680</a></span> | <span class="t">LLM intuition. So let me now try to run through the Dr. Eureka process, which I think is genius.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=d5mdW1yPXIg&t=310" target="_blank">00:05:10.800</a></span> | <span class="t">As with Eureka, we propose the task. What we add to Eureka is a safety instruction.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=d5mdW1yPXIg&t=317" target="_blank">00:05:17.320</a></span> | <span class="t">Basically, GPT-4 be realistic. Our motors can only do this much. Other things they say</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=d5mdW1yPXIg&t=322" target="_blank">00:05:22.600</a></span> | <span class="t">include this policy is going to be deployed in the real world. Be careful. So then we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=d5mdW1yPXIg&t=327" target="_blank">00:05:27.260</a></span> | <span class="t">get the GPT-4 policy or set of instructions. For example, controlling the legs of the robodog.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=d5mdW1yPXIg&t=334" target="_blank">00:05:34.040</a></span> | <span class="t">Now this is where it gets a little bit complicated, so you might have to focus. Taking that policy,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=d5mdW1yPXIg&t=339" target="_blank">00:05:39.600</a></span> | <span class="t">what they then do is isolate each variable in the environment, in this case, gravity.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=d5mdW1yPXIg&t=345" target="_blank">00:05:45.120</a></span> | <span class="t">But then they amp it right up until the policy breaks. They bring it right down until the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=d5mdW1yPXIg&t=349" target="_blank">00:05:49.720</a></span> | <span class="t">policy breaks. That gives us a viable range where the policy works. That's the reward</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=d5mdW1yPXIg&t=355" target="_blank">00:05:55.400</a></span> | <span class="t">aware part. And why limit ourselves to that range? Well, if you set hyper unrealistic</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=d5mdW1yPXIg&t=360" target="_blank">00:06:00.760</a></span> | <span class="t">settings for gravity, then we won't learn anything. The set of instructions will fail</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=d5mdW1yPXIg&t=366" target="_blank">00:06:06.560</a></span> | <span class="t">every single time in that setting. So there's no signal back to the system of what works.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=d5mdW1yPXIg&t=371" target="_blank">00:06:11.680</a></span> | <span class="t">Keep things in a realistic range and we get a more reliable signal. Unfortunately, though,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=d5mdW1yPXIg&t=376" target="_blank">00:06:16.560</a></span> | <span class="t">that's not enough. And that's where we need domain randomization. And to explain that,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=d5mdW1yPXIg&t=381" target="_blank">00:06:21.520</a></span> | <span class="t">I have to give you a vivid demonstration. At the previous stage, we were limited to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=d5mdW1yPXIg&t=386" target="_blank">00:06:26.520</a></span> | <span class="t">ranges for these different variables that could at least sometimes work. Variables for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=d5mdW1yPXIg&t=391" target="_blank">00:06:31.840</a></span> | <span class="t">the bounciness of the ball, restitution and friction and gravity, as I mentioned. There</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=d5mdW1yPXIg&t=397" target="_blank">00:06:37.000</a></span> | <span class="t">you can see the motor strength range. But there's no real common sense here about</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=d5mdW1yPXIg&t=401" target="_blank">00:06:41.560</a></span> | <span class="t">what would happen with a yoga ball. That's why they called it an uninformative context.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=d5mdW1yPXIg&t=407" target="_blank">00:06:47.160</a></span> | <span class="t">What GPT-4 generated domain randomizations do is give a much more realistic range based</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=d5mdW1yPXIg&t=413" target="_blank">00:06:53.800</a></span> | <span class="t">on common sense. Notice how with each of the ranges, we get an explanation from GPT-4 about</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=d5mdW1yPXIg&t=419" target="_blank">00:06:59.200</a></span> | <span class="t">why it's picking that range. For bounciness, it says we're not focused on bouncing. It's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=d5mdW1yPXIg&t=423" target="_blank">00:07:03.800</a></span> | <span class="t">still relevant for minor impacts, though. Notice just between 0 and 0.5. For friction,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=d5mdW1yPXIg&t=429" target="_blank">00:07:09.360</a></span> | <span class="t">it's thinking about tiles, grass, dirt, etc. For motor strength, it's actually half of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=d5mdW1yPXIg&t=434" target="_blank">00:07:14.680</a></span> | <span class="t">the full range. And it says this is a moderate range, allowing for variability in motor performance.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=d5mdW1yPXIg&t=440" target="_blank">00:07:20.640</a></span> | <span class="t">By limiting the ranges we're going to test, we get much more effective learning. This</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=d5mdW1yPXIg&t=445" target="_blank">00:07:25.160</a></span> | <span class="t">is where GPT-4 starts to outstrip humans in teaching robots. In case you didn't know,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=d5mdW1yPXIg&t=450" target="_blank">00:07:30.480</a></span> | <span class="t">by the way, GPT-4 finished training in August of 2022. How good GPT-5 is at training robots,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=d5mdW1yPXIg&t=457" target="_blank">00:07:37.520</a></span> | <span class="t">only time will tell. Now, some of you in bewilderment will be saying, but Philip, why do we even</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=d5mdW1yPXIg&t=462" target="_blank">00:07:42.640</a></span> | <span class="t">need a range? Why can't we just guess a value for each of these things? Well, the real world</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=d5mdW1yPXIg&t=467" target="_blank">00:07:47.280</a></span> | <span class="t">again is messy. By testing your instructions in these realistic scenarios, it becomes much</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=d5mdW1yPXIg&t=472" target="_blank">00:07:52.840</a></span> | <span class="t">more robust in the real world. As we'll see, the original Eureka flops without this step.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=d5mdW1yPXIg&t=478" target="_blank">00:07:58.100</a></span> | <span class="t">Before we carry on, some of you will be shaking your head and saying, I'm sure humans could</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=d5mdW1yPXIg&t=481" target="_blank">00:08:01.820</a></span> | <span class="t">do better than this. Can't humans come up with better reward functions and more realistic</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=d5mdW1yPXIg&t=486" target="_blank">00:08:06.880</a></span> | <span class="t">ranges? Well, here's Guanjue Wang describing how humans get stuck in local optima.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=d5mdW1yPXIg&t=492" target="_blank">00:08:12.040</a></span> | <span class="t">It has a very much prior knowledge and therefore it can just propose different kinds of mutations</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=d5mdW1yPXIg&t=497" target="_blank">00:08:17.480</a></span> | <span class="t">and variations of the reward function based on the environment context. For humans, you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=d5mdW1yPXIg&t=502" target="_blank">00:08:22.600</a></span> | <span class="t">need to manually tune the reward functions and it's very easy for humans to get stuck</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=d5mdW1yPXIg&t=507" target="_blank">00:08:27.400</a></span> | <span class="t">to a local optima. For GPT-4, it can generate tens of reward functions at the same time</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=d5mdW1yPXIg&t=512" target="_blank">00:08:32.800</a></span> | <span class="t">and based on the performance of each reward function, it can continuously improve it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=d5mdW1yPXIg&t=518" target="_blank">00:08:38.280</a></span> | <span class="t">Humans simply don't have the patience of larger language models. Or to bring in some real</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=d5mdW1yPXIg&t=523" target="_blank">00:08:43.000</a></span> | <span class="t">numbers, Dr. Eureka trained robodogs outperform those trained with human designed reward functions</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=d5mdW1yPXIg&t=529" target="_blank">00:08:49.600</a></span> | <span class="t">and domain randomization parameters by 34% in forward velocity and 20% in distance traveled</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=d5mdW1yPXIg&t=536" target="_blank">00:08:56.640</a></span> | <span class="t">across various real world evaluation terrains, the grass pavement, you name it. By the way,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=d5mdW1yPXIg&t=542" target="_blank">00:09:02.820</a></span> | <span class="t">they also did other tasks like cube rotations and there again, Dr. Eureka's best policy</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=d5mdW1yPXIg&t=548" target="_blank">00:09:08.120</a></span> | <span class="t">performs nearly 300% more of them within a fixed time period. More rotations for your</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=d5mdW1yPXIg&t=554" target="_blank">00:09:14.320</a></span> | <span class="t">money if you will. Remember, before this, we had to rely on domain</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=d5mdW1yPXIg&t=558" target="_blank">00:09:18.120</a></span> | <span class="t">experts to manually perturb different parameters such as friction. And another problem, as</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=d5mdW1yPXIg&t=563" target="_blank">00:09:23.700</a></span> | <span class="t">I mentioned earlier, is that then the human would have to observe how those set of instructions</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=d5mdW1yPXIg&t=568" target="_blank">00:09:28.440</a></span> | <span class="t">or policies did, test it in the real world effectively, and then try new reward functions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=d5mdW1yPXIg&t=573" target="_blank">00:09:33.080</a></span> | <span class="t">All of this delay is probably why we don't have robot servants already. To clarify, this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=d5mdW1yPXIg&t=578" target="_blank">00:09:38.140</a></span> | <span class="t">is the first work to investigate whether large language models like GPT-4 themselves can</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=d5mdW1yPXIg&t=584" target="_blank">00:09:44.440</a></span> | <span class="t">be used to guide this simulation to reality transfer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=d5mdW1yPXIg&t=588" target="_blank">00:09:48.320</a></span> | <span class="t">Now what about that safety instruction I mentioned earlier? Why is that crucial? Well, this is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=d5mdW1yPXIg&t=592" target="_blank">00:09:52.620</a></span> | <span class="t">where it gets a little bit funny. Basically, without that safety instruction, GPT-4 starts</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=d5mdW1yPXIg&t=597" target="_blank">00:09:57.720</a></span> | <span class="t">to behave in a degenerate fashion. Things got pretty wild with GPT-4, but I'll give</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=d5mdW1yPXIg&t=603" target="_blank">00:10:03.600</a></span> | <span class="t">you the censored version. Basically, it would cheat by over-exerting the robot motors or</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=d5mdW1yPXIg&t=610" target="_blank">00:10:10.240</a></span> | <span class="t">learning unnatural behavior. Essentially, it would propose things that conquer the simulation,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=d5mdW1yPXIg&t=615" target="_blank">00:10:15.720</a></span> | <span class="t">but which wouldn't work in reality. For example, it would try thrusting its hip against the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=d5mdW1yPXIg&t=620" target="_blank">00:10:20.440</a></span> | <span class="t">ground and dragging itself with three of its legs. Now I'm sure that none of you would</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=d5mdW1yPXIg&t=625" target="_blank">00:10:25.480</a></span> | <span class="t">try such degenerate behavior, but GPT-4 did. Put that into the real world though, and of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=d5mdW1yPXIg&t=630" target="_blank">00:10:30.800</a></span> | <span class="t">course that behavior doesn't transfer. With that policy, the robo-dog directly face plants</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=d5mdW1yPXIg&t=636" target="_blank">00:10:36.640</a></span> | <span class="t">at the starting line. More formally though, we got reward functions</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=d5mdW1yPXIg&t=640" target="_blank">00:10:40.140</a></span> | <span class="t">like this. And unlike human-designed reward functions, which would involve adding each</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=d5mdW1yPXIg&t=644" target="_blank">00:10:44.800</a></span> | <span class="t">component, this was multiplicative. The reward was the product of the terms above. And why</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=d5mdW1yPXIg&t=650" target="_blank">00:10:50.300</a></span> | <span class="t">is that really smart? Well, if any of these tend towards zero, the product will tend towards</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=d5mdW1yPXIg&t=656" target="_blank">00:10:56.520</a></span> | <span class="t">zero. If you violate the degree of freedom of the joints of the robot, the entire reward</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=d5mdW1yPXIg&t=663" target="_blank">00:11:03.640</a></span> | <span class="t">function will generate zero. Remember, if you multiply anything by zero, it's zero.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=d5mdW1yPXIg&t=668" target="_blank">00:11:08.240</a></span> | <span class="t">Whereas with the human-designed policy, you would add these things up and still get some</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=d5mdW1yPXIg&t=672" target="_blank">00:11:12.920</a></span> | <span class="t">reward. Here are some of the examples of the kind</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=d5mdW1yPXIg&t=675" target="_blank">00:11:15.040</a></span> | <span class="t">of prompts they fed GPT-4 to emphasize realism and safety. The policy, they said, will be</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=d5mdW1yPXIg&t=680" target="_blank">00:11:20.780</a></span> | <span class="t">trained in simulation and deployed in the real world. So the policy, they reminded GPT-4,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=d5mdW1yPXIg&t=685" target="_blank">00:11:25.100</a></span> | <span class="t">should be as steady and stable as possible. Keep the torso high up and the orientation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=d5mdW1yPXIg&t=690" target="_blank">00:11:30.980</a></span> | <span class="t">should be perpendicular to gravity. Later, they say, please also penalize jittery or</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=d5mdW1yPXIg&t=696" target="_blank">00:11:36.340</a></span> | <span class="t">fast actions that may burn out the motors. These kinds of safety-oriented prompts were</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=d5mdW1yPXIg&t=701" target="_blank">00:11:41.620</a></span> | <span class="t">crucial. Here you can see GPT-4 reflecting on a reward function that had failed and coming</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=d5mdW1yPXIg&t=707" target="_blank">00:11:47.360</a></span> | <span class="t">up with improvements. It was like, ah, I need an exponential reward component for the height</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=d5mdW1yPXIg&t=712" target="_blank">00:11:52.660</a></span> | <span class="t">reward so that the reward gradient is smoother. Then it updates the reward function.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=d5mdW1yPXIg&t=718" target="_blank">00:11:58.380</a></span> | <span class="t">And here's another way that Dr. Eureka outperforms human training. When humans are trying to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=d5mdW1yPXIg&t=723" target="_blank">00:12:03.640</a></span> | <span class="t">teach a robot a skill, they often come up with a curriculum, a set of things to learn</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=d5mdW1yPXIg&t=729" target="_blank">00:12:09.620</a></span> | <span class="t">in a particular order. So first they might teach a robot to move at half a meter per</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=d5mdW1yPXIg&t=734" target="_blank">00:12:14.940</a></span> | <span class="t">second, then one meter, then two meters per second. These curricula have to be carefully</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=d5mdW1yPXIg&t=740" target="_blank">00:12:20.020</a></span> | <span class="t">designed. Well, with this approach, we don't need a reward curriculum. It's almost like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=d5mdW1yPXIg&t=744" target="_blank">00:12:24.700</a></span> | <span class="t">the model throws out the human textbook and teaches itself. Oh, and why a yoga ball, by</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=d5mdW1yPXIg&t=750" target="_blank">00:12:30.660</a></span> | <span class="t">the way? Well, apparently they were inspired by the circus. Doesn't make you wonder what</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=d5mdW1yPXIg&t=756" target="_blank">00:12:36.060</a></span> | <span class="t">they're going to try next, but let's see. And what about limitations? Well, if you remember</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=d5mdW1yPXIg&t=760" target="_blank">00:12:40.220</a></span> | <span class="t">from earlier, they didn't incorporate any real world feedback, but of course they admit</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=d5mdW1yPXIg&t=765" target="_blank">00:12:45.060</a></span> | <span class="t">that with dynamic adjustment of domain randomization parameters based on policy performance or</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=d5mdW1yPXIg&t=771" target="_blank">00:12:51.140</a></span> | <span class="t">real world feedback, they could of course further improve the simulation to reality</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=d5mdW1yPXIg&t=775" target="_blank">00:12:55.820</a></span> | <span class="t">transferability. I actually had a discussion with Jim Fan about all of this back on my</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=d5mdW1yPXIg&t=781" target="_blank">00:13:01.180</a></span> | <span class="t">Patreon in January, and one of the things we discussed was another way to improve this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=d5mdW1yPXIg&t=786" target="_blank">00:13:06.460</a></span> | <span class="t">approach, incorporating vision. If GPT-4 could see where the robot is going wrong and not</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=d5mdW1yPXIg&t=791" target="_blank">00:13:11.900</a></span> | <span class="t">just read about it, it could do far better. And how about one more way to improve this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=d5mdW1yPXIg&t=797" target="_blank">00:13:17.580</a></span> | <span class="t">approach? Co-evolution. Apologies for the slight audio deformity here. I honestly am</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=d5mdW1yPXIg&t=803" target="_blank">00:13:23.580</a></span> | <span class="t">struggling to see what the limit will be, and I'm wondering what you think about the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=d5mdW1yPXIg&t=808" target="_blank">00:13:28.860</a></span> | <span class="t">limit to the Eureka approach as we are getting more and more powerful models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=d5mdW1yPXIg&t=815" target="_blank">00:13:35.300</a></span> | <span class="t">I think that is a great question. You know, just by sheer coincidence, people are talking</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=d5mdW1yPXIg&t=819" target="_blank">00:13:39.780</a></span> | <span class="t">about two-star and there's this renewed interest in LLM complying with classical approaches</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=d5mdW1yPXIg&t=826" target="_blank">00:13:46.060</a></span> | <span class="t">like search, right? Instead of just generating, you generate and then you get some feedback</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=d5mdW1yPXIg&t=831" target="_blank">00:13:51.420</a></span> | <span class="t">and you generate more, you would do a little bit of search, and then you expand that search</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=d5mdW1yPXIg&t=835" target="_blank">00:13:55.700</a></span> | <span class="t">and that kind of comes back to improve the model and also improve just the intelligence</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=d5mdW1yPXIg&t=840" target="_blank">00:14:00.460</a></span> | <span class="t">of the whole system. And actually, Eureka is doing exactly that. It uses GPT-4 to write</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=d5mdW1yPXIg&t=847" target="_blank">00:14:07.220</a></span> | <span class="t">reward functions, and the reward function instructs a robot hand to do tasks, and you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=d5mdW1yPXIg&t=852" target="_blank">00:14:12.020</a></span> | <span class="t">get feedback. You know how good that robot is performing. And you can use that as a ground</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=d5mdW1yPXIg&t=856" target="_blank">00:14:16.540</a></span> | <span class="t">truth signal to improve even more, which we did in the paper. And one limitation is that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=d5mdW1yPXIg&t=862" target="_blank">00:14:22.460</a></span> | <span class="t">we are not able to fine-tune GPT, but it's possible that some of the open-source models</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=d5mdW1yPXIg&t=867" target="_blank">00:14:27.820</a></span> | <span class="t">will catch up in the future. And actually, we are also actively exploring how to use</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=d5mdW1yPXIg&t=872" target="_blank">00:14:32.140</a></span> | <span class="t">some open-source models in the loop for Eureka. Well, that means we will be able to not just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=d5mdW1yPXIg&t=877" target="_blank">00:14:37.060</a></span> | <span class="t">improve in context, but also improve the intelligence on the underlying language. So basically the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=d5mdW1yPXIg&t=883" target="_blank">00:14:43.100</a></span> | <span class="t">LLM and the Eureka and the robots, they can co-evolve and co-improve. And then, you know,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=d5mdW1yPXIg&t=890" target="_blank">00:14:50.140</a></span> | <span class="t">that means basically the sky's the limit. Or, you know, compute budget is the limit.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=d5mdW1yPXIg&t=894" target="_blank">00:14:54.860</a></span> | <span class="t">In case you were wondering, all of this is open-source and the links will be in the description.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=d5mdW1yPXIg&t=899" target="_blank">00:14:59.900</a></span> | <span class="t">But what about the bigger implications? I predict that within a year, we will see a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=d5mdW1yPXIg&t=905" target="_blank">00:15:05.220</a></span> | <span class="t">humanoid robot perform a complex physical dexterous task, one that is performed commonly</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=d5mdW1yPXIg&t=911" target="_blank">00:15:11.140</a></span> | <span class="t">in industry. That could be the wake-up call for many that the blue-collar world isn't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=d5mdW1yPXIg&t=916" target="_blank">00:15:16.940</a></span> | <span class="t">completely immune to AI. Of course, there's a long way to go between where we are and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=d5mdW1yPXIg&t=921" target="_blank">00:15:21.940</a></span> | <span class="t">the mass manufacturing of the robots needed to affect jobs at a big scale. So of course,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=d5mdW1yPXIg&t=928" target="_blank">00:15:28.180</a></span> | <span class="t">plumbers are safe for now. In high-stakes settings like self-driving, we're clearly</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=d5mdW1yPXIg&t=932" target="_blank">00:15:32.900</a></span> | <span class="t">not quite ready for widespread deployment. Although Waymo is doing pretty well. But for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=d5mdW1yPXIg&t=938" target="_blank">00:15:38.140</a></span> | <span class="t">repetitive tasks, things might change faster than you think. And if you believe that the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=d5mdW1yPXIg&t=943" target="_blank">00:15:43.500</a></span> | <span class="t">dexterity of human fingers is what will differentiate us, then Sanctuary AI will soon be on your</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=d5mdW1yPXIg&t=951" target="_blank">00:15:51.220</a></span> | <span class="t">case. And with AI doing the training in parallel across thousands of simulations, things could</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=d5mdW1yPXIg&t=957" target="_blank">00:15:57.480</a></span> | <span class="t">change fast. Just an amazing paper and super enjoyable to read. And yes, I read many of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=d5mdW1yPXIg&t=963" target="_blank">00:16:03.380</a></span> | <span class="t">the papers linked in the appendices. I kind of went deep for this one. So thank you as</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=d5mdW1yPXIg&t=968" target="_blank">00:16:08.700</a></span> | <span class="t">ever for watching to the end. And if you do want to support the channel, check out my</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=d5mdW1yPXIg&t=973" target="_blank">00:16:13.580</a></span> | <span class="t">amazing Patreon. We have incredible networking on the Discord, plus I do podcasts and interviews</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=d5mdW1yPXIg&t=979" target="_blank">00:16:19.740</a></span> | <span class="t">and more. But regardless of all of that, I hope you have a wonderful day.</span></div></div></body></html>