<html><head><title>Lesson 7: Deep Learning 2</title>
<style>
    body {
        font-family: Arial, sans-serif;
        margin: 0;
        padding: 0;
        background-color: #f4f4f4;
        color: #333;
    }
    .container {
        width: 95%;  /* Increased width to use more space */
        margin: auto;
        overflow: auto;  /* Added to handle overflow by adding a scrollbar if necessary */
    }
    h2, h3 {
        color: #333;
        text-align: center;
    }
    a {
        color: #0000FF;  /* Traditional blue color for links */
        text-decoration: none;
    }
    a:hover {
        text-decoration: underline;
    }
    img {
        display: block;
        margin: auto;
        max-width: 100%;
    }
    .c {
        margin: 10px 0;
    }
    .s, .t {
        display: inline-block;
        margin-right: 5px;
    }
    .max-width {
        max-width: 800px;
        margin: auto;
        padding-left: 20px;
    }
    table {
        width: 100%;
        border-collapse: collapse;
    }
    th, td {
        border: 1px solid #ddd;
        padding: 8px;
        text-align: left;  /* Ensure text alignment is consistent */
    }
    tr:nth-child(even) {
        background-color: #f2f2f2;
    }
    tr:nth-child(odd) {
        background-color: #e6e6e6;
    }
</style>

    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-69VLBMTTP0"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-69VLBMTTP0');
    </script>
    </head><body><div class='container'><a href="index.html">back to index</a><h2>Lesson 7: Deep Learning 2</h2><a href="https://www.youtube.com/watch?v=H3g26EVADgY"><img src="https://i.ytimg.com/vi_webp/H3g26EVADgY/hqdefault.webp" style="width:50%;"></a><div><br></div><h3>Chapters</h3><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=0">0:0</a> <Untitled Chapter 1><br><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=60">1:0</a> Part Two<br><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=78">1:18</a> Generative Modeling<br><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=185">3:5</a> Standard Fully Connected Network<br><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=806">13:26</a> Repackage Variable<br><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3050">50:50</a> Update Gate<br><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3458">57:38</a> Cosine Annealing Callback<br><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3864">64:24</a> Need for Rigor in Experiments in Deep Learning<br><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=4040">67:20</a> Create a Model from Scratch<br><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=4230">70:30</a> Create a Learn Object from a Custom Model<br><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=4439">73:59</a> Convolution<br><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=4537">75:37</a> Stride to Convolution<br><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=4632">77:12</a> Adaptive Max Pooling<br><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=4859">80:59</a> Learning Rate Finder<br><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=5143">85:43</a> Batch Normalization<br><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=5181">86:21</a> Batch Norm<br><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=5300">88:20</a> Normalizing the Inputs<br><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=6660">111:0</a> Increasing the Depth of the Model<br><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=6802">113:22</a> Resnet Block<br><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7146">119:6</a> Bottleneck Layer<br><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7285">121:25</a> The Transformer Architecture<br><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7751">129:11</a> Class Activation Maps<br><br><div style="text-align: left;"><a href="./H3g26EVADgY.html">Whisper Transcript</a> | <a href="./transcript_H3g26EVADgY.html">Transcript Only Page</a></div><br><div style="max-width: 800px;"><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=0" target="_blank">00:00:00.000</a></span> | <span class="t">The last class of Part 1, I guess the theme of Part 1 is classification and regression</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=12" target="_blank">00:00:12.200</a></span> | <span class="t">with deep learning, and specifically it's about identifying and learning the best practices</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=18" target="_blank">00:00:18.320</a></span> | <span class="t">to classification and regression.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=21" target="_blank">00:00:21.920</a></span> | <span class="t">We started out with, here are three lines of code to do image classification, and gradually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=28" target="_blank">00:00:28.600</a></span> | <span class="t">we've been, well the first four lessons were then kind of going through NLP, structured</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=35" target="_blank">00:00:35.480</a></span> | <span class="t">data, cognitive filtering and kind of understanding some of the key pieces, and most importantly</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=39" target="_blank">00:00:39.920</a></span> | <span class="t">understanding how to actually make these things work well in practice.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=45" target="_blank">00:00:45.520</a></span> | <span class="t">And then the last three lessons are then kind of going back over all of those topics in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=50" target="_blank">00:00:50.240</a></span> | <span class="t">kind of reverse order to understand more detail about what was going on and understanding</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=55" target="_blank">00:00:55.680</a></span> | <span class="t">what the code looks like behind the scenes and wanting to write them from scratch.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=62" target="_blank">00:01:02.400</a></span> | <span class="t">Part 2 of the course will move from a focus on classification and regression, which is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=69" target="_blank">00:01:09.920</a></span> | <span class="t">kind of predicting 'a' thing, like 'a' number, or at most a small number of things, like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=76" target="_blank">00:01:16.120</a></span> | <span class="t">a small number of labels.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=77" target="_blank">00:01:17.800</a></span> | <span class="t">And we'll focus more on generative modelling.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=81" target="_blank">00:01:21.040</a></span> | <span class="t">generative modelling means predicting lots of things.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=85" target="_blank">00:01:25.560</a></span> | <span class="t">For example, creating a sentence, such as in neural translation, or image captioning,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=91" target="_blank">00:01:31.640</a></span> | <span class="t">or question-answering, or creating an image, such as in style transfer, super-resolution,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=100" target="_blank">00:01:40.400</a></span> | <span class="t">segmentation, and so forth.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=104" target="_blank">00:01:44.240</a></span> | <span class="t">And then in Part 2, it'll move away from being just, here are some best practices, established</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=111" target="_blank">00:01:51.960</a></span> | <span class="t">best practices either through people that have written papers or through research that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=116" target="_blank">00:01:56.280</a></span> | <span class="t">Fast AI has done and kind of got convinced that these are best practices, to some stuff</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=122" target="_blank">00:02:02.160</a></span> | <span class="t">which will be a little bit more speculative.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=124" target="_blank">00:02:04.560</a></span> | <span class="t">Some stuff which is maybe recent papers that haven't been fully tested yet, and sometimes</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=131" target="_blank">00:02:11.600</a></span> | <span class="t">in Part 2, papers will come out in the middle of the course, and we'll change direction</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=136" target="_blank">00:02:16.040</a></span> | <span class="t">with the course and study that paper because it's just interesting.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=139" target="_blank">00:02:19.880</a></span> | <span class="t">And so if you're interested in learning a bit more about how to read a paper and how</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=146" target="_blank">00:02:26.360</a></span> | <span class="t">to implement it from scratch and so forth, then that's another good reason to do Part</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=150" target="_blank">00:02:30.640</a></span> | <span class="t">2.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=152" target="_blank">00:02:32.560</a></span> | <span class="t">It still doesn't assume any particular math background, but it does assume that you're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=160" target="_blank">00:02:40.720</a></span> | <span class="t">prepared to spend time digging through the notation and understanding it and converting</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=167" target="_blank">00:02:47.240</a></span> | <span class="t">it to code and so forth.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=169" target="_blank">00:02:49.520</a></span> | <span class="t">Alright, so where we're up to is RNNs at the moment.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=174" target="_blank">00:02:54.880</a></span> | <span class="t">I think one of the issues I find most with teaching RNNs is trying to ensure that people</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=180" target="_blank">00:03:00.840</a></span> | <span class="t">understand that they're not in any way different or unusual or magical, they're just a standard</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=187" target="_blank">00:03:07.000</a></span> | <span class="t">fully connected network.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=191" target="_blank">00:03:11.320</a></span> | <span class="t">Let's go back to the standard fully connected network which looks like this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=195" target="_blank">00:03:15.200</a></span> | <span class="t">To remind you, the arrows represent one or more layer operations, generally speaking</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=202" target="_blank">00:03:22.040</a></span> | <span class="t">a linear, followed by a nonlinear function.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=205" target="_blank">00:03:25.160</a></span> | <span class="t">In this case, they're matrix modifications, followed by ReLU or THAN.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=212" target="_blank">00:03:32.800</a></span> | <span class="t">The arrows of the same color represent exactly the same weight matrix being used.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=221" target="_blank">00:03:41.760</a></span> | <span class="t">And so one thing which was just slightly different from previous fully connected networks we've</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=226" target="_blank">00:03:46.320</a></span> | <span class="t">seen is that we have an input coming in not just at the first layer but also at the second</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=233" target="_blank">00:03:53.280</a></span> | <span class="t">layer and also at the third layer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=235" target="_blank">00:03:55.040</a></span> | <span class="t">And we tried a couple of approaches, one was concatenating the inputs and one was adding</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=239" target="_blank">00:03:59.540</a></span> | <span class="t">the inputs.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=240" target="_blank">00:04:00.540</a></span> | <span class="t">But there was nothing at all conceptually different about this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=246" target="_blank">00:04:06.600</a></span> | <span class="t">So that code looked like this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=249" target="_blank">00:04:09.760</a></span> | <span class="t">We had a model where we basically defined the three arrows colors we had as three different</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=259" target="_blank">00:04:19.260</a></span> | <span class="t">weight matrices.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=262" target="_blank">00:04:22.600</a></span> | <span class="t">And by using the linear class, we got actually both the weight matrix and the bias vector</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=268" target="_blank">00:04:28.960</a></span> | <span class="t">wrapped up for free for us.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=271" target="_blank">00:04:31.920</a></span> | <span class="t">And then we went through and we did each of our embeddings, put it through our first linear</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=277" target="_blank">00:04:37.360</a></span> | <span class="t">layer and then we did each of our, we call them hidden, I think they were orange arrows.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=288" target="_blank">00:04:48.640</a></span> | <span class="t">And in order to avoid the fact that there's no orange arrow coming into the first one,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=294" target="_blank">00:04:54.880</a></span> | <span class="t">we decided to invent an empty matrix and that way every one of these rows looked the same.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=301" target="_blank">00:05:01.400</a></span> | <span class="t">And so then we did exactly the same thing except we used a loop just to refactor the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=311" target="_blank">00:05:11.360</a></span> | <span class="t">code.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=312" target="_blank">00:05:12.360</a></span> | <span class="t">So it was just a code refactoring, there was no change of anything conceptually.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=318" target="_blank">00:05:18.720</a></span> | <span class="t">And since we were doing a refactoring, we took advantage of that to increase the number</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=323" target="_blank">00:05:23.240</a></span> | <span class="t">of characters to 8 because I was too lazy to type 8 linear layers, but I'm quite happy</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=328" target="_blank">00:05:28.320</a></span> | <span class="t">to change the loop index to 8.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=331" target="_blank">00:05:31.720</a></span> | <span class="t">So this now loops through this exact same thing, but we had 8 of these rather than 3.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=343" target="_blank">00:05:43.280</a></span> | <span class="t">So then we refactored that again by taking advantage of nn.rnn, which basically puts</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=349" target="_blank">00:05:49.880</a></span> | <span class="t">that loop together for us and keeps track of this h as it goes along for us.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=360" target="_blank">00:06:00.400</a></span> | <span class="t">And so by using that we were able to replace the loop with a single call.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=366" target="_blank">00:06:06.340</a></span> | <span class="t">And so again, that's just a refactoring, doing exactly the same thing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=375" target="_blank">00:06:15.640</a></span> | <span class="t">So then we looked at something which was mainly designed to save some training time, which</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=383" target="_blank">00:06:23.360</a></span> | <span class="t">was previously, if we had a big piece of text, so we've got a movie review, we were basically</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=398" target="_blank">00:06:38.560</a></span> | <span class="t">splitting it up into 8-character segments, and we'd grab segment number 1 and use that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=407" target="_blank">00:06:47.000</a></span> | <span class="t">to predict the next character.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=411" target="_blank">00:06:51.600</a></span> | <span class="t">But in order to make sure we used all of the data, we didn't just split it up like that,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=416" target="_blank">00:06:56.560</a></span> | <span class="t">we actually said here's our whole thing, the first will be to grab this section, the second</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=425" target="_blank">00:07:05.440</a></span> | <span class="t">will be to grab that section, then that section, then that section, and each time we're predicting</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=431" target="_blank">00:07:11.000</a></span> | <span class="t">the next one character along.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=434" target="_blank">00:07:14.560</a></span> | <span class="t">And so I was a bit concerned that that seems pretty wasteful because as we calculate this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=441" target="_blank">00:07:21.560</a></span> | <span class="t">section, nearly all of it overlaps with the previous section.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=446" target="_blank">00:07:26.440</a></span> | <span class="t">So instead what we did was we said what if we actually did split it into non-overlapping</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=454" target="_blank">00:07:34.360</a></span> | <span class="t">pieces and we said let's grab this section here and use it to predict every one of the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=467" target="_blank">00:07:47.200</a></span> | <span class="t">characters one along.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=469" target="_blank">00:07:49.200</a></span> | <span class="t">And then let's grab this section here and use it to predict every one of the characters</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=473" target="_blank">00:07:53.600</a></span> | <span class="t">one along.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=474" target="_blank">00:07:54.600</a></span> | <span class="t">So after we look at the first character in, we try to predict the second character.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=479" target="_blank">00:07:59.240</a></span> | <span class="t">And then after we look at the second character, we try to predict the third character.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=484" target="_blank">00:08:04.240</a></span> | <span class="t">And then what if you perceptive folks asked a really interesting question, or expressed</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=491" target="_blank">00:08:11.280</a></span> | <span class="t">a concern, which was, after we got through the first point here, we kind of threw away</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=507" target="_blank">00:08:27.040</a></span> | <span class="t">our H activations and started a new one, which meant that when it was trying to use character</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=514" target="_blank">00:08:34.760</a></span> | <span class="t">1 to predict character 2, it's got nothing to go on.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=520" target="_blank">00:08:40.360</a></span> | <span class="t">It's only done one linear layer, and so that seems like a problem, which indeed it is.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=529" target="_blank">00:08:49.200</a></span> | <span class="t">So we're going to do the obvious thing, which is let's not throw away H. So let's not throw</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=535" target="_blank">00:08:55.920</a></span> | <span class="t">away that matrix at all.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=539" target="_blank">00:08:59.320</a></span> | <span class="t">So in code, the big problem is here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=544" target="_blank">00:09:04.920</a></span> | <span class="t">Every time we call forward, in other words every time we do a new mini-batch, we're creating</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=551" target="_blank">00:09:11.640</a></span> | <span class="t">our hidden state, which remember is the orange circles, we're resetting it back to a bunch</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=559" target="_blank">00:09:19.080</a></span> | <span class="t">of zeroes.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=560" target="_blank">00:09:20.400</a></span> | <span class="t">And so as we go to the next non-overlapping section, we're saying forget everything that's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=564" target="_blank">00:09:24.880</a></span> | <span class="t">come before.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=565" target="_blank">00:09:25.880</a></span> | <span class="t">But in fact, the whole point is we know exactly where we are, we're at the end of the previous</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=570" target="_blank">00:09:30.860</a></span> | <span class="t">section and about to start the next contiguous section, so let's not throw it away.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=575" target="_blank">00:09:35.460</a></span> | <span class="t">So instead the idea would be to cut this out, move it up to here, store it away in self,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=588" target="_blank">00:09:48.680</a></span> | <span class="t">and then kind of keep updating it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=591" target="_blank">00:09:51.640</a></span> | <span class="t">So we're going to do that, and there's going to be some minor details to get right.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=598" target="_blank">00:09:58.520</a></span> | <span class="t">So let's start by looking at the model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=601" target="_blank">00:10:01.960</a></span> | <span class="t">So here's the model, it's nearly identical, but I've got, as expected, one more line in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=615" target="_blank">00:10:15.560</a></span> | <span class="t">my constructor where I call something called init_hidden, and as expected init_hidden sets</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=622" target="_blank">00:10:22.440</a></span> | <span class="t">self.h to be a bunch of zeroes.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=628" target="_blank">00:10:28.280</a></span> | <span class="t">So that's entirely unsurprising.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=632" target="_blank">00:10:32.720</a></span> | <span class="t">And then as you can see our RNN now takes in self.h, and it, as before, spits out our</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=641" target="_blank">00:10:41.960</a></span> | <span class="t">new hidden activations.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=644" target="_blank">00:10:44.120</a></span> | <span class="t">And so now the trick is to now store that away inside self.h.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=650" target="_blank">00:10:50.840</a></span> | <span class="t">And so here's wrinkle number 1.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=653" target="_blank">00:10:53.720</a></span> | <span class="t">If you think about it, if I was to simply do it like that, and now I train this on a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=662" target="_blank">00:11:02.960</a></span> | <span class="t">document that's a million characters long, then the size of this unrolled RNN is the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=674" target="_blank">00:11:14.100</a></span> | <span class="t">one that has a million circles in.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=677" target="_blank">00:11:17.840</a></span> | <span class="t">And so that's fine going forwards, but when I finally get to the end and I say here's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=682" target="_blank">00:11:22.720</a></span> | <span class="t">my character, and actually remember we're doing multi-output now, so multi-output looks</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=688" target="_blank">00:11:28.440</a></span> | <span class="t">like this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=689" target="_blank">00:11:29.440</a></span> | <span class="t">Or if we were to draw the unrolled version of multi-output, we would have a triangle</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=695" target="_blank">00:11:35.020</a></span> | <span class="t">coming off at every point.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=699" target="_blank">00:11:39.320</a></span> | <span class="t">So the problem is then when we do backpropagation, we're calculating how much does the error</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=707" target="_blank">00:11:47.080</a></span> | <span class="t">at character 1 impact the final answer, how much does the error at character 2 impact</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=713" target="_blank">00:11:53.960</a></span> | <span class="t">the final answer, and so forth.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=715" target="_blank">00:11:55.640</a></span> | <span class="t">And so we need to go back through and say how do we have to update our weights based</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=721" target="_blank">00:12:01.660</a></span> | <span class="t">on all of those errors.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=724" target="_blank">00:12:04.680</a></span> | <span class="t">And so if there are a million characters, my unrolled RNN is a million layers long,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=731" target="_blank">00:12:11.520</a></span> | <span class="t">I have a 1 million layer fully connected network.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=737" target="_blank">00:12:17.160</a></span> | <span class="t">And I didn't have to write the million layers because I have the for loop and the for loop</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=740" target="_blank">00:12:20.800</a></span> | <span class="t">is hidden away behind the self dot RNN, but it's still there.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=748" target="_blank">00:12:28.720</a></span> | <span class="t">So this is actually a 1 million layer fully connected network.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=752" target="_blank">00:12:32.600</a></span> | <span class="t">And so the problem with that is it's going to be very memory intensive because in order</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=757" target="_blank">00:12:37.160</a></span> | <span class="t">to do the chain rule, I have to be able to multiply it every step like f'u g'x.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=766" target="_blank">00:12:46.680</a></span> | <span class="t">So I have to remember those values u, the value of every set of layers, so I'm going</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=773" target="_blank">00:12:53.160</a></span> | <span class="t">to have to remember all those million layers, and I'm going to have to do a million multiplications,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=777" target="_blank">00:12:57.680</a></span> | <span class="t">and I'm going to have to do that every batch.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=781" target="_blank">00:13:01.280</a></span> | <span class="t">So that would be bad.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=783" target="_blank">00:13:03.360</a></span> | <span class="t">So to avoid that, we basically say from time to time, I want you to forget your history.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=792" target="_blank">00:13:12.760</a></span> | <span class="t">So we can still remember the state, which is to remember what's the actual values in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=797" target="_blank">00:13:17.200</a></span> | <span class="t">our hidden matrix, but we can remember the state without remembering everything about</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=802" target="_blank">00:13:22.960</a></span> | <span class="t">how we got there.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=804" target="_blank">00:13:24.720</a></span> | <span class="t">So there's a little function called repackaged variable, which literally is just this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=817" target="_blank">00:13:37.400</a></span> | <span class="t">It just simply says, grab the tensor out of it, because remember the tensor itself doesn't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=825" target="_blank">00:13:45.400</a></span> | <span class="t">have any concept of history, and create a new variable out of that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=830" target="_blank">00:13:50.200</a></span> | <span class="t">And so this variable is going to have the same value, but no history of operations,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=836" target="_blank">00:13:56.320</a></span> | <span class="t">and therefore when it tries to backpropagate, it'll stop there.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=841" target="_blank">00:14:01.160</a></span> | <span class="t">So basically what we're going to do then is we're going to call this in our forward.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=845" target="_blank">00:14:05.800</a></span> | <span class="t">So that means it's going to do 8 characters, it's going to backpropagate through 8 layers,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=853" target="_blank">00:14:13.680</a></span> | <span class="t">it's going to keep track of the actual values in our hidden state, but it's going to throw</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=858" target="_blank">00:14:18.480</a></span> | <span class="t">away at the end of those 8 its history of operations.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=864" target="_blank">00:14:24.040</a></span> | <span class="t">So this approach is called backprop through time, and when you read about it online, people</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=871" target="_blank">00:14:31.880</a></span> | <span class="t">make it sound like a different algorithm, or some big insight or something, but it's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=878" target="_blank">00:14:38.360</a></span> | <span class="t">not at all.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=879" target="_blank">00:14:39.360</a></span> | <span class="t">It's just saying hey, after our for loop, just throw away your history of operations</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=886" target="_blank">00:14:46.180</a></span> | <span class="t">and start afresh.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=887" target="_blank">00:14:47.480</a></span> | <span class="t">So we're keeping our hidden state, but we're not keeping our hidden state's history.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=895" target="_blank">00:14:55.400</a></span> | <span class="t">So that's wrinkle number 1, that's what this repackage bar is doing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=900" target="_blank">00:15:00.340</a></span> | <span class="t">So when you see bptt, that's referring to backprop through time, and you might remember</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=907" target="_blank">00:15:07.320</a></span> | <span class="t">we saw that in our original RNN lesson, we had a variable called bptt = 70, and so when</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=915" target="_blank">00:15:15.880</a></span> | <span class="t">we set that, we're actually saying how many layers to backprop through.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=921" target="_blank">00:15:21.200</a></span> | <span class="t">Another good reason not to backprop through too many layers is if you have any kind of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=925" target="_blank">00:15:25.760</a></span> | <span class="t">gradient instability like gradient explosion or gradient spanishing, the more layers you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=932" target="_blank">00:15:32.240</a></span> | <span class="t">have, the harder the network gets to train.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=935" target="_blank">00:15:35.600</a></span> | <span class="t">So it's slower and less resilient.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=939" target="_blank">00:15:39.040</a></span> | <span class="t">On the other hand, a longer value for bptt means that you're able to explicitly capture</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=947" target="_blank">00:15:47.360</a></span> | <span class="t">a longer kind of memory, more state.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=952" target="_blank">00:15:52.600</a></span> | <span class="t">So that's something that you get to tune when you create your RNN.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=962" target="_blank">00:16:02.320</a></span> | <span class="t">Wrinkle number 2 is how are we going to put the data into this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=970" target="_blank">00:16:10.600</a></span> | <span class="t">It's all very well the way I described it just now where we said we could do this, and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=983" target="_blank">00:16:23.880</a></span> | <span class="t">we can first of all look at this section, then this section, then this section, but</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=990" target="_blank">00:16:30.080</a></span> | <span class="t">we want to do a mini-batch at a time, we want to do a bunch at a time.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=996" target="_blank">00:16:36.920</a></span> | <span class="t">So in other words, we want to say let's do it like this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=1011" target="_blank">00:16:51.200</a></span> | <span class="t">So mini-batch number 1 would say let's look at this section and predict that section.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=1018" target="_blank">00:16:58.080</a></span> | <span class="t">And at the same time in parallel, let's look at this totally different section and predict</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=1023" target="_blank">00:17:03.040</a></span> | <span class="t">this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=1024" target="_blank">00:17:04.040</a></span> | <span class="t">And at the same time in parallel, let's look at this totally different section and predict</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=1028" target="_blank">00:17:08.480</a></span> | <span class="t">this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=1030" target="_blank">00:17:10.600</a></span> | <span class="t">And so then, because remember in our hidden state, we have a vector of hidden state for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=1038" target="_blank">00:17:18.080</a></span> | <span class="t">everything in our mini-batch, so it's going to keep track of at the end of this is going</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=1042" target="_blank">00:17:22.200</a></span> | <span class="t">to be a vector here, a vector here, a vector here, and then we can move across to the next</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=1047" target="_blank">00:17:27.320</a></span> | <span class="t">one and say okay, for this part of the mini-batch, use this to predict that, and use this to predict</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=1054" target="_blank">00:17:34.600</a></span> | <span class="t">that, and use this to predict that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=1058" target="_blank">00:17:38.000</a></span> | <span class="t">So you can see that we've got a number of totally separate bits of our text that we're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=1063" target="_blank">00:17:43.800</a></span> | <span class="t">moving through in parallel.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=1067" target="_blank">00:17:47.440</a></span> | <span class="t">So hopefully this is going to ring a few bells for you, because what happened was back when</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=1075" target="_blank">00:17:55.720</a></span> | <span class="t">we started looking at TorchText for the first time, we started talking about how it creates</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=1080" target="_blank">00:18:00.120</a></span> | <span class="t">these mini-batches.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=1081" target="_blank">00:18:01.720</a></span> | <span class="t">And I said what happened was we took our whole big long document consisting of the entire</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=1090" target="_blank">00:18:10.720</a></span> | <span class="t">works of Nietzsche, or all of the IMDb reviews concatenated together, or whatever, and a lot</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=1097" target="_blank">00:18:17.320</a></span> | <span class="t">of you, not surprisingly, because this is really weird at first, a lot of you didn't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=1101" target="_blank">00:18:21.520</a></span> | <span class="t">quite hear what I said correctly.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=1103" target="_blank">00:18:23.120</a></span> | <span class="t">What I said was we split this into 64 equal-sized chunks, and a lot of your brains went, "Jermi</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=1111" target="_blank">00:18:31.160</a></span> | <span class="t">just said we split this into chunks of size 64."</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=1115" target="_blank">00:18:35.000</a></span> | <span class="t">But that's not what Jermi said.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=1116" target="_blank">00:18:36.360</a></span> | <span class="t">Jermi said we split it into 64 equal-sized chunks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=1121" target="_blank">00:18:41.300</a></span> | <span class="t">So if this whole thing was length 64 million, which would be a reasonable sized corpus,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=1130" target="_blank">00:18:50.360</a></span> | <span class="t">then each of our 64 chunks would have been of length 1 million.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=1137" target="_blank">00:18:57.440</a></span> | <span class="t">And so then what we did was we took the first chunk of 1 million and we put it here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=1143" target="_blank">00:19:03.360</a></span> | <span class="t">And then we took the second chunk of 1 million and we put it here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=1146" target="_blank">00:19:06.920</a></span> | <span class="t">The third chunk of 1 million, we put it here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=1149" target="_blank">00:19:09.280</a></span> | <span class="t">And so forth to create 64 chunks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=1154" target="_blank">00:19:14.880</a></span> | <span class="t">And then each mini-batch consisted of us going, "Let's split this down here, and here, and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=1164" target="_blank">00:19:24.120</a></span> | <span class="t">here."</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=1165" target="_blank">00:19:25.120</a></span> | <span class="t">And each of these is of size BPTT, which I think we had something like 70.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=1176" target="_blank">00:19:36.640</a></span> | <span class="t">And so what happened was we said, "All right, let's look at our first mini-batch is all</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=1182" target="_blank">00:19:42.160</a></span> | <span class="t">of these."</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=1184" target="_blank">00:19:44.040</a></span> | <span class="t">So we do all of those at once and predict everything offset by 1.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=1192" target="_blank">00:19:52.320</a></span> | <span class="t">And then at the end of that first mini-batch, we went to the second chunk and used each</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=1198" target="_blank">00:19:58.000</a></span> | <span class="t">one of these to predict the next one offset by 1.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=1202" target="_blank">00:20:02.760</a></span> | <span class="t">So that's why we did that slightly weird thing, is that we wanted to have a bunch of things</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=1208" target="_blank">00:20:08.960</a></span> | <span class="t">we can look through in parallel, each of which hopefully are far enough away from each other</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=1216" target="_blank">00:20:16.240</a></span> | <span class="t">that we don't have to worry about the fact that the truth is the start of this million</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=1221" target="_blank">00:20:21.200</a></span> | <span class="t">characters was actually in the middle of a sentence, but who cares?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=1226" target="_blank">00:20:26.480</a></span> | <span class="t">Because it only happens once every million characters.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=1230" target="_blank">00:20:30.800</a></span> | <span class="t">I was wondering if you could talk a little bit more about augmentation for this kind</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=1238" target="_blank">00:20:38.880</a></span> | <span class="t">of dataset?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=1241" target="_blank">00:20:41.380</a></span> | <span class="t">Data augmentation for this kind of dataset?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=1243" target="_blank">00:20:43.080</a></span> | <span class="t">Yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=1244" target="_blank">00:20:44.080</a></span> | <span class="t">No, I can't because I don't really know a good way.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=1248" target="_blank">00:20:48.640</a></span> | <span class="t">It's one of the things I'm going to be studying between now and Part 2.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=1254" target="_blank">00:20:54.920</a></span> | <span class="t">There have been some recent developments, particularly something we talked about in the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=1259" target="_blank">00:20:59.640</a></span> | <span class="t">machine learning course, which I think we briefly mentioned here, which was somebody</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=1263" target="_blank">00:21:03.640</a></span> | <span class="t">for a recent Kaggle competition won it by doing data augmentation by randomly inserting</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=1272" target="_blank">00:21:12.240</a></span> | <span class="t">parts of different rows, basically.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=1276" target="_blank">00:21:16.640</a></span> | <span class="t">Something like that may be useful here, and I've seen some papers that do something like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=1280" target="_blank">00:21:20.680</a></span> | <span class="t">that, but I haven't seen any kind of recent-ish state-of-the-art NLP papers that are doing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=1292" target="_blank">00:21:32.240</a></span> | <span class="t">this kind of data augmentation, so it's something we're planning to work on.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=1299" target="_blank">00:21:39.000</a></span> | <span class="t">So Jeremy, how do you choose BPTT?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=1307" target="_blank">00:21:47.000</a></span> | <span class="t">So there's a couple of things to think about when you pick your BPTT.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=1309" target="_blank">00:21:49.840</a></span> | <span class="t">The first is that you'll note that the matrix size for a mini-batch has BPTT by batch size.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=1327" target="_blank">00:22:07.280</a></span> | <span class="t">So one issue is your GPU RAM needs to be able to fit that by your embedding matrix, because</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=1334" target="_blank">00:22:14.960</a></span> | <span class="t">every one of these is going to be of length embedding, plus all of the hidden state.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=1341" target="_blank">00:22:21.320</a></span> | <span class="t">So one thing is if you get a CUDA out of memory error, you need to reduce one of those.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=1349" target="_blank">00:22:29.920</a></span> | <span class="t">If your training is very unstable, like your loss is shooting off to NAN suddenly, then</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=1358" target="_blank">00:22:38.080</a></span> | <span class="t">you could try decreasing your BPTT because you've got less layers to gradient explode</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=1362" target="_blank">00:22:42.440</a></span> | <span class="t">through.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=1366" target="_blank">00:22:46.160</a></span> | <span class="t">You could try decreasing your BPTT because it's got to do one of those steps at a time,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=1371" target="_blank">00:22:51.080</a></span> | <span class="t">like that for loop can't be paralyzed.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=1377" target="_blank">00:22:57.660</a></span> | <span class="t">Well I say that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=1379" target="_blank">00:22:59.160</a></span> | <span class="t">There's a recent thing called QRNN, which we'll hopefully talk about in Part 2 which</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=1384" target="_blank">00:23:04.040</a></span> | <span class="t">kind of does paralyze it, but the versions we're looking at don't paralyze it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=1388" target="_blank">00:23:08.160</a></span> | <span class="t">So that would be the main issues, look at performance, look at memory, and look at stability,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=1393" target="_blank">00:23:13.880</a></span> | <span class="t">and try and find a number that's as high as you can make it, but all of those things</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=1399" target="_blank">00:23:19.220</a></span> | <span class="t">work for you.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=1404" target="_blank">00:23:24.680</a></span> | <span class="t">So trying to get all that chunking and lining up to work is more code than I want to write,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=1413" target="_blank">00:23:33.260</a></span> | <span class="t">so for this section we're going to go back and use Torch Text again.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=1421" target="_blank">00:23:41.880</a></span> | <span class="t">When you're using APIs like FastAI and Torch Text, which in this case these two APIs are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=1427" target="_blank">00:23:47.440</a></span> | <span class="t">designed to work together, you often have a choice which is like, okay, this API has</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=1435" target="_blank">00:23:55.320</a></span> | <span class="t">a number of methods that expect the data in this kind of format, and you can either change</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=1441" target="_blank">00:24:01.080</a></span> | <span class="t">your data to fit that format, or you can write your own data set subclass to handle the format</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=1448" target="_blank">00:24:08.240</a></span> | <span class="t">that your data is already in.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=1451" target="_blank">00:24:11.000</a></span> | <span class="t">I've noticed on the forum a lot of you are spending a lot of time writing your own data</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=1456" target="_blank">00:24:16.080</a></span> | <span class="t">set classes, whereas I am way lazier than you and I spend my time instead changing my</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=1462" target="_blank">00:24:22.040</a></span> | <span class="t">data to fit the data set classes I have.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=1465" target="_blank">00:24:25.960</a></span> | <span class="t">Either is fine, and if you realize there's a kind of a format of data that me and other</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=1474" target="_blank">00:24:34.760</a></span> | <span class="t">people are likely to be seeing quite often and it's not in the FastAI library, then by</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=1478" target="_blank">00:24:38.720</a></span> | <span class="t">all means write the data set subclass, submit it as a PR, and then everybody can benefit.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=1485" target="_blank">00:24:45.640</a></span> | <span class="t">In this case, I just thought I want to have some niche data fed into Torch Text, I'm just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=1495" target="_blank">00:24:55.400</a></span> | <span class="t">going to put it in the format that Torch Text kind of already supports.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=1498" target="_blank">00:24:58.740</a></span> | <span class="t">So Torch Text already has, or at least the FastAI wrapper around Torch Text, already</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=1503" target="_blank">00:25:03.840</a></span> | <span class="t">has something where you can have a training path and a validation path and one or more</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=1509" target="_blank">00:25:09.880</a></span> | <span class="t">text files in each path containing a bunch of stuff that's concatenated together for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=1514" target="_blank">00:25:14.400</a></span> | <span class="t">your language model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=1516" target="_blank">00:25:16.040</a></span> | <span class="t">So in this case, all I did was I made a copy of my nature file, copied it into training,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=1522" target="_blank">00:25:22.480</a></span> | <span class="t">made another copy, stuck it into the validation, and then in the training set, I deleted the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=1529" target="_blank">00:25:29.560</a></span> | <span class="t">last 20% of rows, and in the validation set, I deleted all except for the last 20% of rows.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=1537" target="_blank">00:25:37.800</a></span> | <span class="t">And I was done.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=1538" target="_blank">00:25:38.800</a></span> | <span class="t">In this case, I found that easier than writing a custom data set class.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=1544" target="_blank">00:25:44.400</a></span> | <span class="t">The other benefit of doing it that way was that I felt like it was more realistic to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=1549" target="_blank">00:25:49.240</a></span> | <span class="t">have a validation set that wasn't a random shuffled set of rows of text, but was like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=1555" target="_blank">00:25:55.880</a></span> | <span class="t">a totally separate part of the corpus, because I feel like in practice you're very often</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=1561" target="_blank">00:26:01.140</a></span> | <span class="t">going to be saying, "Oh, I've got these books or these authors I'm learning from, and then</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=1566" target="_blank">00:26:06.880</a></span> | <span class="t">I want to apply it to these different books and these different authors."</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=1570" target="_blank">00:26:10.080</a></span> | <span class="t">So I felt like getting a more realistic validation of my nature model, I should use a whole separate</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=1578" target="_blank">00:26:18.280</a></span> | <span class="t">piece of the text, so in this case it was the last 20% of the rows of the corpus.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=1585" target="_blank">00:26:25.760</a></span> | <span class="t">So I haven't created this for you intentionally, because this is the kind of stuff I want you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=1592" target="_blank">00:26:32.480</a></span> | <span class="t">practicing is making sure that you're familiar enough, comfortable enough with bash or whatever</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=1597" target="_blank">00:26:37.760</a></span> | <span class="t">you can create these, and that you understand what they need to look like and so forth.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=1603" target="_blank">00:26:43.560</a></span> | <span class="t">So in this case, you can see I've now got a train and a validation here, and then I could</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=1612" target="_blank">00:26:52.800</a></span> | <span class="t">go inside here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=1616" target="_blank">00:26:56.920</a></span> | <span class="t">So you can see I've literally just got one file in it, because when you're doing a language</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=1621" target="_blank">00:27:01.400</a></span> | <span class="t">model, i.e. predicting the next character or predicting the next word, you don't really</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=1625" target="_blank">00:27:05.680</a></span> | <span class="t">need separate files.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=1628" target="_blank">00:27:08.160</a></span> | <span class="t">It's fine if you do have separate files, but they just get concatenated together anyway.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=1634" target="_blank">00:27:14.240</a></span> | <span class="t">So that's my source data, and so here is the same lines of code that we've seen before,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=1640" target="_blank">00:27:20.720</a></span> | <span class="t">and let's go over them again because it's a couple of lessons ago.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=1643" target="_blank">00:27:23.880</a></span> | <span class="t">So in Torch Text, we create this thing called a field, and a field initially is just a description</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=1652" target="_blank">00:27:32.320</a></span> | <span class="t">of how to go about pre-processing the text.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=1656" target="_blank">00:27:36.440</a></span> | <span class="t">In this case, I'm going to say lowercase it, because I don't -- now I think about it, there's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=1663" target="_blank">00:27:43.920</a></span> | <span class="t">no particular reason to have done this lowercase, uppercase would work fine too.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=1668" target="_blank">00:27:48.400</a></span> | <span class="t">And then how do I tokenize it?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=1669" target="_blank">00:27:49.960</a></span> | <span class="t">And so you might remember last time we used a tokenization function which largely spit</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=1675" target="_blank">00:27:55.800</a></span> | <span class="t">on white space and tried to do clever things with punctuation, and that gave us the word</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=1680" target="_blank">00:28:00.160</a></span> | <span class="t">model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=1681" target="_blank">00:28:01.160</a></span> | <span class="t">In this case, I want a character model, so I actually want every character put into a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=1685" target="_blank">00:28:05.720</a></span> | <span class="t">separate token.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=1687" target="_blank">00:28:07.660</a></span> | <span class="t">So I can just use the function list in Python, because list in Python does that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=1698" target="_blank">00:28:18.320</a></span> | <span class="t">So this is where you can kind of see like, understanding how libraries like Torch Text</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=1704" target="_blank">00:28:24.780</a></span> | <span class="t">and FastAI are designed to be extended can make your life a lot easier.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=1709" target="_blank">00:28:29.900</a></span> | <span class="t">So when you realize that very often, both of these libraries kind of expect you to pass</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=1716" target="_blank">00:28:36.400</a></span> | <span class="t">a function that does something, and then you realize, oh, I can write any function I like.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=1724" target="_blank">00:28:44.680</a></span> | <span class="t">So this is now going to mean that each mini-batch is going to contain a list of characters.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=1731" target="_blank">00:28:51.480</a></span> | <span class="t">And so here's where we get to define all our different parameters.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=1736" target="_blank">00:28:56.080</a></span> | <span class="t">And so to make it the same as previous sections of this notebook, I'm going to use the same</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=1740" target="_blank">00:29:00.960</a></span> | <span class="t">batch size, the same number of characters, and I'm going to rename it to bptt since we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=1746" target="_blank">00:29:06.480</a></span> | <span class="t">know what that means.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=1749" target="_blank">00:29:09.360</a></span> | <span class="t">The number of the size of the embedding, and the size of our hidden state.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=1755" target="_blank">00:29:15.440</a></span> | <span class="t">Remembering the size of our hidden state simply means going all the way back to the start,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=1764" target="_blank">00:29:24.760</a></span> | <span class="t">and then hidden simply means the size of the state that's created by each of those orange</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=1769" target="_blank">00:29:29.960</a></span> | <span class="t">arrows.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=1770" target="_blank">00:29:30.960</a></span> | <span class="t">So it's the size of each of those circles.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=1779" target="_blank">00:29:39.240</a></span> | <span class="t">So having done that, we can then create a little dictionary saying what's our training,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=1783" target="_blank">00:29:43.440</a></span> | <span class="t">validation and test set.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=1785" target="_blank">00:29:45.080</a></span> | <span class="t">In this case, I don't have a separate test set, so I'll just use the same thing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=1789" target="_blank">00:29:49.760</a></span> | <span class="t">And then I can say I want a language model data subclass with model data, I'm going to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=1795" target="_blank">00:29:55.320</a></span> | <span class="t">grab it from text files, and this is my path, and this is my field, which I defined earlier,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=1805" target="_blank">00:30:05.360</a></span> | <span class="t">and these are my files, and these are my hyperparameters.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=1811" target="_blank">00:30:11.640</a></span> | <span class="t">MinFract is not going to do anything actually in this case because I don't think there's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=1815" target="_blank">00:30:15.120</a></span> | <span class="t">going to be any character that appears less than 3 times, so that's probably redundant.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=1822" target="_blank">00:30:22.180</a></span> | <span class="t">So at the end of that, it says there's going to be 963 batches to go through.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=1828" target="_blank">00:30:28.760</a></span> | <span class="t">And so if you think about it, that should be equal to the number of tokens divided by</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=1834" target="_blank">00:30:34.880</a></span> | <span class="t">the batch size divided by bptt, because that's the size of each of those rectangles.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=1846" target="_blank">00:30:46.120</a></span> | <span class="t">You'll find that in practice it's not exactly that, and the reason it's not exactly that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=1851" target="_blank">00:30:51.200</a></span> | <span class="t">is that the authors of TorchText did something pretty smart, which I think we've briefly</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=1857" target="_blank">00:30:57.600</a></span> | <span class="t">mentioned this before.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=1858" target="_blank">00:30:58.600</a></span> | <span class="t">They said we can't shuffle the data, like with images we like to shuffle the order so</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=1863" target="_blank">00:31:03.240</a></span> | <span class="t">every time we see them in a different order, so there's a bit more randomness.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=1866" target="_blank">00:31:06.480</a></span> | <span class="t">We can't shuffle because we need to be contiguous, but what we could do is basically randomize</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=1874" target="_blank">00:31:14.580</a></span> | <span class="t">bptt a little bit each time.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=1877" target="_blank">00:31:17.900</a></span> | <span class="t">And so that's what PyTorch does.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=1880" target="_blank">00:31:20.480</a></span> | <span class="t">It's not always going to give us exactly 8 characters long, 5% of the time it'll actually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=1887" target="_blank">00:31:27.800</a></span> | <span class="t">cut it in half, and then it's going to add on a small little standard deviation to make</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=1894" target="_blank">00:31:34.880</a></span> | <span class="t">it slightly bigger or smaller than 4 or 8.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=1897" target="_blank">00:31:37.400</a></span> | <span class="t">So it's going to be slightly different to 8 on average.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=1904" target="_blank">00:31:44.600</a></span> | <span class="t">So a mini-batch needs to do a matrix multiplication, and the mini-batch size has to remain constant</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=1928" target="_blank">00:32:08.960</a></span> | <span class="t">because we've got this h-weight matrix that has to line up in size with the size of the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=1937" target="_blank">00:32:17.880</a></span> | <span class="t">mini-batch.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=1940" target="_blank">00:32:20.720</a></span> | <span class="t">But the sequence length can change, no problem.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=1953" target="_blank">00:32:33.560</a></span> | <span class="t">So that's why we have 963, so the length of a data loader is how many mini-batches, in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=1958" target="_blank">00:32:38.920</a></span> | <span class="t">this case it's a little bit approximate.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=1961" target="_blank">00:32:41.760</a></span> | <span class="t">Number of tokens is how many unique things are in the vocabulary.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=1965" target="_blank">00:32:45.960</a></span> | <span class="t">And remember, after we run this line, text now does not just contain a description of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=1975" target="_blank">00:32:55.240</a></span> | <span class="t">what we want, but it also contains an extra attribute called vocab, which contains stuff</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=1984" target="_blank">00:33:04.040</a></span> | <span class="t">like a list of all of the unique items in the vocabulary and a reverse mapping from each</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=1995" target="_blank">00:33:15.680</a></span> | <span class="t">item to its number.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=1998" target="_blank">00:33:18.960</a></span> | <span class="t">So that text object is now an important thing to keep track of.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=2010" target="_blank">00:33:30.600</a></span> | <span class="t">Let's now try this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=2011" target="_blank">00:33:31.960</a></span> | <span class="t">Now we started out by looking at the class.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=2015" target="_blank">00:33:35.480</a></span> | <span class="t">So the class is exactly the same as the class we've had before.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=2019" target="_blank">00:33:39.120</a></span> | <span class="t">The only key difference is to call init_hidden, which sets out.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=2024" target="_blank">00:33:44.240</a></span> | <span class="t">So h is not a variable anymore, it's now an attribute, self.h is a variable containing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=2030" target="_blank">00:33:50.040</a></span> | <span class="t">a bunch of zeroes.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=2033" target="_blank">00:33:53.320</a></span> | <span class="t">Now I mentioned that batch size remains constant each time, but unfortunately when I said that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=2040" target="_blank">00:34:00.240</a></span> | <span class="t">I lied to you.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=2042" target="_blank">00:34:02.760</a></span> | <span class="t">And the way that I lied to you is that the very last mini-batch will be shorter.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=2049" target="_blank">00:34:09.960</a></span> | <span class="t">The very last mini-batch is actually going to have less than 64 -- it might be exactly</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=2054" target="_blank">00:34:14.080</a></span> | <span class="t">the right size if it so happens that this data set is exactly divisible by bptt times</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=2059" target="_blank">00:34:19.800</a></span> | <span class="t">batch size.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=2060" target="_blank">00:34:20.800</a></span> | <span class="t">But it probably isn't, so the last batch will probably have a little bit less.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=2066" target="_blank">00:34:26.320</a></span> | <span class="t">And so that's why I do a little check here that says let's check that the batch size</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=2071" target="_blank">00:34:31.000</a></span> | <span class="t">inside self.h is going to be the height, the number of activations, and the width is going</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=2085" target="_blank">00:34:45.560</a></span> | <span class="t">to be the mini-batch size.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=2088" target="_blank">00:34:48.080</a></span> | <span class="t">Check that that's equal to the actual batch size length that we've received.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=2098" target="_blank">00:34:58.160</a></span> | <span class="t">And if they're not the same, then set it back to zeroes again.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=2103" target="_blank">00:35:03.120</a></span> | <span class="t">So this is just a minor little ring call that basically at the end of each epoch, it's going</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=2108" target="_blank">00:35:08.200</a></span> | <span class="t">to do like a little mini-batch.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=2112" target="_blank">00:35:12.600</a></span> | <span class="t">And so then as soon as it starts the next epoch, it's going to see that they're not</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=2116" target="_blank">00:35:16.360</a></span> | <span class="t">the same again, and it will reinitialize it to the correct full batch size.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=2120" target="_blank">00:35:20.960</a></span> | <span class="t">So that's why if you're wondering, there's an init hidden not just in the constructor,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=2126" target="_blank">00:35:26.240</a></span> | <span class="t">but also inside forward, it's to handle this end of each epoch, start of each epoch difference.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=2134" target="_blank">00:35:34.680</a></span> | <span class="t">Not an important point by any means, but potentially confusing when you see it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=2144" target="_blank">00:35:44.320</a></span> | <span class="t">So the last ring call.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=2147" target="_blank">00:35:47.640</a></span> | <span class="t">The last ring call is something that slightly sucks about PyTorch, and maybe somebody can</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=2155" target="_blank">00:35:55.000</a></span> | <span class="t">be nice enough to try and fix it with a PR if anybody feels like it, which is that the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=2160" target="_blank">00:36:00.400</a></span> | <span class="t">loss functions such as softmax are not happy receiving a rank 3 tensor.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=2170" target="_blank">00:36:10.040</a></span> | <span class="t">Remember a rank 3 tensor is just another way of saying a dimension 3 array.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=2177" target="_blank">00:36:17.040</a></span> | <span class="t">There's no particular reason they ought to not be happy receiving a rank 3 tensor.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=2181" target="_blank">00:36:21.520</a></span> | <span class="t">Like somebody could write some code to say hey, a rank 3 tensor is probably a sequence</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=2185" target="_blank">00:36:25.960</a></span> | <span class="t">length by batch size by results thing, and so you should just do it for each of the two</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=2196" target="_blank">00:36:36.280</a></span> | <span class="t">initial axes.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=2197" target="_blank">00:36:37.280</a></span> | <span class="t">But no one's done that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=2199" target="_blank">00:36:39.920</a></span> | <span class="t">And so it expects it to be a rank 2 tensor.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=2202" target="_blank">00:36:42.920</a></span> | <span class="t">Funnily enough, it can handle rank 2 or rank 4, but not rank 3.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=2209" target="_blank">00:36:49.640</a></span> | <span class="t">So we've got a rank 2 tensor containing, for each time</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=2224" target="_blank">00:37:04.920</a></span> | <span class="t">period (I can't remember which way around the axes are, but whatever) for each time</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=2231" target="_blank">00:37:11.340</a></span> | <span class="t">period for each batch, we've got our predictions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=2239" target="_blank">00:37:19.920</a></span> | <span class="t">And then we've got our actuals for each time period for each batch, we've got our predictions,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=2251" target="_blank">00:37:31.260</a></span> | <span class="t">and we've got our actuals.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=2253" target="_blank">00:37:33.800</a></span> | <span class="t">And so we just want to check whether they're the same.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=2256" target="_blank">00:37:36.400</a></span> | <span class="t">And so in an ideal world, our loss function would check item 1 1, then item 1 2, and then</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=2262" target="_blank">00:37:42.320</a></span> | <span class="t">item 1 3, but since that hasn't been written, we just have to flatten them both out.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=2268" target="_blank">00:37:48.320</a></span> | <span class="t">We can literally just flatten them out, put rows to rows.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=2273" target="_blank">00:37:53.160</a></span> | <span class="t">And so that's why here I have to use .view, and so .view says the number of columns will</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=2284" target="_blank">00:38:04.800</a></span> | <span class="t">be equal to the size of the vocab, because remember we're going to end up with a probability</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=2289" target="_blank">00:38:09.560</a></span> | <span class="t">for each letter.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=2291" target="_blank">00:38:11.120</a></span> | <span class="t">And then the number of rows is however big is necessary, which will be equal to batch</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=2295" target="_blank">00:38:15.960</a></span> | <span class="t">size times bptt.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=2302" target="_blank">00:38:22.780</a></span> | <span class="t">And then you may be wondering where I do that for the target, and the answer is torch text</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=2311" target="_blank">00:38:31.000</a></span> | <span class="t">knows that the target needs to look like that, so torch text has already done that for us.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=2315" target="_blank">00:38:35.840</a></span> | <span class="t">So torch text automatically changes the target to be flattened out.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=2320" target="_blank">00:38:40.320</a></span> | <span class="t">And you might actually remember if you go back to lesson 4 when we actually looked at</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=2325" target="_blank">00:38:45.920</a></span> | <span class="t">a mini-batch that spat out of torch text, we noticed actually that it was flattened, and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=2331" target="_blank">00:38:51.640</a></span> | <span class="t">I said we'll learn about why later, and so later is now arrived.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=2338" target="_blank">00:38:58.600</a></span> | <span class="t">So there are the 3 wrinkles.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=2341" target="_blank">00:39:01.000</a></span> | <span class="t">Get rid of the history, I guess 4 wrinkles.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=2349" target="_blank">00:39:09.080</a></span> | <span class="t">Recreate the hidden state if the batch size changes, flatten out, and then use torch text</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=2359" target="_blank">00:39:19.100</a></span> | <span class="t">to create mini-batches that line up nicely.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=2362" target="_blank">00:39:22.200</a></span> | <span class="t">So once we do those things, we can then create our model, create our optimizer with that model's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=2370" target="_blank">00:39:30.720</a></span> | <span class="t">parameters, and fit it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=2378" target="_blank">00:39:38.600</a></span> | <span class="t">One thing to be careful of here is that softmax now, as of PyTorch 0.3, requires that we pass</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=2396" target="_blank">00:39:56.000</a></span> | <span class="t">in a number here saying which axis do we want to do the softmax over.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=2403" target="_blank">00:40:03.040</a></span> | <span class="t">So at this point, this is a 3-dimensional tensor, and so we want to do the softmax over</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=2410" target="_blank">00:40:10.160</a></span> | <span class="t">the final axis.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=2411" target="_blank">00:40:11.160</a></span> | <span class="t">So when I say which axis do we do the softmax over, remember we divide by, so we go e to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=2417" target="_blank">00:40:17.840</a></span> | <span class="t">the x_i divided by the sum of e to the x_i.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=2421" target="_blank">00:40:21.400</a></span> | <span class="t">So it's saying which axis do we sum over, so which axis do we want to sum to 1.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=2426" target="_blank">00:40:26.520</a></span> | <span class="t">And so in this case, clearly we want to do it over the last axis, because the last axis</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=2431" target="_blank">00:40:31.200</a></span> | <span class="t">is the one that contains the probability per letter of the alphabet, and we want all of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=2436" target="_blank">00:40:36.360</a></span> | <span class="t">those probabilities to sum to 1.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=2440" target="_blank">00:40:40.880</a></span> | <span class="t">So therefore, to run this notebook, you're going to need PyTorch 0.3, which just came</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=2448" target="_blank">00:40:48.600</a></span> | <span class="t">out this week.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=2450" target="_blank">00:40:50.040</a></span> | <span class="t">So if you're doing this on the MOOC, you're fine, I'm sure you've got at least 0.3 or later.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=2455" target="_blank">00:40:55.200</a></span> | <span class="t">Where else are the students here?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=2462" target="_blank">00:41:02.760</a></span> | <span class="t">The really great news is that 0.3, although it does not yet officially support Windows,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=2469" target="_blank">00:41:09.920</a></span> | <span class="t">it does in practice.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=2471" target="_blank">00:41:11.000</a></span> | <span class="t">I successfully installed 0.3 from Conda yesterday by typing Conda install PyTorch in Windows.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=2478" target="_blank">00:41:18.520</a></span> | <span class="t">I then attempted to use the entirety of Lesson 1, and every single part worked.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=2483" target="_blank">00:41:23.720</a></span> | <span class="t">So I actually ran it on this very laptop.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=2487" target="_blank">00:41:27.520</a></span> | <span class="t">So for those who are interested in doing deep learning on their laptop, I can definitely</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=2492" target="_blank">00:41:32.280</a></span> | <span class="t">recommend the New Surface Book.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=2496" target="_blank">00:41:36.000</a></span> | <span class="t">The New Surface Book 15" has a GTX 1060 6GB GPU in it, and it was running about 3 times</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=2507" target="_blank">00:41:47.800</a></span> | <span class="t">slower than my 1080Ti, which I think means it's about the same speed as an AWS P2 instance.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=2520" target="_blank">00:42:00.360</a></span> | <span class="t">And as you can see, it's also a nice convertible tablet that you can write on, and it's thin</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=2525" target="_blank">00:42:05.240</a></span> | <span class="t">and light, so I've never seen such a good deep learning box.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=2531" target="_blank">00:42:11.160</a></span> | <span class="t">Also I successfully installed Linux on it, and all of the fastai stuff worked on the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=2536" target="_blank">00:42:16.920</a></span> | <span class="t">Linux as well, so a really good option if you're interested in a laptop that can run</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=2542" target="_blank">00:42:22.960</a></span> | <span class="t">deep learning stuff.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=2547" target="_blank">00:42:27.720</a></span> | <span class="t">So that's going to be aware of with this dm= -1.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=2551" target="_blank">00:42:31.840</a></span> | <span class="t">So then we can go ahead and construct this, and we can call fit, and we're basically going</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=2557" target="_blank">00:42:37.520</a></span> | <span class="t">to get pretty similar results to what we got before.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=2565" target="_blank">00:42:45.120</a></span> | <span class="t">So then we can go a bit further with our RNN by just unpacking it a bit more.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=2574" target="_blank">00:42:54.000</a></span> | <span class="t">And so this is now exactly the same thing, gives exactly the same answers, but I have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=2579" target="_blank">00:42:59.240</a></span> | <span class="t">removed the call to RNN.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=2582" target="_blank">00:43:02.960</a></span> | <span class="t">So I've got rid of this self.RNN.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=2588" target="_blank">00:43:08.300</a></span> | <span class="t">And so this is just something, I won't spend time on it, but you can check it out.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=2592" target="_blank">00:43:12.280</a></span> | <span class="t">So instead, I've now defined RNN as RNN cell, and I've copied and pasted the code above.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=2598" target="_blank">00:43:18.880</a></span> | <span class="t">Don't run it, this is just for your reference, from PyTorch.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=2602" target="_blank">00:43:22.640</a></span> | <span class="t">This is the definition of RNN cell in PyTorch.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=2606" target="_blank">00:43:26.040</a></span> | <span class="t">And I want you to see that you can now read PyTorch source code and understand it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=2611" target="_blank">00:43:31.980</a></span> | <span class="t">Not only that, you'll recognize it as something we've done before.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=2615" target="_blank">00:43:35.040</a></span> | <span class="t">It's a matrix multiplication of the weights by the inputs plus biases.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=2621" target="_blank">00:43:41.400</a></span> | <span class="t">So f.linear simply does a matrix product followed by an addition.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=2626" target="_blank">00:43:46.940</a></span> | <span class="t">And interestingly, you'll see they do not concatenate the input bit and the hidden bit,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=2635" target="_blank">00:43:55.080</a></span> | <span class="t">they sum them together, which is our first approach.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=2639" target="_blank">00:43:59.480</a></span> | <span class="t">As I said, you can do either, neither one is right or wrong, but it's interesting to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=2643" target="_blank">00:44:03.120</a></span> | <span class="t">see that this is the definition here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=2645" target="_blank">00:44:05.520</a></span> | <span class="t">Can you give us an insight about what are they using that particular activation function?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=2654" target="_blank">00:44:14.800</a></span> | <span class="t">I think we might have briefly covered this last week, but very happy to do it again if</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=2663" target="_blank">00:44:23.000</a></span> | <span class="t">I did.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=2664" target="_blank">00:44:24.680</a></span> | <span class="t">Basically, than looks like that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=2679" target="_blank">00:44:39.080</a></span> | <span class="t">So in other words, it's a sigmoid function, double the height -1, literally, they're equal.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=2687" target="_blank">00:44:47.720</a></span> | <span class="t">So it's a nice function in that it's forcing it to be no smaller than -1, no bigger than</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=2696" target="_blank">00:44:56.120</a></span> | <span class="t">+1.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=2697" target="_blank">00:44:57.220</a></span> | <span class="t">And since we're multiplying by this weight matrix again and again and again and again,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=2703" target="_blank">00:45:03.040</a></span> | <span class="t">we might worry that a ReLU, because it's unbounded, might have more of a gradient explosion problem.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=2710" target="_blank">00:45:10.920</a></span> | <span class="t">That's basically the theory.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=2712" target="_blank">00:45:12.600</a></span> | <span class="t">Having said that, you can actually ask PyTorch for an RNN cell which uses a different nonlinearity.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=2725" target="_blank">00:45:25.240</a></span> | <span class="t">So you can see by default it uses than, but you can ask for a ReLU as well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=2730" target="_blank">00:45:30.560</a></span> | <span class="t">But most people seem to, pretty much everybody still seems to use than as far as I can tell.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=2737" target="_blank">00:45:37.260</a></span> | <span class="t">So you can basically see here, this is all the same except now I've got an RNN cell,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=2741" target="_blank">00:45:41.120</a></span> | <span class="t">which means now I need to put my for loop back.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=2744" target="_blank">00:45:44.280</a></span> | <span class="t">And you can see every time I call my little linear function, I just append the result onto</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=2752" target="_blank">00:45:52.880</a></span> | <span class="t">my list.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=2753" target="_blank">00:45:53.880</a></span> | <span class="t">And at the end, the result is that all stacked up together.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=2759" target="_blank">00:45:59.320</a></span> | <span class="t">So I'm just trying to show you how nothing inside PyTorch is mysterious, you should find</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=2766" target="_blank">00:46:06.360</a></span> | <span class="t">you get basically exactly the same answer from this as the previous one.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=2773" target="_blank">00:46:13.720</a></span> | <span class="t">In practice you would never write it like this, but what you may well find in practice</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=2777" target="_blank">00:46:17.780</a></span> | <span class="t">is that somebody will come up with a new kind of RNN cell, or a different way of keeping</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=2783" target="_blank">00:46:23.440</a></span> | <span class="t">track of things over time, or a different way of doing regularization.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=2787" target="_blank">00:46:27.080</a></span> | <span class="t">And so inside fastai's code, you will find that we do this by hand because we use some</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=2798" target="_blank">00:46:38.960</a></span> | <span class="t">regularization approaches that aren't supported by PyTorch.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=2805" target="_blank">00:46:45.400</a></span> | <span class="t">So another thing I'm not going to spend much time on but I'll mention briefly is that nobody</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=2810" target="_blank">00:46:50.720</a></span> | <span class="t">really uses this RNN cell in practice.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=2814" target="_blank">00:46:54.480</a></span> | <span class="t">And the reason we don't use that RNN cell in practice is even though the than is here,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=2820" target="_blank">00:47:00.420</a></span> | <span class="t">you do tend to find gradient explosions are still a problem, so we have to use pretty</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=2826" target="_blank">00:47:06.400</a></span> | <span class="t">low learning rates to get these to train, and pretty small values for bptt to get them</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=2833" target="_blank">00:47:13.400</a></span> | <span class="t">to train.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=2835" target="_blank">00:47:15.640</a></span> | <span class="t">So what we do instead is we replace the RNN cell with something like this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=2841" target="_blank">00:47:21.280</a></span> | <span class="t">This is called a GRU cell, and here's a picture of it, and there's the equations for it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=2858" target="_blank">00:47:38.320</a></span> | <span class="t">So basically I'll show you both quickly, but we'll talk about it much more in Part 2.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=2864" target="_blank">00:47:44.200</a></span> | <span class="t">We've got our input, and our input normally gets multiplied by a weight matrix to create</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=2877" target="_blank">00:47:57.080</a></span> | <span class="t">our new activations.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=2880" target="_blank">00:48:00.400</a></span> | <span class="t">That's not what happens, and then of course we add it to the existing activations.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=2886" target="_blank">00:48:06.600</a></span> | <span class="t">That's not what happens here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=2887" target="_blank">00:48:07.720</a></span> | <span class="t">In this case, our input goes into this h_tilde temporary thing, and it doesn't just get added</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=2896" target="_blank">00:48:16.000</a></span> | <span class="t">to our previous activations, but our previous activations get multiplied by this value R.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=2904" target="_blank">00:48:24.080</a></span> | <span class="t">And R stands for reset, it's a reset gate.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=2909" target="_blank">00:48:29.240</a></span> | <span class="t">And how do we calculate this value, it goes between 0 and 1 in our reset gate?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=2915" target="_blank">00:48:35.760</a></span> | <span class="t">Well the answer is, it's simply equal to a matrix product between some weight matrix</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=2922" target="_blank">00:48:42.280</a></span> | <span class="t">and the concatenation of our previous hidden state and our new input.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=2927" target="_blank">00:48:47.600</a></span> | <span class="t">In other words, this is a little one hidden layer neural net.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=2932" target="_blank">00:48:52.920</a></span> | <span class="t">And in particular it's a one hidden layer neural net because we then put it through</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=2936" target="_blank">00:48:56.360</a></span> | <span class="t">the sigmoid function.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=2938" target="_blank">00:48:58.760</a></span> | <span class="t">One of the things I hate about mathematical notation is symbols are overloaded a lot.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=2943" target="_blank">00:49:03.800</a></span> | <span class="t">When you see sigma, that means standard deviation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=2946" target="_blank">00:49:06.640</a></span> | <span class="t">When you see it next to a parenthesis like this, it means the sigmoid function.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=2951" target="_blank">00:49:11.440</a></span> | <span class="t">So in other words, that which looks like that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=2966" target="_blank">00:49:26.120</a></span> | <span class="t">So this is like a little mini-neuronet with no hidden layers, so to think of it another</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=2969" target="_blank">00:49:29.780</a></span> | <span class="t">way is like a little logistic regression.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=2972" target="_blank">00:49:32.640</a></span> | <span class="t">And I mentioned this briefly because it's going to come up a lot in part 2, so it's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=2977" target="_blank">00:49:37.360</a></span> | <span class="t">a good thing to start learning about.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=2979" target="_blank">00:49:39.440</a></span> | <span class="t">It's this idea that in the very learning itself, you can have little mini-neuronets inside</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=2987" target="_blank">00:49:47.020</a></span> | <span class="t">your neural nets.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=2988" target="_blank">00:49:48.840</a></span> | <span class="t">And so this little mini-neuronet is going to be used to decide how much of my hidden</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=2994" target="_blank">00:49:54.920</a></span> | <span class="t">state am I going to remember.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=2997" target="_blank">00:49:57.320</a></span> | <span class="t">And so it might learn that in this particular situation, forget everything you know.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3002" target="_blank">00:50:02.640</a></span> | <span class="t">For example, there's a full stop.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3004" target="_blank">00:50:04.600</a></span> | <span class="t">When you see a full stop, you should throw away nearly all of your hidden state.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3009" target="_blank">00:50:09.800</a></span> | <span class="t">That is probably something it would learn, and that's very easy for it to learn using</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3013" target="_blank">00:50:13.960</a></span> | <span class="t">this little mini-neuronet.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3016" target="_blank">00:50:16.200</a></span> | <span class="t">And so that goes through to create my new hidden state along with the input.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3022" target="_blank">00:50:22.040</a></span> | <span class="t">And then there's a second thing that happens, which is there's this gate here called z.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3027" target="_blank">00:50:27.200</a></span> | <span class="t">And what z says is you've got some amount of your previous hidden state plus your new</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3034" target="_blank">00:50:34.240</a></span> | <span class="t">input, and it's going to go through to create your new state.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3038" target="_blank">00:50:38.880</a></span> | <span class="t">And I'm going to let you decide to what degree do you use this new input version of your</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3045" target="_blank">00:50:45.760</a></span> | <span class="t">hidden state, and to what degree will you just leave the hidden state the same as before.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3050" target="_blank">00:50:50.300</a></span> | <span class="t">So this thing here is called the update gate.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3053" target="_blank">00:50:53.080</a></span> | <span class="t">And so it's got two choices it can make.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3054" target="_blank">00:50:54.920</a></span> | <span class="t">The first is to throw away some hidden state when deciding how much to incorporate that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3059" target="_blank">00:50:59.800</a></span> | <span class="t">versus my new input, and how much to update my hidden state versus just leave it exactly</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3065" target="_blank">00:51:05.880</a></span> | <span class="t">the same.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3067" target="_blank">00:51:07.580</a></span> | <span class="t">And the equation hopefully is going to look pretty familiar to you, which is check this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3073" target="_blank">00:51:13.080</a></span> | <span class="t">out here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3074" target="_blank">00:51:14.080</a></span> | <span class="t">Remember how I said you want to start to recognize some common ways of looking at things?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3081" target="_blank">00:51:21.120</a></span> | <span class="t">Well here I have a 1 minus something by a thing, and a something without the 1 minus</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3090" target="_blank">00:51:30.080</a></span> | <span class="t">by a thing, which remember is a linear interpolation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3095" target="_blank">00:51:35.120</a></span> | <span class="t">So in other words, the value of z is going to decide to what degree do I have keep the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3102" target="_blank">00:51:42.680</a></span> | <span class="t">previous hidden state, and to what degree do I use the new hidden state.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3108" target="_blank">00:51:48.800</a></span> | <span class="t">So that's why they draw it here as this kind of like, it's not actually a switch, but you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3115" target="_blank">00:51:55.480</a></span> | <span class="t">can put it in any position.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3116" target="_blank">00:51:56.880</a></span> | <span class="t">You can be like, oh it's here, or it's here, or it's here to decide how much to update.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3124" target="_blank">00:52:04.800</a></span> | <span class="t">So they're basically the equations.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3126" target="_blank">00:52:06.520</a></span> | <span class="t">It's a little mini-neuronet with its own weight matrix to decide how much to update, a little</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3130" target="_blank">00:52:10.520</a></span> | <span class="t">mini-neuronet with its own weight matrix to decide how much to reset, and then that's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3134" target="_blank">00:52:14.520</a></span> | <span class="t">used to do an interpolation between the two hidden states.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3138" target="_blank">00:52:18.440</a></span> | <span class="t">So that's called a GRU, gated recurrent network.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3144" target="_blank">00:52:24.600</a></span> | <span class="t">There's the definition from the PyTorch source code.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3148" target="_blank">00:52:28.440</a></span> | <span class="t">They have some slight optimizations here that if you're interested in we can talk about</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3152" target="_blank">00:52:32.560</a></span> | <span class="t">them on the forum, but it's exactly the same formula we just saw.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3158" target="_blank">00:52:38.580</a></span> | <span class="t">And so if you go nn.giu, then it uses this same code, but it replaces the RNN cell with</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3167" target="_blank">00:52:47.760</a></span> | <span class="t">this cell.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3169" target="_blank">00:52:49.560</a></span> | <span class="t">And as a result, rather than having something where we're getting a 1.54, we're now getting</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3179" target="_blank">00:52:59.600</a></span> | <span class="t">down to 1.40, and we can keep training even more, get right down to 1.36.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3185" target="_blank">00:53:05.640</a></span> | <span class="t">So in practice, a GRU, or very nearly equivalently, we'll see in a moment, an LSTM, is in practice</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3192" target="_blank">00:53:12.440</a></span> | <span class="t">what pretty much everybody always uses.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3196" target="_blank">00:53:16.780</a></span> | <span class="t">So the RT and HT are ultimately scalars after they go through the sigmoid, but they're applied</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3205" target="_blank">00:53:25.600</a></span> | <span class="t">element-wise.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3206" target="_blank">00:53:26.600</a></span> | <span class="t">Is that correct?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3207" target="_blank">00:53:27.600</a></span> | <span class="t">Yes, although of course one for each mini-batch.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3222" target="_blank">00:53:42.880</a></span> | <span class="t">On the excellent Chris Olar's blog, there's an understanding LSTM networks post, which</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3230" target="_blank">00:53:50.840</a></span> | <span class="t">you can read all about this in much more detail if you're interested.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3234" target="_blank">00:53:54.600</a></span> | <span class="t">And also, the other one I was dealing with here is WildML, I also have a good blog post</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3239" target="_blank">00:53:59.280</a></span> | <span class="t">on this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3240" target="_blank">00:54:00.280</a></span> | <span class="t">If somebody wants to be helpful, feel free to put them in the lesson wiki.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3249" target="_blank">00:54:09.960</a></span> | <span class="t">So then putting it all together, I'm now going to replace my GRU with an LSTM.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3256" target="_blank">00:54:16.040</a></span> | <span class="t">I'm not going to bother showing you the cell for this, it's very similar to GRU.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3260" target="_blank">00:54:20.240</a></span> | <span class="t">But the LSTM has one more piece of state in it called the cell state, not just the hidden</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3266" target="_blank">00:54:26.200</a></span> | <span class="t">state.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3267" target="_blank">00:54:27.200</a></span> | <span class="t">So if you do use an LSTM, you now inside your init_hidden have to return a tuple of matrices.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3273" target="_blank">00:54:33.720</a></span> | <span class="t">They're exactly the same size as the hidden state, but you just have to return the tuple.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3280" target="_blank">00:54:40.080</a></span> | <span class="t">The details don't matter too much, but we can talk about it during the week if you're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3284" target="_blank">00:54:44.120</a></span> | <span class="t">interested.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3287" target="_blank">00:54:47.760</a></span> | <span class="t">When you pass in, you still pass in self.h, it still returns a new value of h, you still</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3292" target="_blank">00:54:52.080</a></span> | <span class="t">can repackage it in the usual way.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3294" target="_blank">00:54:54.020</a></span> | <span class="t">So this code is identical to the code before.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3297" target="_blank">00:54:57.400</a></span> | <span class="t">One thing I've done though is I've added dropout inside my RNN, which you can do with the PyTorch</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3305" target="_blank">00:55:05.000</a></span> | <span class="t">RNN function, so that's going to do dropout after each time step.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3309" target="_blank">00:55:09.680</a></span> | <span class="t">And I've doubled the size of my hidden layer since I've now added 0.5 dropout, and so my</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3314" target="_blank">00:55:14.400</a></span> | <span class="t">hope was that this would be able to learn more but be more resilient as it does so.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3324" target="_blank">00:55:24.440</a></span> | <span class="t">So then I wanted to show you how to take advantage of a little bit more fast.ai magic without</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3333" target="_blank">00:55:33.360</a></span> | <span class="t">using the layer class.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3335" target="_blank">00:55:35.400</a></span> | <span class="t">And so I'm going to show you how to use callbacks, and specifically we're going to do SGDR without</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3345" target="_blank">00:55:45.600</a></span> | <span class="t">using the learner class.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3347" target="_blank">00:55:47.760</a></span> | <span class="t">So to do that, we create our model again, just a standard PyTorch model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3352" target="_blank">00:55:52.680</a></span> | <span class="t">And this time, rather than going, remember the usual PyTorch approach is opt=optim.atom</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3360" target="_blank">00:56:00.200</a></span> | <span class="t">and you pass in the parameters and the learning rate, I'm not going to do that, I'm going to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3364" target="_blank">00:56:04.400</a></span> | <span class="t">use the fast.ai layer optimizer class, which takes my optim class constructor from PyTorch.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3376" target="_blank">00:56:16.360</a></span> | <span class="t">It takes my model, it takes my learning rate, and optionally takes weight decay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3384" target="_blank">00:56:24.720</a></span> | <span class="t">And so this class is tiny, it doesn't do very much at all.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3389" target="_blank">00:56:29.700</a></span> | <span class="t">The key reason it exists is to do differential learning rates and differential weight decay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3395" target="_blank">00:56:35.960</a></span> | <span class="t">But the reason we need to use it is that all of the mechanics inside fast.ai assumes that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3401" target="_blank">00:56:41.720</a></span> | <span class="t">you have one of these.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3403" target="_blank">00:56:43.300</a></span> | <span class="t">So if you want to use callbacks or SGDR or whatever in code where you're not using the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3410" target="_blank">00:56:50.040</a></span> | <span class="t">learner class, then you need to use, rather than saying opt=optim.atom, and here's my</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3416" target="_blank">00:56:56.840</a></span> | <span class="t">parameters, you instead say layer optimizer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3423" target="_blank">00:57:03.440</a></span> | <span class="t">So that gives us a layer optimizer object, and if you're interested, basically behind</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3429" target="_blank">00:57:09.840</a></span> | <span class="t">the scenes, you can now grab a .opt property which actually gives you the optimizer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3440" target="_blank">00:57:20.160</a></span> | <span class="t">You don't have to worry about that yourself, but that's basically what happens behind the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3443" target="_blank">00:57:23.240</a></span> | <span class="t">scenes.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3444" target="_blank">00:57:24.240</a></span> | <span class="t">The key thing we can now do is that when we call fit, we can pass in that optimizer, and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3453" target="_blank">00:57:33.640</a></span> | <span class="t">we can also pass in some callbacks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3456" target="_blank">00:57:36.240</a></span> | <span class="t">And specifically we're going to use the cosine annealing callback.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3461" target="_blank">00:57:41.940</a></span> | <span class="t">And so the cosine annealing callback requires a layer optimizer object.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3467" target="_blank">00:57:47.560</a></span> | <span class="t">And so what this is going to do is it's going to do cosine annealing by changing the learning</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3472" target="_blank">00:57:52.160</a></span> | <span class="t">rate inside this object.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3477" target="_blank">00:57:57.000</a></span> | <span class="t">So the details are terribly important, we can talk about them on the forum, it's really</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3481" target="_blank">00:58:01.120</a></span> | <span class="t">the concept I wanted to get across here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3483" target="_blank">00:58:03.800</a></span> | <span class="t">Which is that now that we've done this, we can say create a cosine annealing callback</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3489" target="_blank">00:58:09.120</a></span> | <span class="t">which is going to update the learning rates in this layer optimizer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3494" target="_blank">00:58:14.560</a></span> | <span class="t">The length of an epoch is equal to this here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3498" target="_blank">00:58:18.220</a></span> | <span class="t">How many mini batches are there in an epoch?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3500" target="_blank">00:58:20.920</a></span> | <span class="t">Well it's whatever the length of this data loader is, because it's going to be doing the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3505" target="_blank">00:58:25.680</a></span> | <span class="t">cosine annealing, it needs to know how often to reset.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3511" target="_blank">00:58:31.480</a></span> | <span class="t">And then you can pass in the cycle melt in the usual way.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3514" target="_blank">00:58:34.800</a></span> | <span class="t">And then we can even save our model automatically, like remember how there was that cycle save</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3521" target="_blank">00:58:41.760</a></span> | <span class="t">name parameter that we can pass to learn.fit?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3525" target="_blank">00:58:45.080</a></span> | <span class="t">This is what it does behind the scenes.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3526" target="_blank">00:58:46.480</a></span> | <span class="t">It sets an on-cycle end callback, and so here I have to find that callback as being something</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3533" target="_blank">00:58:53.600</a></span> | <span class="t">that saves my model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3537" target="_blank">00:58:57.080</a></span> | <span class="t">So there's quite a lot of cool stuff that you can do with callbacks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3542" target="_blank">00:59:02.400</a></span> | <span class="t">Callbacks are basically things where you can define at the start of training, or at the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3546" target="_blank">00:59:06.320</a></span> | <span class="t">start of an epoch, or at the start of a batch, or at the end of training, or at the end of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3549" target="_blank">00:59:09.920</a></span> | <span class="t">an epoch, or at the end of a batch, please call this code.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3553" target="_blank">00:59:13.640</a></span> | <span class="t">And so we've written some for you, including SGDR, which is the cosine annealing callback.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3561" target="_blank">00:59:21.760</a></span> | <span class="t">And then Sahar recently wrote a new callback to implement the new approach to decoupled</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3566" target="_blank">00:59:26.820</a></span> | <span class="t">rate decay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3568" target="_blank">00:59:28.760</a></span> | <span class="t">We use callbacks to draw those little graphs of the loss of a time, so there's lots of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3574" target="_blank">00:59:34.880</a></span> | <span class="t">cool stuff you can do with callbacks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3576" target="_blank">00:59:36.600</a></span> | <span class="t">So in this case, by passing in that callback, we're getting SGDR, and that's able to get</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3583" target="_blank">00:59:43.480</a></span> | <span class="t">us down to 1.31 here, and then we can train a little bit more, and eventually get down</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3593" target="_blank">00:59:53.200</a></span> | <span class="t">to 1.25.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3595" target="_blank">00:59:55.340</a></span> | <span class="t">And so we can now test that out.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3599" target="_blank">00:59:59.520</a></span> | <span class="t">And so if we pass in a few characters of text, we get not surprisingly an e after 4 or thus.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3607" target="_blank">01:00:07.160</a></span> | <span class="t">Let's do then 400, and now we have our own Nietzsche.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3612" target="_blank">01:00:12.700</a></span> | <span class="t">So Nietzsche tends to start his sections with a number and a dot.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3615" target="_blank">01:00:15.600</a></span> | <span class="t">So 293, perhaps that every life of values of blood, of intercourse, when it senses there</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3622" target="_blank">01:00:22.000</a></span> | <span class="t">is unscrupulous, his very rights and still impulse love.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3625" target="_blank">01:00:25.920</a></span> | <span class="t">So it's slightly less clear than Nietzsche normally, but it gets the tone right.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3633" target="_blank">01:00:33.240</a></span> | <span class="t">And it's actually quite interesting to play around with training these character-based</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3639" target="_blank">01:00:39.220</a></span> | <span class="t">language models, to run this at different levels of loss, to get a sense of what does</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3645" target="_blank">01:00:45.160</a></span> | <span class="t">it look like.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3646" target="_blank">01:00:46.160</a></span> | <span class="t">You really notice that this is like 1.25, and at slightly worse, like 1.3, this looks</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3655" target="_blank">01:00:55.880</a></span> | <span class="t">like total junk.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3657" target="_blank">01:00:57.440</a></span> | <span class="t">There's punctuation in random places and nothing makes sense.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3662" target="_blank">01:01:02.560</a></span> | <span class="t">And you start to realize that the difference between Nietzsche and random junk is not that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3669" target="_blank">01:01:09.040</a></span> | <span class="t">far in language model terms.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3672" target="_blank">01:01:12.120</a></span> | <span class="t">And so if you train this for a little bit longer, you'll suddenly find it's making more</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3676" target="_blank">01:01:16.640</a></span> | <span class="t">and more sense.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3678" target="_blank">01:01:18.360</a></span> | <span class="t">So if you are playing around with NLP stuff, particularly generative stuff like this, and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3684" target="_blank">01:01:24.000</a></span> | <span class="t">you're like, the results are kind of okay but not great, don't be disheartened because</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3690" target="_blank">01:01:30.600</a></span> | <span class="t">that means you're actually very very nearly there.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3693" target="_blank">01:01:33.520</a></span> | <span class="t">The difference between something which is starting to create something which almost</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3697" target="_blank">01:01:37.880</a></span> | <span class="t">vaguely looks English if you squint, and something that's actually a very good generation, it's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3704" target="_blank">01:01:44.400</a></span> | <span class="t">not far in loss function terms.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3708" target="_blank">01:01:48.800</a></span> | <span class="t">So let's take a 5-minute break, we'll come back at 7.45 and we're going to go back to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3712" target="_blank">01:01:52.800</a></span> | <span class="t">computer vision.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3720" target="_blank">01:02:00.920</a></span> | <span class="t">So now we come full circle back to vision.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3729" target="_blank">01:02:09.660</a></span> | <span class="t">So now we're looking at lesson 7, sci-fi 10 notebook.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3738" target="_blank">01:02:18.140</a></span> | <span class="t">You might have heard of sci-fi 10.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3740" target="_blank">01:02:20.280</a></span> | <span class="t">It's a really well-known dataset in academia.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3744" target="_blank">01:02:24.480</a></span> | <span class="t">And it's actually pretty old by computer vision standards, well before ImageNet was around,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3753" target="_blank">01:02:33.560</a></span> | <span class="t">there was sci-fi 10.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3754" target="_blank">01:02:34.760</a></span> | <span class="t">You might wonder why we're going to be looking at such an old dataset, and actually I think</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3761" target="_blank">01:02:41.080</a></span> | <span class="t">small datasets are much more interesting than ImageNet.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3766" target="_blank">01:02:46.840</a></span> | <span class="t">Because most of the time you're likely to be working with stuff with a small number</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3771" target="_blank">01:02:51.340</a></span> | <span class="t">of thousands of images rather than 1.5 million images.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3776" target="_blank">01:02:56.040</a></span> | <span class="t">Some of you will work with 1.5 million images, but most of you won't.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3779" target="_blank">01:02:59.520</a></span> | <span class="t">So learning how to use these kind of datasets I think is much more interesting.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3783" target="_blank">01:03:03.660</a></span> | <span class="t">Often also a lot of the stuff we're looking at in medical imaging, we're looking at the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3788" target="_blank">01:03:08.120</a></span> | <span class="t">specific area where there's a lung nodule, you're probably looking at 32x32 pixels at</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3794" target="_blank">01:03:14.520</a></span> | <span class="t">most as being the area where that lung nodule actually exists.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3798" target="_blank">01:03:18.720</a></span> | <span class="t">And so sci-fi 10 is small both in terms of it doesn't have many images, and the images</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3802" target="_blank">01:03:22.760</a></span> | <span class="t">are very small, and so therefore I think in a lot of ways it's much more challenging than</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3809" target="_blank">01:03:29.680</a></span> | <span class="t">something like ImageNet.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3810" target="_blank">01:03:30.680</a></span> | <span class="t">In some ways it's much more interesting.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3813" target="_blank">01:03:33.920</a></span> | <span class="t">And also, most importantly, you can run stuff much more quickly on it, so it's much better</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3818" target="_blank">01:03:38.580</a></span> | <span class="t">to test out your algorithms with something you can run quickly, and it's still challenging.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3824" target="_blank">01:03:44.960</a></span> | <span class="t">And so I hear a lot of researchers complain about how they can't afford to study all the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3830" target="_blank">01:03:50.920</a></span> | <span class="t">different versions of their algorithm properly because it's too expensive, and they're doing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3835" target="_blank">01:03:55.400</a></span> | <span class="t">it on ImageNet.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3836" target="_blank">01:03:56.720</a></span> | <span class="t">So it's literally a week of expensive GPU work for every study they do, and I don't understand</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3843" target="_blank">01:04:03.920</a></span> | <span class="t">why you would do that kind of study on ImageNet, it doesn't make sense.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3848" target="_blank">01:04:08.800</a></span> | <span class="t">And so there's been a lot of debate about this this week because a really interesting</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3858" target="_blank">01:04:18.200</a></span> | <span class="t">researcher named Ali Rahami at NIPS this week gave a talk, a really great talk about the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3864" target="_blank">01:04:24.480</a></span> | <span class="t">need for rigor in experiments in deep learning, and he felt like there's a lack of rigor.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3871" target="_blank">01:04:31.000</a></span> | <span class="t">And I've talked to him about it quite a bit since that time, and I'm not sure we yet quite</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3878" target="_blank">01:04:38.880</a></span> | <span class="t">understand each other as to where we're coming from, but we have very similar kinds of concerns,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3884" target="_blank">01:04:44.160</a></span> | <span class="t">which is basically people aren't doing carefully tuned, carefully thought about experiments,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3890" target="_blank">01:04:50.280</a></span> | <span class="t">but instead they throw lots of GPUs and lots of data and consider that a day.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3895" target="_blank">01:04:55.320</a></span> | <span class="t">And so this idea of saying, well, is my algorithm meant to be good at small images, at small</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3904" target="_blank">01:05:04.200</a></span> | <span class="t">data sets, well if so, let's study it on so far 10 rather than studying it on ImageNet</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3909" target="_blank">01:05:09.280</a></span> | <span class="t">and then do more studies of different versions of the algorithm, turning different bits on</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3913" target="_blank">01:05:13.520</a></span> | <span class="t">and off, understand which parts are actually important, and so forth.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3919" target="_blank">01:05:19.600</a></span> | <span class="t">People also complain a lot about MNIST, which we've looked at before, and I would say the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3924" target="_blank">01:05:24.520</a></span> | <span class="t">same thing about MNIST, which is like if you're actually trying to understand which parts</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3928" target="_blank">01:05:28.360</a></span> | <span class="t">of your algorithm make a difference and why, using MNIST for that kind of study is a very</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3932" target="_blank">01:05:32.880</a></span> | <span class="t">good idea.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3934" target="_blank">01:05:34.120</a></span> | <span class="t">And all these people who complain about MNIST, I think they're just showing off.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3938" target="_blank">01:05:38.320</a></span> | <span class="t">They're saying, I work at Google and I have a pod of TPUs and I have $100,000 a week of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3944" target="_blank">01:05:44.000</a></span> | <span class="t">time to spend on it, no worries.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3947" target="_blank">01:05:47.120</a></span> | <span class="t">But I think that's all it is, it's just signaling rather than actually academically rigorous.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3953" target="_blank">01:05:53.560</a></span> | <span class="t">Okay, so sci-fi 10, you can download from here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3958" target="_blank">01:05:58.000</a></span> | <span class="t">This person has very kindly made it available in image form.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3963" target="_blank">01:06:03.600</a></span> | <span class="t">If you Google for sci-fi 10, you'll find a much less convenient form, so please use this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3967" target="_blank">01:06:07.720</a></span> | <span class="t">one.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3968" target="_blank">01:06:08.720</a></span> | <span class="t">It's already in the exact form you need.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3970" target="_blank">01:06:10.360</a></span> | <span class="t">Once you download it, you can use it in the usual way.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3976" target="_blank">01:06:16.840</a></span> | <span class="t">So here's a list of the classes that are there.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3981" target="_blank">01:06:21.760</a></span> | <span class="t">Now you'll see here I've created this thing called stats.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3985" target="_blank">01:06:25.320</a></span> | <span class="t">Normally when we've been using pre-trained models, we have been saying transforms from</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=3993" target="_blank">01:06:33.040</a></span> | <span class="t">model, and that's actually created the necessary transforms to convert our dataset into a normalized</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=4001" target="_blank">01:06:41.960</a></span> | <span class="t">dataset based on the means and standard deviations of each channel in the original model that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=4007" target="_blank">01:06:47.880</a></span> | <span class="t">was trained.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=4008" target="_blank">01:06:48.880</a></span> | <span class="t">In our case, this time we've got to train a model from scratch, so we have no such thing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=4014" target="_blank">01:06:54.760</a></span> | <span class="t">So we actually need to tell it the mean and standard deviation of our data to normalize</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=4021" target="_blank">01:07:01.000</a></span> | <span class="t">it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=4022" target="_blank">01:07:02.160</a></span> | <span class="t">And so in this case, I haven't included the code here to do it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=4025" target="_blank">01:07:05.000</a></span> | <span class="t">You should try and try this yourself to confirm that you can do this and understand where</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=4028" target="_blank">01:07:08.960</a></span> | <span class="t">it comes from.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=4029" target="_blank">01:07:09.960</a></span> | <span class="t">But this is just the mean per channel and the standard deviation per channel of all</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=4035" target="_blank">01:07:15.120</a></span> | <span class="t">of the images.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=4039" target="_blank">01:07:19.080</a></span> | <span class="t">So we're going to try and create a model from scratch.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=4045" target="_blank">01:07:25.300</a></span> | <span class="t">And so the first thing we need is some transformations.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=4048" target="_blank">01:07:28.680</a></span> | <span class="t">So for sci-fi 10, people generally do data augmentation of simply flipping randomly horizontally.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=4057" target="_blank">01:07:37.980</a></span> | <span class="t">So here's how we can create a specific list of augmentations to use.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=4064" target="_blank">01:07:44.400</a></span> | <span class="t">And then they also tend to add a little bit of black padding around the edge and then</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=4069" target="_blank">01:07:49.560</a></span> | <span class="t">randomly pick a 32x32 spot from within that padded image.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=4074" target="_blank">01:07:54.800</a></span> | <span class="t">So if you add the pad parameter to any of the fastai transform creators, it'll do that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=4081" target="_blank">01:08:01.760</a></span> | <span class="t">for you.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=4084" target="_blank">01:08:04.080</a></span> | <span class="t">And so in this case, I'm just going to add 4 pixels around each size.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=4092" target="_blank">01:08:12.200</a></span> | <span class="t">And so now that I've got my transforms, I can go ahead and create my image_classifier</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=4096" target="_blank">01:08:16.240</a></span> | <span class="t">data.from_paths in the usual way.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=4101" target="_blank">01:08:21.160</a></span> | <span class="t">I'm going to use a batch size of 256 because these are pretty small, so it's going to let</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=4105" target="_blank">01:08:25.820</a></span> | <span class="t">me do a little bit more at a time.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=4108" target="_blank">01:08:28.200</a></span> | <span class="t">So here's what the data looks like.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=4110" target="_blank">01:08:30.960</a></span> | <span class="t">So for example, here's a boat.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=4113" target="_blank">01:08:33.120</a></span> | <span class="t">And just to show you how tough this is, what's that?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=4117" target="_blank">01:08:37.360</a></span> | <span class="t">It's a frog.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=4123" target="_blank">01:08:43.360</a></span> | <span class="t">So I guess it's this big thing, whatever the thing is called, there's your frog.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=4129" target="_blank">01:08:49.880</a></span> | <span class="t">So these are the kinds of things that we want to look at.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=4134" target="_blank">01:08:54.440</a></span> | <span class="t">So I'm going to start out, so our student, Karim, we saw one of his posts earlier in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=4139" target="_blank">01:08:59.560</a></span> | <span class="t">this course, he made this really cool notebook which shows how different optimizers work.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=4151" target="_blank">01:09:11.300</a></span> | <span class="t">So Karim made this really cool notebook, I think it was maybe last week, in which he</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=4155" target="_blank">01:09:15.920</a></span> | <span class="t">showed how to create various different optimizers from scratch.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=4159" target="_blank">01:09:19.920</a></span> | <span class="t">So this is kind of like the Excel thing I had, but this is the Python version of Momentum</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=4164" target="_blank">01:09:24.480</a></span> | <span class="t">and Adam and Nesterov and Adagrad, all written from scratch, which is very cool.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=4169" target="_blank">01:09:29.340</a></span> | <span class="t">One of the nice things he did was he showed a tiny little general-purpose fully connected</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=4175" target="_blank">01:09:35.520</a></span> | <span class="t">network generator.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=4177" target="_blank">01:09:37.120</a></span> | <span class="t">So we're going to start with his.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=4178" target="_blank">01:09:38.960</a></span> | <span class="t">So he called that SimpleNet, so are we.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=4181" target="_blank">01:09:41.660</a></span> | <span class="t">So here's a simple class which has a list of fully connected layers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=4190" target="_blank">01:09:50.200</a></span> | <span class="t">Whenever you create a list of layers in PyTorch, you have to wrap it in an nn.module list just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=4195" target="_blank">01:09:55.840</a></span> | <span class="t">to tell PyTorch to register these as attributes.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=4201" target="_blank">01:10:01.800</a></span> | <span class="t">And so then we just go ahead and flatten the data that comes in, because it's fully connected</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=4205" target="_blank">01:10:05.960</a></span> | <span class="t">layers, and then go through each layer and call that linear layer, do the value to it,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=4214" target="_blank">01:10:14.060</a></span> | <span class="t">and at the end do a softmax.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=4216" target="_blank">01:10:16.400</a></span> | <span class="t">So there's a really simple approach, and so we can now take that model and now I'm going</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=4223" target="_blank">01:10:23.160</a></span> | <span class="t">to show you how to step up one level of the API higher.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=4226" target="_blank">01:10:26.720</a></span> | <span class="t">Rather than calling the fit function, we're going to create a learn object, but we're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=4230" target="_blank">01:10:30.500</a></span> | <span class="t">going to create a learn object from a custom model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=4234" target="_blank">01:10:34.720</a></span> | <span class="t">And so we can do that by saying we want a convolutional learner, we want to create it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=4238" target="_blank">01:10:38.880</a></span> | <span class="t">from a model and from some data, and the model is this one.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=4244" target="_blank">01:10:44.880</a></span> | <span class="t">This is just a general PyTorch model, and this is a model data object of the usual kind.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=4251" target="_blank">01:10:51.780</a></span> | <span class="t">And that will return a learner.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=4253" target="_blank">01:10:53.240</a></span> | <span class="t">So this is a bit easier than what we just saw with the RNN -- we don't have to fiddle</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=4257" target="_blank">01:10:57.080</a></span> | <span class="t">around with layer optimizers and cosine annealing callbacks and whatever.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=4261" target="_blank">01:11:01.640</a></span> | <span class="t">This is now a learner that we can do all the usual stuff with, but we can do it with any</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=4266" target="_blank">01:11:06.560</a></span> | <span class="t">model that we create.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=4270" target="_blank">01:11:10.500</a></span> | <span class="t">So if we just go Learn, that will go ahead and print it out.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=4275" target="_blank">01:11:15.520</a></span> | <span class="t">You can see we've got 3,072 features coming in because we've got 32 by 32 pixels by 3</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=4282" target="_blank">01:11:22.120</a></span> | <span class="t">channels.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=4283" target="_blank">01:11:23.120</a></span> | <span class="t">And then we've got 40 features coming out of the first layer, that's going to go into</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=4286" target="_blank">01:11:26.840</a></span> | <span class="t">the second layer, 10 features coming out because we've got the sci-fi 10 categories.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=4294" target="_blank">01:11:34.920</a></span> | <span class="t">You can call dot summary to see that in a little bit more detail.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=4298" target="_blank">01:11:38.520</a></span> | <span class="t">We can do LRfind, we can plot that, and we can then go fit, and we can use cycle length,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=4305" target="_blank">01:11:45.600</a></span> | <span class="t">and so forth.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=4307" target="_blank">01:11:47.320</a></span> | <span class="t">So with a simple -- how many hidden layers do we have?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=4312" target="_blank">01:11:52.720</a></span> | <span class="t">One hidden layer, one output layer, one hidden layer model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=4319" target="_blank">01:11:59.840</a></span> | <span class="t">And here we can see the number of parameters we have is over 120,000.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=4327" target="_blank">01:12:07.560</a></span> | <span class="t">We get a 47% accuracy.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=4332" target="_blank">01:12:12.220</a></span> | <span class="t">So not great, so let's kind of try and improve it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=4337" target="_blank">01:12:17.280</a></span> | <span class="t">And so the goal here is we're going to try and eventually replicate the basic architecture</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=4343" target="_blank">01:12:23.960</a></span> | <span class="t">of a ResNet.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=4344" target="_blank">01:12:24.960</a></span> | <span class="t">So that's where we're going to try and get to here, to gradually build up to a ResNet.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=4350" target="_blank">01:12:30.560</a></span> | <span class="t">So the first step is to replace our fully connected model with a convolutional model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=4357" target="_blank">01:12:37.080</a></span> | <span class="t">So to remind you, a fully connected layer is simply doing a dot product.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=4369" target="_blank">01:12:49.560</a></span> | <span class="t">So if we had all of these data points and all of these weights, then we basically do</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=4381" target="_blank">01:13:01.040</a></span> | <span class="t">some product of all of those together, in other words it's a matrix model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=4385" target="_blank">01:13:05.600</a></span> | <span class="t">And that's a fully connected layer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=4389" target="_blank">01:13:09.520</a></span> | <span class="t">And so the weight matrix is going to contain every element of the input for every element</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=4396" target="_blank">01:13:16.920</a></span> | <span class="t">of the output.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=4398" target="_blank">01:13:18.360</a></span> | <span class="t">So that's why we have here a pretty big weight matrix.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=4406" target="_blank">01:13:26.020</a></span> | <span class="t">And so that's why despite the fact that we have such a crappy accuracy, we have a lot</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=4411" target="_blank">01:13:31.420</a></span> | <span class="t">of parameters because in this very first layer we've got 3072 coming in and 40 coming out,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=4420" target="_blank">01:13:40.560</a></span> | <span class="t">so that gives us 3000x40 parameters.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=4424" target="_blank">01:13:44.400</a></span> | <span class="t">And so we end up not using them very efficiently because we're basically saying every single</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=4429" target="_blank">01:13:49.080</a></span> | <span class="t">pixel in the input has a different weight.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=4431" target="_blank">01:13:51.720</a></span> | <span class="t">And of course what we really want to do is find groups of 3x3 pixels that have particular</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=4437" target="_blank">01:13:57.160</a></span> | <span class="t">patterns to them, and remember we call that a convolution.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=4442" target="_blank">01:14:02.280</a></span> | <span class="t">So a convolution looks like so.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=4452" target="_blank">01:14:12.420</a></span> | <span class="t">We have a little 3x3 section of our image and a corresponding 3x3 set of filters, or</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=4461" target="_blank">01:14:21.840</a></span> | <span class="t">a filter with a 3x3 kernel, and we just do a sum product of just that 3x3 by that 3x3.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=4471" target="_blank">01:14:31.000</a></span> | <span class="t">And then we do that for every single part of our image.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=4476" target="_blank">01:14:36.580</a></span> | <span class="t">And so when we do that across the whole image, that's called a convolution.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=4480" target="_blank">01:14:40.760</a></span> | <span class="t">And remember, in this case we actually had multiple filters, so the result of that convolution</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=4486" target="_blank">01:14:46.920</a></span> | <span class="t">actually had a tensor with an additional third dimension to it effectively.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=4496" target="_blank">01:14:56.920</a></span> | <span class="t">So let's take exactly the same code that we had before, but we're going to replace nn.linear</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=4503" target="_blank">01:15:03.080</a></span> | <span class="t">with nn.com2d.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=4508" target="_blank">01:15:08.040</a></span> | <span class="t">Now what I want to do in this case is each time I have a layer, I want to make the next</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=4514" target="_blank">01:15:14.240</a></span> | <span class="t">layer smaller.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=4516" target="_blank">01:15:16.540</a></span> | <span class="t">And so the way I did that in my Excel example was I used max_pooling.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=4523" target="_blank">01:15:23.080</a></span> | <span class="t">So max_pooling took every 2x2 section and replaced it with its maximum value.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=4531" target="_blank">01:15:31.020</a></span> | <span class="t">Nowadays we don't use that kind of max_pooling much at all.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=4536" target="_blank">01:15:36.120</a></span> | <span class="t">Instead nowadays what we tend to do is do what's called a Stride 2 convolution.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=4540" target="_blank">01:15:40.960</a></span> | <span class="t">A Stride 2 convolution, rather than saying let's go through every single 3x3, it says</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=4551" target="_blank">01:15:51.040</a></span> | <span class="t">let's go through every second 3x3.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=4555" target="_blank">01:15:55.600</a></span> | <span class="t">So rather than moving this 3x3 1 to the right, we move it 2 to the right.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=4561" target="_blank">01:16:01.040</a></span> | <span class="t">And then when we get to the end of the row, rather than moving one row down, we move two</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=4565" target="_blank">01:16:05.640</a></span> | <span class="t">rows down.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=4567" target="_blank">01:16:07.240</a></span> | <span class="t">So that's called a Stride 2 convolution.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=4569" target="_blank">01:16:09.740</a></span> | <span class="t">And so a Stride 2 convolution has the same kind of effect as a max_pooling, which is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=4575" target="_blank">01:16:15.100</a></span> | <span class="t">you end up halving the resolution in each dimension.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=4579" target="_blank">01:16:19.400</a></span> | <span class="t">So we can ask for that by saying Stride = 2.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=4583" target="_blank">01:16:23.960</a></span> | <span class="t">We can say we want it to be 3x3 by saying kernel size, and then the first two parameters</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=4588" target="_blank">01:16:28.440</a></span> | <span class="t">are exactly the same as nn.linear, they're the number of features coming in and the number</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=4592" target="_blank">01:16:32.640</a></span> | <span class="t">of features coming out.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=4595" target="_blank">01:16:35.720</a></span> | <span class="t">So we create a module list of those layers, and then at the very end of that, so in this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=4603" target="_blank">01:16:43.400</a></span> | <span class="t">case I'm going to say I've got three channels coming in, the first one layer will come out</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=4608" target="_blank">01:16:48.540</a></span> | <span class="t">with 20, then 40, and then 80.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=4612" target="_blank">01:16:52.200</a></span> | <span class="t">So if we look at the summary, we're going to start with a 32x32, we're going to spit</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=4616" target="_blank">01:16:56.800</a></span> | <span class="t">out a 15x15, and then a 7x7, and then a 3x3.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=4624" target="_blank">01:17:04.020</a></span> | <span class="t">And so what do we do now to get that down to a prediction of one of 10 classes?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=4631" target="_blank">01:17:11.200</a></span> | <span class="t">What we do is we do something called adaptive max_pooling, and this is what is pretty standard</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=4636" target="_blank">01:17:16.880</a></span> | <span class="t">now for state-of-the-art algorithms, is that the very last layer we do a max_pool, but</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=4644" target="_blank">01:17:24.720</a></span> | <span class="t">rather than doing a 2x2 max_pool, we say it doesn't have to be 2x2, it could have been</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=4651" target="_blank">01:17:31.320</a></span> | <span class="t">3x3, which is like replace every 3x3 pixels with its maximum, it could have been 4x4.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=4657" target="_blank">01:17:37.720</a></span> | <span class="t">Adaptive max_pool is where you say, I'm not going to tell you how big an area to pool,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=4663" target="_blank">01:17:43.920</a></span> | <span class="t">but instead I'm going to tell you how big a resolution to create.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=4669" target="_blank">01:17:49.760</a></span> | <span class="t">So if I said, for example, I think my input here is 28x28, if I said do a 14x14 adaptive</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=4679" target="_blank">01:17:59.080</a></span> | <span class="t">max_pool, that would be the same as a 2x2 max_pool, because in other words it's saying</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=4683" target="_blank">01:18:03.780</a></span> | <span class="t">please create a 14x14 output.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=4687" target="_blank">01:18:07.080</a></span> | <span class="t">If I said do a 2x2 adaptive max_pool, then that would be the same as saying do a 14x14</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=4696" target="_blank">01:18:16.080</a></span> | <span class="t">max_pool.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=4697" target="_blank">01:18:17.280</a></span> | <span class="t">And so what we pretty much always do in modern CNNs is we make our penultimate layer a 1x1</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=4706" target="_blank">01:18:26.360</a></span> | <span class="t">adaptive max_pool.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=4708" target="_blank">01:18:28.480</a></span> | <span class="t">So in other words, find the single largest cell and use that as our new activation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=4719" target="_blank">01:18:39.520</a></span> | <span class="t">And so once we've got that, we've now got a 1x1 tensor, or actually 1x1 by number of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=4728" target="_blank">01:18:48.080</a></span> | <span class="t">features tensor.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=4729" target="_blank">01:18:49.920</a></span> | <span class="t">So we can then on top of that go x.view, x.size, -1, and actually there are no other dimensions</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=4741" target="_blank">01:19:01.040</a></span> | <span class="t">to this basically.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=4742" target="_blank">01:19:02.960</a></span> | <span class="t">So this is going to return a matrix of mini-batch by number of features.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=4749" target="_blank">01:19:09.520</a></span> | <span class="t">And so then we can feed that into a linear layer with however many classes we need.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=4757" target="_blank">01:19:17.680</a></span> | <span class="t">So you can see here the last thing I pass in is how many classes am I trying to predict,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=4762" target="_blank">01:19:22.560</a></span> | <span class="t">and that's what's going to be used to create that last layer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=4765" target="_blank">01:19:25.200</a></span> | <span class="t">So it goes through every convolutional layer, does a convolution, does a ReLU, does an adaptive</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=4772" target="_blank">01:19:32.320</a></span> | <span class="t">max_pool.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=4774" target="_blank">01:19:34.640</a></span> | <span class="t">This dot view just gets rid of those trailing unit axes, the 1,1 axis, which is not necessary.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=4783" target="_blank">01:19:43.840</a></span> | <span class="t">That allows us to feed that into our final linear layer that bits out something of size</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=4789" target="_blank">01:19:49.440</a></span> | <span class="t">C, which here is 10.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=4793" target="_blank">01:19:53.460</a></span> | <span class="t">So you can now see how it works.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=4794" target="_blank">01:19:54.800</a></span> | <span class="t">It goes 32 to 15 to 7x7 to 3x3.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=4799" target="_blank">01:19:59.960</a></span> | <span class="t">The adaptive max_pool makes it 80 by 1 by 1, and then our dot view makes it just mini-batch</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=4808" target="_blank">01:20:08.160</a></span> | <span class="t">size by 80, and then finally a linear layer which takes it from 80 to 10, which is what</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=4814" target="_blank">01:20:14.360</a></span> | <span class="t">we wanted.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=4816" target="_blank">01:20:16.480</a></span> | <span class="t">So that's our most basic -- you'd call this a fully convolutional network, so a fully convolutional</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=4823" target="_blank">01:20:23.160</a></span> | <span class="t">network is something where every layer is convolutional except for the very last.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=4832" target="_blank">01:20:32.280</a></span> | <span class="t">So again, we can now go lr.find, and now in this case when I did lr.find, it went through</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=4839" target="_blank">01:20:39.840</a></span> | <span class="t">the entire data set and was still getting better.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=4843" target="_blank">01:20:43.440</a></span> | <span class="t">And so in other words, the default final learning rate it tries is 10, and even at that point</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=4848" target="_blank">01:20:48.840</a></span> | <span class="t">it was still pretty much getting better.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=4851" target="_blank">01:20:51.600</a></span> | <span class="t">So you can always override the final learning rate by saying end_lr=, and that'll just get</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=4857" target="_blank">01:20:57.520</a></span> | <span class="t">it to try more things.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=4859" target="_blank">01:20:59.320</a></span> | <span class="t">So here is the learning rate finder, and so I picked 10^-1, trained that for a while, and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=4869" target="_blank">01:21:09.640</a></span> | <span class="t">that's looking pretty good, so then I tried it with a cycle length of 1, and it's starting</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=4873" target="_blank">01:21:13.520</a></span> | <span class="t">to flatten out at about 60%.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=4876" target="_blank">01:21:16.360</a></span> | <span class="t">So you can see here the number of parameters I have here are 500, 7000, 28000, about 30,000.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=4888" target="_blank">01:21:28.100</a></span> | <span class="t">So I have about 1/4 of the number of parameters, but my accuracy has gone up from 47% to 60%.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=4896" target="_blank">01:21:36.640</a></span> | <span class="t">And the time per epoch here is under 30 seconds, and here also.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=4902" target="_blank">01:21:42.960</a></span> | <span class="t">So the time per epoch is about the same.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=4904" target="_blank">01:21:44.800</a></span> | <span class="t">And that's not surprising because when you use small simple architectures, most of the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=4909" target="_blank">01:21:49.060</a></span> | <span class="t">time is the memory transfer, the actual time during the compute is trivial.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=4917" target="_blank">01:21:57.820</a></span> | <span class="t">So I'm going to refactor this slightly because I want to try and put less stuff inside my</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=4924" target="_blank">01:22:04.400</a></span> | <span class="t">forward, and so calling relu every time doesn't seem ideal.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=4929" target="_blank">01:22:09.160</a></span> | <span class="t">So I'm going to create a new class called conv_layer, and the conv_layer class is going</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=4935" target="_blank">01:22:15.740</a></span> | <span class="t">to contain a convolution with a kernel size of 3 and a stride of 2.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=4940" target="_blank">01:22:20.960</a></span> | <span class="t">One thing I'm going to do now is add padding.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=4943" target="_blank">01:22:23.800</a></span> | <span class="t">Did you notice here the first layer went from 32x32 to 15x15, not 16x16?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=4951" target="_blank">01:22:31.620</a></span> | <span class="t">And the reason for that is that at the very edge of your convolution, here, see how this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=4963" target="_blank">01:22:43.320</a></span> | <span class="t">first convolution, there isn't a convolution where the middle is the top left point because</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=4970" target="_blank">01:22:50.240</a></span> | <span class="t">there's nothing outside it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=4972" target="_blank">01:22:52.840</a></span> | <span class="t">Or else if we had put a row of 0's at the top and a row of 0's at the edge of each column,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=4979" target="_blank">01:22:59.320</a></span> | <span class="t">we now could go all the way to the edge.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=4982" target="_blank">01:23:02.600</a></span> | <span class="t">So pad=1 adds that little layer of 0's around the edge for us.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=4991" target="_blank">01:23:11.320</a></span> | <span class="t">And so this way we're going to make sure that we go 32x32 to 16x16 to 8x8.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=4997" target="_blank">01:23:17.080</a></span> | <span class="t">It doesn't matter too much when you've got these bigger layers, but by the time you get</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=5000" target="_blank">01:23:20.400</a></span> | <span class="t">down to 4x4, you really don't want to throw away a whole piece.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=5006" target="_blank">01:23:26.560</a></span> | <span class="t">So padding becomes important.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=5008" target="_blank">01:23:28.560</a></span> | <span class="t">So by refactoring it to put this with its defaults here, and then in the forward I'll</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=5014" target="_blank">01:23:34.440</a></span> | <span class="t">put the ReLU in here as well, it makes my ConvNet a little bit smaller and more to the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=5021" target="_blank">01:23:41.080</a></span> | <span class="t">point it's going to be easier for me to make sure that everything's correct in the future</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=5024" target="_blank">01:23:44.960</a></span> | <span class="t">by always using this ConvLayer class.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=5027" target="_blank">01:23:47.740</a></span> | <span class="t">So now you know not only how to create your own neural network model, but how to create</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=5033" target="_blank">01:23:53.040</a></span> | <span class="t">your own neural network layer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=5035" target="_blank">01:23:55.440</a></span> | <span class="t">So here now I can use ConvLayer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=5038" target="_blank">01:23:58.880</a></span> | <span class="t">This is such a cool thing about PyTorch is a layer definition and a neural network definition</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=5044" target="_blank">01:24:04.360</a></span> | <span class="t">are literally identical.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=5046" target="_blank">01:24:06.400</a></span> | <span class="t">They both have a constructor and a forward.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=5049" target="_blank">01:24:09.520</a></span> | <span class="t">And so anytime you've got a layer, you can use it as a neural net, anytime you have a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=5053" target="_blank">01:24:13.280</a></span> | <span class="t">neural net, you can use it as a layer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=5056" target="_blank">01:24:16.800</a></span> | <span class="t">So this is now the exact same thing as we had before.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=5060" target="_blank">01:24:20.320</a></span> | <span class="t">One difference is I now have padding.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=5063" target="_blank">01:24:23.380</a></span> | <span class="t">And another thing just to show you, you can do things differently.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=5066" target="_blank">01:24:26.060</a></span> | <span class="t">Back here, my max_pull I did as an object, I used the class nn.adaptive_max_pull, and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=5075" target="_blank">01:24:35.440</a></span> | <span class="t">I stuck it in this attribute and then I called it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=5078" target="_blank">01:24:38.560</a></span> | <span class="t">But this actually doesn't have any state.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=5080" target="_blank">01:24:40.760</a></span> | <span class="t">There's no weights inside max_pulling, so I can actually do it with a little bit less</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=5085" target="_blank">01:24:45.440</a></span> | <span class="t">code by calling it as a function.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=5089" target="_blank">01:24:49.000</a></span> | <span class="t">So everything that you can do as a class, you can also do as a function inside this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=5092" target="_blank">01:24:52.760</a></span> | <span class="t">capital F which is nn.functional.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=5098" target="_blank">01:24:58.200</a></span> | <span class="t">So this should be a tiny bit better because this time I've got the padding.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=5105" target="_blank">01:25:05.080</a></span> | <span class="t">I didn't train it for as long to actually check, so let's skip over that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=5113" target="_blank">01:25:13.640</a></span> | <span class="t">So one issue here is that in the end, when I tried to add more layers, I had trouble</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=5123" target="_blank">01:25:23.280</a></span> | <span class="t">training it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=5125" target="_blank">01:25:25.960</a></span> | <span class="t">The reason I was having trouble training it was if I used larger learning rates, it would</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=5130" target="_blank">01:25:30.920</a></span> | <span class="t">go off to nin, and if I used smaller learning rates, it kind of takes forever and doesn't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=5135" target="_blank">01:25:35.560</a></span> | <span class="t">really have a chance to explore properly.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=5138" target="_blank">01:25:38.320</a></span> | <span class="t">So it wasn't resilient.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=5140" target="_blank">01:25:40.420</a></span> | <span class="t">So to make my model more resilient, I'm going to use something called batch normalization,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=5145" target="_blank">01:25:45.840</a></span> | <span class="t">which literally everybody calls batchnorm.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=5148" target="_blank">01:25:48.360</a></span> | <span class="t">And batchnorm is a couple of years old now, and it's been pretty transformative since</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=5155" target="_blank">01:25:55.320</a></span> | <span class="t">it came along because it suddenly makes it really easy to train deeper networks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=5161" target="_blank">01:26:01.880</a></span> | <span class="t">So the network I'm going to create is going to have more layers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=5165" target="_blank">01:26:05.120</a></span> | <span class="t">I've got 1, 2, 3, 4, 5 convolutional layers plus a fully connected layer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=5170" target="_blank">01:26:10.840</a></span> | <span class="t">So back in the old days, that would be considered a pretty deep network and we'd be considered</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=5175" target="_blank">01:26:15.360</a></span> | <span class="t">pretty hard to train.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=5176" target="_blank">01:26:16.840</a></span> | <span class="t">Nowadays it's super simple thanks to batchnorm.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=5180" target="_blank">01:26:20.700</a></span> | <span class="t">Now to use batchnorm, you can just write in nn.batchnorm, but to learn about it, we're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=5185" target="_blank">01:26:25.800</a></span> | <span class="t">going to write it from scratch.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=5188" target="_blank">01:26:28.240</a></span> | <span class="t">So the basic idea of batchnorm is that we've got some vector of activations.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=5196" target="_blank">01:26:36.440</a></span> | <span class="t">Any time I draw a vector of activations, obviously I mean you can repeat it for the minibatch,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=5200" target="_blank">01:26:40.280</a></span> | <span class="t">so pretend it's a minibatch of 1.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=5201" target="_blank">01:26:41.840</a></span> | <span class="t">So we've got some vector of activations, and it's coming into some layer, so probably some</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=5209" target="_blank">01:26:49.840</a></span> | <span class="t">convolutional matrix multiplication, and then something comes out the other side.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=5216" target="_blank">01:26:56.600</a></span> | <span class="t">So imagine this is just a matrix multiply, say it was an identity matrix.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=5231" target="_blank">01:27:11.160</a></span> | <span class="t">Then every time I multiply it by that across lots and lots of layers, my activations are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=5235" target="_blank">01:27:15.360</a></span> | <span class="t">not getting bigger, they're not getting smaller, they're not changing at all.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=5239" target="_blank">01:27:19.960</a></span> | <span class="t">That's all fine, but imagine if it was actually like 2, 2, 2.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=5247" target="_blank">01:27:27.160</a></span> | <span class="t">And so if every one of my weight matrices or filters was like that, then my activations</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=5252" target="_blank">01:27:32.200</a></span> | <span class="t">are doubling each time.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=5254" target="_blank">01:27:34.760</a></span> | <span class="t">And so suddenly I've got this exponential growth, and in deep models that's going to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=5261" target="_blank">01:27:41.040</a></span> | <span class="t">be a disaster because my gradients are exploding at an exponential rate.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=5266" target="_blank">01:27:46.840</a></span> | <span class="t">And so the challenge you have is that it's very unlikely unless you try carefully to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=5274" target="_blank">01:27:54.600</a></span> | <span class="t">deal with it that your weight matrices on average are not going to cause your activations</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=5283" target="_blank">01:28:03.040</a></span> | <span class="t">to keep getting smaller and smaller, or keep getting bigger and bigger.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=5286" target="_blank">01:28:06.280</a></span> | <span class="t">You have to carefully control things to make sure that they stay at a reasonable size,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=5292" target="_blank">01:28:12.440</a></span> | <span class="t">you want to keep them at a reasonable scale.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=5296" target="_blank">01:28:16.760</a></span> | <span class="t">So we start things off with 0 mean standard deviation 1 by normalizing the inputs, but</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=5303" target="_blank">01:28:23.920</a></span> | <span class="t">what we'd really like to do is to normalize every layer, not just the inputs.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=5311" target="_blank">01:28:31.440</a></span> | <span class="t">And so, okay, fine, let's do that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=5316" target="_blank">01:28:36.620</a></span> | <span class="t">So here I've created a bn layer which is exactly like my conv layer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=5320" target="_blank">01:28:40.800</a></span> | <span class="t">It's got my conv2d with my stride, my padding.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=5325" target="_blank">01:28:45.200</a></span> | <span class="t">I do my conv and my relu, and then I calculate the mean of each channel or of each filter,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=5335" target="_blank">01:28:55.560</a></span> | <span class="t">and the standard deviation of each channel or each filter, and then I subtract the means</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=5340" target="_blank">01:29:00.980</a></span> | <span class="t">and divide by the standard deviations.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=5344" target="_blank">01:29:04.540</a></span> | <span class="t">So now I don't actually need to normalize my input at all because it's actually going</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=5350" target="_blank">01:29:10.760</a></span> | <span class="t">to do it automatically.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=5352" target="_blank">01:29:12.240</a></span> | <span class="t">It's normalizing it per channel, and for later layers it's normalizing it per filter.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=5361" target="_blank">01:29:21.120</a></span> | <span class="t">So it turns out that's not enough because SGD is bloody-minded.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=5369" target="_blank">01:29:29.960</a></span> | <span class="t">And so if SGD decided that it wants the weight matrix to be like so, where that matrix is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=5377" target="_blank">01:29:37.480</a></span> | <span class="t">something which is going to increase the values overall repeatedly, then subtract the means</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=5386" target="_blank">01:29:46.720</a></span> | <span class="t">and divide by the standard deviations just means the next mini-batch is going to try</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=5390" target="_blank">01:29:50.880</a></span> | <span class="t">and do it again.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=5393" target="_blank">01:29:53.880</a></span> | <span class="t">So it turns out that this actually doesn't help, it literally does nothing because SGD</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=5400" target="_blank">01:30:00.680</a></span> | <span class="t">is just going to go ahead and undo the next mini-batch.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=5406" target="_blank">01:30:06.280</a></span> | <span class="t">So what we do is we create a new multiplier for each channel and a new added value for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=5418" target="_blank">01:30:18.600</a></span> | <span class="t">each channel, and we just start them out as the addition is just a bunch of zeros, so for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=5425" target="_blank">01:30:25.440</a></span> | <span class="t">the first layer, 3 zeros, and the multiplier for the first layer is just 3 ones.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=5431" target="_blank">01:30:31.360</a></span> | <span class="t">So the number of filters for the first layer is just 3.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=5435" target="_blank">01:30:35.060</a></span> | <span class="t">And so we then basically undo exactly what we just did, or potentially we undo them.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=5442" target="_blank">01:30:42.160</a></span> | <span class="t">So by saying this is an nn.parameter, that tells PyTorch you're allowed to learn these</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=5448" target="_blank">01:30:48.220</a></span> | <span class="t">as weights.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=5450" target="_blank">01:30:50.400</a></span> | <span class="t">So initially it says subtract the means, divide by the standard deviations, multiply by 1,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=5457" target="_blank">01:30:57.820</a></span> | <span class="t">add on 0, okay that's fine, nothing much happened there.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=5467" target="_blank">01:31:07.280</a></span> | <span class="t">Like if it wants to kind of scale the layer up, it doesn't have to scale up every single</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=5473" target="_blank">01:31:13.000</a></span> | <span class="t">value in the matrix, it can just scale up this single trio of numbers, self.m.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=5481" target="_blank">01:31:21.240</a></span> | <span class="t">If it wants to shift it all up or down a bit, it doesn't have to shift the entire weight</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=5485" target="_blank">01:31:25.480</a></span> | <span class="t">matrix, it can just shift this trio of numbers, self.a.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=5491" target="_blank">01:31:31.980</a></span> | <span class="t">So I will say this, at this talk I mentioned at Nip's Ali Rahimi's talk about rigor, he</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=5498" target="_blank">01:31:38.080</a></span> | <span class="t">actually pointed to this batch norm paper as being a particularly useful, particularly</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=5506" target="_blank">01:31:46.160</a></span> | <span class="t">interesting paper where a lot of people don't necessarily know why it works.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=5516" target="_blank">01:31:56.080</a></span> | <span class="t">And so if you're thinking subtracting out the means and then adding some learned weights</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=5522" target="_blank">01:32:02.000</a></span> | <span class="t">of exactly the same rank and size sounds like a weird thing to do, there are a lot of people</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=5531" target="_blank">01:32:11.280</a></span> | <span class="t">that feel the same way.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=5533" target="_blank">01:32:13.480</a></span> | <span class="t">So at the moment I think the best is intuitively what's going on here is that we're normalizing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=5542" target="_blank">01:32:22.480</a></span> | <span class="t">the data and then we're saying you can then shift it and scale it using far fewer parameters</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=5551" target="_blank">01:32:31.400</a></span> | <span class="t">than would have been necessary if I was asking you to actually shift and scale the entire</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=5556" target="_blank">01:32:36.620</a></span> | <span class="t">set of convolutional filters.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=5559" target="_blank">01:32:39.480</a></span> | <span class="t">That's the kind of basic intuition.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=5562" target="_blank">01:32:42.040</a></span> | <span class="t">More importantly, in practice, what this does is it basically allows us to increase our learning</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=5571" target="_blank">01:32:51.660</a></span> | <span class="t">rates and it increases the resilience of training and allows us to add more layers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=5576" target="_blank">01:32:56.960</a></span> | <span class="t">So once I added a bn layer rather than a conv layer, I found I was able to add more layers</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=5588" target="_blank">01:33:08.620</a></span> | <span class="t">to my model and it's still trained effectively.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=5592" target="_blank">01:33:12.240</a></span> | <span class="t">Question 6 Are we worried about anything that maybe we are divided by something very small</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=5601" target="_blank">01:33:21.880</a></span> | <span class="t">or anything like that?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=5605" target="_blank">01:33:25.880</a></span> | <span class="t">Once we do this...</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=5606" target="_blank">01:33:26.880</a></span> | <span class="t">Answer 7 Yeah, probably.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=5607" target="_blank">01:33:27.880</a></span> | <span class="t">I think in the PyTorch version it would probably be divided by self.studs plus epsilon or something.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=5618" target="_blank">01:33:38.480</a></span> | <span class="t">This worked fine for me, but that is definitely something to think about if you were trying</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=5625" target="_blank">01:33:45.040</a></span> | <span class="t">to make this more reliable.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=5626" target="_blank">01:33:46.840</a></span> | <span class="t">Question 8 So the self.m and self.a, I'm guessing it's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=5635" target="_blank">01:33:55.600</a></span> | <span class="t">getting updated through backpropagation as well?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=5638" target="_blank">01:33:58.400</a></span> | <span class="t">Answer 9 Yeah, so by saying it's an nn.parameter, that's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=5642" target="_blank">01:34:02.360</a></span> | <span class="t">how we flag to PyTorch to learn it through backprop.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=5649" target="_blank">01:34:09.880</a></span> | <span class="t">The other interesting thing it turns out that BatchNorm does is it regularizes.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=5656" target="_blank">01:34:16.000</a></span> | <span class="t">In other words, you can often decrease or remove dropout or decrease or remove weight</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=5661" target="_blank">01:34:21.120</a></span> | <span class="t">decay when you use BatchNorm.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=5663" target="_blank">01:34:23.720</a></span> | <span class="t">And the reason why is if you think about it, each many batch is going to have a different</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=5670" target="_blank">01:34:30.280</a></span> | <span class="t">mean and a different standard deviation to the previous mini-batch.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=5674" target="_blank">01:34:34.440</a></span> | <span class="t">So these things keep changing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=5677" target="_blank">01:34:37.080</a></span> | <span class="t">Because they keep changing, it's kind of changing the meaning of the filters in this subtle way.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=5682" target="_blank">01:34:42.840</a></span> | <span class="t">And so it's adding a regularization effect because it's noise.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=5686" target="_blank">01:34:46.240</a></span> | <span class="t">When you add noise of any kind, it regularizes your model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=5692" target="_blank">01:34:52.440</a></span> | <span class="t">I'm actually cheating a little bit here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=5695" target="_blank">01:34:55.560</a></span> | <span class="t">In the real version of BatchNorm, you don't just use this batch's mean and standard deviation,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=5702" target="_blank">01:35:02.560</a></span> | <span class="t">but instead you take an exponentially weighted moving average standard deviation and mean.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=5709" target="_blank">01:35:09.020</a></span> | <span class="t">And so if you wanted to exercise to try during the week, that would be a good thing to try.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=5714" target="_blank">01:35:14.240</a></span> | <span class="t">But I will point out something very important here, which is if self.training.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=5719" target="_blank">01:35:19.560</a></span> | <span class="t">When we are doing our training loop, this will be true when it's being applied to the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=5727" target="_blank">01:35:27.580</a></span> | <span class="t">training set, and it will be false when it's being applied to the validation set.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=5733" target="_blank">01:35:33.200</a></span> | <span class="t">And this is really important because when you're going through the validation set, you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=5736" target="_blank">01:35:36.560</a></span> | <span class="t">do not want to be changing the meaning of the model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=5741" target="_blank">01:35:41.280</a></span> | <span class="t">So this really important idea is that there are some types of layer that are actually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=5748" target="_blank">01:35:48.240</a></span> | <span class="t">sensitive to what the mode of the network is, whether it's in training mode or, as PyTorch</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=5756" target="_blank">01:35:56.560</a></span> | <span class="t">calls it, evaluation mode, or we might say test mode.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=5762" target="_blank">01:36:02.160</a></span> | <span class="t">We actually had a bug a couple of weeks ago when we did our Mininet for MovieLens, the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=5768" target="_blank">01:36:08.080</a></span> | <span class="t">collaborative filtering, we actually had f.dropout in our forward pass without protecting it with</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=5774" target="_blank">01:36:14.800</a></span> | <span class="t">a if self.training f.dropout, as a result of which we were actually doing dropout in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=5781" target="_blank">01:36:21.560</a></span> | <span class="t">the validation piece as well as the training piece, which obviously isn't what you want.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=5787" target="_blank">01:36:27.240</a></span> | <span class="t">So I've actually gone back and fixed this by changing it to using an n.dropout.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=5794" target="_blank">01:36:34.360</a></span> | <span class="t">And nn.dropout has already been written for us to check whether it's being used in training</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=5799" target="_blank">01:36:39.360</a></span> | <span class="t">mode or not.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=5801" target="_blank">01:36:41.520</a></span> | <span class="t">Or alternatively, I could have added an if self.training before I use the dropout here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=5809" target="_blank">01:36:49.640</a></span> | <span class="t">So it's important to think about that, and the main two, or pretty much the only two</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=5815" target="_blank">01:36:55.280</a></span> | <span class="t">built into PyTorch where this happens is dropout and that's not.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=5822" target="_blank">01:37:02.240</a></span> | <span class="t">And so interestingly, this is also a key difference in fast.ai, which no other library does, is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=5829" target="_blank">01:37:09.480</a></span> | <span class="t">that these means and standard deviations get updated in training mode in every other library</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=5840" target="_blank">01:37:20.400</a></span> | <span class="t">as soon as you basically say I'm training, regardless of whether that layer is set to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=5844" target="_blank">01:37:24.840</a></span> | <span class="t">trainable or not.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=5847" target="_blank">01:37:27.100</a></span> | <span class="t">And it turns out that with a pre-trained network, that's a terrible idea.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=5851" target="_blank">01:37:31.400</a></span> | <span class="t">If you have a pre-trained network, the specific values of those means and standard deviations</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=5856" target="_blank">01:37:36.040</a></span> | <span class="t">in batch norm, if you change them, it changes the meaning of those pre-trained layers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=5861" target="_blank">01:37:41.640</a></span> | <span class="t">And so in fast.ai, always by default it won't touch those means and standard deviations</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=5867" target="_blank">01:37:47.580</a></span> | <span class="t">if your layer is frozen.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=5869" target="_blank">01:37:49.760</a></span> | <span class="t">As soon as you unfreeze it, it'll start updating them.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=5875" target="_blank">01:37:55.520</a></span> | <span class="t">Unless you've set learn.bnfreeze true.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=5881" target="_blank">01:38:01.040</a></span> | <span class="t">If you set learn.bnfreeze true, it says never touch these means and standard deviations.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=5886" target="_blank">01:38:06.920</a></span> | <span class="t">And I've found in practice that that often seems to work a lot better for pre-trained</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=5894" target="_blank">01:38:14.800</a></span> | <span class="t">models, particularly if you're working with data that's quite similar to what the pre-trained</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=5899" target="_blank">01:38:19.360</a></span> | <span class="t">model was trained with.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=5901" target="_blank">01:38:21.560</a></span> | <span class="t">So, I have two questions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=5909" target="_blank">01:38:29.160</a></span> | <span class="t">Looks like you did a lot more work calculating the aggregates, you know, as you...</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=5913" target="_blank">01:38:33.480</a></span> | <span class="t">Looks like I did a lot of work, did you say?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=5916" target="_blank">01:38:36.680</a></span> | <span class="t">Like quite a lot of code here?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=5918" target="_blank">01:38:38.040</a></span> | <span class="t">Well, you're doing more work than you would normally do, essentially you're calculating</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=5922" target="_blank">01:38:42.800</a></span> | <span class="t">all these aggregates as you go through each layer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=5925" target="_blank">01:38:45.680</a></span> | <span class="t">Yes.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=5926" target="_blank">01:38:46.680</a></span> | <span class="t">Wouldn't this mean you're training like your epoch time loser?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=5932" target="_blank">01:38:52.040</a></span> | <span class="t">Now this is super fast.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=5933" target="_blank">01:38:53.680</a></span> | <span class="t">If you think about what a conv has to do, a conv has to go through every 3x3 with a stride</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=5941" target="_blank">01:39:01.960</a></span> | <span class="t">and do this multiplication and then addition.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=5945" target="_blank">01:39:05.240</a></span> | <span class="t">That is a lot more work than simply calculating the per-channel mean.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=5951" target="_blank">01:39:11.600</a></span> | <span class="t">So it adds a little bit of time, but it's less time-intensive than the convolution.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=5958" target="_blank">01:39:18.000</a></span> | <span class="t">So how would you basically position the batch norm?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=5961" target="_blank">01:39:21.240</a></span> | <span class="t">Would it be right after the convolutional layer, or would it be after the relu?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=5966" target="_blank">01:39:26.080</a></span> | <span class="t">Yeah, we'll talk about that in a moment.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=5968" target="_blank">01:39:28.680</a></span> | <span class="t">So at the moment, we have it after the relu, and in the original batch norm paper, I believe</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=5975" target="_blank">01:39:35.200</a></span> | <span class="t">that's where they put it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=5981" target="_blank">01:39:41.120</a></span> | <span class="t">So there's this idea of something called an ablation study, and an ablation study is something</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=5988" target="_blank">01:39:48.720</a></span> | <span class="t">where you basically try kind of turning on and off different pieces of your model to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=5996" target="_blank">01:39:56.180</a></span> | <span class="t">see which bits make which impacts.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=5998" target="_blank">01:39:58.840</a></span> | <span class="t">And one of the things that wasn't done in the original batch norm paper was any kind</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=6002" target="_blank">01:40:02.980</a></span> | <span class="t">of really effective ablation study, and one of the things therefore that was missing was</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=6008" target="_blank">01:40:08.040</a></span> | <span class="t">this question which you just asked, which is where do you put the batch norm, before</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=6012" target="_blank">01:40:12.360</a></span> | <span class="t">the relu, after the relu, whatever.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=6014" target="_blank">01:40:14.400</a></span> | <span class="t">And so since that time, that oversight has caused a lot of problems because it turned</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=6020" target="_blank">01:40:20.200</a></span> | <span class="t">out the original paper didn't actually put it in the best spot.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=6025" target="_blank">01:40:25.000</a></span> | <span class="t">And so then other people since then have now figured that out, and now every time I show</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=6029" target="_blank">01:40:29.060</a></span> | <span class="t">people code where it's actually in the spot that turns out to be better, people always</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=6033" target="_blank">01:40:33.380</a></span> | <span class="t">say your batch norm is in the wrong spot, and I have to go back and say no, I know that's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=6037" target="_blank">01:40:37.720</a></span> | <span class="t">what the paper said, but it turned out that's not actually the right spot, and so it's kind</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=6040" target="_blank">01:40:40.920</a></span> | <span class="t">of caused this confusion.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=6042" target="_blank">01:40:42.680</a></span> | <span class="t">So there's been a lot of question about that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=6046" target="_blank">01:40:46.000</a></span> | <span class="t">So, a little bit of a higher level question, so we started out with CIFAR data, so is the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=6058" target="_blank">01:40:58.440</a></span> | <span class="t">basic reasoning that you use a smaller data set to quickly train a new model, and then</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=6066" target="_blank">01:41:06.480</a></span> | <span class="t">you take the same model and you're using a much bigger data set to get a higher accuracy</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=6075" target="_blank">01:41:15.800</a></span> | <span class="t">level?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=6076" target="_blank">01:41:16.800</a></span> | <span class="t">Is that the basic question?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=6078" target="_blank">01:41:18.580</a></span> | <span class="t">Maybe.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=6079" target="_blank">01:41:19.580</a></span> | <span class="t">So if you had a large data set, or if you were interested in the question of how good</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=6088" target="_blank">01:41:28.000</a></span> | <span class="t">is this technique on a large data set, then yes, what you just said would be what I would</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=6092" target="_blank">01:41:32.240</a></span> | <span class="t">do.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=6093" target="_blank">01:41:33.240</a></span> | <span class="t">I would do lots of testing on a small data set which I had already discovered had the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=6098" target="_blank">01:41:38.640</a></span> | <span class="t">same kinds of properties as my larger data set, and therefore my conclusions would likely</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=6103" target="_blank">01:41:43.260</a></span> | <span class="t">carry forward and then I would test them at the end.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=6106" target="_blank">01:41:46.200</a></span> | <span class="t">Having said that, personally, I'm actually more interested in actually studying small</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=6113" target="_blank">01:41:53.640</a></span> | <span class="t">data sets for their own sake because I find most people I speak to in the real world don't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=6120" target="_blank">01:42:00.960</a></span> | <span class="t">have a million images, they have somewhere between about 2,000 and 20,000 images seems</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=6126" target="_blank">01:42:06.460</a></span> | <span class="t">to be much more common.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=6129" target="_blank">01:42:09.640</a></span> | <span class="t">So I'm very interested in having fewer rows because I think it's more valuable in practice.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=6137" target="_blank">01:42:17.800</a></span> | <span class="t">I'm also pretty interested in small images, not just for the reason you mentioned which</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=6142" target="_blank">01:42:22.120</a></span> | <span class="t">is it allows me to test things out more quickly, but also as I mentioned before, often a small</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=6148" target="_blank">01:42:28.640</a></span> | <span class="t">part of an image actually turns out to be what you're interested in that's certainly</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=6152" target="_blank">01:42:32.540</a></span> | <span class="t">true in medicine.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=6157" target="_blank">01:42:37.160</a></span> | <span class="t">I have two questions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=6159" target="_blank">01:42:39.040</a></span> | <span class="t">The first is on what you mentioned in terms of small data sets, particularly medical imaging</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=6164" target="_blank">01:42:44.440</a></span> | <span class="t">if you've heard of, I guess, is it vicarious to start up in the specialization and one</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=6168" target="_blank">01:42:48.480</a></span> | <span class="t">shot learning?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=6169" target="_blank">01:42:49.480</a></span> | <span class="t">So your opinions on that, and then the second being, this is related to I guess Ali's talk</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=6176" target="_blank">01:42:56.600</a></span> | <span class="t">at NIPS, so I don't want to say it's controversial, but like Yann LeCun, there was like a really,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=6182" target="_blank">01:43:02.000</a></span> | <span class="t">I guess, controversial thread attacking it in terms of what you're talking about as a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=6185" target="_blank">01:43:05.920</a></span> | <span class="t">baseline of theory just not keeping up with practice.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=6191" target="_blank">01:43:11.080</a></span> | <span class="t">And so I guess I was starting with Yann, whereas Ali actually, he tweeted at me quite a bit</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=6195" target="_blank">01:43:15.760</a></span> | <span class="t">trying to defend like he wasn't attacking Yann at all, but in fact, he was trying to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=6203" target="_blank">01:43:23.760</a></span> | <span class="t">support him, but I just kind of feel like a lot of theory as you go is just sort of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=6208" target="_blank">01:43:28.920</a></span> | <span class="t">added data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=6209" target="_blank">01:43:29.920</a></span> | <span class="t">It's hard to keep up other than an archive from Andre Keparthi to keep up, but if the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=6215" target="_blank">01:43:35.040</a></span> | <span class="t">theory isn't keeping up but the industry is the one that's actually setting the standard,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=6218" target="_blank">01:43:38.520</a></span> | <span class="t">then doesn't that mean that people who are actual practitioners are the ones like Yann</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=6223" target="_blank">01:43:43.920</a></span> | <span class="t">LeCun that are publishing the theory that are keeping up to date, or is like academic</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=6227" target="_blank">01:43:47.480</a></span> | <span class="t">research institutions are actually behind?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=6229" target="_blank">01:43:49.420</a></span> | <span class="t">So I don't have any comments on the vicarious papers because I haven't read them.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=6232" target="_blank">01:43:52.960</a></span> | <span class="t">I'm not aware of any of them as actually showing better results than other papers, but I think</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=6240" target="_blank">01:44:00.960</a></span> | <span class="t">they've come a long way in the last 12 months, so that might be wrong.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=6245" target="_blank">01:44:05.720</a></span> | <span class="t">I think the discussion between Yann LeCun and Ali Rahimi is very interesting because</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=6249" target="_blank">01:44:09.040</a></span> | <span class="t">they're both smart people who have interesting things to say.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=6252" target="_blank">01:44:12.680</a></span> | <span class="t">Unfortunately, a lot of people talk Ali's talk as meaning something which he says it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=6260" target="_blank">01:44:20.040</a></span> | <span class="t">didn't mean, and when I listen to his talk I'm not sure he didn't actually mean it at</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=6264" target="_blank">01:44:24.880</a></span> | <span class="t">the time, but he clearly doesn't mean it now, which is, he's now said many times he was</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=6270" target="_blank">01:44:30.160</a></span> | <span class="t">not talking about theory, he was not saying we need more theory at all.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=6274" target="_blank">01:44:34.920</a></span> | <span class="t">Actually he thinks we need more experiments.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=6277" target="_blank">01:44:37.320</a></span> | <span class="t">And so specifically he's also now saying he wished he hadn't used the word rigor, which</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=6282" target="_blank">01:44:42.880</a></span> | <span class="t">I also wish because rigor is kind of meaningless and everybody can kind of say when he says</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=6288" target="_blank">01:44:48.680</a></span> | <span class="t">rigor he means the specific thing I study.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=6295" target="_blank">01:44:55.680</a></span> | <span class="t">So lots of people have kind of taken his talk as being like "Oh yes, this proves that nobody</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=6300" target="_blank">01:45:00.080</a></span> | <span class="t">else should work in neural networks unless they are experts at the one thing I'm an expert</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=6305" target="_blank">01:45:05.200</a></span> | <span class="t">in."</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=6306" target="_blank">01:45:06.200</a></span> | <span class="t">So I'm going to catch up with him and talk more about this in January and hopefully we'll</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=6311" target="_blank">01:45:11.600</a></span> | <span class="t">figure some more stuff out together.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=6313" target="_blank">01:45:13.120</a></span> | <span class="t">But basically what we can clearly agree on, and I think Yann LeCun also agrees on, is careful</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=6322" target="_blank">01:45:22.000</a></span> | <span class="t">experiments are important, just doing things on massive amounts of data using massive amounts</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=6328" target="_blank">01:45:28.080</a></span> | <span class="t">of TPUs or GPUs is not interesting of itself, and we should instead try to design experiments</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=6335" target="_blank">01:45:35.120</a></span> | <span class="t">that give us the maximum amount of insight into what's going on.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=6338" target="_blank">01:45:38.400</a></span> | <span class="t">So Jeremy, is it a good statement to say something like, so dropout and bashnorm are very different</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=6352" target="_blank">01:45:52.160</a></span> | <span class="t">things.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=6353" target="_blank">01:45:53.160</a></span> | <span class="t">Dropout is a regularization technique and bashnorm has maybe some realization effect</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=6359" target="_blank">01:45:59.400</a></span> | <span class="t">but it's actually just about convergence of the optimization method.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=6364" target="_blank">01:46:04.040</a></span> | <span class="t">And I would further say I can't see any reason not to use batchnorm.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=6373" target="_blank">01:46:13.920</a></span> | <span class="t">There are versions of batchnorm that in certain situations turned out not to work so well,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=6380" target="_blank">01:46:20.560</a></span> | <span class="t">but people have figured out ways around that for nearly every one of those situations now.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=6386" target="_blank">01:46:26.240</a></span> | <span class="t">So I would always seek to find a way to use batchnorm.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=6390" target="_blank">01:46:30.800</a></span> | <span class="t">It may be a little harder in RNNs at least, but even there, there are ways of doing batchnorm</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=6398" target="_blank">01:46:38.320</a></span> | <span class="t">in RNNs as well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=6401" target="_blank">01:46:41.080</a></span> | <span class="t">Try and always use batchnorm on every layer if you can.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=6404" target="_blank">01:46:44.440</a></span> | <span class="t">The question that somebody asked is, does it mean I can stop normalizing my data?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=6423" target="_blank">01:47:03.400</a></span> | <span class="t">It does, although do it anyway because it's not at all hard to do it, and at least that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=6426" target="_blank">01:47:06.240</a></span> | <span class="t">way the people using your data, I don't know, they kind of know how you've normalized it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=6432" target="_blank">01:47:12.920</a></span> | <span class="t">And particularly with these issues around a lot of libraries, in my opinion, my experiments</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=6441" target="_blank">01:47:21.800</a></span> | <span class="t">don't deal with batchnorm correctly for pre-trained models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=6446" target="_blank">01:47:26.680</a></span> | <span class="t">Just remember that when somebody starts retraining, those averages and stuff are going to change</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=6452" target="_blank">01:47:32.320</a></span> | <span class="t">for your dataset, and so if your new dataset has very different input averages, it could</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=6456" target="_blank">01:47:36.640</a></span> | <span class="t">really cause a lot of problems.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=6460" target="_blank">01:47:40.440</a></span> | <span class="t">So yeah, I went through a period where I actually stopped normalizing my data, and things kind</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=6466" target="_blank">01:47:46.660</a></span> | <span class="t">of worked, but it's probably not worth it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=6474" target="_blank">01:47:54.520</a></span> | <span class="t">So the rest of this is identical.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=6477" target="_blank">01:47:57.280</a></span> | <span class="t">All I've done is I've changed conv_layer to bn_layer, but I've done one more thing, which</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=6483" target="_blank">01:48:03.720</a></span> | <span class="t">is I'm trying to get closer and closer to modern approaches, which I've added a single</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=6488" target="_blank">01:48:08.480</a></span> | <span class="t">convolutional layer at the start, with a bigger kernel size and a stride of 1.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=6496" target="_blank">01:48:16.600</a></span> | <span class="t">Why have I done that?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=6498" target="_blank">01:48:18.640</a></span> | <span class="t">So the basic idea is that I want my first layer to have a richer input.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=6505" target="_blank">01:48:25.960</a></span> | <span class="t">So before my first layer had an input of just 3, because it was just 3 channels.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=6511" target="_blank">01:48:31.360</a></span> | <span class="t">But if I start with my image, and I kind of take a bigger area, and I do a convolution</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=6530" target="_blank">01:48:50.320</a></span> | <span class="t">using that bigger area, in this case I'm doing 5x5, then that kind of allows me to try and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=6540" target="_blank">01:49:00.800</a></span> | <span class="t">find more interesting, richer features in that 5x5 area.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=6546" target="_blank">01:49:06.640</a></span> | <span class="t">And so then I spit out a bigger output, in this case I spit out 10 5x5 filters.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=6555" target="_blank">01:49:15.620</a></span> | <span class="t">And so the idea is pretty much every state-of-the-art convolutional architecture now starts out</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=6561" target="_blank">01:49:21.840</a></span> | <span class="t">with a single conv layer with like a 5x5 or 7x7 or sometimes even like 11x11 convolution</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=6572" target="_blank">01:49:32.000</a></span> | <span class="t">with quite a few filters, something like 32 filters coming out.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=6581" target="_blank">01:49:41.200</a></span> | <span class="t">And it's just a way of trying to -- because I used a stride of 1 and a padding of kernel</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=6589" target="_blank">01:49:49.220</a></span> | <span class="t">size -1/2, that means that my output is going to be exactly the same size as my input, but</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=6595" target="_blank">01:49:55.040</a></span> | <span class="t">just got more filters.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=6596" target="_blank">01:49:56.440</a></span> | <span class="t">So this is just a good way of trying to create a richer starting point for my sequence of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=6603" target="_blank">01:50:03.400</a></span> | <span class="t">convolutional layers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=6605" target="_blank">01:50:05.640</a></span> | <span class="t">So that's the basic theory of why I've added this single convolution, which I just do once</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=6611" target="_blank">01:50:11.140</a></span> | <span class="t">at the start, and then I just go through all my layers, and then I do my adaptive max pooling</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=6616" target="_blank">01:50:16.440</a></span> | <span class="t">and my final classifier layer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=6619" target="_blank">01:50:19.000</a></span> | <span class="t">So it's a minor tweak, but it helps.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=6622" target="_blank">01:50:22.960</a></span> | <span class="t">And so you'll see now I can go from 60% and after a couple it's 45%, now after a couple</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=6634" target="_blank">01:50:34.360</a></span> | <span class="t">it's 57%, and after a few more I'm up to 68%.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=6638" target="_blank">01:50:38.760</a></span> | <span class="t">So you can see the batch norm and tiny bit, the conv layer at the start, it's helping.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=6645" target="_blank">01:50:45.160</a></span> | <span class="t">And what's more, you can see this is still increasing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=6648" target="_blank">01:50:48.840</a></span> | <span class="t">So that's looking pretty encouraging.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=6652" target="_blank">01:50:52.160</a></span> | <span class="t">So given that this is looking pretty good, an obvious thing to try is to try increasing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=6662" target="_blank">01:51:02.000</a></span> | <span class="t">the depth of the model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=6663" target="_blank">01:51:03.680</a></span> | <span class="t">And now I can't just add more of my stride 2 layers, because remember how at half the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=6670" target="_blank">01:51:10.800</a></span> | <span class="t">size of the image each time?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=6672" target="_blank">01:51:12.640</a></span> | <span class="t">I'm basically down to 2x2 at the end, so I can't add much more.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=6678" target="_blank">01:51:18.080</a></span> | <span class="t">So what I did instead was I said, okay, here's my original layers, these are my stride 2 layers,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=6684" target="_blank">01:51:24.360</a></span> | <span class="t">for every one also create a stride 1 layer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=6688" target="_blank">01:51:28.280</a></span> | <span class="t">So a stride 1 layer doesn't change the size.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=6690" target="_blank">01:51:30.940</a></span> | <span class="t">And so now I'm saying zip my stride 2 layers and my stride 1 layers together, and so first</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=6698" target="_blank">01:51:38.920</a></span> | <span class="t">of all do the stride 2 and then do the stride 1.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=6702" target="_blank">01:51:42.300</a></span> | <span class="t">So this is now actually twice as deep, but I end up with the exact same 2x2 that I had</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=6717" target="_blank">01:51:57.040</a></span> | <span class="t">before.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=6718" target="_blank">01:51:58.760</a></span> | <span class="t">And so if I try this, here after 1, 2, 3, 4 epochs is at 65%, after 1, 2, 3 epochs I'm</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=6727" target="_blank">01:52:07.080</a></span> | <span class="t">still at 65%.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=6728" target="_blank">01:52:08.080</a></span> | <span class="t">It hasn't helped.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=6730" target="_blank">01:52:10.960</a></span> | <span class="t">And so the reason it hasn't helped is I'm now too deep even for batch norm to handle</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=6739" target="_blank">01:52:19.720</a></span> | <span class="t">it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=6740" target="_blank">01:52:20.720</a></span> | <span class="t">So my depth is now 1, 2, 3, 4, 5 times 2 is 10, 11, conv1, 12.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=6751" target="_blank">01:52:31.100</a></span> | <span class="t">So 12 layers deep, it's possible to train a standard convNet 12 layers deep, but it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=6756" target="_blank">01:52:36.800</a></span> | <span class="t">starts to get difficult to do it properly.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=6759" target="_blank">01:52:39.480</a></span> | <span class="t">And it certainly doesn't seem to be really helping much, if at all.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=6763" target="_blank">01:52:43.100</a></span> | <span class="t">So that's where I'm instead going to replace this with a ResNet.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=6769" target="_blank">01:52:49.120</a></span> | <span class="t">So ResNet is our final stage, and what a ResNet does is I'm going to replace our BN layer,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=6777" target="_blank">01:52:57.880</a></span> | <span class="t">I'm going to inherit from BN layer, and replace our forward with that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=6784" target="_blank">01:53:04.080</a></span> | <span class="t">And that's it, everything else is going to be identical.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=6787" target="_blank">01:53:07.840</a></span> | <span class="t">But now I'm going to do way lots of layers, I'm going to make it 4 times deeper, and it's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=6793" target="_blank">01:53:13.160</a></span> | <span class="t">going to train beautifully, just because of that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=6798" target="_blank">01:53:18.680</a></span> | <span class="t">So why does that help so much?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=6802" target="_blank">01:53:22.120</a></span> | <span class="t">So this is called a ResNet block, and as you can see I'm saying my predictions equals my</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=6816" target="_blank">01:53:36.240</a></span> | <span class="t">input plus some function, in this case a convolution of my input.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=6824" target="_blank">01:53:44.360</a></span> | <span class="t">That's what I've written here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=6827" target="_blank">01:53:47.460</a></span> | <span class="t">And so I'm now going to shuffle that around a little bit.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=6833" target="_blank">01:53:53.120</a></span> | <span class="t">And I'm going to say f(x) = y - x.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=6845" target="_blank">01:54:05.720</a></span> | <span class="t">So that's the same thing shuffled around.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=6849" target="_blank">01:54:09.440</a></span> | <span class="t">That's my prediction from the previous layer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=6854" target="_blank">01:54:14.680</a></span> | <span class="t">And so what this is then doing is it's trying to fit a function to the difference between</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=6860" target="_blank">01:54:20.540</a></span> | <span class="t">these two.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=6862" target="_blank">01:54:22.580</a></span> | <span class="t">And so the difference is actually the residual.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=6876" target="_blank">01:54:36.860</a></span> | <span class="t">So if this is what I'm trying to calculate, my actual y value, and this is the thing that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=6885" target="_blank">01:54:45.560</a></span> | <span class="t">I've most recently calculated, then the difference between the two is basically the error in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=6891" target="_blank">01:54:51.140</a></span> | <span class="t">terms of what I've calculated so far.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=6893" target="_blank">01:54:53.920</a></span> | <span class="t">And so this is therefore saying that try to find a set of convolutional weights that attempts</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=6901" target="_blank">01:55:01.200</a></span> | <span class="t">to fill in the amount I was off by.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=6906" target="_blank">01:55:06.920</a></span> | <span class="t">So in other words, if we have some inputs coming in, and then we have this function</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=6917" target="_blank">01:55:17.600</a></span> | <span class="t">which is basically trying to predict the error, it's like how much are we off by, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=6924" target="_blank">01:55:24.480</a></span> | <span class="t">And then we add that on.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=6925" target="_blank">01:55:25.960</a></span> | <span class="t">So we basically add on this additional prediction of how much were we wrong by.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=6931" target="_blank">01:55:31.020</a></span> | <span class="t">And then we add on another prediction of how much were we wrong by that time.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=6935" target="_blank">01:55:35.240</a></span> | <span class="t">And add on another prediction of how much were we wrong by that time.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=6938" target="_blank">01:55:38.520</a></span> | <span class="t">Then each time we're kind of zooming in, getting closer and closer to our correct answer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=6945" target="_blank">01:55:45.720</a></span> | <span class="t">And each time we're saying we've got to a certain point, but we've still got an error.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=6951" target="_blank">01:55:51.440</a></span> | <span class="t">We've still got a residual.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=6953" target="_blank">01:55:53.320</a></span> | <span class="t">So let's try and create a model that just predicts that residual, and add that onto</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=6958" target="_blank">01:55:58.120</a></span> | <span class="t">our previous model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=6959" target="_blank">01:55:59.120</a></span> | <span class="t">And then let's build another model that predicts the residual, and add that onto our previous</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=6963" target="_blank">01:56:03.360</a></span> | <span class="t">model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=6964" target="_blank">01:56:04.360</a></span> | <span class="t">And if we keep doing that again and again, we should get closer and closer to our answer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=6970" target="_blank">01:56:10.760</a></span> | <span class="t">And this is based on a theory called boosting, which people that have done some machine learning</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=6976" target="_blank">01:56:16.680</a></span> | <span class="t">will have certainly come across.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=6978" target="_blank">01:56:18.960</a></span> | <span class="t">And so basically the trick here is that by specifying that as being the thing that we're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=6990" target="_blank">01:56:30.440</a></span> | <span class="t">trying to calculate, then we kind of get boosting for free.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7000" target="_blank">01:56:40.680</a></span> | <span class="t">It's because we can just juggle that around to show that actually it's just calculating</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7005" target="_blank">01:56:45.760</a></span> | <span class="t">a model on the residual.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7008" target="_blank">01:56:48.440</a></span> | <span class="t">So that's kind of amazing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7012" target="_blank">01:56:52.200</a></span> | <span class="t">And it totally works.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7015" target="_blank">01:56:55.920</a></span> | <span class="t">As you can see here, I've now got my standard batch norm layer, which is something which</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7022" target="_blank">01:57:02.200</a></span> | <span class="t">is going to reduce my size by 2 because it's got the stride 2.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7026" target="_blank">01:57:06.960</a></span> | <span class="t">And then I've got a ResNet layer of stride 1, and another ResNet layer of stride 1.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7031" target="_blank">01:57:11.560</a></span> | <span class="t">I think I said that was 4 of these, it's actually 3 of these.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7035" target="_blank">01:57:15.580</a></span> | <span class="t">So this is now 3 times deeper, I've zipped through all of those.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7039" target="_blank">01:57:19.120</a></span> | <span class="t">And so I've now got a function of a function of a function.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7043" target="_blank">01:57:23.440</a></span> | <span class="t">So 3 layers per group, and then my conv at the start, and my linear at the end.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7050" target="_blank">01:57:30.680</a></span> | <span class="t">So this is now 3 times bigger than my original.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7055" target="_blank">01:57:35.440</a></span> | <span class="t">And if I fit it, you can see it just keeps going up, and up, and up, and up.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7060" target="_blank">01:57:40.560</a></span> | <span class="t">I keep fitting it more, it keeps going up, and up, and up, and up, and up.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7064" target="_blank">01:57:44.800</a></span> | <span class="t">And it's still going up when I kind of got bored.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7068" target="_blank">01:57:48.940</a></span> | <span class="t">So the ResNet has been a really important development, and it's allowed us to create</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7080" target="_blank">01:58:00.000</a></span> | <span class="t">these really deep networks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7084" target="_blank">01:58:04.000</a></span> | <span class="t">The full ResNet does not quite look the way I've described it here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7089" target="_blank">01:58:09.480</a></span> | <span class="t">The full ResNet doesn't just have one convolution, but it actually has two convolutions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7096" target="_blank">01:58:16.440</a></span> | <span class="t">So the way people normally draw ResNet blocks is they normally say you've got some input</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7101" target="_blank">01:58:21.400</a></span> | <span class="t">coming into the layer, it goes through one convolution, two convolutions, and then gets</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7111" target="_blank">01:58:31.800</a></span> | <span class="t">added back to the original input.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7116" target="_blank">01:58:36.440</a></span> | <span class="t">That's the full version of a ResNet block.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7118" target="_blank">01:58:38.960</a></span> | <span class="t">In my case, I've just done one convolution.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7122" target="_blank">01:58:42.920</a></span> | <span class="t">And then you'll see also, in every block, one of them is not a ResNet block, but a standard</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7140" target="_blank">01:59:00.880</a></span> | <span class="t">convolution with a stride of 2.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7146" target="_blank">01:59:06.000</a></span> | <span class="t">This is called a bottleneck layer, and the idea is this is not a ResNet block.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7151" target="_blank">01:59:11.040</a></span> | <span class="t">So from time to time, we actually change the geometry, we're doing the stride too.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7156" target="_blank">01:59:16.600</a></span> | <span class="t">In ResNet, we don't actually use just a standard convolutional layer, there's actually a different</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7162" target="_blank">01:59:22.080</a></span> | <span class="t">form of bottleneck block that I'm not going to teach you in this course, I'm going to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7165" target="_blank">01:59:25.800</a></span> | <span class="t">teach you in Part 2.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7166" target="_blank">01:59:26.880</a></span> | <span class="t">But as you can see, even this somewhat simplified version of a ResNet still works pretty well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7173" target="_blank">01:59:33.160</a></span> | <span class="t">And so we can make it a little bit bigger.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7178" target="_blank">01:59:38.360</a></span> | <span class="t">And so here I've just increased all of my sizes, I have still got my 3, and also I've</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7185" target="_blank">01:59:45.120</a></span> | <span class="t">added dropout.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7186" target="_blank">01:59:46.920</a></span> | <span class="t">So at this point, I'm going to say this is, other than the minor simplification of ResNet,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7192" target="_blank">01:59:52.680</a></span> | <span class="t">a reasonable approximation of a good starting point for a modern architecture.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7198" target="_blank">01:59:58.560</a></span> | <span class="t">And so now I've added in my point 2 dropout, I've increased the size here, and if I train</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7203" target="_blank">02:00:03.720</a></span> | <span class="t">this, I can train it for a while, it's going pretty well, I can then add in TTA at the end,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7210" target="_blank">02:00:10.440</a></span> | <span class="t">eventually I get 85%.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7212" target="_blank">02:00:12.800</a></span> | <span class="t">And this is at a point now where literally I wrote this whole notebook in like 3 hours.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7218" target="_blank">02:00:18.560</a></span> | <span class="t">We can create this thing in 3 hours, and this is like an accuracy that in 2012, 2013 was</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7226" target="_blank">02:00:26.320</a></span> | <span class="t">considered pretty much state-of-the-art for SciFi 10.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7230" target="_blank">02:00:30.560</a></span> | <span class="t">Nowadays, the most recent results are like 97%, there's plenty of room we can still improve,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7243" target="_blank">02:00:43.360</a></span> | <span class="t">but they're all based on these techniques.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7245" target="_blank">02:00:45.600</a></span> | <span class="t">There isn't really anything -- when we start looking in Part 2 at how to get this right</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7252" target="_blank">02:00:52.640</a></span> | <span class="t">up to state-of-the-art, you'll see it's basically better approaches to data augmentation, better</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7257" target="_blank">02:00:57.360</a></span> | <span class="t">approaches to regularization, some tweaks on ResNet, but it's all basically this idea.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7264" target="_blank">02:01:04.400</a></span> | <span class="t">"So is the training on the residual method, is that only, looks like it's a generic thing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7275" target="_blank">02:01:15.200</a></span> | <span class="t">that can be applied, non-image problems?"</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7278" target="_blank">02:01:18.000</a></span> | <span class="t">Oh, great question.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7279" target="_blank">02:01:19.400</a></span> | <span class="t">Yeah, yes it is, but it's been ignored everywhere else.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7284" target="_blank">02:01:24.360</a></span> | <span class="t">In NLP, something called the transformer architecture recently appeared, and it was shown to be the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7291" target="_blank">02:01:31.400</a></span> | <span class="t">state-of-the-art for translation, and it's got a simple ResNet structure in it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7298" target="_blank">02:01:38.480</a></span> | <span class="t">First time I've ever seen it in NLP.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7300" target="_blank">02:01:40.000</a></span> | <span class="t">I haven't really seen anybody else take advantage of it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7304" target="_blank">02:01:44.600</a></span> | <span class="t">This general approach, we call these skip connections, this idea of skipping over a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7308" target="_blank">02:01:48.400</a></span> | <span class="t">layer and doing an identity, it's been appearing a lot in computer vision and nobody else much</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7315" target="_blank">02:01:55.400</a></span> | <span class="t">seems to be using it, even though there's nothing computer vision specific about it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7319" target="_blank">02:01:59.680</a></span> | <span class="t">So I think it's a big opportunity.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7323" target="_blank">02:02:03.780</a></span> | <span class="t">So final stage I want to show you is how to use an extra feature of PyTorch to do something</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7332" target="_blank">02:02:12.600</a></span> | <span class="t">cool, and it's going to be a segue into Part 2.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7336" target="_blank">02:02:16.720</a></span> | <span class="t">It's going to be our first little hint as to what else we can build on these neural nets.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7342" target="_blank">02:02:22.280</a></span> | <span class="t">It's also going to take us all the way back to lesson 1, which is we're going to do dogs</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7346" target="_blank">02:02:26.960</a></span> | <span class="t">and cats.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7349" target="_blank">02:02:29.080</a></span> | <span class="t">So going all the way back to dogs and cats, we're going to create a ResNet-34.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7354" target="_blank">02:02:34.700</a></span> | <span class="t">So these different ResNet-34, 50, 101, they're basically just different numbers, different</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7363" target="_blank">02:02:43.640</a></span> | <span class="t">size blocks, it's like how many of these pieces do you have before each bottleneck block, and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7369" target="_blank">02:02:49.960</a></span> | <span class="t">then how many of these sets of super blocks do you have.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7373" target="_blank">02:02:53.840</a></span> | <span class="t">That's all these different numbers mean.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7375" target="_blank">02:02:55.880</a></span> | <span class="t">So if you look at the TorchVision source code, you can actually see the definition of these</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7381" target="_blank">02:03:01.720</a></span> | <span class="t">different ResNets, you'll see they're all just different parameters.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7389" target="_blank">02:03:09.440</a></span> | <span class="t">So we're going to use ResNet-34, and so we're going to do this a little bit more by hand.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7396" target="_blank">02:03:16.240</a></span> | <span class="t">So if this is my architecture, this is just the name of a function, then I can call it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7401" target="_blank">02:03:21.280</a></span> | <span class="t">to get that model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7403" target="_blank">02:03:23.160</a></span> | <span class="t">And then true, if we look at the definition, is do I want the pre-trained, so in other</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7408" target="_blank">02:03:28.600</a></span> | <span class="t">words, is it going to load in the pre-trained image net weights.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7412" target="_blank">02:03:32.560</a></span> | <span class="t">So m now contains a model, and so I can take a look at it like so.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7419" target="_blank">02:03:39.600</a></span> | <span class="t">And so you can see here what's going on is that inside here I've got my initial 2D convolution,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7430" target="_blank">02:03:50.400</a></span> | <span class="t">and here is that kernel size of 7x7.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7434" target="_blank">02:03:54.120</a></span> | <span class="t">And interestingly in this case, it actually starts out with a 7x7 strived 2.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7438" target="_blank">02:03:58.680</a></span> | <span class="t">There's the padding that we talked about to make sure that we don't lose the edges.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7442" target="_blank">02:04:02.520</a></span> | <span class="t">There's our batchnorm, there's our ReLU, and you get the idea, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7448" target="_blank">02:04:08.520</a></span> | <span class="t">And then so here you can now see there's a layer that contains a bunch of blocks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7455" target="_blank">02:04:15.120</a></span> | <span class="t">So here's a block which contains a conv, batchnorm, ReLU, conv, batchnorm.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7460" target="_blank">02:04:20.600</a></span> | <span class="t">You can't see it printed, but after this is where it does the addition.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7465" target="_blank">02:04:25.680</a></span> | <span class="t">So there's like a whole ResNet block, and then another ResNet block, and then another</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7469" target="_blank">02:04:29.280</a></span> | <span class="t">ResNet block.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7473" target="_blank">02:04:33.560</a></span> | <span class="t">And then you can see also sometimes you see one where there's a strived 2.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7480" target="_blank">02:04:40.760</a></span> | <span class="t">So here's actually one of these bottleneck layers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7487" target="_blank">02:04:47.240</a></span> | <span class="t">So you can kind of see how this is structured.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7491" target="_blank">02:04:51.440</a></span> | <span class="t">So in our case, sorry I skipped over this a little bit, but the approach that we ended</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7500" target="_blank">02:05:00.280</a></span> | <span class="t">up using for ReLU was to put it before our batchnorm, which we've got batchnorm, ReLU,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7524" target="_blank">02:05:24.520</a></span> | <span class="t">conv, batchnorm, ReLU, conv.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7526" target="_blank">02:05:26.160</a></span> | <span class="t">So you can see the order that they're using it here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7529" target="_blank">02:05:29.600</a></span> | <span class="t">And you'll find there's 3 different versions of ResNet floating around.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7536" target="_blank">02:05:36.520</a></span> | <span class="t">The one which actually turns out to be the best is called the Preact ResNet, which has</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7541" target="_blank">02:05:41.840</a></span> | <span class="t">a different ordering again, but you can look it up.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7548" target="_blank">02:05:48.160</a></span> | <span class="t">It's basically a different order of where the ReLU and where the batchnorm sit.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7553" target="_blank">02:05:53.240</a></span> | <span class="t">So we're going to start with a standard ResNet 34, and normally what we do is we need to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7561" target="_blank">02:06:01.000</a></span> | <span class="t">now turn this into something that can predict dogs versus cats.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7566" target="_blank">02:06:06.480</a></span> | <span class="t">So currently the final layer has 1000 features because ImageNet has 1000 features.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7574" target="_blank">02:06:14.040</a></span> | <span class="t">So we need to get rid of this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7576" target="_blank">02:06:16.500</a></span> | <span class="t">So when you use conf-learner from pre-trained in fast.ai, it actually deletes this layer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7583" target="_blank">02:06:23.280</a></span> | <span class="t">for you, and it also deletes this layer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7589" target="_blank">02:06:29.440</a></span> | <span class="t">And something that as far as I know is unique to fast.ai is we see this average pooling</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7595" target="_blank">02:06:35.840</a></span> | <span class="t">layer of size 7x7, so this is basically the adaptive pooling layer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7601" target="_blank">02:06:41.320</a></span> | <span class="t">But whoever wrote this didn't know about adaptive pooling, so they manually said I know it's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7605" target="_blank">02:06:45.380</a></span> | <span class="t">meant to be 7x7.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7607" target="_blank">02:06:47.520</a></span> | <span class="t">So in fast.ai, we replace this with adaptive pooling, but we actually do both adaptive average</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7612" target="_blank">02:06:52.120</a></span> | <span class="t">pooling and adaptive max pooling, and we then concatenate the two together, which is something</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7620" target="_blank">02:07:00.080</a></span> | <span class="t">we invented, but at the same time we invented it, somebody wrote a paper about it, so we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7625" target="_blank">02:07:05.560</a></span> | <span class="t">don't get any credit.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7626" target="_blank">02:07:06.560</a></span> | <span class="t">But I think we're the only library that provides it, and certainly anyone that does it by default.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7633" target="_blank">02:07:13.440</a></span> | <span class="t">We're going to, for the purpose of this exercise though, do a simple version where we delete</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7638" target="_blank">02:07:18.120</a></span> | <span class="t">the last two layers, so we'll grab all the children of the model, we'll delete the last</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7642" target="_blank">02:07:22.160</a></span> | <span class="t">two layers, and then instead we're going to add a convolution which just has two outputs.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7651" target="_blank">02:07:31.480</a></span> | <span class="t">I'll show you why in a moment.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7655" target="_blank">02:07:35.080</a></span> | <span class="t">Then we're going to do our average pooling, and then we're going to do our softmax.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7661" target="_blank">02:07:41.680</a></span> | <span class="t">So that's a model which you'll see that this one has a fully connected layer at the end,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7669" target="_blank">02:07:49.820</a></span> | <span class="t">this one does not have a fully connected layer at the end.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7673" target="_blank">02:07:53.000</a></span> | <span class="t">But if you think about it, this convolutional layer is going to be 2 filters only, and it's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7681" target="_blank">02:08:01.720</a></span> | <span class="t">going to be 2x7x7.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7685" target="_blank">02:08:05.200</a></span> | <span class="t">And so once we then do the average pooling, it's going to end up being just two numbers</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7690" target="_blank">02:08:10.240</a></span> | <span class="t">that it produces.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7691" target="_blank">02:08:11.240</a></span> | <span class="t">So this is a different way of producing just two numbers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7693" target="_blank">02:08:13.560</a></span> | <span class="t">I'm not going to say it's better, I'm just going to say it's different, but there's a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7697" target="_blank">02:08:17.720</a></span> | <span class="t">reason we do it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7698" target="_blank">02:08:18.720</a></span> | <span class="t">I'll show you the reason.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7700" target="_blank">02:08:20.400</a></span> | <span class="t">We can now train this model in the usual way.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7703" target="_blank">02:08:23.480</a></span> | <span class="t">So we can say transforms.model, image_classifier_data_from_paths, and then we can use that conv_learner_from_model_data</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7711" target="_blank">02:08:31.400</a></span> | <span class="t">we just learned about.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7712" target="_blank">02:08:32.640</a></span> | <span class="t">I'm now going to freeze every single layer except for that one, and this is the 4th last</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7721" target="_blank">02:08:41.480</a></span> | <span class="t">layer, so we'll say freeze to -4.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7725" target="_blank">02:08:45.240</a></span> | <span class="t">And so this is just training the last layer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7728" target="_blank">02:08:48.320</a></span> | <span class="t">So we get 99.1% accuracy, so this approach is working fine.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7733" target="_blank">02:08:53.200</a></span> | <span class="t">And here's what we can do though.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7735" target="_blank">02:08:55.200</a></span> | <span class="t">We can now do something called class_activation_maps.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7745" target="_blank">02:09:05.800</a></span> | <span class="t">What we're going to do is we're going to try to look at this particular cat, and we're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7751" target="_blank">02:09:11.360</a></span> | <span class="t">going to use a technique called class_activation_maps where we take our model and we ask it which</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7756" target="_blank">02:09:16.920</a></span> | <span class="t">parts of this image turned out to be important.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7761" target="_blank">02:09:21.040</a></span> | <span class="t">And when we do this, it's going to feed out, this is the picture it's going to create.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7767" target="_blank">02:09:27.040</a></span> | <span class="t">And so as you can see here, it's found the cat.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7770" target="_blank">02:09:30.760</a></span> | <span class="t">So how did it do that?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7771" target="_blank">02:09:31.920</a></span> | <span class="t">Well the way it did that, we'll kind of work backwards, is to produce this matrix.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7778" target="_blank">02:09:38.320</a></span> | <span class="t">You'll see in this matrix, there's some pretty big numbers around about here which correspond</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7785" target="_blank">02:09:45.200</a></span> | <span class="t">to our cat.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7787" target="_blank">02:09:47.840</a></span> | <span class="t">So what is this matrix?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7789" target="_blank">02:09:49.980</a></span> | <span class="t">This matrix is simply equal to the value of this feature matrix times this py vector.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7804" target="_blank">02:10:04.600</a></span> | <span class="t">The py vector is simply equal to the predictions, which in this case said I'm 100% confident</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7811" target="_blank">02:10:11.760</a></span> | <span class="t">it's a cat.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7813" target="_blank">02:10:13.360</a></span> | <span class="t">So this is just equal to the value of, if I just call the model passing in our cat, then</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7822" target="_blank">02:10:22.560</a></span> | <span class="t">we get our predictions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7823" target="_blank">02:10:23.560</a></span> | <span class="t">So that's just the value of our predictions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7825" target="_blank">02:10:25.600</a></span> | <span class="t">So py is just the value of our predictions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7828" target="_blank">02:10:28.900</a></span> | <span class="t">What about feed?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7829" target="_blank">02:10:29.900</a></span> | <span class="t">What's that equal to?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7831" target="_blank">02:10:31.700</a></span> | <span class="t">Feed is equal to the values in this layer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7839" target="_blank">02:10:39.960</a></span> | <span class="t">In other words, the value that comes out of the final convolutional layer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7846" target="_blank">02:10:46.700</a></span> | <span class="t">So it's actually the 7x7x2.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7852" target="_blank">02:10:52.120</a></span> | <span class="t">And so you can see here, the shape of features is 2 filters by 7x7.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7861" target="_blank">02:11:01.880</a></span> | <span class="t">So the idea is, if we multiply that vector by that tensor, then it's going to end up</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7872" target="_blank">02:11:12.080</a></span> | <span class="t">grabbing all of the first channel, because that's a 1, and none of the second channel,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7878" target="_blank">02:11:18.200</a></span> | <span class="t">because that's a 0.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7880" target="_blank">02:11:20.480</a></span> | <span class="t">And so therefore it's going to return the value of the last convolutional layer for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7887" target="_blank">02:11:27.920</a></span> | <span class="t">the section which lines up with being a cat.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7891" target="_blank">02:11:31.560</a></span> | <span class="t">But if you think about it, the first section lines up with being a cat, the second section</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7896" target="_blank">02:11:36.880</a></span> | <span class="t">lines up with being a dog.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7898" target="_blank">02:11:38.440</a></span> | <span class="t">So if we multiply that tensor by that tensor, we end up with this matrix.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7905" target="_blank">02:11:45.840</a></span> | <span class="t">And this matrix is which parts are most like a cat.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7911" target="_blank">02:11:51.640</a></span> | <span class="t">Or to put it another way, in our model, the only thing that happened after the convolutional</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7917" target="_blank">02:11:57.360</a></span> | <span class="t">layer was an average pooling layer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7920" target="_blank">02:12:00.840</a></span> | <span class="t">So the average pooling layer took that 7x7 grid and said average out how much each part</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7927" target="_blank">02:12:07.360</a></span> | <span class="t">is cat-like.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7928" target="_blank">02:12:08.360</a></span> | <span class="t">And so my final prediction was the average cattiness of the whole thing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7937" target="_blank">02:12:17.040</a></span> | <span class="t">And so because it had to be able to average out these things to get the average cattiness,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7942" target="_blank">02:12:22.640</a></span> | <span class="t">that means I could then just take this matrix and resize it to be the same size as my original</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7949" target="_blank">02:12:29.740</a></span> | <span class="t">cat and just overlay it on top to get this heatmap.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7954" target="_blank">02:12:34.440</a></span> | <span class="t">So the way you can use this technique at home is to basically calculate this matrix on some</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7961" target="_blank">02:12:41.680</a></span> | <span class="t">really big picture.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7964" target="_blank">02:12:44.960</a></span> | <span class="t">You can calculate this matrix on a quick small little ConvNet and then zoom into the bit</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7970" target="_blank">02:12:50.280</a></span> | <span class="t">that has the highest value, and then rerun it just on that part.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7975" target="_blank">02:12:55.720</a></span> | <span class="t">So this is the area that seems to be the most like a cat or the most like a dog, that zoom</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7980" target="_blank">02:13:00.680</a></span> | <span class="t">in to that bit.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7984" target="_blank">02:13:04.120</a></span> | <span class="t">So I skipped over that pretty quickly because we ran out of time.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7989" target="_blank">02:13:09.680</a></span> | <span class="t">And so we'll be learning more about these kind of approaches in Part 2 and we can talk</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7993" target="_blank">02:13:13.040</a></span> | <span class="t">about it more on the forum, but hopefully you get the idea.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=7995" target="_blank">02:13:15.400</a></span> | <span class="t">The one thing I totally skipped over was how do we actually ask for that particular layer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=8002" target="_blank">02:13:22.960</a></span> | <span class="t">I'll let you read about this during the week, but basically there's a thing called a hook.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=8009" target="_blank">02:13:29.120</a></span> | <span class="t">So we called save_features, which is this little class that we wrote that goes register_forward_hook.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=8019" target="_blank">02:13:39.520</a></span> | <span class="t">And basically a forward_hook is a special PyTorch thing that every time it calculates</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=8024" target="_blank">02:13:44.880</a></span> | <span class="t">a layer, it runs this function.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=8027" target="_blank">02:13:47.740</a></span> | <span class="t">It's like a callback, basically.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=8029" target="_blank">02:13:49.960</a></span> | <span class="t">It's like a callback that happens every time it calculates a layer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=8032" target="_blank">02:13:52.840</a></span> | <span class="t">And so in this case, it just saved the value of the particular layer that I was interested</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=8039" target="_blank">02:13:59.360</a></span> | <span class="t">in.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=8041" target="_blank">02:14:01.260</a></span> | <span class="t">And so that way I was able to go inside here and grab those features out after I was done.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=8051" target="_blank">02:14:11.000</a></span> | <span class="t">So I called save_features, that gives me my hook, and then later on I can just grab the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=8056" target="_blank">02:14:16.200</a></span> | <span class="t">value that I saved.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=8058" target="_blank">02:14:18.380</a></span> | <span class="t">So I skipped over that pretty quickly, but if you look in the PyTorch docs, they have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=8061" target="_blank">02:14:21.840</a></span> | <span class="t">some more information and help about that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=8064" target="_blank">02:14:24.560</a></span> | <span class="t">Yes, you're next.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=8066" target="_blank">02:14:26.040</a></span> | <span class="t">Can you spend five minutes talking about your journey into deep learning and finally how</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=8077" target="_blank">02:14:37.440</a></span> | <span class="t">can we keep up with important research that is important to practitioners?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=8086" target="_blank">02:14:46.320</a></span> | <span class="t">I think I'll close more on the latter bit, which is like what now?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=8090" target="_blank">02:14:50.480</a></span> | <span class="t">So for those of you who are interested, you should aim to come back for part 2.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=8097" target="_blank">02:14:57.540</a></span> | <span class="t">If you're aiming to come back for part 2, how many people would like to come back for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=8100" target="_blank">02:15:00.880</a></span> | <span class="t">part 2?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=8101" target="_blank">02:15:01.880</a></span> | <span class="t">Okay, that's not bad.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=8102" target="_blank">02:15:02.880</a></span> | <span class="t">I think almost everybody.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=8105" target="_blank">02:15:05.000</a></span> | <span class="t">So if you want to come back for part 2, be aware of this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=8108" target="_blank">02:15:08.700</a></span> | <span class="t">By that time, you're expected to have mastered all of the techniques we've learned in part</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=8113" target="_blank">02:15:13.000</a></span> | <span class="t">1.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=8114" target="_blank">02:15:14.000</a></span> | <span class="t">There's plenty of time between now and then, even if you haven't done much or any ML before,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=8119" target="_blank">02:15:19.440</a></span> | <span class="t">but it does assume that you're going to be working at the same level of intensity from</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=8124" target="_blank">02:15:24.840</a></span> | <span class="t">now until then that you have been with practicing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=8127" target="_blank">02:15:27.920</a></span> | <span class="t">So generally speaking, the people who did well in part 2 last year had watched each</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=8133" target="_blank">02:15:33.560</a></span> | <span class="t">of the videos about three times, and some of the people I knew had actually discovered</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=8139" target="_blank">02:15:39.800</a></span> | <span class="t">they learned some of them off by heart by mistake.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=8142" target="_blank">02:15:42.840</a></span> | <span class="t">Watching the videos again is helpful.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=8144" target="_blank">02:15:44.520</a></span> | <span class="t">And make sure you get to the point that you can recreate the notebooks without watching</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=8148" target="_blank">02:15:48.680</a></span> | <span class="t">the videos.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=8150" target="_blank">02:15:50.640</a></span> | <span class="t">And so to make it more interesting, obviously try and recreate the notebooks using different</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=8155" target="_blank">02:15:55.120</a></span> | <span class="t">datasets.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=8158" target="_blank">02:15:58.520</a></span> | <span class="t">And definitely then just keep up with the forum and you'll see people keep on posting</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=8163" target="_blank">02:16:03.000</a></span> | <span class="t">more stuff about recent papers and recent advances, and over the next couple of months</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=8168" target="_blank">02:16:08.060</a></span> | <span class="t">you'll find increasingly less and less of it seems weird and mysterious, and more and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=8172" target="_blank">02:16:12.800</a></span> | <span class="t">more of it makes perfect sense.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=8176" target="_blank">02:16:16.480</a></span> | <span class="t">And so it's a bit of a case of staying tenacious, there's always going to be stuff that you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=8181" target="_blank">02:16:21.840</a></span> | <span class="t">don't understand yet, but you'll be surprised.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=8185" target="_blank">02:16:25.280</a></span> | <span class="t">If you go back to lesson 1 and 2 now, you'll be like, oh that's all trivial.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=8192" target="_blank">02:16:32.720</a></span> | <span class="t">So that's kind of hopefully a bit of your learning journey, and I think the main thing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=8200" target="_blank">02:16:40.160</a></span> | <span class="t">I've noticed is the people who succeed are the ones who just keep working at it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=8204" target="_blank">02:16:44.680</a></span> | <span class="t">So not coming back here every Monday, you're not going to have that forcing function.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=8209" target="_blank">02:16:49.120</a></span> | <span class="t">I've noticed the forum suddenly gets busy at 5pm on a Monday.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=8213" target="_blank">02:16:53.560</a></span> | <span class="t">It's like, oh, the course is about to start and suddenly these questions start coming</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=8217" target="_blank">02:16:57.240</a></span> | <span class="t">in.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=8218" target="_blank">02:16:58.240</a></span> | <span class="t">So now that you don't have that forcing function, try and use some other technique to give yourself</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=8224" target="_blank">02:17:04.120</a></span> | <span class="t">that little kick.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=8225" target="_blank">02:17:05.120</a></span> | <span class="t">Maybe you can tell your partner at home, I'm going to try and produce something every Saturday</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=8229" target="_blank">02:17:09.320</a></span> | <span class="t">for the next 4 weeks, or I'm going to try and finish reading this paper or something.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=8236" target="_blank">02:17:16.280</a></span> | <span class="t">So I hope to see you all back in March, and regardless whether I do or don't, it's been</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=8242" target="_blank">02:17:22.240</a></span> | <span class="t">a really great pleasure to get to know you all, and I hope to keep seeing you on the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=8246" target="_blank">02:17:26.120</a></span> | <span class="t">forum.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=8247" target="_blank">02:17:27.120</a></span> | <span class="t">Thanks very much.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=8248" target="_blank">02:17:28.120</a></span> | <span class="t">[Applause]</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H3g26EVADgY&t=8248" target="_blank">02:17:28.120</a></span> | <span class="t">(applause)</span></div></div></body></html>