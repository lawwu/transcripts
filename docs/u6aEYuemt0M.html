<html><head><title>Deep Learning for Computer Vision (Andrej Karpathy, OpenAI)</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            margin: 0;
            padding: 0;
            background-color: #f4f4f4;
            color: #333;
        }
        .container {
            width: 80%;
            margin: auto;
            overflow: hidden;
        }
        h2, h3 {
            color: #333;
            text-align: center;
        }
        a {
            color: #0000FF;  /* Traditional blue color for links */
            text-decoration: none;
        }
        a:hover {
            text-decoration: underline;
        }
        img {
            display: block;
            margin: auto;
            max-width: 100%;
        }
        .c {
            margin: 10px 0;
        }
        .s, .t {
            display: inline-block;
            margin-right: 5px;
        }
        .max-width {
            max-width: 800px;
            margin: auto;
        }
    </style>
    
    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-69VLBMTTP0"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-69VLBMTTP0');
    </script>
    </head><body><div class='container'><a href="index.html">back to index</a><h2>Deep Learning for Computer Vision (Andrej Karpathy, OpenAI)</h2><a href="https://www.youtube.com/watch?v=u6aEYuemt0M"><img src="https://i.ytimg.com/vi_webp/u6aEYuemt0M/maxresdefault.webp" style="width:50%;"></a><div><br></div><h3>Chapters</h3><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=0">0:0</a> Deep Learning for Computer Vision<br><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=263">4:23</a> Computer Vision 2011<br><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=599">9:59</a> Transfer Learning<br><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=676">11:16</a> The power is easily accessible.<br><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=718">11:58</a> ConvNets are everywhere...<br><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1018">16:58</a> Convolution Layer<br><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1165">19:25</a> For example, if we had 6 5x5 filters, we'll get 6 separate activation maps<br><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1496">24:56</a> MAX POOLING<br><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1933">32:13</a> Case Study: AlexNet NELA<br><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3154">52:34</a> Addressing other tasks...<br><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3204">53:24</a> Image Classification thing = a vector of probabilities for different classes<br><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3249">54:9</a> Localization<br><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3288">54:48</a> Reinforcement Learning<br><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3338">55:38</a> Segmentation<br><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3446">57:26</a> Variational Autoencoders<br><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3461">57:41</a> Detection<br><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3566">59:26</a> Dense Image Captioning<br><br><div style="text-align: left;"><a href="./u6aEYuemt0M.html">Whisper Transcript</a> | <a href="./transcript_u6aEYuemt0M.html">Transcript Only Page</a></div><br><div style="max-width: 800px;"><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=0" target="_blank">00:00:00.000</a></span> | <span class="t">So thank you very much for the introduction.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3" target="_blank">00:00:03.160</a></span> | <span class="t">So today I'll speak about deep learning, especially in the context of computer vision.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=7" target="_blank">00:00:07.880</a></span> | <span class="t">So what you saw in the previous talk is neural networks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=10" target="_blank">00:00:10.760</a></span> | <span class="t">So you saw that neural networks are organized into these layers, fully connected layers,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=14" target="_blank">00:00:14.720</a></span> | <span class="t">where neurons in one layer are not connected, but they're connected fully to all the neurons</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=18" target="_blank">00:00:18.680</a></span> | <span class="t">in the previous layer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=19" target="_blank">00:00:19.920</a></span> | <span class="t">And we saw that basically we have this layer-wise structure from input until output.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=25" target="_blank">00:00:25.280</a></span> | <span class="t">And there are neurons and nonlinearities, et cetera.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=27" target="_blank">00:00:27.720</a></span> | <span class="t">Now so far we have not made too many assumptions about the inputs.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=31" target="_blank">00:00:31.140</a></span> | <span class="t">So in particular, here we just assume that an input is some kind of a vector of numbers</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=34" target="_blank">00:00:34.700</a></span> | <span class="t">that we plug into this neural network.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=37" target="_blank">00:00:37.340</a></span> | <span class="t">So that's both a bug and a feature to some extent, because in most real world applications</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=44" target="_blank">00:00:44.700</a></span> | <span class="t">we actually can make some assumptions about the input that makes learning much more efficient.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=52" target="_blank">00:00:52.140</a></span> | <span class="t">So in particular, usually we don't just want to plug into neural networks vectors of numbers,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=58" target="_blank">00:00:58.460</a></span> | <span class="t">but they actually have some kind of a structure.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=60" target="_blank">00:01:00.180</a></span> | <span class="t">So we don't have vectors of numbers, but these numbers are arranged in some kind of a layout,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=64" target="_blank">00:01:04.820</a></span> | <span class="t">like an n-dimensional array of numbers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=67" target="_blank">00:01:07.040</a></span> | <span class="t">So for example, spectrograms are two-dimensional arrays of numbers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=69" target="_blank">00:01:09.780</a></span> | <span class="t">Images are three-dimensional arrays of numbers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=72" target="_blank">00:01:12.060</a></span> | <span class="t">Videos would be four-dimensional arrays of numbers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=74" target="_blank">00:01:14.260</a></span> | <span class="t">Text you could treat as one-dimensional array of numbers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=77" target="_blank">00:01:17.060</a></span> | <span class="t">And so whenever you have this kind of local connectivity structure in your data, then</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=81" target="_blank">00:01:21.500</a></span> | <span class="t">you'd like to take advantage of it, and convolutional neural networks allow you to do that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=86" target="_blank">00:01:26.140</a></span> | <span class="t">So before I dive into convolutional neural networks and all the details of the architectures,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=90" target="_blank">00:01:30.020</a></span> | <span class="t">I'd like to briefly talk about a bit of the history of how this field evolved over time.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=94" target="_blank">00:01:34.800</a></span> | <span class="t">So I like to start off usually with talking about Hubel and Wiesel and the experiments</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=98" target="_blank">00:01:38.860</a></span> | <span class="t">that they performed in the 1960s.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=100" target="_blank">00:01:40.660</a></span> | <span class="t">So what they were doing is trying to study the computations that happened in the early</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=105" target="_blank">00:01:45.240</a></span> | <span class="t">visual cortex areas of a cat.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=108" target="_blank">00:01:48.220</a></span> | <span class="t">And so they had cats, and they plugged in electrodes that could record from the different</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=112" target="_blank">00:01:52.540</a></span> | <span class="t">neurons.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=113" target="_blank">00:01:53.700</a></span> | <span class="t">And then they showed the cat different patterns of light.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=116" target="_blank">00:01:56.180</a></span> | <span class="t">And they were trying to debug neurons effectively and try to show them different patterns and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=119" target="_blank">00:01:59.820</a></span> | <span class="t">see what they responded to.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=121" target="_blank">00:02:01.780</a></span> | <span class="t">And a lot of these experiments inspired some of the modeling that came in afterwards.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=127" target="_blank">00:02:07.100</a></span> | <span class="t">So in particular, one of the early models that tried to take advantage of some of the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=130" target="_blank">00:02:10.020</a></span> | <span class="t">results of these experiments was the model called Neurocognitron from Fukushima in the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=137" target="_blank">00:02:17.260</a></span> | <span class="t">'60s.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=138" target="_blank">00:02:18.260</a></span> | <span class="t">And so what you saw here was this architecture that, again, is layer-wise, similar to what</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=142" target="_blank">00:02:22.020</a></span> | <span class="t">you see in the cortex, where you have these simple and complex cells, where the simple</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=146" target="_blank">00:02:26.020</a></span> | <span class="t">cells detect small things in the visual field.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=149" target="_blank">00:02:29.720</a></span> | <span class="t">And then you have this local connectivity pattern, and the simple and complex cells</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=152" target="_blank">00:02:32.860</a></span> | <span class="t">alternate in this layered architecture throughout.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=156" target="_blank">00:02:36.300</a></span> | <span class="t">And so this looks a bit like a ConvNet, because you have some of its features, like, say,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=160" target="_blank">00:02:40.540</a></span> | <span class="t">the local connectivity.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=161" target="_blank">00:02:41.860</a></span> | <span class="t">But at the time, this was not trained with backpropagation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=164" target="_blank">00:02:44.140</a></span> | <span class="t">These were specific, heuristically chosen updates.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=169" target="_blank">00:02:49.800</a></span> | <span class="t">And this was unsupervised learning back then.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=172" target="_blank">00:02:52.340</a></span> | <span class="t">So the first time that we've actually used backpropagation to train some of these networks</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=175" target="_blank">00:02:55.300</a></span> | <span class="t">was an experiment of Jan Lekun in the 1990s.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=179" target="_blank">00:02:59.000</a></span> | <span class="t">And so this is an example of one of the networks that was developed back then, in the 1990s,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=184" target="_blank">00:03:04.380</a></span> | <span class="t">by Jan Lekun, is LeanNet5.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=186" target="_blank">00:03:06.220</a></span> | <span class="t">And this is what you would recognize today as a convolutional neural network.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=189" target="_blank">00:03:09.280</a></span> | <span class="t">So it has a lot of the very convolutional layers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=192" target="_blank">00:03:12.380</a></span> | <span class="t">And it's alternating.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=193" target="_blank">00:03:13.820</a></span> | <span class="t">And it's a similar kind of design to what you would see in the Fukushima's neurocognitron.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=198" target="_blank">00:03:18.180</a></span> | <span class="t">But this was actually trained with backpropagation end-to-end using supervised learning.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=204" target="_blank">00:03:24.320</a></span> | <span class="t">So this happened in roughly the 1990s.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=206" target="_blank">00:03:26.260</a></span> | <span class="t">And we're here in 2016, basically about 20 years later.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=211" target="_blank">00:03:31.240</a></span> | <span class="t">Now computer vision has, for a long time, kind of worked on larger images.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=218" target="_blank">00:03:38.740</a></span> | <span class="t">And a lot of these models back then were applied to very small kind of settings, like, say,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=223" target="_blank">00:03:43.420</a></span> | <span class="t">minimizing digits in zip codes and things like that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=226" target="_blank">00:03:46.780</a></span> | <span class="t">And they were very successful in those domains.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=228" target="_blank">00:03:48.700</a></span> | <span class="t">But back at least when I entered computer vision, roughly 2011, it was thought that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=232" target="_blank">00:03:52.820</a></span> | <span class="t">a lot of people were aware of these models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=234" target="_blank">00:03:54.540</a></span> | <span class="t">But it was thought that they would not scale up naively into large, complex images, that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=239" target="_blank">00:03:59.900</a></span> | <span class="t">they would be constrained to these toy tasks for a long time.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=242" target="_blank">00:04:02.620</a></span> | <span class="t">Or I shouldn't say toy, because these were very important tasks, but certainly like smaller</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=246" target="_blank">00:04:06.180</a></span> | <span class="t">visual recognition problems.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=248" target="_blank">00:04:08.180</a></span> | <span class="t">And so in computer vision in roughly 2011, it was much more common to use a kind of these</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=252" target="_blank">00:04:12.980</a></span> | <span class="t">feature-based approaches at the time.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=255" target="_blank">00:04:15.220</a></span> | <span class="t">And they didn't work actually that well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=257" target="_blank">00:04:17.060</a></span> | <span class="t">So when I entered my PhD in 2011 working on computer vision, you would run a state-of-the-art</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=261" target="_blank">00:04:21.020</a></span> | <span class="t">object detector on this image, and you might get something like this, where cars were detected</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=267" target="_blank">00:04:27.020</a></span> | <span class="t">in trees.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=268" target="_blank">00:04:28.020</a></span> | <span class="t">And you would kind of just shrug your shoulders and say, well, that just happens sometimes.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=271" target="_blank">00:04:31.240</a></span> | <span class="t">You kind of just accept it as something that would just happen.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=276" target="_blank">00:04:36.080</a></span> | <span class="t">And of course, this is a caricature.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=277" target="_blank">00:04:37.220</a></span> | <span class="t">Things actually worked relatively decent, I should say.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=279" target="_blank">00:04:39.580</a></span> | <span class="t">But definitely there were many mistakes that you would not see today about four years in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=284" target="_blank">00:04:44.380</a></span> | <span class="t">2016, five years later.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=287" target="_blank">00:04:47.100</a></span> | <span class="t">And so a lot of computer vision kind of looked much more like this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=289" target="_blank">00:04:49.660</a></span> | <span class="t">When you look into a paper that tried to do image classification, you would find this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=293" target="_blank">00:04:53.900</a></span> | <span class="t">section in the paper on the features that they used.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=296" target="_blank">00:04:56.600</a></span> | <span class="t">So this is one page of features.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=299" target="_blank">00:04:59.420</a></span> | <span class="t">And so they would use a gist, hog, et cetera, and then a second page of features and all</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=305" target="_blank">00:05:05.660</a></span> | <span class="t">their hyperparameters.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=306" target="_blank">00:05:06.940</a></span> | <span class="t">So all kinds of different histograms.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=307" target="_blank">00:05:07.940</a></span> | <span class="t">And you would extract this kitchen sink of features and a third page here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=312" target="_blank">00:05:12.500</a></span> | <span class="t">And so you end up with this very large, complex code base, because some of these feature types</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=316" target="_blank">00:05:16.660</a></span> | <span class="t">are implemented in MATLAB, some of them in Python, some of them in C++.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=320" target="_blank">00:05:20.180</a></span> | <span class="t">And you end up with this large code base of extracting all these features, caching them,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=323" target="_blank">00:05:23.520</a></span> | <span class="t">and then eventually plugging them into linear classifiers to do some kind of visual recognition</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=326" target="_blank">00:05:26.940</a></span> | <span class="t">task.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=327" target="_blank">00:05:27.940</a></span> | <span class="t">So it was quite unwieldy.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=331" target="_blank">00:05:31.100</a></span> | <span class="t">But it worked to some extent.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=332" target="_blank">00:05:32.700</a></span> | <span class="t">But there were definitely room for improvement.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=334" target="_blank">00:05:34.920</a></span> | <span class="t">And so a lot of this changed in computer vision in 2012 with this paper from Alex Kurchevsky,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=339" target="_blank">00:05:39.860</a></span> | <span class="t">Ilya Satskever, and Jeff Hinton.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=341" target="_blank">00:05:41.900</a></span> | <span class="t">So this is the first time that someone took a convolutional neural network that is very</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=346" target="_blank">00:05:46.180</a></span> | <span class="t">similar to the one that you saw from 1998 from Yanma Kun.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=350" target="_blank">00:05:50.040</a></span> | <span class="t">And I'll go into details of how they differ exactly.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=352" target="_blank">00:05:52.780</a></span> | <span class="t">But they took that kind of network.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=354" target="_blank">00:05:54.340</a></span> | <span class="t">They scaled it up.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=355" target="_blank">00:05:55.340</a></span> | <span class="t">They made it much bigger.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=356" target="_blank">00:05:56.340</a></span> | <span class="t">And they trained it on a much bigger data set on GPUs.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=358" target="_blank">00:05:58.860</a></span> | <span class="t">And things basically ended up working extremely well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=361" target="_blank">00:06:01.060</a></span> | <span class="t">And this is the first time that computer vision community has really noticed these models</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=364" target="_blank">00:06:04.260</a></span> | <span class="t">and adopted them to work on larger images.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=368" target="_blank">00:06:08.540</a></span> | <span class="t">So we saw that the performance of these models has improved drastically.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=373" target="_blank">00:06:13.540</a></span> | <span class="t">Here we are looking at the ImageNet ILS VRC visual recognition challenge over the years.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=379" target="_blank">00:06:19.440</a></span> | <span class="t">And we're looking at the top five errors.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=380" target="_blank">00:06:20.860</a></span> | <span class="t">So low is good.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=381" target="_blank">00:06:21.860</a></span> | <span class="t">And you can see that from 2010 in the beginning, these were feature-based methods.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=386" target="_blank">00:06:26.700</a></span> | <span class="t">And then in 2012, we had this huge jump in performance.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=389" target="_blank">00:06:29.740</a></span> | <span class="t">And that was due to the first kind of convolutional neural network in 2012.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=393" target="_blank">00:06:33.980</a></span> | <span class="t">And then we've managed to push that over time.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=395" target="_blank">00:06:35.620</a></span> | <span class="t">And now we're down to about 3.57%.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=398" target="_blank">00:06:38.500</a></span> | <span class="t">I think the results for ImageNet Challenge 2016 are actually due to come out today.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=404" target="_blank">00:06:44.560</a></span> | <span class="t">But I don't think that actually they've come out yet.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=406" target="_blank">00:06:46.740</a></span> | <span class="t">I have this second tab here opened.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=411" target="_blank">00:06:51.220</a></span> | <span class="t">I was waiting for the result.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=412" target="_blank">00:06:52.380</a></span> | <span class="t">But I don't think this is up yet.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=414" target="_blank">00:06:54.100</a></span> | <span class="t">Yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=415" target="_blank">00:06:55.100</a></span> | <span class="t">OK.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=416" target="_blank">00:06:56.100</a></span> | <span class="t">No.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=417" target="_blank">00:06:57.100</a></span> | <span class="t">Nothing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=418" target="_blank">00:06:58.100</a></span> | <span class="t">All right.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=419" target="_blank">00:06:59.100</a></span> | <span class="t">Well, we'll get to find out very soon what happens right here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=420" target="_blank">00:07:00.540</a></span> | <span class="t">So I'm very excited to see that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=422" target="_blank">00:07:02.900</a></span> | <span class="t">Just to put this in context, by the way, because you're just looking at numbers, like 3.57,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=426" target="_blank">00:07:06.260</a></span> | <span class="t">how good is that?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=427" target="_blank">00:07:07.380</a></span> | <span class="t">That's actually really, really good.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=428" target="_blank">00:07:08.900</a></span> | <span class="t">So something that I did about two years ago now is that I tried to measure the human accuracy</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=434" target="_blank">00:07:14.500</a></span> | <span class="t">on this data set.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=435" target="_blank">00:07:15.500</a></span> | <span class="t">And so what I did for that is I developed this web interface where I would show myself</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=440" target="_blank">00:07:20.700</a></span> | <span class="t">ImageNet images from the test set.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=442" target="_blank">00:07:22.820</a></span> | <span class="t">And then I had this interface here where I would have all the different classes of ImageNet.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=447" target="_blank">00:07:27.340</a></span> | <span class="t">There's 1,000 of them.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=448" target="_blank">00:07:28.620</a></span> | <span class="t">And some example images.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=450" target="_blank">00:07:30.260</a></span> | <span class="t">And then basically, you go down this list and you scroll for a long time and you find</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=453" target="_blank">00:07:33.780</a></span> | <span class="t">what class you think that image might be.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=456" target="_blank">00:07:36.060</a></span> | <span class="t">And then I competed against the ComNet at the time.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=459" target="_blank">00:07:39.700</a></span> | <span class="t">And this was GoogleNet in 2014.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=464" target="_blank">00:07:44.820</a></span> | <span class="t">And so HotDog is a very simple class.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=466" target="_blank">00:07:46.620</a></span> | <span class="t">You can do that quite easily.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=468" target="_blank">00:07:48.440</a></span> | <span class="t">But why is the accuracy not 0%?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=470" target="_blank">00:07:50.260</a></span> | <span class="t">Well, some of the things, like HotDog seems very easy.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=473" target="_blank">00:07:53.060</a></span> | <span class="t">Why isn't it trivial for humans to see?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=474" target="_blank">00:07:54.580</a></span> | <span class="t">Well, it turns out that some of the images in a test set of ImageNet are actually mislabeled.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=478" target="_blank">00:07:58.940</a></span> | <span class="t">But also, some of the images are just very difficult to guess.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=482" target="_blank">00:08:02.340</a></span> | <span class="t">So in particular, if you have this terrier, there's 50 different types of terriers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=485" target="_blank">00:08:05.700</a></span> | <span class="t">And it turns out to be a very difficult task to find exactly which type of terrier that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=489" target="_blank">00:08:09.660</a></span> | <span class="t">is.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=490" target="_blank">00:08:10.660</a></span> | <span class="t">You can spend minutes trying to find it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=492" target="_blank">00:08:12.140</a></span> | <span class="t">It turns out that convolutional neural networks are actually extremely good at this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=496" target="_blank">00:08:16.100</a></span> | <span class="t">And so this is where I would lose points compared to ComNet.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=500" target="_blank">00:08:20.080</a></span> | <span class="t">So I estimate that human accuracy based on this is roughly 2% to 5% range, depending</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=503" target="_blank">00:08:23.940</a></span> | <span class="t">on how much time you have and how much expertise you have and how many people you involve and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=508" target="_blank">00:08:28.320</a></span> | <span class="t">how much they really want to do this, which is not too much.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=511" target="_blank">00:08:31.940</a></span> | <span class="t">And so really, we're doing extremely well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=514" target="_blank">00:08:34.460</a></span> | <span class="t">And so we're down to 3%.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=516" target="_blank">00:08:36.260</a></span> | <span class="t">And I think the error rate, if I remember correctly, was about 1.5%.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=520" target="_blank">00:08:40.700</a></span> | <span class="t">So if we get below 1.5%, I would be extremely suspicious on ImageNet.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=525" target="_blank">00:08:45.500</a></span> | <span class="t">That seems wrong.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=526" target="_blank">00:08:46.680</a></span> | <span class="t">So to summarize, basically, what we've done is, before 2012, computer vision looked somewhat</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=533" target="_blank">00:08:53.060</a></span> | <span class="t">like this, where we had these feature extractors.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=534" target="_blank">00:08:54.940</a></span> | <span class="t">And then we trained a small portion at the end of the feature extraction step.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=539" target="_blank">00:08:59.800</a></span> | <span class="t">And so we only trained this last piece on top of these features that were fixed.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=543" target="_blank">00:09:03.640</a></span> | <span class="t">And we've basically replaced the feature extraction step with a single convolutional neural network.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=547" target="_blank">00:09:07.820</a></span> | <span class="t">And now we train everything completely end to end.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=549" target="_blank">00:09:09.880</a></span> | <span class="t">And this turns out to work quite nicely.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=552" target="_blank">00:09:12.080</a></span> | <span class="t">So I'm going to go into details of how this works in a bit.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=555" target="_blank">00:09:15.220</a></span> | <span class="t">Also in terms of code complexity, we kind of went from a setup that looks-- whoops.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=560" target="_blank">00:09:20.320</a></span> | <span class="t">I'm way ahead.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=563" target="_blank">00:09:23.000</a></span> | <span class="t">We went from a setup that looks something like that in papers to something like, instead</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=567" target="_blank">00:09:27.200</a></span> | <span class="t">of extracting all these things, we just say, apply 20 layers with 3 by 3 conv or something</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=571" target="_blank">00:09:31.160</a></span> | <span class="t">like that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=572" target="_blank">00:09:32.160</a></span> | <span class="t">And things work quite well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=573" target="_blank">00:09:33.640</a></span> | <span class="t">This is, of course, an over-exaggeration.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=575" target="_blank">00:09:35.100</a></span> | <span class="t">But I think it's a correct first order statement to make, is that we've definitely seen that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=579" target="_blank">00:09:39.560</a></span> | <span class="t">we've reduced code complexity quite a lot, because these architectures are so homogeneous</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=583" target="_blank">00:09:43.860</a></span> | <span class="t">compared to what we've done before.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=586" target="_blank">00:09:46.180</a></span> | <span class="t">So it's also remarkable that-- so we had this reduction in complexity.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=589" target="_blank">00:09:49.660</a></span> | <span class="t">We had this amazing performance on ImageNet.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=591" target="_blank">00:09:51.900</a></span> | <span class="t">One other thing that was quite amazing about the results in 2012 that is also a separate</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=596" target="_blank">00:09:56.040</a></span> | <span class="t">thing that did not have to be the case is that the features that you learn by training</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=600" target="_blank">00:10:00.540</a></span> | <span class="t">on ImageNet turn out to be quite generic.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=602" target="_blank">00:10:02.380</a></span> | <span class="t">And you can apply them in different settings.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=604" target="_blank">00:10:04.380</a></span> | <span class="t">So in other words, this transfer learning works extremely well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=608" target="_blank">00:10:08.280</a></span> | <span class="t">And of course, I didn't go into details of convolutional networks yet.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=610" target="_blank">00:10:10.520</a></span> | <span class="t">But we start with an image.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=612" target="_blank">00:10:12.040</a></span> | <span class="t">And we have a sequence of layers, just like in a normal neural network.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=614" target="_blank">00:10:14.700</a></span> | <span class="t">And at the end, we have a classifier.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=616" target="_blank">00:10:16.540</a></span> | <span class="t">And when you pre-train this network on ImageNet, then it turns out that the features that you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=620" target="_blank">00:10:20.540</a></span> | <span class="t">learn in the middle are actually transferable.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=623" target="_blank">00:10:23.180</a></span> | <span class="t">And you can use them on different data sets, and that this works extremely well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=626" target="_blank">00:10:26.500</a></span> | <span class="t">And so that didn't have to be the case.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=628" target="_blank">00:10:28.240</a></span> | <span class="t">You might imagine that you could have a convolutional network that works extremely well on ImageNet.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=632" target="_blank">00:10:32.220</a></span> | <span class="t">But when you try to run it on something else, like BIRDS data set or something, that it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=635" target="_blank">00:10:35.540</a></span> | <span class="t">might just not work well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=636" target="_blank">00:10:36.940</a></span> | <span class="t">But that is not the case.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=638" target="_blank">00:10:38.020</a></span> | <span class="t">And that's a very interesting finding, in my opinion.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=640" target="_blank">00:10:40.940</a></span> | <span class="t">So people noticed this back in roughly 2013, after the first convolutional networks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=645" target="_blank">00:10:45.880</a></span> | <span class="t">They noticed that you can actually take many computer vision data sets.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=649" target="_blank">00:10:49.060</a></span> | <span class="t">And it used to be that you would compete on all of these separately and design features</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=652" target="_blank">00:10:52.000</a></span> | <span class="t">maybe for some of these separately.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=653" target="_blank">00:10:53.980</a></span> | <span class="t">And you can just shortcut all those steps that we had designed.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=658" target="_blank">00:10:58.060</a></span> | <span class="t">And you can just take these pre-trained features that you get from ImageNet.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=661" target="_blank">00:11:01.740</a></span> | <span class="t">And you can just train a linear classifier on every single data set on top of those features.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=665" target="_blank">00:11:05.260</a></span> | <span class="t">And you obtain many state-of-the-art results across many different data sets.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=668" target="_blank">00:11:08.820</a></span> | <span class="t">And so this was quite a remarkable finding back then, I believe.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=673" target="_blank">00:11:13.020</a></span> | <span class="t">So things worked very well on ImageNet.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=674" target="_blank">00:11:14.580</a></span> | <span class="t">Things transferred very well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=676" target="_blank">00:11:16.300</a></span> | <span class="t">And the code complexity, of course, got much more manageable.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=680" target="_blank">00:11:20.100</a></span> | <span class="t">So now all this power is actually available to you with very few lines of code.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=683" target="_blank">00:11:23.780</a></span> | <span class="t">If you want to just use a convolutional network on images, it turns out to be only a few lines</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=688" target="_blank">00:11:28.180</a></span> | <span class="t">of code.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=689" target="_blank">00:11:29.180</a></span> | <span class="t">If you use, for example, Keras, it's one of the deep learning libraries that I'm going</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=692" target="_blank">00:11:32.020</a></span> | <span class="t">to go into and I'll mention again later in the talk.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=695" target="_blank">00:11:35.260</a></span> | <span class="t">But basically, you just load a state-of-the-art convolutional neural network.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=698" target="_blank">00:11:38.400</a></span> | <span class="t">You take an image.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=699" target="_blank">00:11:39.400</a></span> | <span class="t">You load it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=700" target="_blank">00:11:40.400</a></span> | <span class="t">And you compute your predictions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=701" target="_blank">00:11:41.740</a></span> | <span class="t">And it tells you that this is an African elephant inside that image.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=705" target="_blank">00:11:45.380</a></span> | <span class="t">And this took a couple hundred or a couple ten milliseconds if you have a GPU.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=709" target="_blank">00:11:49.700</a></span> | <span class="t">And so everything got much faster, much simpler, works really well, transfers really well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=713" target="_blank">00:11:53.500</a></span> | <span class="t">So this was really a huge advance in computer vision.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=715" target="_blank">00:11:55.980</a></span> | <span class="t">And so as a result of all these nice properties, ComNets today are everywhere.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=719" target="_blank">00:11:59.940</a></span> | <span class="t">So here is a collection of some of the things that I try to find across different applications.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=727" target="_blank">00:12:07.020</a></span> | <span class="t">So for example, you can search Google Photos for different types of categories, like in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=731" target="_blank">00:12:11.500</a></span> | <span class="t">this case Rubik's Cube.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=733" target="_blank">00:12:13.620</a></span> | <span class="t">You can find house numbers very efficiently.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=736" target="_blank">00:12:16.420</a></span> | <span class="t">You can-- of course, this is very relevant in self-driving cars.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=738" target="_blank">00:12:18.940</a></span> | <span class="t">And we're doing perception in the cars.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=741" target="_blank">00:12:21.100</a></span> | <span class="t">Convolutional networks are very relevant there.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=742" target="_blank">00:12:22.760</a></span> | <span class="t">Medical image diagnosis, recognizing Chinese characters, doing all kinds of medical segmentation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=747" target="_blank">00:12:27.660</a></span> | <span class="t">tasks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=749" target="_blank">00:12:29.280</a></span> | <span class="t">Quite random tasks, like whale recognition and more generally many Kaggle challenges.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=754" target="_blank">00:12:34.500</a></span> | <span class="t">Satellite image analysis, recognizing different types of galaxies.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=757" target="_blank">00:12:37.620</a></span> | <span class="t">You may have seen recently that a WaveNet from DeepMind, also a very interesting paper</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=762" target="_blank">00:12:42.600</a></span> | <span class="t">that they generate music and they generate speech.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=766" target="_blank">00:12:46.300</a></span> | <span class="t">And so this is a generative model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=767" target="_blank">00:12:47.580</a></span> | <span class="t">And that's also just a ComNet is doing most of the heavy lifting here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=770" target="_blank">00:12:50.700</a></span> | <span class="t">So it's a convolutional network on top of sound.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=773" target="_blank">00:12:53.780</a></span> | <span class="t">And other tasks, like image captioning.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=776" target="_blank">00:12:56.420</a></span> | <span class="t">In the context of reinforcement learning and agent environment interactions, we've also</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=780" target="_blank">00:13:00.680</a></span> | <span class="t">seen a lot of advances of using ComNets as the core computational building block.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=784" target="_blank">00:13:04.620</a></span> | <span class="t">So when you want to play Atari games, or you want to play AlphaGo, or Doom, or StarCraft,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=788" target="_blank">00:13:08.920</a></span> | <span class="t">or if you want to get robots to perform interesting manipulation tasks, all of this uses ComNets</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=793" target="_blank">00:13:13.940</a></span> | <span class="t">as a core computational block to do very impressive things.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=799" target="_blank">00:13:19.740</a></span> | <span class="t">Not only are we using it for a lot of different applications, we're also finding uses in art.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=806" target="_blank">00:13:26.300</a></span> | <span class="t">So here are some examples from DeepDream.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=808" target="_blank">00:13:28.100</a></span> | <span class="t">So you can basically simulate what it looks like, what it feels like maybe to be on some</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=812" target="_blank">00:13:32.660</a></span> | <span class="t">drugs.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=813" target="_blank">00:13:33.660</a></span> | <span class="t">So you can take images and you can just hallucinate features using ComNets.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=817" target="_blank">00:13:37.020</a></span> | <span class="t">Or you might be familiar with neural style, which allows you to take arbitrary images</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=820" target="_blank">00:13:40.340</a></span> | <span class="t">and transfer arbitrary styles of different paintings like Van Gogh on top of them.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=824" target="_blank">00:13:44.480</a></span> | <span class="t">And this is all using convolutional networks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=826" target="_blank">00:13:46.620</a></span> | <span class="t">The last thing I'd like to note that I find also interesting is that in the process of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=830" target="_blank">00:13:50.620</a></span> | <span class="t">trying to develop better computer vision architectures and trying to basically optimize for performance</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=836" target="_blank">00:13:56.000</a></span> | <span class="t">on the ImageNet challenge, we've actually ended up converging to something that potentially</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=840" target="_blank">00:14:00.100</a></span> | <span class="t">might function something like your visual cortex in some ways.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=843" target="_blank">00:14:03.520</a></span> | <span class="t">And so these are some of the experiments that I find interesting where they've studied macaque</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=847" target="_blank">00:14:07.200</a></span> | <span class="t">monkeys and they record from a subpopulation of the IT cortex.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=853" target="_blank">00:14:13.660</a></span> | <span class="t">This is the part that does a lot of object recognition.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=855" target="_blank">00:14:15.940</a></span> | <span class="t">And so they record.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=856" target="_blank">00:14:16.940</a></span> | <span class="t">So basically, they take a monkey and they take a ComNet and they show them images.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=860" target="_blank">00:14:20.540</a></span> | <span class="t">And then you look at what those images are represented at the end of this network.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=864" target="_blank">00:14:24.280</a></span> | <span class="t">So inside the monkey's brain or on top of your convolutional network.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=867" target="_blank">00:14:27.460</a></span> | <span class="t">And so you look at representations of different images.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=869" target="_blank">00:14:29.460</a></span> | <span class="t">And then it turns out that there's a mapping between those two spaces that actually seems</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=873" target="_blank">00:14:33.460</a></span> | <span class="t">to indicate to some extent that some of the things we're doing somehow ended up converging</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=877" target="_blank">00:14:37.680</a></span> | <span class="t">to something that the brain could be doing as well in the visual cortex.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=882" target="_blank">00:14:42.060</a></span> | <span class="t">So that's just some intro.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=883" target="_blank">00:14:43.380</a></span> | <span class="t">I'm now going to dive into convolutional networks and try to explain briefly how these networks</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=889" target="_blank">00:14:49.500</a></span> | <span class="t">work.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=890" target="_blank">00:14:50.500</a></span> | <span class="t">Of course, there's an entire class on this that I taught, which is a convolutional networks</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=893" target="_blank">00:14:53.460</a></span> | <span class="t">class.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=894" target="_blank">00:14:54.460</a></span> | <span class="t">And so I'm going to distill some of those 13 lectures into one lecture.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=897" target="_blank">00:14:57.940</a></span> | <span class="t">So we'll see how that goes.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=899" target="_blank">00:14:59.540</a></span> | <span class="t">I won't cover everything, of course.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=902" target="_blank">00:15:02.900</a></span> | <span class="t">So convolutional neural network is really just a single function.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=906" target="_blank">00:15:06.380</a></span> | <span class="t">It's a function from the raw pixels of some kind of an image.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=909" target="_blank">00:15:09.940</a></span> | <span class="t">So we take 224 by 224 by 3 image.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=912" target="_blank">00:15:12.700</a></span> | <span class="t">So 3 here is for the call channels, RGB.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=915" target="_blank">00:15:15.180</a></span> | <span class="t">You take the raw pixels, you put it through this function, and you get 1,000 numbers at</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=918" target="_blank">00:15:18.540</a></span> | <span class="t">the end.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=919" target="_blank">00:15:19.540</a></span> | <span class="t">In the case of image classification, if you're trying to categorize images into 1,000 different</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=923" target="_blank">00:15:23.060</a></span> | <span class="t">classes.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=924" target="_blank">00:15:24.520</a></span> | <span class="t">And really, functionally, all that's happening in a convolutional network is just dot products</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=928" target="_blank">00:15:28.860</a></span> | <span class="t">and max operations.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=930" target="_blank">00:15:30.400</a></span> | <span class="t">That's everything.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=931" target="_blank">00:15:31.400</a></span> | <span class="t">They're wired up together in interesting ways so that you are basically doing visual recognition.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=936" target="_blank">00:15:36.460</a></span> | <span class="t">And in particular, this function f has a lot of knobs in it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=940" target="_blank">00:15:40.620</a></span> | <span class="t">So these W's here that participate in these dot products and in these convolutions and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=944" target="_blank">00:15:44.140</a></span> | <span class="t">fully connected layers and so on, these W's are all parameters of this network.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=948" target="_blank">00:15:48.220</a></span> | <span class="t">So normally, you might have about on the order of 10 million parameters.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=951" target="_blank">00:15:51.600</a></span> | <span class="t">And those are basically knobs that change this function.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=955" target="_blank">00:15:55.580</a></span> | <span class="t">And so we'd like to change those knobs, of course, so that when you put images through</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=959" target="_blank">00:15:59.900</a></span> | <span class="t">that function, you get probabilities that are consistent with your training data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=964" target="_blank">00:16:04.060</a></span> | <span class="t">And so that gives us a lot to tune.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=966" target="_blank">00:16:06.180</a></span> | <span class="t">And it turns out that we can do that tuning automatically with back propagation through</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=969" target="_blank">00:16:09.980</a></span> | <span class="t">that search process.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=971" target="_blank">00:16:11.300</a></span> | <span class="t">Now, more concretely, a convolutional neural network is made up of a sequence of layers,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=975" target="_blank">00:16:15.620</a></span> | <span class="t">just as in the case of normal neural networks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=977" target="_blank">00:16:17.580</a></span> | <span class="t">But we have different types of layers that we play with.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=980" target="_blank">00:16:20.280</a></span> | <span class="t">So we have convolutional layers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=981" target="_blank">00:16:21.860</a></span> | <span class="t">Here I'm using rectified linear unit, ReLU, for short, as a non-linearity.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=986" target="_blank">00:16:26.460</a></span> | <span class="t">So I'm making that an explicit its own layer, pooling layers, and fully connected layers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=991" target="_blank">00:16:31.940</a></span> | <span class="t">The core computational building block of a convolutional network, though, is this convolutional</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=995" target="_blank">00:16:35.580</a></span> | <span class="t">layer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=996" target="_blank">00:16:36.580</a></span> | <span class="t">And we have non-linearities interspersed.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=998" target="_blank">00:16:38.680</a></span> | <span class="t">We are probably getting rid of things like pooling layers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1000" target="_blank">00:16:40.980</a></span> | <span class="t">So you might see them slightly going away over time.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1003" target="_blank">00:16:43.340</a></span> | <span class="t">And fully connected layers can actually be represented-- they're basically equivalent</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1006" target="_blank">00:16:46.300</a></span> | <span class="t">to convolutional layers as well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1008" target="_blank">00:16:48.020</a></span> | <span class="t">And so really, it's just a sequence of conv layers in the simplest case.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1012" target="_blank">00:16:52.300</a></span> | <span class="t">So let me explain convolutional layer, because that's the core computational building block</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1015" target="_blank">00:16:55.380</a></span> | <span class="t">here that does all the heavy lifting.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1018" target="_blank">00:16:58.520</a></span> | <span class="t">So the entire com net is this collection of layers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1023" target="_blank">00:17:03.080</a></span> | <span class="t">And these layers don't function over vectors.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1025" target="_blank">00:17:05.420</a></span> | <span class="t">So they don't transform vectors as a normal neural network.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1027" target="_blank">00:17:07.540</a></span> | <span class="t">But they function over volumes.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1029" target="_blank">00:17:09.300</a></span> | <span class="t">So a layer will take a volume, a three-dimensional volume of numbers, an array.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1033" target="_blank">00:17:13.420</a></span> | <span class="t">In this case, for example, we have a 32 by 32 by 3 image.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1037" target="_blank">00:17:17.180</a></span> | <span class="t">So those three dimensions are the width, height, and I'll refer to the third dimension as depth.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1041" target="_blank">00:17:21.140</a></span> | <span class="t">We have three channels.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1042" target="_blank">00:17:22.900</a></span> | <span class="t">That's not to be confused with the depth of a network, which is the number of layers in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1045" target="_blank">00:17:25.820</a></span> | <span class="t">that network.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1046" target="_blank">00:17:26.820</a></span> | <span class="t">So this is just the depth of a volume.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1048" target="_blank">00:17:28.700</a></span> | <span class="t">So this convolutional layer accepts a three-dimensional volume.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1051" target="_blank">00:17:31.180</a></span> | <span class="t">And it produces a three-dimensional volume using some weights.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1054" target="_blank">00:17:34.580</a></span> | <span class="t">So the way it actually produces this output volume is as follows.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1057" target="_blank">00:17:37.700</a></span> | <span class="t">We're going to have these filters in a convolutional layer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1060" target="_blank">00:17:40.260</a></span> | <span class="t">So these filters are always small spatially, like, say, for example, 5 by 5 filter.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1065" target="_blank">00:17:45.540</a></span> | <span class="t">But their depth extends always through the input depth of the input volume.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1071" target="_blank">00:17:51.220</a></span> | <span class="t">So since the input volume has three channels, the depth is three, then our filters will</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1075" target="_blank">00:17:55.700</a></span> | <span class="t">always match that number.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1077" target="_blank">00:17:57.900</a></span> | <span class="t">So we have depth of three in our filters as well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1081" target="_blank">00:18:01.000</a></span> | <span class="t">And then we can take those filters, and we can basically convolve them with the input</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1083" target="_blank">00:18:03.940</a></span> | <span class="t">volume.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1084" target="_blank">00:18:04.940</a></span> | <span class="t">So what that amounts to is we take this filter.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1088" target="_blank">00:18:08.060</a></span> | <span class="t">Oh, yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1089" target="_blank">00:18:09.060</a></span> | <span class="t">So that's just the point that the channels here must match.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1092" target="_blank">00:18:12.260</a></span> | <span class="t">We take that filter, and we slide it through all spatial positions of the input volume.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1096" target="_blank">00:18:16.620</a></span> | <span class="t">And along the way, as we're sliding this filter, we're computing dot products.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1100" target="_blank">00:18:20.020</a></span> | <span class="t">So W transpose X plus B, where W are the filters, and X is a small piece of the input volume,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1105" target="_blank">00:18:25.500</a></span> | <span class="t">and B is the offset.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1107" target="_blank">00:18:27.020</a></span> | <span class="t">And so this is basically the convolutional operation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1108" target="_blank">00:18:28.780</a></span> | <span class="t">You're taking this filter, and you're sliding it through at all spatial positions, and you're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1112" target="_blank">00:18:32.140</a></span> | <span class="t">computing dot products.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1113" target="_blank">00:18:33.720</a></span> | <span class="t">So when you do this, you end up with this activation map.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1117" target="_blank">00:18:37.040</a></span> | <span class="t">So in this case, we get a 28 by 28 activation map.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1121" target="_blank">00:18:41.300</a></span> | <span class="t">28 comes from the fact that there are 28 unique positions to place this 5 by 5 filter into</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1126" target="_blank">00:18:46.180</a></span> | <span class="t">this 32 by 32 space.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1129" target="_blank">00:18:49.420</a></span> | <span class="t">So there are 28 by 28 unique positions you can place that filter in.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1132" target="_blank">00:18:52.260</a></span> | <span class="t">In every one of those, you're going to get a single number of how well that filter likes</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1137" target="_blank">00:18:57.700</a></span> | <span class="t">that part of the input.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1140" target="_blank">00:19:00.580</a></span> | <span class="t">So that carves out a single activation map.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1143" target="_blank">00:19:03.420</a></span> | <span class="t">And now in a convolutional layer, we don't just have a single filter, but we're going</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1145" target="_blank">00:19:05.860</a></span> | <span class="t">to have an entire set of filters.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1147" target="_blank">00:19:07.740</a></span> | <span class="t">So here's another filter, a green filter.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1149" target="_blank">00:19:09.740</a></span> | <span class="t">We're going to slide it through the input volume.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1152" target="_blank">00:19:12.040</a></span> | <span class="t">It has its own parameters.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1153" target="_blank">00:19:13.500</a></span> | <span class="t">So there are 75 numbers here that basically make up a filter.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1157" target="_blank">00:19:17.500</a></span> | <span class="t">There are different 75 numbers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1159" target="_blank">00:19:19.080</a></span> | <span class="t">We convolve them through, get a new activation map, and we continue doing this for all the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1162" target="_blank">00:19:22.780</a></span> | <span class="t">filters in that convolutional layer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1165" target="_blank">00:19:25.140</a></span> | <span class="t">So for example, if we had six filters in this convolutional layer, then we might end up</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1169" target="_blank">00:19:29.140</a></span> | <span class="t">with 28 by 28 activation maps six times.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1172" target="_blank">00:19:32.440</a></span> | <span class="t">And we stack them along the depth dimension to arrive at the output volume of 28 by 28</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1176" target="_blank">00:19:36.700</a></span> | <span class="t">by 6.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1177" target="_blank">00:19:37.700</a></span> | <span class="t">And so really what we've done is we've re-represented the original image, which is 32 by 32 by</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1182" target="_blank">00:19:42.380</a></span> | <span class="t">3, into a kind of a new image that is 28 by 28 by 6, where this image basically has these</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1188" target="_blank">00:19:48.840</a></span> | <span class="t">six channels that tell you how well every filter matches or likes every part of the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1195" target="_blank">00:19:55.080</a></span> | <span class="t">input image.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1197" target="_blank">00:19:57.020</a></span> | <span class="t">So let's compare this operation to, say, using a fully connected layer as you would in a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1200" target="_blank">00:20:00.920</a></span> | <span class="t">normal neural network.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1203" target="_blank">00:20:03.060</a></span> | <span class="t">So in particular, we saw that we processed a 32 by 32 by 3 volume into 28 by 28 by 6</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1209" target="_blank">00:20:09.000</a></span> | <span class="t">volume.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1210" target="_blank">00:20:10.000</a></span> | <span class="t">But one question you might want to ask is, how many parameters would this require if</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1213" target="_blank">00:20:13.560</a></span> | <span class="t">we wanted a fully connected layer of the same number of output neurons here?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1217" target="_blank">00:20:17.160</a></span> | <span class="t">So we wanted 28 by 28 by 6 or times-- 28 times 28 times 6 number of neurons fully connected.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1224" target="_blank">00:20:24.840</a></span> | <span class="t">How many parameters would that be?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1226" target="_blank">00:20:26.560</a></span> | <span class="t">Turns out that that would be quite a few parameters, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1228" target="_blank">00:20:28.760</a></span> | <span class="t">Because every single neuron in the output volume would be fully connected to all of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1232" target="_blank">00:20:32.080</a></span> | <span class="t">the 32 by 32 by 3 numbers here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1234" target="_blank">00:20:34.960</a></span> | <span class="t">So basically, every one of those 28 by 28 by 6 neurons is connected to 32 by 32 by 3.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1241" target="_blank">00:20:41.360</a></span> | <span class="t">Turns out to be about 15 million parameters, and also on that order of number of multiplies.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1245" target="_blank">00:20:45.920</a></span> | <span class="t">So you're doing a lot of compute, and you're introducing a huge amount of parameters into</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1248" target="_blank">00:20:48.960</a></span> | <span class="t">your network.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1249" target="_blank">00:20:49.960</a></span> | <span class="t">Now, since we're doing convolution instead, you'll notice that-- think about the number</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1255" target="_blank">00:20:55.480</a></span> | <span class="t">of parameters that we've introduced with this example convolutional layer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1259" target="_blank">00:20:59.120</a></span> | <span class="t">So we've used-- we had six filters, and every one of them was a 5 by 5 by 3 filter.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1266" target="_blank">00:21:06.280</a></span> | <span class="t">So basically, we just have 5 by 5 by 3 filters.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1268" target="_blank">00:21:08.480</a></span> | <span class="t">We have six of them.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1269" target="_blank">00:21:09.540</a></span> | <span class="t">If you just multiply that out, we have 450 parameters.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1272" target="_blank">00:21:12.400</a></span> | <span class="t">And in this, I'm not counting the biases.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1273" target="_blank">00:21:13.800</a></span> | <span class="t">I'm just counting the raw weights.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1275" target="_blank">00:21:15.640</a></span> | <span class="t">So compared to 15 million, we've only introduced very few parameters.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1279" target="_blank">00:21:19.240</a></span> | <span class="t">Also, how many multiplies have we done?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1281" target="_blank">00:21:21.840</a></span> | <span class="t">So computationally, how many flops are we doing?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1284" target="_blank">00:21:24.960</a></span> | <span class="t">Well, we have 28 by 28 by 6 outputs to produce.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1287" target="_blank">00:21:27.800</a></span> | <span class="t">And every one of these numbers is a function of a 5 by 5 by 3 region in the original image.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1293" target="_blank">00:21:33.120</a></span> | <span class="t">So basically, we have 28 by 28 by 6.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1295" target="_blank">00:21:35.840</a></span> | <span class="t">And then every one of them is computed by doing 5 times 5 times 3 multiplies.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1299" target="_blank">00:21:39.800</a></span> | <span class="t">So you end up with only on the order of 350,000 multiplies.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1303" target="_blank">00:21:43.880</a></span> | <span class="t">So we've reduced from 15 million to quite a few.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1306" target="_blank">00:21:46.600</a></span> | <span class="t">So we're doing less flops, and we're using fewer parameters.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1310" target="_blank">00:21:50.200</a></span> | <span class="t">And really, what we've done here is we've made assumptions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1312" target="_blank">00:21:52.920</a></span> | <span class="t">So we've made the assumption that because the fully connected layer, if this was a fully</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1318" target="_blank">00:21:58.080</a></span> | <span class="t">connected layer, could compute the exact same thing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1322" target="_blank">00:22:02.400</a></span> | <span class="t">So a specific setting of those 15 million parameters would actually produce the exact</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1325" target="_blank">00:22:05.640</a></span> | <span class="t">output of this convolutional layer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1327" target="_blank">00:22:07.240</a></span> | <span class="t">But we've done it much more efficiently.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1328" target="_blank">00:22:08.480</a></span> | <span class="t">We've done that by introducing these biases.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1331" target="_blank">00:22:11.800</a></span> | <span class="t">So in particular, we've made assumptions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1333" target="_blank">00:22:13.600</a></span> | <span class="t">We've assumed, for example, that since we have these fixed filters that we're sliding</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1336" target="_blank">00:22:16.640</a></span> | <span class="t">across space, we've assumed that if there's some interesting feature that you'd like to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1340" target="_blank">00:22:20.320</a></span> | <span class="t">detect in one part of the image, like, say, top left, then that feature will also be useful</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1344" target="_blank">00:22:24.200</a></span> | <span class="t">somewhere else, like on the bottom right, because we fixed these filters and applied</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1347" target="_blank">00:22:27.760</a></span> | <span class="t">them at all the spatial positions equally.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1350" target="_blank">00:22:30.240</a></span> | <span class="t">You might notice that this is not always something that you might want.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1353" target="_blank">00:22:33.080</a></span> | <span class="t">For example, if you're getting inputs that are centered face images, and you're doing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1356" target="_blank">00:22:36.640</a></span> | <span class="t">some kind of a face recognition or something like that, then you might expect that you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1359" target="_blank">00:22:39.680</a></span> | <span class="t">might want different filters at different spatial positions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1362" target="_blank">00:22:42.600</a></span> | <span class="t">Like say, for eye regions, you might want to have some eye-like filters.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1365" target="_blank">00:22:45.800</a></span> | <span class="t">And for mouth region, you might want to have mouth-specific features and so on.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1369" target="_blank">00:22:49.280</a></span> | <span class="t">And so in that case, you might not want to use convolutional layer, because those features</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1372" target="_blank">00:22:52.240</a></span> | <span class="t">have to be shared across all spatial positions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1375" target="_blank">00:22:55.240</a></span> | <span class="t">And the second assumption that we made is that these filters are small locally.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1379" target="_blank">00:22:59.800</a></span> | <span class="t">And so we don't have global connectivity.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1381" target="_blank">00:23:01.580</a></span> | <span class="t">We have this local connectivity.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1383" target="_blank">00:23:03.040</a></span> | <span class="t">But that's OK, because we end up stacking up these convolutional layers in sequence.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1386" target="_blank">00:23:06.840</a></span> | <span class="t">And so the neurons at the end of the ConvNet will grow their receptive field as you stack</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1392" target="_blank">00:23:12.160</a></span> | <span class="t">these convolutional layers on top of each other.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1394" target="_blank">00:23:14.160</a></span> | <span class="t">So at the end of the ConvNet, those neurons end up being a function of the entire image</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1397" target="_blank">00:23:17.000</a></span> | <span class="t">eventually.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1398" target="_blank">00:23:18.000</a></span> | <span class="t">So just to give you an idea about what these activation maps look like concretely, here's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1402" target="_blank">00:23:22.600</a></span> | <span class="t">an example of an image on the top left.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1404" target="_blank">00:23:24.880</a></span> | <span class="t">This is a part of a car, I believe.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1406" target="_blank">00:23:26.640</a></span> | <span class="t">And we have these different filters at-- we have 32 different small filters here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1410" target="_blank">00:23:30.720</a></span> | <span class="t">And so if we were to convolve these filters with this image, we end up with these activation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1414" target="_blank">00:23:34.240</a></span> | <span class="t">maps.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1415" target="_blank">00:23:35.240</a></span> | <span class="t">So this filter, if you convolve it, you get this activation map and so on.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1418" target="_blank">00:23:38.920</a></span> | <span class="t">So this one, for example, has some orange stuff in it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1421" target="_blank">00:23:41.080</a></span> | <span class="t">So when we convolve with this image, you see that this white here is denoting the fact</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1424" target="_blank">00:23:44.900</a></span> | <span class="t">that that filter matches that part of the image quite well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1427" target="_blank">00:23:47.840</a></span> | <span class="t">And so we get these activation maps.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1429" target="_blank">00:23:49.480</a></span> | <span class="t">You stack them up.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1430" target="_blank">00:23:50.520</a></span> | <span class="t">And then that goes into the next convolutional layer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1433" target="_blank">00:23:53.720</a></span> | <span class="t">So the way this looks like then is that we've processed this with some kind of a convolutional</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1439" target="_blank">00:23:59.680</a></span> | <span class="t">layer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1440" target="_blank">00:24:00.680</a></span> | <span class="t">We get some output.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1441" target="_blank">00:24:01.680</a></span> | <span class="t">We apply a rectified linear unit, some kind of a non-linearity as normal.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1445" target="_blank">00:24:05.040</a></span> | <span class="t">And then we would just repeat that operation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1446" target="_blank">00:24:06.880</a></span> | <span class="t">So we keep plugging these conv volumes into the next convolutional layer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1451" target="_blank">00:24:11.480</a></span> | <span class="t">And so they plug into each other in sequence.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1454" target="_blank">00:24:14.080</a></span> | <span class="t">And so we end up processing the image over time.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1457" target="_blank">00:24:17.040</a></span> | <span class="t">So that's the convolutional layer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1459" target="_blank">00:24:19.160</a></span> | <span class="t">You'll notice that there are a few more layers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1460" target="_blank">00:24:20.640</a></span> | <span class="t">So in particular, the pooling layer I'll explain very briefly.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1464" target="_blank">00:24:24.800</a></span> | <span class="t">Pooling layer is quite simple.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1467" target="_blank">00:24:27.060</a></span> | <span class="t">If you've used Photoshop or something like that, you've taken a large image and you've</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1470" target="_blank">00:24:30.520</a></span> | <span class="t">resized it, you've down sampled the image, well, pooling layers do basically something</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1474" target="_blank">00:24:34.920</a></span> | <span class="t">exactly like that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1475" target="_blank">00:24:35.920</a></span> | <span class="t">But they're doing it on every single channel independently.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1478" target="_blank">00:24:38.640</a></span> | <span class="t">So for every one of these channels independently in a input volume, we'll pluck out that activation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1484" target="_blank">00:24:44.400</a></span> | <span class="t">map.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1485" target="_blank">00:24:45.400</a></span> | <span class="t">We'll down sample it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1486" target="_blank">00:24:46.400</a></span> | <span class="t">And that becomes a channel in the output volume.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1488" target="_blank">00:24:48.720</a></span> | <span class="t">So it's really just a down sampling operation on these volumes.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1492" target="_blank">00:24:52.720</a></span> | <span class="t">So for example, one of the common ways of doing this in the context of neural networks</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1495" target="_blank">00:24:55.400</a></span> | <span class="t">especially is to use max pooling operation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1497" target="_blank">00:24:57.860</a></span> | <span class="t">So in this case, it would be common to say, for example, use 2 by 2 filters stride 2 and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1504" target="_blank">00:25:04.000</a></span> | <span class="t">do max operation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1505" target="_blank">00:25:05.840</a></span> | <span class="t">So if this is an input channel in a volume, then we're basically-- what that amounts to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1510" target="_blank">00:25:10.080</a></span> | <span class="t">is we're truncating it into these 2 by 2 regions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1513" target="_blank">00:25:13.400</a></span> | <span class="t">And we're taking a max over 4 numbers to produce one piece of the output.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1518" target="_blank">00:25:18.880</a></span> | <span class="t">So this is a very cheap operation that down samples your volumes.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1521" target="_blank">00:25:21.860</a></span> | <span class="t">It's really a way to control the capacity of the network.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1524" target="_blank">00:25:24.040</a></span> | <span class="t">So you don't want too many numbers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1525" target="_blank">00:25:25.160</a></span> | <span class="t">You don't want things to be too computationally expensive.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1527" target="_blank">00:25:27.220</a></span> | <span class="t">It turns out that a pooling layer allows you to down sample your volumes.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1530" target="_blank">00:25:30.760</a></span> | <span class="t">You're going to end up doing less computation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1532" target="_blank">00:25:32.760</a></span> | <span class="t">And it turns out to not hurt the performance too much.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1535" target="_blank">00:25:35.080</a></span> | <span class="t">So we use them basically as a way of controlling the capacity of these networks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1539" target="_blank">00:25:39.960</a></span> | <span class="t">And the last layer that I want to briefly mention, of course, is the fully connected</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1543" target="_blank">00:25:43.120</a></span> | <span class="t">layer, which is exactly what you're familiar with.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1546" target="_blank">00:25:46.100</a></span> | <span class="t">So we have these volumes throughout as we've processed the image.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1548" target="_blank">00:25:48.720</a></span> | <span class="t">At the end, you're left with this volume.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1550" target="_blank">00:25:50.220</a></span> | <span class="t">And now you'd like to predict some classes.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1551" target="_blank">00:25:51.920</a></span> | <span class="t">So what we do is we just take that volume.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1553" target="_blank">00:25:53.520</a></span> | <span class="t">We stretch it out into a single column.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1555" target="_blank">00:25:55.560</a></span> | <span class="t">And then we apply a fully connected layer, which really amounts to just a matrix multiplication.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1560" target="_blank">00:26:00.000</a></span> | <span class="t">And then that gives us probabilities after applying a softmax or something like that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1566" target="_blank">00:26:06.180</a></span> | <span class="t">So let me now show you briefly a demo of what a convolutional network looks like.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1571" target="_blank">00:26:11.000</a></span> | <span class="t">So this is ConvNetJS.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1572" target="_blank">00:26:12.920</a></span> | <span class="t">This is a deep learning library for training convolutional neural networks that is implemented</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1577" target="_blank">00:26:17.340</a></span> | <span class="t">in JavaScript.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1578" target="_blank">00:26:18.340</a></span> | <span class="t">I wrote this maybe two years ago at this point.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1581" target="_blank">00:26:21.380</a></span> | <span class="t">So here what we're doing is we're training a convolutional network on the CIFAR-10 dataset.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1585" target="_blank">00:26:25.040</a></span> | <span class="t">CIFAR-10 is a dataset of 50,000 images.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1587" target="_blank">00:26:27.880</a></span> | <span class="t">Each image is 32 by 32 by 3.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1590" target="_blank">00:26:30.200</a></span> | <span class="t">And there are 10 different classes.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1592" target="_blank">00:26:32.800</a></span> | <span class="t">So here we are training this network in the browser.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1595" target="_blank">00:26:35.280</a></span> | <span class="t">And you can see that the loss is decreasing, which means that we're better classifying</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1599" target="_blank">00:26:39.320</a></span> | <span class="t">these inputs.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1600" target="_blank">00:26:40.840</a></span> | <span class="t">And so here's the network specification, which you can play with because this is all done</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1604" target="_blank">00:26:44.700</a></span> | <span class="t">in the browser.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1605" target="_blank">00:26:45.700</a></span> | <span class="t">So you can just change this and play with this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1608" target="_blank">00:26:48.080</a></span> | <span class="t">So this is an input image.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1609" target="_blank">00:26:49.380</a></span> | <span class="t">And this convolutional network I'm showing here, all the intermediate activations and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1613" target="_blank">00:26:53.080</a></span> | <span class="t">all the intermediate, basically, activation maps that we're producing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1617" target="_blank">00:26:57.460</a></span> | <span class="t">So here we have a set of filters.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1619" target="_blank">00:26:59.680</a></span> | <span class="t">We're convolving them with the image and getting all these activation maps.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1622" target="_blank">00:27:02.880</a></span> | <span class="t">I'm also showing the gradients, but I don't want to dwell on that too much.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1626" target="_blank">00:27:06.480</a></span> | <span class="t">Then you threshold.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1627" target="_blank">00:27:07.640</a></span> | <span class="t">So ReLU thresholding anything below 0 gets clamped at 0.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1631" target="_blank">00:27:11.600</a></span> | <span class="t">And then you pool.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1632" target="_blank">00:27:12.800</a></span> | <span class="t">So this is just a downsampling operation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1634" target="_blank">00:27:14.980</a></span> | <span class="t">And then another convolution, ReLU pool, conv, ReLU pool, et cetera, until at the end we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1640" target="_blank">00:27:20.160</a></span> | <span class="t">have a fully connected layer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1641" target="_blank">00:27:21.240</a></span> | <span class="t">And then we have our softmax so that we get probabilities out.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1644" target="_blank">00:27:24.600</a></span> | <span class="t">And then we apply a loss to those probabilities and backpropagate.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1648" target="_blank">00:27:28.200</a></span> | <span class="t">And so here we see that I've been training in this tab for the last maybe 30 seconds</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1652" target="_blank">00:27:32.300</a></span> | <span class="t">or one minute.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1653" target="_blank">00:27:33.300</a></span> | <span class="t">And we're already getting about 30% accuracy on CIFAR-10.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1656" target="_blank">00:27:36.420</a></span> | <span class="t">So these are test images from CIFAR-10.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1658" target="_blank">00:27:38.400</a></span> | <span class="t">And these are the outputs of this convolutional network.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1660" target="_blank">00:27:40.680</a></span> | <span class="t">And you can see that it learned that this is already a car or something like that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1663" target="_blank">00:27:43.440</a></span> | <span class="t">So this trains pretty quickly in JavaScript.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1666" target="_blank">00:27:46.360</a></span> | <span class="t">So you can play with this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1667" target="_blank">00:27:47.360</a></span> | <span class="t">And you can change the architecture and so on.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1670" target="_blank">00:27:50.280</a></span> | <span class="t">Another thing I'd like to show you is this video, because it gives you, again, this very</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1673" target="_blank">00:27:53.880</a></span> | <span class="t">intuitive visceral feeling of exactly what this is computing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1677" target="_blank">00:27:57.080</a></span> | <span class="t">Is there is a very good video by Jason Yosinski from--</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1679" target="_blank">00:27:59.920</a></span> | <span class="t">Recent advance--</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1681" target="_blank">00:28:01.240</a></span> | <span class="t">I'm going to play this in a bit.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1682" target="_blank">00:28:02.600</a></span> | <span class="t">This is from the deep visualization toolbox.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1685" target="_blank">00:28:05.420</a></span> | <span class="t">So you can download this code.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1686" target="_blank">00:28:06.480</a></span> | <span class="t">And you can play with this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1687" target="_blank">00:28:07.600</a></span> | <span class="t">It's this interactive convolutional network demo.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1689" target="_blank">00:28:09.880</a></span> | <span class="t">[VIDEO PLAYBACK]</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1690" target="_blank">00:28:10.880</a></span> | <span class="t">- --neural networks have enabled computers to better see and understand the world.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1694" target="_blank">00:28:14.600</a></span> | <span class="t">They can recognize school buses and--</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1696" target="_blank">00:28:16.160</a></span> | <span class="t">[END PLAYBACK]</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1697" target="_blank">00:28:17.160</a></span> | <span class="t">--top left corner, we show the--</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1698" target="_blank">00:28:18.160</a></span> | <span class="t">[END PLAYBACK]</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1699" target="_blank">00:28:19.160</a></span> | <span class="t">I'm going to skip a bit.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1700" target="_blank">00:28:20.160</a></span> | <span class="t">So what we're seeing here is these are activation maps in some particular-- shown in real time</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1705" target="_blank">00:28:25.660</a></span> | <span class="t">as this demo is running.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1707" target="_blank">00:28:27.760</a></span> | <span class="t">So these are for the conv1 layer of an AlexNet, which we're going to go into in much more</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1711" target="_blank">00:28:31.400</a></span> | <span class="t">detail.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1712" target="_blank">00:28:32.400</a></span> | <span class="t">But these are the different activation maps that are being produced at this point.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1715" target="_blank">00:28:35.360</a></span> | <span class="t">[VIDEO PLAYBACK]</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1716" target="_blank">00:28:36.360</a></span> | <span class="t">- --neural network called AlexNet running in CAFE.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1719" target="_blank">00:28:39.800</a></span> | <span class="t">By interacting with the network, we can see what some of the neurons are doing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1724" target="_blank">00:28:44.600</a></span> | <span class="t">For example, on this first layer, a unit in the center responds strongly to light to dark</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1728" target="_blank">00:28:48.800</a></span> | <span class="t">edges.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1731" target="_blank">00:28:51.620</a></span> | <span class="t">This neighbor, one neuron over, responds to edges in the opposite direction, dark to light.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1738" target="_blank">00:28:58.520</a></span> | <span class="t">Using optimization, we can synthetically produce images that light up each neuron on this layer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1742" target="_blank">00:29:02.720</a></span> | <span class="t">to see what each neuron is looking for.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1745" target="_blank">00:29:05.320</a></span> | <span class="t">We can scroll through every layer in the network to see what it does, including convolution,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1749" target="_blank">00:29:09.680</a></span> | <span class="t">pooling, and normalization layers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1752" target="_blank">00:29:12.900</a></span> | <span class="t">We can switch back and forth between showing the actual activations and showing images</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1756" target="_blank">00:29:16.860</a></span> | <span class="t">synthesized to produce high activation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1762" target="_blank">00:29:22.500</a></span> | <span class="t">By the time we get to the fifth convolutional layer, the features being computed represent</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1766" target="_blank">00:29:26.220</a></span> | <span class="t">abstract concepts.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1769" target="_blank">00:29:29.500</a></span> | <span class="t">For example, this neuron seems to respond to faces.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1772" target="_blank">00:29:32.700</a></span> | <span class="t">We can further investigate this neuron by showing a few different types of information.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1776" target="_blank">00:29:36.940</a></span> | <span class="t">First we can artificially create optimized images using new regularization techniques</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1780" target="_blank">00:29:40.740</a></span> | <span class="t">that are described in our paper.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1782" target="_blank">00:29:42.620</a></span> | <span class="t">These synthetic images show that this neuron fires in response to a face and shoulders.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1787" target="_blank">00:29:47.060</a></span> | <span class="t">We can also plot the images from the training set that activate this neuron the most, as</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1790" target="_blank">00:29:50.740</a></span> | <span class="t">well as pixels from those images most responsible for the high activations, computed via the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1795" target="_blank">00:29:55.060</a></span> | <span class="t">deconvolution technique.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1797" target="_blank">00:29:57.120</a></span> | <span class="t">This feature responds to multiple faces in different locations.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1800" target="_blank">00:30:00.740</a></span> | <span class="t">And by looking at the deconv, we can see that it would respond more strongly if we had even</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1805" target="_blank">00:30:05.920</a></span> | <span class="t">darker eyes and rosier lips.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1808" target="_blank">00:30:08.300</a></span> | <span class="t">We can also confirm that it cares about the head and shoulders, but ignores the arms and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1812" target="_blank">00:30:12.180</a></span> | <span class="t">torso.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1814" target="_blank">00:30:14.060</a></span> | <span class="t">We can even see that it fires to some extent for cat faces.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1818" target="_blank">00:30:18.540</a></span> | <span class="t">Using backprop or deconv, we can see that this unit depends most strongly on a couple</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1822" target="_blank">00:30:22.860</a></span> | <span class="t">units in the previous layer, conv4, and on about a dozen or so in conv3.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1828" target="_blank">00:30:28.580</a></span> | <span class="t">Now let's look at another neuron on this layer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1831" target="_blank">00:30:31.180</a></span> | <span class="t">So what's this unit doing?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1833" target="_blank">00:30:33.020</a></span> | <span class="t">From the top nine images, we might conclude that it fires for different types of clothing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1837" target="_blank">00:30:37.620</a></span> | <span class="t">But examining the synthetic images shows that it may be detecting not clothing per se, but</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1842" target="_blank">00:30:42.020</a></span> | <span class="t">wrinkles.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1843" target="_blank">00:30:43.300</a></span> | <span class="t">In the live plot, we can see that it's activated by my shirt.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1846" target="_blank">00:30:46.820</a></span> | <span class="t">And smoothing out half of my shirt causes that half of the activations to decrease.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1852" target="_blank">00:30:52.060</a></span> | <span class="t">Finally, here's another interesting neuron.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1856" target="_blank">00:30:56.120</a></span> | <span class="t">This one has learned to look for printed text in a variety of sizes, colors, and fonts.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1862" target="_blank">00:31:02.080</a></span> | <span class="t">This is pretty cool, because we never ask the network to look for wrinkles or text or</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1865" target="_blank">00:31:05.700</a></span> | <span class="t">faces.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1866" target="_blank">00:31:06.700</a></span> | <span class="t">But the only labels we provided were at the very last layer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1869" target="_blank">00:31:09.460</a></span> | <span class="t">So the only reason the network learned features like text and faces in the middle was to support</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1873" target="_blank">00:31:13.580</a></span> | <span class="t">final decisions at that last layer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1876" target="_blank">00:31:16.260</a></span> | <span class="t">For example, the text detector may provide good evidence that a rectangle is in fact</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1881" target="_blank">00:31:21.140</a></span> | <span class="t">a book seen on edge.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1882" target="_blank">00:31:22.740</a></span> | <span class="t">And detecting many books next to each other might be a good way of detecting a bookcase,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1886" target="_blank">00:31:26.820</a></span> | <span class="t">which was one of the categories we trained the net to recognize.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1891" target="_blank">00:31:31.420</a></span> | <span class="t">In this video, we've shown some of the features of the DeepViz toolbox.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1895" target="_blank">00:31:35.100</a></span> | <span class="t">So I encourage you to play with that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1896" target="_blank">00:31:36.500</a></span> | <span class="t">It's really fun.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1897" target="_blank">00:31:37.700</a></span> | <span class="t">So I hope that gives you an idea about exactly what's going on.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1899" target="_blank">00:31:39.660</a></span> | <span class="t">There are these convolutional layers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1900" target="_blank">00:31:40.780</a></span> | <span class="t">We down sample them from time to time.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1903" target="_blank">00:31:43.020</a></span> | <span class="t">There's usually some fully connected layers at the end.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1905" target="_blank">00:31:45.380</a></span> | <span class="t">But mostly it's just these convolutional operations stacked on top of each other.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1909" target="_blank">00:31:49.220</a></span> | <span class="t">So what I'd like to do now is I'll dive into some details of how these architectures are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1912" target="_blank">00:31:52.700</a></span> | <span class="t">actually put together.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1914" target="_blank">00:31:54.300</a></span> | <span class="t">The way I'll do this is I'll go over all the winners of the ImageNet challenges, and I'll</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1917" target="_blank">00:31:57.940</a></span> | <span class="t">tell you about the architectures, how they came about, how they differ.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1920" target="_blank">00:32:00.780</a></span> | <span class="t">And so you'll get a concrete idea about what these architectures look like in practice.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1924" target="_blank">00:32:04.300</a></span> | <span class="t">So we'll start off with the AlexNet in 2012.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1928" target="_blank">00:32:08.360</a></span> | <span class="t">So the AlexNet, just to give you an idea about the sizes of these networks and the images</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1933" target="_blank">00:32:13.300</a></span> | <span class="t">that they process, it took 227 by 227 by 3 images.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1937" target="_blank">00:32:17.860</a></span> | <span class="t">And the first layer of an AlexNet, for example, was a convolutional layer that had 11 by 11</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1942" target="_blank">00:32:22.500</a></span> | <span class="t">filters applied with a stride of 4.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1945" target="_blank">00:32:25.860</a></span> | <span class="t">And there are 96 of them.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1947" target="_blank">00:32:27.440</a></span> | <span class="t">Stride of 4 I didn't fully explain because I wanted to save some time.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1950" target="_blank">00:32:30.660</a></span> | <span class="t">But intuitively, it just means that as you're sliding this filter across the input, you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1954" target="_blank">00:32:34.460</a></span> | <span class="t">don't have to slide it one pixel at a time, but you can actually jump a few pixels at</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1957" target="_blank">00:32:37.620</a></span> | <span class="t">a time.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1958" target="_blank">00:32:38.620</a></span> | <span class="t">So we have 11 by 11 filters with a stride, a skip of 4.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1962" target="_blank">00:32:42.320</a></span> | <span class="t">And we have 96 of them.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1963" target="_blank">00:32:43.600</a></span> | <span class="t">You can try to compute, for example, what is the output volume if you apply this sort</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1969" target="_blank">00:32:49.540</a></span> | <span class="t">of convolutional layer on top of this volume.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1971" target="_blank">00:32:51.420</a></span> | <span class="t">And I didn't go into details of how you compute that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1973" target="_blank">00:32:53.560</a></span> | <span class="t">But basically, there are formulas for this, and you can look into details in the class.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1978" target="_blank">00:32:58.260</a></span> | <span class="t">But you arrive at 55 by 55 by 96 volume as output.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1983" target="_blank">00:33:03.260</a></span> | <span class="t">The total number of parameters in this layer, we have 96 filters.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1987" target="_blank">00:33:07.500</a></span> | <span class="t">Every one of them is 11 by 11 by 3 because that's the input depth of these images.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1994" target="_blank">00:33:14.460</a></span> | <span class="t">So basically, it just amounts to 11 times 11 times 3.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=1997" target="_blank">00:33:17.280</a></span> | <span class="t">And then you have 96 filters, so about 35,000 parameters in this very first layer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2002" target="_blank">00:33:22.820</a></span> | <span class="t">Then the second layer of an AlexNet is a pooling layer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2005" target="_blank">00:33:25.500</a></span> | <span class="t">So we apply 3 by 3 filters at stride of 2, and they do max pooling.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2010" target="_blank">00:33:30.040</a></span> | <span class="t">So you can, again, compute the output volume size of that after applying this to that volume.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2015" target="_blank">00:33:35.220</a></span> | <span class="t">And you arrive, if you do some very simple arithmetic there, you arrive at 27 by 27 by</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2019" target="_blank">00:33:39.860</a></span> | <span class="t">96.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2020" target="_blank">00:33:40.860</a></span> | <span class="t">So this is the downsampling operation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2022" target="_blank">00:33:42.580</a></span> | <span class="t">You can think about what is the number of parameters in this pooling layer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2027" target="_blank">00:33:47.000</a></span> | <span class="t">And of course, it's 0.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2028" target="_blank">00:33:48.760</a></span> | <span class="t">So pooling layers compute a fixed function, a fixed downsampling operation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2032" target="_blank">00:33:52.460</a></span> | <span class="t">There are no parameters involved in a pooling layer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2034" target="_blank">00:33:54.580</a></span> | <span class="t">All the parameters are in convolutional layers and the fully connected layers, which are,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2037" target="_blank">00:33:57.780</a></span> | <span class="t">to some extent, equivalent to convolutional layers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2041" target="_blank">00:34:01.220</a></span> | <span class="t">So we can go ahead and just basically, based on the description in the paper-- although</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2045" target="_blank">00:34:05.220</a></span> | <span class="t">it's non-trivial, I think, based on the description of this particular paper-- but you can go</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2048" target="_blank">00:34:08.560</a></span> | <span class="t">ahead and decipher what the volumes are throughout.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2051" target="_blank">00:34:11.940</a></span> | <span class="t">You can look at the kind of patterns that emerge in terms of how you actually increase</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2056" target="_blank">00:34:16.460</a></span> | <span class="t">the number of filters in higher convolutional layers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2059" target="_blank">00:34:19.060</a></span> | <span class="t">So we started off with 96.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2060" target="_blank">00:34:20.060</a></span> | <span class="t">Then we go to 256 filters.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2062" target="_blank">00:34:22.300</a></span> | <span class="t">Then to 384.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2064" target="_blank">00:34:24.060</a></span> | <span class="t">And eventually, 4,096 units of fully connected layers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2067" target="_blank">00:34:27.540</a></span> | <span class="t">You'll see also normalization layers here, which have since become slightly deprecated.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2071" target="_blank">00:34:31.660</a></span> | <span class="t">It's not very common to use the normalization layers that were used at the time for the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2076" target="_blank">00:34:36.020</a></span> | <span class="t">AlexNet architecture.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2077" target="_blank">00:34:37.620</a></span> | <span class="t">What's interesting to note is how this differs from the 1998 YAMLACoon network.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2081" target="_blank">00:34:41.780</a></span> | <span class="t">So in particular, I usually like to think about four things that hold back progress,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2086" target="_blank">00:34:46.340</a></span> | <span class="t">so at least in deep learning.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2088" target="_blank">00:34:48.700</a></span> | <span class="t">So the data is a constraint, compute.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2092" target="_blank">00:34:52.900</a></span> | <span class="t">And then I like to differentiate between algorithms and infrastructure, algorithms being something</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2097" target="_blank">00:34:57.060</a></span> | <span class="t">that feels like research and infrastructure being something that feels like a lot of engineering</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2100" target="_blank">00:35:00.500</a></span> | <span class="t">has to happen.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2101" target="_blank">00:35:01.500</a></span> | <span class="t">And so in particular, we've had progress in all those four fronts.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2104" target="_blank">00:35:04.540</a></span> | <span class="t">So we see that in 1998, the data you could get a hold of maybe would be on the order</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2108" target="_blank">00:35:08.860</a></span> | <span class="t">of a few thousand, whereas now we have a few million.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2111" target="_blank">00:35:11.280</a></span> | <span class="t">So we have three orders of magnitude of increase in number of data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2114" target="_blank">00:35:14.660</a></span> | <span class="t">Compute, GPUs have become available, and we use them to train these networks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2118" target="_blank">00:35:18.900</a></span> | <span class="t">They are about, say, roughly 20 times faster than CPUs.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2123" target="_blank">00:35:23.380</a></span> | <span class="t">And then, of course, CPUs we have today are much, much faster than CPUs that they had</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2126" target="_blank">00:35:26.700</a></span> | <span class="t">back in 1998.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2128" target="_blank">00:35:28.060</a></span> | <span class="t">So I don't know exactly to what that works out to, but I wouldn't be surprised if it's,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2130" target="_blank">00:35:30.580</a></span> | <span class="t">again, on the order of three orders of magnitude of improvement again.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2134" target="_blank">00:35:34.540</a></span> | <span class="t">I'd like to actually skip over the algorithm and talk about infrastructure.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2137" target="_blank">00:35:37.020</a></span> | <span class="t">So in this case, we're talking about NVIDIA releasing the CUDA library that allows you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2141" target="_blank">00:35:41.820</a></span> | <span class="t">to efficiently create all these matrix vector operations and apply them on arrays of numbers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2146" target="_blank">00:35:46.900</a></span> | <span class="t">So that's a piece of software that we rely on and that we take advantage of that wasn't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2151" target="_blank">00:35:51.620</a></span> | <span class="t">available before.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2152" target="_blank">00:35:52.940</a></span> | <span class="t">And finally, algorithms is kind of an interesting one, because in those 20 years, there's been</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2157" target="_blank">00:35:57.260</a></span> | <span class="t">much less improvement in algorithms than all these other three pieces.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2162" target="_blank">00:36:02.380</a></span> | <span class="t">So in particular, what we've done with the 1998 network is we've made it bigger.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2165" target="_blank">00:36:05.880</a></span> | <span class="t">So you have more channels.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2167" target="_blank">00:36:07.180</a></span> | <span class="t">You have more layers by a bit.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2169" target="_blank">00:36:09.340</a></span> | <span class="t">And the two really new things algorithmically are dropout and rectified linear units.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2176" target="_blank">00:36:16.660</a></span> | <span class="t">So dropout is a regularization technique developed by Geoff Hinton and colleagues.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2181" target="_blank">00:36:21.700</a></span> | <span class="t">And rectified linear units are these nonlinearities that train much faster than sigmoids and tanhs.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2187" target="_blank">00:36:27.420</a></span> | <span class="t">And this paper actually had a plot that showed that the rectified linear units trained a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2192" target="_blank">00:36:32.300</a></span> | <span class="t">bit faster than sigmoids.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2193" target="_blank">00:36:33.780</a></span> | <span class="t">And that's intuitively because of the vanishing gradient problems.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2196" target="_blank">00:36:36.460</a></span> | <span class="t">And when you have very deep networks with sigmoids, those gradients vanish, as Hugo was</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2200" target="_blank">00:36:40.380</a></span> | <span class="t">talking about in the last lecture.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2203" target="_blank">00:36:43.420</a></span> | <span class="t">So what's interesting also to note, by the way, is that both dropout and ReLU are basically</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2207" target="_blank">00:36:47.380</a></span> | <span class="t">like one line or two lines of code to change.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2210" target="_blank">00:36:50.500</a></span> | <span class="t">So it's about a two line diff total in those 20 years.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2213" target="_blank">00:36:53.880</a></span> | <span class="t">And both of them consist of setting things to zero.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2216" target="_blank">00:36:56.460</a></span> | <span class="t">So with the ReLU, you set things to zero when they're lower than zero.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2219" target="_blank">00:36:59.820</a></span> | <span class="t">And with dropout, you set things to zero at random.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2222" target="_blank">00:37:02.100</a></span> | <span class="t">So it's a good idea to set things to zero.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2224" target="_blank">00:37:04.820</a></span> | <span class="t">Apparently, that's what we've learned.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2226" target="_blank">00:37:06.060</a></span> | <span class="t">So if you try to find a new cool algorithm, look for one line diffs that set something</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2230" target="_blank">00:37:10.120</a></span> | <span class="t">to zero.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2231" target="_blank">00:37:11.120</a></span> | <span class="t">It probably will work better.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2232" target="_blank">00:37:12.660</a></span> | <span class="t">And we could add you here to this list.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2236" target="_blank">00:37:16.020</a></span> | <span class="t">Now some of the newest things that happened, some of the comparing it again and giving</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2240" target="_blank">00:37:20.700</a></span> | <span class="t">you an idea about the hyperparameters that were in this architecture.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2245" target="_blank">00:37:25.100</a></span> | <span class="t">It was the first use of rectified linear units.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2246" target="_blank">00:37:26.780</a></span> | <span class="t">We haven't seen that as much before.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2249" target="_blank">00:37:29.380</a></span> | <span class="t">This network used the normalization layers, which are not used anymore, at least in the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2252" target="_blank">00:37:32.820</a></span> | <span class="t">specific way that they use them in this paper.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2255" target="_blank">00:37:35.980</a></span> | <span class="t">They used heavy data augmentation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2257" target="_blank">00:37:37.700</a></span> | <span class="t">So you don't only pipe these images into the networks exactly as they come from the data</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2262" target="_blank">00:37:42.940</a></span> | <span class="t">set, but you jitter them spatially around a bit.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2265" target="_blank">00:37:45.420</a></span> | <span class="t">And you warp them, and you change the colors a bit, and you just do this randomly because</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2269" target="_blank">00:37:49.060</a></span> | <span class="t">you're trying to build in some invariances to these small perturbations.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2272" target="_blank">00:37:52.340</a></span> | <span class="t">And you're basically hallucinating additional data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2275" target="_blank">00:37:55.220</a></span> | <span class="t">It was the first real use of dropout.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2279" target="_blank">00:37:59.860</a></span> | <span class="t">And roughly, you see standard hyperparameters, like say batch sizes of roughly 128, using</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2285" target="_blank">00:38:05.060</a></span> | <span class="t">stochastic gradient descent with momentum, usually 0.9.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2289" target="_blank">00:38:09.460</a></span> | <span class="t">The momentum learning rates of 1e negative 2, you reduce them in normal ways.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2293" target="_blank">00:38:13.660</a></span> | <span class="t">So you reduce roughly by a factor of 10 whenever validation stops improving.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2297" target="_blank">00:38:17.860</a></span> | <span class="t">And weight decay of just a bit, 5e negative 4.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2301" target="_blank">00:38:21.480</a></span> | <span class="t">And ensembling always helps.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2303" target="_blank">00:38:23.860</a></span> | <span class="t">So you train seven independent convolutional networks separately, and then you just average</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2308" target="_blank">00:38:28.340</a></span> | <span class="t">their predictions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2309" target="_blank">00:38:29.540</a></span> | <span class="t">Always gives you additional 2% improvement.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2312" target="_blank">00:38:32.400</a></span> | <span class="t">So this is AlexNet, the winner of 2012.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2314" target="_blank">00:38:34.580</a></span> | <span class="t">In 2013, the winner was the ZFNet.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2317" target="_blank">00:38:37.700</a></span> | <span class="t">This was developed by Matthew Zeiler and Rob Fergus in 2013.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2323" target="_blank">00:38:43.240</a></span> | <span class="t">And this was an improvement on top of AlexNet architecture.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2325" target="_blank">00:38:45.820</a></span> | <span class="t">In particular, one of the bigger differences here were that the first convolutional layer,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2330" target="_blank">00:38:50.740</a></span> | <span class="t">they went from 11 by 11 stride 4 to 7 by 7 stride 2.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2333" target="_blank">00:38:53.900</a></span> | <span class="t">So you have slightly smaller filters, and you apply them more densely.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2337" target="_blank">00:38:57.420</a></span> | <span class="t">And then also, they noticed that these convolutional layers in the middle, if you make them larger,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2342" target="_blank">00:39:02.220</a></span> | <span class="t">if you scale them up, then you actually gain performance.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2344" target="_blank">00:39:04.420</a></span> | <span class="t">So they managed to improve a tiny bit.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2346" target="_blank">00:39:06.380</a></span> | <span class="t">Matthew Zeiler then went-- he became the founder of Clarify.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2351" target="_blank">00:39:11.620</a></span> | <span class="t">And he worked on this a bit more inside Clarify, and he managed to push the performance to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2355" target="_blank">00:39:15.060</a></span> | <span class="t">11%, which was the winning entry at the time.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2357" target="_blank">00:39:17.880</a></span> | <span class="t">But we don't actually know what gets you from 14% to 11%, because Matthew never disclosed</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2362" target="_blank">00:39:22.900</a></span> | <span class="t">the full details of what happened there.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2364" target="_blank">00:39:24.300</a></span> | <span class="t">But he did say that it was more tweaking of these hyperparameters and optimizing that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2368" target="_blank">00:39:28.220</a></span> | <span class="t">a bit.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2369" target="_blank">00:39:29.620</a></span> | <span class="t">So that was 2013 winner.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2371" target="_blank">00:39:31.020</a></span> | <span class="t">In 2014, we saw a slightly bigger diff to this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2374" target="_blank">00:39:34.580</a></span> | <span class="t">So one of the networks that was introduced then was a VGG net from Karen Simonian and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2377" target="_blank">00:39:37.740</a></span> | <span class="t">Andrew Zisterman.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2379" target="_blank">00:39:39.220</a></span> | <span class="t">What's beautiful about VGG net-- and they explored a few architectures here, and the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2382" target="_blank">00:39:42.020</a></span> | <span class="t">one that ended up working best was this D column, which is why I'm highlighting it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2385" target="_blank">00:39:45.460</a></span> | <span class="t">What's beautiful about the VGG net is that it's so simple.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2388" target="_blank">00:39:48.500</a></span> | <span class="t">So you might have noticed in these previous networks, you have these different filter</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2392" target="_blank">00:39:52.980</a></span> | <span class="t">sizes, different layers, and you do different amount of strides, and everything kind of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2396" target="_blank">00:39:56.620</a></span> | <span class="t">looks a bit hairy, and you're not sure where these hyperparameters are coming from.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2399" target="_blank">00:39:59.700</a></span> | <span class="t">VGG net is extremely uniform.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2402" target="_blank">00:40:02.020</a></span> | <span class="t">All you do is 3 by 3 convolutions with stride 1, pad 1, and you do 2 by 2 max poolings with</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2406" target="_blank">00:40:06.980</a></span> | <span class="t">stride 2.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2408" target="_blank">00:40:08.260</a></span> | <span class="t">And you do this throughout completely homogeneous architecture, and you just alternate a few</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2412" target="_blank">00:40:12.620</a></span> | <span class="t">conv and a few pool layers, and you get top performance.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2416" target="_blank">00:40:16.660</a></span> | <span class="t">So they managed to reduce the error down to 7.3% in the VGG net, just with a very simple</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2422" target="_blank">00:40:22.780</a></span> | <span class="t">and homogeneous architecture.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2424" target="_blank">00:40:24.060</a></span> | <span class="t">So I've also here written out this D architecture.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2427" target="_blank">00:40:27.980</a></span> | <span class="t">So you can see-- I'm not sure how instructive this is, because it's kind of dense.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2432" target="_blank">00:40:32.100</a></span> | <span class="t">But you can definitely see, and you can look at this offline perhaps, but you can see how</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2435" target="_blank">00:40:35.580</a></span> | <span class="t">these volumes develop, and you can see the kinds of sizes of these filters.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2441" target="_blank">00:40:41.100</a></span> | <span class="t">So they're always 3 by 3, but the number of filters, again, grows.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2443" target="_blank">00:40:43.860</a></span> | <span class="t">So we started off with 64, and then we go to 128, 256, 512.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2447" target="_blank">00:40:47.620</a></span> | <span class="t">So we're just doubling it over time.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2451" target="_blank">00:40:51.140</a></span> | <span class="t">I also have a few numbers here, just to give you an idea of the scale at which these networks</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2454" target="_blank">00:40:54.960</a></span> | <span class="t">normally operate.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2456" target="_blank">00:40:56.260</a></span> | <span class="t">So we have on the order of 140 million parameters.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2458" target="_blank">00:40:58.700</a></span> | <span class="t">This is actually quite a lot.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2459" target="_blank">00:40:59.860</a></span> | <span class="t">I'll show you in a bit that this can be about 5 or 10 million parameters, and it works just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2463" target="_blank">00:41:03.020</a></span> | <span class="t">as well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2465" target="_blank">00:41:05.020</a></span> | <span class="t">And it's about 100 megabytes for image, in terms of memory, in the forward pass.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2469" target="_blank">00:41:09.820</a></span> | <span class="t">And then the backward pass also needs roughly on that order.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2472" target="_blank">00:41:12.280</a></span> | <span class="t">So that's roughly the numbers that we're working with here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2476" target="_blank">00:41:16.380</a></span> | <span class="t">Also you can note that most of the-- and this is true mostly in convolutional networks--</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2480" target="_blank">00:41:20.140</a></span> | <span class="t">is that most of the memory is in the early convolutional layers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2483" target="_blank">00:41:23.180</a></span> | <span class="t">Most of the parameters, at least in the case where you use these giant fully connected</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2486" target="_blank">00:41:26.380</a></span> | <span class="t">layers at the top, would be here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2489" target="_blank">00:41:29.340</a></span> | <span class="t">So the winner, actually, in 2014 was not the VGGnet.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2491" target="_blank">00:41:31.780</a></span> | <span class="t">I only present it because it's such a simple architecture.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2494" target="_blank">00:41:34.500</a></span> | <span class="t">But the winner was actually GoogleNet, with a slightly hairier architecture, we should</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2498" target="_blank">00:41:38.500</a></span> | <span class="t">say.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2499" target="_blank">00:41:39.500</a></span> | <span class="t">So it's still a sequence of things.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2501" target="_blank">00:41:41.440</a></span> | <span class="t">But in this case, they've put inception modules in sequence.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2504" target="_blank">00:41:44.700</a></span> | <span class="t">And this is an example inception module.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2506" target="_blank">00:41:46.380</a></span> | <span class="t">I don't have too much time to go into the details, but you can see that it consists</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2509" target="_blank">00:41:49.700</a></span> | <span class="t">basically of convolutions and different kinds of strides and so on.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2514" target="_blank">00:41:54.500</a></span> | <span class="t">So the GoogleNet looks slightly hairier, but it turns out to be more efficient in several</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2521" target="_blank">00:42:01.260</a></span> | <span class="t">respects.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2522" target="_blank">00:42:02.260</a></span> | <span class="t">So for example, it works a bit better than VGGnet, at least at the time.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2526" target="_blank">00:42:06.780</a></span> | <span class="t">It only has 5 million parameters, compared to VGGnet's 140 million parameters, so a huge</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2531" target="_blank">00:42:11.220</a></span> | <span class="t">reduction.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2532" target="_blank">00:42:12.220</a></span> | <span class="t">And you do that, by the way, by just throwing away fully connected layers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2535" target="_blank">00:42:15.180</a></span> | <span class="t">So you'll notice in this breakdown I did, these fully connected layers here have 100</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2538" target="_blank">00:42:18.980</a></span> | <span class="t">million parameters and 16 million parameters.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2541" target="_blank">00:42:21.020</a></span> | <span class="t">Turns out you don't actually need that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2542" target="_blank">00:42:22.460</a></span> | <span class="t">So if you take them away, that actually doesn't hurt performance too much.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2546" target="_blank">00:42:26.220</a></span> | <span class="t">So you can get a huge reduction of parameters.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2550" target="_blank">00:42:30.000</a></span> | <span class="t">And it was slightly -- we can also compare to the original AlexNet.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2555" target="_blank">00:42:35.180</a></span> | <span class="t">So compared to the original AlexNet, we have fewer parameters, a bit more compute, and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2558" target="_blank">00:42:38.820</a></span> | <span class="t">a much better performance.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2560" target="_blank">00:42:40.380</a></span> | <span class="t">So GoogleNet was really optimized to have a low footprint, both memory-wise, both computation-wise,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2565" target="_blank">00:42:45.220</a></span> | <span class="t">and both parameter-wise.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2566" target="_blank">00:42:46.980</a></span> | <span class="t">But it looks a bit uglier.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2567" target="_blank">00:42:47.980</a></span> | <span class="t">And VGGnet is a very beautiful, homogeneous architecture, but there are some inefficiencies</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2572" target="_blank">00:42:52.220</a></span> | <span class="t">in it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2573" target="_blank">00:42:53.220</a></span> | <span class="t">Okay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2574" target="_blank">00:42:54.220</a></span> | <span class="t">So that's 2014.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2575" target="_blank">00:42:55.220</a></span> | <span class="t">Now, in 2015, we had a slightly bigger delta on top of the architectures.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2580" target="_blank">00:43:00.460</a></span> | <span class="t">So right now, these architectures, if Jan Lekhoene looked at them maybe in 1998, he</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2583" target="_blank">00:43:03.660</a></span> | <span class="t">would still recognize everything.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2584" target="_blank">00:43:04.860</a></span> | <span class="t">So everything looks very simple.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2586" target="_blank">00:43:06.740</a></span> | <span class="t">You just played with hyperparameters.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2588" target="_blank">00:43:08.660</a></span> | <span class="t">So one of the first kind of bigger departures, I would argue, was in 2015, with the introduction</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2592" target="_blank">00:43:12.180</a></span> | <span class="t">of residual networks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2594" target="_blank">00:43:14.260</a></span> | <span class="t">And so this is work from Kangming He and colleagues in Microsoft Research Asia.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2598" target="_blank">00:43:18.840</a></span> | <span class="t">And so they did not only win the ImageNet Challenge in 2015, but they won a whole bunch</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2603" target="_blank">00:43:23.360</a></span> | <span class="t">of challenges.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2604" target="_blank">00:43:24.360</a></span> | <span class="t">And this was all just by applying these residual networks that were trained on ImageNet and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2608" target="_blank">00:43:28.640</a></span> | <span class="t">then fine-tuned on all these different tasks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2610" target="_blank">00:43:30.600</a></span> | <span class="t">And you basically can crush lots of different tasks whenever you get a new awesome ConvNet.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2616" target="_blank">00:43:36.860</a></span> | <span class="t">So at this time, the performance was basically 3.57% from these residual networks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2622" target="_blank">00:43:42.260</a></span> | <span class="t">So this is 2015.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2624" target="_blank">00:43:44.100</a></span> | <span class="t">So this paper tried to argue that if you look at the number of layers, it goes up.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2628" target="_blank">00:43:48.340</a></span> | <span class="t">And then they made the point that with residual networks, as we'll see in a bit, you can introduce</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2633" target="_blank">00:43:53.100</a></span> | <span class="t">many more layers and that that correlates strongly with performance.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2637" target="_blank">00:43:57.580</a></span> | <span class="t">We've since found that, in fact, you can make these residual networks quite a lot shallower,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2641" target="_blank">00:44:01.980</a></span> | <span class="t">like say on the order of 20 or 30 layers, and they work just as fine, just as well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2645" target="_blank">00:44:05.580</a></span> | <span class="t">So it's not necessarily the depth here, but I'll go into that in a bit.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2649" target="_blank">00:44:09.200</a></span> | <span class="t">But you get a much better performance.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2650" target="_blank">00:44:10.900</a></span> | <span class="t">What's interesting about this paper is this plot here, where they compare these residual</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2655" target="_blank">00:44:15.900</a></span> | <span class="t">networks-- and I'll go into details of how they work in a bit-- and these what they call</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2659" target="_blank">00:44:19.060</a></span> | <span class="t">plane networks, which is everything I've explained until now.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2662" target="_blank">00:44:22.420</a></span> | <span class="t">And the problem with plane networks is that when you try to scale them up and introduce</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2665" target="_blank">00:44:25.820</a></span> | <span class="t">additional layers, they don't get monotonically better.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2669" target="_blank">00:44:29.080</a></span> | <span class="t">So if you take a 20-layer model-- and this is on CIFAR-10 experience-- if you take a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2674" target="_blank">00:44:34.740</a></span> | <span class="t">20-layer model and you run it, and then you take a 56-layer model, you'll see that the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2679" target="_blank">00:44:39.020</a></span> | <span class="t">56-layer model performs worse.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2681" target="_blank">00:44:41.500</a></span> | <span class="t">And this is not just on the test data, so it's not just an overfitting issue.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2684" target="_blank">00:44:44.940</a></span> | <span class="t">This is on the training data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2686" target="_blank">00:44:46.020</a></span> | <span class="t">The 56-layer model performs worse on the training data than the 20-layer model, even though</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2690" target="_blank">00:44:50.580</a></span> | <span class="t">the 56-layer model can imitate 20-layer model by setting 36 layers to compute identities.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2696" target="_blank">00:44:56.420</a></span> | <span class="t">So basically, it's an optimization problem that you can't find the solution once your</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2701" target="_blank">00:45:01.340</a></span> | <span class="t">problem size grows that much bigger in this plane net architecture.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2705" target="_blank">00:45:05.980</a></span> | <span class="t">So in the residual networks that they proposed, they found that when you wire them up in a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2709" target="_blank">00:45:09.300</a></span> | <span class="t">slightly different way, you monotonically get a better performance as you add more layers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2714" target="_blank">00:45:14.360</a></span> | <span class="t">So more layers, always strictly better, and you don't run into these optimization issues.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2719" target="_blank">00:45:19.460</a></span> | <span class="t">So comparing residual networks to plane networks, in plane networks, as I've explained already,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2724" target="_blank">00:45:24.020</a></span> | <span class="t">you have this sequence of convolutional layers, where every convolutional layer operates over</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2728" target="_blank">00:45:28.420</a></span> | <span class="t">volume before and produces volume.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2730" target="_blank">00:45:30.840</a></span> | <span class="t">In residual networks, we have this first convolutional layer on top of the raw image.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2734" target="_blank">00:45:34.840</a></span> | <span class="t">And there's a pooling layer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2736" target="_blank">00:45:36.880</a></span> | <span class="t">So at this point, we've reduced to 56 by 56 by 64, the original image.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2741" target="_blank">00:45:41.660</a></span> | <span class="t">And then from here on, they have these residual blocks with these funny skip connections.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2745" target="_blank">00:45:45.740</a></span> | <span class="t">And this turns out to be quite important.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2749" target="_blank">00:45:49.200</a></span> | <span class="t">So let me show you what these look like.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2752" target="_blank">00:45:52.180</a></span> | <span class="t">So the original Kyming paper had this architecture here shown under original.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2757" target="_blank">00:45:57.040</a></span> | <span class="t">So on the left, you see original residual networks design.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2760" target="_blank">00:46:00.140</a></span> | <span class="t">Since then, they had an additional paper that played with the architecture and found that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2763" target="_blank">00:46:03.660</a></span> | <span class="t">there's a better arrangement of layers inside this block that works better empirically.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2768" target="_blank">00:46:08.900</a></span> | <span class="t">And so the way this works-- so concentrate on the proposed one in the middle, since that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2772" target="_blank">00:46:12.180</a></span> | <span class="t">works so well-- is you have this pathway where you have this representation of the image</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2777" target="_blank">00:46:17.540</a></span> | <span class="t">x.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2778" target="_blank">00:46:18.540</a></span> | <span class="t">And then instead of transforming that representation x to get a new x to plug in later, we end</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2783" target="_blank">00:46:23.260</a></span> | <span class="t">up having this x.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2785" target="_blank">00:46:25.100</a></span> | <span class="t">We go off, and we do some compute on the side.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2787" target="_blank">00:46:27.840</a></span> | <span class="t">So that's that residual block doing some computation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2790" target="_blank">00:46:30.240</a></span> | <span class="t">And then you add your result on top of x.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2793" target="_blank">00:46:33.500</a></span> | <span class="t">So you have this addition operation here going to the next residual block.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2797" target="_blank">00:46:37.280</a></span> | <span class="t">So you have this x, and you always compute deltas to it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2800" target="_blank">00:46:40.860</a></span> | <span class="t">And I think it's not intuitive that this should work much better or why that works much better.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2804" target="_blank">00:46:44.860</a></span> | <span class="t">I think it becomes a bit more intuitively clear if you actually understand the backpropagation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2808" target="_blank">00:46:48.540</a></span> | <span class="t">dynamics and how backprop works.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2810" target="_blank">00:46:50.780</a></span> | <span class="t">And this is why I always urge people also to implement backprop themselves to get an</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2814" target="_blank">00:46:54.260</a></span> | <span class="t">intuition for how it works, what it's computing, and so on.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2817" target="_blank">00:46:57.380</a></span> | <span class="t">Because if you understand backprop, you'll see that addition operation is a gradient</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2820" target="_blank">00:47:00.820</a></span> | <span class="t">distributor.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2821" target="_blank">00:47:01.940</a></span> | <span class="t">So you get a gradient from the top, and this gradient will flow equally to all the children</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2826" target="_blank">00:47:06.380</a></span> | <span class="t">that participated in that addition.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2828" target="_blank">00:47:08.320</a></span> | <span class="t">So you have gradient flowing here from the supervision.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2830" target="_blank">00:47:10.560</a></span> | <span class="t">So you have supervision at the very bottom here in this diagram.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2833" target="_blank">00:47:13.180</a></span> | <span class="t">And it kind of flows upwards.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2834" target="_blank">00:47:14.780</a></span> | <span class="t">And it flows through these residual blocks and then gets added to the stream.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2839" target="_blank">00:47:19.080</a></span> | <span class="t">But this addition distributes that gradient always identically through.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2843" target="_blank">00:47:23.760</a></span> | <span class="t">So what you end up with is this kind of a gradient superhighway, as I like to call it,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2847" target="_blank">00:47:27.260</a></span> | <span class="t">where these gradients from your supervision go directly to the original convolutional</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2850" target="_blank">00:47:30.420</a></span> | <span class="t">layer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2851" target="_blank">00:47:31.420</a></span> | <span class="t">And on top of that, you get these deltas from all the residual blocks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2854" target="_blank">00:47:34.100</a></span> | <span class="t">So these blocks can come on online and can help out that original stream of information.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2860" target="_blank">00:47:40.380</a></span> | <span class="t">This is also related to, I think, why LSTMs, long short-term memory networks, work better</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2865" target="_blank">00:47:45.780</a></span> | <span class="t">than recurrent neural networks, because they also have these kind of addition operations</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2870" target="_blank">00:47:50.460</a></span> | <span class="t">in the LSTM.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2871" target="_blank">00:47:51.660</a></span> | <span class="t">And it just makes the gradients flow significantly better.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2875" target="_blank">00:47:55.260</a></span> | <span class="t">Then there were some results on top of residual networks that I thought were quite amusing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2878" target="_blank">00:47:58.600</a></span> | <span class="t">So recently, for example, we had this result on deep networks with stochastic depth.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2883" target="_blank">00:48:03.380</a></span> | <span class="t">The idea here was that the authors of this paper noticed that you have these residual</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2887" target="_blank">00:48:07.820</a></span> | <span class="t">blocks that compute deltas on top of your stream.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2891" target="_blank">00:48:11.020</a></span> | <span class="t">And you can basically randomly throw out layers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2894" target="_blank">00:48:14.020</a></span> | <span class="t">So you have these, say, 100 blocks, 100 residual blocks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2896" target="_blank">00:48:16.220</a></span> | <span class="t">And you can randomly drop them out.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2898" target="_blank">00:48:18.460</a></span> | <span class="t">And at test time, similar to dropout, you introduce all of them.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2901" target="_blank">00:48:21.980</a></span> | <span class="t">And they all work at the same time.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2903" target="_blank">00:48:23.300</a></span> | <span class="t">But you have to scale things a bit, just like with dropout.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2906" target="_blank">00:48:26.500</a></span> | <span class="t">But basically, it's kind of an unintuitive result, because you can throw out layers at</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2909" target="_blank">00:48:29.780</a></span> | <span class="t">random.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2910" target="_blank">00:48:30.780</a></span> | <span class="t">And I think it breaks the original notion of what we had of ConvNets as these feature</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2915" target="_blank">00:48:35.820</a></span> | <span class="t">transformers that compute more and more complex features over time or something like that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2920" target="_blank">00:48:40.780</a></span> | <span class="t">And I think it seems much more intuitive to think about these residual networks, at least</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2924" target="_blank">00:48:44.740</a></span> | <span class="t">to me, as some kinds of dynamical systems, where you have this original representation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2929" target="_blank">00:48:49.940</a></span> | <span class="t">of the image x.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2930" target="_blank">00:48:50.940</a></span> | <span class="t">And then every single residual block is kind of like a vector field, because it computes</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2934" target="_blank">00:48:54.860</a></span> | <span class="t">in a delta on top of your signal.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2937" target="_blank">00:48:57.420</a></span> | <span class="t">And so these vector fields nudge your original representation x towards a space where you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2942" target="_blank">00:49:02.020</a></span> | <span class="t">can decode the answer y of the class of that x.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2946" target="_blank">00:49:06.180</a></span> | <span class="t">And so if you drop off some of these residual blocks at random, then if you haven't applied</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2949" target="_blank">00:49:09.980</a></span> | <span class="t">one of these vector fields, then the other vector fields that come later can kind of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2953" target="_blank">00:49:13.020</a></span> | <span class="t">make up for it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2954" target="_blank">00:49:14.020</a></span> | <span class="t">And they basically nudge the-- they pick up the slack.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2957" target="_blank">00:49:17.980</a></span> | <span class="t">And they nudge it along anyways.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2959" target="_blank">00:49:19.740</a></span> | <span class="t">And so that's possibly why the image I currently have in mind of how these things work.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2964" target="_blank">00:49:24.820</a></span> | <span class="t">So much more like dynamical systems.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2967" target="_blank">00:49:27.660</a></span> | <span class="t">In fact, another experiment that people are playing with that I also find interesting</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2970" target="_blank">00:49:30.780</a></span> | <span class="t">is you can share these residual blocks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2973" target="_blank">00:49:33.700</a></span> | <span class="t">So it starts to look more like a recurrent neural network.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2976" target="_blank">00:49:36.340</a></span> | <span class="t">So these residual blocks would have shared connectivity.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2979" target="_blank">00:49:39.020</a></span> | <span class="t">And then you have this dynamical system, really, where you're just running a single RNN, a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2982" target="_blank">00:49:42.940</a></span> | <span class="t">single vector field that you keep iterating over and over.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2985" target="_blank">00:49:45.380</a></span> | <span class="t">And then your fixed point gives you the answer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2987" target="_blank">00:49:47.380</a></span> | <span class="t">So it's kind of interesting what's happening.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2989" target="_blank">00:49:49.980</a></span> | <span class="t">It looks very funny.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2992" target="_blank">00:49:52.860</a></span> | <span class="t">We've had many more interesting results.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2994" target="_blank">00:49:54.780</a></span> | <span class="t">So people are playing a lot with these residual networks and improving on them in various</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=2999" target="_blank">00:49:59.260</a></span> | <span class="t">ways.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3000" target="_blank">00:50:00.260</a></span> | <span class="t">So as I mentioned already, it turns out that you can make these residual networks much</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3003" target="_blank">00:50:03.180</a></span> | <span class="t">shallower and make them wider.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3005" target="_blank">00:50:05.600</a></span> | <span class="t">So you introduce more channels.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3007" target="_blank">00:50:07.020</a></span> | <span class="t">And that can work just as well, if not better.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3008" target="_blank">00:50:08.960</a></span> | <span class="t">So it's not necessarily the depth that is giving you a lot of the performance.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3013" target="_blank">00:50:13.680</a></span> | <span class="t">You can scale down the depth.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3015" target="_blank">00:50:15.100</a></span> | <span class="t">And if you increase the width, that can actually work better.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3018" target="_blank">00:50:18.180</a></span> | <span class="t">And they're also more efficient if you do it that way.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3021" target="_blank">00:50:21.140</a></span> | <span class="t">There's more funny regularization techniques.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3023" target="_blank">00:50:23.700</a></span> | <span class="t">Here swap out is a funny regularization technique that actually interpolates between plain nets,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3028" target="_blank">00:50:28.660</a></span> | <span class="t">res nets, and dropout.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3030" target="_blank">00:50:30.260</a></span> | <span class="t">So that's also a funny paper.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3032" target="_blank">00:50:32.180</a></span> | <span class="t">We have fractal nets.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3033" target="_blank">00:50:33.620</a></span> | <span class="t">We actually have many more different types of nets.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3035" target="_blank">00:50:35.660</a></span> | <span class="t">And so people have really experimented with this a lot.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3037" target="_blank">00:50:37.460</a></span> | <span class="t">I'm really eager to see what the winning architecture will be in 2016 as a result of a lot of this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3042" target="_blank">00:50:42.260</a></span> | <span class="t">One of the things that has really enabled this rapid experimentation in the community</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3045" target="_blank">00:50:45.700</a></span> | <span class="t">is that somehow we've developed, luckily, this culture of sharing a lot of code among</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3050" target="_blank">00:50:50.220</a></span> | <span class="t">ourselves.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3051" target="_blank">00:50:51.220</a></span> | <span class="t">So for example, Facebook has released-- just as an example-- Facebook has released residual</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3055" target="_blank">00:50:55.740</a></span> | <span class="t">networks code in Torch that is really good that a lot of these papers, I believe, have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3059" target="_blank">00:50:59.140</a></span> | <span class="t">adopted and worked on top of and that allowed them to actually really scale up their experiments</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3063" target="_blank">00:51:03.740</a></span> | <span class="t">and explore different architectures.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3067" target="_blank">00:51:07.920</a></span> | <span class="t">So it's great that this has happened.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3069" target="_blank">00:51:09.580</a></span> | <span class="t">Unfortunately, a lot of these papers are coming on archive.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3072" target="_blank">00:51:12.340</a></span> | <span class="t">And it's kind of a chaos as these are being uploaded.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3074" target="_blank">00:51:14.260</a></span> | <span class="t">So at this point, I think this is a natural point to plug very briefly my archivesanity.com.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3079" target="_blank">00:51:19.820</a></span> | <span class="t">So this is the best website ever.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3081" target="_blank">00:51:21.640</a></span> | <span class="t">And what it does is it crawls archive.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3084" target="_blank">00:51:24.500</a></span> | <span class="t">And it takes all the papers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3086" target="_blank">00:51:26.500</a></span> | <span class="t">And it analyzes all the papers, the full text of the papers, and creates TF-IDF bag of words</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3090" target="_blank">00:51:30.540</a></span> | <span class="t">features for all the papers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3092" target="_blank">00:51:32.580</a></span> | <span class="t">And then you can do things like you can search a particular paper, like residual networks</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3095" target="_blank">00:51:35.580</a></span> | <span class="t">paper here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3096" target="_blank">00:51:36.580</a></span> | <span class="t">And you can look for similar papers on archive.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3098" target="_blank">00:51:38.580</a></span> | <span class="t">And so this is a sorted list of basically all the residual networks papers that are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3101" target="_blank">00:51:41.540</a></span> | <span class="t">most related to that paper.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3103" target="_blank">00:51:43.700</a></span> | <span class="t">Or you can also create user accounts.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3105" target="_blank">00:51:45.260</a></span> | <span class="t">And you can create a library of papers that you like.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3107" target="_blank">00:51:47.340</a></span> | <span class="t">And then Archive Sanity will train a support vector machine for you.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3110" target="_blank">00:51:50.400</a></span> | <span class="t">And basically, you can look at what are archive papers over the last month that I would enjoy</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3114" target="_blank">00:51:54.660</a></span> | <span class="t">the most.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3115" target="_blank">00:51:55.660</a></span> | <span class="t">And that's just computed by Archive Sanity.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3117" target="_blank">00:51:57.460</a></span> | <span class="t">And so it's like a curated feed specifically for you.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3120" target="_blank">00:52:00.080</a></span> | <span class="t">So I use this quite a bit.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3121" target="_blank">00:52:01.080</a></span> | <span class="t">And I find it useful.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3122" target="_blank">00:52:02.360</a></span> | <span class="t">So I hope that other people do as well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3125" target="_blank">00:52:05.060</a></span> | <span class="t">OK.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3126" target="_blank">00:52:06.100</a></span> | <span class="t">So we saw convolutional neural networks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3128" target="_blank">00:52:08.300</a></span> | <span class="t">I explained how they work.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3129" target="_blank">00:52:09.500</a></span> | <span class="t">I explained some of the background context.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3131" target="_blank">00:52:11.100</a></span> | <span class="t">I've given you an idea of what they look like in practice.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3133" target="_blank">00:52:13.500</a></span> | <span class="t">And we went through case studies of the winning architectures over time.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3136" target="_blank">00:52:16.900</a></span> | <span class="t">But so far, we've only looked at image classification specifically.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3139" target="_blank">00:52:19.540</a></span> | <span class="t">So we're categorizing images into some number of bins.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3142" target="_blank">00:52:22.380</a></span> | <span class="t">So I'd like to briefly talk about addressing other tasks in computer vision and how you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3146" target="_blank">00:52:26.220</a></span> | <span class="t">might go about doing that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3148" target="_blank">00:52:28.160</a></span> | <span class="t">So the way to think about doing other tasks in computer vision is that really what we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3152" target="_blank">00:52:32.300</a></span> | <span class="t">have is you can think of this convolutional neural network as this block of compute that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3157" target="_blank">00:52:37.500</a></span> | <span class="t">has a few million parameters in it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3159" target="_blank">00:52:39.540</a></span> | <span class="t">And it can do basically arbitrary functions that are very nice over images.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3163" target="_blank">00:52:43.740</a></span> | <span class="t">And so it takes an image, gives you some kind of features.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3167" target="_blank">00:52:47.260</a></span> | <span class="t">And now different tasks will basically look as follows.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3170" target="_blank">00:52:50.540</a></span> | <span class="t">You want to predict some kind of a thing in different tasks that will be different things.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3174" target="_blank">00:52:54.620</a></span> | <span class="t">And you always have a desired thing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3176" target="_blank">00:52:56.300</a></span> | <span class="t">And then you want to make the predicted thing much more closer to the desired thing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3179" target="_blank">00:52:59.660</a></span> | <span class="t">And you back propagate.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3181" target="_blank">00:53:01.100</a></span> | <span class="t">So this is the only part usually that changes from task to task.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3183" target="_blank">00:53:03.940</a></span> | <span class="t">You'll see that these comm nets don't change too much.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3186" target="_blank">00:53:06.020</a></span> | <span class="t">What changes is your loss function at the very end.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3188" target="_blank">00:53:08.120</a></span> | <span class="t">And that's what actually helps you really transfer a lot of these winning architectures.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3192" target="_blank">00:53:12.260</a></span> | <span class="t">You usually use these pre-trained networks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3193" target="_blank">00:53:13.900</a></span> | <span class="t">And you don't worry too much about the details of that architecture.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3196" target="_blank">00:53:16.460</a></span> | <span class="t">Because you're only worried about adding a small piece at the top or changing the loss</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3199" target="_blank">00:53:19.660</a></span> | <span class="t">function or substituting a new data set and so on.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3202" target="_blank">00:53:22.520</a></span> | <span class="t">So just to make this slightly more concrete, in image classification, we apply this compute</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3206" target="_blank">00:53:26.780</a></span> | <span class="t">block.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3207" target="_blank">00:53:27.780</a></span> | <span class="t">We get these features.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3208" target="_blank">00:53:28.780</a></span> | <span class="t">And then if I want to do classification, I would basically predict 1,000 numbers that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3212" target="_blank">00:53:32.260</a></span> | <span class="t">give me the log probabilities of different classes.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3214" target="_blank">00:53:34.700</a></span> | <span class="t">And then I have a predicted thing, a desired thing, particular class.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3218" target="_blank">00:53:38.260</a></span> | <span class="t">And I can back prop.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3219" target="_blank">00:53:39.740</a></span> | <span class="t">If I'm doing image captioning, it also looks very similar.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3222" target="_blank">00:53:42.940</a></span> | <span class="t">Instead of predicting just a vector of 1,000 numbers, I now have, for example, 10,000 words</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3228" target="_blank">00:53:48.900</a></span> | <span class="t">in some kind of vocabulary.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3230" target="_blank">00:53:50.580</a></span> | <span class="t">And I'd be predicting 10,000 numbers and a sequence of them.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3233" target="_blank">00:53:53.480</a></span> | <span class="t">And so I can use a recurrent neural network, which you will hear much more about, I think,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3237" target="_blank">00:53:57.460</a></span> | <span class="t">in Richard's lecture just after this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3240" target="_blank">00:54:00.340</a></span> | <span class="t">And so I produce a sequence of 10,000 dimensional vectors.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3242" target="_blank">00:54:02.540</a></span> | <span class="t">And that's just a description.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3243" target="_blank">00:54:03.580</a></span> | <span class="t">And they indicate the probabilities of different words to be emitted at different time steps.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3248" target="_blank">00:54:08.020</a></span> | <span class="t">Or for example, if you want to do localization, again, most of the block stays unchanged.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3252" target="_blank">00:54:12.460</a></span> | <span class="t">But now we also want some kind of an extent in the image.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3256" target="_blank">00:54:16.660</a></span> | <span class="t">So suppose we want to classify-- we don't only just want to classify this as an airplane,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3260" target="_blank">00:54:20.300</a></span> | <span class="t">but we want to localize it with x, y, width, height, bounding box coordinates.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3264" target="_blank">00:54:24.280</a></span> | <span class="t">And if we make the specific assumption as well that there's always a single one thing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3268" target="_blank">00:54:28.000</a></span> | <span class="t">in the image, like a single airplane in every image, then you can just afford to just predict</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3272" target="_blank">00:54:32.020</a></span> | <span class="t">that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3273" target="_blank">00:54:33.020</a></span> | <span class="t">So we predict these softmax scores, just like before, and apply the cross-entropy loss.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3277" target="_blank">00:54:37.380</a></span> | <span class="t">And then we can predict x, y, width, height on top of that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3279" target="_blank">00:54:39.780</a></span> | <span class="t">And we use an L2 loss or a Hoover loss or something like that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3283" target="_blank">00:54:43.500</a></span> | <span class="t">So you just have a predicted thing, a desired thing, and you just backprop.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3287" target="_blank">00:54:47.940</a></span> | <span class="t">If you want to do reinforcement learning because you want to play different games, then again,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3291" target="_blank">00:54:51.500</a></span> | <span class="t">the setup is you just predict some different thing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3293" target="_blank">00:54:53.740</a></span> | <span class="t">And it has some different semantics.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3295" target="_blank">00:54:55.420</a></span> | <span class="t">So in this case, we would be, for example, predicting eight numbers that give us the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3298" target="_blank">00:54:58.400</a></span> | <span class="t">probabilities of taking different actions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3301" target="_blank">00:55:01.060</a></span> | <span class="t">For example, there are eight discrete actions in Atari.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3303" target="_blank">00:55:03.420</a></span> | <span class="t">And we just predict eight numbers, and then we train this with a slightly different manner.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3307" target="_blank">00:55:07.820</a></span> | <span class="t">Because in the case of reinforcement learning, you don't actually know what the correct action</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3312" target="_blank">00:55:12.500</a></span> | <span class="t">is to take at any point in time.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3314" target="_blank">00:55:14.300</a></span> | <span class="t">But you can still get a desired thing eventually, because you just run these rollouts over time,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3318" target="_blank">00:55:18.940</a></span> | <span class="t">and you just see what happens.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3322" target="_blank">00:55:22.000</a></span> | <span class="t">And then that helps inform exactly what the correct answer should have been or what the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3326" target="_blank">00:55:26.820</a></span> | <span class="t">desired thing should have been in any one of those rollouts in any point in time.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3330" target="_blank">00:55:30.580</a></span> | <span class="t">I don't want to dwell on this too much in this lecture, though.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3332" target="_blank">00:55:32.340</a></span> | <span class="t">It's outside of the scope.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3333" target="_blank">00:55:33.700</a></span> | <span class="t">You'll hear much more about reinforcement learning in a later lecture.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3338" target="_blank">00:55:38.460</a></span> | <span class="t">If you wanted to do segmentation, for example, then you don't want to predict a single vector</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3343" target="_blank">00:55:43.320</a></span> | <span class="t">of numbers for a single image.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3345" target="_blank">00:55:45.980</a></span> | <span class="t">But every single pixel has its own category that you'd like to predict.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3348" target="_blank">00:55:48.980</a></span> | <span class="t">So a data set will actually be colored like this, and you have different classes, different</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3352" target="_blank">00:55:52.020</a></span> | <span class="t">areas.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3353" target="_blank">00:55:53.200</a></span> | <span class="t">And then instead of predicting a single vector of classes, you predict an entire array of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3358" target="_blank">00:55:58.500</a></span> | <span class="t">224 by 224, since that's the extent of the original image, for example, times 20 if you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3362" target="_blank">00:56:02.740</a></span> | <span class="t">have 20 different classes.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3364" target="_blank">00:56:04.340</a></span> | <span class="t">And then you basically have 224 by 224 independent soft maxes here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3368" target="_blank">00:56:08.940</a></span> | <span class="t">That's one way you could pose this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3370" target="_blank">00:56:10.180</a></span> | <span class="t">And then you back propagate.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3371" target="_blank">00:56:11.720</a></span> | <span class="t">This here would be slightly more difficult, because you see here I have deconv layers</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3376" target="_blank">00:56:16.240</a></span> | <span class="t">mentioned here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3377" target="_blank">00:56:17.240</a></span> | <span class="t">And I didn't explain deconvolutional layers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3379" target="_blank">00:56:19.380</a></span> | <span class="t">They're related to convolutional layers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3380" target="_blank">00:56:20.740</a></span> | <span class="t">They do a very similar operation, but kind of backwards in some way.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3384" target="_blank">00:56:24.860</a></span> | <span class="t">So a convolutional layer kind of does these downsampling operations as it computes.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3388" target="_blank">00:56:28.300</a></span> | <span class="t">A deconv layer does these kind of upsampling operations as it computes these convolutions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3392" target="_blank">00:56:32.660</a></span> | <span class="t">But in fact, you can implement a deconv layer using a conv layer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3395" target="_blank">00:56:35.780</a></span> | <span class="t">So what you do is you deconv forward pass is the conv layer backward pass.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3400" target="_blank">00:56:40.060</a></span> | <span class="t">And the deconv backward pass is the conv layer forward pass, basically.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3403" target="_blank">00:56:43.580</a></span> | <span class="t">So they're basically an identical operation, but just are you upsampling or downsampling</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3407" target="_blank">00:56:47.380</a></span> | <span class="t">kind of.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3408" target="_blank">00:56:48.880</a></span> | <span class="t">So you can use deconv layers, or you can use hypercolumns.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3411" target="_blank">00:56:51.820</a></span> | <span class="t">And there are different things that people do in segmentation literature.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3415" target="_blank">00:56:55.140</a></span> | <span class="t">But that's just a rough idea, as you're just changing the loss function at the end.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3418" target="_blank">00:56:58.500</a></span> | <span class="t">If you wanted to do autoencoders, so you want to do some unsupervised learning or something</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3421" target="_blank">00:57:01.660</a></span> | <span class="t">like that, well, you're just trying to predict the original image.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3424" target="_blank">00:57:04.620</a></span> | <span class="t">So you're trying to get the convolutional network to implement the identity transformation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3429" target="_blank">00:57:09.140</a></span> | <span class="t">And the trick, of course, that makes it non-trivial is that you're forcing the representation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3432" target="_blank">00:57:12.700</a></span> | <span class="t">to go through this representational bottleneck of 7 by 7 by 512.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3436" target="_blank">00:57:16.580</a></span> | <span class="t">So the network must find an efficient representation of the original image so that it can decode</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3440" target="_blank">00:57:20.100</a></span> | <span class="t">it later.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3441" target="_blank">00:57:21.100</a></span> | <span class="t">So that would be an autoencoder.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3442" target="_blank">00:57:22.740</a></span> | <span class="t">You again have an L2 loss at the end, and you backprop.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3445" target="_blank">00:57:25.620</a></span> | <span class="t">Or if you want to do variational autoencoders, you have to introduce a reparameterization</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3448" target="_blank">00:57:28.900</a></span> | <span class="t">layer, and you have to append an additional small loss that makes your posterior be your</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3452" target="_blank">00:57:32.940</a></span> | <span class="t">prior.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3453" target="_blank">00:57:33.940</a></span> | <span class="t">But it's just like an additional layer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3455" target="_blank">00:57:35.020</a></span> | <span class="t">And then you have an entire generative model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3456" target="_blank">00:57:36.820</a></span> | <span class="t">And you can actually sample images as well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3459" target="_blank">00:57:39.740</a></span> | <span class="t">If you wanted to do detection, things get a little more hairy, perhaps, compared to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3463" target="_blank">00:57:43.940</a></span> | <span class="t">localization or something like that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3465" target="_blank">00:57:45.700</a></span> | <span class="t">So one of my favorite detectors, perhaps, to explain is the YOLO detector, because it's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3468" target="_blank">00:57:48.980</a></span> | <span class="t">perhaps the simplest one.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3470" target="_blank">00:57:50.500</a></span> | <span class="t">It doesn't work the best, but it's the simplest one to explain and has the core idea of how</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3473" target="_blank">00:57:53.940</a></span> | <span class="t">people do detection in computer vision.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3477" target="_blank">00:57:57.340</a></span> | <span class="t">And so the way this works is we reduced the original image to a 7 by 7 by 512 feature.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3483" target="_blank">00:58:03.780</a></span> | <span class="t">So really, there are these 49 discrete locations that we have.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3488" target="_blank">00:58:08.500</a></span> | <span class="t">And at every single one of these 49 locations, we're going to predict-- in YOLO, we're going</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3493" target="_blank">00:58:13.400</a></span> | <span class="t">to predict a class.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3494" target="_blank">00:58:14.740</a></span> | <span class="t">So that's shown here on the top right.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3495" target="_blank">00:58:15.940</a></span> | <span class="t">So every single one of these 49 will be some kind of a softmax.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3500" target="_blank">00:58:20.140</a></span> | <span class="t">And then additionally, at every single position, we're going to predict some number of bounding</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3503" target="_blank">00:58:23.940</a></span> | <span class="t">boxes.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3505" target="_blank">00:58:25.060</a></span> | <span class="t">And so there's going to be a b number of bounding boxes.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3507" target="_blank">00:58:27.700</a></span> | <span class="t">Say b is 10.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3509" target="_blank">00:58:29.080</a></span> | <span class="t">So we're going to be predicting 50 numbers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3511" target="_blank">00:58:31.780</a></span> | <span class="t">And the 5 comes from the fact that every bounding box will have five numbers associated with</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3515" target="_blank">00:58:35.300</a></span> | <span class="t">it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3516" target="_blank">00:58:36.300</a></span> | <span class="t">So you have to describe the x, y, the width, and the height.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3518" target="_blank">00:58:38.620</a></span> | <span class="t">And you have to also indicate some kind of a confidence of that bounding box.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3523" target="_blank">00:58:43.620</a></span> | <span class="t">So that's the fifth number, some kind of a confidence measure.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3526" target="_blank">00:58:46.180</a></span> | <span class="t">So you basically end up predicting these bounding boxes.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3528" target="_blank">00:58:48.580</a></span> | <span class="t">They have positions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3529" target="_blank">00:58:49.620</a></span> | <span class="t">They have class.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3530" target="_blank">00:58:50.660</a></span> | <span class="t">They have confidence.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3532" target="_blank">00:58:52.280</a></span> | <span class="t">And then you have some true bounding boxes in the image.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3534" target="_blank">00:58:54.660</a></span> | <span class="t">So you know that there are certain true boxes.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3537" target="_blank">00:58:57.200</a></span> | <span class="t">And they have certain class.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3539" target="_blank">00:58:59.060</a></span> | <span class="t">And what you do then is you match up the desired thing with the predicted thing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3543" target="_blank">00:59:03.780</a></span> | <span class="t">And whatever-- so say, for example, you had one bounding box of a cat.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3548" target="_blank">00:59:08.420</a></span> | <span class="t">Then you would find the closest predicted bounding box.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3550" target="_blank">00:59:10.960</a></span> | <span class="t">And you would mark it as a positive.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3552" target="_blank">00:59:12.760</a></span> | <span class="t">And you would try to make that associated grid cell predict cat.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3556" target="_blank">00:59:16.100</a></span> | <span class="t">And you would nudge the prediction to be slightly more towards the cat box.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3560" target="_blank">00:59:20.900</a></span> | <span class="t">And so all of this can be done with simple losses.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3562" target="_blank">00:59:22.580</a></span> | <span class="t">And you just back propagate that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3563" target="_blank">00:59:23.740</a></span> | <span class="t">And then you have a detector.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3565" target="_blank">00:59:25.540</a></span> | <span class="t">Or if you want to get much more fancy, you could do dense image captioning.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3568" target="_blank">00:59:28.940</a></span> | <span class="t">So in this case, this is a combination of detection and image captioning.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3572" target="_blank">00:59:32.380</a></span> | <span class="t">This is a paper with my equal co-author Justin Johnson and Fei-Fei Li from last year.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3576" target="_blank">00:59:36.460</a></span> | <span class="t">And so what we did here is image comes in.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3578" target="_blank">00:59:38.240</a></span> | <span class="t">And it becomes much more complex.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3579" target="_blank">00:59:39.420</a></span> | <span class="t">I don't maybe want to go into it as much.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3581" target="_blank">00:59:41.580</a></span> | <span class="t">But the first order approximation is that instead-- it's basically a detection.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3585" target="_blank">00:59:45.400</a></span> | <span class="t">But instead of predicting fixed classes, we instead predict a sequence of words.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3589" target="_blank">00:59:49.560</a></span> | <span class="t">So we use a recurrent neural network there.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3591" target="_blank">00:59:51.960</a></span> | <span class="t">But basically, you can take an image then.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3593" target="_blank">00:59:53.260</a></span> | <span class="t">And you can predict-- you can both detect and describe everything in a complex visual</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3597" target="_blank">00:59:57.420</a></span> | <span class="t">scene.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3598" target="_blank">00:59:58.960</a></span> | <span class="t">So that's just some overview of different tasks that people care about.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3601" target="_blank">01:00:01.700</a></span> | <span class="t">Most of them consist of just changing this top part.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3604" target="_blank">01:00:04.560</a></span> | <span class="t">You put a different loss function, a different data set.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3607" target="_blank">01:00:07.240</a></span> | <span class="t">But you'll see that this computational block stays relatively unchanged from time to time.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3611" target="_blank">01:00:11.340</a></span> | <span class="t">And that's why, as I mentioned, when you do transfer learning, you just want to take these</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3614" target="_blank">01:00:14.980</a></span> | <span class="t">pre-trained networks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3615" target="_blank">01:00:15.980</a></span> | <span class="t">And you mostly want to use whatever works well on ImageNet, because a lot of that does</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3619" target="_blank">01:00:19.500</a></span> | <span class="t">not change too much.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3622" target="_blank">01:00:22.420</a></span> | <span class="t">So in the last part of the talk, I'd like to-- let me just make sure we're good on time.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3625" target="_blank">01:00:25.940</a></span> | <span class="t">OK, we're good.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3627" target="_blank">01:00:27.280</a></span> | <span class="t">So in the last part of the talk, I just wanted to give some hints or some practical considerations</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3631" target="_blank">01:00:31.740</a></span> | <span class="t">when you want to apply convolutional networks in practice.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3634" target="_blank">01:00:34.820</a></span> | <span class="t">So first consideration you might have if you want to run these networks is, what hardware</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3638" target="_blank">01:00:38.480</a></span> | <span class="t">do I use?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3640" target="_blank">01:00:40.460</a></span> | <span class="t">So some of the options that I think are available to you-- well, first of all, you can just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3644" target="_blank">01:00:44.540</a></span> | <span class="t">buy a machine.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3645" target="_blank">01:00:45.640</a></span> | <span class="t">So for example, NVIDIA has these Digits dev boxes that you can buy.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3650" target="_blank">01:00:50.260</a></span> | <span class="t">They have Titan X GPUs, which are strong GPUs.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3653" target="_blank">01:00:53.460</a></span> | <span class="t">You can also, if you're much more ambitious, you can buy a DGX1, which has the newest Pascal</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3657" target="_blank">01:00:57.540</a></span> | <span class="t">P100 GPUs.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3658" target="_blank">01:00:58.540</a></span> | <span class="t">Unfortunately, the DGX1 is about $130,000.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3662" target="_blank">01:01:02.400</a></span> | <span class="t">So this is kind of an expensive supercomputer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3665" target="_blank">01:01:05.600</a></span> | <span class="t">But the Digits dev box, I think, is more accessible.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3667" target="_blank">01:01:07.940</a></span> | <span class="t">And so that's one option you can go with.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3670" target="_blank">01:01:10.140</a></span> | <span class="t">Alternatively, you can look at the specs of a dev box.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3673" target="_blank">01:01:13.780</a></span> | <span class="t">And those specs are-- they're good specs.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3675" target="_blank">01:01:15.980</a></span> | <span class="t">And then you can buy all the components yourself and assemble it like LEGO.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3679" target="_blank">01:01:19.660</a></span> | <span class="t">Unfortunately, that's prone to mistakes, of course.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3682" target="_blank">01:01:22.500</a></span> | <span class="t">But you can definitely reduce the price maybe by a factor of like two compared to the NVIDIA</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3687" target="_blank">01:01:27.820</a></span> | <span class="t">machine.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3688" target="_blank">01:01:28.820</a></span> | <span class="t">But of course, NVIDIA machine would just come with all the software installed, all the hardware</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3691" target="_blank">01:01:31.780</a></span> | <span class="t">is ready, and you can just do work.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3693" target="_blank">01:01:33.940</a></span> | <span class="t">There are a few GPU offerings in the cloud.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3695" target="_blank">01:01:35.620</a></span> | <span class="t">But unfortunately, it's actually not at a good place right now.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3698" target="_blank">01:01:38.900</a></span> | <span class="t">It's actually quite difficult to get GPUs in the cloud-- good GPUs, at least.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3702" target="_blank">01:01:42.480</a></span> | <span class="t">So Amazon AWS has these grid K5 520s.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3705" target="_blank">01:01:45.920</a></span> | <span class="t">They're not very good GPUs.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3707" target="_blank">01:01:47.640</a></span> | <span class="t">They're not fast.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3708" target="_blank">01:01:48.640</a></span> | <span class="t">They don't have too much memory.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3709" target="_blank">01:01:49.640</a></span> | <span class="t">It's actually kind of a problem.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3711" target="_blank">01:01:51.640</a></span> | <span class="t">Microsoft Azure is coming up with its own offering soon.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3715" target="_blank">01:01:55.400</a></span> | <span class="t">So I think they've announced it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3717" target="_blank">01:01:57.080</a></span> | <span class="t">And it's in some kind of a beta stage, if I remember correctly.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3720" target="_blank">01:02:00.140</a></span> | <span class="t">And so those are powerful GPUs, K80s, that would be available to you.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3723" target="_blank">01:02:03.520</a></span> | <span class="t">At OpenAI, for example, you use Cerescale.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3725" target="_blank">01:02:05.920</a></span> | <span class="t">So Cerescale is a slightly different model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3727" target="_blank">01:02:07.760</a></span> | <span class="t">You can't spin up GPUs on demand.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3729" target="_blank">01:02:09.680</a></span> | <span class="t">But they allow you to rent a box in the cloud.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3731" target="_blank">01:02:11.900</a></span> | <span class="t">So what that amounts to is that we have these boxes somewhere in the cloud.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3734" target="_blank">01:02:14.880</a></span> | <span class="t">I have just the DNN.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3737" target="_blank">01:02:17.240</a></span> | <span class="t">I just have the URL.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3738" target="_blank">01:02:18.240</a></span> | <span class="t">I SSH to it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3739" target="_blank">01:02:19.960</a></span> | <span class="t">It's a Titan X boxes in the machine.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3741" target="_blank">01:02:21.920</a></span> | <span class="t">And so you can just do work that way.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3744" target="_blank">01:02:24.920</a></span> | <span class="t">So these options are available to you hardware-wise.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3747" target="_blank">01:02:27.680</a></span> | <span class="t">In terms of software, there are many different frameworks, of course, that you could use</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3750" target="_blank">01:02:30.720</a></span> | <span class="t">for deep learning.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3752" target="_blank">01:02:32.280</a></span> | <span class="t">So these are some of the more common ones that you might see in practice.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3756" target="_blank">01:02:36.880</a></span> | <span class="t">So different people have different recommendations on this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3760" target="_blank">01:02:40.000</a></span> | <span class="t">My personal recommendation right now to most people, if you just want to apply this in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3763" target="_blank">01:02:43.620</a></span> | <span class="t">practical settings, 90% of the use cases are probably addressable with things like Keras.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3769" target="_blank">01:02:49.300</a></span> | <span class="t">So Keras would be my go-to number one thing to look at.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3773" target="_blank">01:02:53.060</a></span> | <span class="t">Keras is a layer over TensorFlow or Theano.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3778" target="_blank">01:02:58.520</a></span> | <span class="t">And basically, it's just a higher-level API over either of those.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3781" target="_blank">01:03:01.080</a></span> | <span class="t">So for example, I usually use Keras on top of TensorFlow.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3783" target="_blank">01:03:03.840</a></span> | <span class="t">And it's a much more higher-level language than raw TensorFlow.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3788" target="_blank">01:03:08.300</a></span> | <span class="t">So you can also work in raw TensorFlow, but you'll have to do a lot of low-level stuff.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3791" target="_blank">01:03:11.740</a></span> | <span class="t">If you need all that freedom, then that's great, because that allows you to have much</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3794" target="_blank">01:03:14.980</a></span> | <span class="t">more freedom in terms of how you design everything.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3797" target="_blank">01:03:17.260</a></span> | <span class="t">But it can be slightly more wordy.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3799" target="_blank">01:03:19.820</a></span> | <span class="t">For example, you have to assign every single weight.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3801" target="_blank">01:03:21.580</a></span> | <span class="t">You have to assign a name, stuff like that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3804" target="_blank">01:03:24.260</a></span> | <span class="t">And so it's just much more wordy, but you can work at that level.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3807" target="_blank">01:03:27.180</a></span> | <span class="t">Or for most applications, I think Keras would be sufficient.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3809" target="_blank">01:03:29.980</a></span> | <span class="t">And I've used Torch for a long time.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3811" target="_blank">01:03:31.140</a></span> | <span class="t">I still really like Torch.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3812" target="_blank">01:03:32.460</a></span> | <span class="t">It's very lightweight, interpretable.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3814" target="_blank">01:03:34.020</a></span> | <span class="t">It works just fine.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3815" target="_blank">01:03:35.640</a></span> | <span class="t">So those are the options that I would currently consider, at least.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3821" target="_blank">01:03:41.600</a></span> | <span class="t">Another practical consideration-- you might be wondering, what architecture do I use in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3825" target="_blank">01:03:45.660</a></span> | <span class="t">my problem?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3826" target="_blank">01:03:46.660</a></span> | <span class="t">So my answer here-- and I've already hinted at this-- is don't be a hero.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3831" target="_blank">01:03:51.500</a></span> | <span class="t">Don't go crazy.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3832" target="_blank">01:03:52.500</a></span> | <span class="t">Don't design your own neural networks and convolutional layers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3835" target="_blank">01:03:55.160</a></span> | <span class="t">And you don't want to do that, probably.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3838" target="_blank">01:03:58.320</a></span> | <span class="t">So the algorithm is actually very simple.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3840" target="_blank">01:04:00.560</a></span> | <span class="t">Look at whatever is currently the latest released thing that works really well in ILS VRC.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3845" target="_blank">01:04:05.980</a></span> | <span class="t">You download that pre-trained model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3847" target="_blank">01:04:07.920</a></span> | <span class="t">And then you potentially add or delete some layers on top, because you want to do some</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3851" target="_blank">01:04:11.280</a></span> | <span class="t">other task.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3852" target="_blank">01:04:12.280</a></span> | <span class="t">So that usually requires some tinkering at the top or something like that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3855" target="_blank">01:04:15.400</a></span> | <span class="t">And then you fine tune it on your application.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3857" target="_blank">01:04:17.300</a></span> | <span class="t">So actually, a very straightforward process.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3859" target="_blank">01:04:19.880</a></span> | <span class="t">The first degree, I think, to most applications would be don't tinker with it too much.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3863" target="_blank">01:04:23.420</a></span> | <span class="t">You're going to break it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3865" target="_blank">01:04:25.340</a></span> | <span class="t">But of course, you can also take 231n, and then you might become much better at tinkering</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3869" target="_blank">01:04:29.480</a></span> | <span class="t">with these architectures.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3872" target="_blank">01:04:32.120</a></span> | <span class="t">Second is how do I choose the parameters?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3875" target="_blank">01:04:35.680</a></span> | <span class="t">And my answer here, again, would be don't be a hero.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3879" target="_blank">01:04:39.520</a></span> | <span class="t">Look into papers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3880" target="_blank">01:04:40.520</a></span> | <span class="t">Look at what parameters they use.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3881" target="_blank">01:04:41.520</a></span> | <span class="t">For the most part, you'll see that all papers use the same hyperparameters.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3884" target="_blank">01:04:44.360</a></span> | <span class="t">They look very similar.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3885" target="_blank">01:04:45.500</a></span> | <span class="t">So Adam-- when you use Adam for optimization, it's always learning rate 1e negative 3 or</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3889" target="_blank">01:04:49.480</a></span> | <span class="t">1e negative 4.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3892" target="_blank">01:04:52.720</a></span> | <span class="t">So you can also use SGD momentum.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3894" target="_blank">01:04:54.840</a></span> | <span class="t">It's always the similar kinds of learning rates.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3896" target="_blank">01:04:56.720</a></span> | <span class="t">So don't go too crazy designing this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3898" target="_blank">01:04:58.780</a></span> | <span class="t">One of the things you probably want to play with the most is the regularization.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3902" target="_blank">01:05:02.680</a></span> | <span class="t">And in particular, not the L2 regularization, but the dropout rates is something I would</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3906" target="_blank">01:05:06.000</a></span> | <span class="t">advise instead.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3910" target="_blank">01:05:10.000</a></span> | <span class="t">Because you might have a smaller or a much larger data set, if you have a much smaller</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3912" target="_blank">01:05:12.620</a></span> | <span class="t">data set, then overfitting is a concern.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3914" target="_blank">01:05:14.520</a></span> | <span class="t">So you want to make sure that you regularize properly with dropout.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3917" target="_blank">01:05:17.660</a></span> | <span class="t">And then you might want to, as a second degree consideration, maybe learning rate, you want</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3921" target="_blank">01:05:21.720</a></span> | <span class="t">to tune that a tiny bit.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3922" target="_blank">01:05:22.880</a></span> | <span class="t">But that usually doesn't have as much of an effect.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3926" target="_blank">01:05:26.380</a></span> | <span class="t">So really, there's like two hyperparameters.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3928" target="_blank">01:05:28.000</a></span> | <span class="t">And you take a pre-trained network.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3929" target="_blank">01:05:29.000</a></span> | <span class="t">And this is 90% of the use cases, I would say.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3933" target="_blank">01:05:33.840</a></span> | <span class="t">So compared to when-- computer vision in 2011, where you might have hundreds of hyperparameters.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3938" target="_blank">01:05:38.360</a></span> | <span class="t">So yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3942" target="_blank">01:05:42.000</a></span> | <span class="t">And in terms of distributed training, so if you want to work at scale, because if you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3946" target="_blank">01:05:46.920</a></span> | <span class="t">want to train ImageNet or some large scale data sets, you might want to train across</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3949" target="_blank">01:05:49.660</a></span> | <span class="t">multiple GPUs.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3951" target="_blank">01:05:51.120</a></span> | <span class="t">So just to give you an idea, most of these state-of-the-art networks are trained on the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3954" target="_blank">01:05:54.100</a></span> | <span class="t">order of a few weeks across multiple GPUs, usually four or eight GPUs.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3958" target="_blank">01:05:58.920</a></span> | <span class="t">And these GPUs are roughly on the order of $1,000 each.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3961" target="_blank">01:06:01.360</a></span> | <span class="t">But then you also have to house them.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3962" target="_blank">01:06:02.860</a></span> | <span class="t">So of course, that adds additional price.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3964" target="_blank">01:06:04.960</a></span> | <span class="t">But you almost always want to train on multiple GPUs if possible.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3968" target="_blank">01:06:08.460</a></span> | <span class="t">Usually you don't end up training across machines.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3970" target="_blank">01:06:10.380</a></span> | <span class="t">That's much more rare, I think, to train across machines.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3972" target="_blank">01:06:12.820</a></span> | <span class="t">What's much more common is you have a single machine.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3974" target="_blank">01:06:14.460</a></span> | <span class="t">And it has eight Titan Xs or something like that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3976" target="_blank">01:06:16.840</a></span> | <span class="t">And you do distributed training on those eight Titan Xs.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3979" target="_blank">01:06:19.740</a></span> | <span class="t">There are different ways to do distributed training.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3981" target="_blank">01:06:21.520</a></span> | <span class="t">So if you're feeling fancy, you can try to do some model parallelism, where you split</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3986" target="_blank">01:06:26.460</a></span> | <span class="t">your network across multiple GPUs.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3989" target="_blank">01:06:29.440</a></span> | <span class="t">I would instead advise some kind of a data parallelism architecture.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3992" target="_blank">01:06:32.060</a></span> | <span class="t">So usually what you see in practice is you have eight GPUs.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3995" target="_blank">01:06:35.420</a></span> | <span class="t">So I take my batch of 256 images or something like that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3998" target="_blank">01:06:38.660</a></span> | <span class="t">I split it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=3999" target="_blank">01:06:39.660</a></span> | <span class="t">And I split it equally across the GPUs.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4001" target="_blank">01:06:41.500</a></span> | <span class="t">I do forward pass on those GPUs.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4003" target="_blank">01:06:43.420</a></span> | <span class="t">And then I basically just add up all the gradients.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4006" target="_blank">01:06:46.420</a></span> | <span class="t">And I propagate that through.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4007" target="_blank">01:06:47.880</a></span> | <span class="t">So you're just distributing this batch.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4009" target="_blank">01:06:49.420</a></span> | <span class="t">And mathematically, you're doing the exact same thing as if you had a giant GPU.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4013" target="_blank">01:06:53.940</a></span> | <span class="t">But you're just splitting up that batch across different GPUs.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4017" target="_blank">01:06:57.180</a></span> | <span class="t">But you're still doing synchronous training with SGD as normal.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4019" target="_blank">01:06:59.940</a></span> | <span class="t">So that's what you'll see most in practice, which I think is the best thing to do right</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4023" target="_blank">01:07:03.340</a></span> | <span class="t">now for most normal applications.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4027" target="_blank">01:07:07.140</a></span> | <span class="t">And other kind of considerations that sometimes enter that you could maybe worry about is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4031" target="_blank">01:07:11.700</a></span> | <span class="t">that there are these bottlenecks to be aware of.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4033" target="_blank">01:07:13.540</a></span> | <span class="t">So in particular, CPU to disk bottleneck.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4036" target="_blank">01:07:16.100</a></span> | <span class="t">This means that you have a giant data set.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4037" target="_blank">01:07:17.500</a></span> | <span class="t">It's somewhere on some disk.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4038" target="_blank">01:07:18.940</a></span> | <span class="t">You want that disk to probably be an SSD because you want this loading to be quick.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4043" target="_blank">01:07:23.220</a></span> | <span class="t">Because these GPUs process data very quickly.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4044" target="_blank">01:07:24.900</a></span> | <span class="t">And that might actually be a bottleneck.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4046" target="_blank">01:07:26.260</a></span> | <span class="t">Like loading the data could be a bottleneck.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4048" target="_blank">01:07:28.020</a></span> | <span class="t">So in many applications, you might want to pre-process your data, make sure that it's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4051" target="_blank">01:07:31.420</a></span> | <span class="t">read out contiguously in very raw form from something like an HDFI file or some kind of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4056" target="_blank">01:07:36.300</a></span> | <span class="t">other binary format.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4058" target="_blank">01:07:38.180</a></span> | <span class="t">And another bottleneck to be aware of is the CPU-GPU bottleneck.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4061" target="_blank">01:07:41.880</a></span> | <span class="t">So the GPU is doing a lot of heavy lifting of the neural network.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4064" target="_blank">01:07:44.320</a></span> | <span class="t">And the CPU is loading the data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4066" target="_blank">01:07:46.180</a></span> | <span class="t">And you might want to use things like prefetching threads, where the CPU, while the networks</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4070" target="_blank">01:07:50.180</a></span> | <span class="t">are doing forward-backward on the GPU, your CPU is busy loading the data from the disk</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4074" target="_blank">01:07:54.380</a></span> | <span class="t">and maybe doing some pre-processing and making sure that it can ship it off to the GPU at</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4079" target="_blank">01:07:59.100</a></span> | <span class="t">the next time step.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4080" target="_blank">01:08:00.900</a></span> | <span class="t">So those are some of the practical considerations I could come up with for this lecture.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4084" target="_blank">01:08:04.740</a></span> | <span class="t">If you wanted to learn much more about convolutional neural networks and a lot of what I've been</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4087" target="_blank">01:08:07.520</a></span> | <span class="t">talking about, then I encourage you to check out CS231n.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4091" target="_blank">01:08:11.100</a></span> | <span class="t">We have lecture videos available.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4092" target="_blank">01:08:12.940</a></span> | <span class="t">We have notes, slides, and assignments.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4095" target="_blank">01:08:15.020</a></span> | <span class="t">Everything is up and available.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4096" target="_blank">01:08:16.980</a></span> | <span class="t">So you're welcome to check it out.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4099" target="_blank">01:08:19.540</a></span> | <span class="t">And that's it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4100" target="_blank">01:08:20.540</a></span> | <span class="t">Thank you.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4101" target="_blank">01:08:21.540</a></span> | <span class="t">[ Applause ]</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4110" target="_blank">01:08:30.820</a></span> | <span class="t">So I guess I can take some questions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4111" target="_blank">01:08:31.820</a></span> | <span class="t">Yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4112" target="_blank">01:08:32.820</a></span> | <span class="t">[ Inaudible ]</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4133" target="_blank">01:08:53.620</a></span> | <span class="t">Hello?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4134" target="_blank">01:08:54.620</a></span> | <span class="t">Hello.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4135" target="_blank">01:08:55.620</a></span> | <span class="t">Hi.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4136" target="_blank">01:08:56.620</a></span> | <span class="t">I'm Kyle Farr from Lumna.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4138" target="_blank">01:08:58.860</a></span> | <span class="t">I'm using a lot of convolutional nets for genomics.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4141" target="_blank">01:09:01.100</a></span> | <span class="t">One of the problems that we see is that our genomic sequence tends to be arbitrary length.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4146" target="_blank">01:09:06.860</a></span> | <span class="t">So right now we're patterned for a lot of zeros, but we're curious as to what your thoughts</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4150" target="_blank">01:09:10.340</a></span> | <span class="t">are on using CNNs for things of arbitrary size.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4153" target="_blank">01:09:13.980</a></span> | <span class="t">Or we can't just downsample to 277 by 277.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4158" target="_blank">01:09:18.380</a></span> | <span class="t">So is this like a genomic sequence of like ATCG?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4160" target="_blank">01:09:20.660</a></span> | <span class="t">Like that kind of sequence?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4161" target="_blank">01:09:21.660</a></span> | <span class="t">Yeah, exactly.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4162" target="_blank">01:09:22.660</a></span> | <span class="t">Yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4163" target="_blank">01:09:23.660</a></span> | <span class="t">So some of the options would be -- so recurrent neural networks might be a good fit because</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4166" target="_blank">01:09:26.060</a></span> | <span class="t">they allow arbitrarily sized contexts.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4168" target="_blank">01:09:28.980</a></span> | <span class="t">Another option I would say is if you look at the WaveNet paper from DeepMind, they have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4172" target="_blank">01:09:32.900</a></span> | <span class="t">audio and they're using convolutional networks for processing it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4175" target="_blank">01:09:35.740</a></span> | <span class="t">And I would basically adopt that kind of an architecture.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4177" target="_blank">01:09:37.700</a></span> | <span class="t">They have this clever way of doing what's called atros or dilated convolutions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4182" target="_blank">01:09:42.060</a></span> | <span class="t">And so that allows you to capture a lot of context with few layers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4185" target="_blank">01:09:45.600</a></span> | <span class="t">And so that's called dilated convolutions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4187" target="_blank">01:09:47.540</a></span> | <span class="t">And the WaveNet paper has some details.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4189" target="_blank">01:09:49.160</a></span> | <span class="t">And there's an efficient implementation of it that you should be aware of on GitHub.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4191" target="_blank">01:09:51.460</a></span> | <span class="t">And so you might be able to just drag and drop the fast WaveNet code into that application.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4196" target="_blank">01:09:56.100</a></span> | <span class="t">And so you have much larger context, but it's, of course, not infinite context as you might</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4199" target="_blank">01:09:59.260</a></span> | <span class="t">have with a recurrent network.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4200" target="_blank">01:10:00.540</a></span> | <span class="t">Yeah, we're definitely checking those out.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4202" target="_blank">01:10:02.380</a></span> | <span class="t">We also tried RNNs.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4203" target="_blank">01:10:03.580</a></span> | <span class="t">They're quite slow for these things.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4205" target="_blank">01:10:05.780</a></span> | <span class="t">Our main problem is that the genes can be very short or very long, but the whole sequence</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4209" target="_blank">01:10:09.940</a></span> | <span class="t">matters.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4211" target="_blank">01:10:11.420</a></span> | <span class="t">So I think that's one of the challenges that we're looking at with this type of problem.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4215" target="_blank">01:10:15.780</a></span> | <span class="t">Interesting.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4216" target="_blank">01:10:16.780</a></span> | <span class="t">Yeah, so those would be the two options that I would play with, basically.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4219" target="_blank">01:10:19.740</a></span> | <span class="t">I think those are the two that I'm aware of.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4221" target="_blank">01:10:21.940</a></span> | <span class="t">Thank you.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4222" target="_blank">01:10:22.940</a></span> | <span class="t">Thanks for a great lecture.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4229" target="_blank">01:10:29.540</a></span> | <span class="t">So my question is that, is there a clear mathematical or conceptual understanding when people decide</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4234" target="_blank">01:10:34.540</a></span> | <span class="t">how many hidden layers have to be part of their architecture?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4238" target="_blank">01:10:38.540</a></span> | <span class="t">So the answer with a lot of this is there a mathematical understanding will likely be</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4243" target="_blank">01:10:43.300</a></span> | <span class="t">no, because we are in very early phases of just doing a lot of empirical guess and check</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4248" target="_blank">01:10:48.160</a></span> | <span class="t">kind of work.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4249" target="_blank">01:10:49.380</a></span> | <span class="t">And so theory is in some ways lagging behind a bit.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4253" target="_blank">01:10:53.300</a></span> | <span class="t">I would say that with residual networks, you want to have more layers usually works better.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4258" target="_blank">01:10:58.660</a></span> | <span class="t">And so you can take these layers out or you can put them in, and it's just mostly computational</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4262" target="_blank">01:11:02.420</a></span> | <span class="t">consideration of how much can you fit in.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4264" target="_blank">01:11:04.760</a></span> | <span class="t">So our consideration is usually is you have a GPU.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4267" target="_blank">01:11:07.380</a></span> | <span class="t">It has maybe 16 gigs of RAM or 12 gigs of RAM or something.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4270" target="_blank">01:11:10.700</a></span> | <span class="t">I want certain batch size, and I have these considerations, and that upper bounds the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4274" target="_blank">01:11:14.380</a></span> | <span class="t">amount of layers or how big they could be.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4277" target="_blank">01:11:17.340</a></span> | <span class="t">And so I use the biggest thing that fits in my GPU, and that's mostly the way you choose</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4281" target="_blank">01:11:21.460</a></span> | <span class="t">this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4283" target="_blank">01:11:23.120</a></span> | <span class="t">And then you regularize it very strongly.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4284" target="_blank">01:11:24.460</a></span> | <span class="t">So if you have a very small data set, then you might end up with a pretty big network</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4287" target="_blank">01:11:27.500</a></span> | <span class="t">for your data set.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4288" target="_blank">01:11:28.500</a></span> | <span class="t">So you might want to make sure that you are tuning those dropout rates properly, and so</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4291" target="_blank">01:11:31.980</a></span> | <span class="t">you're not overfitting.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4292" target="_blank">01:11:32.980</a></span> | <span class="t">I have a question.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4293" target="_blank">01:11:33.980</a></span> | <span class="t">My understanding is that the recent convolution nets doesn't use pooling layers, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4304" target="_blank">01:11:44.140</a></span> | <span class="t">So the question is, why don't they use pooling layers?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4308" target="_blank">01:11:48.700</a></span> | <span class="t">So is there still a place for pooling?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4312" target="_blank">01:11:52.940</a></span> | <span class="t">Yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4313" target="_blank">01:11:53.940</a></span> | <span class="t">So certainly, so if you saw, for example, the residual network at the end, there was</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4317" target="_blank">01:11:57.540</a></span> | <span class="t">a single pooling layer at the very beginning, but mostly they went away.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4321" target="_blank">01:12:01.100</a></span> | <span class="t">You're right.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4322" target="_blank">01:12:02.100</a></span> | <span class="t">So it took-- I wonder if I can find the slide.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4324" target="_blank">01:12:04.020</a></span> | <span class="t">I wonder if this is a good idea to try to find the slide.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4326" target="_blank">01:12:06.900</a></span> | <span class="t">That's probably-- OK, let me just find this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4332" target="_blank">01:12:12.340</a></span> | <span class="t">Oh, OK.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4333" target="_blank">01:12:13.820</a></span> | <span class="t">So this was the residual network architecture.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4335" target="_blank">01:12:15.700</a></span> | <span class="t">So you see that they do a first conv, and then there's a single pool right there.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4339" target="_blank">01:12:19.820</a></span> | <span class="t">But certainly, the trend has been to throw them away over time.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4342" target="_blank">01:12:22.500</a></span> | <span class="t">And there's a paper also.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4344" target="_blank">01:12:24.020</a></span> | <span class="t">It's called Striving for Simplicity, the All-Convolutional Neural Network.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4347" target="_blank">01:12:27.620</a></span> | <span class="t">And the point in that paper is, look, you can actually do strided convolutions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4351" target="_blank">01:12:31.020</a></span> | <span class="t">You can throw away pooling layers altogether, or it's just as well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4354" target="_blank">01:12:34.300</a></span> | <span class="t">So pooling layers are kind of, I would say, this kind of a bit of a historical vestige</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4357" target="_blank">01:12:37.820</a></span> | <span class="t">of they needed things to be efficient, and they need to control the capacity and down</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4360" target="_blank">01:12:40.860</a></span> | <span class="t">sample things quite a lot.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4363" target="_blank">01:12:43.060</a></span> | <span class="t">And so we're kind of throwing them away over time.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4364" target="_blank">01:12:44.780</a></span> | <span class="t">And yeah, they're not doing anything super useful.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4368" target="_blank">01:12:48.140</a></span> | <span class="t">They're doing this fixed operation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4370" target="_blank">01:12:50.340</a></span> | <span class="t">And you want to learn as much as possible.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4372" target="_blank">01:12:52.420</a></span> | <span class="t">So maybe you don't actually want to get rid of that information.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4375" target="_blank">01:12:55.820</a></span> | <span class="t">So it's always more appealing to-- it's probably more appealing, I would say, to throw them</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4379" target="_blank">01:12:59.220</a></span> | <span class="t">away.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4380" target="_blank">01:13:00.220</a></span> | <span class="t">But you mentioned there is a sort of cognitive or brain analogy that the brain is doing pooling.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4386" target="_blank">01:13:06.620</a></span> | <span class="t">Yeah, so I think that analogy is stretched by a lot.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4389" target="_blank">01:13:09.220</a></span> | <span class="t">So the brain-- I'm not sure if the brain is doing pooling.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4392" target="_blank">01:13:12.220</a></span> | <span class="t">[LAUGHTER]</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4393" target="_blank">01:13:13.220</a></span> | <span class="t">Yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4394" target="_blank">01:13:14.220</a></span> | <span class="t">How about image compression?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4395" target="_blank">01:13:15.220</a></span> | <span class="t">Not for just classification, but the usage of neural networks for image compression.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4396" target="_blank">01:13:16.220</a></span> | <span class="t">Do we have any examples?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4397" target="_blank">01:13:17.220</a></span> | <span class="t">Sorry, I couldn't hear the question.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4398" target="_blank">01:13:18.220</a></span> | <span class="t">Instead of classification for images, can we use the neural networks for image compression?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4411" target="_blank">01:13:31.660</a></span> | <span class="t">Image compression.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4412" target="_blank">01:13:32.660</a></span> | <span class="t">Yeah, I think there's actually really exciting work in this area.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4415" target="_blank">01:13:35.600</a></span> | <span class="t">So one that I'm aware of, for example, is recent work from Google, where they're using</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4419" target="_blank">01:13:39.840</a></span> | <span class="t">convolutional networks and recurrent networks to come up with variably sized codes for images.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4424" target="_blank">01:13:44.760</a></span> | <span class="t">So certainly, a lot of these generative models, I mean, they are very related to compression.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4429" target="_blank">01:13:49.300</a></span> | <span class="t">So definitely a lot of work in the area that I'm excited about.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4432" target="_blank">01:13:52.740</a></span> | <span class="t">Also, for example, super resolution networks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4434" target="_blank">01:13:54.700</a></span> | <span class="t">So you saw the recent acquisition of Magic Pony by Twitter.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4438" target="_blank">01:13:58.940</a></span> | <span class="t">So they were also doing something that basically allows you to compress.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4442" target="_blank">01:14:02.260</a></span> | <span class="t">You can send low resolution streams, because you can upsample it on the client.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4446" target="_blank">01:14:06.380</a></span> | <span class="t">And so a lot of work in that area.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4448" target="_blank">01:14:08.860</a></span> | <span class="t">Yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4449" target="_blank">01:14:09.860</a></span> | <span class="t">I had one question.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4450" target="_blank">01:14:10.860</a></span> | <span class="t">One more, but maybe after you.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4451" target="_blank">01:14:11.860</a></span> | <span class="t">Can you please comment on scalability regarding number of classes?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4458" target="_blank">01:14:18.380</a></span> | <span class="t">So what does it take if we go up to 10,000 or 100,000 classes?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4462" target="_blank">01:14:22.420</a></span> | <span class="t">Yeah, so if you have a lot of classes, then of course, you can grow your softmax, but</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4466" target="_blank">01:14:26.940</a></span> | <span class="t">that becomes inefficient at some point, because you're doing a giant matrix multiply.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4471" target="_blank">01:14:31.100</a></span> | <span class="t">So some of the ways that people are addressing this in practice, I believe, is use of hierarchical</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4475" target="_blank">01:14:35.060</a></span> | <span class="t">softmax and things like that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4477" target="_blank">01:14:37.460</a></span> | <span class="t">So you decompose your classes into groups, and then you kind of predict one group at</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4482" target="_blank">01:14:42.940</a></span> | <span class="t">a time, and you kind of converge that way.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4487" target="_blank">01:14:47.140</a></span> | <span class="t">So I see these papers, but I'm not an expert on exactly how this works.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4491" target="_blank">01:14:51.700</a></span> | <span class="t">But I do know that hierarchical softmax is something that people use in this setting.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4494" target="_blank">01:14:54.740</a></span> | <span class="t">Especially, for example, in language models, this is often used, because you have a huge</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4497" target="_blank">01:14:57.900</a></span> | <span class="t">amount of words, and you still need to predict them somehow.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4500" target="_blank">01:15:00.380</a></span> | <span class="t">And so I believe Tomasz Michalow, for example, he has some papers on using hierarchical softmax</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4504" target="_blank">01:15:04.060</a></span> | <span class="t">in this context.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4506" target="_blank">01:15:06.980</a></span> | <span class="t">Could you talk a little bit about the convolutional functions?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4511" target="_blank">01:15:11.220</a></span> | <span class="t">Like what considerations you should make in selecting the functions that are used in the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4516" target="_blank">01:15:16.100</a></span> | <span class="t">convolutional filters?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4518" target="_blank">01:15:18.180</a></span> | <span class="t">Selecting the functions that are used in the convolutional filters?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4521" target="_blank">01:15:21.640</a></span> | <span class="t">So these filters are just parameters, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4523" target="_blank">01:15:23.320</a></span> | <span class="t">So we train those filters.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4525" target="_blank">01:15:25.100</a></span> | <span class="t">They're just numbers that we train with backpropagation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4529" target="_blank">01:15:29.100</a></span> | <span class="t">Are you talking about the nonlinearities, perhaps?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4530" target="_blank">01:15:30.860</a></span> | <span class="t">Yeah, I'm just wondering about when you're selecting the features, or when you're getting</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4536" target="_blank">01:15:36.340</a></span> | <span class="t">the-- when you're trying to train to understand different features within an image, what are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4541" target="_blank">01:15:41.820</a></span> | <span class="t">those filters actually doing?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4543" target="_blank">01:15:43.580</a></span> | <span class="t">Oh, I see.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4544" target="_blank">01:15:44.580</a></span> | <span class="t">You're talking about understanding exactly what those filters are looking for in the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4547" target="_blank">01:15:47.020</a></span> | <span class="t">image and so on.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4548" target="_blank">01:15:48.020</a></span> | <span class="t">So a lot of interesting work, especially, for example, so Jason Yosinski, he has this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4552" target="_blank">01:15:52.020</a></span> | <span class="t">DeepVist toolbox.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4553" target="_blank">01:15:53.100</a></span> | <span class="t">And I've shown you that you can kind of debug it that way a bit.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4555" target="_blank">01:15:55.740</a></span> | <span class="t">There's an entire lecture that I encourage you to watch in CS231N on visualizing and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4560" target="_blank">01:16:00.020</a></span> | <span class="t">understanding convolutional networks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4562" target="_blank">01:16:02.260</a></span> | <span class="t">So people use things like a deconv or guided backpropagation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4566" target="_blank">01:16:06.420</a></span> | <span class="t">Or you backpropagate to image, and you try to find a stimulus that maximally activates</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4570" target="_blank">01:16:10.340</a></span> | <span class="t">any arbitrary neuron.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4571" target="_blank">01:16:11.740</a></span> | <span class="t">So different ways of probing it, and different ways have been developed.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4575" target="_blank">01:16:15.880</a></span> | <span class="t">And there's a lecture about it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4577" target="_blank">01:16:17.080</a></span> | <span class="t">So I would check that out.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4579" target="_blank">01:16:19.140</a></span> | <span class="t">Great, thanks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4580" target="_blank">01:16:20.140</a></span> | <span class="t">I had a question regarding the size of fine-tuning data set.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4584" target="_blank">01:16:24.940</a></span> | <span class="t">For example, is there a ballpark number if you are trying to do classification?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4590" target="_blank">01:16:30.940</a></span> | <span class="t">How many do you need for fine-tuning it to your sample set?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4596" target="_blank">01:16:36.020</a></span> | <span class="t">So how many data points do you need to get good performance?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4600" target="_blank">01:16:40.100</a></span> | <span class="t">That's the question.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4603" target="_blank">01:16:43.100</a></span> | <span class="t">So this is like the most boring answer, I think.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4606" target="_blank">01:16:46.140</a></span> | <span class="t">Because the more, the better always.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4607" target="_blank">01:16:47.860</a></span> | <span class="t">And it's really hard to say, actually, how many you need.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4612" target="_blank">01:16:52.540</a></span> | <span class="t">So usually one way to look at it is-- one heuristic that people sometimes follow is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4617" target="_blank">01:16:57.100</a></span> | <span class="t">you look at the number of parameters, and you want the number of examples to be on the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4620" target="_blank">01:17:00.220</a></span> | <span class="t">order of number of parameters.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4621" target="_blank">01:17:01.860</a></span> | <span class="t">That's one way people sometimes break it down.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4623" target="_blank">01:17:03.580</a></span> | <span class="t">Even for fine-tuning?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4625" target="_blank">01:17:05.300</a></span> | <span class="t">Because we'll have an ImageNet model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4627" target="_blank">01:17:07.300</a></span> | <span class="t">So I was hoping that most of the things would be taken care of there, and then you're just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4631" target="_blank">01:17:11.260</a></span> | <span class="t">fine-tuning.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4632" target="_blank">01:17:12.260</a></span> | <span class="t">So you might need a lower order.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4633" target="_blank">01:17:13.900</a></span> | <span class="t">I see.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4634" target="_blank">01:17:14.900</a></span> | <span class="t">So when you're saying fine-tuning, are you fine-tuning the whole network, or you're freezing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4637" target="_blank">01:17:17.100</a></span> | <span class="t">some of it, or just the top classifier?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4639" target="_blank">01:17:19.020</a></span> | <span class="t">Just the top classifier.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4640" target="_blank">01:17:20.020</a></span> | <span class="t">Yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4641" target="_blank">01:17:21.020</a></span> | <span class="t">So another way to look at it is you have some number of parameters, and you can estimate</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4643" target="_blank">01:17:23.660</a></span> | <span class="t">the number of bits that you think every parameter has.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4647" target="_blank">01:17:27.280</a></span> | <span class="t">And then you count the number of bits in your data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4649" target="_blank">01:17:29.280</a></span> | <span class="t">So that's the kind of comparisons you would do.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4651" target="_blank">01:17:31.660</a></span> | <span class="t">But really, I have no good answer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4654" target="_blank">01:17:34.460</a></span> | <span class="t">So the more, the better.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4655" target="_blank">01:17:35.460</a></span> | <span class="t">And you have to try, and you have to regularize, and you have to cross-validate that, and you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4658" target="_blank">01:17:38.020</a></span> | <span class="t">have to see what performance you get over time.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4660" target="_blank">01:17:40.940</a></span> | <span class="t">Because it's too task-dependent for me to say something stronger.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4663" target="_blank">01:17:43.580</a></span> | <span class="t">Hi.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4664" target="_blank">01:17:44.580</a></span> | <span class="t">I would like to know how do you think the Covenant will work in the 3D case?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4669" target="_blank">01:17:49.940</a></span> | <span class="t">Like is it just a simple extension of the 2D case, or do we need some extra tweak about</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4675" target="_blank">01:17:55.420</a></span> | <span class="t">it?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4676" target="_blank">01:17:56.420</a></span> | <span class="t">So in the 3D case, so you're talking specifically about, say, videos or some 3D--</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4679" target="_blank">01:17:59.680</a></span> | <span class="t">Actually, I'm talking about the image that has the depth information.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4683" target="_blank">01:18:03.880</a></span> | <span class="t">Oh, I see.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4685" target="_blank">01:18:05.200</a></span> | <span class="t">So say you have like RGBD input and things like that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4687" target="_blank">01:18:07.720</a></span> | <span class="t">Yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4688" target="_blank">01:18:08.720</a></span> | <span class="t">So I'm not too familiar with what people do.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4690" target="_blank">01:18:10.200</a></span> | <span class="t">But I do know, for example, that people try to have-- for example, one thing you can do</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4695" target="_blank">01:18:15.240</a></span> | <span class="t">is just treat it as a fourth channel.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4697" target="_blank">01:18:17.520</a></span> | <span class="t">Or maybe you want a separate ConvNet on top of the depth channel and do some fusion later.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4701" target="_blank">01:18:21.440</a></span> | <span class="t">So I don't know exactly what the state of the art in treating that depth channel is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4704" target="_blank">01:18:24.260</a></span> | <span class="t">right now.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4707" target="_blank">01:18:27.480</a></span> | <span class="t">So I don't know exactly how they do it right now.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4710" target="_blank">01:18:30.080</a></span> | <span class="t">So maybe just one more question.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4712" target="_blank">01:18:32.000</a></span> | <span class="t">Just how do you think the 3D object recognition--</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4714" target="_blank">01:18:34.520</a></span> | <span class="t">3D object?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4715" target="_blank">01:18:35.520</a></span> | <span class="t">Yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4716" target="_blank">01:18:36.520</a></span> | <span class="t">Recognition?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4717" target="_blank">01:18:37.520</a></span> | <span class="t">So what is the output that you'd like?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4719" target="_blank">01:18:39.840</a></span> | <span class="t">The output is still the class probability.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4723" target="_blank">01:18:43.120</a></span> | <span class="t">But we are not treating the 2D image, but the 3D representation of the object.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4727" target="_blank">01:18:47.600</a></span> | <span class="t">I see.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4728" target="_blank">01:18:48.600</a></span> | <span class="t">So do you have a mesh or a point cloud?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4729" target="_blank">01:18:49.600</a></span> | <span class="t">Yeah, a mesh.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4730" target="_blank">01:18:50.600</a></span> | <span class="t">I see.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4731" target="_blank">01:18:51.600</a></span> | <span class="t">Yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4732" target="_blank">01:18:52.940</a></span> | <span class="t">So that's exactly my area, unfortunately.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4734" target="_blank">01:18:54.040</a></span> | <span class="t">But the problem with these meshes and so on is that there's this rotational degree of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4738" target="_blank">01:18:58.440</a></span> | <span class="t">freedom that I'm not sure what people do about, honestly.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4741" target="_blank">01:19:01.680</a></span> | <span class="t">So I'm actually not an expert on this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4745" target="_blank">01:19:05.440</a></span> | <span class="t">So I don't want to comment.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4746" target="_blank">01:19:06.440</a></span> | <span class="t">There are some obvious things you might want to try.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4747" target="_blank">01:19:07.720</a></span> | <span class="t">You might want to plug in all the possible ways you could orient this and then a test</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4751" target="_blank">01:19:11.920</a></span> | <span class="t">time average over them.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4753" target="_blank">01:19:13.120</a></span> | <span class="t">So that would be some of the obvious things to play with.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4754" target="_blank">01:19:14.780</a></span> | <span class="t">But I'm not actually sure what the state of the art is.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4757" target="_blank">01:19:17.600</a></span> | <span class="t">Thank you.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4758" target="_blank">01:19:18.600</a></span> | <span class="t">OK, one more question.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4759" target="_blank">01:19:19.600</a></span> | <span class="t">Go ahead.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4760" target="_blank">01:19:20.600</a></span> | <span class="t">OK.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4761" target="_blank">01:19:21.600</a></span> | <span class="t">So coming back to distributed training, is it possible to do even the classification</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4766" target="_blank">01:19:26.240</a></span> | <span class="t">in a distributed way?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4767" target="_blank">01:19:27.520</a></span> | <span class="t">Or my question is, in the future, can I imagine our cell phones do these things together for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4773" target="_blank">01:19:33.560</a></span> | <span class="t">one inquiry?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4776" target="_blank">01:19:36.640</a></span> | <span class="t">Our cell phones?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4777" target="_blank">01:19:37.640</a></span> | <span class="t">Oh, I see.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4778" target="_blank">01:19:38.640</a></span> | <span class="t">You're trying to get cell phones distributed training.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4780" target="_blank">01:19:40.440</a></span> | <span class="t">Yes, yes.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4781" target="_blank">01:19:41.440</a></span> | <span class="t">A train and also classify for one cell phone.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4782" target="_blank">01:19:42.440</a></span> | <span class="t">That's a radical idea.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4783" target="_blank">01:19:43.440</a></span> | <span class="t">Is there any hope in that?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4784" target="_blank">01:19:44.440</a></span> | <span class="t">Very radical idea.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4787" target="_blank">01:19:47.080</a></span> | <span class="t">So related thoughts I had recently was, so I had come to JS in the browser.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4790" target="_blank">01:19:50.520</a></span> | <span class="t">And I was thinking of basically, this trains networks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4793" target="_blank">01:19:53.920</a></span> | <span class="t">And I was thinking about similar questions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4795" target="_blank">01:19:55.400</a></span> | <span class="t">Because you could imagine shipping this off as an ad equivalent.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4798" target="_blank">01:19:58.600</a></span> | <span class="t">Like people just include this in the JavaScript.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4800" target="_blank">01:20:00.400</a></span> | <span class="t">And then everyone's browsers are kind of like training a small network.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4805" target="_blank">01:20:05.160</a></span> | <span class="t">So I think that's a related question.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4806" target="_blank">01:20:06.160</a></span> | <span class="t">But do you think there's too much communication overhead?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4808" target="_blank">01:20:08.600</a></span> | <span class="t">Or it could be actually really distributed in an efficient way?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4812" target="_blank">01:20:12.160</a></span> | <span class="t">Yes, so the problem with distributing it a lot is actually the stale gradients problem.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4816" target="_blank">01:20:16.960</a></span> | <span class="t">So when you look at some of the papers that Google has put out about distributed training,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4821" target="_blank">01:20:21.320</a></span> | <span class="t">as you look at the number of workers when you do asynchronous SGD, number of workers</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4825" target="_blank">01:20:25.580</a></span> | <span class="t">and the performance improvement you get, it kind of plateaus quite quickly after eight</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4829" target="_blank">01:20:29.400</a></span> | <span class="t">workers or something quite small.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4831" target="_blank">01:20:31.560</a></span> | <span class="t">So I'm not sure if there are ways of dealing with thousands of workers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4835" target="_blank">01:20:35.120</a></span> | <span class="t">The issue is that you have a distributed-- every worker has this specific snapshot of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4839" target="_blank">01:20:39.840</a></span> | <span class="t">the weights that are currently-- you pull from the master.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4845" target="_blank">01:20:45.820</a></span> | <span class="t">And now you have a set of weights that you're using.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4847" target="_blank">01:20:47.640</a></span> | <span class="t">And you do forward, backward.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4848" target="_blank">01:20:48.640</a></span> | <span class="t">And then you send an update.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4850" target="_blank">01:20:50.240</a></span> | <span class="t">But by the time you send an update and you've done your forward, backward, the parameter</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4853" target="_blank">01:20:53.320</a></span> | <span class="t">server has now done lots of updates from thousands of other things.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4857" target="_blank">01:20:57.860</a></span> | <span class="t">And so your gradient is stale.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4859" target="_blank">01:20:59.480</a></span> | <span class="t">You've evaluated it at the wrong and old location.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4862" target="_blank">01:21:02.440</a></span> | <span class="t">And so it's an incorrect direction now.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4865" target="_blank">01:21:05.100</a></span> | <span class="t">And everything breaks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4866" target="_blank">01:21:06.440</a></span> | <span class="t">So that's the challenge.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4867" target="_blank">01:21:07.480</a></span> | <span class="t">And I'm not sure what people are doing about this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4871" target="_blank">01:21:11.440</a></span> | <span class="t">I was wondering about applications of convolutional nets to two inputs at a time.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4877" target="_blank">01:21:17.200</a></span> | <span class="t">So let's say you have two pictures of jigs of puzzles, jigs of pieces.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4881" target="_blank">01:21:21.240</a></span> | <span class="t">And you're trying to figure out if they fit together or whether one object compares to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4886" target="_blank">01:21:26.240</a></span> | <span class="t">the other in a specific way.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4887" target="_blank">01:21:27.480</a></span> | <span class="t">Have you heard of any implementation of this kind?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4889" target="_blank">01:21:29.720</a></span> | <span class="t">Yes.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4890" target="_blank">01:21:30.720</a></span> | <span class="t">So you have two inputs instead of one.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4892" target="_blank">01:21:32.320</a></span> | <span class="t">So the common ways of dealing with that is you put a commnet on each.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4895" target="_blank">01:21:35.120</a></span> | <span class="t">And then you do some kind of a fusion eventually to merge the information.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4898" target="_blank">01:21:38.480</a></span> | <span class="t">Right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4899" target="_blank">01:21:39.480</a></span> | <span class="t">I see.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4900" target="_blank">01:21:40.480</a></span> | <span class="t">And what about for recurring neural networks if you had variable input?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4905" target="_blank">01:21:45.200</a></span> | <span class="t">So for example, in the context of videos where you have frames coming in, then yes, some</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4908" target="_blank">01:21:48.600</a></span> | <span class="t">of the approaches are you have a convolutional network on a frame.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4911" target="_blank">01:21:51.240</a></span> | <span class="t">And then at the top, you tie it in with a recurring neural network.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4914" target="_blank">01:21:54.760</a></span> | <span class="t">So you have these-- you reduce the image to some kind of a lower dimensional representation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4918" target="_blank">01:21:58.920</a></span> | <span class="t">And then that's an input to a recurring neural network at the top.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4922" target="_blank">01:22:02.820</a></span> | <span class="t">There are other ways to play with this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4924" target="_blank">01:22:04.200</a></span> | <span class="t">For example, you can actually make the recurrent-- you can make every single neuron in the commnet</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4927" target="_blank">01:22:07.480</a></span> | <span class="t">recurrent.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4928" target="_blank">01:22:08.480</a></span> | <span class="t">That's also one funny way of doing this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4931" target="_blank">01:22:11.420</a></span> | <span class="t">So right now, when a neuron computes its output, it's only a function of a local neighborhood</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4936" target="_blank">01:22:16.040</a></span> | <span class="t">and below it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4937" target="_blank">01:22:17.880</a></span> | <span class="t">But you can also make it, in addition, a function of that same local neighborhood or its own</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4942" target="_blank">01:22:22.740</a></span> | <span class="t">activation perhaps at the previous time step, if that makes sense.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4947" target="_blank">01:22:27.800</a></span> | <span class="t">So this neuron is not just computing a dot product with the current patch, but it's also</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4951" target="_blank">01:22:31.920</a></span> | <span class="t">incorporating a dot product of its own and maybe its neighborhoods activations at the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4957" target="_blank">01:22:37.280</a></span> | <span class="t">previous time step of the frame.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4958" target="_blank">01:22:38.640</a></span> | <span class="t">So that's kind of like a small RNN update hidden inside every single neuron.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4961" target="_blank">01:22:41.640</a></span> | <span class="t">So those are the things that I think people play with when I'm not familiar with what</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4964" target="_blank">01:22:44.280</a></span> | <span class="t">currently is working best in this area.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4965" target="_blank">01:22:45.920</a></span> | <span class="t">Pretty awesome.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4966" target="_blank">01:22:46.920</a></span> | <span class="t">Thank you.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4967" target="_blank">01:22:47.920</a></span> | <span class="t">Yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4968" target="_blank">01:22:48.920</a></span> | <span class="t">Yeah, hi.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4969" target="_blank">01:22:49.920</a></span> | <span class="t">Thanks for the great talk.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4970" target="_blank">01:22:50.920</a></span> | <span class="t">I have a question regarding the latency for the models that are trained using multiple</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4975" target="_blank">01:22:55.280</a></span> | <span class="t">layers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4976" target="_blank">01:22:56.280</a></span> | <span class="t">So especially at the prediction time, as we add more layers for the forward pass, it will</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4981" target="_blank">01:23:01.200</a></span> | <span class="t">take some time.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4982" target="_blank">01:23:02.200</a></span> | <span class="t">It will increase in the latency for the prediction.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4985" target="_blank">01:23:05.060</a></span> | <span class="t">So what are the numbers that we have seen presently that if you can share the prediction</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4993" target="_blank">01:23:13.440</a></span> | <span class="t">time or the latency at the forward pass?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=4997" target="_blank">01:23:17.520</a></span> | <span class="t">So you're worried, for example, you want to run a prediction very quickly.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=5001" target="_blank">01:23:21.280</a></span> | <span class="t">Would it be on an embedded device, or is this in the cloud?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=5003" target="_blank">01:23:23.920</a></span> | <span class="t">Yeah, suppose it's a cell phone.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=5006" target="_blank">01:23:26.360</a></span> | <span class="t">You're identifying the objects, or you're doing some image analysis or something.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=5013" target="_blank">01:23:33.480</a></span> | <span class="t">Yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=5014" target="_blank">01:23:34.480</a></span> | <span class="t">So there's definitely a lot of work on this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=5015" target="_blank">01:23:35.640</a></span> | <span class="t">So one way you would approach this, actually, is you have this network that you've trained</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=5018" target="_blank">01:23:38.920</a></span> | <span class="t">using floating point arithmetic, 32 bits, say.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=5022" target="_blank">01:23:42.320</a></span> | <span class="t">And so there's a lot of work on taking that network and discretizing all the weights into</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=5027" target="_blank">01:23:47.720</a></span> | <span class="t">like ints and making it much smaller and pruning connections.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=5031" target="_blank">01:23:51.200</a></span> | <span class="t">So one of the works related to this, for example, is Song Han here at Stanford has a few papers</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=5036" target="_blank">01:23:56.200</a></span> | <span class="t">on getting rid of spurious connections and reducing the network as much as possible,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=5040" target="_blank">01:24:00.200</a></span> | <span class="t">and then making everything very efficient with integer arithmetic.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=5043" target="_blank">01:24:03.480</a></span> | <span class="t">So basically, you achieve this by discretizing all the weights and all the activations and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=5050" target="_blank">01:24:10.600</a></span> | <span class="t">throwing away and pruning the network.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=5052" target="_blank">01:24:12.480</a></span> | <span class="t">So there are some tricks like that that people play.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=5055" target="_blank">01:24:15.480</a></span> | <span class="t">That's mostly what you would do on an embedded device.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=5058" target="_blank">01:24:18.280</a></span> | <span class="t">And then the challenge, of course, is you've changed the network, and now you just kind</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=5061" target="_blank">01:24:21.480</a></span> | <span class="t">of are crossing your fingers that it works well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=5063" target="_blank">01:24:23.320</a></span> | <span class="t">And so I think what's interesting from a research standpoint is you'd like your test time to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=5069" target="_blank">01:24:29.080</a></span> | <span class="t">exactly match your training time.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=5071" target="_blank">01:24:31.160</a></span> | <span class="t">So then you get the best performance.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=5072" target="_blank">01:24:32.960</a></span> | <span class="t">And so the question is, how do we train with low precision arithmetic?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=5075" target="_blank">01:24:35.960</a></span> | <span class="t">And there's a lot of work on this as well, so say from Yoshua Bengio's lab as well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=5081" target="_blank">01:24:41.040</a></span> | <span class="t">So that's exciting directions of how you train in a low precision regime.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=5085" target="_blank">01:24:45.080</a></span> | <span class="t">Do you have any numbers that you can share for the state of the art, how much time does</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=5089" target="_blank">01:24:49.800</a></span> | <span class="t">it take?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=5090" target="_blank">01:24:50.800</a></span> | <span class="t">Yes, I see the papers, but I'm not sure if I remember the exact reductions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=5094" target="_blank">01:24:54.600</a></span> | <span class="t">It's on the order of-- OK, I don't want to say, because basically I don't know.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=5098" target="_blank">01:24:58.480</a></span> | <span class="t">I don't want to try to guess this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=5100" target="_blank">01:25:00.520</a></span> | <span class="t">Thank you.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=5101" target="_blank">01:25:01.520</a></span> | <span class="t">All right.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=5102" target="_blank">01:25:02.520</a></span> | <span class="t">So with that, we'll take our time.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=5103" target="_blank">01:25:03.520</a></span> | <span class="t">Let's thank Andre.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=u6aEYuemt0M&t=5104" target="_blank">01:25:04.520</a></span> | <span class="t">Lunch is outside, and we'll restart at 1245.</span></div></div></body></html>