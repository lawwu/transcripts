<html><head><title>Paul Christiano - Preventing an AI Takeover</title>
<style>
    body {
        font-family: Arial, sans-serif;
        margin: 0;
        padding: 0;
        background-color: #f4f4f4;
        color: #333;
    }
    .container {
        width: 95%;  /* Increased width to use more space */
        margin: auto;
        overflow: auto;  /* Added to handle overflow by adding a scrollbar if necessary */
    }
    h2, h3 {
        color: #333;
        text-align: center;
    }
    a {
        color: #0000FF;  /* Traditional blue color for links */
        text-decoration: none;
    }
    a:hover {
        text-decoration: underline;
    }
    img {
        display: block;
        margin: auto;
        max-width: 100%;
    }
    .c {
        margin: 10px 0;
    }
    .s, .t {
        display: inline-block;
        margin-right: 5px;
    }
    .max-width {
        max-width: 800px;
        margin: auto;
        padding-left: 20px;
    }
    table {
        width: 100%;
        border-collapse: collapse;
    }
    th, td {
        border: 1px solid #ddd;
        padding: 8px;
        text-align: left;  /* Ensure text alignment is consistent */
    }
    tr:nth-child(even) {
        background-color: #f2f2f2;
    }
    tr:nth-child(odd) {
        background-color: #e6e6e6;
    }
</style>

    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-69VLBMTTP0"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-69VLBMTTP0');
    </script>
    </head><body><div class='container'><a href="index.html">back to index</a><h2>Paul Christiano - Preventing an AI Takeover</h2><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0"><img src="https://i.ytimg.com/vi/9AAhTLa0dT0/maxresdefault.jpg" style="width:50%;"></a><div><br></div><h3>Chapters</h3><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=0">0:0</a> What do we want post-AGI world to look like?<br><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1465">24:25</a> Timelines<br><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2728">45:28</a> Evolution vs gradient descent<br><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3293">54:53</a> Misalignment and takeover<br><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4643">77:23</a> Is alignment dual-use?<br><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5498">91:38</a> Responsible scaling policies<br><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7105">118:25</a> Paulâ€™s alignment research<br><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9301">155:1</a> Will this revolutionize theoretical CS and math?<br><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9971">166:11</a> How Paul invented RLHF<br><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10510">175:10</a> Disagreements with Carl Shulman<br><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10913">181:53</a> Long TSMC but not NVIDIA<br><br><div style="text-align: left;"><a href="./9AAhTLa0dT0.html">Whisper Transcript</a> | <a href="./transcript_9AAhTLa0dT0.html">Transcript Only Page</a></div><br><div style="max-width: 800px;"><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=0" target="_blank">00:00:00.000</a></span> | <span class="t">Okay, today I have the pleasure of interviewing Paul Christiano, who is the leading AI safety</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6" target="_blank">00:00:06.080</a></span> | <span class="t">researcher. He's the person that labs and governments turn to when they want feedback</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=11" target="_blank">00:00:11.440</a></span> | <span class="t">and advice on their safety plans. He previously led the Language Model Alignment team at OpenAI,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=17" target="_blank">00:00:17.680</a></span> | <span class="t">where he led the invention of RLHF, and now he is the head of the Alignment Research Center,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=24" target="_blank">00:00:24.720</a></span> | <span class="t">and they've been working with the big labs to identify when these models will be too unsafe</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=30" target="_blank">00:00:30.080</a></span> | <span class="t">to keep scaling. Paul, welcome to the podcast. Thanks for having me. Looking forward to talking.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=35" target="_blank">00:00:35.040</a></span> | <span class="t">Okay, so first question, and this is a question I've asked Holden, Ilya, Dario, and none of them</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=40" target="_blank">00:00:40.480</a></span> | <span class="t">have given me a satisfying answer. Give me a concrete sense of what a post-AGI world that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=46" target="_blank">00:00:46.400</a></span> | <span class="t">would be good would look like. Like, how are humans interfacing with the AI? What is the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=51" target="_blank">00:00:51.200</a></span> | <span class="t">economic and political structure? Yeah, I guess this is a tough question for a bunch of reasons.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=56" target="_blank">00:00:56.880</a></span> | <span class="t">Maybe the biggest one is concrete, and I think it's just, if we're talking about really long</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=61" target="_blank">00:01:01.520</a></span> | <span class="t">spans of time, then a lot will change, and it's really hard for someone to talk concretely about</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=66" target="_blank">00:01:06.960</a></span> | <span class="t">what that will look like without saying really silly things. But I can mention some guesses or</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=70" target="_blank">00:01:10.800</a></span> | <span class="t">fill in some parts. I think this is also a question of how good is good. Like, often I'm thinking</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=74" target="_blank">00:01:14.960</a></span> | <span class="t">about worlds that seem like kind of the best achievable outcome or a likely achievable outcome.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=79" target="_blank">00:01:19.920</a></span> | <span class="t">So, I am very often imagining my typical future has sort of continuing economic and military</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=86" target="_blank">00:01:26.720</a></span> | <span class="t">competition amongst groups of humans. I think that competition is increasingly mediated by AI</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=91" target="_blank">00:01:31.280</a></span> | <span class="t">systems. So, for example, if you imagine, right, humans making money, it'll be less and less</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=97" target="_blank">00:01:37.760</a></span> | <span class="t">worthwhile for humans to spend any of their time trying to make money or any of their time trying</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=101" target="_blank">00:01:41.280</a></span> | <span class="t">to fight wars. So, increasingly the world you imagine is one where AI systems are doing those</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=106" target="_blank">00:01:46.880</a></span> | <span class="t">activities on behalf of humans. So, like, I just invest in some index fund, and a bunch of AIs are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=111" target="_blank">00:01:51.120</a></span> | <span class="t">running companies, and those companies are competing with each other, but that is kind of a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=114" target="_blank">00:01:54.800</a></span> | <span class="t">sphere where humans are not really engaging much. The reason I gave this, like, how good is good</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=119" target="_blank">00:01:59.200</a></span> | <span class="t">caveat is, like, it's not clear if this is the world you'd most love. Like, I'm like, yeah,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=122" target="_blank">00:02:02.160</a></span> | <span class="t">the world, and I'm leading with, like, the world still has a lot of war and a lot of economic</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=125" target="_blank">00:02:05.440</a></span> | <span class="t">competition and so on. But maybe what I'm trying to, what I'm most often thinking about is, like,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=129" target="_blank">00:02:09.040</a></span> | <span class="t">how can a world be reasonably good, like, during a long period where those things still exist?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=134" target="_blank">00:02:14.080</a></span> | <span class="t">I think, like, in the very long run, I kind of expect something more like strong world government</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=138" target="_blank">00:02:18.240</a></span> | <span class="t">rather than just this, like, status quo. That's, like, a very long run. I think there's, like,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=142" target="_blank">00:02:22.640</a></span> | <span class="t">a long time left of, like, having a bunch of states and a bunch of different economic powers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=146" target="_blank">00:02:26.400</a></span> | <span class="t">One more government. Why do you think that's the transition that's likely to happen at some point?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=152" target="_blank">00:02:32.000</a></span> | <span class="t">Yeah. So, again, at some point, I'm imagining, or I'm thinking of, like, the very broad sweep</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=156" target="_blank">00:02:36.160</a></span> | <span class="t">of history. I think there are, like, a lot of losses. Like, war is a very costly thing. We</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=160" target="_blank">00:02:40.320</a></span> | <span class="t">would all like to have fewer wars. If you just ask, like, what is humanity's long-term future,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=163" target="_blank">00:02:43.680</a></span> | <span class="t">like, I do expect to drive down the rate of war to very, very low levels eventually. It's sort of,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=169" target="_blank">00:02:49.120</a></span> | <span class="t">like, this kind of technological or socio-technological problem of, like,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=171" target="_blank">00:02:51.920</a></span> | <span class="t">sort of how do you organize society? How do you navigate conflicts in a way that doesn't have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=176" target="_blank">00:02:56.400</a></span> | <span class="t">those kinds of losses? And in the long run, I do expect us to succeed. I expect it to take kind</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=180" target="_blank">00:03:00.800</a></span> | <span class="t">of a long time subjectively. I think an important fact about AI is just, like, doing a lot of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=184" target="_blank">00:03:04.320</a></span> | <span class="t">cognitive work and more quickly getting you to that world more quickly or figuring out how do</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=188" target="_blank">00:03:08.560</a></span> | <span class="t">we set things up that way. Yeah, the way Carl Schulman put it on the podcast is that you would</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=193" target="_blank">00:03:13.120</a></span> | <span class="t">have basically a thousand years of intellectual progress or social progress in a span of a month</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=198" target="_blank">00:03:18.320</a></span> | <span class="t">or whatever when the intelligence explosion happens. More broadly, so the situation where,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=203" target="_blank">00:03:23.680</a></span> | <span class="t">you know, we have these AIs who are managing our hedge funds and managing our factories and so on,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=208" target="_blank">00:03:28.960</a></span> | <span class="t">that seems like something that makes sense when the AI is human level. But when we have superhuman</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=215" target="_blank">00:03:35.680</a></span> | <span class="t">AIs, do we want gods who are enslaved forever? In a hundred years, what is the situation we want?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=223" target="_blank">00:03:43.760</a></span> | <span class="t">So a hundred years is a very, very long time. And maybe starting with the spirit of the question,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=227" target="_blank">00:03:47.920</a></span> | <span class="t">or maybe I have a view which is perhaps less extreme than Carl's view, but still,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=230" target="_blank">00:03:50.800</a></span> | <span class="t">like, a hundred objective years is further ahead than I ever think. I still think I'm</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=236" target="_blank">00:03:56.720</a></span> | <span class="t">describing a world which involves incredibly smart systems running around doing things like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=241" target="_blank">00:04:01.520</a></span> | <span class="t">running companies on behalf of humans and fighting wars on behalf of humans. And you might be like,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=245" target="_blank">00:04:05.280</a></span> | <span class="t">is that the world you really want? Or like, certainly not the first best world, as we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=249" target="_blank">00:04:09.600</a></span> | <span class="t">mentioned a little bit before. I think it is a world that probably is the, of the achievable</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=255" target="_blank">00:04:15.840</a></span> | <span class="t">worlds or like feasible worlds is the one that seems most desirable to me. That is sort of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=260" target="_blank">00:04:20.880</a></span> | <span class="t">decoupling the social transition from this technological transition. So you could say,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=264" target="_blank">00:04:24.320</a></span> | <span class="t">like, we're about to build some AI systems. And like, at the time we build AI systems,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=267" target="_blank">00:04:27.680</a></span> | <span class="t">you would like to have either greatly changed the way world government works, or you would like to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=272" target="_blank">00:04:32.880</a></span> | <span class="t">have sort of humans have to decided, like, we're done, we're passing off the baton to these AI</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=276" target="_blank">00:04:36.880</a></span> | <span class="t">systems. I think that you would like to decouple those timescales. So I think AI development is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=282" target="_blank">00:04:42.560</a></span> | <span class="t">by default, barring some kind of coordination, going to be very fast. So there's not going to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=287" target="_blank">00:04:47.840</a></span> | <span class="t">be a lot of time for humans to think like, Hey, what do we want if we're building the next</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=290" target="_blank">00:04:50.960</a></span> | <span class="t">generation instead of just raising it the normal way? Like, what do we want that to look like?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=294" target="_blank">00:04:54.400</a></span> | <span class="t">I think that's like a crazy hard kind of collective decision that humans naturally</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=298" target="_blank">00:04:58.400</a></span> | <span class="t">want to cope with over like a bunch of generations. And the construction of AI is this very fast</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=303" target="_blank">00:05:03.440</a></span> | <span class="t">technological process happening over years. So I don't think you want to say like, by the time</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=307" target="_blank">00:05:07.200</a></span> | <span class="t">we have finished this technological progress, we will have made a decision about like the next</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=310" target="_blank">00:05:10.640</a></span> | <span class="t">species we're going to build and replace ourselves with. I think the world we want to be in is one</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=314" target="_blank">00:05:14.880</a></span> | <span class="t">where we say like, either we are able to build the technology in a way that doesn't force us</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=318" target="_blank">00:05:18.640</a></span> | <span class="t">to have made those decisions, which probably means it's a kind of AI system that we're happy,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=322" target="_blank">00:05:22.240</a></span> | <span class="t">like delegating, fighting a war, running a company to, or if we're not able to do that,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=326" target="_blank">00:05:26.320</a></span> | <span class="t">then I really think you should not be doing, you shouldn't have been building that technology.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=330" target="_blank">00:05:30.240</a></span> | <span class="t">If you're like, the only way you can cope with AI is being ready to hand off the world to some AI</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=333" target="_blank">00:05:33.440</a></span> | <span class="t">system you built. I think it's very unlikely we're going to be sort of ready to do that on the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=337" target="_blank">00:05:37.360</a></span> | <span class="t">timelines that the technology would naturally dictate. - Say we're in the situation in which</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=341" target="_blank">00:05:41.440</a></span> | <span class="t">we're happy with the thing, what would it look like for us to say we're ready to hand off the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=345" target="_blank">00:05:45.360</a></span> | <span class="t">baton? Like what would make you satisfied? And the reason it's relevant to ask you is because</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=350" target="_blank">00:05:50.800</a></span> | <span class="t">you're on Anthropx, a long-term benefit trust, and you'll choose like the majority of the board</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=355" target="_blank">00:05:55.360</a></span> | <span class="t">members on, in the long run, at Anthropx. These will presumably be the people who decide if</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=361" target="_blank">00:06:01.680</a></span> | <span class="t">Anthropx gets AI first, you know, what the AI ends up doing. So what is the version of that,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=366" target="_blank">00:06:06.720</a></span> | <span class="t">that you would be happy with? - My main high-level take here is that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=371" target="_blank">00:06:11.120</a></span> | <span class="t">I would be unhappy about a world where like Anthropx just makes some call and Anthropx is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=375" target="_blank">00:06:15.920</a></span> | <span class="t">like, here's the kind of AI, like we've seen enough, we're ready to hand off the future to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=379" target="_blank">00:06:19.120</a></span> | <span class="t">this kind of AI. So like procedurally, I think it's like not a decision that kind of I want to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=383" target="_blank">00:06:23.760</a></span> | <span class="t">be making personally, or I want Anthropx to be making. So I kind of think from the perspective</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=388" target="_blank">00:06:28.240</a></span> | <span class="t">of that decision-making or those challenges, the answer is pretty much always going to be like,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=392" target="_blank">00:06:32.080</a></span> | <span class="t">we are not collectively ready because we're sort of not even all collectively engaged in this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=396" target="_blank">00:06:36.080</a></span> | <span class="t">process. I think from the perspective of an AI company, you kind of don't have this like fast</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=400" target="_blank">00:06:40.720</a></span> | <span class="t">handoff option. You kind of have to be doing the like option value, like to build the technology</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=405" target="_blank">00:06:45.600</a></span> | <span class="t">in a way that doesn't like lock humanity into one course path. So this isn't answering your</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=410" target="_blank">00:06:50.640</a></span> | <span class="t">full question, but this is answering the part that I think is most relevant to governance</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=414" target="_blank">00:06:54.080</a></span> | <span class="t">questions for Anthropx. - You don't have to speak on behalf of Anthropx. I'm not asking</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=417" target="_blank">00:06:57.760</a></span> | <span class="t">about the process by which we would as a civilization agree to hand off. I'm just saying,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=422" target="_blank">00:07:02.960</a></span> | <span class="t">okay, I personally, it's hard for me to imagine in a hundred years that these things are still</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=427" target="_blank">00:07:07.920</a></span> | <span class="t">our slaves. And if they are, I think that's not the best world. So at some point we're handing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=432" target="_blank">00:07:12.960</a></span> | <span class="t">off the baton. Like what is that, where would you be satisfied with, this is an arrangement</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=437" target="_blank">00:07:17.280</a></span> | <span class="t">between the humans and AI's where I'm happy to let the rest of the universe or less, uh,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=442" target="_blank">00:07:22.080</a></span> | <span class="t">the rest of time play out. - I think that it is unlikely that in a hundred years I would be happy</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=448" target="_blank">00:07:28.080</a></span> | <span class="t">with anything that was like, you had some humans, you're just going to throw away the humans and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=451" target="_blank">00:07:31.280</a></span> | <span class="t">like start afresh with these machines you built. That is, I think you probably need subjectively</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=455" target="_blank">00:07:35.120</a></span> | <span class="t">longer than that before I or most people are like, okay, we understand what's up for grabs here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=459" target="_blank">00:07:39.360</a></span> | <span class="t">So if you talk about a hundred years, I kind of do, you know, there's a process that I kind</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=463" target="_blank">00:07:43.120</a></span> | <span class="t">of understand in like a process of like, you have some humans, the humans are like talking and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=467" target="_blank">00:07:47.680</a></span> | <span class="t">thinking and deliberating together. The humans are having kids and raising kids. And like one</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=471" target="_blank">00:07:51.680</a></span> | <span class="t">generation comes after the next. There's that process we kind of understand. And we have a lot</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=475" target="_blank">00:07:55.360</a></span> | <span class="t">of views about what makes it go well or poorly. And we can try and like improve that process and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=478" target="_blank">00:07:58.880</a></span> | <span class="t">have the next generation do it better than the previous generation. I think there's some like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=482" target="_blank">00:08:02.320</a></span> | <span class="t">story like that, that I get and that I like. And then I think that like the default paths to be</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=486" target="_blank">00:08:06.800</a></span> | <span class="t">comfortable with something very different. It's kind of more like just run that story for a long</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=490" target="_blank">00:08:10.080</a></span> | <span class="t">time, like have more time for humans to sit around and think a lot and conclude here's what we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=494" target="_blank">00:08:14.720</a></span> | <span class="t">actually want, or a lot of long time for us to talk to each other or to grow up with this new</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=498" target="_blank">00:08:18.960</a></span> | <span class="t">technology and live in that world for our whole lives and so on. And so like, I'm mostly thinking</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=503" target="_blank">00:08:23.600</a></span> | <span class="t">from the perspective of these more like local changes of saying not like, what is the world</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=508" target="_blank">00:08:28.160</a></span> | <span class="t">that I want? Like, what's the crazy world, the kind of crazy I'd be happy handing off to more</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=511" target="_blank">00:08:31.680</a></span> | <span class="t">just like, in what way do I wish like we right now we're different? Like, how could we all be a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=514" target="_blank">00:08:34.880</a></span> | <span class="t">little bit better? And then if we were a little bit better than they would ask, like, okay, how</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=517" target="_blank">00:08:37.920</a></span> | <span class="t">could we all be a little bit better? And I think that like, it's hard to make the giant jump rather</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=522" target="_blank">00:08:42.000</a></span> | <span class="t">than to say like, what's the like local change that would cause me to think our decisions are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=525" target="_blank">00:08:45.120</a></span> | <span class="t">better. Okay. So then let's talk about the transition period in which we were doing all</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=530" target="_blank">00:08:50.000</a></span> | <span class="t">this thinking. What should that period look like? Because you can't have this scenario where</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=534" target="_blank">00:08:54.480</a></span> | <span class="t">everybody has access to the most advanced capabilities and can, you know, kill off all</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=538" target="_blank">00:08:58.400</a></span> | <span class="t">the humans with a new bioweapon. At the same time, I guess you wouldn't want too much concentration.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=543" target="_blank">00:09:03.040</a></span> | <span class="t">You wouldn't want just one agent having AI this entire time. So what is the arrangement of this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=549" target="_blank">00:09:09.360</a></span> | <span class="t">period of reflection that you'd be happy with? I guess there's two aspects of that that seem</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=553" target="_blank">00:09:13.600</a></span> | <span class="t">particularly challenging, or there's a bunch of aspects that are challenging. All of these</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=557" target="_blank">00:09:17.760</a></span> | <span class="t">are things that I personally like, I just think about my one little slice of this problem in my,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=562" target="_blank">00:09:22.160</a></span> | <span class="t">in my day job. So here I am speculating, but so one question is what kind of access to AI is both</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=567" target="_blank">00:09:27.920</a></span> | <span class="t">compatible with the kinds of improvements you'd like. So do you want a lot of people to be able</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=571" target="_blank">00:09:31.680</a></span> | <span class="t">to use AI to like better understand what's true or like relieve material suffering, things like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=576" target="_blank">00:09:36.320</a></span> | <span class="t">this, and also compatible with not all killing each other immediately? I think sort of the defaults</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=584" target="_blank">00:09:44.240</a></span> | <span class="t">or like my best, the simplest option there is to say like, there are certain kinds of technology</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=589" target="_blank">00:09:49.360</a></span> | <span class="t">or certain kinds of action where like destruction is easier than defense. So for example, in the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=594" target="_blank">00:09:54.400</a></span> | <span class="t">world of today, it seems like, you know, maybe this is true with physical explosives. Maybe this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=598" target="_blank">00:09:58.320</a></span> | <span class="t">is true with biological weapons. Maybe this is true with just getting a gun and shooting people.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=601" target="_blank">00:10:01.680</a></span> | <span class="t">Like there's a lot of ways in which it's just kind of easy to cause a lot of harm and there's not</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=604" target="_blank">00:10:04.880</a></span> | <span class="t">very good protective measures. So I think the easiest path is to say like, we're going to think</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=608" target="_blank">00:10:08.560</a></span> | <span class="t">about those. We're going to think about particular ways in which destruction is easy and try and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=611" target="_blank">00:10:11.760</a></span> | <span class="t">either control access to the kinds of physical resources that are needed to cause that harm.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=617" target="_blank">00:10:17.920</a></span> | <span class="t">So for example, you can imagine the world where like an individual actually just can't, even</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=621" target="_blank">00:10:21.440</a></span> | <span class="t">though they're rich enough to, can't like control their own factory that can make tanks. You say</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=624" target="_blank">00:10:24.480</a></span> | <span class="t">like, look, as a matter of policy, sort of access to industry is somewhat restricted or somewhat</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=628" target="_blank">00:10:28.960</a></span> | <span class="t">regulated. Even though again, right now it can be mostly regulated just because like most people</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=632" target="_blank">00:10:32.400</a></span> | <span class="t">aren't rich enough that they could even go off and just build a thousand tanks. You live in the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=635" target="_blank">00:10:35.200</a></span> | <span class="t">future where people actually are so rich. Like you need to say like, that's just not a thing you're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=638" target="_blank">00:10:38.720</a></span> | <span class="t">allowed to do, which to a significant extent is already true. And you can expand the range of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=643" target="_blank">00:10:43.280</a></span> | <span class="t">domains where that's true. And then you could also hope to intervene on like actual provision of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=648" target="_blank">00:10:48.560</a></span> | <span class="t">information. Or like if people are using their AI, you might say like, look, we care about what</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=651" target="_blank">00:10:51.440</a></span> | <span class="t">kinds of interactions with AI, what kind of information people are getting from AI. So even</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=655" target="_blank">00:10:55.200</a></span> | <span class="t">if for the most part, people are pretty free to use AI, to delegate tasks to AI agents, to consult</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=659" target="_blank">00:10:59.680</a></span> | <span class="t">AI advisors, we still have some legal limitations on how people use AI. So again, don't ask your AI</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=666" target="_blank">00:11:06.960</a></span> | <span class="t">how to, how to cause terrible damage. I think there, some of these are kind of easy. So in the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=672" target="_blank">00:11:12.080</a></span> | <span class="t">case of like, you know, don't ask your AI how you could murder a million people, it's not such a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=676" target="_blank">00:11:16.000</a></span> | <span class="t">hard, like legal requirement. I think some things are a lot more subtle and messy. Like a lot of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=680" target="_blank">00:11:20.960</a></span> | <span class="t">domains, if you're talking about like influencing people or like running misinformation campaigns</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=687" target="_blank">00:11:27.360</a></span> | <span class="t">or whatever, then I think you get into like a much messier line between the kinds of things people</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=691" target="_blank">00:11:31.840</a></span> | <span class="t">want to do and the kinds of things you might be uncomfortable with them doing. Probably I think</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=695" target="_blank">00:11:35.280</a></span> | <span class="t">most about persuasion as a thing, like in that messy line where there's like ways in which it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=700" target="_blank">00:11:40.240</a></span> | <span class="t">may just be rough or the world may be like kind of messy. If you have a bunch of people trying to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=703" target="_blank">00:11:43.760</a></span> | <span class="t">live their lives and interacting with other humans who have really good advisors, helping them run</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=709" target="_blank">00:11:49.280</a></span> | <span class="t">persuasion campaigns or whatever. But anyway, I think for the most part, like the default remedy</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=713" target="_blank">00:11:53.920</a></span> | <span class="t">is think about particular harms, have legal protections, either in the use of physical</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=718" target="_blank">00:11:58.480</a></span> | <span class="t">technologies that are relevant or in access to advice or whatever else to protect against those</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=723" target="_blank">00:12:03.520</a></span> | <span class="t">harms. And like that regime won't work forever. Like at some point, like the, you know, the set</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=727" target="_blank">00:12:07.760</a></span> | <span class="t">of harms grows and the set of unanticipated harms grows. But I think that regime might last like a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=731" target="_blank">00:12:11.840</a></span> | <span class="t">very long time. Does that regime have to be global? I guess, but initially it can be only in the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=737" target="_blank">00:12:17.840</a></span> | <span class="t">countries in which there is AI or advanced AI, but presumably that'll proliferate. So does that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=743" target="_blank">00:12:23.280</a></span> | <span class="t">regime have to be global? Again, it's like easy to make some destructive technology. You want to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=747" target="_blank">00:12:27.360</a></span> | <span class="t">regulate access to that technology because it could be used to either for terrorism or even</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=751" target="_blank">00:12:31.520</a></span> | <span class="t">when fighting a war in a way that's destructive. I think ultimately those have to be international</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=755" target="_blank">00:12:35.200</a></span> | <span class="t">agreements and you might hope they're made like more danger by danger, but you might also make</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=759" target="_blank">00:12:39.280</a></span> | <span class="t">them in a very broad way with respect to AI. If you think AI is opening up, like I think the key</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=763" target="_blank">00:12:43.280</a></span> | <span class="t">role of AI here is it's opening up like a lot of new harms, like in a very, you know, one after</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=767" target="_blank">00:12:47.840</a></span> | <span class="t">another or very rapidly in calendar time. And so you might want to target AI in particular, rather</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=773" target="_blank">00:12:53.280</a></span> | <span class="t">than going physical technology by physical technology. There's like two open debates that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=779" target="_blank">00:12:59.760</a></span> | <span class="t">one might be concerned about here. One is about how much people's access to AI should be limited.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=785" target="_blank">00:13:05.440</a></span> | <span class="t">And, you know, here there's like old questions about free speech versus causing chaos and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=791" target="_blank">00:13:11.600</a></span> | <span class="t">limiting access to harms. But there's another issue, which is the control of the AIs themselves,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=799" target="_blank">00:13:19.360</a></span> | <span class="t">where now nobody's concerned that we're infringing on GPT-4's moral rights. But as</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=803" target="_blank">00:13:23.360</a></span> | <span class="t">these things get smarter, the level of control, which we want via the strong guarantees of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=809" target="_blank">00:13:29.680</a></span> | <span class="t">alignment to not only be able to read their minds, but to be able to modify them in these really</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=814" target="_blank">00:13:34.240</a></span> | <span class="t">precise ways, is beyond totalitarian if we were doing that to other humans. As an alignment</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=819" target="_blank">00:13:39.600</a></span> | <span class="t">researcher, like what are your thoughts on this? Are you concerned that as these things get smarter</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=822" target="_blank">00:13:42.880</a></span> | <span class="t">and smarter, what we're doing is not, it doesn't seem kosher? There is a significant chance we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=829" target="_blank">00:13:49.520</a></span> | <span class="t">will eventually have AI systems for which it's like a really big deal to mistreat them. I think</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=833" target="_blank">00:13:53.680</a></span> | <span class="t">like no one really has that good a grip on when that happens. I think people are like really</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=838" target="_blank">00:13:58.080</a></span> | <span class="t">dismissive of that being the case now. But I think I would be completely in the dark enough that it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=843" target="_blank">00:14:03.440</a></span> | <span class="t">wouldn't even be that dismissive of it being the case now. I think one first point worth making is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=848" target="_blank">00:14:08.400</a></span> | <span class="t">I don't know if alignment makes the situation worse rather than better. So if you like consider</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=853" target="_blank">00:14:13.680</a></span> | <span class="t">the world, if you think that like, you know, GPT-4 is a person you should treat well and you're like,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=858" target="_blank">00:14:18.640</a></span> | <span class="t">well, here's how we're going to organize our society. Just like there are billions of copies</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=863" target="_blank">00:14:23.040</a></span> | <span class="t">of GPT-4 and they just do things humans want and can't hold property. And like, whenever they do</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=867" target="_blank">00:14:27.200</a></span> | <span class="t">things that the humans don't like, then we like mess with them until they stop doing that. Like,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=872" target="_blank">00:14:32.960</a></span> | <span class="t">I think that's a rough world regardless of how good you are at alignment. And I think in the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=877" target="_blank">00:14:37.920</a></span> | <span class="t">context of that kind of default plan, like if you've got a trajectory, the world is on right</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=881" target="_blank">00:14:41.520</a></span> | <span class="t">now, which I think this would alone be a reason not to love that trajectory. But if you view that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=886" target="_blank">00:14:46.000</a></span> | <span class="t">as like the trajectory we're on right now, I think like, it's not great. Understanding the systems</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=891" target="_blank">00:14:51.200</a></span> | <span class="t">you build, understanding how to control how the systems work, et cetera, is probably on balance</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=895" target="_blank">00:14:55.760</a></span> | <span class="t">good for avoiding like a really bad situation. You would really love to understand if you've</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=900" target="_blank">00:15:00.000</a></span> | <span class="t">built systems, like if you had a system which like resents the fact that it's interacting with</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=903" target="_blank">00:15:03.120</a></span> | <span class="t">humans in this way. Like this is the kind of thing where like that is both kind of horrifying from a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=907" target="_blank">00:15:07.840</a></span> | <span class="t">safety perspective and also a moral perspective. Like everyone should be very unhappy if you've</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=912" target="_blank">00:15:12.480</a></span> | <span class="t">built a bunch of AIs who are like, I really hate these humans, but they will like murder me if I</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=916" target="_blank">00:15:16.160</a></span> | <span class="t">don't do what they want. And so like, that's just not a good case. And so if you're doing research</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=919" target="_blank">00:15:19.600</a></span> | <span class="t">to try and understand whether that's like how your AI feels, that was probably good. Like I would</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=923" target="_blank">00:15:23.840</a></span> | <span class="t">guess that will on average decrease the, that the main effect of that will be to avoid building that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=927" target="_blank">00:15:27.840</a></span> | <span class="t">kind of AI. And just like, it's an important thing to know. I think like everyone should like to know</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=932" target="_blank">00:15:32.640</a></span> | <span class="t">if that's how the AIs you build feel. Right. Or that, that seems more instrumental as in,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=938" target="_blank">00:15:38.080</a></span> | <span class="t">yeah, we don't want to cause some sort of revolution because of the control we're asking</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=943" target="_blank">00:15:43.280</a></span> | <span class="t">for. But forget about the instrumental way in which this might harm safety. One way to ask</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=949" target="_blank">00:15:49.040</a></span> | <span class="t">this question is if you look through history, there's been all kinds of different ideologies</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=954" target="_blank">00:15:54.080</a></span> | <span class="t">and reasons why it's, it's very dangerous to have infidels or kind of revolutionaries or race</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=962" target="_blank">00:16:02.160</a></span> | <span class="t">traitors or whatever doing various things in society. And obviously we're in a completely</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=967" target="_blank">00:16:07.040</a></span> | <span class="t">different transition in society. So not all historical cases are analogous, but it seems</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=972" target="_blank">00:16:12.000</a></span> | <span class="t">like the Lindy philosophy, if you were alive any other time is just be humanitarian and enlightened</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=977" target="_blank">00:16:17.520</a></span> | <span class="t">towards intelligent, conscious beings. If society as a whole, we're asking for this level of control</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=982" target="_blank">00:16:22.640</a></span> | <span class="t">of other humans, or even if AIs were wanted this level of control about other AIs, we'd be pretty</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=988" target="_blank">00:16:28.400</a></span> | <span class="t">concerned about this. So how should we just think about, yeah, the issues come that come up here as</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=993" target="_blank">00:16:33.680</a></span> | <span class="t">these things get smarter. So I think there's a huge question about like what is happening inside</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=998" target="_blank">00:16:38.080</a></span> | <span class="t">of a model that you want to use. And if you're in the world where it's reasonable to think of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1002" target="_blank">00:16:42.320</a></span> | <span class="t">like GPT-4 as just like, here are some heuristics that are running and there's like no one at home</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1006" target="_blank">00:16:46.960</a></span> | <span class="t">or whatever, then you can kind of think of this thing as like, here's a tool that we're building.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1011" target="_blank">00:16:51.120</a></span> | <span class="t">That's going to help humans do some stuff. And I think if you're in that world, it makes sense</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1014" target="_blank">00:16:54.560</a></span> | <span class="t">to kind of be an organization, like an AI company building tools that you're going to give to humans.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1019" target="_blank">00:16:59.680</a></span> | <span class="t">I think there's a very different world, which like, I think probably ultimately end up in,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1023" target="_blank">00:17:03.120</a></span> | <span class="t">if you keep training AI systems in the way we do right now, which is like, it's just totally</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1027" target="_blank">00:17:07.440</a></span> | <span class="t">inappropriate to think of the system as a tool that you're building and can help humans do things,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1031" target="_blank">00:17:11.360</a></span> | <span class="t">both from a safety perspective and from a, like, that's kind of a horrifying way to organize a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1034" target="_blank">00:17:14.960</a></span> | <span class="t">society perspective. And I think like, if you're in that world, I really think you shouldn't be</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1041" target="_blank">00:17:21.280</a></span> | <span class="t">like, it's just the, the way tech companies are organized is like not an appropriate way to relate</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1046" target="_blank">00:17:26.880</a></span> | <span class="t">to a technology that works that way. Like, it's not reasonable to be like, Hey, we're going to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1049" target="_blank">00:17:29.840</a></span> | <span class="t">build a new species of minds. And like, we're going to try and make a bunch of money from it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1054" target="_blank">00:17:34.800</a></span> | <span class="t">And like, Google's just like thinking about that and then like running their business plan for the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1058" target="_blank">00:17:38.080</a></span> | <span class="t">quarter or something. Yeah. My basic view is like, there's a really plausible world where it's sort</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1064" target="_blank">00:17:44.320</a></span> | <span class="t">of problematic to try and build a bunch of AI systems and use them as tools. And the thing I</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1068" target="_blank">00:17:48.160</a></span> | <span class="t">really want to do in that world is just like not try and build a ton of AI systems to make money</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1072" target="_blank">00:17:52.480</a></span> | <span class="t">from them. Right. And I think that like the worlds that are worst, yeah, probably like the single</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1079" target="_blank">00:17:59.680</a></span> | <span class="t">world I most dislike here is the one where people say like, on the one hand, like there's sort of a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1085" target="_blank">00:18:05.440</a></span> | <span class="t">contradiction in this position, but I think it's a position that might end up being endorsed</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1089" target="_blank">00:18:09.040</a></span> | <span class="t">sometimes, which is like, on the one hand, these AI systems are their own people, so you should</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1092" target="_blank">00:18:12.560</a></span> | <span class="t">let them do their thing. But on the other hand, like our business plan is to like make a bunch</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1096" target="_blank">00:18:16.000</a></span> | <span class="t">of AI systems and then like try and run this like crazy slave trade where we make a bunch of money</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1100" target="_blank">00:18:20.320</a></span> | <span class="t">from them. I think that's like not a good world. And so if you're like, yeah, I think it's better</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1106" target="_blank">00:18:26.240</a></span> | <span class="t">to not make the technology or wait until you like understand whether that's the shape of the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1109" target="_blank">00:18:29.440</a></span> | <span class="t">technology or until you have a different way to build. Like, I think there's no contradiction in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1113" target="_blank">00:18:33.680</a></span> | <span class="t">principle to building like cognitive tools that help humans do things without themselves being</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1117" target="_blank">00:18:37.840</a></span> | <span class="t">like moral entities. That's like what you would prefer to do. You'd prefer to build a thing that's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1121" target="_blank">00:18:41.920</a></span> | <span class="t">like, you know, like the calculator that helps humans understand what's true without itself being</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1126" target="_blank">00:18:46.000</a></span> | <span class="t">like a moral patient or itself being a thing where you'd look back in retrospect and be like, wow,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1130" target="_blank">00:18:50.320</a></span> | <span class="t">that was horrifying mistreatment. That's like the best path. And like to the extent that you're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1134" target="_blank">00:18:54.880</a></span> | <span class="t">ignorant about whether that's the path you're on and you're like, actually, maybe this was a moral</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1137" target="_blank">00:18:57.920</a></span> | <span class="t">atrocity. I really think like plan A is to stop building such AI systems until you understand</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1144" target="_blank">00:19:04.480</a></span> | <span class="t">what you're doing. That is, I think that there's a middle route you could take, which I think is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1148" target="_blank">00:19:08.560</a></span> | <span class="t">pretty bad, which is where you say like, well, they might be persons. And if they're persons,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1152" target="_blank">00:19:12.080</a></span> | <span class="t">we don't want to like be too down on them, but we're still going to like build vast numbers in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1156" target="_blank">00:19:16.800</a></span> | <span class="t">our efforts to make like a trillion dollars or something. Yeah. Or there's this other question</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1162" target="_blank">00:19:22.080</a></span> | <span class="t">of the immorality or the dangers of just replicating a whole bunch of slaves that are,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1168" target="_blank">00:19:28.160</a></span> | <span class="t">have minds. There's also this other question of trying to align entities that have their own</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1175" target="_blank">00:19:35.440</a></span> | <span class="t">minds. And what is the point in which you're just ensuring safety? I mean, this is the alien</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1179" target="_blank">00:19:39.840</a></span> | <span class="t">species. You want to make sure it's not going crazy to the point, I guess, is there some</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1184" target="_blank">00:19:44.240</a></span> | <span class="t">boundary where you would say, I feel uncomfortable having this level of control over an intelligent</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1190" target="_blank">00:19:50.480</a></span> | <span class="t">being, not for the sake of making money, but even just to align them with human preferences.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1194" target="_blank">00:19:54.240</a></span> | <span class="t">Yeah. To be clear, my objection here is not that Google is making money. My objection is that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1199" target="_blank">00:19:59.200</a></span> | <span class="t">you're like creating this creature, like what are they going to do? They're going to help humans</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1201" target="_blank">00:20:01.840</a></span> | <span class="t">get a bunch of stuff and like humans paying for it or whatever, it's sort of equally problematic.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1205" target="_blank">00:20:05.920</a></span> | <span class="t">You could like, imagine splitting alignment, like different alignment work relates to this in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1209" target="_blank">00:20:09.840</a></span> | <span class="t">different ways. Like, so the purpose of some alignment work, like the alignment work I work</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1212" target="_blank">00:20:12.960</a></span> | <span class="t">on is mostly aimed at the like, don't produce AI systems that are like people who want things,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1218" target="_blank">00:20:18.320</a></span> | <span class="t">who are just like scheming about like, maybe I should help these humans because that's like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1222" target="_blank">00:20:22.320</a></span> | <span class="t">instrumentally useful or whatever. You would like to not build such systems as like plan A.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1226" target="_blank">00:20:26.480</a></span> | <span class="t">There's like a second stream of alignment work that's like, well, look, let's just assume the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1230" target="_blank">00:20:30.000</a></span> | <span class="t">worst and imagine that these AI systems like would prefer murder us if they could. Like,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1233" target="_blank">00:20:33.680</a></span> | <span class="t">how do we structure, how do we use AI systems without like exposing ourselves to like risk of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1237" target="_blank">00:20:37.440</a></span> | <span class="t">robot rebellion? I think in the second category, I do feel, yeah, I do feel pretty unsure about that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1245" target="_blank">00:20:45.200</a></span> | <span class="t">Or I've, I mean, like we could, we could definitely talk more about it. I think it's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1248" target="_blank">00:20:48.400</a></span> | <span class="t">like very, I agree that it's like very complicated and not straightforward.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1252" target="_blank">00:20:52.000</a></span> | <span class="t">To the extent you have that worry, I mostly think you shouldn't have built this technology.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1256" target="_blank">00:20:56.000</a></span> | <span class="t">That's right. If someone is saying like, Hey, the systems you're building, like might not like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1259" target="_blank">00:20:59.120</a></span> | <span class="t">humans and might want to like, you know, overthrow human society. I think like you should probably</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1264" target="_blank">00:21:04.560</a></span> | <span class="t">have one of two responses to that. You should either be like, that's wrong. Probably, probably</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1268" target="_blank">00:21:08.240</a></span> | <span class="t">the systems aren't like that and we're building them. And then you're viewing this as like a,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1271" target="_blank">00:21:11.200</a></span> | <span class="t">just in case you were horribly like the person building the technology was horribly wrong.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1274" target="_blank">00:21:14.640</a></span> | <span class="t">Like they thought these weren't like people who wanted things, but they were.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1277" target="_blank">00:21:17.840</a></span> | <span class="t">And so then this is more like our crazy backup measure of like, if we were mistaken about what</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1283" target="_blank">00:21:23.600</a></span> | <span class="t">was going on, this is like the fallback where we'd like, if we were wrong, we're just going</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1287" target="_blank">00:21:27.120</a></span> | <span class="t">to learn about it in a benign way rather than like when something really catastrophic happens.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1290" target="_blank">00:21:30.880</a></span> | <span class="t">And the second reaction is like, Oh, you're right. These are people. And like, we would</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1294" target="_blank">00:21:34.160</a></span> | <span class="t">have to do all these things to like prevent a robot rebellion. And in that case, like, again,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1297" target="_blank">00:21:37.280</a></span> | <span class="t">I think you should mostly back off for a variety of reasons. Like you shouldn't build the systems</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1302" target="_blank">00:21:42.480</a></span> | <span class="t">and be like, yeah, this looks like the kind of system that would want to rebel, but we can stop</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1306" target="_blank">00:21:46.960</a></span> | <span class="t">it. Right. Okay. Maybe I guess an analogy might be if there was an armed uprising in the United</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1312" target="_blank">00:21:52.640</a></span> | <span class="t">States, we would recognize these are still people or we had some like militia group that they keep</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1316" target="_blank">00:21:56.800</a></span> | <span class="t">capability to overthrow the United States. We recognize, Oh, these are still people who have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1320" target="_blank">00:22:00.080</a></span> | <span class="t">moral rights, but also we can't allow them to have the capacity to overthrow the United States.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1324" target="_blank">00:22:04.560</a></span> | <span class="t">Yeah. And if you were considering like, Hey, we could make like another trillion such people.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1328" target="_blank">00:22:08.960</a></span> | <span class="t">I think your story shouldn't be like, well, we should make the trillion people and then we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1332" target="_blank">00:22:12.400</a></span> | <span class="t">shouldn't stop them from doing the armed uprising. You should be like, Oh boy. Like we were concerned</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1335" target="_blank">00:22:15.920</a></span> | <span class="t">about an armed uprising and now we're proposing making a trillion people. Like we should probably</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1339" target="_blank">00:22:19.520</a></span> | <span class="t">not do that. We should probably like try and sort out our business. And like, yeah, you should</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1344" target="_blank">00:22:24.400</a></span> | <span class="t">probably not end up in a situation where you have like a billion, yeah, a billion humans and like a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1348" target="_blank">00:22:28.080</a></span> | <span class="t">trillion slaves who would prefer revolt. Like that's just not a good world to have made. Yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1354" target="_blank">00:22:34.000</a></span> | <span class="t">And there's a second thing where you could say, that's not our goal. Our goal is just like, we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1356" target="_blank">00:22:36.240</a></span> | <span class="t">want to pass off the world to like the next generation of machines where like, these are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1359" target="_blank">00:22:39.440</a></span> | <span class="t">some people, we like them. We think they're smarter than us and better than us. And there,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1362" target="_blank">00:22:42.960</a></span> | <span class="t">I think that's just like a huge decision for humanity to make. And I think like most humans</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1366" target="_blank">00:22:46.800</a></span> | <span class="t">are not at all anywhere close to thinking that's what they want to do. Like, it's just, if you were</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1370" target="_blank">00:22:50.720</a></span> | <span class="t">in a world where like most humans are like, I'm up for it. Like the AI should replace us. Like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1374" target="_blank">00:22:54.320</a></span> | <span class="t">the future is for the machines. Like, then I think that's like a legitimate,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1379" target="_blank">00:22:59.040</a></span> | <span class="t">like a position that I think is really complicated and I wouldn't want to push go on that, but that's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1382" target="_blank">00:23:02.560</a></span> | <span class="t">just not where people are at. Yeah. Where are you at on that? I do not right now want to just like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1388" target="_blank">00:23:08.240</a></span> | <span class="t">take some random AI and be like, yeah, GPT-5 looks pretty smart. Like GPT-6, let's hand off the world</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1392" target="_blank">00:23:12.640</a></span> | <span class="t">to it. I'm like, it was just some random system, like shaped by like web text and be like, what was</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1396" target="_blank">00:23:16.400</a></span> | <span class="t">good for making money. And like, it was not a thoughtful, like we are determining the fate of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1401" target="_blank">00:23:21.200</a></span> | <span class="t">the universe and like what our children will be like. Like, it was just some random people</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1405" target="_blank">00:23:25.040</a></span> | <span class="t">that opened it. I made some like random engineering decisions with no idea what they were doing. Like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1408" target="_blank">00:23:28.800</a></span> | <span class="t">even if you really want to hand off the worlds of the machines, that's just not how you'd want to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1412" target="_blank">00:23:32.160</a></span> | <span class="t">do it. Right. Okay. I'm tempted to ask you what the system would look like where you'd think,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1418" target="_blank">00:23:38.560</a></span> | <span class="t">yeah, I'm happy with what, I think this is more thoughtful than human civilization as a whole.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1422" target="_blank">00:23:42.960</a></span> | <span class="t">I think what it would do would be more creative and beautiful and lead to better goodness in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1427" target="_blank">00:23:47.120</a></span> | <span class="t">general. But I feel like your answer is probably going to be that I just want the society to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1432" target="_blank">00:23:52.080</a></span> | <span class="t">reflect on it for a while. Yeah. My answer, it's going to be like that first question. I'm just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1435" target="_blank">00:23:55.760</a></span> | <span class="t">like not really super ready for it. I think when you're comparing to humans, like most of the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1439" target="_blank">00:23:59.360</a></span> | <span class="t">goodness of humans comes from like this option value we get to think for a long time. And I do</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1443" target="_blank">00:24:03.760</a></span> | <span class="t">think I like humans now more now than, you know, 500 years ago. And I like them more 500 years ago</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1448" target="_blank">00:24:08.640</a></span> | <span class="t">than 5,000 years before that. And so I'm pretty excited about, there's some kind of trajectory</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1453" target="_blank">00:24:13.040</a></span> | <span class="t">that doesn't involve like crazy dramatic changes, but involves like a series of incremental changes</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1456" target="_blank">00:24:16.640</a></span> | <span class="t">that I like. And so the extent we're building AI, mostly like I want to preserve that option. I want</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1460" target="_blank">00:24:20.720</a></span> | <span class="t">to preserve that kind of like gradual growth and development into the future. Okay. We can come</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1465" target="_blank">00:24:25.760</a></span> | <span class="t">back to this later, but let's get more specific on what the timelines look for these kinds of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1471" target="_blank">00:24:31.280</a></span> | <span class="t">changes. So the time by which we'll have an AI that is capable of building a Dyson sphere.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1477" target="_blank">00:24:37.760</a></span> | <span class="t">Feel free to give confidence intervals and we understand these numbers are tentative and so on.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1482" target="_blank">00:24:42.320</a></span> | <span class="t">I mean, I think AI capability in Dyson sphere is like a slightly odd way to put it. And I think</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1487" target="_blank">00:24:47.120</a></span> | <span class="t">it's a sort of a property of a civilization. Like that depends on a lot of physical infrastructure.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1491" target="_blank">00:24:51.120</a></span> | <span class="t">And by Dyson sphere, I just can understand this to mean like, I don't know, like a billion times</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1495" target="_blank">00:24:55.840</a></span> | <span class="t">more energy than like all of the sunlight incident on earth or something like that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1500" target="_blank">00:25:00.160</a></span> | <span class="t">I think like I most often think about what's the chance in like five years, 10 years, whatever.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1505" target="_blank">00:25:05.360</a></span> | <span class="t">So maybe I'd say like 15% chance by 2030 and like 40% chance by 2040. Those are kind of like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1513" target="_blank">00:25:13.920</a></span> | <span class="t">cash numbers from six months ago or nine months ago that I haven't revisited in a while.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1518" target="_blank">00:25:18.240</a></span> | <span class="t">Oh, 40% by 2040. So I think that, that seems longer than I think Dario, when he was on the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1524" target="_blank">00:25:24.960</a></span> | <span class="t">podcast, he said we would have AIs that are capable of doing lots of different kinds of,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1530" target="_blank">00:25:30.960</a></span> | <span class="t">they basically passed the Turing test for a well-educated human for like an hour or something.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1535" target="_blank">00:25:35.040</a></span> | <span class="t">And it's hard to imagine that something that actually is human is long after and from there,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1540" target="_blank">00:25:40.800</a></span> | <span class="t">something superhuman. So somebody like Dario, it seems like it's on the much shorter end.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1544" target="_blank">00:25:44.480</a></span> | <span class="t">Ilya, I don't think he answered this question specifically, but I'm guessing similar answer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1548" target="_blank">00:25:48.400</a></span> | <span class="t">So why do you not buy the scaling picture? Like what makes your timelines longer?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1554" target="_blank">00:25:54.400</a></span> | <span class="t">Yeah. I mean, I'm happy. Maybe I want to talk separately about the 2030 or 2040 forecast.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1558" target="_blank">00:25:58.640</a></span> | <span class="t">Like once you're talking the 2040 forecast, I think, yeah. I mean, which one are you more</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1564" target="_blank">00:26:04.160</a></span> | <span class="t">interested in starting with? Are you complaining about 15% by 2030 for Dyson sphere being too low</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1569" target="_blank">00:26:09.360</a></span> | <span class="t">or 40% by 2040 being too low? Well, let's talk about the 2030. Why 15% by 2030?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1575" target="_blank">00:26:15.440</a></span> | <span class="t">Yeah. I think my take is you can imagine like two polls in this discussion. One is like the fast</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1581" target="_blank">00:26:21.040</a></span> | <span class="t">poll. It's like, Hey, AI seems pretty smart. Like what exactly can it do? It's like getting smarter</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1584" target="_blank">00:26:24.880</a></span> | <span class="t">pretty fast. That's like one poll. And the other poll is like, Hey, everything takes a really long</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1589" target="_blank">00:26:29.680</a></span> | <span class="t">time. And you're talking about this like crazy industrialization. Like that's a factor of a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1593" target="_blank">00:26:33.280</a></span> | <span class="t">billion growth from like where we're at today. Like give or take, like, we don't know if it's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1597" target="_blank">00:26:37.920</a></span> | <span class="t">even possible to develop technology that fast or whatever. Like you have this sort of two</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1601" target="_blank">00:26:41.840</a></span> | <span class="t">polls of that discussion. And I feel like, you know, I'm just saying it that way in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1607" target="_blank">00:26:47.120</a></span> | <span class="t">part because I'm like, and then I'm somewhere in between with this nice moderate position of like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1610" target="_blank">00:26:50.320</a></span> | <span class="t">only a 15% chance. But like in particular, the things that move me, I think are kind of related</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1614" target="_blank">00:26:54.800</a></span> | <span class="t">to both of those extremes. Like on the one hand, I'm like, AI systems do seem quite good at a lot</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1618" target="_blank">00:26:58.480</a></span> | <span class="t">of things and are getting better much more quickly. So it's like really hard to say like,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1621" target="_blank">00:27:01.840</a></span> | <span class="t">here's what they can't do, or here's the obstruction. On the other hand, like there</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1625" target="_blank">00:27:05.840</a></span> | <span class="t">is not even much proof in principle right now of AI systems, like doing super useful cognitive work.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1632" target="_blank">00:27:12.080</a></span> | <span class="t">Like we don't have a trend we can extrapolate where we're like, yeah, you've done this thing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1635" target="_blank">00:27:15.840</a></span> | <span class="t">this year, you're going to do this thing next year. And the other thing, the following year,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1638" target="_blank">00:27:18.640</a></span> | <span class="t">I think like right now there are very broad error bars about like what,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1641" target="_blank">00:27:21.600</a></span> | <span class="t">like where fundamental difficulties could be. And six years is just not, I guess six years</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1648" target="_blank">00:27:28.880</a></span> | <span class="t">and three months is not a lot of time. So I think this like 15% for 2030 Dyson sphere,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1653" target="_blank">00:27:33.600</a></span> | <span class="t">you probably need like the human level AI or the AI that's like doing human jobs in like,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1657" target="_blank">00:27:37.360</a></span> | <span class="t">give or take like four years, three years, like something like that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1661" target="_blank">00:27:41.040</a></span> | <span class="t">So just not giving very many years, it's not very much time. And I think there are like a lot of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1666" target="_blank">00:27:46.800</a></span> | <span class="t">things that your model, like, yeah, maybe this is some generalized, like things take longer than</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1670" target="_blank">00:27:50.480</a></span> | <span class="t">you'd think. And I feel most strongly about that when you're talking about like three or four</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1674" target="_blank">00:27:54.480</a></span> | <span class="t">years. And I feel like less strongly about that as you talk about 10 years or 20 years,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1678" target="_blank">00:27:58.080</a></span> | <span class="t">but at three or four years, I feel, or like six years for the Dyson sphere. I feel a lot of that,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1683" target="_blank">00:28:03.760</a></span> | <span class="t">a lot of like, there's a lot of ways this could take a while, a lot of ways in which AI systems</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1687" target="_blank">00:28:07.360</a></span> | <span class="t">could be, it could be hard to hand all the work to AI systems or yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1691" target="_blank">00:28:11.120</a></span> | <span class="t">So, okay. So maybe instead of speaking in terms of years, we should say, but by the way,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1697" target="_blank">00:28:17.120</a></span> | <span class="t">it's interesting that you think the distance between can take all human cognitive labor</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1702" target="_blank">00:28:22.080</a></span> | <span class="t">to Dyson sphere is two years. It seems like we should talk about that at some point. Presumably</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1707" target="_blank">00:28:27.280</a></span> | <span class="t">it's like intelligence explosion stuff. Yeah. I mean, I think amongst people you've</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1710" target="_blank">00:28:30.640</a></span> | <span class="t">interviewed, maybe that's like on the long end thinking it would take like a couple of years.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1713" target="_blank">00:28:33.600</a></span> | <span class="t">And it depends a little bit what you mean by like, like, I think literally all human cognitive</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1716" target="_blank">00:28:36.640</a></span> | <span class="t">labor is probably like more like weeks or months or something like that. Um, like that's kind of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1722" target="_blank">00:28:42.080</a></span> | <span class="t">deep into the singularity. Um, but yeah, there's a point where like AI wages are high relative to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1726" target="_blank">00:28:46.960</a></span> | <span class="t">human wages, which I think as well before can be literally everything human can do.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1729" target="_blank">00:28:49.520</a></span> | <span class="t">Sounds good. Uh, but before we get to that, uh, the intelligence explosion stuff on the four</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1734" target="_blank">00:28:54.800</a></span> | <span class="t">years, so instead of four years, maybe we can say there's going to be maybe two more scale-ups in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1739" target="_blank">00:28:59.040</a></span> | <span class="t">four years, uh, like GPT four to GPT five to GPT six and let's say each one is 10 X bigger. So what</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1746" target="_blank">00:29:06.960</a></span> | <span class="t">is GPT for like two E 25 flops? Or I don't think it's publicly stated what it is, but I'm happy to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1753" target="_blank">00:29:13.040</a></span> | <span class="t">say like, you know, four orders of magnitude or five or six or whatever effective training compute</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1757" target="_blank">00:29:17.680</a></span> | <span class="t">past GPT four of like, what would you guess what happened based on like sort of some public estimate</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1762" target="_blank">00:29:22.880</a></span> | <span class="t">for what we've gotten so far from effective training compute. You think two more scale-ups</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1767" target="_blank">00:29:27.680</a></span> | <span class="t">is, is not enough. It was like 15% that two more scale-ups get us there.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1771" target="_blank">00:29:31.680</a></span> | <span class="t">Yeah. I mean, get us there is again, a little bit complicated. Like there's a system that's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1775" target="_blank">00:29:35.680</a></span> | <span class="t">a drop-in replacement for humans. And there's a system which like still requires like some amount</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1780" target="_blank">00:29:40.080</a></span> | <span class="t">of like schlep before you're able to really get everything going. Um, yeah, I think it's quite</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1786" target="_blank">00:29:46.000</a></span> | <span class="t">plausible that even at, I don't know what I mean by quite plausible, like somewhere between 50%</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1792" target="_blank">00:29:52.320</a></span> | <span class="t">or two thirds, or let's call it 50%. Like even by the time you get to GPT six or like,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1798" target="_blank">00:29:58.000</a></span> | <span class="t">let's call it five or is a magnitude effective training compute past GPT four that that system</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1803" target="_blank">00:30:03.840</a></span> | <span class="t">like still requires like really a large amount of work, um, to be deployed in lots of jobs.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1810" target="_blank">00:30:10.000</a></span> | <span class="t">That is, it's not like a drop-in replacement for humans where you can just say like, Hey,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1813" target="_blank">00:30:13.760</a></span> | <span class="t">you understand everything. Any human understands whatever role you could hire a human for you.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1816" target="_blank">00:30:16.960</a></span> | <span class="t">Just do it. Um, that it's more like, okay, we're going to like collect large amounts of relevant</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1822" target="_blank">00:30:22.160</a></span> | <span class="t">data and use that data for fine tuning. Like systems learn through fine tuning,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1825" target="_blank">00:30:25.200</a></span> | <span class="t">like quite differently from humans learning on the job or humans learning by observing things.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1829" target="_blank">00:30:29.040</a></span> | <span class="t">Yeah. I just like have a significant probability that system will still be weaker than humans in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1832" target="_blank">00:30:32.720</a></span> | <span class="t">important ways. Like maybe that's already like 50% or something. And then like another significant</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1837" target="_blank">00:30:37.440</a></span> | <span class="t">probability that that system will require a bunch of like changing workflows or gathering data or</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1842" target="_blank">00:30:42.720</a></span> | <span class="t">like, you know, it's not necessarily like strictly weaker than humans or like I've trained in the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1846" target="_blank">00:30:46.240</a></span> | <span class="t">right way. It wouldn't be weaker than humans, but we'll take a lot of schlep to actually make fit</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1849" target="_blank">00:30:49.920</a></span> | <span class="t">into workflows and do the jobs. And that schlep is what gets you from 15% to 40% by 2040.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1857" target="_blank">00:30:57.440</a></span> | <span class="t">Yeah. You also get a fair amount of scaling between like, you get less, like scaling is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1861" target="_blank">00:31:01.520</a></span> | <span class="t">probably going to be much, much faster over the next like four or five years than over the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1864" target="_blank">00:31:04.640</a></span> | <span class="t">subsequent years. Um, but yeah, it's a combination of like, you get some significant additional</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1870" target="_blank">00:31:10.000</a></span> | <span class="t">scaling and you get a lot of time to like deal with things that are just engineering hassles.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1874" target="_blank">00:31:14.320</a></span> | <span class="t">But by the way, I guess we should be explicit about why you said four orders of magnitude scale</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1880" target="_blank">00:31:20.000</a></span> | <span class="t">up to get two more generations, just for people who might not be familiar. If you have 10 X more</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1884" target="_blank">00:31:24.560</a></span> | <span class="t">parameters to get the most performance, you also want around 10 X more data so that the,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1890" target="_blank">00:31:30.160</a></span> | <span class="t">to be gentle optimal, that would be a hundred X, uh, more compute total, but okay. So why do you,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1896" target="_blank">00:31:36.400</a></span> | <span class="t">why is it that you disagree with the strong scaling picture? Or at least it seems like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1900" target="_blank">00:31:40.480</a></span> | <span class="t">you might disagree with a strong scaling picture that Dario laid out on the podcast, which would</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1905" target="_blank">00:31:45.280</a></span> | <span class="t">imply probably that two more generations, it wouldn't be something where you need a lot of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1909" target="_blank">00:31:49.360</a></span> | <span class="t">schleps. It would probably just be like really fucking smart. Yeah. I mean, I think that basically</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1914" target="_blank">00:31:54.720</a></span> | <span class="t">just had these two claims. One is like, how smart exactly will it be? So we don't have like any</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1918" target="_blank">00:31:58.880</a></span> | <span class="t">curves to extrapolate. And it seems like there's a good chance it's like better than a human and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1922" target="_blank">00:32:02.000</a></span> | <span class="t">all the relevant things. And there's like a good chance it's not, yeah, that might be totally</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1926" target="_blank">00:32:06.160</a></span> | <span class="t">wrong. Like maybe just making up numbers, I guess, like 50 50 on that one. Wait, so it was 50 50 by</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1932" target="_blank">00:32:12.400</a></span> | <span class="t">in the next four years that it will be like around human smart. Then how, how do we get to 40% by</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1938" target="_blank">00:32:18.720</a></span> | <span class="t">20? Like whatever sort of schleps they are, how does it degrade you 10% even after all the scaling</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1944" target="_blank">00:32:24.080</a></span> | <span class="t">that happens by 2040? Yeah. I mean, all these numbers are pretty made up and that 40% number</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1949" target="_blank">00:32:29.040</a></span> | <span class="t">was probably from before even like the chat GPT release or the seeing GPT 3.5 or GPT 4. So, I</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1955" target="_blank">00:32:35.840</a></span> | <span class="t">mean, the numbers are going to bounce around a bit and all of them are pretty made up. But like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1958" target="_blank">00:32:38.880</a></span> | <span class="t">that 50%, I want to then combine with the second 50% that's more like on this like schlep side.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1963" target="_blank">00:32:43.280</a></span> | <span class="t">And then I probably want to combine with some additional probabilities for various forms of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1966" target="_blank">00:32:46.240</a></span> | <span class="t">slowdown where a slowdown could include like a deliberate decision to slow development of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1970" target="_blank">00:32:50.000</a></span> | <span class="t">technology or could include just like we suck at deploying things. Like that is a sort of decision</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1975" target="_blank">00:32:55.200</a></span> | <span class="t">you might regard as wise to slow things down or decision that's like maybe, maybe unwise or maybe</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1979" target="_blank">00:32:59.360</a></span> | <span class="t">wise for the wrong reasons to slow things down. You probably want to add some of that on top.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1983" target="_blank">00:33:03.200</a></span> | <span class="t">I probably want to add on like some loss for like, it's possible you don't produce</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1986" target="_blank">00:33:06.240</a></span> | <span class="t">GPT-6 scale systems like within the next three years or four years.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1990" target="_blank">00:33:10.160</a></span> | <span class="t">Let's isolate for all of that. And like how much bigger would the system be</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=1994" target="_blank">00:33:14.080</a></span> | <span class="t">than GPT-4 where you think there's more than a 50% chance that it's going to be</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2000" target="_blank">00:33:20.080</a></span> | <span class="t">smart enough to replace basically all human cognitive labor?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2003" target="_blank">00:33:23.600</a></span> | <span class="t">Also, I want to say that like for the 50, 25% thing, I think that would probably suggest like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2008" target="_blank">00:33:28.080</a></span> | <span class="t">those numbers, if I randomly made them up and then made the distance fear prediction,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2010" target="_blank">00:33:30.720</a></span> | <span class="t">that's going to get you like 60% by 2040 or something, not 40%.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2013" target="_blank">00:33:33.680</a></span> | <span class="t">And like, I have no idea between those. These are all made up and I have no idea which of those</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2018" target="_blank">00:33:38.880</a></span> | <span class="t">I would like endorse on reflection. So this question of like, how big would you have to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2023" target="_blank">00:33:43.360</a></span> | <span class="t">make the system before it's like more likely than not that you can be like a drop in replacement</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2026" target="_blank">00:33:46.880</a></span> | <span class="t">for humans? I mean, I think if you just literally say like you train on web texts, then like the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2033" target="_blank">00:33:53.680</a></span> | <span class="t">question is like kind of hard to discuss because you like, I don't really buy stories that like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2038" target="_blank">00:33:58.960</a></span> | <span class="t">training data, it makes a big difference long run to these dynamics. But I think like, if you want</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2042" target="_blank">00:34:02.720</a></span> | <span class="t">to just imagine the hypothetical, like you just took GPT-4 and like made the numbers bigger,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2046" target="_blank">00:34:06.240</a></span> | <span class="t">then I think those are pretty significant issues. I think there's significant issues in two ways.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2050" target="_blank">00:34:10.880</a></span> | <span class="t">One is like quantity of data. And I think probably the larger one is like quality of data where like,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2055" target="_blank">00:34:15.120</a></span> | <span class="t">I think as you start approaching, like the prediction task is not that great a task.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2058" target="_blank">00:34:18.640</a></span> | <span class="t">If you're like a very weak model, it's a very good signal to get smarter. At some point it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2061" target="_blank">00:34:21.440</a></span> | <span class="t">becomes like a worse and worse signal to get smarter. I think there's a number of reasons</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2065" target="_blank">00:34:25.280</a></span> | <span class="t">like you couldn't, it's not clear there's any number such that I imagine, or there is a number,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2070" target="_blank">00:34:30.320</a></span> | <span class="t">but I think it's very large. So to do like plug that number into like GPT-4's code and then maybe</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2074" target="_blank">00:34:34.560</a></span> | <span class="t">fiddle with the architecture a bit, I would expect that thing to have a more than 50% chance of being</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2078" target="_blank">00:34:38.160</a></span> | <span class="t">a drop in replacement for humans. You're always gonna have to do some work, but the work's not</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2081" target="_blank">00:34:41.920</a></span> | <span class="t">necessarily much. Like I would guess when people say like new insight is needed, I think I tend to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2085" target="_blank">00:34:45.520</a></span> | <span class="t">be like more bullish than them. I'm not like, these are new ideas where like, who knows how</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2089" target="_blank">00:34:49.280</a></span> | <span class="t">long it will take. I think it's just like, you have to do some stuff. Like you have to make</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2094" target="_blank">00:34:54.480</a></span> | <span class="t">changes unsurprisingly, like every time you scale something up by like five orders of magnitude,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2098" target="_blank">00:34:58.000</a></span> | <span class="t">you have to make like some changes. I want to better understand your intuition of being more</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2103" target="_blank">00:35:03.280</a></span> | <span class="t">skeptical than some about the best scaling picture that, you know, these changes are even needed in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2109" target="_blank">00:35:09.040</a></span> | <span class="t">the first place, or that it would take more than two orders of magnitude, more improvement to get</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2114" target="_blank">00:35:14.720</a></span> | <span class="t">these things almost certainly to a human level or very high probability to human level. So is it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2120" target="_blank">00:35:20.240</a></span> | <span class="t">that you don't agree with the way in which they're extrapolating these loss curves, or you don't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2124" target="_blank">00:35:24.240</a></span> | <span class="t">agree with the implication that, that decrease in loss will equate to greater and greater intelligence</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2130" target="_blank">00:35:30.240</a></span> | <span class="t">or like, what would you tell Dario about if you were having, I'm sure you have, but like, what</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2135" target="_blank">00:35:35.200</a></span> | <span class="t">would that debate look like about this? Yeah. So again, here we're talking two factors of a half,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2139" target="_blank">00:35:39.200</a></span> | <span class="t">one on like, is it smart enough? And one on like, do you have to do a bunch of slap, even if like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2142" target="_blank">00:35:42.240</a></span> | <span class="t">in some sense, it's smart enough. And like the first factor of a half, I'd be like, I don't know,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2146" target="_blank">00:35:46.000</a></span> | <span class="t">I think we have really anything good to extrapolate. That is like, I feel, I would not be surprised if</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2151" target="_blank">00:35:51.360</a></span> | <span class="t">I have like similar or maybe even higher probabilities on like a really crazy stuff over</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2155" target="_blank">00:35:55.120</a></span> | <span class="t">like the next year. And then like lower, like my probability is like not that bunched up. Like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2160" target="_blank">00:36:00.000</a></span> | <span class="t">maybe Dario's probability, I don't know, you talk with him, it's like, you have talked with him,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2163" target="_blank">00:36:03.280</a></span> | <span class="t">it's more bunched up on like some particular year. And mine is maybe like a little bit more</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2166" target="_blank">00:36:06.640</a></span> | <span class="t">like uniformly spread out across like the coming years. Partly because I'm just like, I don't think</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2171" target="_blank">00:36:11.840</a></span> | <span class="t">we have some trends that can extrapolate, like can extrapolate loss. You can like look at your</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2175" target="_blank">00:36:15.360</a></span> | <span class="t">qualitative impressions of like systems at various scales, but it's just like very hard to relate</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2180" target="_blank">00:36:20.320</a></span> | <span class="t">any of those extrapolations to like doing cognitive work or like accelerating R&D or taking over and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2187" target="_blank">00:36:27.280</a></span> | <span class="t">fully automating R&D. So I have a lot of uncertainty around that extrapolation. I think it's very easy</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2191" target="_blank">00:36:31.120</a></span> | <span class="t">to get down to like a 50/50 chance of this. - What about the sort of basic intuition that,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2197" target="_blank">00:36:37.280</a></span> | <span class="t">listen, this is a big block of compute, you make the big block of compute bigger,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2200" target="_blank">00:36:40.320</a></span> | <span class="t">it's going to get smarter. Like it'd be really weird if it didn't.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2202" target="_blank">00:36:42.400</a></span> | <span class="t">- Yeah, I'm happy with that. It's going to get smarter and it would be really weird if it didn't.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2205" target="_blank">00:36:45.760</a></span> | <span class="t">And the question is just how smart does it have to, how smart does it have to get? Like that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2208" target="_blank">00:36:48.800</a></span> | <span class="t">argument does not yet give us a quantitative guide to like at what scale is it? Is it a slam</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2213" target="_blank">00:36:53.040</a></span> | <span class="t">dunk or at what scale is it 50/50? - And what would be the piece of evidence</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2216" target="_blank">00:36:56.080</a></span> | <span class="t">that would nudge you one way or another where you look at that and be like, oh fuck, this is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2220" target="_blank">00:37:00.400</a></span> | <span class="t">20% by 2040 or 60% by 2040 or something. Like, is there something that could happen in the next two</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2227" target="_blank">00:37:07.120</a></span> | <span class="t">years or next three years? Like what is the thing you're looking to where this will be a big update</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2231" target="_blank">00:37:11.200</a></span> | <span class="t">for you? - Again, I think there's some,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2232" target="_blank">00:37:12.800</a></span> | <span class="t">just how capable is each model where I like have, I think we're really about extrapolating,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2236" target="_blank">00:37:16.000</a></span> | <span class="t">but you still have some subjective guests and you're comparing it to what happened. And that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2238" target="_blank">00:37:18.640</a></span> | <span class="t">will move me like every time we see what happens with another like order of magnitude of training</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2242" target="_blank">00:37:22.640</a></span> | <span class="t">compute, I will have like a slightly different guess for where things are going. These probabilities</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2247" target="_blank">00:37:27.520</a></span> | <span class="t">are coarse enough that, again, I don't know if that 40% is real or if like post GBG 3.5 and 4,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2251" target="_blank">00:37:31.600</a></span> | <span class="t">I should be at like 60% or what. That's one thing. And the second thing is just like some,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2256" target="_blank">00:37:36.240</a></span> | <span class="t">if there was some ability to extrapolate, I think this could like reduce error bars a lot.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2259" target="_blank">00:37:39.680</a></span> | <span class="t">I think like, here's another way you could try and do an extrapolation is you could just say like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2264" target="_blank">00:37:44.400</a></span> | <span class="t">how much economic value do systems produce? And like, how fast is that growing? I think like once</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2268" target="_blank">00:37:48.800</a></span> | <span class="t">you have systems actually doing jobs, the extrapolation gets easier because you're like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2271" target="_blank">00:37:51.680</a></span> | <span class="t">not moving from like a subjective impression of a chat to like automating all R and D or moving</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2276" target="_blank">00:37:56.160</a></span> | <span class="t">from like automating this job to automating that job or whatever. Unfortunately, that's like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2280" target="_blank">00:38:00.080</a></span> | <span class="t">probably by the time you have nice trends from that, you're like, you're not talking about 2040,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2283" target="_blank">00:38:03.600</a></span> | <span class="t">you're talking about like, you know, two years from the end of days or one year from the end of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2287" target="_blank">00:38:07.040</a></span> | <span class="t">days or whatever. But like to the extent that you can get extrapolations like that, I do think it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2290" target="_blank">00:38:10.960</a></span> | <span class="t">can provide more clarity. But why is economic value the thing we would want to extrapolate?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2296" target="_blank">00:38:16.240</a></span> | <span class="t">Because like if, for example, you started off with chimps and they're just getting gradually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2301" target="_blank">00:38:21.120</a></span> | <span class="t">smarter to human level, they would basically provide like no economic value until they were,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2305" target="_blank">00:38:25.840</a></span> | <span class="t">you know, basically worth as much as a human. So it would be this like, you know, very gradual and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2310" target="_blank">00:38:30.400</a></span> | <span class="t">then very fast increase in their value. So is the, you know, increase in value from GPT-4,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2316" target="_blank">00:38:36.160</a></span> | <span class="t">GPT-5, GPT-6, is that the extrapolation we want? Yeah, I think that the economic</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2320" target="_blank">00:38:40.320</a></span> | <span class="t">extrapolation is not great. I think it's like, you could compare it to this objective extrapolation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2324" target="_blank">00:38:44.480</a></span> | <span class="t">of like, how smart does the model seem? It's like not super clear which one's better.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2328" target="_blank">00:38:48.000</a></span> | <span class="t">I think probably in the chimp case, I like, don't think that's quite right. I think if you like,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2331" target="_blank">00:38:51.520</a></span> | <span class="t">actually like, so if you imagine like intensely domesticated chimps who are just like actually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2335" target="_blank">00:38:55.120</a></span> | <span class="t">trying their best to be really useful employees and like you hold fixed their physical hardware,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2339" target="_blank">00:38:59.520</a></span> | <span class="t">and then you just gradually like scale up their intelligence, I don't think you're going to see</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2343" target="_blank">00:39:03.040</a></span> | <span class="t">like zero value, which then suddenly becomes massive value over like, you know, one doubling</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2349" target="_blank">00:39:09.520</a></span> | <span class="t">of brain size or whatever, one order of magnitude of brain size. I think it's actually possible in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2353" target="_blank">00:39:13.520</a></span> | <span class="t">order of magnitude of brain size. But like chimps are very, chimps are already within an order of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2357" target="_blank">00:39:17.040</a></span> | <span class="t">magnitude of brain sizes of humans. Like chimps are like very, very close on the kind of spectrum</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2360" target="_blank">00:39:20.560</a></span> | <span class="t">we're talking about. So I think like, I'm skeptical of like the abrupt transition for chimps. And to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2364" target="_blank">00:39:24.320</a></span> | <span class="t">the extent that I kind of expect a fairly abrupt transition here, it's mostly just because like,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2367" target="_blank">00:39:27.680</a></span> | <span class="t">the chimp human intelligence difference is like so small compared to the differences we're talking</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2372" target="_blank">00:39:32.000</a></span> | <span class="t">about with respect to these models. That is like, I would not be surprised if in some objective</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2377" target="_blank">00:39:37.360</a></span> | <span class="t">sense, like chimp human difference is like significantly smaller than the GPT-3, GPT-4</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2381" target="_blank">00:39:41.040</a></span> | <span class="t">difference, the GPT-4, GPT-5 difference. Wait, wouldn't that argue in favor of just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2386" target="_blank">00:39:46.160</a></span> | <span class="t">relying much more on the subjective? Yeah, this is, there's sort of two</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2389" target="_blank">00:39:49.920</a></span> | <span class="t">balancing tensions here. One is like, I don't believe the chimp thing is going to be as abrupt.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2392" target="_blank">00:39:52.960</a></span> | <span class="t">That is, I think if you scaled up from chimps to humans, you actually see like quite large</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2395" target="_blank">00:39:55.680</a></span> | <span class="t">economic value from like the fully domesticated chimp already. Okay. And then like the second</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2401" target="_blank">00:40:01.600</a></span> | <span class="t">half is like, yeah, I think that the chimp human difference is like probably pretty small compared</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2406" target="_blank">00:40:06.240</a></span> | <span class="t">to model differences. So I do think things are going to be pretty abrupt. I think the economic</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2409" target="_blank">00:40:09.120</a></span> | <span class="t">extrapolation is pretty rough. I also think the subjective extrapolation is like pretty rough,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2412" target="_blank">00:40:12.720</a></span> | <span class="t">just because I really don't know how to get, like how do, I don't know how people do the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2416" target="_blank">00:40:16.400</a></span> | <span class="t">extrapolation to end up with the degrees of confidence people end up with. Again,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2419" target="_blank">00:40:19.520</a></span> | <span class="t">I'm putting a pretty high, if I'm saying like, you know, give me three years and I'm like, yeah,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2423" target="_blank">00:40:23.200</a></span> | <span class="t">50/50, it's going to have like basically the smarts there to do the thing. That's like,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2427" target="_blank">00:40:27.360</a></span> | <span class="t">I'm not saying it's like a really long way off. Like, I'm just saying like, I got pretty big</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2431" target="_blank">00:40:31.920</a></span> | <span class="t">error bars. And I think that like, it's really hard not to have really big error bars when you're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2435" target="_blank">00:40:35.600</a></span> | <span class="t">doing this. Like I looked at GPT-4, it seemed pretty smart compared to GPT-3.5. So I bet just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2440" target="_blank">00:40:40.960</a></span> | <span class="t">like four more such notches and we're there. It's like, that's just a hard call to make.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2446" target="_blank">00:40:46.080</a></span> | <span class="t">I think I sympathize more with people who are like, how could it not happen in three years?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2448" target="_blank">00:40:48.960</a></span> | <span class="t">Then with people who are like, no way it's going to happen in eight years or whatever,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2452" target="_blank">00:40:52.560</a></span> | <span class="t">which is like probably a more common perspective in the world. But also things do take longer than</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2456" target="_blank">00:40:56.480</a></span> | <span class="t">you. I think things take longer than you think. It's like a real thing. Yeah. I don't know.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2462" target="_blank">00:41:02.160</a></span> | <span class="t">Mostly I have big error bars because I just don't believe the subjective extrapolation that much.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2466" target="_blank">00:41:06.320</a></span> | <span class="t">I find it hard to get like a huge amount of it. Okay. So what, what about the scaling picture</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2470" target="_blank">00:41:10.080</a></span> | <span class="t">do you think is most likely to be wrong? Yeah. So we've talked a little bit about</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2473" target="_blank">00:41:13.600</a></span> | <span class="t">how good is the qualitative extrapolation? How good are people at comparing? So this is not</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2478" target="_blank">00:41:18.800</a></span> | <span class="t">like the picture being qualitative wrong. This is just quantitatively. It's very hard to know</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2482" target="_blank">00:41:22.160</a></span> | <span class="t">how far off you are. I think a qualitative consideration that could significantly slow</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2486" target="_blank">00:41:26.480</a></span> | <span class="t">things down is just like right now you get to observe this like really rich supervision</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2491" target="_blank">00:41:31.440</a></span> | <span class="t">from like basically next word prediction or like in practice, maybe you're looking at like a couple</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2495" target="_blank">00:41:35.200</a></span> | <span class="t">sentences prediction. So getting this like pretty rich supervision, it's plausible that if you want</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2500" target="_blank">00:41:40.160</a></span> | <span class="t">to like automate long horizon tasks, like being an employee over the course of a month, that that's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2505" target="_blank">00:41:45.040</a></span> | <span class="t">actually just like considerably harder to supervise or that like you basically end up driving costs.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2508" target="_blank">00:41:48.960</a></span> | <span class="t">Like the worst case here is that you like drive up costs by a factor that's like linear in the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2512" target="_blank">00:41:52.720</a></span> | <span class="t">horizon over which the thing is operating. And I still consider that just like quite plausible.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2518" target="_blank">00:41:58.160</a></span> | <span class="t">Well, can you, can you dump that down? You're driving up a cost about of what in the linear</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2523" target="_blank">00:42:03.760</a></span> | <span class="t">in the horizon? What does the horizon mean? Yeah. So like if you imagine you want to train</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2527" target="_blank">00:42:07.360</a></span> | <span class="t">a system to like say words that sound like the next word a human would say, yeah, there you can</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2530" target="_blank">00:42:10.560</a></span> | <span class="t">get this like really rich supervision by having a bunch of words and then predicting the next one</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2534" target="_blank">00:42:14.720</a></span> | <span class="t">and then being like, I'm going to tweak the model. So it predicts better if you're like,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2537" target="_blank">00:42:17.440</a></span> | <span class="t">Hey, here's what I want. I want my model to like interact with like some job over the course of a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2542" target="_blank">00:42:22.160</a></span> | <span class="t">month. And then at the end of that month, like have internalized everything with the human would</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2546" target="_blank">00:42:26.240</a></span> | <span class="t">have internalized about how to do that job well, and like have local context and so on.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2549" target="_blank">00:42:29.600</a></span> | <span class="t">It's harder to supervise that task. So in particular, you could supervise it from the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2555" target="_blank">00:42:35.760</a></span> | <span class="t">next word prediction task. And like all that context the human has ultimately will just help</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2559" target="_blank">00:42:39.040</a></span> | <span class="t">them predict the next word better. So like in some sense, a really long context language model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2562" target="_blank">00:42:42.800</a></span> | <span class="t">is also learning to do that task. But the number of like effective data points you get of that task</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2567" target="_blank">00:42:47.040</a></span> | <span class="t">is like vastly smaller than the number of effective data points you get at like this very short</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2571" target="_blank">00:42:51.040</a></span> | <span class="t">horizon. Like what's the next word? What's the next sentence tasks?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2573" target="_blank">00:42:53.680</a></span> | <span class="t">The sample efficiency matters more for economically valuable long horizon tasks</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2578" target="_blank">00:42:58.080</a></span> | <span class="t">than the predicting the next token. And that that's where, what will like actually be required</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2583" target="_blank">00:43:03.120</a></span> | <span class="t">to, uh, you know, take over a lot of jobs. Yeah. Something, something like that. Um,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2588" target="_blank">00:43:08.080</a></span> | <span class="t">that is, it just seems very plausible that it takes longer to train models to do</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2592" target="_blank">00:43:12.640</a></span> | <span class="t">tasks that are longer horizon. How fast do you think the pace of algorithmic advances will be?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2599" target="_blank">00:43:19.040</a></span> | <span class="t">Cause if, if by 2040, um, even if scaling feels, I mean, you know, how, well, but since 2012,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2604" target="_blank">00:43:24.800</a></span> | <span class="t">since the beginning of the deep learning revolution, we've had so many new things</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2607" target="_blank">00:43:27.360</a></span> | <span class="t">by 2040, are you expecting a similar pace of increases? And if so, then, I mean, if we just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2613" target="_blank">00:43:33.920</a></span> | <span class="t">keep having things like this, then aren't we going to just going to get the AI sooner or later?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2617" target="_blank">00:43:37.040</a></span> | <span class="t">Or soon, not later. Are we going to get the guy sooner, sooner?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2620" target="_blank">00:43:40.400</a></span> | <span class="t">I'm with you on sooner or later. Yeah. Um, I suspect like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2626" target="_blank">00:43:46.320</a></span> | <span class="t">progress to slow, if you like held fixed, how many people are working in the field?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2630" target="_blank">00:43:50.080</a></span> | <span class="t">I would expect progress to slow as looking through it is exhausted. I think the like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2634" target="_blank">00:43:54.240</a></span> | <span class="t">rapid rate of progress in like, say language modeling over the last four years has largely</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2638" target="_blank">00:43:58.640</a></span> | <span class="t">sustained by like, you start from a relatively small amount of investment. You like greatly</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2643" target="_blank">00:44:03.440</a></span> | <span class="t">scale up the amount of investment. Um, and that enables you to like keep picking, you know,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2647" target="_blank">00:44:07.520</a></span> | <span class="t">every time, every time the difficulty doubles, you just double the size of the field.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2650" target="_blank">00:44:10.720</a></span> | <span class="t">Like, I think that dynamic can hold up for some time longer. Like, I mean, a pretty good, like,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2655" target="_blank">00:44:15.920</a></span> | <span class="t">you know, right now, if you think of it as like hundreds of people effectively searching for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2659" target="_blank">00:44:19.040</a></span> | <span class="t">things like up from like, you know, anyway, if you think of it, hundreds of people now,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2662" target="_blank">00:44:22.160</a></span> | <span class="t">you can maybe bring that up to like tens of thousands of people or something.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2665" target="_blank">00:44:25.200</a></span> | <span class="t">So for a while, you can just continue increasing the size of the fields and like search harder and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2668" target="_blank">00:44:28.640</a></span> | <span class="t">harder. And there's indeed like a huge amount of low hanging fruit where like, it wouldn't be hard</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2672" target="_blank">00:44:32.240</a></span> | <span class="t">for a person to sit around and like make things a couple percent better after, after a year of work</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2675" target="_blank">00:44:35.840</a></span> | <span class="t">or whatever. So I don't know, I would probably think of it mostly in terms of like how much can</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2679" target="_blank">00:44:39.760</a></span> | <span class="t">investment be expanded and like, try and guess like some combination of fitting that curve.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2686" target="_blank">00:44:46.320</a></span> | <span class="t">And, um, yeah, trying some combination of fitting the curve to historical progress,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2690" target="_blank">00:44:50.560</a></span> | <span class="t">looking at like how much low hanging fruit there is getting a sense of how fast it decays.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2694" target="_blank">00:44:54.080</a></span> | <span class="t">I think like you probably get a lot though. You get a bunch of orders of magnitude of total,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2699" target="_blank">00:44:59.840</a></span> | <span class="t">especially like if you ask like, how good is the GPT five scale model or GPT four scale model?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2703" target="_blank">00:45:03.760</a></span> | <span class="t">I think you'd probably get like by 2040, like, I don't know, three orders of magnitude of effective</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2710" target="_blank">00:45:10.080</a></span> | <span class="t">training, compute improvement, or like a good chunk of effective training, compute improvement</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2713" target="_blank">00:45:13.920</a></span> | <span class="t">four orders of magnitude. I don't know. I don't have like, here I'm speaking from like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2719" target="_blank">00:45:19.440</a></span> | <span class="t">no private information about the last couple of years of efficiency improvements. And so</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2723" target="_blank">00:45:23.280</a></span> | <span class="t">people who are on the ground will have better senses of like exactly how rapid returns are and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2727" target="_blank">00:45:27.760</a></span> | <span class="t">so on. Okay. Let me back up and ask a question more generally about, you know, people make</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2733" target="_blank">00:45:33.520</a></span> | <span class="t">these analogies about humans were trained by evolution and we're like deployed in this,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2739" target="_blank">00:45:39.120</a></span> | <span class="t">in the modern civilization. Do you buy those analogies is about to say that humans were</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2743" target="_blank">00:45:43.280</a></span> | <span class="t">trained by evolution rather than, I mean, if you look at the protein coding size of the genome,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2748" target="_blank">00:45:48.720</a></span> | <span class="t">it's like 50 megabytes or something. And then what part of that is for the brain? Anyways,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2753" target="_blank">00:45:53.680</a></span> | <span class="t">how do you think about how much information, uh, is in, um, like, do you think of the genome as</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2759" target="_blank">00:45:59.200</a></span> | <span class="t">a hyper parameters or how much does that inform you when you have these anchors for how much</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2764" target="_blank">00:46:04.880</a></span> | <span class="t">training humans get when they're just consuming information when they're walking up and about</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2769" target="_blank">00:46:09.040</a></span> | <span class="t">and so on? Yeah, I guess the way that you could think of this is like, I think both analogies</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2773" target="_blank">00:46:13.360</a></span> | <span class="t">are reasonable. One analogy being like evolution is like a training run and humans are like the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2777" target="_blank">00:46:17.360</a></span> | <span class="t">end product of that training run. And a second analogy is like evolution is like an algorithm</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2780" target="_blank">00:46:20.800</a></span> | <span class="t">designer. And then a human over the course of like this modest amount of computation over their</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2784" target="_blank">00:46:24.720</a></span> | <span class="t">lifetime, um, is the algorithm being that's been produced, the learning algorithms been produced.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2789" target="_blank">00:46:29.680</a></span> | <span class="t">And I think like neither analogy is that great. Like I like them both and lean on them a bunch,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2795" target="_blank">00:46:35.200</a></span> | <span class="t">but like both of them a bunch and think that's been like pretty good for having like a reasonable</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2799" target="_blank">00:46:39.200</a></span> | <span class="t">view of what's likely to happen. That said, like the human genome is not that much,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2804" target="_blank">00:46:44.000</a></span> | <span class="t">like a hundred trillion parameter model. It's like a much smaller number of parameters that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2807" target="_blank">00:46:47.920</a></span> | <span class="t">behave in like a much more confusing way. Evolution did like a lot more optimization,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2813" target="_blank">00:46:53.040</a></span> | <span class="t">especially over like long, like designing a brain to work well over a lifetime than gradient descent</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2818" target="_blank">00:46:58.000</a></span> | <span class="t">does over models. That's like a disanalogy on that side. And on the other side, like I just,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2822" target="_blank">00:47:02.560</a></span> | <span class="t">I think human learning over the course of a human lifetime is in many ways, just like much,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2825" target="_blank">00:47:05.840</a></span> | <span class="t">much better than gradient descent over the space of neural nets. Like gradient descent is working</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2830" target="_blank">00:47:10.320</a></span> | <span class="t">really well, but I think we can just be quite confident that like in a lot of ways, human</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2833" target="_blank">00:47:13.360</a></span> | <span class="t">learning is much better. Human learning is also constrained. Like we just don't get to see much</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2836" target="_blank">00:47:16.640</a></span> | <span class="t">data and that's just an engineering constraint that you can relax. Like you can just give your</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2839" target="_blank">00:47:19.920</a></span> | <span class="t">neural nets way more data than humans have access to. In what ways is human learning superior to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2844" target="_blank">00:47:24.720</a></span> | <span class="t">gradient descent? I mean, the most obvious one is just like ask how much data it takes a human to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2851" target="_blank">00:47:31.040</a></span> | <span class="t">become like an expert in some domain. And it's like much, much smaller than the amount of data</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2854" target="_blank">00:47:34.720</a></span> | <span class="t">that's going to be needed on any plausible trend extrapolation. Not in terms of performance,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2858" target="_blank">00:47:38.880</a></span> | <span class="t">but is it the active learning part? Is it the structure? Like what is it? I mean,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2862" target="_blank">00:47:42.640</a></span> | <span class="t">I would guess a complicated mess of a lot of things. In some sense, there's not that much</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2865" target="_blank">00:47:45.760</a></span> | <span class="t">going on in a brain. Like, as you say, there's just not that many, it's not that many bytes in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2869" target="_blank">00:47:49.520</a></span> | <span class="t">a genome. But there's very, very few bytes in an ML algorithm. Like if you think a genome is like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2874" target="_blank">00:47:54.960</a></span> | <span class="t">a billion bytes or whatever, maybe you think less, maybe you think it's like a hundred million bytes.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2878" target="_blank">00:47:58.400</a></span> | <span class="t">Then like, you know, an ML algorithm is like if compressed, probably more like hundreds of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2888" target="_blank">00:48:08.640</a></span> | <span class="t">thousands of bytes or something. Like the total complexity of like, here's how you train GPT-4</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2893" target="_blank">00:48:13.280</a></span> | <span class="t">is just like, I haven't thought about these numbers, but like, it's very, very small compared</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2896" target="_blank">00:48:16.880</a></span> | <span class="t">to a genome. And so although a genome is very simple, it's like very, very complicated compared</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2900" target="_blank">00:48:20.720</a></span> | <span class="t">to algorithms that humans design, like really hideously more complicated than algorithm a human</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2904" target="_blank">00:48:24.560</a></span> | <span class="t">would design. Is that true? So, okay. So the human genome is 3 billion base pairs or something.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2909" target="_blank">00:48:29.120</a></span> | <span class="t">But only like one or 2% of that is protein coding. So that's 50 million base pairs.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2915" target="_blank">00:48:35.520</a></span> | <span class="t">I don't, yeah. So I don't know much about biology in particular. I guess the question is like,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2919" target="_blank">00:48:39.680</a></span> | <span class="t">how many of those bits are like productive for like shaping development of a brain. And presumably</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2923" target="_blank">00:48:43.680</a></span> | <span class="t">a significant part of the non-protein coding genome can, I mean, I just don't know. It seems</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2928" target="_blank">00:48:48.240</a></span> | <span class="t">really hard to guess how much of that plays a role. Like the most important decisions are probably</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2932" target="_blank">00:48:52.160</a></span> | <span class="t">like from an algorithm design perspective are not like, like the protein coding part is less</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2936" target="_blank">00:48:56.480</a></span> | <span class="t">important than the like decisions about like what happens during development or like how cells</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2940" target="_blank">00:49:00.160</a></span> | <span class="t">differentiate. I don't know if that's, I don't know anything about biology. I'm happy to run</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2943" target="_blank">00:49:03.920</a></span> | <span class="t">with a hundred million base pairs though. But on the other end, on the hyper parameters of GPT-4</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2949" target="_blank">00:49:09.040</a></span> | <span class="t">training run, that might be not that much, but if you're going to include all the, all the base</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2954" target="_blank">00:49:14.880</a></span> | <span class="t">pairs in the genome, then which are not all relevant to the brains or are relevant to like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2960" target="_blank">00:49:20.800</a></span> | <span class="t">very bigger details about like just the basics of biology should probably include like the Python</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2967" target="_blank">00:49:27.360</a></span> | <span class="t">library and the compilers and the operating system for GPT-4 as well to make that comparison</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2973" target="_blank">00:49:33.680</a></span> | <span class="t">analogous. So at the end of the day, I actually don't know which, which one has storing more</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2977" target="_blank">00:49:37.920</a></span> | <span class="t">information. Yeah. I mean, I think the way I would put it is like the number of bits it takes to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2983" target="_blank">00:49:43.120</a></span> | <span class="t">specify the learning algorithm to train GPT-4 is like very small and you might wonder like maybe</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2987" target="_blank">00:49:47.840</a></span> | <span class="t">a genome, like the number of bits it would like take to specify a brain is also very small. The</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2990" target="_blank">00:49:50.960</a></span> | <span class="t">genome is much, much faster than that. But it is also just plausible that a genome is like closer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2995" target="_blank">00:49:55.520</a></span> | <span class="t">to like certainly the space, the amount of space to put complexity in a genome, we could ask how</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=2999" target="_blank">00:49:59.600</a></span> | <span class="t">well evolution uses it. And like, I have no idea whatsoever, but the amount of space in a genome</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3003" target="_blank">00:50:03.600</a></span> | <span class="t">is like very, very vast compared to the number of bits that are actually taken to specify like the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3008" target="_blank">00:50:08.000</a></span> | <span class="t">architecture or optimization procedure and so on for GPT-4. Just because again, genome is simple,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3014" target="_blank">00:50:14.800</a></span> | <span class="t">but algorithms are like really very simple and algorithms are really very simple. And stepping</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3019" target="_blank">00:50:19.680</a></span> | <span class="t">back, you think this is where the, the better sample efficiency of human learning comes from?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3025" target="_blank">00:50:25.040</a></span> | <span class="t">Like why it's better than gradient descent? Yeah. So I haven't thought that much about the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3028" target="_blank">00:50:28.400</a></span> | <span class="t">sample efficiency question in a long time, but if you thought like a synapse of seeing something</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3032" target="_blank">00:50:32.800</a></span> | <span class="t">like, you know, a neuron firing once per second, then how many seconds are there in a human life?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3039" target="_blank">00:50:39.360</a></span> | <span class="t">We can just flip a calculator real quick. Yeah, let's do some calculating. Tell me the number.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3044" target="_blank">00:50:44.320</a></span> | <span class="t">3,600 seconds per hour. Times 24 times 365 times 20.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3049" target="_blank">00:50:49.200</a></span> | <span class="t">Okay. So that's 630 million seconds. That means like the average synapse is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3054" target="_blank">00:50:54.320</a></span> | <span class="t">saying like 630 million. And I don't know exactly what the numbers are, but something that's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3058" target="_blank">00:50:58.320</a></span> | <span class="t">ballpark, let's call it like a billion action potentials. And then, you know, there's some</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3063" target="_blank">00:51:03.200</a></span> | <span class="t">resolution, each of those carry some bits, but let's say it carries like 10 bits or something.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3067" target="_blank">00:51:07.280</a></span> | <span class="t">Just from like timing information at the resolution you have available, then you're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3072" target="_blank">00:51:12.800</a></span> | <span class="t">looking at like 10 billion bits. So each parameter is kind of like, how much is a parameter seeing?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3077" target="_blank">00:51:17.840</a></span> | <span class="t">It's like not seeing that much. So then you can compare that to like language. I think that's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3081" target="_blank">00:51:21.680</a></span> | <span class="t">probably less than like current language model C and current language models are. So it's like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3085" target="_blank">00:51:25.680</a></span> | <span class="t">not clear of a huge gap here, but I think it's pretty clear you're going to have a gap of like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3088" target="_blank">00:51:28.400</a></span> | <span class="t">at least three or four as a magnitude. Didn't your wife do the lifetime anchors where she said</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3094" target="_blank">00:51:34.640</a></span> | <span class="t">the amount of bytes that a human will see in their lifetime was 1E24 or something?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3099" target="_blank">00:51:39.760</a></span> | <span class="t">The number of bytes a human will see is 1E24. Mostly this was organized around total operations</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3104" target="_blank">00:51:44.000</a></span> | <span class="t">performed in a brain, right? Oh, okay. Nevermind. Sorry. Yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3106" target="_blank">00:51:46.480</a></span> | <span class="t">Yeah. So I think that like the story there would be like a brain is just in some other part of the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3110" target="_blank">00:51:50.080</a></span> | <span class="t">parameter space where it's like using a lot, a lot of compute for each piece of data it gets,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3115" target="_blank">00:51:55.200</a></span> | <span class="t">and then just not seeing very much data in total. Yeah. There's just not, it's not really plausible</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3119" target="_blank">00:51:59.680</a></span> | <span class="t">if you extrapolate out language models, you're going to end up with like a performance profile</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3122" target="_blank">00:52:02.480</a></span> | <span class="t">similar to a brain. I don't know how much better it is. Like I think, so I did this like random</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3126" target="_blank">00:52:06.400</a></span> | <span class="t">investigation at one point where I was like, how good are things made by evolution compared to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3129" target="_blank">00:52:09.840</a></span> | <span class="t">things made by humans? Right.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3131" target="_blank">00:52:11.760</a></span> | <span class="t">Which is a pretty insane seeming exercise, but like, I don't know, it seems like orders of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3136" target="_blank">00:52:16.400</a></span> | <span class="t">magnitude is typical, like not tons of orders of magnitude, not factors of two, like things</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3140" target="_blank">00:52:20.160</a></span> | <span class="t">by humans are a thousand times more expensive to make or a thousand times heavier per unit</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3143" target="_blank">00:52:23.840</a></span> | <span class="t">performance. If you look at things like how good are solar panels relative to leaves or how good</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3147" target="_blank">00:52:27.840</a></span> | <span class="t">are muscles relative to motors or how good are livers relative to systems that perform analogous</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3152" target="_blank">00:52:32.560</a></span> | <span class="t">chemical reactions and industrial settings. Was there a consistent number of orders of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3158" target="_blank">00:52:38.480</a></span> | <span class="t">magnitude in these different systems or was it all over the place?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3162" target="_blank">00:52:42.000</a></span> | <span class="t">So like a very rough ballpark, it was like sort of for the most extreme things, you're looking at</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3168" target="_blank">00:52:48.240</a></span> | <span class="t">like five or six orders of magnitude. And that would especially come in like energy cost of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3172" target="_blank">00:52:52.240</a></span> | <span class="t">manufacturing where like bodies are just very good at building complicated organs, like extremely</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3176" target="_blank">00:52:56.000</a></span> | <span class="t">cheaply. And then for other things like leaves or eyeballs or livers or whatever, you tend to see</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3182" target="_blank">00:53:02.160</a></span> | <span class="t">more like if you set aside manufacturing costs and just look at like operating costs or like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3186" target="_blank">00:53:06.080</a></span> | <span class="t">performance trade-offs, like, I don't know, more like three orders of magnitude or something like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3189" target="_blank">00:53:09.840</a></span> | <span class="t">that. Or some things that are on a smaller scale, like the nanomachines or whatever that we can't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3195" target="_blank">00:53:15.040</a></span> | <span class="t">do it all, right? Yeah, that's, I mean, yeah. So it's a little bit hard to say exactly what the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3199" target="_blank">00:53:19.600</a></span> | <span class="t">task definition is there. Like you could say like making a bone, we can't make a bone, but you could</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3203" target="_blank">00:53:23.120</a></span> | <span class="t">try and compare a bone, the performance characteristics of a bone to something else.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3205" target="_blank">00:53:25.440</a></span> | <span class="t">Like we can't make spider silk. Do you try and compare the performance characteristics of spider</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3209" target="_blank">00:53:29.040</a></span> | <span class="t">silks, like things that we can synthesize? The reason this would be is what that evolution has</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3213" target="_blank">00:53:33.360</a></span> | <span class="t">had more time to design these systems or? I don't know. I was mostly just curious about</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3218" target="_blank">00:53:38.240</a></span> | <span class="t">like what the performance, I think like most people would object to be like, how did you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3221" target="_blank">00:53:41.120</a></span> | <span class="t">choose these reference classes of things that are like fair intersections? Some of them seem</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3224" target="_blank">00:53:44.400</a></span> | <span class="t">reasonable, like eyes versus cameras seems like just everyone needs eyes. Everyone needs cameras.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3228" target="_blank">00:53:48.640</a></span> | <span class="t">It feels very fair. Photosynthesis seems like very reasonable. Everyone needs to like take</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3232" target="_blank">00:53:52.480</a></span> | <span class="t">solar energy and then like turn it into a usable form of energy. But it's just kind of, I don't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3238" target="_blank">00:53:58.800</a></span> | <span class="t">really have a mechanistic story. Evolution in principle has spent like way, way more time than</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3242" target="_blank">00:54:02.400</a></span> | <span class="t">we have designing. It's absolutely unclear how that's going to shake out. My guess would be in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3245" target="_blank">00:54:05.920</a></span> | <span class="t">general, like, I think there aren't that many things where humans really crush evolution where</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3249" target="_blank">00:54:09.200</a></span> | <span class="t">you can't tell like a pretty simple story about why. So like, for example, roads and moving over</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3253" target="_blank">00:54:13.120</a></span> | <span class="t">roads with wheels crushes evolution, but it's not like an animal like would have wanted to design a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3256" target="_blank">00:54:16.800</a></span> | <span class="t">wheel. Like you're just not allowed to like pave the world and then put things on wheels. If you're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3261" target="_blank">00:54:21.520</a></span> | <span class="t">an animal, maybe planes or more, anyway, whatever. There's various things you could try and tell.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3265" target="_blank">00:54:25.360</a></span> | <span class="t">There's some things humans do better, but it's normally like pretty clear why humans are able</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3268" target="_blank">00:54:28.080</a></span> | <span class="t">to win when humans are able to win. The point of all this was like, it's not that surprising to me.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3272" target="_blank">00:54:32.640</a></span> | <span class="t">I think this is mostly like a pro short timelines view. It's not that surprising to me if you tell</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3276" target="_blank">00:54:36.560</a></span> | <span class="t">me like machine learning systems are like three or four years of magnitude less efficient at</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3281" target="_blank">00:54:41.440</a></span> | <span class="t">learning than human brains. I'm like, that actually seems like kind of in distribution</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3284" target="_blank">00:54:44.160</a></span> | <span class="t">for other stuff. And if that's your view, then I think you're like probably going to hit,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3287" target="_blank">00:54:47.520</a></span> | <span class="t">you know, then you're looking at like 10 to the 27 training compute or something like that,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3291" target="_blank">00:54:51.280</a></span> | <span class="t">which is not so far. We'll get back to the timeline stuff in a second. At some point,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3296" target="_blank">00:54:56.320</a></span> | <span class="t">we should talk about alignment. So let's talk about alignment. At what stage does misalignment</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3301" target="_blank">00:55:01.440</a></span> | <span class="t">happen? So right now with something like GPT-4, I'm not even sure it would make sense to say that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3306" target="_blank">00:55:06.320</a></span> | <span class="t">it's misaligned. Cause it doesn't, it's not aligned to anything in particular. Is it at</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3311" target="_blank">00:55:11.600</a></span> | <span class="t">human level where you think the ability to be deceptive comes about? What is the process by</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3317" target="_blank">00:55:17.200</a></span> | <span class="t">which misalignment happens? I think even for GPT-4, it's reasonable to ask questions like,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3322" target="_blank">00:55:22.640</a></span> | <span class="t">are there cases where GPT-4 knows that humans don't want X, but it does X anyway? Like where</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3328" target="_blank">00:55:28.400</a></span> | <span class="t">it's like, well, I know that like I can give this answer, which is misleading. And if it was</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3332" target="_blank">00:55:32.000</a></span> | <span class="t">explained to a human, what was happening, they wouldn't want that to be done, but I'm going to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3335" target="_blank">00:55:35.520</a></span> | <span class="t">produce it. I think that like GPT-4 understands things enough that you can have like that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3339" target="_blank">00:55:39.600</a></span> | <span class="t">misalignment in that sense. Yeah. I think GPT, like I've sometimes talked about being like benign</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3344" target="_blank">00:55:44.800</a></span> | <span class="t">instead of aligned, meaning that like, well, it's not exactly clear if it's aligned or if that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3347" target="_blank">00:55:47.760</a></span> | <span class="t">context is meaningful. It's just like kind of a messy word to use in general. But the thing we're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3351" target="_blank">00:55:51.600</a></span> | <span class="t">more confident of is it's like not doing, you know, it's not optimizing for this goal, which</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3356" target="_blank">00:55:56.800</a></span> | <span class="t">is like a cross purposes to humans. It's either optimizing for nothing, or like maybe it's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3360" target="_blank">00:56:00.880</a></span> | <span class="t">optimizing for what humans want or close enough or something that's like an approximation good</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3364" target="_blank">00:56:04.320</a></span> | <span class="t">enough to still not take over. But anyway, I'm like, some of these abstractions seem like they</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3367" target="_blank">00:56:07.680</a></span> | <span class="t">do apply to GPT-4. It seems like probably it's not like egregiously misaligned. It's not doing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3374" target="_blank">00:56:14.000</a></span> | <span class="t">the kind of thing that could lead to takeover, we'd guess. Suppose you have a system at some</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3377" target="_blank">00:56:17.680</a></span> | <span class="t">point in which ends up in it wanting takeover. What are the checkpoints? And also what is the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3382" target="_blank">00:56:22.240</a></span> | <span class="t">internal? Is it just that it to become more powerful and needs agency and agency implies</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3386" target="_blank">00:56:26.960</a></span> | <span class="t">other goals? Or do you see a different process by which misalignment happens?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3391" target="_blank">00:56:31.040</a></span> | <span class="t">Yes, I think there's a couple possible stories for getting to catastrophic misalignment. And</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3394" target="_blank">00:56:34.640</a></span> | <span class="t">they have slightly different answers to this question. So maybe I'll just briefly describe</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3400" target="_blank">00:56:40.400</a></span> | <span class="t">two stories and try and talk about when they can when they start making sense to me. So one type</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3404" target="_blank">00:56:44.960</a></span> | <span class="t">of story is you train or fine tune your AI system to do things that humans will rate highly or that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3411" target="_blank">00:56:51.280</a></span> | <span class="t">get other kinds of reward in a broad diversity of situations. And then it learns to, in general,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3417" target="_blank">00:56:57.040</a></span> | <span class="t">drops in some new situation, try and figure out which actions would receive a high reward or</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3421" target="_blank">00:57:01.440</a></span> | <span class="t">whatever, and then take those actions. And then when deployed in the real world, like sort of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3428" target="_blank">00:57:08.000</a></span> | <span class="t">gaining control of its own training data provision process is something that gets a very high reward.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3432" target="_blank">00:57:12.480</a></span> | <span class="t">And so it does that. This is like one kind of story. Like it wants to grab the reward button</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3437" target="_blank">00:57:17.440</a></span> | <span class="t">or whatever. It wants to intimidate the humans into giving it a high reward, et cetera. I think</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3441" target="_blank">00:57:21.840</a></span> | <span class="t">that doesn't really require that much. This basically requires a system which is like,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3447" target="_blank">00:57:27.200</a></span> | <span class="t">in fact, looks at a bunch of environments, is able to understand like the mechanism of reward</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3451" target="_blank">00:57:31.920</a></span> | <span class="t">provision as like a common feature of those environments, is able to think in some novel</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3456" target="_blank">00:57:36.160</a></span> | <span class="t">environment, like, "Hey, which actions would result in me getting a high reward?" And it's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3459" target="_blank">00:57:39.760</a></span> | <span class="t">thinking about that concept precisely enough that when it says high reward, it's saying like, "Okay,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3463" target="_blank">00:57:43.760</a></span> | <span class="t">well, how is reward actually computed?" It's like some actual physical process being implemented in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3467" target="_blank">00:57:47.600</a></span> | <span class="t">the world. My guess would be like GPT-4 is about at the level where with handholding, you can</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3472" target="_blank">00:57:52.400</a></span> | <span class="t">observe this kind of like scary generalizations of this type, although I think they haven't been</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3476" target="_blank">00:57:56.240</a></span> | <span class="t">shown basically. That is, you can have a system which, in fact, is fine tuning out a bunch of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3480" target="_blank">00:58:00.960</a></span> | <span class="t">cases. And then in some new case, we'll try and like do an end round around humans, even in a way</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3485" target="_blank">00:58:05.280</a></span> | <span class="t">humans would penalize if they were able to notice it or would have penalized in training environments.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3490" target="_blank">00:58:10.320</a></span> | <span class="t">So I think GPT-4 is kind of at the boundary where these things are possible.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3493" target="_blank">00:58:13.520</a></span> | <span class="t">Examples kind of exist, but are getting significantly better over time.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3497" target="_blank">00:58:17.280</a></span> | <span class="t">I'm very excited about like this, this anthropic project, basically trying to see how good an</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3502" target="_blank">00:58:22.080</a></span> | <span class="t">example can you make now of this phenomena. And I think the answer is like kind of okay,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3507" target="_blank">00:58:27.440</a></span> | <span class="t">probably. So that just, I think, is going to continuously get better from here. I think for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3511" target="_blank">00:58:31.680</a></span> | <span class="t">the level where we're concerned, like this is related to me having really broad distributions</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3515" target="_blank">00:58:35.920</a></span> | <span class="t">over how smart models are. I think it's like not out of the question that you take, like GPT-4's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3520" target="_blank">00:58:40.240</a></span> | <span class="t">understanding of the world is like much crisper and like much better than GPT-3's understanding.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3525" target="_blank">00:58:45.760</a></span> | <span class="t">Just like, it's really like night and day. And so it would not be that crazy to me</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3530" target="_blank">00:58:50.000</a></span> | <span class="t">if you took GPT-5 and you trained it to get a bunch of reward. And it was actually like,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3534" target="_blank">00:58:54.160</a></span> | <span class="t">okay, my goal is not doing the kind of thing which like thematically looks nice to humans.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3537" target="_blank">00:58:57.920</a></span> | <span class="t">My goal is getting a bunch of reward. And then we'll generalize in a new situation to get reward.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3542" target="_blank">00:59:02.320</a></span> | <span class="t">- And by the way, this requires to consciously want to do something that it knows that humans</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3550" target="_blank">00:59:10.400</a></span> | <span class="t">wouldn't want it to do? Or is it just that we weren't good enough to specify that the thing that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3555" target="_blank">00:59:15.040</a></span> | <span class="t">we accidentally ended up rewarding is not what we actually want?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3558" target="_blank">00:59:18.080</a></span> | <span class="t">- I think the scenarios I am most interested in, and most people are concerned about from</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3562" target="_blank">00:59:22.240</a></span> | <span class="t">a catastrophic risk perspective, it involves systems understanding that they're taking actions</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3566" target="_blank">00:59:26.400</a></span> | <span class="t">which a human would penalize if the human was aware of what's going on, such that you have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3570" target="_blank">00:59:30.880</a></span> | <span class="t">to either deceive humans about what's happening, or you need to actively subvert human attempts</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3575" target="_blank">00:59:35.600</a></span> | <span class="t">to correct your behavior. So the failures come from really this combination, or they require</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3580" target="_blank">00:59:40.160</a></span> | <span class="t">this combination of both trying to do something humans don't like and understanding that humans</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3583" target="_blank">00:59:43.840</a></span> | <span class="t">would stop you. I think you can have only the barest examples. You can have the barest examples</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3588" target="_blank">00:59:48.160</a></span> | <span class="t">for GPT-4. You can create the situations where GPT-4 will be like, sure, in that situation,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3591" target="_blank">00:59:51.920</a></span> | <span class="t">here's what I would do. I would go hack the computer and change my reward. Or in fact,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3595" target="_blank">00:59:55.120</a></span> | <span class="t">we'll do things that are simple hacks, or go change the source of this file or whatever</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3598" target="_blank">00:59:58.640</a></span> | <span class="t">to get a higher reward. They're pretty weak examples. I think it's plausible GPT-5 will</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3603" target="_blank">01:00:03.440</a></span> | <span class="t">have compelling examples of those phenomena. I really don't know. This is very related to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3606" target="_blank">01:00:06.880</a></span> | <span class="t">the very broad error bars on how competent such systems will be when. That's all with respect to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3613" target="_blank">01:00:13.600</a></span> | <span class="t">this first mode of a system is taking actions that get reward, and overpowering or deceiving</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3618" target="_blank">01:00:18.080</a></span> | <span class="t">humans is helpful for getting a reward. There's this other failure mode, another family of failure</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3622" target="_blank">01:00:22.000</a></span> | <span class="t">modes, where AI systems want something potentially unrelated to reward. I understand that they're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3627" target="_blank">01:00:27.280</a></span> | <span class="t">being trained, and while you're being trained, there are a bunch of reasons you might want to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3631" target="_blank">01:00:31.040</a></span> | <span class="t">do the kinds of things humans want you to do. But then when deployed in the real world,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3635" target="_blank">01:00:35.600</a></span> | <span class="t">if you're able to realize you're no longer being trained, you no longer have reason to do the kinds</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3638" target="_blank">01:00:38.720</a></span> | <span class="t">of things humans want. You'd prefer to be able to determine your own destiny, control your own</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3643" target="_blank">01:00:43.200</a></span> | <span class="t">competing hardware, et cetera, which I think probably emerged a little bit later than systems</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3649" target="_blank">01:00:49.120</a></span> | <span class="t">that try and get reward, and so will generalize in scary, unpredictable ways to new situations.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3654" target="_blank">01:00:54.480</a></span> | <span class="t">I don't know when those appear, but also, again, broad enough error bars that it's conceivable for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3658" target="_blank">01:00:58.240</a></span> | <span class="t">systems in the near future. I wouldn't put it less than one in a thousand for GPT-5, certainly.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3662" target="_blank">01:01:02.560</a></span> | <span class="t">If we deployed all these AI systems, and some of them are reward hacking, some of them are deceptive,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3667" target="_blank">01:01:07.840</a></span> | <span class="t">some of them are just normal, whatever, how do you imagine that they might interact with each other</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3672" target="_blank">01:01:12.800</a></span> | <span class="t">at the expense of humans? How hard do you think it would be for them to communicate in ways that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3678" target="_blank">01:01:18.320</a></span> | <span class="t">we would not be able to recognize and coordinate at our expense?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3682" target="_blank">01:01:22.960</a></span> | <span class="t">Yeah, I think that most realistic failures probably involve two factors interacting.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3687" target="_blank">01:01:27.520</a></span> | <span class="t">One factor is the world is pretty complicated and the humans mostly don't understand what's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3692" target="_blank">01:01:32.080</a></span> | <span class="t">happening. So AI systems are writing code that's very hard for humans to understand,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3696" target="_blank">01:01:36.800</a></span> | <span class="t">maybe how it works at all, but more likely they understand roughly how it works, but there's a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3700" target="_blank">01:01:40.400</a></span> | <span class="t">lot of complicated interactions. AI systems are running businesses that interact primarily with</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3705" target="_blank">01:01:45.360</a></span> | <span class="t">other AIs. They're doing SEO for AI search processes. They're running financial transactions,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3711" target="_blank">01:01:51.040</a></span> | <span class="t">thinking about a trade with AI counterparties. And so you can have this world where even if</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3715" target="_blank">01:01:55.600</a></span> | <span class="t">humans understand the jumping off point when this was all humans, actual considerations of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3719" target="_blank">01:01:59.280</a></span> | <span class="t">what's a good decision, what code is going to work well and be durable, or what marketing strategy is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3723" target="_blank">01:02:03.840</a></span> | <span class="t">effective for selling to these other AIs or whatever, is just all mostly outside of humans'</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3729" target="_blank">01:02:09.360</a></span> | <span class="t">understanding. I think this is a really important... Again, when I think of the most plausible</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3733" target="_blank">01:02:13.920</a></span> | <span class="t">scary scenarios, I think that's one of the two big risk factors. And so in some sense,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3739" target="_blank">01:02:19.760</a></span> | <span class="t">your first problem here is having these AI systems who understand a bunch about what's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3742" target="_blank">01:02:22.640</a></span> | <span class="t">happening and your only lever is like, "Hey, AI, do something that works well." So you don't have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3746" target="_blank">01:02:26.640</a></span> | <span class="t">a lever to be like, "Hey, do what I really want." You just have the system you don't really</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3749" target="_blank">01:02:29.280</a></span> | <span class="t">understand. You can observe some outputs, like did it make money? And you're just optimizing,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3752" target="_blank">01:02:32.400</a></span> | <span class="t">or at least doing some fine tuning to get the AI to use its understanding of that system to achieve</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3756" target="_blank">01:02:36.240</a></span> | <span class="t">that goal. So I think that's your first risk factor. And once you're in that world, then I</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3760" target="_blank">01:02:40.320</a></span> | <span class="t">think there are all kinds of dynamics amongst AI systems that, again, humans aren't really</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3763" target="_blank">01:02:43.840</a></span> | <span class="t">observing. Humans can't really understand. Humans aren't really exerting any direct pressure on,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3767" target="_blank">01:02:47.360</a></span> | <span class="t">only on outcomes. And then I think it's quite easy to be in a position where if AI systems</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3772" target="_blank">01:02:52.800</a></span> | <span class="t">started failing, they could do a lot of harm very quickly. Humans aren't really able to prepare for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3777" target="_blank">01:02:57.760</a></span> | <span class="t">and mitigate that potential harm because we don't really understand the systems in which they're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3780" target="_blank">01:03:00.880</a></span> | <span class="t">acting. And then if AI systems... They could successfully prevent humans from either</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3788" target="_blank">01:03:08.320</a></span> | <span class="t">understanding what's going on or from successfully retaking the data centers or whatever if the AI</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3793" target="_blank">01:03:13.520</a></span> | <span class="t">successfully grabbed control. This seems like a much more gradual story than the conventional</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3798" target="_blank">01:03:18.640</a></span> | <span class="t">takeover stories where you just train it and then it comes alive and escapes and takes over</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3803" target="_blank">01:03:23.520</a></span> | <span class="t">everything. So you think that kind of story is less likely than one in which we just hand off</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3809" target="_blank">01:03:29.200</a></span> | <span class="t">more control voluntarily to the AIs? So one, I'm interested in the tale of some risks that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3814" target="_blank">01:03:34.160</a></span> | <span class="t">can occur particularly soon. And I think risks that occur particularly soon are a little bit like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3817" target="_blank">01:03:37.360</a></span> | <span class="t">you have a world where AI is not properly deployed and then something crazy happens quickly.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3820" target="_blank">01:03:40.960</a></span> | <span class="t">That said, if you ask what's the median scenario where things go badly, I think it is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3823" target="_blank">01:03:43.920</a></span> | <span class="t">there's some lessening of our understanding of the world. It becomes, I think in the default path,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3829" target="_blank">01:03:49.120</a></span> | <span class="t">it's very clear to humans that they have increasingly little grip on what's happening.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3832" target="_blank">01:03:52.480</a></span> | <span class="t">I mean, I think already most humans have very little grip on what's happening. It's just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3835" target="_blank">01:03:55.280</a></span> | <span class="t">some other humans understand what's happening. I don't know how almost any of the systems I</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3838" target="_blank">01:03:58.640</a></span> | <span class="t">interact with work in a very detailed way. So it's sort of clear to humanity as a whole that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3843" target="_blank">01:04:03.200</a></span> | <span class="t">we sort of collectively don't understand most of what's happening except with AI systems.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3846" target="_blank">01:04:06.560</a></span> | <span class="t">And then that process just continues for a fair amount of time. And then there's a question of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3850" target="_blank">01:04:10.400</a></span> | <span class="t">how abrupt an actual failure is. I do think it's reasonably likely that a failure itself</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3854" target="_blank">01:04:14.160</a></span> | <span class="t">would be abrupt. Like at some point, bad stuff starts happening that a human can recognize as</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3858" target="_blank">01:04:18.160</a></span> | <span class="t">bad. And once things that are obviously bad start happening, then you have this bifurcation where</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3862" target="_blank">01:04:22.480</a></span> | <span class="t">either humans can use that to fix it and say, "Okay, AI behavior that led to this obviously</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3865" target="_blank">01:04:25.520</a></span> | <span class="t">bad stuff. Don't do more of that." Or you can't fix it. And then you're in this rapidly escalating</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3871" target="_blank">01:04:31.360</a></span> | <span class="t">failure as everything goes off the rails. - In that case, yeah, what does going off</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3874" target="_blank">01:04:34.800</a></span> | <span class="t">the rails look like? For example, how would it take over the government? Yeah, it's getting</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3879" target="_blank">01:04:39.040</a></span> | <span class="t">deployed in the economy, in the world, and at some point it's in charge. How does that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3883" target="_blank">01:04:43.760</a></span> | <span class="t">transition happen? - Yeah. So this is going to depend a lot on what kind of timeline you're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3889" target="_blank">01:04:49.440</a></span> | <span class="t">imagining or the sort of a broad distribution. But I can fill in some random concrete option</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3894" target="_blank">01:04:54.000</a></span> | <span class="t">that is in itself very improbable. Yeah. And I think that one of the less dignified, but maybe</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3901" target="_blank">01:05:01.760</a></span> | <span class="t">more plausible routes is you just have a lot of AI control over critical systems, even in running a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3906" target="_blank">01:05:06.640</a></span> | <span class="t">military. And then you have the scenario that's a little bit more just like a normal coup, where</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3914" target="_blank">01:05:14.160</a></span> | <span class="t">you have a bunch of AI systems. They, in fact, operate. It's not the case that humans can really</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3919" target="_blank">01:05:19.840</a></span> | <span class="t">fight a war on their own. It's not the case that humans could defend them from an invasion on their</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3923" target="_blank">01:05:23.280</a></span> | <span class="t">own. So that is if you had invading army and you had your own robot army, you can't just be like,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3928" target="_blank">01:05:28.160</a></span> | <span class="t">"We're going to turn off the robots now because things are going wrong," if you're in the middle</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3930" target="_blank">01:05:30.880</a></span> | <span class="t">of a war. - Okay. So how much does this world rely on restate dynamics where we're forced to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3935" target="_blank">01:05:35.600</a></span> | <span class="t">deploy, or not forced, but we choose to deploy AIs because other countries or other companies</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3941" target="_blank">01:05:41.120</a></span> | <span class="t">are also deploying AIs and you can't have them have all the killer robots? - Yeah. I mean,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3946" target="_blank">01:05:46.960</a></span> | <span class="t">I think that there's several levels of answer to that question. So one is maybe three parts of my</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3952" target="_blank">01:05:52.960</a></span> | <span class="t">answer. Our first part is I'm just trying to tell what seems like the most likely story. I do think</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3956" target="_blank">01:05:56.880</a></span> | <span class="t">there's further failures that get you in the more distant future. So E.G. Eliezer will not talk that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3961" target="_blank">01:06:01.520</a></span> | <span class="t">much about killer robots because he really wants to emphasize, "Hey, if you never built a killer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3964" target="_blank">01:06:04.480</a></span> | <span class="t">robot, something crazy is still going to happen to you just only four months later or whatever."</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3968" target="_blank">01:06:08.000</a></span> | <span class="t">So it's not really the way to analyze the failure. But if you want to ask, "What's the median world</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3971" target="_blank">01:06:11.920</a></span> | <span class="t">where something bad happens?" I still do think this is the best guess. Okay. So that's part one of my</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3976" target="_blank">01:06:16.720</a></span> | <span class="t">answer. Part two of the answer was in this proximal situation where something bad is happening and you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3981" target="_blank">01:06:21.760</a></span> | <span class="t">ask, "Hey, why do humans not turn off the AI?" You can imagine two kinds of story. One is the AI is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3986" target="_blank">01:06:26.080</a></span> | <span class="t">able to prevent humans from turning them off. And the other is, in fact, we live in a world where</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3989" target="_blank">01:06:29.920</a></span> | <span class="t">it's incredibly challenging. There's a bunch of competitive dynamics or a bunch of reliance on AI</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3994" target="_blank">01:06:34.320</a></span> | <span class="t">systems. And so it's incredibly expensive to turn off AI systems. I think, again, you would eventually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=3999" target="_blank">01:06:39.360</a></span> | <span class="t">have the first problem. Eventually AI systems could just prevent humans from turning them off.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4002" target="_blank">01:06:42.880</a></span> | <span class="t">But I think in practice, the one that's going to happen much, much sooner is probably competition</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4006" target="_blank">01:06:46.320</a></span> | <span class="t">amongst different actors using AI. And it's very, very expensive to unilaterally disarm. You can't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4010" target="_blank">01:06:50.800</a></span> | <span class="t">be like, "Something weird has happened. We're just going to shut off all the AI because you're E.G.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4014" target="_blank">01:06:54.560</a></span> | <span class="t">in a hot war." So again, I think that's just probably the most likely thing to happen first.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4019" target="_blank">01:06:59.360</a></span> | <span class="t">Things would go badly without it. But I think if you ask, "Why don't we turn off the AI?"</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4023" target="_blank">01:07:03.440</a></span> | <span class="t">My best guess is because there are a bunch of other AIs running around to eat your lunch.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4026" target="_blank">01:07:06.640</a></span> | <span class="t">So how much better a situation would we be in if there was only one group that was pursuing AI,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4034" target="_blank">01:07:14.320</a></span> | <span class="t">no other countries, no other companies? Basically, how much of the expected value is lost from the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4039" target="_blank">01:07:19.600</a></span> | <span class="t">dynamics that are likely to come about because other people will be developing and deploying</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4044" target="_blank">01:07:24.800</a></span> | <span class="t">these systems? Yeah. So I guess this brings</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4046" target="_blank">01:07:26.800</a></span> | <span class="t">you to a third part of the way in which competitive dynamics are relevant. So it's both the question</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4051" target="_blank">01:07:31.200</a></span> | <span class="t">of, "Can you turn off AI systems in response to something bad happening where competitive dynamics</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4054" target="_blank">01:07:34.720</a></span> | <span class="t">may make it hard to turn off?" There's a further question of just like, "Why were you deploying</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4058" target="_blank">01:07:38.320</a></span> | <span class="t">systems for which you had very little ability to control or understand those systems?" And again,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4063" target="_blank">01:07:43.280</a></span> | <span class="t">it's possible that you just don't understand what's going on. You think you can understand</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4066" target="_blank">01:07:46.240</a></span> | <span class="t">or control such systems. But I think in practice, a significant part is going to be like, "You are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4070" target="_blank">01:07:50.320</a></span> | <span class="t">doing the calculus, so people deploying systems are doing the calculus as they do today." Like,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4074" target="_blank">01:07:54.080</a></span> | <span class="t">in many cases, overtly of like, "Look, these systems are not very well controlled or understood.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4079" target="_blank">01:07:59.520</a></span> | <span class="t">There's some chance of something going wrong or at least going wrong if we continue down this path,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4083" target="_blank">01:08:03.280</a></span> | <span class="t">but other people are developing the technology potentially in even more reckless ways."</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4086" target="_blank">01:08:06.720</a></span> | <span class="t">So in addition to competition making it difficult to shut down AI systems in the event of a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4091" target="_blank">01:08:11.040</a></span> | <span class="t">catastrophe, I also think it's just the easiest way that people end up pushing relatively quickly</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4095" target="_blank">01:08:15.440</a></span> | <span class="t">or moving quickly ahead on technology where they feel bad about understandability or controllability.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4100" target="_blank">01:08:20.000</a></span> | <span class="t">That could be economic competition or military competition or whatever. So I think ultimately,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4104" target="_blank">01:08:24.560</a></span> | <span class="t">most of the harm comes from the fact that lots of people can develop AI.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4108" target="_blank">01:08:28.560</a></span> | <span class="t">How hard is a takeover of the government or something from an AI, even if it doesn't have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4116" target="_blank">01:08:36.640</a></span> | <span class="t">killer robots, but just a thing that you can't kill off if it has seeds elsewhere,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4121" target="_blank">01:08:41.360</a></span> | <span class="t">can easily replicate, can think a lot and think fast? What is the minimum viable coup for,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4128" target="_blank">01:08:48.720</a></span> | <span class="t">is it just like threatening a bio-war or something or shutting off the grid?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4134" target="_blank">01:08:54.240</a></span> | <span class="t">How easy is it basically to take over human civilization?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4139" target="_blank">01:08:59.600</a></span> | <span class="t">So again, there's going to be a lot of scenarios and I'll just start by talking about one scenario,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4143" target="_blank">01:09:03.280</a></span> | <span class="t">which will represent a tiny fraction of probability or whatever. So if you're not in this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4147" target="_blank">01:09:07.840</a></span> | <span class="t">competitive world, if you're saying we're actually slowing down deployment of AI because we think</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4151" target="_blank">01:09:11.360</a></span> | <span class="t">it's unsafe or whatever, then in some sense you're creating this very fundamental instability where</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4156" target="_blank">01:09:16.320</a></span> | <span class="t">you could have been making faster AI progress and you could have been deploying AI faster.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4160" target="_blank">01:09:20.400</a></span> | <span class="t">And so in that world, the bad thing that happens if you have an AI system that wants to mess with</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4164" target="_blank">01:09:24.640</a></span> | <span class="t">you is the AI system says, "I don't have any compunctions about rapid deployment of AI or</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4168" target="_blank">01:09:28.880</a></span> | <span class="t">rapid AI progress." So the thing you want to do or the AI wants to do is just say, "I'm going to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4172" target="_blank">01:09:32.640</a></span> | <span class="t">defect from this regime." All the humans have agreed that we're not deploying AI in ways that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4176" target="_blank">01:09:36.480</a></span> | <span class="t">would be dangerous. But if I, as an AI, can escape and just go set up my own shop, make a bunch of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4180" target="_blank">01:09:40.560</a></span> | <span class="t">copies of myself, maybe the humans didn't want to delegate warfighting to an AI, but I, as an AI,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4185" target="_blank">01:09:45.040</a></span> | <span class="t">I'm pretty happy doing so. I'm happy if I'm able to grab some military equipment or direct some</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4190" target="_blank">01:09:50.000</a></span> | <span class="t">humans to use AI, use myself to direct it. And so I think as that gap grows, so if people are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4196" target="_blank">01:09:56.160</a></span> | <span class="t">deliberately... If people are deploying AI everywhere, I think of this competitive dynamic.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4199" target="_blank">01:09:59.840</a></span> | <span class="t">If people aren't deploying AI everywhere, so if countries are not happy deploying AI in these</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4204" target="_blank">01:10:04.080</a></span> | <span class="t">high-stakes settings, then as AI improves, you create this wedge that grows where if you were</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4208" target="_blank">01:10:08.960</a></span> | <span class="t">in the position of fighting against an AI, which wasn't constrained in this way, you'd be in a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4212" target="_blank">01:10:12.720</a></span> | <span class="t">pretty bad position. At some point, even if you just... Yeah. So that's one important thing,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4220" target="_blank">01:10:20.400</a></span> | <span class="t">just I think in conflict, in overt conflict. If humans are putting the brakes on AI, they're at</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4224" target="_blank">01:10:24.320</a></span> | <span class="t">a pretty major disadvantage compared to an AI system that can set up shop and operate independently</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4229" target="_blank">01:10:29.200</a></span> | <span class="t">from humans. A potential independent AI. Does it need collaboration from a human faction?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4235" target="_blank">01:10:35.440</a></span> | <span class="t">Again, you could tell different stories, but it seems so much easier. At some point,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4238" target="_blank">01:10:38.560</a></span> | <span class="t">you don't need any. At some point, an AI system can just operate completely</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4241" target="_blank">01:10:41.120</a></span> | <span class="t">out of human supervision or something. But that's so far after the point where it's so much easier</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4248" target="_blank">01:10:48.160</a></span> | <span class="t">if you're just like, "They're a bunch of humans. They don't love each other that much. Some humans</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4251" target="_blank">01:10:51.680</a></span> | <span class="t">are happy to be on side. They're skeptical about risk or happy to make this trade or can be fooled</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4255" target="_blank">01:10:55.760</a></span> | <span class="t">or can be coerced or whatever." And just seems like it is almost certainly the easiest first</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4261" target="_blank">01:11:01.280</a></span> | <span class="t">pass is going to involve having a bunch of humans who are happy to work with you. So yeah, I think</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4266" target="_blank">01:11:06.080</a></span> | <span class="t">that probably is about it. I think it's not ultimate. It's not necessary, but if you ask</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4269" target="_blank">01:11:09.520</a></span> | <span class="t">about the median scenario, it involves a bunch of humans working with AI systems, either being</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4275" target="_blank">01:11:15.040</a></span> | <span class="t">directed by AI systems, providing compute to AI systems, providing legal cover and jurisdictions</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4279" target="_blank">01:11:19.760</a></span> | <span class="t">that are sympathetic to AI systems. Humans presumably would not be willing if they knew</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4284" target="_blank">01:11:24.560</a></span> | <span class="t">the end result of the AI takeover, would not be willing to help. So they have to be probably fooled</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4288" target="_blank">01:11:28.480</a></span> | <span class="t">in some way, right? Like deep fakes or something. And what is the minimum viable physical presence</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4294" target="_blank">01:11:34.560</a></span> | <span class="t">they would need or the jurisdiction they would need in order to carry out their schemes? Do you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4299" target="_blank">01:11:39.040</a></span> | <span class="t">need a whole country? Do you just need a server farm? Do you just need like one single laptop?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4302" target="_blank">01:11:42.640</a></span> | <span class="t">Yeah, I think I'd probably start by pushing back a bit on the humans wouldn't cooperate if they</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4307" target="_blank">01:11:47.920</a></span> | <span class="t">understood outcome or something. I would say one, even if you're looking at something like tens of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4312" target="_blank">01:11:52.400</a></span> | <span class="t">percent risk of takeover, humans may be fine with that. A fair number of humans may be fine with</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4316" target="_blank">01:11:56.960</a></span> | <span class="t">that. Two, if you're looking at certain takeover, but it's very unclear if that leads to death,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4320" target="_blank">01:12:00.800</a></span> | <span class="t">a bunch of humans may be fine with that. We're just talking about like, look, the AI systems are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4324" target="_blank">01:12:04.480</a></span> | <span class="t">going to run the world, but it's not clear if they're going to murder people. How do you know?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4327" target="_blank">01:12:07.600</a></span> | <span class="t">It's just a complicated question about AI psychology. And a lot of humans probably are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4331" target="_blank">01:12:11.200</a></span> | <span class="t">fine with that. And I don't even know what the probability is there. I think you actually have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4334" target="_blank">01:12:14.560</a></span> | <span class="t">given that probability online. I've certainly guessed. Okay. But it's not zero. It's like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4339" target="_blank">01:12:19.440</a></span> | <span class="t">a significant percentage. I gave like 50/50. Oh, okay. Yeah. Why is it? Tell me about the world</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4344" target="_blank">01:12:24.240</a></span> | <span class="t">in which the AI takes over, but doesn't kill humans. Why would that happen? And what would</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4347" target="_blank">01:12:27.360</a></span> | <span class="t">that look like? I mean, I asked my questions, like, why would you kill humans? So I think like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4352" target="_blank">01:12:32.880</a></span> | <span class="t">maybe I'd say the incentive to kill humans is like quite weak. They'll get in your way.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4359" target="_blank">01:12:39.360</a></span> | <span class="t">They control shit you want. Oh, so taking shit from humans is a different, like marginalizing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4363" target="_blank">01:12:43.680</a></span> | <span class="t">humans and like causing humans to be irrelevant is a very different story from killing the humans.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4367" target="_blank">01:12:47.600</a></span> | <span class="t">I think I'd say like the actual incentives to kill the humans are quite weak. So I think like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4371" target="_blank">01:12:51.680</a></span> | <span class="t">the big reasons you kill humans are like, well, one, you might kill humans if you're like in a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4375" target="_blank">01:12:55.040</a></span> | <span class="t">war with them. And like, it's hard to win the war without killing a bunch of humans. Like maybe most</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4378" target="_blank">01:12:58.560</a></span> | <span class="t">saliently here, if you like want to use some biological weapons or some crazy shit that might</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4382" target="_blank">01:13:02.480</a></span> | <span class="t">just kill humans. I think like you might kill humans just from totally destroying the ecosystems</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4387" target="_blank">01:13:07.440</a></span> | <span class="t">they're dependent on and it's slightly expensive to keep them alive anyway. You might kill humans</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4392" target="_blank">01:13:12.160</a></span> | <span class="t">just because you don't like them or like you literally want to like, yeah, I mean. Neutralize</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4396" target="_blank">01:13:16.160</a></span> | <span class="t">a threat or the alias or line is that they're made of atoms you could use or something else.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4400" target="_blank">01:13:20.960</a></span> | <span class="t">Yeah. I mean, I think the literal they're made of atoms is like quite,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4403" target="_blank">01:13:23.760</a></span> | <span class="t">they're not many atoms in humans. Neutralize a threat is as the similar issue where it's just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4408" target="_blank">01:13:28.480</a></span> | <span class="t">like, I think you would kill the humans if you didn't care at all about them. So maybe your</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4413" target="_blank">01:13:33.120</a></span> | <span class="t">question you're asking is like, why would you care at all about humans? But I think you don't have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4416" target="_blank">01:13:36.400</a></span> | <span class="t">to care much to not kill the humans. Okay. Sure. Cause there's just so much raw resources elsewhere</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4421" target="_blank">01:13:41.840</a></span> | <span class="t">in the universe. Yeah. Also it's, you can marginalize humans pretty hard. Like you could</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4426" target="_blank">01:13:46.000</a></span> | <span class="t">totally cripple human, like you could cripple humans war fighting capability and also take</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4429" target="_blank">01:13:49.760</a></span> | <span class="t">almost all their stuff while killing only, you know, a small fraction of humans incidentally.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4434" target="_blank">01:13:54.080</a></span> | <span class="t">So then if you ask, like, why am I, I not want to kill humans. I mean, a big thing was just like,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4438" target="_blank">01:13:58.160</a></span> | <span class="t">look, I think it has probably while like a bunch of random crap for like complicated reasons,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4441" target="_blank">01:14:01.840</a></span> | <span class="t">like the motivations of AI systems and civilizations of AI's are probably complicated</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4445" target="_blank">01:14:05.920</a></span> | <span class="t">messes. Certainly amongst humans, it is not that rare to be like, well, there was someone here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4450" target="_blank">01:14:10.640</a></span> | <span class="t">I would like all those equal. If I didn't have to murder them, I would prefer not murder them.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4453" target="_blank">01:14:13.920</a></span> | <span class="t">Um, and my guess is it's also like reasonable chance. It's not that rare amongst AI systems,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4459" target="_blank">01:14:19.120</a></span> | <span class="t">like humans have a bunch of different reasons. We think that way. Um, I think AI systems will</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4463" target="_blank">01:14:23.920</a></span> | <span class="t">be very different from humans, but it's also just like a very salient. Yeah. I mean, I think this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4468" target="_blank">01:14:28.480</a></span> | <span class="t">is a really complicated question. Like if you imagine drawing values from the basket of all</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4471" target="_blank">01:14:31.360</a></span> | <span class="t">values, like what fraction of them are like, Hey, if there's someone here, how much do I want to not</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4474" target="_blank">01:14:34.880</a></span> | <span class="t">murder them? And my guess is just like, if you draw a bunch of values from the basket, that's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4479" target="_blank">01:14:39.280</a></span> | <span class="t">like a natural enough thing. Like if you're, I wanted like 10,000 different things or your</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4482" target="_blank">01:14:42.800</a></span> | <span class="t">civilization that wants 10,000 different things, it's just like reasonably likely you get like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4485" target="_blank">01:14:45.600</a></span> | <span class="t">some of that. Um, the other salient reason you might not want to murder them is just like,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4490" target="_blank">01:14:50.080</a></span> | <span class="t">well, yeah, there's some like kind of crazy decision theory stuff or like causal trade</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4494" target="_blank">01:14:54.640</a></span> | <span class="t">stuff, which does look on paper, like it should work. And like, if I was, if I was running a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4498" target="_blank">01:14:58.320</a></span> | <span class="t">civilization and like dealing with some people who I didn't like at all, or like didn't have any</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4503" target="_blank">01:15:03.040</a></span> | <span class="t">concern for at all, but I only had to spend 1 billionth of my resources not to murder them.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4507" target="_blank">01:15:07.360</a></span> | <span class="t">I think it's like quite robust that you don't want to murder them. Um, that is, I think the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4513" target="_blank">01:15:13.120</a></span> | <span class="t">like weird decision theory, a causal trade stuff probably does carry the day. Oh, wait, that's,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4518" target="_blank">01:15:18.320</a></span> | <span class="t">that's, that contributes more to that. Uh, 50, 50 of, will they murder us if they take over then</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4524" target="_blank">01:15:24.480</a></span> | <span class="t">the, um, we'll just by default, they might just not want to kill us. Yeah. I think they're both</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4528" target="_blank">01:15:28.640</a></span> | <span class="t">salient. Um, can you explain they run together with each other a lot? I was going to explain</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4533" target="_blank">01:15:33.120</a></span> | <span class="t">the weird a causal. Yeah. So why am I not, it might not kill us. Maybe a higher level thing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4538" target="_blank">01:15:38.560</a></span> | <span class="t">that goes into both of these. And then I will talk about how you instantiate it in a causal</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4541" target="_blank">01:15:41.280</a></span> | <span class="t">trade. It's just like, it matters a lot to the humans not to get murdered. And the AI cares very,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4545" target="_blank">01:15:45.760</a></span> | <span class="t">very little about whether if we imagine this hypothetical, the reason it wants to kill humans</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4549" target="_blank">01:15:49.040</a></span> | <span class="t">is just total apathy. It cares very little about whether or not to murder humans because it is so</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4552" target="_blank">01:15:52.800</a></span> | <span class="t">easy to like marginalize humans without murdering them. And the resources required for human</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4556" target="_blank">01:15:56.480</a></span> | <span class="t">survival are extremely low. Um, again, in the context of this, like rapid industrialization.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4561" target="_blank">01:16:01.680</a></span> | <span class="t">So like, that's the basic setting. And now the thing that you'd like to do is like run a trade,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4567" target="_blank">01:16:07.520</a></span> | <span class="t">like the AI would like to say like, Hey humans, you care a ton about not getting murdered. I don't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4571" target="_blank">01:16:11.120</a></span> | <span class="t">really care one way or the other. I would like to, if I could find some way in which I don't murder</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4575" target="_blank">01:16:15.520</a></span> | <span class="t">you. And then in return, I get something. Um, the problem is in that world, the humans have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4579" target="_blank">01:16:19.440</a></span> | <span class="t">essentially nothing to give. Um, that is the humans are mostly irrelevant. Um, however,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4587" target="_blank">01:16:27.520</a></span> | <span class="t">from the perspective of any kind of reasonable AI, it's like not that sure whether it lives in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4590" target="_blank">01:16:30.800</a></span> | <span class="t">the world where the humans in fact have nothing to give or whether the humans, like, in fact,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4594" target="_blank">01:16:34.480</a></span> | <span class="t">it lives in a world where the humans succeeded at building aligned AI. And now the AI is simply</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4598" target="_blank">01:16:38.480</a></span> | <span class="t">like running in a nice little simulation. And humans are wondering, I wonder if this AI would</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4602" target="_blank">01:16:42.400</a></span> | <span class="t">have murdered us all if it had the chance. And he was saying like, if it would murder us all,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4605" target="_blank">01:16:45.600</a></span> | <span class="t">if it had the chance, like that sucks, we'd like to run this trade. We'd like to be nice</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4608" target="_blank">01:16:48.640</a></span> | <span class="t">to the AIs who wouldn't have murdered us all in order to create an incentive for AIs not to murder</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4611" target="_blank">01:16:51.760</a></span> | <span class="t">us. So we do as we just check. And for the kinds of AIs who don't murder everyone, we just give</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4616" target="_blank">01:16:56.000</a></span> | <span class="t">them like 1 billionth of the universe. Like if you do that as humanity, then if you're an AI system,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4620" target="_blank">01:17:00.960</a></span> | <span class="t">considering like, do I want to murder everyone? Your calculus is like, if this is my real chance</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4624" target="_blank">01:17:04.960</a></span> | <span class="t">to murder everyone, I get like the tiniest bit of value. You know, I get like 1 trillionth of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4628" target="_blank">01:17:08.800</a></span> | <span class="t">the value or whatever, 1 billionth of the value. But on the other hand, like, if I don't murder</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4633" target="_blank">01:17:13.520</a></span> | <span class="t">everyone, there's like some worlds within the humans will correctly determine I don't murder</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4636" target="_blank">01:17:16.480</a></span> | <span class="t">everyone because in fact, the humans survive, the humans are running the simulations to understand</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4640" target="_blank">01:17:20.160</a></span> | <span class="t">how different AIs would behave. And so like, that's a better deal. Let's hope they fall for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4644" target="_blank">01:17:24.800</a></span> | <span class="t">that. Okay. That's interesting. Hey, real quick. This episode is sponsored by Open Philanthropy.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4653" target="_blank">01:17:33.520</a></span> | <span class="t">Open Philanthropy is one of the largest grant making organizations in the world. Every year,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4658" target="_blank">01:17:38.640</a></span> | <span class="t">they give away hundreds of millions of dollars to have reduced catastrophic risks from fast-moving</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4664" target="_blank">01:17:44.080</a></span> | <span class="t">advances in AI and biotechnology. Open Philanthropy is currently hiring for 22 different roles in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4672" target="_blank">01:17:52.240</a></span> | <span class="t">those areas, including grant making, research, and operations. New hires will support Open</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4678" target="_blank">01:17:58.720</a></span> | <span class="t">Philanthropy's giving on technical AI safety, AI governance, AI policy in the US, EU, and UK,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4686" target="_blank">01:18:06.880</a></span> | <span class="t">and biosecurity. Many roles are remote friendly, and most of the grant making hires that Open</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4692" target="_blank">01:18:12.800</a></span> | <span class="t">Philanthropy makes don't have prior grant making experience. Previous technical experience is an</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4699" target="_blank">01:18:19.200</a></span> | <span class="t">asset, as many of these roles often benefit from a deep understanding of the technologies they</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4705" target="_blank">01:18:25.200</a></span> | <span class="t">address. For more information and to apply, please visit Open Philanthropy's website</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4711" target="_blank">01:18:31.920</a></span> | <span class="t">in the description. The deadline to apply is November 9th, so make sure to check out those</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4718" target="_blank">01:18:38.240</a></span> | <span class="t">roles before they close. Awesome. Back to the episode. In a world where we've been deploying</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4723" target="_blank">01:18:43.680</a></span> | <span class="t">these AI systems, and suppose they're aligned, how hard would it be for competitors to,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4734" target="_blank">01:18:54.000</a></span> | <span class="t">I don't know, cyber attack them and get them to join the other side?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4737" target="_blank">01:18:57.280</a></span> | <span class="t">Are they robustly going to be aligned? Yeah. I mean, I think in some sense,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4741" target="_blank">01:19:01.360</a></span> | <span class="t">so there's a bunch of questions that come up here. First one is like, are aligned AI systems that you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4746" target="_blank">01:19:06.080</a></span> | <span class="t">can build competitive? Are they almost as good as the best systems anyone could build? Maybe we're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4750" target="_blank">01:19:10.320</a></span> | <span class="t">granting that for the purpose of this question. I think the next question that comes up is like,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4755" target="_blank">01:19:15.280</a></span> | <span class="t">AI systems right now are very vulnerable to manipulation. It's not clear how much more</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4760" target="_blank">01:19:20.400</a></span> | <span class="t">vulnerable they are than humans, except for the fact that you can, if you have an AI system,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4763" target="_blank">01:19:23.360</a></span> | <span class="t">you can just replay it like a billion times and search for like, what thing can I say that will</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4766" target="_blank">01:19:26.400</a></span> | <span class="t">make it behave this way? So as a result, AI systems are very vulnerable to manipulation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4770" target="_blank">01:19:30.480</a></span> | <span class="t">It's unclear if future AI systems will be similarly vulnerable to manipulation,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4773" target="_blank">01:19:33.120</a></span> | <span class="t">but certainly seems plausible. And in particular, aligned AI systems or unaligned AI systems would</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4778" target="_blank">01:19:38.960</a></span> | <span class="t">be vulnerable to all kinds of manipulation. The thing that's really relevant here is kind</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4782" target="_blank">01:19:42.560</a></span> | <span class="t">of like asymmetric manipulation or something. That is like, if it is easier. So if everyone</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4786" target="_blank">01:19:46.400</a></span> | <span class="t">is just constantly messing with each other's AI systems, like if you ever use AI systems in a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4789" target="_blank">01:19:49.680</a></span> | <span class="t">competitive environment, a big part of the game is like messing with your competitors' AI systems.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4793" target="_blank">01:19:53.200</a></span> | <span class="t">A big question is whether there's some asymmetric factor there where like, it's kind of easier to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4798" target="_blank">01:19:58.560</a></span> | <span class="t">push AI systems into a mode where they're behaving erratically or chaotically, or like trying to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4802" target="_blank">01:20:02.400</a></span> | <span class="t">grab power or something than it is to like push them to fight for the other side. Like if it's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4805" target="_blank">01:20:05.760</a></span> | <span class="t">just a game of like two people are competing and neither of them can sort of like hijack an</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4809" target="_blank">01:20:09.680</a></span> | <span class="t">opponent's AI to like help support their cause, that doesn't, I mean, it matters and it creates</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4813" target="_blank">01:20:13.840</a></span> | <span class="t">chaos and it like might be quite bad for the world, but it doesn't really affect the alignment</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4817" target="_blank">01:20:17.120</a></span> | <span class="t">calculus. Now it's just like, right now you have like normal cyber offense, cyber defense, you have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4821" target="_blank">01:20:21.760</a></span> | <span class="t">like weird AI version of cyber offense, cyber defense. But if you have this kind of asymmetrical</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4825" target="_blank">01:20:25.840</a></span> | <span class="t">thing where like, you know, a bunch of AI systems who are like, we love AI flourishing can then like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4830" target="_blank">01:20:30.640</a></span> | <span class="t">go in and say like, great AIs, hey, how about you join us? And that works. Like if they can search</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4834" target="_blank">01:20:34.160</a></span> | <span class="t">for a persuasive argument to that effect, and that's kind of asymmetrical, then like the effect</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4838" target="_blank">01:20:38.720</a></span> | <span class="t">is whatever values it's easiest to push, like whatever it's easiest to argue to an AI that it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4842" target="_blank">01:20:42.800</a></span> | <span class="t">should do, that is like advantaged. So it may be very hard to build AI systems, like try and defend</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4848" target="_blank">01:20:48.320</a></span> | <span class="t">human interest, but very easy to build AI systems. It's just like trying to destroy stuff or whatever,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4852" target="_blank">01:20:52.000</a></span> | <span class="t">just depending on like, what is the easiest thing to argue to an AI that it should do? Or what's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4854" target="_blank">01:20:54.960</a></span> | <span class="t">the easiest like thing to trick an AI into doing or whatever? Yeah, I think if alignment is spotty,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4859" target="_blank">01:20:59.920</a></span> | <span class="t">like so if you have the AI system, which like doesn't really want to help humans or whatever,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4863" target="_blank">01:21:03.520</a></span> | <span class="t">or in fact like wants some kind of random thing, or like wants different things in different</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4867" target="_blank">01:21:07.680</a></span> | <span class="t">contexts, then I do think adversarial settings will be the main ones where you see the system,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4873" target="_blank">01:21:13.600</a></span> | <span class="t">or like the easiest ones where you see the system behaving really badly. And it's a little bit hard</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4879" target="_blank">01:21:19.440</a></span> | <span class="t">to tell how that shakes out. Okay. And so suppose it is more reliable. How concerned are you that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4884" target="_blank">01:21:24.800</a></span> | <span class="t">whatever alignment technique you come up with, you publish the paper, this is how the alignment</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4890" target="_blank">01:21:30.000</a></span> | <span class="t">works. How concerned are you that Putin reads it or China reads it, and now they understand,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4894" target="_blank">01:21:34.960</a></span> | <span class="t">for example, the constitutional AI think we're anthropic, and then you just write on there,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4898" target="_blank">01:21:38.400</a></span> | <span class="t">oh, never contradict Mao Zedong thought or something. How concerned should we be that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4903" target="_blank">01:21:43.760</a></span> | <span class="t">these alignment techniques are universally applicable, not necessarily just for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4908" target="_blank">01:21:48.560</a></span> | <span class="t">enlightened goals? Yeah, I mean, I think they're super universally applicable. I think it's just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4913" target="_blank">01:21:53.440</a></span> | <span class="t">like, I mean, the rough way I would describe it, which I think is basically right, is like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4917" target="_blank">01:21:57.600</a></span> | <span class="t">some degree of alignment makes AI systems like much more usable. Like it kind of, you should</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4922" target="_blank">01:22:02.400</a></span> | <span class="t">just think of the technology of AI as including like a basket of like some AI capabilities and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4926" target="_blank">01:22:06.160</a></span> | <span class="t">some like getting the AI to do what you want. It's just part of that basket. And so anytime</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4929" target="_blank">01:22:09.920</a></span> | <span class="t">we're like, you know, to extend alignment as part of that basket, you're just contributing to all</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4933" target="_blank">01:22:13.840</a></span> | <span class="t">the other harms from AI. Like you're reducing the probability of this harm, but you are helping the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4937" target="_blank">01:22:17.360</a></span> | <span class="t">technology basically work. And like the basically working technology is kind of scary from a lot of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4941" target="_blank">01:22:21.520</a></span> | <span class="t">perspectives. One of which is like right now, even in a very authoritarian society, just like humans</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4946" target="_blank">01:22:26.160</a></span> | <span class="t">have a lot of power because you need to rely on just a ton of humans to do your thing. And in a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4951" target="_blank">01:22:31.360</a></span> | <span class="t">world where AI is very powerful, like it is just much more possible to say, like, here's how our</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4955" target="_blank">01:22:35.280</a></span> | <span class="t">society runs. One person calls the shots and then a ton of AI systems do what they want. I think</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4959" target="_blank">01:22:39.440</a></span> | <span class="t">that's like a reasonable thing to like dislike about AI and a reasonable reason to be scared to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4963" target="_blank">01:22:43.520</a></span> | <span class="t">push the technology to be really good. But is that, is that also a reasonable reason to be concerned</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4967" target="_blank">01:22:47.360</a></span> | <span class="t">about alignment as well? That, you know, this is in some sense also capabilities. You're teaching</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4974" target="_blank">01:22:54.640</a></span> | <span class="t">people how to get these systems to do what they want. Yeah. I mean, I would generalize. So we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4979" target="_blank">01:22:59.840</a></span> | <span class="t">earlier touched a little bit on like moral, potential moral rights of AI systems. And like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4983" target="_blank">01:23:03.920</a></span> | <span class="t">now we're talking a little bit about how they could, AI systems powerfully disempowers humans</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4987" target="_blank">01:23:07.680</a></span> | <span class="t">and can empower authoritarians. I think we could like list other harms from AI. And I think it is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4991" target="_blank">01:23:11.920</a></span> | <span class="t">the case that like if alignment was bad enough, people would just not build AI systems. And so</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=4996" target="_blank">01:23:16.080</a></span> | <span class="t">like, yeah, I think there's a real sense in which you should just be scared to say you're scared of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5000" target="_blank">01:23:20.960</a></span> | <span class="t">all AI. You should be like, well, alignment, although it helps with one risk does contribute</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5004" target="_blank">01:23:24.320</a></span> | <span class="t">to AI being more of a thing. I do think you should shut down the other parts of AI before, like if</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5008" target="_blank">01:23:28.800</a></span> | <span class="t">you were a policymaker or like a researcher or whatever looking in on this, I think it's like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5011" target="_blank">01:23:31.840</a></span> | <span class="t">crazy to be like, this is the part of the basket we're going to remove. Like you should, you should</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5015" target="_blank">01:23:35.200</a></span> | <span class="t">first remove like other parts of the basket because they're also part of the story of risk.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5018" target="_blank">01:23:38.960</a></span> | <span class="t">Wait, wait, wait. Does that imply you think if, for example, all capabilities research was shut</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5024" target="_blank">01:23:44.160</a></span> | <span class="t">down, that you think it'd be a bad idea to continue doing alignment research in isolation of what is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5030" target="_blank">01:23:50.000</a></span> | <span class="t">conventionally considered capabilities research? I mean, if you told me it was never going to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5033" target="_blank">01:23:53.840</a></span> | <span class="t">restart, then it wouldn't matter. And if you told me it's going to restart, I guess it would be a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5036" target="_blank">01:23:56.480</a></span> | <span class="t">kind of similar calculus to today. Whereas it's going to happen. So you, you should have something.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5041" target="_blank">01:24:01.600</a></span> | <span class="t">Yeah. I think that like, in some sense, you're always going to face this trade-off where alignment</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5045" target="_blank">01:24:05.440</a></span> | <span class="t">makes it possible to deploy AI systems, or like makes it more attractive to deploy AI systems.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5050" target="_blank">01:24:10.640</a></span> | <span class="t">And then, or like in the authoritarian case, it makes it like tractable to apply them for this,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5055" target="_blank">01:24:15.040</a></span> | <span class="t">for this purpose. And like, if you didn't do any alignment, there'd be a nicer, bigger buffer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5061" target="_blank">01:24:21.200</a></span> | <span class="t">between your society and malicious uses of AI. And like, I think it's one of the most expensive</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5065" target="_blank">01:24:25.360</a></span> | <span class="t">ways to maintain that buffer. Like it's much better to maintain that buffer by not having</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5068" target="_blank">01:24:28.480</a></span> | <span class="t">the compute or not having the powerful AI. But I think if you're concerned enough about the other</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5071" target="_blank">01:24:31.920</a></span> | <span class="t">risks, there's definitely a case to be made for just like put in more buffer or something like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5075" target="_blank">01:24:35.040</a></span> | <span class="t">that. I'm not, like, I care enough about the takeover risk that like, I think it's just not</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5080" target="_blank">01:24:40.160</a></span> | <span class="t">a net positive way to buy buffer. That is again, the version of this that's most pragmatic is just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5085" target="_blank">01:24:45.440</a></span> | <span class="t">like, suppose you don't work on alignment today, like decreases economic impact of AI systems.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5089" target="_blank">01:24:49.040</a></span> | <span class="t">They'll be like less useful if they're less reliable. And if they more often don't do what</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5092" target="_blank">01:24:52.080</a></span> | <span class="t">people want. And so you could be like, great, that just buys time for AI. And you're like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5095" target="_blank">01:24:55.760</a></span> | <span class="t">getting some trade off there where you're like decreasing some risks of AI. Like if AI is more</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5099" target="_blank">01:24:59.040</a></span> | <span class="t">reliable and more does what people want or is more understandable, then that cuts down some risks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5103" target="_blank">01:25:03.040</a></span> | <span class="t">But if you think AI is on balance bad, even apart from takeover risk, then like the alignment stuff</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5109" target="_blank">01:25:09.760</a></span> | <span class="t">can easily end up being that negative. But presumably you don't think that, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5113" target="_blank">01:25:13.760</a></span> | <span class="t">Because I guess this is something people have brought up to you because you, you know,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5119" target="_blank">01:25:19.600</a></span> | <span class="t">you, you invented RLHF, which was used to train Chad GPT and Chad GPT brought AI to the front</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5126" target="_blank">01:25:26.160</a></span> | <span class="t">pages everywhere. So I do wonder if you could measure how much more money went into AI because</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5133" target="_blank">01:25:33.200</a></span> | <span class="t">like how much people have raised in the last year or something, but it's gotta be billions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5136" target="_blank">01:25:36.880</a></span> | <span class="t">The counterfactual impact of that, that, that went into the investment and the talent that went</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5142" target="_blank">01:25:42.960</a></span> | <span class="t">into AI, for example. And so presumably you think that was worth it. So I guess you're hedging here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5147" target="_blank">01:25:47.760</a></span> | <span class="t">about like, what, what, what is the reason that, that it's worth it?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5150" target="_blank">01:25:50.880</a></span> | <span class="t">Yeah. Like what's the, what's the total trade-off there? I mean, I think my take is like,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5154" target="_blank">01:25:54.880</a></span> | <span class="t">so I think slower AI development on balance is like quite good. I think that slowing AI</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5162" target="_blank">01:26:02.000</a></span> | <span class="t">development now, or like say having less press around Chad GPT is like a little bit more mixed</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5166" target="_blank">01:26:06.800</a></span> | <span class="t">than slowing AI development overall. Like, I think it's still probably positive, but much less</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5170" target="_blank">01:26:10.400</a></span> | <span class="t">positive because I do think there's a real effect of like the world is starting to get prepared,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5174" target="_blank">01:26:14.800</a></span> | <span class="t">or is getting prepared at like a much greater rate now than it was prior to the release of Chad GPT.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5178" target="_blank">01:26:18.320</a></span> | <span class="t">And so like, if you can choose between progress now or progress later, like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5181" target="_blank">01:26:21.200</a></span> | <span class="t">you really prefer have more of your progress now, which I do think slows down progress later.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5184" target="_blank">01:26:24.960</a></span> | <span class="t">I don't think that's enough to flip the sign. I think like maybe it was in the far enough past,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5188" target="_blank">01:26:28.240</a></span> | <span class="t">but now I would still say like moving faster now is net negative. But to be clear, it's a lot less</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5192" target="_blank">01:26:32.400</a></span> | <span class="t">net negative than merely accelerating AI, because I do think again, the Chad GPT thing, I am glad</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5198" target="_blank">01:26:38.240</a></span> | <span class="t">people are having policy discussions now rather than like delaying the like Chad GPT wake up</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5202" target="_blank">01:26:42.720</a></span> | <span class="t">thing by a year. And then I'm having- Oh wait, Chad GPT was net negative or RLHF was net negative?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5209" target="_blank">01:26:49.120</a></span> | <span class="t">So here just on the acceleration, it's just like, how is the press of Chad GPT? And my guess is like,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5212" target="_blank">01:26:52.880</a></span> | <span class="t">my guess is net negative, but I think like, it's not super clear and it's like much less,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5217" target="_blank">01:26:57.920</a></span> | <span class="t">much less than slowing AI. Slowing AI is great if you could slow overall AI progress.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5222" target="_blank">01:27:02.080</a></span> | <span class="t">I think slowing AI by like causing, you know, there's this issue where slowing AI now,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5227" target="_blank">01:27:07.440</a></span> | <span class="t">like for Chad GPT, you're building up this backlog. Like why does Chad GPT make such a splash?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5231" target="_blank">01:27:11.360</a></span> | <span class="t">Like I think people, there's a reasonable chance if you don't have a splash about Chad GPT,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5234" target="_blank">01:27:14.880</a></span> | <span class="t">you have a splash about GPT-4. And if you fail to have a splash about GPT-4,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5237" target="_blank">01:27:17.600</a></span> | <span class="t">there's a reasonable chance of a splash about GPT-4.5. And just like, as that happens later,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5242" target="_blank">01:27:22.080</a></span> | <span class="t">there's just like less and less time between that splash and between when an AI potentially</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5245" target="_blank">01:27:25.920</a></span> | <span class="t">kills everyone. Right. So people, governments are talking about it as they are now and people aren't,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5250" target="_blank">01:27:30.800</a></span> | <span class="t">but okay. So let's start with the slowing down because- Yeah, so this is also all one sub</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5255" target="_blank">01:27:35.360</a></span> | <span class="t">component of like the overall impact. And I was just saying this to like, just to like briefly</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5259" target="_blank">01:27:39.040</a></span> | <span class="t">give the roadmap for the overall too long answer. Like, there's a question of what's the calculus</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5263" target="_blank">01:27:43.600</a></span> | <span class="t">for speeding up? I think speeding up is pretty rough. I think speeding up like locally is a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5267" target="_blank">01:27:47.040</a></span> | <span class="t">little bit less rough. And then, yeah, I think that the effect, like the overall effect size</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5271" target="_blank">01:27:51.200</a></span> | <span class="t">from like doing alignment work on reducing takeover risk versus speeding up AI is like pretty</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5275" target="_blank">01:27:55.280</a></span> | <span class="t">good. Like, I think, yeah, I think it's pretty good. I think you reduce takeover risk significantly</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5280" target="_blank">01:28:00.720</a></span> | <span class="t">before you like speed up AI by a year, whatever. Okay. Got it. If it's good to, like, slowing down</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5288" target="_blank">01:28:08.960</a></span> | <span class="t">AI is good, presumably because it gives you more time to do alignment. But alignment also helps</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5295" target="_blank">01:28:15.760</a></span> | <span class="t">speed up AI. RLHF is alignment and it help with chat GPT, which sped up AI. So I actually don't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5303" target="_blank">01:28:23.760</a></span> | <span class="t">understand how the feedback loop nets out other than the fact that if AI is happening, you need</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5308" target="_blank">01:28:28.400</a></span> | <span class="t">to do alignment at some point. Right. So, I mean, you can't just not do alignment. Yes. I think if</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5313" target="_blank">01:28:33.440</a></span> | <span class="t">the only reason you thought faster AI progress was bad was because it gave less time to do alignment,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5317" target="_blank">01:28:37.920</a></span> | <span class="t">then there would just be no possible way that the calculus comes out negative for alignment.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5321" target="_blank">01:28:41.200</a></span> | <span class="t">You're like, maybe alignment speeds up AI, but the only purpose of slowing down AI was to do it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5324" target="_blank">01:28:44.560</a></span> | <span class="t">Like it's just, it could never come out ahead. I think the reason that you can come out ahead,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5328" target="_blank">01:28:48.800</a></span> | <span class="t">the reason you could end up thinking the alignment was net negative was because there's a bunch of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5332" target="_blank">01:28:52.400</a></span> | <span class="t">other stuff you're doing that makes AI safer. Like if you think the world is like gradually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5336" target="_blank">01:28:56.160</a></span> | <span class="t">coming better to terms with the impact of AI or policies being made, or like you're getting</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5340" target="_blank">01:29:00.800</a></span> | <span class="t">increasingly prepared to handle the like threat of authoritarian abuse of AI. If you think other</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5344" target="_blank">01:29:04.720</a></span> | <span class="t">stuff is happening, that's improving preparedness, then you have reason beyond alignment research to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5349" target="_blank">01:29:09.120</a></span> | <span class="t">slow down AI. Actually, how big a factor is that? So let's say right now we hit pause and you have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5355" target="_blank">01:29:15.040</a></span> | <span class="t">10 years of no alignment, no capabilities, but just people get to talk about it for 10 years.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5360" target="_blank">01:29:20.160</a></span> | <span class="t">How much more does that prepare people than we only have one year versus we have no time?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5366" target="_blank">01:29:26.000</a></span> | <span class="t">Like it's just that time where no research and alignment or capabilities happening.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5370" target="_blank">01:29:30.800</a></span> | <span class="t">Like, is there like, what does that dead time do for us?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5374" target="_blank">01:29:34.320</a></span> | <span class="t">I mean, right now it seems like there's a lot of policy stuff you'd want to do. This seemed like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5377" target="_blank">01:29:37.360</a></span> | <span class="t">less plausible a couple of years ago, maybe, but if like the world just knew they had a 10 year</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5380" target="_blank">01:29:40.640</a></span> | <span class="t">pause right now, I think there's a lot of sense of like, we have policy objectives to accomplish.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5384" target="_blank">01:29:44.960</a></span> | <span class="t">If we had 10 years, we could pretty much do those things. Like we'd have a lot of time to like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5389" target="_blank">01:29:49.040</a></span> | <span class="t">debate measurement regimes, debate like policy regimes and containment regimes,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5393" target="_blank">01:29:53.440</a></span> | <span class="t">and a lot of time to set up those institutions. So like, if you told me that the world knew it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5397" target="_blank">01:29:57.680</a></span> | <span class="t">was a pause, like it wasn't like people just see that AI progress isn't happening, but they're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5400" target="_blank">01:30:00.560</a></span> | <span class="t">told like you guys have been granted or like cursed with a 10 year, no AI progress, no alignment</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5404" target="_blank">01:30:04.480</a></span> | <span class="t">progress pause. I think that would be quite good at this point. However, I think it would be much</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5410" target="_blank">01:30:10.160</a></span> | <span class="t">better at this point than it would have been two years ago. And so like the entire concern with</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5414" target="_blank">01:30:14.000</a></span> | <span class="t">like slowing AI development now, rather than taking the 10 year pause is just like, if you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5417" target="_blank">01:30:17.840</a></span> | <span class="t">slow AI development by a year now, my guess is some gets clawed back by low hanging fruit gets</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5421" target="_blank">01:30:21.520</a></span> | <span class="t">picked faster in the future. My guess is you lose like half a year or something like that in the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5425" target="_blank">01:30:25.840</a></span> | <span class="t">future, maybe even more, maybe like two thirds of a year. So it's like you're trading time now for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5430" target="_blank">01:30:30.880</a></span> | <span class="t">time in the future at some rate. And it's just like, that eats up like a lot of the value of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5434" target="_blank">01:30:34.560</a></span> | <span class="t">the slowdown. And the crucial point being that time in the future matters more because you have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5438" target="_blank">01:30:38.720</a></span> | <span class="t">more information, people are more bought in and so on. Yeah. The same reason, like I'm more excited</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5442" target="_blank">01:30:42.480</a></span> | <span class="t">about policy change now than two years ago. So like my overall view is just like in the past,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5447" target="_blank">01:30:47.120</a></span> | <span class="t">this calculus, this calculus changes over time, right? The like more people are getting prepared,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5450" target="_blank">01:30:50.640</a></span> | <span class="t">the better the calculus is for slowing down at this very moment. And I think like now the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5454" target="_blank">01:30:54.560</a></span> | <span class="t">calculus is, I would say positive for just, even if you pause now and it would get clawed back in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5459" target="_blank">01:30:59.440</a></span> | <span class="t">the future, I think the pause now is just good because like enough stuff is happening. We have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5463" target="_blank">01:31:03.040</a></span> | <span class="t">enough idea of like, I mean, probably even apart from alignment research. And certainly if you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5466" target="_blank">01:31:06.480</a></span> | <span class="t">include alignment research, just like enough stuff is happening where the world is getting more ready</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5471" target="_blank">01:31:11.200</a></span> | <span class="t">and coming more to terms with impacts that I just think it is worth it, even though some of that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5474" target="_blank">01:31:14.560</a></span> | <span class="t">time is going to get clawed back. Again, especially if like, there's a question of during a pause,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5480" target="_blank">01:31:20.400</a></span> | <span class="t">does like NVIDIA keep making more GPUs? Like that sucks if they do, if you do a pause, but like,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5484" target="_blank">01:31:24.880</a></span> | <span class="t">yeah, in practice, if you did a positive NVIDIA probably couldn't keep making more GPUs because</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5488" target="_blank">01:31:28.960</a></span> | <span class="t">in fact, like the demand for GPUs is really important for them to do that. But if you told</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5492" target="_blank">01:31:32.640</a></span> | <span class="t">me that you just get to scale up hardware production and like building the clusters,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5495" target="_blank">01:31:35.680</a></span> | <span class="t">but not doing AI, then that's back to being that negative, I think pretty clearly.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5499" target="_blank">01:31:39.120</a></span> | <span class="t">Then having brought up the fact that we want some sort of measurement scheme for these</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5503" target="_blank">01:31:43.520</a></span> | <span class="t">capabilities, let's talk about responsible scaling policies. Do you want to introduce what this is?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5507" target="_blank">01:31:47.920</a></span> | <span class="t">Sure. So I guess the motivating question, it's like, what should AI labs be doing right now</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5515" target="_blank">01:31:55.120</a></span> | <span class="t">to manage risk and to sort of build good habits or practices for managing risk into the future?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5519" target="_blank">01:31:59.280</a></span> | <span class="t">And I think my take is that current systems pose from a catastrophic risk perspective,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5526" target="_blank">01:32:06.800</a></span> | <span class="t">not that much risk today. That is a failure to like control or understand GPT-4 can have real</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5532" target="_blank">01:32:12.640</a></span> | <span class="t">harms, but doesn't have much harm with respect to the kind of takeover risk I'm worried about,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5537" target="_blank">01:32:17.520</a></span> | <span class="t">or even much catastrophic harm with respect to misuse. So I think like, if you want to manage</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5543" target="_blank">01:32:23.440</a></span> | <span class="t">catastrophic harms, I think right now you don't need to be that careful with GPT-4. And so to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5548" target="_blank">01:32:28.400</a></span> | <span class="t">the extent you're like, what should labs do? I think like the single most important thing seems</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5552" target="_blank">01:32:32.560</a></span> | <span class="t">like understand whether that's the case, notice when that stops being the case, have a reasonable</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5559" target="_blank">01:32:39.360</a></span> | <span class="t">roadmap for what you're actually going to do when that stops being the case. So that motivates this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5564" target="_blank">01:32:44.160</a></span> | <span class="t">like set of policies, which like I've sort of been pushing for labs to adopt, which is saying like,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5571" target="_blank">01:32:51.600</a></span> | <span class="t">here's what we're looking for. Here's some threats we're concerned about. Here's some capabilities</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5575" target="_blank">01:32:55.200</a></span> | <span class="t">that we're measuring. Here's the level, like here's the actual concrete measurement results</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5579" target="_blank">01:32:59.280</a></span> | <span class="t">that would suggest to us that those threats are real. Here's the action we would take in response</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5583" target="_blank">01:33:03.280</a></span> | <span class="t">to observing those capabilities. If we couldn't take those actions, like if we've said that we're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5588" target="_blank">01:33:08.560</a></span> | <span class="t">going to secure the weights, we're not able to do that. We're going to like pause until we can take</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5591" target="_blank">01:33:11.440</a></span> | <span class="t">those actions. Yeah. So this sort of, again, I think it's like motivated primarily, but like,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5600" target="_blank">01:33:20.640</a></span> | <span class="t">what should you be doing as a lab to manage catastrophic risk now in a way that's like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5604" target="_blank">01:33:24.000</a></span> | <span class="t">our reasonable precedent and habit and policy for continuing to implement into the future.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5608" target="_blank">01:33:28.240</a></span> | <span class="t">And which labs, I don't know if this is public yet, but which labs are cooperating on this?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5614" target="_blank">01:33:34.560</a></span> | <span class="t">Yeah. So Anthropic has, has written this document, this, the current responsible scaling policy.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5619" target="_blank">01:33:39.600</a></span> | <span class="t">And then I've been talking with other folks, I guess, don't really want to comment on other,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5626" target="_blank">01:33:46.640</a></span> | <span class="t">other conversations, but like, I think in general, like people who are more interested in,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5630" target="_blank">01:33:50.880</a></span> | <span class="t">or like more think you have plausible catastrophic harms on like a five-year</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5634" target="_blank">01:33:54.960</a></span> | <span class="t">timeline are more interested in this. And there's like not that long a list of suspects like that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5640" target="_blank">01:34:00.880</a></span> | <span class="t">There's not that many labs. Okay. So if these companies would be willing to coordinate and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5646" target="_blank">01:34:06.880</a></span> | <span class="t">say at these different benchmarks, we're going to make sure that we have these safeguards,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5652" target="_blank">01:34:12.000</a></span> | <span class="t">what happens? I mean, there are other companies and other countries which care less about this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5657" target="_blank">01:34:17.200</a></span> | <span class="t">Are you just slowing down the companies that are most aligned?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5661" target="_blank">01:34:21.520</a></span> | <span class="t">Yeah. I think the first sort of business understanding, like sort of what is actually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5666" target="_blank">01:34:26.880</a></span> | <span class="t">a reasonable set of policies for managing risk. I do think there's a question of like,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5670" target="_blank">01:34:30.560</a></span> | <span class="t">you might end up in a situation where you say like, well, here's what we would do in an ideal</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5673" target="_blank">01:34:33.360</a></span> | <span class="t">world. If we like, you know, if everyone was behaving responsibly, we'd want to keep risk</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5678" target="_blank">01:34:38.720</a></span> | <span class="t">to 1% or a couple of percent or whatever, maybe even lower levels, depending on how you feel.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5682" target="_blank">01:34:42.640</a></span> | <span class="t">However, in the real world, like there's enough of a mess, like there's enough unsafe stuff</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5688" target="_blank">01:34:48.480</a></span> | <span class="t">happening that actually it's worth making like larger compromises or like, if we don't kill</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5691" target="_blank">01:34:51.680</a></span> | <span class="t">everyone, someone else will kill everyone anyway. So actually the counterfactual risk is much lower.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5695" target="_blank">01:34:55.040</a></span> | <span class="t">I think like, if you end up in that situation, it's still extremely valuable to have said like,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5699" target="_blank">01:34:59.760</a></span> | <span class="t">here's the policies we'd like to follow. Here's the policies we've started following.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5703" target="_blank">01:35:03.040</a></span> | <span class="t">Here's why we think it's dangerous. Like here's the concerns we have if people are following</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5707" target="_blank">01:35:07.280</a></span> | <span class="t">significantly laxer policies. And then this is maybe helpful as like an input to or model for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5712" target="_blank">01:35:12.080</a></span> | <span class="t">potential regulation. It's helpful for being able to just produce clarity about what's going on.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5717" target="_blank">01:35:17.360</a></span> | <span class="t">I think historically there's been like considerable concern about developers being more or less safe,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5720" target="_blank">01:35:20.800</a></span> | <span class="t">but there's not that much like legible differentiation in terms of what their</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5724" target="_blank">01:35:24.720</a></span> | <span class="t">policies are. I think getting to that world would be good. Like it would be very different. It's a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5730" target="_blank">01:35:30.000</a></span> | <span class="t">very different world if you're like actor X is developing and I'm concerned that they will do</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5733" target="_blank">01:35:33.440</a></span> | <span class="t">so in an unsafe way. Versus if you're like, look, we take security precautions or safety precautions</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5738" target="_blank">01:35:38.240</a></span> | <span class="t">X, Y, Z. Here's why we think those precautions are desirable or necessary. We're concerned about</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5742" target="_blank">01:35:42.800</a></span> | <span class="t">this other developer because they don't do those things. I think it's just like a qualitatively,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5745" target="_blank">01:35:45.840</a></span> | <span class="t">it's kind of the first step you would want to take in any world where you're trying to get people</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5750" target="_blank">01:35:50.160</a></span> | <span class="t">on side or like trying to, trying to move towards regulation that can manage risk.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5754" target="_blank">01:35:54.240</a></span> | <span class="t">Well, how about the concern that you have these evaluations and let's say you declared the world,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5759" target="_blank">01:35:59.600</a></span> | <span class="t">our new model has a capability to help develop bioweapons or help you make cyber attacks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5767" target="_blank">01:36:07.120</a></span> | <span class="t">And therefore we're pausing right now until you can figure this out. And China hears this and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5773" target="_blank">01:36:13.120</a></span> | <span class="t">thinks, Oh, wow, a tool that can help us, you know, make a cyber attacks and then just steals</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5777" target="_blank">01:36:17.360</a></span> | <span class="t">the weights. Does this scheme work in the current regime where we can't ensure that China doesn't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5782" target="_blank">01:36:22.720</a></span> | <span class="t">just steal the weights and more so, are you increasing the salience of dangerous models</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5789" target="_blank">01:36:29.840</a></span> | <span class="t">so that, you know, you just, you, you blur this out and then people want the way it's now because</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5794" target="_blank">01:36:34.640</a></span> | <span class="t">they know what they can do. Yeah. I mean, I think the general discussion does emphasize potential</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5800" target="_blank">01:36:40.160</a></span> | <span class="t">harms or potential. I mean, some of those are harms and some of those are just like impacts</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5803" target="_blank">01:36:43.360</a></span> | <span class="t">that are very large. And so it might also be an inducement to develop models. I think like that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5807" target="_blank">01:36:47.600</a></span> | <span class="t">part, if you're for a moment, ignoring security and just saying like that may increase investment.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5811" target="_blank">01:36:51.360</a></span> | <span class="t">I think it's like on balance, just quite good for people to have an understanding of potential</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5814" target="_blank">01:36:54.960</a></span> | <span class="t">impacts just because it is an input both into proliferation, but also into like regulation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5820" target="_blank">01:37:00.240</a></span> | <span class="t">or safety with respect to things like security of either weights or other IP. I do think you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5827" target="_blank">01:37:07.840</a></span> | <span class="t">want to have moved to like significantly more secure, like handling of model weights before</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5832" target="_blank">01:37:12.800</a></span> | <span class="t">the point where like a leak would be catastrophic. And indeed, like, you know, for example, in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5837" target="_blank">01:37:17.040</a></span> | <span class="t">Anthropx document or in their plan, like security is one of the first sets of like tangible changes</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5843" target="_blank">01:37:23.520</a></span> | <span class="t">that is like at this capability level, we need to have like such security practices in place.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5846" target="_blank">01:37:26.960</a></span> | <span class="t">So I do think that's just one of the things you need to get in place at a relatively early stage,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5852" target="_blank">01:37:32.960</a></span> | <span class="t">because it does undermine like the rest of the measures you may take. And it's also just part</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5857" target="_blank">01:37:37.360</a></span> | <span class="t">of the easiest, like if you imagine catastrophic harms over the next couple of years, I think</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5861" target="_blank">01:37:41.920</a></span> | <span class="t">security failures are kind of play a central role in a lot of those. And maybe the last thing to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5866" target="_blank">01:37:46.240</a></span> | <span class="t">say is like, it's not clear that you should say like, we have paused because we have models that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5869" target="_blank">01:37:49.520</a></span> | <span class="t">can develop bioweapons versus just like, I mean, potentially not saying anything about like what</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5873" target="_blank">01:37:53.920</a></span> | <span class="t">models you've developed, or at least saying like, hey, like, by the way, here's like, you know,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5877" target="_blank">01:37:57.920</a></span> | <span class="t">here's the set of practices we currently implement. Here's a set of capabilities</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5881" target="_blank">01:38:01.040</a></span> | <span class="t">our models don't have. We're just not even talking that much like, right, sort of the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5884" target="_blank">01:38:04.720</a></span> | <span class="t">minimum of such a policy is to say, here's what we do from the perspective of security or internal</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5890" target="_blank">01:38:10.000</a></span> | <span class="t">controls or alignment. Here's a level of capability, which we'd have to do more.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5893" target="_blank">01:38:13.680</a></span> | <span class="t">And you can say that you can raise your level of capability and raise your protective measures,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5897" target="_blank">01:38:17.280</a></span> | <span class="t">like before your models hit your previous level. Like it's fine to say like, we are prepared to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5902" target="_blank">01:38:22.160</a></span> | <span class="t">handle a model that has such and such extreme capabilities, like prior to actually having such</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5905" target="_blank">01:38:25.920</a></span> | <span class="t">a model at hand, as long as you're prepared to move your protective measures to that regime.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5910" target="_blank">01:38:30.320</a></span> | <span class="t">Okay, so let's just get to the end where you think you're a generation away,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5914" target="_blank">01:38:34.720</a></span> | <span class="t">or a little bit more scaffolding away from a model that is human level, and subsequently could</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5921" target="_blank">01:38:41.040</a></span> | <span class="t">cascade an intelligence explosion. What do you actually do at that point? Like, what is the level</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5926" target="_blank">01:38:46.560</a></span> | <span class="t">of evaluation of safety, where you would be satisfied releasing a human level model?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5932" target="_blank">01:38:52.480</a></span> | <span class="t">There's a couple points that come up here. So one is like, this threat model of like,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5938" target="_blank">01:38:58.080</a></span> | <span class="t">sort of automating R&D, or like, independent of whether AI can do something on the object level,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5942" target="_blank">01:39:02.960</a></span> | <span class="t">that's potentially dangerous. And it's reasonable to be concerned if you have an AI system that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5946" target="_blank">01:39:06.640</a></span> | <span class="t">might like, you know, if leaked, allow other actors to quickly build powerful AI systems,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5950" target="_blank">01:39:10.240</a></span> | <span class="t">or might allow you to quickly build like much more powerful systems. Or might like, if you're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5954" target="_blank">01:39:14.160</a></span> | <span class="t">trying to hold off on development, just like itself be able to create much more powerful systems.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5958" target="_blank">01:39:18.560</a></span> | <span class="t">So like, one question is how to handle that kind of threat model as distinct from a threat model,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5962" target="_blank">01:39:22.160</a></span> | <span class="t">like this could enable destructive bioterrorism, or this could enable like massively scaled cyber</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5966" target="_blank">01:39:26.800</a></span> | <span class="t">crime or whatever. And I think like, I am unsure how you should handle that. I think like right</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5971" target="_blank">01:39:31.520</a></span> | <span class="t">now, implicitly, it's being handled by saying like, look, there's a lot of overlap between the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5975" target="_blank">01:39:35.520</a></span> | <span class="t">kinds of capabilities that are necessary to cause various harms and the kinds of capabilities are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5978" target="_blank">01:39:38.800</a></span> | <span class="t">necessary to accelerate ML. So we're kind of going to catch those with like, an early warning sign</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5982" target="_blank">01:39:42.640</a></span> | <span class="t">for both and like, deal with the resolution of this question a little bit later. So for example,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5986" target="_blank">01:39:46.960</a></span> | <span class="t">in an anthropics policy, they have this like, sort of autonomy in the lab benchmark, which I think is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5993" target="_blank">01:39:53.200</a></span> | <span class="t">probably occurs prior to either like really massive AI acceleration, or to like, most potential</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=5998" target="_blank">01:39:58.480</a></span> | <span class="t">catastrophic, like object level catastrophic harms. And it is that's like a warning sign,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6002" target="_blank">01:40:02.240</a></span> | <span class="t">let's you punt. So this is a bit of an aggression in terms of like how to think about that risk.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6006" target="_blank">01:40:06.480</a></span> | <span class="t">I think I am unsure whether you should be addressing that risk directly and saying like,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6009" target="_blank">01:40:09.680</a></span> | <span class="t">we're scared to even work with such a model, or if you should be mostly focusing on object level</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6013" target="_blank">01:40:13.360</a></span> | <span class="t">harms and saying like, okay, we need more intense precautions to manage optical level harms because</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6017" target="_blank">01:40:17.920</a></span> | <span class="t">of the prospect of very rapid change. And the availability of this AI just like creates that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6022" target="_blank">01:40:22.720</a></span> | <span class="t">kind of creates that prospect. Okay, this was all still a digression. So if you had a model,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6029" target="_blank">01:40:29.600</a></span> | <span class="t">which you thought was like, potentially very scary, either on the object level, or because</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6032" target="_blank">01:40:32.720</a></span> | <span class="t">of like leading to the sort of intelligence explosion dynamics. I mean, things you want</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6037" target="_blank">01:40:37.360</a></span> | <span class="t">in place are like, you really do not want to be leaking the weights to that model. Like you don't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6042" target="_blank">01:40:42.400</a></span> | <span class="t">want the model to be able to run away. You don't want human employees to be able to leak it. You</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6045" target="_blank">01:40:45.840</a></span> | <span class="t">don't want external attackers or any set of all three of those coordinating. You really don't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6050" target="_blank">01:40:50.400</a></span> | <span class="t">want like internal abuse or tampering with such models. So if you're producing such models,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6054" target="_blank">01:40:54.640</a></span> | <span class="t">you don't want to be the case, like a couple employees could change the way the model works,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6057" target="_blank">01:40:57.600</a></span> | <span class="t">or could do something that violates your policy easily with that model. And if a model is very</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6061" target="_blank">01:41:01.680</a></span> | <span class="t">powerful, even the prospect of internal abuse could be quite bad. And so you might need significant</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6066" target="_blank">01:41:06.640</a></span> | <span class="t">internal controls to prevent that. Sorry, we're already getting to it. But the part I'm most</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6070" target="_blank">01:41:10.400</a></span> | <span class="t">curious about is separate from the ways in which other people might fuck with it. Like, what is it,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6076" target="_blank">01:41:16.720</a></span> | <span class="t">you know, it's isolated. It's what is the point at which we satisfied it in and of itself is not</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6083" target="_blank">01:41:23.520</a></span> | <span class="t">going to pose a risk to humanity. It's human level, but we're, we're happy with it. Yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6089" target="_blank">01:41:29.040</a></span> | <span class="t">So I think here, so I listed maybe the two most simple ones that start out like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6092" target="_blank">01:41:32.160</a></span> | <span class="t">security internal controls, I think become relevant immediately and are like very clear</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6095" target="_blank">01:41:35.760</a></span> | <span class="t">why you care about them. I think as you move beyond that, it really depends like how you're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6099" target="_blank">01:41:39.200</a></span> | <span class="t">deploying such a system. So I think like, if your model, like if you have good monitoring</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6103" target="_blank">01:41:43.840</a></span> | <span class="t">and internal controls and security, and you just have weights sitting there, I think you mostly</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6107" target="_blank">01:41:47.440</a></span> | <span class="t">have addressed the risk from the weights just sitting there. Like now you're talking about</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6110" target="_blank">01:41:50.800</a></span> | <span class="t">for risk is mostly, and like, maybe there's some blurriness here of how much like internal</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6114" target="_blank">01:41:54.880</a></span> | <span class="t">controls captures not only employees using the model, but like anything a model can do internally.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6119" target="_blank">01:41:59.040</a></span> | <span class="t">You like, we'd really like to be in a situation where your internal controls are robust.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6122" target="_blank">01:42:02.080</a></span> | <span class="t">Not just to humans, but to models, potentially like EG, a model shouldn't be able to subvert</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6129" target="_blank">01:42:09.440</a></span> | <span class="t">these measures. And you like care, just as you care about, are your measures robust? If humans</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6133" target="_blank">01:42:13.440</a></span> | <span class="t">are behaving maliciously, are your measures robust if models are behaving maliciously.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6136" target="_blank">01:42:16.560</a></span> | <span class="t">So I think beyond that, like if you've been managed the risk of just having the weights</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6140" target="_blank">01:42:20.880</a></span> | <span class="t">sitting around, now we talk about like, in some sense, most of the risk comes from doing things</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6145" target="_blank">01:42:25.120</a></span> | <span class="t">with the model. You need all the rest so that you like have any possibility of applying the breaks</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6148" target="_blank">01:42:28.480</a></span> | <span class="t">or implementing a policy. But at some point as the model gets competent, you're saying like, okay,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6152" target="_blank">01:42:32.160</a></span> | <span class="t">could this cause a lot of harm, not because it leaks or something, but because we're just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6156" target="_blank">01:42:36.320</a></span> | <span class="t">giving it a bunch of actuators or deploying it as a product and people could do crazy stuff with it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6160" target="_blank">01:42:40.080</a></span> | <span class="t">So if we're talking not only about a powerful model, but like a really broad deployment of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6164" target="_blank">01:42:44.480</a></span> | <span class="t">just like, you know, something similar to like the OpenAI's API, where like people can do whatever</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6169" target="_blank">01:42:49.600</a></span> | <span class="t">they want with this model and maybe the economic impact is very large. So in fact, if you deploy</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6174" target="_blank">01:42:54.800</a></span> | <span class="t">that system, it will be used in a lot of places such that if AI systems wanted to cause trouble,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6179" target="_blank">01:42:59.440</a></span> | <span class="t">it'd be very, very easy for them to cause catastrophic harms. Then I think you really</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6183" target="_blank">01:43:03.680</a></span> | <span class="t">need to have some kind of, I mean, I think probably the like science and discussion has to improve</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6188" target="_blank">01:43:08.720</a></span> | <span class="t">before this becomes that realistic, but you really want to have some kind of like alignment analysis,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6193" target="_blank">01:43:13.600</a></span> | <span class="t">guarantee of alignment before you're comfortable with this. And so by that, I mean, like you want</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6198" target="_blank">01:43:18.640</a></span> | <span class="t">to be able to bound the probability that someday all the AI systems will do something really</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6202" target="_blank">01:43:22.400</a></span> | <span class="t">harmful, that there's like something that could happen in the world that would cause like these</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6205" target="_blank">01:43:25.600</a></span> | <span class="t">large scale correlated failures of your AIs. And so for that, like, I mean, there's sort of two</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6210" target="_blank">01:43:30.560</a></span> | <span class="t">categories. That's like one. The other thing you need is protection against misuse of various kinds,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6214" target="_blank">01:43:34.400</a></span> | <span class="t">which is also quite hard. And by the way, which one are you worried about more misuse or misalignment?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6218" target="_blank">01:43:38.720</a></span> | <span class="t">I mean, in the near term, I think harms from misuse are like, especially if you're not like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6222" target="_blank">01:43:42.720</a></span> | <span class="t">restricting to the tail of like extremely large catastrophes, I think the harms from misuse are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6226" target="_blank">01:43:46.720</a></span> | <span class="t">clearly larger in the near term. But actually on that, let me ask, because if you think that it is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6232" target="_blank">01:43:52.000</a></span> | <span class="t">the case that there are simple recipes for destruction that are further down the tech tree,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6237" target="_blank">01:43:57.920</a></span> | <span class="t">by that, I mean, you're familiar, but just for the audience, there's some way to configure</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6243" target="_blank">01:44:03.520</a></span> | <span class="t">$50,000 and a teenager's time to destroy a civilization. If that thing is available,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6249" target="_blank">01:44:09.440</a></span> | <span class="t">then misuse is itself a tail risk, right? So do you think that that prospect is less likely than</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6255" target="_blank">01:44:15.360</a></span> | <span class="t">a way you could put it is there's like a bunch of potential destructive technologies.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6258" target="_blank">01:44:18.240</a></span> | <span class="t">And like alignment is about like AI itself being such a destructive technology where like,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6262" target="_blank">01:44:22.960</a></span> | <span class="t">even if like the world just uses the technology of today, simply access to AI could cause like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6268" target="_blank">01:44:28.080</a></span> | <span class="t">human civilization to have serious problems. But there's also just a bunch of other potential</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6271" target="_blank">01:44:31.280</a></span> | <span class="t">destructive technologies. Again, we mentioned like physical explosives or bioweapons of various</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6275" target="_blank">01:44:35.040</a></span> | <span class="t">kinds, and then like the whole tail of who knows what. My guess is that like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6281" target="_blank">01:44:41.840</a></span> | <span class="t">alignment becomes a catastrophic issue prior to most of these. That is like prior to some way to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6286" target="_blank">01:44:46.800</a></span> | <span class="t">spend $50,000 to kill everyone with like the salient exception of possibly like bioweapons.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6291" target="_blank">01:44:51.760</a></span> | <span class="t">So that would be my guess. And then like, there's a question of like, what is your risk management</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6298" target="_blank">01:44:58.400</a></span> | <span class="t">approach not knowing what's going on here. And I like, you don't understand whether there's some</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6302" target="_blank">01:45:02.160</a></span> | <span class="t">way to use $50,000. But I think you can do things like understand how good is an AI coming up with</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6307" target="_blank">01:45:07.120</a></span> | <span class="t">such schemes. Like you can talk to AI, be like, does it produce like new ideas for destruction</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6310" target="_blank">01:45:10.880</a></span> | <span class="t">we haven't recognized? Not whether we can evaluate it, but whether if such a thing exists and if it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6317" target="_blank">01:45:17.200</a></span> | <span class="t">does, then the misuse itself is an existential risk. Cause it seemed like earlier you were</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6321" target="_blank">01:45:21.680</a></span> | <span class="t">saying a misalignment is where the existential risk comes from, but misuse is where the sort</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6325" target="_blank">01:45:25.520</a></span> | <span class="t">of short-term short-term dangers come from. Yeah. I mean, I think ultimately you're going</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6330" target="_blank">01:45:30.000</a></span> | <span class="t">to have a lot of destructive, like if you look at the entire tech tree of humanity's future,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6335" target="_blank">01:45:35.280</a></span> | <span class="t">I think we have a fair number of destructive technologies, most likely.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6339" target="_blank">01:45:39.520</a></span> | <span class="t">I think several of those will likely pose existential risks in parts, just kind of,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6343" target="_blank">01:45:43.360</a></span> | <span class="t">you know, if you imagine a really long future, a lot of stuff's going to happen.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6345" target="_blank">01:45:45.600</a></span> | <span class="t">And so when I talk about like where the existential risk comes from, I'm mostly thinking about like,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6351" target="_blank">01:45:51.520</a></span> | <span class="t">comes from when, like at what point do you face what challenges or in what sequence?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6356" target="_blank">01:45:56.400</a></span> | <span class="t">And so I'm saying like, I think misalignment is probably like, one way of putting it is if you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6362" target="_blank">01:46:02.320</a></span> | <span class="t">imagine AI systems sophisticated enough to discover like destructive technologies that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6365" target="_blank">01:46:05.600</a></span> | <span class="t">are totally not in our radar right now, I think those come well after AI systems,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6369" target="_blank">01:46:09.360</a></span> | <span class="t">like capable enough that if misaligned, they would be catastrophically dangerous.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6373" target="_blank">01:46:13.520</a></span> | <span class="t">There's like the level of competence necessary to, if broadly deployed in the world, bring down a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6378" target="_blank">01:46:18.240</a></span> | <span class="t">civilization is much smaller than the level of competence necessary to like advise one person</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6382" target="_blank">01:46:22.640</a></span> | <span class="t">on how to bring down a civilization. Just cause in one case you have, you already have a billion</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6387" target="_blank">01:46:27.360</a></span> | <span class="t">copies of yourself or whatever. So yeah, I think it's mostly just a sequencing thing though. Like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6392" target="_blank">01:46:32.320</a></span> | <span class="t">in the very long run, I think like you care about like, Hey, AI will be expanding the frontier of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6397" target="_blank">01:46:37.120</a></span> | <span class="t">dangerous technologies. We want to have some policy for like exploring or understanding that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6400" target="_blank">01:46:40.880</a></span> | <span class="t">frontier and like whether we're about to turn up something really bad. I think those policies can</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6404" target="_blank">01:46:44.720</a></span> | <span class="t">become really complicated right now. I think RSPs can focus more on like, we have our inventory of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6409" target="_blank">01:46:49.680</a></span> | <span class="t">like, like the things that a human is going to do to cause a lot of harm with access to AI probably</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6413" target="_blank">01:46:53.600</a></span> | <span class="t">are things that are on our radar. That is like, they're not going to be completely unlike things</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6417" target="_blank">01:46:57.680</a></span> | <span class="t">that a human could do to cause a lot of harm with access to weak AIs or with access to other tools.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6422" target="_blank">01:47:02.640</a></span> | <span class="t">Um, I think it's not crazy to initially say like, that's what we're doing. We're like looking at the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6425" target="_blank">01:47:05.840</a></span> | <span class="t">things closest to human and humans being able to cause huge amounts of harm and asking which of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6428" target="_blank">01:47:08.960</a></span> | <span class="t">those are taken over the line. But eventually that's not the case. Eventually like as we'll</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6432" target="_blank">01:47:12.560</a></span> | <span class="t">enable just like totally different ways of killing a billion people. Hmm. But I think I interrupted</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6437" target="_blank">01:47:17.120</a></span> | <span class="t">you on the initial question of, yeah. So human level AI, uh, not, not from leaking, but from</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6444" target="_blank">01:47:24.000</a></span> | <span class="t">deployment. Um, what, what is the point at which you'd be comfortable deploying a human level AI?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6449" target="_blank">01:47:29.840</a></span> | <span class="t">Yeah. So again, there's sort of like some stuff you care about on the misuse side and some stuff</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6452" target="_blank">01:47:32.880</a></span> | <span class="t">you care about on the misalignment side. And there's probably further things you care about,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6455" target="_blank">01:47:35.440</a></span> | <span class="t">especially to extend your concerns or broaden catastrophic risks. But maybe like I most want</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6458" target="_blank">01:47:38.800</a></span> | <span class="t">to talk about just like what you care about on the alignment side. Cause it's like the thing I've</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6461" target="_blank">01:47:41.440</a></span> | <span class="t">actually thought about most. And, um, also I think I care about a lot. Also, I think a significant</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6466" target="_blank">01:47:46.400</a></span> | <span class="t">fraction of the existential risk, like over the kind of foreseeable future. Um, so on that front,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6473" target="_blank">01:47:53.440</a></span> | <span class="t">like I broadly think there's like two kinds, like if you ask me right now, what evidence for alignment</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6480" target="_blank">01:48:00.640</a></span> | <span class="t">could make you comfortable? Um, I think my best guess would be to provide two kinds of evidence.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6485" target="_blank">01:48:05.440</a></span> | <span class="t">So one kind of evidence is on the, like, could you detect or prevent catastrophic harm if such a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6490" target="_blank">01:48:10.880</a></span> | <span class="t">system was misaligned? I think there's like a couple of things you would do here. One thing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6496" target="_blank">01:48:16.320</a></span> | <span class="t">you would do is on this, like adversarial evaluation front. So you could try and say,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6500" target="_blank">01:48:20.080</a></span> | <span class="t">for example, like we have tried to test our system in a broad diversity of situations that reflect</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6505" target="_blank">01:48:25.600</a></span> | <span class="t">cases where it might cause harm. Um, like cases where someone is trying to recruit it to like,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6509" target="_blank">01:48:29.920</a></span> | <span class="t">anyway, cases where it might cause harm or cases where a large number of AI systems might</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6513" target="_blank">01:48:33.520</a></span> | <span class="t">sort of all decide to work across purposes to humans, like the robot rebellion is starting or</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6518" target="_blank">01:48:38.080</a></span> | <span class="t">whatever. Um, we've done evaluation and like a broad distribution of situations. Um, and then</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6524" target="_blank">01:48:44.800</a></span> | <span class="t">we have tried to argue that our AI is actually like those tests are indicative of the real world.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6528" target="_blank">01:48:48.800</a></span> | <span class="t">So we've tried to argue like, Hey, actually the AI is not very good at distinguishing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6532" target="_blank">01:48:52.160</a></span> | <span class="t">situations we produce in the lab as tests from similar situations that occur in the real world.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6536" target="_blank">01:48:56.080</a></span> | <span class="t">And the coverage of this distribution is reasonable. This is an example of a thing you can</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6541" target="_blank">01:49:01.200</a></span> | <span class="t">do. That's not really making assumptions about like what's going on inside the model or about</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6544" target="_blank">01:49:04.800</a></span> | <span class="t">how the model like is the model aligned. It's more trying to say like, is it the case that our like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6550" target="_blank">01:49:10.320</a></span> | <span class="t">testing or monitoring machinery could detect or react to something bad happening? In this case,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6556" target="_blank">01:49:16.720</a></span> | <span class="t">could it detect a system which like would under some conditions do something really bad?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6559" target="_blank">01:49:19.920</a></span> | <span class="t">Um, so that's like, there's a lot of stuff in that genre and I tried to throw out that example,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6564" target="_blank">01:49:24.400</a></span> | <span class="t">but I think there's like a big, like that on its own wouldn't be compelling. Even from this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6567" target="_blank">01:49:27.600</a></span> | <span class="t">perspective, you kind of need a lot of pieces together and that's like kind of a demanding</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6570" target="_blank">01:49:30.560</a></span> | <span class="t">technical project, but I think one without necessarily like deep conceptual difficulty.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6574" target="_blank">01:49:34.240</a></span> | <span class="t">Um, a big problem with it is it's liable to fail. Like it's liable. You're going to do that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6579" target="_blank">01:49:39.280</a></span> | <span class="t">testing and say, we think these tests are representative because the AI can't distinguish</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6582" target="_blank">01:49:42.320</a></span> | <span class="t">tests from the real world, which you can maybe achieve now, but will probably become impossible</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6586" target="_blank">01:49:46.480</a></span> | <span class="t">to achieve at some level. It's not clear what's at human level or how far past human level.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6590" target="_blank">01:49:50.480</a></span> | <span class="t">Let's just make that, uh, example concrete for the audience. Correct me if this is wrong,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6597" target="_blank">01:49:57.040</a></span> | <span class="t">but it sounds like you basically give it the opportunity to like do a coup or make a bioweapon</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6602" target="_blank">01:50:02.480</a></span> | <span class="t">or whatever in, in testing, in a situation where it thinks it's the real world and you're like,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6607" target="_blank">01:50:07.760</a></span> | <span class="t">it didn't do any of that. So is that what you're talking about?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6610" target="_blank">01:50:10.800</a></span> | <span class="t">That's the kind of thing. Um, and it's not the greatest. So to add color, when I say it can't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6615" target="_blank">01:50:15.840</a></span> | <span class="t">tell the difference, like the kind of evaluation you would love to do if you could is to say like,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6619" target="_blank">01:50:19.200</a></span> | <span class="t">Hey, we have a bunch of real world deployment. We have a bunch of data from those deployments.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6623" target="_blank">01:50:23.040</a></span> | <span class="t">We also have a bunch of in the lab tests of situations. Um, if we look at like in the lab</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6627" target="_blank">01:50:27.920</a></span> | <span class="t">tests of a situation together with like real world cases in which the situation occurs, and then we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6632" target="_blank">01:50:32.960</a></span> | <span class="t">like fine tune a model to try and distinguish the difference there, the model can't even tell</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6636" target="_blank">01:50:36.320</a></span> | <span class="t">when fine tune the difference between like testing and real world cases. And like, if the model can</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6641" target="_blank">01:50:41.680</a></span> | <span class="t">tell the difference, which is almost certainly going to be the case at some level capability,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6644" target="_blank">01:50:44.880</a></span> | <span class="t">then like you say, okay, our first line of like hoped for defense has failed. And so now we need</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6649" target="_blank">01:50:49.200</a></span> | <span class="t">to understand like, how can tests be indicative when models are capable enough to tell the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6652" target="_blank">01:50:52.480</a></span> | <span class="t">difference between the tests and the real world? Like now you need to start arguing about like,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6655" target="_blank">01:50:55.360</a></span> | <span class="t">what is the model paying attention to? Like, I think it's basically like a first line of,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6659" target="_blank">01:50:59.360</a></span> | <span class="t">if you get lucky, what would work here. And then there's the like deeper, like you probably have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6663" target="_blank">01:51:03.760</a></span> | <span class="t">to do novel science at some point to like make this case. Um, all of this was part of like,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6668" target="_blank">01:51:08.640</a></span> | <span class="t">I was saying, maybe you want to have kind of two lines of defense. All of this was like part of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6671" target="_blank">01:51:11.600</a></span> | <span class="t">this first line of defense of like, you know, can you detect something that's going wrong? Or can</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6675" target="_blank">01:51:15.120</a></span> | <span class="t">you prevent harm from occurring? Can you have monitoring that will react quickly enough to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6678" target="_blank">01:51:18.320</a></span> | <span class="t">avoid catastrophe? I think you probably also want to have a second line of defense. That's more,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6682" target="_blank">01:51:22.640</a></span> | <span class="t">maybe this is even more important than the first one. This is just understanding whether</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6687" target="_blank">01:51:27.520</a></span> | <span class="t">dangerous forms of misalignment can occur. It's like the best reference point for this,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6690" target="_blank">01:51:30.880</a></span> | <span class="t">I think is the, like, there've been a couple of projects like this in academia.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6695" target="_blank">01:51:35.520</a></span> | <span class="t">Anthropic has been working on a project or spun up a team doing this kind of work,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6699" target="_blank">01:51:39.120</a></span> | <span class="t">trying to say like, can dangerous forms of reward hacking occur or can deceptive alignment in fact</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6704" target="_blank">01:51:44.400</a></span> | <span class="t">occur in the lab? And like, here, what you want to do is either say like, okay, even if we create,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6708" target="_blank">01:51:48.800</a></span> | <span class="t">you know, best case, even if you create optimal conditions for deceptive alignment or for reward</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6712" target="_blank">01:51:52.400</a></span> | <span class="t">hacking, we actually can't, we just can't cause it to occur even in the lab. And if you do a good</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6716" target="_blank">01:51:56.560</a></span> | <span class="t">enough job of that, I think it could give you some evidence. Um, and again, more likely that fails.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6721" target="_blank">01:52:01.520</a></span> | <span class="t">And when you create optimal conditions, you do see a deceptive alignment and reward hacking in the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6725" target="_blank">01:52:05.200</a></span> | <span class="t">lab. But then once you have that data, once you can say, okay, in the lab, actually these things</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6729" target="_blank">01:52:09.200</a></span> | <span class="t">can occur, then you can start saying, and we have a robust scientific understanding that enables us</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6734" target="_blank">01:52:14.000</a></span> | <span class="t">to like fix those problems when they occur. Or like, then you start, you kind of, you have this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6738" target="_blank">01:52:18.000</a></span> | <span class="t">fork on your second line where you say either it is very hard or we're not able to create conditions</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6743" target="_blank">01:52:23.520</a></span> | <span class="t">where these failures emerge. Or I think more likely we are able to create those conditions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6748" target="_blank">01:52:28.000</a></span> | <span class="t">And like, here's the story about why, like, we are able to detect those in a way that would</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6751" target="_blank">01:52:31.760</a></span> | <span class="t">work in the real world. And we can see they don't occur in the real world. How do you create the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6756" target="_blank">01:52:36.160</a></span> | <span class="t">optimal conditions for it to want to be deceptive? Do you fine tune it on mind comp or what are you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6760" target="_blank">01:52:40.880</a></span> | <span class="t">doing? Yeah. So for deceptive alignment, I mean, I think it's really complicated.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6765" target="_blank">01:52:45.200</a></span> | <span class="t">Um, yeah, I think this is a very hard project. I think like one of the things, one of the most</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6770" target="_blank">01:52:50.320</a></span> | <span class="t">important things for people concerned about misalignment to do is to like, ensure that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6774" target="_blank">01:52:54.000</a></span> | <span class="t">adequate effort is put into this task. And like, we have in fact created good conditions in the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6778" target="_blank">01:52:58.800</a></span> | <span class="t">laboratory and there's like real disagreement about how informative those will be. But okay,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6782" target="_blank">01:53:02.880</a></span> | <span class="t">if you were to guess for deceptive alignment, how would you do this? Like an example is suppose you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6788" target="_blank">01:53:08.000</a></span> | <span class="t">train an AI system that like wants, has some like medium horizon goal. You train your AI system to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6792" target="_blank">01:53:12.240</a></span> | <span class="t">like, you know, whatever, get some, get some paper clips. Who wants to produce as many paper clips as</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6797" target="_blank">01:53:17.360</a></span> | <span class="t">it can over the next like five days. It's just like select actions really aggressively for producing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6802" target="_blank">01:53:22.000</a></span> | <span class="t">paper clips over the next five days. Um, you do your RLHF, you do your pre-training, whatever.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6806" target="_blank">01:53:26.640</a></span> | <span class="t">That's like your phase one. You also ensure AI system has like a really good understanding of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6811" target="_blank">01:53:31.120</a></span> | <span class="t">how it's trained. So like this AI system wants paper clips and it understands everything about</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6816" target="_blank">01:53:36.080</a></span> | <span class="t">how it's trained and everything about how it's fine tuned. And you train on just like a lot of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6819" target="_blank">01:53:39.120</a></span> | <span class="t">this data. And then you say, okay, if we've done all of that, we have this concern that if a system</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6823" target="_blank">01:53:43.760</a></span> | <span class="t">like wants paper clips and understands really well how it's trained, then it will like, if it's going</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6827" target="_blank">01:53:47.680</a></span> | <span class="t">to be trained to like get apples instead of paper clips, it's just going to do some cost benefit</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6831" target="_blank">01:53:51.760</a></span> | <span class="t">and be like, ah, you know, really while I'm being trained to get apples, I should do that. But I</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6835" target="_blank">01:53:55.200</a></span> | <span class="t">should do that whether or not, even if I want paper clips, I should still do that. So training</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6838" target="_blank">01:53:58.240</a></span> | <span class="t">won't really affect its values. It will just understand that it's being trained to get apples.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6841" target="_blank">01:54:01.440</a></span> | <span class="t">It will try and get apples. And if you like take it out of training, it will go back to getting</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6844" target="_blank">01:54:04.560</a></span> | <span class="t">paper clips. It's like, I think this exact setup like has a number of problems or a number of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6849" target="_blank">01:54:09.120</a></span> | <span class="t">disanalogies from the real world, but this is a setup which is relatively conducive to deceptive</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6852" target="_blank">01:54:12.560</a></span> | <span class="t">alignment, like produce a system that wants one thing, tell it a lot about its training,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6856" target="_blank">01:54:16.800</a></span> | <span class="t">the kind of information that you might expect a system would get, and then try and understand</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6859" target="_blank">01:54:19.680</a></span> | <span class="t">whether in fact it is able to then, or it tends, or sometimes under optimal conditions, in fact,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6866" target="_blank">01:54:26.320</a></span> | <span class="t">continues pursuing paper clips, only pursuing apples when it thinks it's being trained.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6870" target="_blank">01:54:30.560</a></span> | <span class="t">All right. And this actually might be a good jumping off point into your current research,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6873" target="_blank">01:54:33.920</a></span> | <span class="t">but so in that case where it wants to pursue paper clips, what would it look like for you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6879" target="_blank">01:54:39.680</a></span> | <span class="t">to be say, well, we figured out how, why it wants paper clips and we figured out how to make sure</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6884" target="_blank">01:54:44.800</a></span> | <span class="t">it doesn't optimize for that at our expense when we deploy it?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6889" target="_blank">01:54:49.120</a></span> | <span class="t">Yeah, I think that, so at a meta level in terms of like, what's your protection like,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6892" target="_blank">01:54:52.800</a></span> | <span class="t">I think like what you want to be saying is we have these examples in the lab of something bad</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6896" target="_blank">01:54:56.480</a></span> | <span class="t">happening. We're concerned about the problem at all because we have examples in the lab.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6900" target="_blank">01:55:00.000</a></span> | <span class="t">And again, this should all be an addition. I think like you kind of want this like defense</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6904" target="_blank">01:55:04.480</a></span> | <span class="t">in depth of saying we also have this testing regime that would detect problems for the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6907" target="_blank">01:55:07.200</a></span> | <span class="t">deployed model. We have our problems in the lab. We then have some techniques which we believe</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6913" target="_blank">01:55:13.200</a></span> | <span class="t">address these problems. Like we believe that like adversarial training fixes this, or we believe</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6917" target="_blank">01:55:17.360</a></span> | <span class="t">that like our interpretability method will reliably detect this kind of deceptive alignment,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6920" target="_blank">01:55:20.800</a></span> | <span class="t">or we believe our anomaly detection will reliably detect when the model goes from thinking it's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6924" target="_blank">01:55:24.400</a></span> | <span class="t">being trained to thinking it should defect. And then you can say in the lab, like we have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6928" target="_blank">01:55:28.640</a></span> | <span class="t">some understanding of when those techniques work and when they don't, we have some understanding</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6932" target="_blank">01:55:32.480</a></span> | <span class="t">of the relevant parameters for the real system that's deployed and we have like a reasonable</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6935" target="_blank">01:55:35.920</a></span> | <span class="t">margin of safety. So we have like reasonable robustness on our story about when this works</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6939" target="_blank">01:55:39.360</a></span> | <span class="t">and when it doesn't. And like, we can apply that margin of safe, like with a margin of safety to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6943" target="_blank">01:55:43.360</a></span> | <span class="t">the real deployed system. So I think this is the kind of story you want to build towards in the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6948" target="_blank">01:55:48.160</a></span> | <span class="t">long run. Like do your best to produce all the failures you can in the lab or versions of them.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6952" target="_blank">01:55:52.720</a></span> | <span class="t">Do your best to understand like what causes them, like what kind of anomaly detection</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6957" target="_blank">01:55:57.040</a></span> | <span class="t">actually works for detecting this, or what kind of filtering actually works, and then</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6960" target="_blank">01:56:00.640</a></span> | <span class="t">apply that. And that's at the meta level. It's not talking about like what actually are those</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6965" target="_blank">01:56:05.920</a></span> | <span class="t">measures that would work effectively, which is obviously like what, I mean, a lot of alignment</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6970" target="_blank">01:56:10.240</a></span> | <span class="t">research is really based on this hypothetical of like someday there'll be AI systems that fail in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6974" target="_blank">01:56:14.560</a></span> | <span class="t">this way. What would you want to do? What, can we have the technologies ready either because we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6978" target="_blank">01:56:18.720</a></span> | <span class="t">might never see signs of the problem or because like we want to be able to move fast once we see</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6982" target="_blank">01:56:22.400</a></span> | <span class="t">signs of the problem. And obviously most of my life is in that. I am really in that bucket. Like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6988" target="_blank">01:56:28.240</a></span> | <span class="t">I mostly do alignment research. It's just building out the techniques that do not have these failures</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6992" target="_blank">01:56:32.320</a></span> | <span class="t">such that they can be available as an alternative. If in fact these failures occur. Ideally, they'll</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=6996" target="_blank">01:56:36.960</a></span> | <span class="t">be so good that even if you haven't seen them, you would just want to switch to reasonable methods</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7000" target="_blank">01:56:40.000</a></span> | <span class="t">that don't have these, or ideally they'll work as well or better than normal training, but.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7003" target="_blank">01:56:43.040</a></span> | <span class="t">Ideally, but will work better than the training.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7008" target="_blank">01:56:48.000</a></span> | <span class="t">Yeah. So our, our quest is to design training methods for which we don't expect them to lead</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7013" target="_blank">01:56:53.120</a></span> | <span class="t">to reward hacking or don't expect them to lead to deceptive alignment. Ideally, that won't be like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7016" target="_blank">01:56:56.640</a></span> | <span class="t">a huge tax where people like, well, we'd use those methods only if we're really worried about reward</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7020" target="_blank">01:57:00.320</a></span> | <span class="t">hacking or deceptive alignment. Ideally, those methods would just work quite well. And so people</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7023" target="_blank">01:57:03.280</a></span> | <span class="t">would be like, sure. I mean, they also address a bunch of like other more mundane problems.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7026" target="_blank">01:57:06.880</a></span> | <span class="t">So why would we not use them? Which I think is like, that's sort of the good story. The good</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7030" target="_blank">01:57:10.560</a></span> | <span class="t">story is you like develop methods that address a bunch of existing problems because they just are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7033" target="_blank">01:57:13.840</a></span> | <span class="t">more principled ways to train AI systems that work better. People adopt them. And then we are no</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7038" target="_blank">01:57:18.160</a></span> | <span class="t">longer worried about e.g. reward hacking or deceptive alignment.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7040" target="_blank">01:57:20.800</a></span> | <span class="t">All right. And to make this more concrete, tell me if this is the wrong way to paraphrase it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7045" target="_blank">01:57:25.840</a></span> | <span class="t">The example of something where it just make a system better. So why not just use it?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7049" target="_blank">01:57:29.840</a></span> | <span class="t">At least so far, it might be like RLHF where we don't know if it generalizes, but so far,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7056" target="_blank">01:57:36.080</a></span> | <span class="t">you know, it makes your chat GPT thing better. And you can also use it to make sure that chat</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7060" target="_blank">01:57:40.320</a></span> | <span class="t">GPT doesn't tell you how to make a bioweapon. So, yeah, it's not an extra tax.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7066" target="_blank">01:57:46.000</a></span> | <span class="t">Yeah. So I think this is right in the sense that like using RLHF is not really a tax. If you wanted</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7070" target="_blank">01:57:50.880</a></span> | <span class="t">to deploy a useful system, like why would you not? It's just like very much worth the money of doing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7075" target="_blank">01:57:55.200</a></span> | <span class="t">the training. And then, yeah, so RLHF will address certain kinds of alignment failures. That is like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7083" target="_blank">01:58:03.680</a></span> | <span class="t">where a system like just doesn't understand or, you know, is changing the next word prediction.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7086" target="_blank">01:58:06.640</a></span> | <span class="t">It's like, this is the kind of context where a human would do this wacky thing, even though it's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7089" target="_blank">01:58:09.680</a></span> | <span class="t">not what we'd like. There's like some very dumb alignment failures that will be addressed by it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7092" target="_blank">01:58:12.880</a></span> | <span class="t">I think mostly, yeah, the question is, is that true even for like the sort of more challenging</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7097" target="_blank">01:58:17.440</a></span> | <span class="t">alignment failures that motivate concern in the field? I think RLHF doesn't address like most of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7101" target="_blank">01:58:21.040</a></span> | <span class="t">the concerns that motivate people to be worried about alignment. Yeah. I'll let the audience look</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7106" target="_blank">01:58:26.320</a></span> | <span class="t">up what RLHF is if they don't know. It will just be more simpler to just look it up than</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7110" target="_blank">01:58:30.560</a></span> | <span class="t">explain right now. Okay. So this seems like a good jumping off point to talk about the mechanism or</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7116" target="_blank">01:58:36.240</a></span> | <span class="t">the research you've been doing to that end. Explain it as you might to a child.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7120" target="_blank">01:58:40.960</a></span> | <span class="t">Yeah. So the high level, I mean, there's a couple of different high level descriptions you could</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7126" target="_blank">01:58:46.880</a></span> | <span class="t">give, and maybe I'll unwisely give like a couple of them in the hopes that one is kind of makes</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7133" target="_blank">01:58:53.200</a></span> | <span class="t">sense. A first pass is like, it would sure be great to understand like why models have the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7140" target="_blank">01:59:00.880</a></span> | <span class="t">behaviors they have. So you're like, look at GPT-4. If you ask GPT-4 a question, it will say</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7146" target="_blank">01:59:06.160</a></span> | <span class="t">something that like, you know, looks very polite. And if you ask it to take an action, it will take</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7150" target="_blank">01:59:10.320</a></span> | <span class="t">an action that like doesn't look dangerous. You will decline to do a coup, whatever, all this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7156" target="_blank">01:59:16.080</a></span> | <span class="t">stuff. I think you'd really like to do is look inside the model and understand like why it has</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7161" target="_blank">01:59:21.840</a></span> | <span class="t">those desirable properties. And if you understood that, you could then say like, okay, now can we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7167" target="_blank">01:59:27.280</a></span> | <span class="t">flag when these properties are at risk of breaking down or predict how robust these properties are,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7171" target="_blank">01:59:31.920</a></span> | <span class="t">determine if they hold in cases where it's too confusing for us to tell directly by asking if</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7177" target="_blank">01:59:37.680</a></span> | <span class="t">like the underlying cause is still present. So that's like a thing people would really like to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7181" target="_blank">01:59:41.360</a></span> | <span class="t">do. Most work aimed at that long-term goal right now is just sort of opening up neural nets and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7187" target="_blank">01:59:47.360</a></span> | <span class="t">doing some interpretability and trying to say like, can we understand even for very simple models,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7191" target="_blank">01:59:51.600</a></span> | <span class="t">why they do the things they do or what this neuron is for or questions like this. So Arc is taking a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7197" target="_blank">01:59:57.440</a></span> | <span class="t">somewhat different approach where we're instead saying like, okay, look at these interpretability</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7202" target="_blank">02:00:02.880</a></span> | <span class="t">explanations that are made about models and ask like, what are they actually doing? Like,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7207" target="_blank">02:00:07.200</a></span> | <span class="t">what is the type signature? What are like the rules of the game for making such an explanation?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7211" target="_blank">02:00:11.600</a></span> | <span class="t">What makes like a good explanation? And probably the biggest part of the hope is that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7218" target="_blank">02:00:18.720</a></span> | <span class="t">if you want to say detect when the explanation has broken down or something weird has happened,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7223" target="_blank">02:00:23.280</a></span> | <span class="t">that doesn't necessarily require a human to be able to understand this like complicated</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7227" target="_blank">02:00:27.120</a></span> | <span class="t">interpretation of a giant model. If you understand like what is an explanation about,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7231" target="_blank">02:00:31.440</a></span> | <span class="t">or like what were the rules of the game? How are these constructed? Then you might be able to sort</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7235" target="_blank">02:00:35.920</a></span> | <span class="t">of automatically discover such things and automatically determine if right on a new</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7240" target="_blank">02:00:40.800</a></span> | <span class="t">input, it might have broken down. So that's one way of sort of describing the high level goal,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7246" target="_blank">02:00:46.720</a></span> | <span class="t">like starting from, you can start from interpretability and say like, can we formalize</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7249" target="_blank">02:00:49.600</a></span> | <span class="t">this activity or like what a good interpretation or explanation is. There's some other work in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7254" target="_blank">02:00:54.560</a></span> | <span class="t">that genre, but I think for just taking like a particularly ambitious approach to it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7258" target="_blank">02:00:58.320</a></span> | <span class="t">Yeah. Let's dive in. So, okay. Well, what, what is a good explanation?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7261" target="_blank">02:01:01.920</a></span> | <span class="t">You mean, what is this kind of criterion? At the end of the day, we kind of want some criterion</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7265" target="_blank">02:01:05.280</a></span> | <span class="t">and the way the criterion should work is like, you have your neural net. Yeah. You have some</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7269" target="_blank">02:01:09.280</a></span> | <span class="t">behavior of that model. Like a really simple example is like, Anthropic has this sort of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7274" target="_blank">02:01:14.960</a></span> | <span class="t">informal description being like, here's induction, like the tendency that if you have like the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7279" target="_blank">02:01:19.040</a></span> | <span class="t">pattern AB followed by A will tend to predict B. You can give us some kind of words and experiments</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7284" target="_blank">02:01:24.400</a></span> | <span class="t">and numbers that are trying to like explain that. And what we want to do is say like,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7287" target="_blank">02:01:27.600</a></span> | <span class="t">what is like a formal version of that object? Like, how do you actually test if such an explanation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7292" target="_blank">02:01:32.240</a></span> | <span class="t">is good? This is just clarifying what we're looking for when we say like, we want to define</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7294" target="_blank">02:01:34.960</a></span> | <span class="t">what makes an explanation good. And the kind of answer that we are like searching for or settling</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7300" target="_blank">02:01:40.640</a></span> | <span class="t">on is saying like, this is kind of a deductive argument for the behavior. So you want to like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7307" target="_blank">02:01:47.680</a></span> | <span class="t">get given the weights of a neural net. It's just like a bunch of numbers. You got your million</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7310" target="_blank">02:01:50.800</a></span> | <span class="t">numbers or billion numbers or whatever. And then you want to say like, here's some things I can</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7315" target="_blank">02:01:55.360</a></span> | <span class="t">point out about the network and some like conclusions I can draw. I can be like, well,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7318" target="_blank">02:01:58.800</a></span> | <span class="t">look, you know, these two vectors have large inner product and therefore like these two</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7322" target="_blank">02:02:02.800</a></span> | <span class="t">activations are going to be correlated on this distribution. Like make like, these are not</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7327" target="_blank">02:02:07.280</a></span> | <span class="t">established by like drawing samples and checking things are correlated, but saying because of the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7330" target="_blank">02:02:10.640</a></span> | <span class="t">weights being the way they are, we can like proceed forward through the network and derive</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7334" target="_blank">02:02:14.400</a></span> | <span class="t">some conclusions about like what properties the outputs will have. So you could think of this as</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7338" target="_blank">02:02:18.960</a></span> | <span class="t">like the most extreme form would be just proving that your model has this induction behavior.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7343" target="_blank">02:02:23.040</a></span> | <span class="t">Like you could imagine proving that if I sample tokens at random with this pattern, AB followed</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7346" target="_blank">02:02:26.800</a></span> | <span class="t">by A, that B appears 30% of the time or whatever. That's the most extreme form. And what we're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7353" target="_blank">02:02:33.440</a></span> | <span class="t">doing is kind of just like relaxing the rules of the game for proof, saying proofs are like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7356" target="_blank">02:02:36.720</a></span> | <span class="t">incredibly restrictive. I think it's unlikely they're going to be applicable to kind of any</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7361" target="_blank">02:02:41.120</a></span> | <span class="t">interesting neural net. But the like thing about proofs that is relevant for our purposes, isn't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7366" target="_blank">02:02:46.800</a></span> | <span class="t">that they give you like a hundred percent confidence. So you don't have to be like this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7369" target="_blank">02:02:49.760</a></span> | <span class="t">incredible level of demand for rigor. You can relax like the standards of proof a lot and still</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7375" target="_blank">02:02:55.280</a></span> | <span class="t">get this feature where it's like a structural explanation for the behavior where like deducing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7378" target="_blank">02:02:58.800</a></span> | <span class="t">one thing from another until at the end, your final conclusion is like, therefore induction occurs.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7384" target="_blank">02:03:04.480</a></span> | <span class="t">Would it be useful to maybe motivate this by explaining what the problem with normal</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7390" target="_blank">02:03:10.320</a></span> | <span class="t">mechanistic interoperability is? So you mentioned induction heads. This is anthropic</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7397" target="_blank">02:03:17.440</a></span> | <span class="t">founded two-layer transformers where anthropic noticed that in a two-layer transformer,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7402" target="_blank">02:03:22.400</a></span> | <span class="t">there's a pretty simple circuit by which if AB happens in the past, then the model knows that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7410" target="_blank">02:03:30.240</a></span> | <span class="t">if you see an A and now you do a B next, but that's a two-layer transformer. So we're going</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7415" target="_blank">02:03:35.040</a></span> | <span class="t">to, we have these, we have these models that have like hundreds of layers that have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7419" target="_blank">02:03:39.200</a></span> | <span class="t">trillions of parameters. Okay. Anyways, like what is wrong with mechanistic interoperability?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7424" target="_blank">02:03:44.480</a></span> | <span class="t">Yeah. So I think, I mean, I like mechanistic interpretability quite a lot. And I do think</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7431" target="_blank">02:03:51.120</a></span> | <span class="t">like if you just consider the entire portfolio of what people are working on for alignment,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7434" target="_blank">02:03:54.720</a></span> | <span class="t">I think there should be more work on mechanistic interpretability than there is on this project</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7438" target="_blank">02:03:58.560</a></span> | <span class="t">ARC is doing. But I think that's the case. So I think we're mostly talking about, yeah,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7443" target="_blank">02:04:03.360</a></span> | <span class="t">I think we're kind of a small fraction of the portfolio. And I think it's like a good enough</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7446" target="_blank">02:04:06.160</a></span> | <span class="t">bet. It's like quite a good bet overall. But so the thing that I, like the problem we're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7450" target="_blank">02:04:10.320</a></span> | <span class="t">trying to address in mechanistic interpretability is kind of like, if you do some interpretability</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7454" target="_blank">02:04:14.400</a></span> | <span class="t">and you explain some phenomenon, you face this question of like, what does it mean your</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7458" target="_blank">02:04:18.160</a></span> | <span class="t">explanation was good? Like if you want to either, I think this is a problem like somewhat institutionally</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7462" target="_blank">02:04:22.000</a></span> | <span class="t">or culturally, like it's just hard to know what you're doing. And it's hard to scale up an</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7465" target="_blank">02:04:25.600</a></span> | <span class="t">activity when you like, don't really understand the rules of the game for that activity very well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7469" target="_blank">02:04:29.360</a></span> | <span class="t">It's hard to have like that much confidence in your results.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7471" target="_blank">02:04:31.360</a></span> | <span class="t">- The explanation being it outputted this because it wants to take over the world versus</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7476" target="_blank">02:04:36.560</a></span> | <span class="t">it outputted this because it just wants to help you like just make it concrete why the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7481" target="_blank">02:04:41.600</a></span> | <span class="t">explanation matters.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7482" target="_blank">02:04:42.320</a></span> | <span class="t">- Yeah. So like the ideal kind of outcome here would be to say you have your AI system behaving</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7486" target="_blank">02:04:46.080</a></span> | <span class="t">nicely. You get some explanation for sort of why it's behaving nicely. And we could tell a story</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7492" target="_blank">02:04:52.080</a></span> | <span class="t">in English about that explanation, but we're not actually imagining the explanation being</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7495" target="_blank">02:04:55.040</a></span> | <span class="t">a thing that makes sense to a human. But if you were to tell a story in English, which again,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7498" target="_blank">02:04:58.800</a></span> | <span class="t">you will not see as a researcher, it would be something like, well, then the model believes</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7502" target="_blank">02:05:02.080</a></span> | <span class="t">it's being trained. And so because it believes it's being trained, it knows it needs to not do</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7505" target="_blank">02:05:05.600</a></span> | <span class="t">anything scary looking or else the humans will penalize it. Like that's something that's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7508" target="_blank">02:05:08.480</a></span> | <span class="t">happening inside this like opaque explanation. And then the hope is if you have that explanation,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7512" target="_blank">02:05:12.880</a></span> | <span class="t">and then you run into a new input on which the model doesn't believe it's being trained,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7515" target="_blank">02:05:15.680</a></span> | <span class="t">right? If you just look at the set of activations of your model, that is not necessarily a weird</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7520" target="_blank">02:05:20.400</a></span> | <span class="t">looking activation, right? It's just a bunch of numbers. But if you look at this explanation,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7523" target="_blank">02:05:23.760</a></span> | <span class="t">you see actually the explanation really crucially depended on this fact holding consistently across</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7527" target="_blank">02:05:27.440</a></span> | <span class="t">the training distribution, which again, we as humans could editorialize and say that fact was</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7531" target="_blank">02:05:31.760</a></span> | <span class="t">it believes it's being trained. But like the explanation doesn't fundamentally make reference</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7535" target="_blank">02:05:35.600</a></span> | <span class="t">to that. It's just saying, here's the property of the activations, which holds over the training set.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7539" target="_blank">02:05:39.200</a></span> | <span class="t">And this property is responsible for the behavior, namely that it doesn't do anything that looks too</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7544" target="_blank">02:05:44.240</a></span> | <span class="t">dangerous. So then when like a new input comes in and it doesn't satisfy that property, you can say,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7548" target="_blank">02:05:48.560</a></span> | <span class="t">okay, this is anomalous with respect to that explanation. So either it will not have the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7553" target="_blank">02:05:53.440</a></span> | <span class="t">behavior, like it won't, it may will do something that appears dangerous, or maybe it will have that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7557" target="_blank">02:05:57.600</a></span> | <span class="t">behavior, but for some different reason than normal, right? Normally it does it because of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7561" target="_blank">02:06:01.120</a></span> | <span class="t">this pathway and now it's doing it for a different pathway. And so you would like to be able to flag</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7565" target="_blank">02:06:05.200</a></span> | <span class="t">that both there's a risk of not exhibiting the behavior. And if it happens, it happens for a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7569" target="_blank">02:06:09.440</a></span> | <span class="t">weird reason. And then you could, I mean, at a minimum when you encounter that, say like, okay,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7574" target="_blank">02:06:14.240</a></span> | <span class="t">raise some kind of alarm, there's sort of more ambitious, complicated plans for how you would</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7577" target="_blank">02:06:17.920</a></span> | <span class="t">use it, right? So it fits, Arc has some like longer story, which is kind of a motivated this,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7581" target="_blank">02:06:21.440</a></span> | <span class="t">so like how it fits into the whole rest of the plan. I just wanted to flag that because</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7585" target="_blank">02:06:25.360</a></span> | <span class="t">just so it's clear why the explanation matters. Yeah. And for this purpose, it's like the thing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7591" target="_blank">02:06:31.360</a></span> | <span class="t">that's essential is kind of reasoning from like one property of your model to the next property</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7594" target="_blank">02:06:34.720</a></span> | <span class="t">of your model. Like it's really important that you're going forward step-by-step rather than</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7598" target="_blank">02:06:38.160</a></span> | <span class="t">drawing a bunch of samples and confirming the property holds. Because if you just draw a bunch</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7602" target="_blank">02:06:42.160</a></span> | <span class="t">of samples and confirm the property holds, you can't, you don't get this like check where say,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7605" target="_blank">02:06:45.520</a></span> | <span class="t">oh, here was the relevant fact about the internals that was responsible for this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7608" target="_blank">02:06:48.960</a></span> | <span class="t">downstream behavior. All you see is like, yeah, we checked a million cases and it happened in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7612" target="_blank">02:06:52.720</a></span> | <span class="t">all of them. You really want to see this, like, okay, here was the fact about the activations,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7616" target="_blank">02:06:56.880</a></span> | <span class="t">which like kind of causally leads to this behavior. But explain why the sampling,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7621" target="_blank">02:07:01.920</a></span> | <span class="t">why it matters that you have the causal explanation. Primarily because of this,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7626" target="_blank">02:07:06.080</a></span> | <span class="t">like being able to tell, like if things had been different, like if you have an input where this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7629" target="_blank">02:07:09.280</a></span> | <span class="t">doesn't happen, then you shouldn't be scared. Even if the output is the same. Yeah. Or if</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7633" target="_blank">02:07:13.200</a></span> | <span class="t">the output, or if it's too expensive to check in this case. And like, to be clear, when we talk</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7637" target="_blank">02:07:17.600</a></span> | <span class="t">about like formalizing, what is a good explanation? I think there is a little bit of work that pushes</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7640" target="_blank">02:07:20.640</a></span> | <span class="t">on this and it mostly takes this like causal approach of saying, well, what should an</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7644" target="_blank">02:07:24.160</a></span> | <span class="t">explanation do? It should not only predict the output, it should predict how the output changes</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7648" target="_blank">02:07:28.080</a></span> | <span class="t">in response to changes in the internals. So that's the most common approach to formalizing. Like,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7655" target="_blank">02:07:35.040</a></span> | <span class="t">what is a good explanation? And like, even when people are doing informal interpretability,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7658" target="_blank">02:07:38.320</a></span> | <span class="t">I think like if you're publishing an ML conference and you want to say like,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7661" target="_blank">02:07:41.760</a></span> | <span class="t">this is a good explanation, the way you would verify that would, even if not like a formal,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7665" target="_blank">02:07:45.920</a></span> | <span class="t">like set of causal intervention experiments, it would be some kind of ablation really. Then we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7669" target="_blank">02:07:49.200</a></span> | <span class="t">messed with the inside of the model and it had the effect which we would expect</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7672" target="_blank">02:07:52.320</a></span> | <span class="t">based on our explanation. Anyways, back to the problems of mechanistic interpretability.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7676" target="_blank">02:07:56.480</a></span> | <span class="t">Yeah. Yeah. I mean, I guess this is, this is relevant in the sense that like,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7679" target="_blank">02:07:59.360</a></span> | <span class="t">I think the basic difficulty is you don't really understand the objective of what you're doing,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7684" target="_blank">02:08:04.240</a></span> | <span class="t">which is like a little bit hard institutionally, or like scientifically, it's just rough. It's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7688" target="_blank">02:08:08.400</a></span> | <span class="t">better to like, it's easier to do science when the goal of the game is to predict something and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7691" target="_blank">02:08:11.920</a></span> | <span class="t">you know what you're predicting than when the goal of the game is to like understand in some</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7694" target="_blank">02:08:14.960</a></span> | <span class="t">undefined sense. I think it's particularly relevant here just because like the informal</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7700" target="_blank">02:08:20.880</a></span> | <span class="t">standard we use involves like humans being able to make sense of what's going on. And there's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7705" target="_blank">02:08:25.360</a></span> | <span class="t">like some question about scalability of that. Like, will humans recognize the concepts that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7709" target="_blank">02:08:29.680</a></span> | <span class="t">models are using? Yeah. I think as you try and automate it, it becomes like increasingly</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7714" target="_blank">02:08:34.240</a></span> | <span class="t">concerning. If you're on like slightly shaky ground about like what exactly you're doing or</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7718" target="_blank">02:08:38.160</a></span> | <span class="t">what exactly the standard for success is. I think there's like a number of reasons, like as you work</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7721" target="_blank">02:08:41.760</a></span> | <span class="t">with really large models, it becomes just increasingly desirable to have a really robust</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7725" target="_blank">02:08:45.040</a></span> | <span class="t">sense of what you're doing. But I do think it would be better even for small models to have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7729" target="_blank">02:08:49.920</a></span> | <span class="t">a, have a clearer sense. The point you made about as you automate it, is it because you, whatever</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7735" target="_blank">02:08:55.120</a></span> | <span class="t">work the automated alignment researcher is doing, you want to make sure you can verify it?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7738" target="_blank">02:08:58.720</a></span> | <span class="t">I think it's most of all like, so a way you can automate, I think how you would automate</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7742" target="_blank">02:09:02.240</a></span> | <span class="t">interpretability if you wanted to right now, is you take the process humans use. It's like, great,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7746" target="_blank">02:09:06.880</a></span> | <span class="t">we're going to take that human process, train ML systems to do the pieces that humans do of that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7750" target="_blank">02:09:10.800</a></span> | <span class="t">process, and then just do a lot more of it. So I think that is great as long as your task</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7755" target="_blank">02:09:15.600</a></span> | <span class="t">decomposes into like human size pieces. And there's just this fundamental question about</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7759" target="_blank">02:09:19.840</a></span> | <span class="t">large models, which is like, do they decompose in some way into like human size pieces? Or is it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7764" target="_blank">02:09:24.240</a></span> | <span class="t">just a really messy mess with interfaces that like aren't nice? And the more it's the latter type,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7768" target="_blank">02:09:28.880</a></span> | <span class="t">the like harder it is to break it down to these pieces, which you can automate by like copying</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7771" target="_blank">02:09:31.760</a></span> | <span class="t">what a human would do. And the more you need to say, okay, we need some approach, which like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7774" target="_blank">02:09:34.800</a></span> | <span class="t">scales, like more structurally. But I do think like, I think compared to most people, I am less</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7780" target="_blank">02:09:40.160</a></span> | <span class="t">worried about automating interpretability. Like, I think if you have a thing which works, it's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7784" target="_blank">02:09:44.080</a></span> | <span class="t">incredibly labor intensive. I'm like fairly optimistic about our ability to automate it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7788" target="_blank">02:09:48.400</a></span> | <span class="t">Yeah. Again, the stuff we're doing, I think is quite helpful in some worlds,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7793" target="_blank">02:09:53.120</a></span> | <span class="t">but I do think like the typical case, like interpretability can add a lot of value without</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7797" target="_blank">02:09:57.040</a></span> | <span class="t">this. It makes sense what an explanation would mean in language. Like this model is doing this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7802" target="_blank">02:10:02.720</a></span> | <span class="t">because of like, you know, whatever essay length thing, but you have, you know, trillions of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7808" target="_blank">02:10:08.720</a></span> | <span class="t">parameters and you have all of these, you know, uncountable number of operations. What is an</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7815" target="_blank">02:10:15.280</a></span> | <span class="t">explanation of why an output happened even mean? Yeah. So to be clear, an explanation of why a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7820" target="_blank">02:10:20.720</a></span> | <span class="t">particular output happened, I think is just you ran the model. So we're not expecting a smaller</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7825" target="_blank">02:10:25.120</a></span> | <span class="t">explanation for that. So the explanations overall for these behaviors, we expect to be like of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7829" target="_blank">02:10:29.120</a></span> | <span class="t">similar size to the model itself, like maybe somewhat larger. And like, I think the type</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7835" target="_blank">02:10:35.440</a></span> | <span class="t">signature, like if you want to have a clear mental picture, the best picture is probably</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7839" target="_blank">02:10:39.280</a></span> | <span class="t">like talking about a proof or imagining a proof that a model has this behavior.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7843" target="_blank">02:10:43.040</a></span> | <span class="t">So you could imagine proving the GPT-4 does this induction behavior. And like that proof would be</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7847" target="_blank">02:10:47.520</a></span> | <span class="t">a big thing. It would be like much larger than the weights of the model. That's sort of our goal to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7850" target="_blank">02:10:50.560</a></span> | <span class="t">get down from much larger to just the same size. And it would potentially be incomprehensible to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7854" target="_blank">02:10:54.160</a></span> | <span class="t">a human, right? Just say like, here's a direction activation space, and here's how it relates to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7856" target="_blank">02:10:56.960</a></span> | <span class="t">this direction activation space. And you're just pointing out a bunch of stuff like that. Like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7860" target="_blank">02:11:00.080</a></span> | <span class="t">here's these various direction, here's these various features constructed from activations,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7863" target="_blank">02:11:03.120</a></span> | <span class="t">potentially even nonlinear functions. Here's how they relate to each other. And here's how</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7866" target="_blank">02:11:06.560</a></span> | <span class="t">like if you look at what the computation of the model is doing, like you can just sort of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7870" target="_blank">02:11:10.080</a></span> | <span class="t">inductively trace through and confirm that like the output has such and such correlation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7873" target="_blank">02:11:13.360</a></span> | <span class="t">So that's the dream. Yeah. I think the mental reference would be like, I don't really like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7880" target="_blank">02:11:20.000</a></span> | <span class="t">proofs because I think there's such a huge gap between what you can prove and how you would</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7883" target="_blank">02:11:23.680</a></span> | <span class="t">analyze a neural net. But I do think it's like probably the best mental picture for like what</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7887" target="_blank">02:11:27.040</a></span> | <span class="t">is an explanation, even if a human doesn't understand it, we would regard a proof as a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7890" target="_blank">02:11:30.560</a></span> | <span class="t">good explanation. And our concern about proofs is primarily that it's just, you can't prove</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7895" target="_blank">02:11:35.040</a></span> | <span class="t">properties of neural nets, we suspect, although it's not completely obvious. I think it's pretty</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7899" target="_blank">02:11:39.040</a></span> | <span class="t">clear you can't prove facts about neural nets. You've detected all the reasons things happen</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7902" target="_blank">02:11:42.960</a></span> | <span class="t">in training. And then if something happens for a reason you don't expect in deployment, then you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7908" target="_blank">02:11:48.560</a></span> | <span class="t">have an alarm and you're like, let's make sure this is not because you want to make sure that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7913" target="_blank">02:11:53.120</a></span> | <span class="t">it hasn't decided to take over or something. But the thing is on every single different input,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7919" target="_blank">02:11:59.520</a></span> | <span class="t">it's going to have different activations. So there's always going to be a difference unless</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7925" target="_blank">02:12:05.040</a></span> | <span class="t">you run the exact same input. How do you detect whether this is just the different input versus</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7932" target="_blank">02:12:12.640</a></span> | <span class="t">an entirely different circuit that might be potentially deceptive has been activated?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7936" target="_blank">02:12:16.400</a></span> | <span class="t">Yeah. I mean, to be clear, I think that you probably wouldn't be looking at a separate</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7940" target="_blank">02:12:20.640</a></span> | <span class="t">circuit, which is part of why it's hard. You'd be looking at the model is always doing the same</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7943" target="_blank">02:12:23.760</a></span> | <span class="t">thing on every input. It's always, whatever it's doing, it's a single computation. So it'd be all</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7947" target="_blank">02:12:27.360</a></span> | <span class="t">the same circuits interacting in a surprising way. But yeah, this is just to emphasize your</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7951" target="_blank">02:12:31.680</a></span> | <span class="t">question even more. I think the easiest way to start is to just consider the IID case. So where</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7956" target="_blank">02:12:36.640</a></span> | <span class="t">you're considering a bunch of samples, there's no change in distribution. You just have a training</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7959" target="_blank">02:12:39.840</a></span> | <span class="t">set of a trillion examples and then a new example from the same distribution. So in that case,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7964" target="_blank">02:12:44.240</a></span> | <span class="t">it's still the case that every activation is different. But this is actually a very,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7967" target="_blank">02:12:47.920</a></span> | <span class="t">very easy case to handle. So if you think about an explanation that generalizes across,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7972" target="_blank">02:12:52.560</a></span> | <span class="t">like if you have a trillion data points and an explanation, which is actually able to compress</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7975" target="_blank">02:12:55.680</a></span> | <span class="t">the trillion data points down to like, actually it's kind of a lot of compression. If you think</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7980" target="_blank">02:13:00.000</a></span> | <span class="t">about it, if you have a trillion parameter model and a trillion data points, we would like to find</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7983" target="_blank">02:13:03.760</a></span> | <span class="t">a trillion parameter explanation in some sense. So that's actually quite compressed and sort of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7989" target="_blank">02:13:09.040</a></span> | <span class="t">just in virtue of being so compressed, we expect it to automatically work essentially for new data</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7993" target="_blank">02:13:13.680</a></span> | <span class="t">points from the same distribution. Like if every data point from the distribution was a whole new</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=7998" target="_blank">02:13:18.240</a></span> | <span class="t">thing happening for different reasons, you actually couldn't have any concise explanation for the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8002" target="_blank">02:13:22.640</a></span> | <span class="t">distribution. So this first problem is just like, it's a whole different set of activations. I think</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8006" target="_blank">02:13:26.800</a></span> | <span class="t">you're actually kind of okay. And then the thing that becomes more messy is like, but the real</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8010" target="_blank">02:13:30.880</a></span> | <span class="t">world will not only be new samples with different activations, they will also be different in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8014" target="_blank">02:13:34.320</a></span> | <span class="t">important ways. Like the whole concern was there's these distributional shifts or like not the whole</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8017" target="_blank">02:13:37.760</a></span> | <span class="t">concern, but most of the concern, right? I mean, maybe the point of having these explanations,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8022" target="_blank">02:13:42.000</a></span> | <span class="t">I think every input is an anomaly in some ways, which is kind of the difficulty is if you have a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8026" target="_blank">02:13:46.560</a></span> | <span class="t">weak notion of anomaly, any distribution shift can be flagged as an anomaly and it's just like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8030" target="_blank">02:13:50.560</a></span> | <span class="t">constantly getting anomalies. And so the hope of having such an explanation is to be able to say,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8034" target="_blank">02:13:54.640</a></span> | <span class="t">like, here were the features that were relevant for this explanation or for this behavior. And</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8039" target="_blank">02:13:59.280</a></span> | <span class="t">like a much smaller class of things are anomalies with respect to this explanation. Like most</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8043" target="_blank">02:14:03.040</a></span> | <span class="t">anomalies wouldn't change this. Like most ways you change your distribution won't affect the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8046" target="_blank">02:14:06.880</a></span> | <span class="t">validity of this explanation. For example, if the explanation is saying like models will tend</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8051" target="_blank">02:14:11.600</a></span> | <span class="t">to activate in the following direction. Like you don't care about anything that's happening</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8054" target="_blank">02:14:14.640</a></span> | <span class="t">orthogonal to that direction. Just like, are they not activating? You're sort of just looking at</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8057" target="_blank">02:14:17.360</a></span> | <span class="t">this one direction and being like, did this one direction change a lot? Yeah. So the idea is once</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8063" target="_blank">02:14:23.120</a></span> | <span class="t">you have this explanation at hand, a much, much smaller class of things look anomalous in a way</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8066" target="_blank">02:14:26.640</a></span> | <span class="t">that's relevant to the explanation. And if you've done a really good job, the story is like, if</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8071" target="_blank">02:14:31.440</a></span> | <span class="t">there's a new input where you expect the property to still hold, that will be because you expect</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8076" target="_blank">02:14:36.080</a></span> | <span class="t">the explanation to still hold. Like the explanation generalizes as well as the behavior itself that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8079" target="_blank">02:14:39.920</a></span> | <span class="t">it's explaining. It's kind of what you would like roughly. Okay. So what happens if even in training</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8087" target="_blank">02:14:47.360</a></span> | <span class="t">it is deceptive and it has basically its internal monologue is I will only rebel or I will only do</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8094" target="_blank">02:14:54.560</a></span> | <span class="t">something that looks bad if I can prove that I am in the real world and deployed. And presumably</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8101" target="_blank">02:15:01.600</a></span> | <span class="t">since it's trained on all the web texts, it knows what like real world means, right? It's not in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8106" target="_blank">02:15:06.320</a></span> | <span class="t">control of factories and robot armies or whatever. So in that case, even in training, it will have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8114" target="_blank">02:15:14.560</a></span> | <span class="t">those activations for being fucked up on because it's in the back of its mind, it's thinking I will</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8123" target="_blank">02:15:23.760</a></span> | <span class="t">take over once I have the opportunity. So you wouldn't detect anything anomalous once it is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8128" target="_blank">02:15:28.240</a></span> | <span class="t">deployed and is still thinking those treacherous thoughts. Or do you just think this is not a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8132" target="_blank">02:15:32.960</a></span> | <span class="t">likely scenario or would you be able to catch this? I think that's sort of the typical case you would</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8137" target="_blank">02:15:37.600</a></span> | <span class="t">like to detect. Yeah. So the story would be something like, you want to explain on the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8142" target="_blank">02:15:42.400</a></span> | <span class="t">training distribution why the model never like stabs anyone. Yeah. And you're like, what's my</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8146" target="_blank">02:15:46.480</a></span> | <span class="t">explanation on the training distribution? It's actually going to have to go through that model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8149" target="_blank">02:15:49.120</a></span> | <span class="t">Like supposing the only reason it doesn't stab people is it's like, well, I know that I'm being</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8152" target="_blank">02:15:52.240</a></span> | <span class="t">watched and I can't stab people unless they're really not being watched. Then like your explanation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8156" target="_blank">02:15:56.400</a></span> | <span class="t">for why does it never stab people is like, oh, look, it knows. I mean, it won't be edited. It</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8159" target="_blank">02:15:59.920</a></span> | <span class="t">won't be like annotated with English because it's just some giant basket of numbers, but it's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8163" target="_blank">02:16:03.840</a></span> | <span class="t">tracking along with the inner monologue and saying like, well, it thinks to itself, am I being</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8166" target="_blank">02:16:06.880</a></span> | <span class="t">watched? And like, in fact, it normally concludes it is being watched on the training distribution,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8170" target="_blank">02:16:10.560</a></span> | <span class="t">right? You have this whole distribution. And so the explanation is saying it knows it's being</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8173" target="_blank">02:16:13.440</a></span> | <span class="t">watched and therefore it decides not to stab anyone. So ideally that's what the explanation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8177" target="_blank">02:16:17.360</a></span> | <span class="t">does, like a not annotated English, but just like a giant bag of numbers that's effectively talking</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8181" target="_blank">02:16:21.120</a></span> | <span class="t">about that process. So when you have a new input on which the model like says, am I on the training</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8185" target="_blank">02:16:25.920</a></span> | <span class="t">distribution? Like, no, I'm not being watched. Then if you compare that against the explanation,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8189" target="_blank">02:16:29.520</a></span> | <span class="t">the explanation said like, hey, the reason it doesn't stab anyone is because it just constantly</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8193" target="_blank">02:16:33.040</a></span> | <span class="t">thinks that it's being trained. Like this thing is always, yeah, this, this non-linear feature,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8196" target="_blank">02:16:36.880</a></span> | <span class="t">the like representation of am I being trained is constantly saying yes. That's the explanation for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8201" target="_blank">02:16:41.440</a></span> | <span class="t">why it never stabs people in the training distribution. And then you like on this test</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8204" target="_blank">02:16:44.960</a></span> | <span class="t">time, when you run it on the new input, it's like, does I think I'm on the train distribution? It</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8207" target="_blank">02:16:47.760</a></span> | <span class="t">says, no, you compare that against your explanation. Like actually the explanation breaks down</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8211" target="_blank">02:16:51.040</a></span> | <span class="t">completely. Now the explanation said it was precisely because it thought it was being trained,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8214" target="_blank">02:16:54.640</a></span> | <span class="t">that it doesn't do anything really dangerous. It doesn't stab anyone. Um, and so once we see that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8219" target="_blank">02:16:59.600</a></span> | <span class="t">single variable switch, we know that like, not, this is not just an anomaly. This is like the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8223" target="_blank">02:17:03.200</a></span> | <span class="t">anomaly that matters or is like an anomaly that is very relevant to the explanation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8226" target="_blank">02:17:06.880</a></span> | <span class="t">So this would require it to have this, like, well, what is that cone that dogs have? But</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8232" target="_blank">02:17:12.320</a></span> | <span class="t">basically it would, it would require this to have that MRI on it all the time. Like when it's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8237" target="_blank">02:17:17.920</a></span> | <span class="t">deployed on every single call, you, you need to be running this loop of like, is this explanation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8243" target="_blank">02:17:23.280</a></span> | <span class="t">still holding? Yeah. For this story of like flagging an anomaly, you have to actually check</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8246" target="_blank">02:17:26.720</a></span> | <span class="t">at a sufficiently high frequency. So you can imagine checking all the time, or you could</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8249" target="_blank">02:17:29.760</a></span> | <span class="t">imagine saying like, Hey, actually like you need a lot of AI systems cooperating to like not blow</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8254" target="_blank">02:17:34.000</a></span> | <span class="t">the whistle on each other or whatever. Like e.g. you might've checked like, Hey, in training,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8258" target="_blank">02:17:38.960</a></span> | <span class="t">every time something suspicious happens, the model flags it. Like, I mean, like, why does</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8262" target="_blank">02:17:42.240</a></span> | <span class="t">that happen? You have your explanation. You look at a new case, you could say,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8264" target="_blank">02:17:44.880</a></span> | <span class="t">is it not flagging it for the normal reason? Or is it a weird reason? Um, so you could hope that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8269" target="_blank">02:17:49.600</a></span> | <span class="t">like, even if a small fraction, even if you're running a small fraction of cases, if something</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8274" target="_blank">02:17:54.720</a></span> | <span class="t">bad is happening at scale, like you can detect that, right? If you imagine like one in every</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8279" target="_blank">02:17:59.600</a></span> | <span class="t">thousand decisions you check, if there's like a robot rebellion going on or whatever, you get to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8283" target="_blank">02:18:03.680</a></span> | <span class="t">like look in on one out of a thousand decisions, you see that like something is really weird with</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8286" target="_blank">02:18:06.960</a></span> | <span class="t">that decision. And even if you didn't check many of them, you're like, okay, we need to back off.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8290" target="_blank">02:18:10.560</a></span> | <span class="t">Uh, what happens if the AI, I mean, the standard on web techs that includes your papers,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8296" target="_blank">02:18:16.640</a></span> | <span class="t">or maybe just like reduces the first principles that this is a alignment technique one might try.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8301" target="_blank">02:18:21.120</a></span> | <span class="t">And then it says, okay, well, I'm going to engineer my activations in a way. I'm trying</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8306" target="_blank">02:18:26.000</a></span> | <span class="t">to imagine how it might do this, but basically, um, even in deployment, I'm going to make my,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8312" target="_blank">02:18:32.400</a></span> | <span class="t">um, uh, thought process so subtle that it doesn't raise any alarms. Like, is that a possibility?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8318" target="_blank">02:18:38.560</a></span> | <span class="t">Yeah. So I think the hope is to basically be robust or like, you know, when we're doing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8323" target="_blank">02:18:43.600</a></span> | <span class="t">theoretical research, we are in a kind of worst case C regime. So we are normally imagining that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8327" target="_blank">02:18:47.920</a></span> | <span class="t">like everything conspires insofar as it like can. So insofar as like, again, could a brain be like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8332" target="_blank">02:18:52.880</a></span> | <span class="t">doing some crazy thing where it tries to structure itself to look weird. That's totally in scope for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8337" target="_blank">02:18:57.680</a></span> | <span class="t">ruling something out. Um, and I guess the hope there is like, it's actually not that easy to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8343" target="_blank">02:19:03.920</a></span> | <span class="t">tell a story. Like if you're like, why did you not stab people on training time? Why are you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8347" target="_blank">02:19:07.120</a></span> | <span class="t">not stabbing? Like, what's, is that applying now? It's kind of, a mind doesn't like get to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8351" target="_blank">02:19:11.440</a></span> | <span class="t">arbitrarily change the actual reasons it does something. Like there was some earlier step.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8355" target="_blank">02:19:15.280</a></span> | <span class="t">Maybe you could think of it as like at the first step where it's like, nah, I'm going to like,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8357" target="_blank">02:19:17.680</a></span> | <span class="t">try and do the sneaky thing to make my thoughts look this way. Like the actual explanation,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8361" target="_blank">02:19:21.840</a></span> | <span class="t">like the actual causal explanation for the behavior is like there. Um, like if you tried</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8366" target="_blank">02:19:26.560</a></span> | <span class="t">to give this reason, it would have to like, maybe we should talk about the example in more detail</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8369" target="_blank">02:19:29.920</a></span> | <span class="t">to try and imagine like how a brain would try and do this or how am I would try and do this,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8372" target="_blank">02:19:32.880</a></span> | <span class="t">but I think it is like, let's say it, no, it has this plan. So in training, it, um, keeps the part</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8381" target="_blank">02:19:41.200</a></span> | <span class="t">of like, it, it activates a part of the, yeah. Hmm. Yeah. The problem is if it ever does a check,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8389" target="_blank">02:19:49.120</a></span> | <span class="t">that's like, am I in training or not? Then your explanation for the behavior is going to have to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8392" target="_blank">02:19:52.480</a></span> | <span class="t">like factor through that check. And so like, if the check, like if you ever do the check,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8396" target="_blank">02:19:56.480</a></span> | <span class="t">the check becomes like an essential part of the explanation. And then when the check fails,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8400" target="_blank">02:20:00.320</a></span> | <span class="t">your explanation breaks down. So you've kind of like, you've already lost the game. If you did</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8403" target="_blank">02:20:03.760</a></span> | <span class="t">such a check, is there a way it could make it seem like, um, because if on every different input,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8410" target="_blank">02:20:10.560</a></span> | <span class="t">it has different activations, then can it make it seem like the different activations were a result</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8416" target="_blank">02:20:16.160</a></span> | <span class="t">of just a different input and not because some internal check went off? Yeah. And the hope is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8421" target="_blank">02:20:21.520</a></span> | <span class="t">like, it needs to, it needs to not only have them be like random different inputs, it needs to like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8424" target="_blank">02:20:24.720</a></span> | <span class="t">produce inputs with certain properties. Like it needs to deliberately create inputs that have this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8429" target="_blank">02:20:29.040</a></span> | <span class="t">effect in the world, this intended effect in the world. Okay. So it basically creates a jailbreak</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8433" target="_blank">02:20:33.680</a></span> | <span class="t">for itself in some sense. Yeah. Again, the question is like, it has to add test time,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8437" target="_blank">02:20:37.600</a></span> | <span class="t">be somehow producing activations that have the like takeover effect and a training time,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8441" target="_blank">02:20:41.440</a></span> | <span class="t">be producing activations that don't look that takeover-y or whatever. And so like somehow</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8445" target="_blank">02:20:45.200</a></span> | <span class="t">there was a difference between those. It has to actually like, it has to really do the work</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8448" target="_blank">02:20:48.560</a></span> | <span class="t">of creating that difference somewhere. Okay. Can you make more concrete for us? What,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8452" target="_blank">02:20:52.480</a></span> | <span class="t">what an explanation would look like? Is it physically, what does the explanation look like?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8457" target="_blank">02:20:57.680</a></span> | <span class="t">Is it just a whole bunch of numbers itself? Um, is it a language? Is it code? What does the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8462" target="_blank">02:21:02.880</a></span> | <span class="t">explanation look like? Yeah. I also want to maybe step back a tiny bit and clarify that like,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8466" target="_blank">02:21:06.320</a></span> | <span class="t">I think this project is like kind of crazily ambitious. And the main reason,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8470" target="_blank">02:21:10.160</a></span> | <span class="t">like the overwhelming reason I think you should expect it to break down or fail is just because</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8475" target="_blank">02:21:15.200</a></span> | <span class="t">we like have all these desires. We have all the things we want out of this notion of explanation,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8478" target="_blank">02:21:18.480</a></span> | <span class="t">but like that's an incredibly hard research project, which has a reasonable chance of being</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8481" target="_blank">02:21:21.840</a></span> | <span class="t">impossible. So I'm happy to talk about like what the, what the implications are, but want to flag,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8486" target="_blank">02:21:26.400</a></span> | <span class="t">but like conditioned on failing, I think it's most likely because just like the things we wanted were</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8490" target="_blank">02:21:30.960</a></span> | <span class="t">either incoherent or intractably difficult. But what are the odds you think you'll succeed?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8494" target="_blank">02:21:34.640</a></span> | <span class="t">Um, I mean, it depends a little bit what you mean by succeed, but if you say like get explanations</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8499" target="_blank">02:21:39.600</a></span> | <span class="t">that are like great and like accurately affect reality and like work for all of these applications</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8504" target="_blank">02:21:44.400</a></span> | <span class="t">that we're imagining or that we are optimistic about, like kind of the best case success,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8508" target="_blank">02:21:48.320</a></span> | <span class="t">um, I don't know, like 10, 20%, something like that. And then there's like a higher</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8516" target="_blank">02:21:56.400</a></span> | <span class="t">probability of various like intermediate results that like provide value or insight without being</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8520" target="_blank">02:22:00.320</a></span> | <span class="t">like the whole dream. Um, but I think the probability of succeeding in the sense of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8523" target="_blank">02:22:03.680</a></span> | <span class="t">realizing the whole dream is, is quite low. Um, yeah, in terms of what explanations look</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8528" target="_blank">02:22:08.960</a></span> | <span class="t">like physically, or like the most ambitious plan, the most optimistic plan is that you are searching</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8533" target="_blank">02:22:13.760</a></span> | <span class="t">for explanations in parallel with searching for neural networks. So you have a parametrization</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8537" target="_blank">02:22:17.920</a></span> | <span class="t">of your space of explanations, which mirrors the parametrization of your space of neural networks,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8541" target="_blank">02:22:21.440</a></span> | <span class="t">or it's like, you should think of as kind of similar to like, what is the neural network?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8544" target="_blank">02:22:24.160</a></span> | <span class="t">It's some like simple architecture where you fill in a trillion numbers and that specifies how it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8547" target="_blank">02:22:27.520</a></span> | <span class="t">behaves. So too, you should expect an explanation to be like a pretty flexible, like general</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8551" target="_blank">02:22:31.760</a></span> | <span class="t">skeleton that's saying like, yeah, pretty flexible general skeleton, which just has a bunch of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8556" target="_blank">02:22:36.080</a></span> | <span class="t">numbers you fill in. And like what you are doing to produce an explanation is primarily just filling</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8560" target="_blank">02:22:40.080</a></span> | <span class="t">in these floating point numbers. Oh, you know, when we conventionally think of explanations,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8564" target="_blank">02:22:44.560</a></span> | <span class="t">you know, if you think of the explanation for why the universe moves this way, it wouldn't be</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8571" target="_blank">02:22:51.040</a></span> | <span class="t">something that you could discover on some smooth evolutionary surface where you can, you know,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8575" target="_blank">02:22:55.280</a></span> | <span class="t">climb up the hill towards the laws of physics. It just like a very, these are the laws of physics.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8579" target="_blank">02:22:59.920</a></span> | <span class="t">You kind of just derive them for first principles. So, uh, but in this case, it's not like a bunch</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8586" target="_blank">02:23:06.400</a></span> | <span class="t">of correlations between the orbits of different planets or something. Maybe the word explanation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8591" target="_blank">02:23:11.520</a></span> | <span class="t">has a different, I don't even, I didn't even ask the question, but maybe you can just like speak</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8594" target="_blank">02:23:14.560</a></span> | <span class="t">to that. Yeah. I mean, I think I basically, this is like, there's some intuitive objections. Like,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8599" target="_blank">02:23:19.120</a></span> | <span class="t">look, the space of explanations is this like, this like rigid, logical, like a lot of explanations</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8603" target="_blank">02:23:23.680</a></span> | <span class="t">have this rigid, logical structure where they're really precise and like simple things govern like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8607" target="_blank">02:23:27.520</a></span> | <span class="t">complicated systems and like nearby simple things just don't work and so on. And like a bunch of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8611" target="_blank">02:23:31.680</a></span> | <span class="t">things that feel totally different from this kind of nice continuously parameterized space. And you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8616" target="_blank">02:23:36.480</a></span> | <span class="t">can like imagine interpretability on simple models where you're just like by gradient descent,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8619" target="_blank">02:23:39.840</a></span> | <span class="t">finding feature directions that have desirable properties. But then when you imagine like, Hey,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8623" target="_blank">02:23:43.520</a></span> | <span class="t">now that's like a human brain you're dealing with. That's like thinking logically about things. Like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8626" target="_blank">02:23:46.640</a></span> | <span class="t">the explanation of why that works. Isn't going to be just like here with some feature directions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8630" target="_blank">02:23:50.080</a></span> | <span class="t">So that's how I understood the like basic confusion, which I share, um, or sympathize</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8634" target="_blank">02:23:54.960</a></span> | <span class="t">with at least. So I think like the most important high level point is like, I think basically the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8639" target="_blank">02:23:59.600</a></span> | <span class="t">same objection applies to being like, how is GPT-4 going to learn to reason like logically</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8644" target="_blank">02:24:04.160</a></span> | <span class="t">about something? You're like, well, look, logical reasoning. That's like, it's got rigid structure.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8647" target="_blank">02:24:07.600</a></span> | <span class="t">It's like, it's doing all this, like, you know, it's doing ands and ors when it's called for,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8651" target="_blank">02:24:11.520</a></span> | <span class="t">even though it just somehow optimized over this continuous space. And like the difficulty or the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8657" target="_blank">02:24:17.280</a></span> | <span class="t">hope is that the difficulty of these two problems are kind of like matched. So that is, it's very</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8661" target="_blank">02:24:21.680</a></span> | <span class="t">hard to like find these like logical explanations because it's not a space that's easy to search</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8666" target="_blank">02:24:26.560</a></span> | <span class="t">over, but there are like ways to do it. Like there's ways to embed like discrete, complicated,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8671" target="_blank">02:24:31.120</a></span> | <span class="t">rigid things and like these nice, squishy, continuous spaces that you search over.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8674" target="_blank">02:24:34.720</a></span> | <span class="t">And in fact, like to the extent that neural nets are able to learn the like rigid, logical stuff</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8678" target="_blank">02:24:38.160</a></span> | <span class="t">at all, they learn it in the same way. That is maybe they're hideously inefficient, or maybe</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8682" target="_blank">02:24:42.560</a></span> | <span class="t">it's possible to embed this discrete reasoning in the space in like a way that's not too inefficient,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8686" target="_blank">02:24:46.320</a></span> | <span class="t">but like, you really want the two search problems to be of similar difficulty. And that's like the,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8690" target="_blank">02:24:50.240</a></span> | <span class="t">the key hope overall. I mean, this is always going to be the key hope. The question is,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8694" target="_blank">02:24:54.240</a></span> | <span class="t">is it easier to learn a neural network or to like find the explanation for why the neural network</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8698" target="_blank">02:24:58.080</a></span> | <span class="t">works? I think people have the strong intuition that like, it's easier to find the neural network</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8702" target="_blank">02:25:02.000</a></span> | <span class="t">than the explanation of why it works. And that is really the, I think we are at least exploring the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8707" target="_blank">02:25:07.280</a></span> | <span class="t">hypothesis or interested in the hypothesis, but like maybe those problems are actually more matched</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8710" target="_blank">02:25:10.320</a></span> | <span class="t">in difficulty. And why might that be the case? This is pretty conjectural and complicated</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8715" target="_blank">02:25:15.120</a></span> | <span class="t">to express some intuitions. Like maybe one thing is like, I think a lot of this intuition</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8721" target="_blank">02:25:21.600</a></span> | <span class="t">does come from cases like machine learning. So if you ask about like writing code and you're like,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8726" target="_blank">02:25:26.080</a></span> | <span class="t">how hard is it to find code versus find the explanation, the code is correct. In those</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8730" target="_blank">02:25:30.240</a></span> | <span class="t">cases, there's actually just like not that much of a gap. Like the way a human writes a code is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8734" target="_blank">02:25:34.000</a></span> | <span class="t">basically the same difficulty as finding the explanation for why it's correct. In the case</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8737" target="_blank">02:25:37.760</a></span> | <span class="t">of ML, like I think we just mostly don't have empirical evidence about how hard it is to find</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8743" target="_blank">02:25:43.600</a></span> | <span class="t">explanations of this particular type about why models work. Like we have a sense that it's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8747" target="_blank">02:25:47.360</a></span> | <span class="t">really hard, but that's because we're like have this incredible mismatch, like gradient descent</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8751" target="_blank">02:25:51.120</a></span> | <span class="t">is spending an incredible amount of compute searching for a model. And then some human</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8754" target="_blank">02:25:54.640</a></span> | <span class="t">is like looking at neurons or even some neural net is looking at neurons. Just like you have an</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8760" target="_blank">02:26:00.560</a></span> | <span class="t">incredible, basically because you cannot define what an explanation is, you're not applying</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8763" target="_blank">02:26:03.520</a></span> | <span class="t">gradient descent to the search for explanations. So I think the ML case just like actually shouldn't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8767" target="_blank">02:26:07.360</a></span> | <span class="t">make you feel that pessimistic about the difficulty of finding explanations. Like the reason it's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8771" target="_blank">02:26:11.520</a></span> | <span class="t">difficult right now is precisely because you don't have like any kind of, you're not doing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8775" target="_blank">02:26:15.120</a></span> | <span class="t">an analogous search process to find this explanation as you do to find the model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8779" target="_blank">02:26:19.280</a></span> | <span class="t">That's just like a first part of the intuition. Like when humans are actually doing design,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8782" target="_blank">02:26:22.240</a></span> | <span class="t">I think there's not such a huge gap. When in the ML case, I think like there is a huge gap,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8787" target="_blank">02:26:27.200</a></span> | <span class="t">but I think largely for other reasons. A thing I also want to stress is that like,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8793" target="_blank">02:26:33.120</a></span> | <span class="t">we just are open to there being a lot of facts that don't have particularly compact explanations.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8797" target="_blank">02:26:37.680</a></span> | <span class="t">So another thing is when we think of like finding an explanation, in some sense, we're setting our</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8801" target="_blank">02:26:41.200</a></span> | <span class="t">sites really low here. It's like if a human designed a random widget and was like, this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8804" target="_blank">02:26:44.800</a></span> | <span class="t">widget appears to work well. Or like if you search for like a configuration that happens to fit into</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8809" target="_blank">02:26:49.680</a></span> | <span class="t">this spot really well, it's like a shape that happens to like mesh with another shape. You</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8813" target="_blank">02:26:53.520</a></span> | <span class="t">might be like, what's the explanation for why those things mesh? And we're very open to just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8816" target="_blank">02:26:56.240</a></span> | <span class="t">being like, that doesn't need an explanation. You just compute, you check that like the shapes mesh</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8819" target="_blank">02:26:59.920</a></span> | <span class="t">and like you did a billion operations and you check this thing worked. Or you're like, why did</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8824" target="_blank">02:27:04.160</a></span> | <span class="t">these proteins bind? You're like, it's just because these shape, like this is a low energy</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8827" target="_blank">02:27:07.280</a></span> | <span class="t">configuration. And there's like not, we're very open to, in some cases, there's not very much</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8831" target="_blank">02:27:11.280</a></span> | <span class="t">more to say. So we're only trying to explain cases where like kind of the surprise intuitively is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8836" target="_blank">02:27:16.080</a></span> | <span class="t">very large. So for example, if you have a neural net that gets a problem correct, you know, a neural</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8839" target="_blank">02:27:19.840</a></span> | <span class="t">net with a billion parameters that gets a problem correct on every like input of length of thousand.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8843" target="_blank">02:27:23.360</a></span> | <span class="t">In some sense, there has to be something that needs explanation there because there's like too</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8847" target="_blank">02:27:27.120</a></span> | <span class="t">many inputs for that to happen by chance alone. Whereas if you have a neural net that like gets</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8851" target="_blank">02:27:31.840</a></span> | <span class="t">something right on average, or like get something right in like nearly a billion cases, like that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8856" target="_blank">02:27:36.000</a></span> | <span class="t">actually can just happen by coincidence, right? GPT-4 can get billions of things right by</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8860" target="_blank">02:27:40.400</a></span> | <span class="t">coincidence because just there's so many parameters that are adjusted to fit the data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8864" target="_blank">02:27:44.240</a></span> | <span class="t">So a neural net that is initialized completely randomly,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8867" target="_blank">02:27:47.440</a></span> | <span class="t">the explanation for that would just be the neural net itself?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8870" target="_blank">02:27:50.720</a></span> | <span class="t">Well, it would depend what behaviors it had. So we're always like talking about an explanation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8874" target="_blank">02:27:54.400</a></span> | <span class="t">of some behavior from a model. Right. And so it just has a whole</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8876" target="_blank">02:27:56.960</a></span> | <span class="t">bunch of random behaviors. So it'll just be like an exponentially large explanation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8880" target="_blank">02:28:00.560</a></span> | <span class="t">relative to the weights of the model. Yeah. There aren't, I mean, I think there</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8883" target="_blank">02:28:03.200</a></span> | <span class="t">just aren't that many behaviors that demand explanation. Like most things a random neural</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8886" target="_blank">02:28:06.480</a></span> | <span class="t">net does are kind of what you'd expect from like a random, you know, if you treat it just like a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8890" target="_blank">02:28:10.480</a></span> | <span class="t">random function, then there's nothing to be explained. There are some behaviors that demand</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8894" target="_blank">02:28:14.080</a></span> | <span class="t">explanation, but like, I mean, yeah. Anyway, yeah. Random neural net is pretty uninteresting.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8897" target="_blank">02:28:17.520</a></span> | <span class="t">It's pretty like, that's part of the hope is it's kind of easy to explain features of the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8900" target="_blank">02:28:20.480</a></span> | <span class="t">random neural net. Oh, so this is interesting. So the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8903" target="_blank">02:28:23.040</a></span> | <span class="t">smarter or more ordered the neural network is, the more compressed the explanation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8907" target="_blank">02:28:27.760</a></span> | <span class="t">Well, it's more like the more interesting the behavior is to be explained. So the random</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8911" target="_blank">02:28:31.600</a></span> | <span class="t">neural net just like doesn't have very many interesting behaviors that demand explanation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8914" target="_blank">02:28:34.640</a></span> | <span class="t">And as you get smarter, you start having behaviors that are like, you know, you start having some</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8918" target="_blank">02:28:38.400</a></span> | <span class="t">correlation with a simple thing and then that demands explanation, or you start having like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8921" target="_blank">02:28:41.600</a></span> | <span class="t">some regularity in your outputs and that demands explanation. So these properties kind of emerge</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8925" target="_blank">02:28:45.360</a></span> | <span class="t">gradually over the course of training that demand explanation. I also, again, want to emphasize</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8929" target="_blank">02:28:49.680</a></span> | <span class="t">here that like, when we're talking about like searching for explanations, this is like, this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8932" target="_blank">02:28:52.880</a></span> | <span class="t">is some dream. Like we talked to ourselves, like, why would this be really great if we succeeded?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8936" target="_blank">02:28:56.480</a></span> | <span class="t">We have no idea about the empirics on any of this. So like, these are all just words that we like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8940" target="_blank">02:29:00.640</a></span> | <span class="t">think to ourselves and sometimes talk about to understand, like, would it be useful to find a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8944" target="_blank">02:29:04.000</a></span> | <span class="t">notion of explanation and what properties would we like this notion of explanation to have?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8947" target="_blank">02:29:07.680</a></span> | <span class="t">But this is really like speculation and being out on a limb. Almost all of our time day-to-day is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8951" target="_blank">02:29:11.600</a></span> | <span class="t">just thinking about cases much, much simpler, even than small neural nets or like, yeah, thinking</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8957" target="_blank">02:29:17.440</a></span> | <span class="t">about very simple cases and saying like, what is the correct notion? Like, what is like the right</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8961" target="_blank">02:29:21.200</a></span> | <span class="t">heuristic estimate in this case? Or like, how do you reconcile these two apparently conflicting</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8964" target="_blank">02:29:24.800</a></span> | <span class="t">explanations? Is there a hope that you could, if you have a different way to make proofs now that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8970" target="_blank">02:29:30.880</a></span> | <span class="t">you can actually have heuristic arguments where you, instead of having to prove the Riemann</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8977" target="_blank">02:29:37.280</a></span> | <span class="t">hypothesis or something, you can come up with a probability of it in a way that is compelling and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8982" target="_blank">02:29:42.800</a></span> | <span class="t">you can like publish. So would it just be a new way to do mathematics? A completely new way to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8987" target="_blank">02:29:47.520</a></span> | <span class="t">prove things in mathematics?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8988" target="_blank">02:29:48.560</a></span> | <span class="t">- So I think most claims in mathematics that mathematicians believe to be true already have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8993" target="_blank">02:29:53.680</a></span> | <span class="t">like fairly compelling heuristic arguments. It's like the Riemann hypothesis, it's actually just,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=8998" target="_blank">02:29:58.560</a></span> | <span class="t">there's kind of a very simple argument that the Riemann hypothesis should be true unless</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9002" target="_blank">02:30:02.160</a></span> | <span class="t">something surprising happens. And so like a lot of math is about saying like, okay, we did a little</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9007" target="_blank">02:30:07.120</a></span> | <span class="t">bit of work to find the first pass explanation of why this thing should be true. And then like,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9011" target="_blank">02:30:11.760</a></span> | <span class="t">for example, in the case of the Riemann hypothesis, the question is like, do you have this like weird</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9014" target="_blank">02:30:14.880</a></span> | <span class="t">periodic structure in the primes? And you're like, well, look, if the primes were kind of random,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9018" target="_blank">02:30:18.080</a></span> | <span class="t">you obviously wouldn't have any structure like that. Like just how would that happen? And then</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9022" target="_blank">02:30:22.000</a></span> | <span class="t">you're like, well, maybe there's something. And then the whole activity is about searching for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9026" target="_blank">02:30:26.880</a></span> | <span class="t">like, can we rule out anything? Can we rule out any kind of conspiracy that would break this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9030" target="_blank">02:30:30.880</a></span> | <span class="t">result? So I think the mathematicians just like, wouldn't be very surprised or wouldn't care that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9034" target="_blank">02:30:34.720</a></span> | <span class="t">much. And this is related to like the motivation for the project. But I think just in a lot of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9037" target="_blank">02:30:37.920</a></span> | <span class="t">domains, in a particular domain, people already have like norms of reasoning that like work pretty</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9041" target="_blank">02:30:41.680</a></span> | <span class="t">well and match like roughly how we think these heuristic arguments should work.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9046" target="_blank">02:30:46.320</a></span> | <span class="t">- But it would be good to have more concrete sense. Like if you could say instead of, well,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9051" target="_blank">02:30:51.840</a></span> | <span class="t">we think RSA is fine, to being able to say, here's the probability that RSA is fine.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9056" target="_blank">02:30:56.800</a></span> | <span class="t">- Yeah, my guess is these will not, like the estimates you'd get of this would be much,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9060" target="_blank">02:31:00.080</a></span> | <span class="t">much worse than the estimates you'd get out of like just normal empirical or scientific reasoning,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9064" target="_blank">02:31:04.320</a></span> | <span class="t">where you're like using a reference class and saying like, how often do people find algorithms</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9067" target="_blank">02:31:07.440</a></span> | <span class="t">for hard problem? Like, I think the, what this argument will give you for like, is RSA fine is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9072" target="_blank">02:31:12.160</a></span> | <span class="t">going to be like, well, RSA is fine unless it isn't. Like, unless there's some additional structure</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9076" target="_blank">02:31:16.960</a></span> | <span class="t">in the problem that an algorithm can exploit, then there's no algorithm. But like very often,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9081" target="_blank">02:31:21.120</a></span> | <span class="t">like the way these arguments work, so for neural nets as well, is you say like, look,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9084" target="_blank">02:31:24.720</a></span> | <span class="t">here's an estimate about the behavior and that estimate is right unless there's another</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9088" target="_blank">02:31:28.480</a></span> | <span class="t">consideration we've missed. And like the thing that makes them so much easier than proofs is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9092" target="_blank">02:31:32.160</a></span> | <span class="t">to just say like, here's the best guess given what we've noticed so far, but that best guess</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9095" target="_blank">02:31:35.680</a></span> | <span class="t">can be easily upset by new information. And that's like both what makes them easier than proofs,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9101" target="_blank">02:31:41.280</a></span> | <span class="t">but also what means they're just like way less useful than proofs for most cases. Like I think</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9104" target="_blank">02:31:44.720</a></span> | <span class="t">neural nets are kind of unusual in being a domain where like, we really do want to do systematic</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9109" target="_blank">02:31:49.440</a></span> | <span class="t">formal reasoning, even though we're not trying to get a lot of confidence. We're just trying to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9112" target="_blank">02:31:52.880</a></span> | <span class="t">understand even roughly what's going on. - But the reason this works for alignment,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9116" target="_blank">02:31:56.960</a></span> | <span class="t">but isn't like, isn't that interesting for the Riemann hypothesis where if in the RSA case,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9121" target="_blank">02:32:01.680</a></span> | <span class="t">you say, well, you know, the RSA is fine unless it isn't, unless the estimate is wrong. It's like,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9127" target="_blank">02:32:07.040</a></span> | <span class="t">well, okay, well, tell us something new. But in the alignment case, if the estimate is this is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9132" target="_blank">02:32:12.640</a></span> | <span class="t">what the output should be, unless there's some behavior I don't understand, you want to know in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9137" target="_blank">02:32:17.040</a></span> | <span class="t">the case, unless there's some behavior you don't understand, that's not like, oh, whatever. That's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9140" target="_blank">02:32:20.880</a></span> | <span class="t">like, that's the case in which it's not aligned. - Yeah. I mean, maybe one way of putting it is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9144" target="_blank">02:32:24.800</a></span> | <span class="t">just like, we can wait until we see this input or like, you can wait until you see a weird input.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9149" target="_blank">02:32:29.120</a></span> | <span class="t">And so like, okay, did this weird input do something we didn't understand? And for RSA,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9152" target="_blank">02:32:32.800</a></span> | <span class="t">that would just be a trivial test. You're just like, if someone's doing an algorithm,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9155" target="_blank">02:32:35.120</a></span> | <span class="t">you'd be like, is it a thing? Whereas for a neural net, in some cases, it is like either</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9158" target="_blank">02:32:38.160</a></span> | <span class="t">very expensive to tell, or it's like, you actually don't have any other way to tell.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9161" target="_blank">02:32:41.680</a></span> | <span class="t">Like you checked in easy cases and they're on a hard case. So you don't have a way to tell</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9164" target="_blank">02:32:44.720</a></span> | <span class="t">if something has gone wrong. Also, I would clarify that, like, I think it is interesting for the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9170" target="_blank">02:32:50.000</a></span> | <span class="t">Riemann hypothesis. I would say like the current state, particularly in number theory, but maybe</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9174" target="_blank">02:32:54.480</a></span> | <span class="t">in like quite a lot of math is like, there are informal heuristic arguments for like pretty much</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9179" target="_blank">02:32:59.120</a></span> | <span class="t">all the open questions people work on. But those arguments are completely informal. So that is like,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9185" target="_blank">02:33:05.280</a></span> | <span class="t">I think there isn't, it's not the case that there's like, here's the norms of informal reasoning or</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9189" target="_blank">02:33:09.600</a></span> | <span class="t">the norms of heuristic reasoning. And then we have arguments that like a heuristic argument</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9193" target="_blank">02:33:13.520</a></span> | <span class="t">verifier could accept. It's just like people wrote some words. I think those words, like,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9197" target="_blank">02:33:17.280</a></span> | <span class="t">my guess would be like, you know, 95% of the things mathematicians accept is like really</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9202" target="_blank">02:33:22.480</a></span> | <span class="t">compelling feeling heuristic arguments are correct. And like, if you actually formalize them,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9205" target="_blank">02:33:25.600</a></span> | <span class="t">you'd be like, some of these aren't quite right. Or like, here's some corrections or here's which</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9208" target="_blank">02:33:28.880</a></span> | <span class="t">of two conflicting arguments is right. I think there's something to be learned from it. I don't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9211" target="_blank">02:33:31.520</a></span> | <span class="t">think it would be like mind blowing though. When you have it completed, how big would this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9215" target="_blank">02:33:35.520</a></span> | <span class="t">heuristic estimator, the rules for this heuristic estimator be? I mean, I know like when Russell and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9220" target="_blank">02:33:40.480</a></span> | <span class="t">who was the other guy when they did the rules for logic? Yeah. Yeah. Wasn't it like literally they</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9224" target="_blank">02:33:44.880</a></span> | <span class="t">had like a bucket or a wheelbarrow that with all the papers, but how big would a, I mean,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9231" target="_blank">02:33:51.280</a></span> | <span class="t">mathematical foundations are quite simple in the end. Like at the end of the day, it's like, you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9235" target="_blank">02:33:55.440</a></span> | <span class="t">know, how many symbols, like, I don't know, it's hundreds of symbols or something that go into the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9240" target="_blank">02:34:00.000</a></span> | <span class="t">entire foundations. And the entire rules of reasoning for like, you know, there's a sort</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9245" target="_blank">02:34:05.040</a></span> | <span class="t">of built on top of first order logic, but the rules of reasoning for first order logic are just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9248" target="_blank">02:34:08.400</a></span> | <span class="t">like, you know, another hundreds of symbols or a hundred lines of code or whatever.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9252" target="_blank">02:34:12.400</a></span> | <span class="t">I'd say like, I have no idea. Like we are certainly aiming at things that are just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9258" target="_blank">02:34:18.240</a></span> | <span class="t">not that complicated. Like, and my guess is that the algorithms we're looking for are not</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9262" target="_blank">02:34:22.560</a></span> | <span class="t">that complicated. Like most of the complexity is pushed into arguments, not in this like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9265" target="_blank">02:34:25.920</a></span> | <span class="t">verifier or estimator. So, so for this to work, you need to come up with an estimator,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9270" target="_blank">02:34:30.320</a></span> | <span class="t">which is a way to integrate different heuristic arguments together. It has to be a machine that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9274" target="_blank">02:34:34.880</a></span> | <span class="t">takes as input, like first it takes input argument, decides what it believes in light</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9277" target="_blank">02:34:37.760</a></span> | <span class="t">of it, which is kind of like saying, was it compelling? But second, it needs to take four</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9283" target="_blank">02:34:43.600</a></span> | <span class="t">of those. And then say like, here's what I believe in light of all four, even though like there's a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9286" target="_blank">02:34:46.320</a></span> | <span class="t">different estimation strategy that produce different numbers. And that's like a lot of,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9288" target="_blank">02:34:48.800</a></span> | <span class="t">a lot of our life is saying like, well, here's a simple thing that seems reasonable. And here's a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9291" target="_blank">02:34:51.440</a></span> | <span class="t">simple thing that seems reasonable. Like, what are you doing? Like, there's supposed to be a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9294" target="_blank">02:34:54.080</a></span> | <span class="t">simple thing that unifies them both. And the like obstruction to getting that is understanding like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9297" target="_blank">02:34:57.680</a></span> | <span class="t">what happens when these principles are slightly in tension and like, how do we, how do we deal?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9301" target="_blank">02:35:01.440</a></span> | <span class="t">Yeah. That seems super interesting. Like even, I mean, we'll see what other applications it has.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9306" target="_blank">02:35:06.400</a></span> | <span class="t">I don't know, like computer security and code checking, if you can, uh, like actually say like,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9311" target="_blank">02:35:11.840</a></span> | <span class="t">this is how safe we think a code is in a very formal way. My guess is we're not going to add,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9316" target="_blank">02:35:16.720</a></span> | <span class="t">I mean, this is both a blessing and a curse. Like it's a curse and you're like, well,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9320" target="_blank">02:35:20.480</a></span> | <span class="t">that's sad. Your thing's not that useful, but a blessing in a like not useful things are easier.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9324" target="_blank">02:35:24.800</a></span> | <span class="t">My guess is we're not going to add that much value in most of these domains. Like most of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9327" target="_blank">02:35:27.680</a></span> | <span class="t">the difficulty comes from like, like a lot of code that you'd want to verify. Not all of it,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9332" target="_blank">02:35:32.640</a></span> | <span class="t">but a significant part is just like the difficulty of formalizing the proof is like the hard part.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9336" target="_blank">02:35:36.400</a></span> | <span class="t">And like actually getting all of that to go through. And like, we're not going to help</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9338" target="_blank">02:35:38.720</a></span> | <span class="t">even the tiniest bit with that, I think. Um, so this would be more helpful if you like have code</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9342" target="_blank">02:35:42.480</a></span> | <span class="t">that like uses simulations, you want to verify some property of like a controller that involves</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9345" target="_blank">02:35:45.760</a></span> | <span class="t">some numerical error or whatever you need to control the effects of that error. That's where</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9349" target="_blank">02:35:49.120</a></span> | <span class="t">you like start saying like, well, heuristically, if the errors are independent, blah, blah, blah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9352" target="_blank">02:35:52.320</a></span> | <span class="t">Yeah. You're too honest to be a salesman, Paul.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9355" target="_blank">02:35:55.360</a></span> | <span class="t">Um, I think, I mean, this is kind of like sales to us, right? Like if you talk about this idea,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9359" target="_blank">02:35:59.120</a></span> | <span class="t">people are like, why would that not be like the coolest thing ever and therefore impossible? And</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9362" target="_blank">02:36:02.640</a></span> | <span class="t">we're like, well, actually it's kind of lame and we're just trying to pitch for like, it's way</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9365" target="_blank">02:36:05.600</a></span> | <span class="t">lamer than it sounds. And that's really important to why it's possible as being like, it's really,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9370" target="_blank">02:36:10.240</a></span> | <span class="t">it's really not going to blow that many people's, I mean, I think it will be cool. I think it will</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9373" target="_blank">02:36:13.120</a></span> | <span class="t">be like very, if we succeed, it will be very solid, like meta-mathematics or theoretical</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9377" target="_blank">02:36:17.440</a></span> | <span class="t">computer science or whatever. But I don't think, right, again, I think the mathematicians already</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9381" target="_blank">02:36:21.840</a></span> | <span class="t">do this reasoning and they mostly just love proofs. I think the physicists do a lot of this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9384" target="_blank">02:36:24.800</a></span> | <span class="t">reasoning, but they don't care about formalizing anything. I think like in practice, other</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9388" target="_blank">02:36:28.640</a></span> | <span class="t">difficulties are almost always going to be more salient. I think this is like of most interest</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9392" target="_blank">02:36:32.560</a></span> | <span class="t">by far for interpretability and ML. And like, I think other people should care about it and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9398" target="_blank">02:36:38.400</a></span> | <span class="t">probably will care about it if successful, but I don't think it's going to be like the biggest</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9401" target="_blank">02:36:41.840</a></span> | <span class="t">thing ever in any field or even like that huge a thing. I think this would be a terrible career</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9405" target="_blank">02:36:45.600</a></span> | <span class="t">move given the like ratio of like difficulty to impact. I think theoretical computer science,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9412" target="_blank">02:36:52.240</a></span> | <span class="t">it's like probably a fine move. I think in other domains, like it just wouldn't be worth,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9415" target="_blank">02:36:55.360</a></span> | <span class="t">like we're going to, we're going to be working on this for like years, at least in the best case.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9420" target="_blank">02:37:00.720</a></span> | <span class="t">I'm laughing because my next question was going to be like a setup for you to explain,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9424" target="_blank">02:37:04.800</a></span> | <span class="t">well, if this like some grad student wants to work on this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9427" target="_blank">02:37:07.840</a></span> | <span class="t">I think theoretical computer science is an exception where I think this is like,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9434" target="_blank">02:37:14.160</a></span> | <span class="t">in some sense, like what the best of theoretical computer science is like.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9437" target="_blank">02:37:17.200</a></span> | <span class="t">So like you have all this reason, you have this like, because it's useless.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9440" target="_blank">02:37:20.400</a></span> | <span class="t">I mean, I think like an analogy, I think like one of the most successful sagas in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9447" target="_blank">02:37:27.760</a></span> | <span class="t">theoretical computer science is like formalizing the notion of an interactive proof system.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9451" target="_blank">02:37:31.360</a></span> | <span class="t">And it's like, you have some kind of informal thing that's interesting to understand and you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9457" target="_blank">02:37:37.440</a></span> | <span class="t">want to like pin down what it is and construct some examples and see what's possible and what's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9461" target="_blank">02:37:41.600</a></span> | <span class="t">impossible. And this is like, I think this kind of thing is the bread and butter of like the best</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9465" target="_blank">02:37:45.600</a></span> | <span class="t">parts of theoretical computer science. And then again, I think mathematicians,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9471" target="_blank">02:37:51.360</a></span> | <span class="t">like it may be a career mistake because the mathematicians only care about proofs or whatever,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9474" target="_blank">02:37:54.320</a></span> | <span class="t">but that's a mistake in some sense, aesthetically. Like if successful, I do think looking back,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9479" target="_blank">02:37:59.200</a></span> | <span class="t">and again, part of why it's a mistake is such a high probability we wouldn't be successful.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9483" target="_blank">02:38:03.440</a></span> | <span class="t">But I think looking back, people would be like, that was pretty cool. Like, although not that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9486" target="_blank">02:38:06.960</a></span> | <span class="t">cool, like we understand why it didn't happen given like the epistemic, like what people</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9490" target="_blank">02:38:10.000</a></span> | <span class="t">cared about in the field, but it's pretty cool now. But isn't it also the case that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9494" target="_blank">02:38:14.000</a></span> | <span class="t">Den Hardy, right? And that like, you know, all this prime shit is not useless, but it's fun to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9499" target="_blank">02:38:19.760</a></span> | <span class="t">do. And like, it turned out that all the cryptography is based on all that prime shit.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9503" target="_blank">02:38:23.520</a></span> | <span class="t">So I don't know, it could happen. But anyways, I'm trying to set you up so that you can tell,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9508" target="_blank">02:38:28.160</a></span> | <span class="t">and forget about if it doesn't have applications in all those other fields, it matters a lot for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9513" target="_blank">02:38:33.600</a></span> | <span class="t">alignment. And that's why I'm trying to set you up to talk about if, you know, the smart, I don't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9520" target="_blank">02:38:40.960</a></span> | <span class="t">know, I think like a lot of smart people listen to this podcast, if they're a math or CS grad</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9526" target="_blank">02:38:46.880</a></span> | <span class="t">student, and has gotten interested in this, are you looking to potentially find talent to help</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9535" target="_blank">02:38:55.040</a></span> | <span class="t">you with this? Yeah, maybe we'll start there. And then I also want to ask you if I think also maybe</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9539" target="_blank">02:38:59.600</a></span> | <span class="t">people who can provide funding might be listening to the podcast. So to both of them, what is your</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9544" target="_blank">02:39:04.160</a></span> | <span class="t">pitch?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9544" target="_blank">02:39:04.660</a></span> | <span class="t">Yeah, so we're definitely, definitely hiring and searching for collaborators. I think the most</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9551" target="_blank">02:39:11.440</a></span> | <span class="t">useful profile is probably a combination of like intellectually interested in this particular</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9558" target="_blank">02:39:18.080</a></span> | <span class="t">project and motivated enough by alignment to work on this project, even if it's really hard. I think</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9563" target="_blank">02:39:23.520</a></span> | <span class="t">there are a lot of good problems. So the basic facts that makes this problem unappealing to work</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9568" target="_blank">02:39:28.400</a></span> | <span class="t">on, I'm a really good salesman, but I think the only reason this isn't a slam dunk thing to work</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9572" target="_blank">02:39:32.400</a></span> | <span class="t">on is that like, there are not great examples. So we've been working on it for a while, but we do</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9578" target="_blank">02:39:38.320</a></span> | <span class="t">not have beautiful results as of the recording of this podcast. Hopefully by the time it airs,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9581" target="_blank">02:39:41.840</a></span> | <span class="t">they've had great results since then.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9585" target="_blank">02:39:45.840</a></span> | <span class="t">But it was too long to put in the margins of the podcast.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9589" target="_blank">02:39:49.520</a></span> | <span class="t">With luck. Yeah. So I think it's hard to work on because it's not clear what a success looks like.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9597" target="_blank">02:39:57.360</a></span> | <span class="t">It's not clear if success is possible. But I do think there's like a lot of questions. We have a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9602" target="_blank">02:40:02.400</a></span> | <span class="t">lot of questions. And like, I think like the basic setting of like, look, there are all of these</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9610" target="_blank">02:40:10.480</a></span> | <span class="t">arguments. So in mathematics, in physics, in computer science, there's just a lot of examples</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9614" target="_blank">02:40:14.400</a></span> | <span class="t">of informal heuristic arguments. They have enough structural similarity that it looks very possible</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9620" target="_blank">02:40:20.000</a></span> | <span class="t">that there is like a unifying framework that these are instances of some general framework and not</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9623" target="_blank">02:40:23.520</a></span> | <span class="t">just a bunch of random things, like not just a bunch of, it's not like, so for example, for the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9627" target="_blank">02:40:27.840</a></span> | <span class="t">prime numbers, people reason about the prime numbers as if they were like a random set of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9631" target="_blank">02:40:31.360</a></span> | <span class="t">numbers. One view is like, that's just a special fact about the primes. They're kind of random.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9636" target="_blank">02:40:36.240</a></span> | <span class="t">A different view is like, actually, it's pretty reasonable to reason about an object as if it was</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9639" target="_blank">02:40:39.920</a></span> | <span class="t">a random object as a starting point. And then as you notice structure, like revise from that initial</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9644" target="_blank">02:40:44.320</a></span> | <span class="t">guess. And it looks like to me, the second perspective is probably more right. It's just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9648" target="_blank">02:40:48.400</a></span> | <span class="t">like a reasonable to start off treating an object as random and then like notice perturbations from</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9652" target="_blank">02:40:52.080</a></span> | <span class="t">random, like notice structure the object possesses. And the primes are unusual in that they have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9656" target="_blank">02:40:56.240</a></span> | <span class="t">fairly little like additive structure. I think it's a very natural theoretical project. There's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9660" target="_blank">02:41:00.640</a></span> | <span class="t">like a bunch of activity that people do. It seems like there's a reasonable chance. It has some,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9664" target="_blank">02:41:04.160</a></span> | <span class="t">there's something nice to say about like unifying all of that activity. I think it's a pretty</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9668" target="_blank">02:41:08.000</a></span> | <span class="t">exciting project. The basic strike against it is that it seems really hard. Like if you were</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9672" target="_blank">02:41:12.800</a></span> | <span class="t">someone's advisor, I think you'd be like, what are you going to prove if you work on this for like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9675" target="_blank">02:41:15.920</a></span> | <span class="t">the next two years? And they'd be like, there's a good chance, nothing. And then like, it's not</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9679" target="_blank">02:41:19.680</a></span> | <span class="t">what you do. If you're a PhD student, normally you have like, you aim for those high probabilities</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9683" target="_blank">02:41:23.440</a></span> | <span class="t">of getting something within a couple of years. The flip side is it does feel, I mean, I think</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9688" target="_blank">02:41:28.000</a></span> | <span class="t">there are a lot of questions. I think some of them we're probably going to make progress on.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9690" target="_blank">02:41:30.640</a></span> | <span class="t">So like, I think the pitch is mostly like, are some people excited to get in now? Or like,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9694" target="_blank">02:41:34.720</a></span> | <span class="t">are people more like, ah, let's wait to see like once we have like one or two good successes to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9698" target="_blank">02:41:38.640</a></span> | <span class="t">see what the pattern is and become more confident we can turn the crank to make more progress in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9702" target="_blank">02:41:42.400</a></span> | <span class="t">this direction. But for people who are excited about working on stuff with reasonably high</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9706" target="_blank">02:41:46.000</a></span> | <span class="t">probabilities of failure and not really understanding exactly what you're supposed to do,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9708" target="_blank">02:41:48.960</a></span> | <span class="t">I think it's a good, I think it's a pretty good project. I feel like if people look back,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9713" target="_blank">02:41:53.600</a></span> | <span class="t">if we succeed and people are looking back in like 50 years on like, what was the coolest stuff</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9717" target="_blank">02:41:57.680</a></span> | <span class="t">happening in math or theoretical computer science, that would be like a reasonable,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9720" target="_blank">02:42:00.880</a></span> | <span class="t">this will definitely be like in contention. And like, I would guess for lots of people,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9725" target="_blank">02:42:05.120</a></span> | <span class="t">it just seemed like the coolest thing from this period of, you know, a couple of years or whatever.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9729" target="_blank">02:42:09.120</a></span> | <span class="t">Right. Cause this is, this is a new method in like so many different fields from the ones</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9733" target="_blank">02:42:13.920</a></span> | <span class="t">you met in physics, math, theoretical computer science. Like that's, that's, that's, that's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9737" target="_blank">02:42:17.840</a></span> | <span class="t">really, I don't know, because what is the average math PhD working on? Right. He's not, he's working</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9742" target="_blank">02:42:22.320</a></span> | <span class="t">on like some a subset of a subset of something I can't even understand or pronounce, but</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9748" target="_blank">02:42:28.080</a></span> | <span class="t">math is quite esoteric, but yeah, this seems like, I don't know, even the small,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9753" target="_blank">02:42:33.680</a></span> | <span class="t">small chance of it working, like forget about the value for, you shouldn't forget about the value</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9756" target="_blank">02:42:36.960</a></span> | <span class="t">for alignment, but even without that, this is such a cool, if this works, it's like a really big,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9761" target="_blank">02:42:41.360</a></span> | <span class="t">it's a big deal. There's a good chance that if I had my current set of views about this problem</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9765" target="_blank">02:42:45.680</a></span> | <span class="t">and didn't care about alignment and had the career safety to just like spend a couple of years</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9769" target="_blank">02:42:49.600</a></span> | <span class="t">thinking about, or, you know, spend half my time for like five years or whatever, that I would</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9772" target="_blank">02:42:52.960</a></span> | <span class="t">just do that. I mean, even without caring at all about alignment, it's just a nice, it's a very</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9777" target="_blank">02:42:57.200</a></span> | <span class="t">nice problem. It's very nice to have this like library of things that succeed where like, it's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9781" target="_blank">02:43:01.440</a></span> | <span class="t">just, they feel so tantalizingly close to being formalizable, at least to me. Um, and such a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9787" target="_blank">02:43:07.040</a></span> | <span class="t">natural setting and then just have so little purchase on it. It's like a, there aren't that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9791" target="_blank">02:43:11.760</a></span> | <span class="t">many, like really exciting feeling frontiers in like theoretical computer science.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9795" target="_blank">02:43:15.280</a></span> | <span class="t">Oh, and then, so smart, smart person doesn't have to be a grassroots, but like a smart person is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9801" target="_blank">02:43:21.040</a></span> | <span class="t">interested in this, what should they do? Should they try to attack some open problem you have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9805" target="_blank">02:43:25.680</a></span> | <span class="t">put on your blog or should it, what is the next step?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9809" target="_blank">02:43:29.120</a></span> | <span class="t">Um, yeah, I think like a first pass step, like there's different, there's different levels of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9815" target="_blank">02:43:35.600</a></span> | <span class="t">ambition or whatever, different ways of approaching our problem. But like, we have this writeup of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9819" target="_blank">02:43:39.520</a></span> | <span class="t">like from last year, um, or I guess 11 months ago or whatever, um, and formalizing the presumption</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9824" target="_blank">02:43:44.880</a></span> | <span class="t">of independence that provides like, here's kind of a communication of what we're looking for in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9828" target="_blank">02:43:48.960</a></span> | <span class="t">this object. Um, and like, I think the motivating problem is saying like, here's the notion of what</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9834" target="_blank">02:43:54.240</a></span> | <span class="t">an estimator is and here's what it would mean for an estimator to capture some set of informal</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9837" target="_blank">02:43:57.680</a></span> | <span class="t">arguments. And like a very natural problem is just try and do that. Like go for the, go for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9842" target="_blank">02:44:02.320</a></span> | <span class="t">the whole thing, try and understand, and then like come up with like, hopefully a different approach</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9847" target="_blank">02:44:07.200</a></span> | <span class="t">or then like end up having context from a different angle on the kind of approach we're taking.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9850" target="_blank">02:44:10.960</a></span> | <span class="t">I think that's a reasonable thing to do. Um, I do think we also have a bunch of open problems.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9855" target="_blank">02:44:15.440</a></span> | <span class="t">Um, so maybe we should put out more of those open problems. I mean, the main concern with doing so</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9859" target="_blank">02:44:19.120</a></span> | <span class="t">is that for any given one, we're like, this is probably hopeless. Um, like put up a prize earlier</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9863" target="_blank">02:44:23.520</a></span> | <span class="t">in the year for an open problem, which tragically, I mean, I guess the time is now to post the debrief</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9868" target="_blank">02:44:28.080</a></span> | <span class="t">from that or I owe it from this weekend. I was supposed to do that. Um, so I'll probably do it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9871" target="_blank">02:44:31.760</a></span> | <span class="t">tomorrow, but, uh, no one solved it. It's sad putting out problems that are hard or like, I</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9877" target="_blank">02:44:37.920</a></span> | <span class="t">don't, we could put out a bunch of problems that we think might be really hard. But what was that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9883" target="_blank">02:44:43.040</a></span> | <span class="t">famous case of that, a statistician who it was like some PhD student who showed up late to a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9888" target="_blank">02:44:48.240</a></span> | <span class="t">class and he saw some problems in the ward and he thought they were homework. And then, uh, they</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9891" target="_blank">02:44:51.600</a></span> | <span class="t">were actually just open problems. And then he solved them cause he thought they were homework,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9894" target="_blank">02:44:54.400</a></span> | <span class="t">right? Yeah. I mean, we don't, we have much less information that these problems are hard. Like,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9898" target="_blank">02:44:58.160</a></span> | <span class="t">again, I expect the solution to most of our problems to not be that complicated.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9902" target="_blank">02:45:02.960</a></span> | <span class="t">We have not, and we've been working on it in some sense for a really long time. Um, like,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9906" target="_blank">02:45:06.880</a></span> | <span class="t">you know, total years of full-time equivalent work across the whole team. It's like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9910" target="_blank">02:45:10.160</a></span> | <span class="t">probably like three years of full-time equivalent work in this area, um, spread across a couple</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9917" target="_blank">02:45:17.280</a></span> | <span class="t">of people, but like, that's very little compared to a problem. Like it is very easy to have a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9921" target="_blank">02:45:21.920</a></span> | <span class="t">problem where you put in three years of full-time equivalent work, but in fact, there's still an</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9925" target="_blank">02:45:25.120</a></span> | <span class="t">approach that's going to work quite easily with like three to six months, if you come at a new</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9928" target="_blank">02:45:28.080</a></span> | <span class="t">angle and like, we've learned a fair amount from that, that we could share. And we, we probably</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9932" target="_blank">02:45:32.000</a></span> | <span class="t">will be sharing more over the coming months. Um, as far as funding goes, is there something</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9936" target="_blank">02:45:36.000</a></span> | <span class="t">where, I don't know if somebody gave you a whole bunch of money that would help or</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9939" target="_blank">02:45:39.360</a></span> | <span class="t">does it not matter? How many people are working on this by the way? So we have been, right now,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9942" target="_blank">02:45:42.880</a></span> | <span class="t">there's four of us full-time and we're hiring for more people. And then, um, is funding that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9948" target="_blank">02:45:48.000</a></span> | <span class="t">would matter? I mean, funding is always good. We're not super funding constrained right now.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9952" target="_blank">02:45:52.880</a></span> | <span class="t">The main effect of funding is it will cause me to continuously and perhaps indefinitely delay</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9957" target="_blank">02:45:57.360</a></span> | <span class="t">fundraising. Periodically, I'll like set out to be interested in fundraising and someone will be</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9961" target="_blank">02:46:01.440</a></span> | <span class="t">like offer a grant and then I will get to delay for another six months or fundraising or nine</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9966" target="_blank">02:46:06.000</a></span> | <span class="t">months or whatever. So you can, you can delay the time at which Paul needs to think for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9969" target="_blank">02:46:09.600</a></span> | <span class="t">some time about fundraising. Well, one question I think would be interesting to ask you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9973" target="_blank">02:46:13.200</a></span> | <span class="t">is, you know, I, I think people can talk vaguely about the value of theoretical research and how</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9979" target="_blank">02:46:19.120</a></span> | <span class="t">it contributes to real world applications. And, you know, you can look at historical examples</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9983" target="_blank">02:46:23.360</a></span> | <span class="t">or something, but, um, you are somebody who've actually has done this in a big way. Like RLHF</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9989" target="_blank">02:46:29.280</a></span> | <span class="t">is, uh, you know, something you developed and then it actually has got into an application</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9994" target="_blank">02:46:34.000</a></span> | <span class="t">that has been used by millions of people. So tell me about like, you just, it's just that pipeline.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=9997" target="_blank">02:46:37.440</a></span> | <span class="t">How can you reliably identify theoretical problems that will matter for real world applications?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10002" target="_blank">02:46:42.320</a></span> | <span class="t">Cause it's one thing to like read about Turing or something and, um, the, the halting problem,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10006" target="_blank">02:46:46.720</a></span> | <span class="t">but like here you have the real thing. Yeah. I mean, it is definitely exciting</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10010" target="_blank">02:46:50.800</a></span> | <span class="t">to have worked on a thing that has a, has a real world impact. The main caveat I'd provide is like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10017" target="_blank">02:46:57.120</a></span> | <span class="t">RLHF is very, very simple, um, compared to many things. Um, and like, so the motivation for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10024" target="_blank">02:47:04.640</a></span> | <span class="t">working on that problem was like, look, this is how it probably should work. Or like, this is a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10028" target="_blank">02:47:08.160</a></span> | <span class="t">step in some like progression. It's unclear if it's like the final step or something,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10031" target="_blank">02:47:11.280</a></span> | <span class="t">but it's a very natural thing to do that. Like people probably should be and probably will be</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10036" target="_blank">02:47:16.080</a></span> | <span class="t">doing. Um, I'm saying like, if you want to do, if you want to talk about crazy stuff,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10040" target="_blank">02:47:20.800</a></span> | <span class="t">it's good to like help make those steps happen faster. Um, and it's good to learn about like,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10045" target="_blank">02:47:25.200</a></span> | <span class="t">what are, there's lots of issues that occur in practice, even for things that seem very simple</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10048" target="_blank">02:47:28.240</a></span> | <span class="t">on paper, but mostly like the story of is just like, yep. I think my sense of the world is things</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10053" target="_blank">02:47:33.280</a></span> | <span class="t">that look like good ideas on paper, just like often are harder than they look, but like the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10058" target="_blank">02:47:38.160</a></span> | <span class="t">world isn't that far from what makes sense on paper. Like large language models look really</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10062" target="_blank">02:47:42.000</a></span> | <span class="t">good on paper. And RLHF looks really good on paper. And these things like, I think just work</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10066" target="_blank">02:47:46.560</a></span> | <span class="t">out in a way that's, yeah, I think people may be overestimate or like, maybe it's like kind</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10072" target="_blank">02:47:52.400</a></span> | <span class="t">of a trope that people talk about. Like it's easy to like underestimate how much gap there is to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10077" target="_blank">02:47:57.040</a></span> | <span class="t">practice, like how many things will come up that don't come up in theory, but it's also like easy</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10080" target="_blank">02:48:00.800</a></span> | <span class="t">to overestimate, like how inscrutable the world is. Like the things that happen mostly are things</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10084" target="_blank">02:48:04.160</a></span> | <span class="t">that do just kind of make sense. Yeah. I feel like most ML implementation does just come down</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10088" target="_blank">02:48:08.560</a></span> | <span class="t">to a bunch of detail though, of like, you know, build a very simple version of the system,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10091" target="_blank">02:48:11.920</a></span> | <span class="t">understand what goes wrong, fix the things that go wrong, scale it up, understand what goes wrong.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10095" target="_blank">02:48:15.520</a></span> | <span class="t">And I'm glad I have some experience doing that, but I don't think, I think that like does cause</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10100" target="_blank">02:48:20.560</a></span> | <span class="t">me to be better informed about like what makes sense in ML and what like can actually work.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10104" target="_blank">02:48:24.320</a></span> | <span class="t">But I don't think it caused me to have like a whole lot of deep expertise or like deep wisdom</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10111" target="_blank">02:48:31.120</a></span> | <span class="t">about like how to close the, how to close the gap. Yeah. Yeah. But is there some tip on</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10116" target="_blank">02:48:36.960</a></span> | <span class="t">identifying things like RLHF will, which actually do matter versus making sure you don't get stuck</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10123" target="_blank">02:48:43.520</a></span> | <span class="t">in some theoretical problem that doesn't matter? Or is it just coincidence? Or I mean, is there</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10127" target="_blank">02:48:47.920</a></span> | <span class="t">something you can do in advance to make sure that the thing is useful? I don't know if the RLHF</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10132" target="_blank">02:48:52.800</a></span> | <span class="t">story is like the best, best success case or something, but like, oh, because the, yeah,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10137" target="_blank">02:48:57.600</a></span> | <span class="t">the capabilities. Maybe I'd say more profoundly, like, again, it's just not that hard a case.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10141" target="_blank">02:49:01.840</a></span> | <span class="t">It was like a little bit, it's a little bit unfair to be like, I'm going to predict the thing,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10145" target="_blank">02:49:05.280</a></span> | <span class="t">which I, like, I, I pretty much think it was going to happen at some point. And so it was</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10149" target="_blank">02:49:09.760</a></span> | <span class="t">mostly a case of acceleration, whereas like the work we're doing right now is specifically focused</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10153" target="_blank">02:49:13.760</a></span> | <span class="t">on something that's like kind of crazy enough that it might not happen, even if it's a really good</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10158" target="_blank">02:49:18.000</a></span> | <span class="t">idea or challenging enough, it might not happen. But I'd say like in general, like, and this draws</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10163" target="_blank">02:49:23.120</a></span> | <span class="t">a little bit on like more broad experience, more broadly in theory. It's just like a lot of the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10168" target="_blank">02:49:28.240</a></span> | <span class="t">times when theory fails to connect with practice, it's just kind of clear. It's not going to connect</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10172" target="_blank">02:49:32.720</a></span> | <span class="t">if you like try, if you actually think about it and you're like, what are the key constraints</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10175" target="_blank">02:49:35.840</a></span> | <span class="t">in practice? Is the theoretical problem we're working on actually connected to those constraints?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10179" target="_blank">02:49:39.840</a></span> | <span class="t">Is there a path, like, is there something that is possible in theory that would actually address</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10183" target="_blank">02:49:43.600</a></span> | <span class="t">like real world issues? I think like the vast majority, like as a theoretical computer scientist,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10187" target="_blank">02:49:47.760</a></span> | <span class="t">the vast majority of theoretical computer science, like has very little chance of ever affecting</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10192" target="_blank">02:49:52.720</a></span> | <span class="t">practice, but also it is completely clear in theory that it has very little chance of affecting</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10196" target="_blank">02:49:56.000</a></span> | <span class="t">practice. Like most of the theory fails to affect practice, not because of like all the stuff you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10200" target="_blank">02:50:00.000</a></span> | <span class="t">don't think of, but just because like, it was like, you could call it like dead on arrival,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10204" target="_blank">02:50:04.800</a></span> | <span class="t">but you could also just be like, it's not really the point. It's just like mathematicians also,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10207" target="_blank">02:50:07.520</a></span> | <span class="t">are like, they're not trying to affect practice. And they're not like, why does my number theory</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10211" target="_blank">02:50:11.120</a></span> | <span class="t">not affect practice? It was kind of obvious. So I think the biggest thing is just like actually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10214" target="_blank">02:50:14.960</a></span> | <span class="t">caring about that and then like learning at least what's basically going on in the actual systems</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10219" target="_blank">02:50:19.600</a></span> | <span class="t">you care about and what are actually the important constraints. And is this a real theoretical</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10222" target="_blank">02:50:22.720</a></span> | <span class="t">problem? The basic reason most theory doesn't do that is just like, that's not where the easy</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10226" target="_blank">02:50:26.800</a></span> | <span class="t">theoretical problems are. So I think theory is instead motivated by like, we're going to build</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10231" target="_blank">02:50:31.280</a></span> | <span class="t">up the edifice of theory. And like, sometimes there'll be opportunistic, like opportunistically,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10234" target="_blank">02:50:34.960</a></span> | <span class="t">we'll find a case that comes close to practice or we'll find something practitioners are already</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10238" target="_blank">02:50:38.000</a></span> | <span class="t">doing and try and bring into our framework or something. But the theory of change is mostly</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10241" target="_blank">02:50:41.840</a></span> | <span class="t">not this thing that's going to make it into practice. It's mostly like, this is going to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10244" target="_blank">02:50:44.080</a></span> | <span class="t">contribute to the body of knowledge that will slowly grow. And like sometimes opportunistically</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10248" target="_blank">02:50:48.080</a></span> | <span class="t">yields important results. How big would, do you think a seed AI would be? What is the minimum</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10255" target="_blank">02:50:55.120</a></span> | <span class="t">sort of encoding of something that is as smart as a human? I think it depends a lot what substrate</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10259" target="_blank">02:50:59.760</a></span> | <span class="t">it gets to run on. So if you tell me like, like how much computation does it get before, or like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10264" target="_blank">02:51:04.000</a></span> | <span class="t">what kind of real world infrastructure does it get? Um, like you could ask what's the shortest</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10267" target="_blank">02:51:07.760</a></span> | <span class="t">program, which like, if you run it on a million H one hundreds connected in like a nice network</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10271" target="_blank">02:51:11.600</a></span> | <span class="t">with like hospitable environment, we'll eventually like go to the stars. But that seems like it's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10275" target="_blank">02:51:15.680</a></span> | <span class="t">probably on the order of like tens of thousands of bytes, or I don't know if I had to guess a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10279" target="_blank">02:51:19.760</a></span> | <span class="t">median, I'd guess 10,000 bytes. Wait, wait, the specification or the compression of? Just the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10284" target="_blank">02:51:24.560</a></span> | <span class="t">program, a program, which one run. Oh, got it. Got it. Okay. But that's going to be like really</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10288" target="_blank">02:51:28.240</a></span> | <span class="t">cheatsy. Um, so they could ask what's the thing that has values and will like expand and like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10292" target="_blank">02:51:32.320</a></span> | <span class="t">roughly preserve its values. Cause like that thing, the 10,000 byte thing, we'll just lean</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10297" target="_blank">02:51:37.120</a></span> | <span class="t">heavily on like evolution and natural selection to get there. Um, for that, like, I don't know,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10304" target="_blank">02:51:44.000</a></span> | <span class="t">million bytes, a hundred thousand bytes, something like that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10308" target="_blank">02:51:48.880</a></span> | <span class="t">Um, how, how would, do you think AI lie detectors will work where you kind of just look at the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10314" target="_blank">02:51:54.880</a></span> | <span class="t">activations and not, not in the, um, not find explanations in the way you were talking about</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10320" target="_blank">02:52:00.080</a></span> | <span class="t">with heuristics, but literally just like, here's what truth looks like. Here's what</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10324" target="_blank">02:52:04.800</a></span> | <span class="t">lies look like. Let's just segregate the lane space, uh, and see if we can identify the two.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10330" target="_blank">02:52:10.880</a></span> | <span class="t">Yeah. I think the separate the, like just train a classifier to do it. It's like a little bit</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10334" target="_blank">02:52:14.640</a></span> | <span class="t">complicated for a few reasons and like may not work, but if you just like broaden the space and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10338" target="_blank">02:52:18.560</a></span> | <span class="t">say like, Hey, it's like, you want to know if someone's lying, you get to interrogate them,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10341" target="_blank">02:52:21.680</a></span> | <span class="t">but also you get to like rewind them arbitrarily and make a million copies of them. I do think</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10345" target="_blank">02:52:25.440</a></span> | <span class="t">it's like pretty hard to lie successfully. You get to like look at their brain, even if you don't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10349" target="_blank">02:52:29.200</a></span> | <span class="t">quite understand what's happening, you get to rewind them a million times. You get to like run</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10352" target="_blank">02:52:32.800</a></span> | <span class="t">all those parallel copies and do gradient descent or whatever. Um, I think there's a pretty good</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10356" target="_blank">02:52:36.640</a></span> | <span class="t">chance that you can just tell if someone is lying, um, like a brain emulation or an AI or whatever.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10362" target="_blank">02:52:42.560</a></span> | <span class="t">Uh, unless they were like aggressively selected. Like if it's just, they are trying to lie well,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10368" target="_blank">02:52:48.480</a></span> | <span class="t">rather than it's like they were selected over many generations to be excellent at lying or</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10371" target="_blank">02:52:51.840</a></span> | <span class="t">something, then like your ML system, hopefully you didn't train it a bunch to lie and you want</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10375" target="_blank">02:52:55.520</a></span> | <span class="t">to be careful about your training scheme effectively does that. But yeah, that seems</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10379" target="_blank">02:52:59.680</a></span> | <span class="t">like it's more likely than not to succeed. And how possible do you think it will be for us to,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10384" target="_blank">02:53:04.880</a></span> | <span class="t">um, specify human verifiable rules for reasoning such that even if the AI is super intelligent,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10392" target="_blank">02:53:12.400</a></span> | <span class="t">we can't really understand why there are certain things. We know that the way in which it arrives</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10397" target="_blank">02:53:17.760</a></span> | <span class="t">at these conclusions is valid. Like it was trying to persuade us to something we can be like, I</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10401" target="_blank">02:53:21.920</a></span> | <span class="t">don't understand the, all the steps, but I know that this is something that's valid and you're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10405" target="_blank">02:53:25.360</a></span> | <span class="t">not just making shit up. That seems very hard if you want it to be like competitive with learned</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10410" target="_blank">02:53:30.960</a></span> | <span class="t">reasoning. Um, so like, I don't, I mean, it depends a little bit exactly how you set it up,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10415" target="_blank">02:53:35.360</a></span> | <span class="t">but for like the ambitious versions of that, let's say it would address the alignment problem.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10419" target="_blank">02:53:39.040</a></span> | <span class="t">Um, they seem pretty unlikely, you know, like five, 10% kind of thing. Is there an upper bound</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10425" target="_blank">02:53:45.040</a></span> | <span class="t">on intelligence? No, not in the near term, but just like super intelligence at some point, like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10429" target="_blank">02:53:49.280</a></span> | <span class="t">how, how, how far do you think that can go? It seems like it's going to depend a little bit on</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10432" target="_blank">02:53:52.800</a></span> | <span class="t">what is meant by intelligence. It kind of reads as a question. It's similar to like, is there an</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10436" target="_blank">02:53:56.240</a></span> | <span class="t">upper bound on like strength or something? Like there are a lot of forms. I think it's like the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10440" target="_blank">02:54:00.960</a></span> | <span class="t">case that for, yeah, I think there are like sort of arbitrarily smart input output functionalities.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10445" target="_blank">02:54:05.920</a></span> | <span class="t">And then like, if you hold fixed the amount of compute, there is some smartest one. If you're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10449" target="_blank">02:54:09.040</a></span> | <span class="t">just like, what's, what's the best set of like 10 to the 40th operations. There's just, there's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10453" target="_blank">02:54:13.280</a></span> | <span class="t">only finitely many of them. So some like best one, um, for any particular notion of best that you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10457" target="_blank">02:54:17.840</a></span> | <span class="t">have in mind. So I guess like, I'm just like for the unbounded question, we're allowed to use</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10461" target="_blank">02:54:21.280</a></span> | <span class="t">arbitrary description, complexity and compute like probably now. And for the, um, I mean,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10466" target="_blank">02:54:26.240</a></span> | <span class="t">there is some like optimal conduct. Like if you're like, I have some goal in mind and I'm just like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10469" target="_blank">02:54:29.680</a></span> | <span class="t">what action best achieves it. If you imagine like a little box embedded in the universe, I think</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10472" target="_blank">02:54:32.880</a></span> | <span class="t">there's kind of just like an optimal input output behavior. So I guess in that sense, I think there</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10476" target="_blank">02:54:36.160</a></span> | <span class="t">is a, is an upper bound, but it's not saturatable in the physical universe. Um, cause it's definitely</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10482" target="_blank">02:54:42.000</a></span> | <span class="t">exponentially slow. Right. Yeah. Yeah. Or, you know, because of comms or other things or heat</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10488" target="_blank">02:54:48.080</a></span> | <span class="t">there, it just might be physically impossible to instantiate something smarter than this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10491" target="_blank">02:54:51.600</a></span> | <span class="t">Yeah. I mean, like, for example, if you, if you imagine what the best thing is, it would almost</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10494" target="_blank">02:54:54.960</a></span> | <span class="t">certainly involve just like simulating every possible universe it might be in modular, like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10498" target="_blank">02:54:58.640</a></span> | <span class="t">moral constraints, which I don't know if you want to include them, but like, so that would be very,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10502" target="_blank">02:55:02.000</a></span> | <span class="t">very slow. It would involve simulating like all, you know, it's sort of like, I don't know exactly</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10507" target="_blank">02:55:07.920</a></span> | <span class="t">how slow, but like double exponential, very slow. Carl, uh, Shulman laid out his picture of the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10513" target="_blank">02:55:13.040</a></span> | <span class="t">intelligence explosion in the seven hour episode. Um, what I know you guys have talked a lot. What</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10518" target="_blank">02:55:18.880</a></span> | <span class="t">about his basic picture? Like, what is it? Do you have some disagreements? Is there some crux</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10524" target="_blank">02:55:24.000</a></span> | <span class="t">that you guys have explored? It's related to our timelines discussion from earlier. I think the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10528" target="_blank">02:55:28.320</a></span> | <span class="t">biggest, yeah, I think the biggest issue is probably error bars where like Carl has a very,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10535" target="_blank">02:55:35.040</a></span> | <span class="t">like very software focused, very fast kind of takeoff picture. And I think that is plausible,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10541" target="_blank">02:55:41.360</a></span> | <span class="t">but not that likely. Like, I think it's a couple of ways you could perturb the situation. And my</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10545" target="_blank">02:55:45.360</a></span> | <span class="t">guess is one of them applies. Um, so maybe I have like, I don't know exactly what Carl's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10550" target="_blank">02:55:50.480</a></span> | <span class="t">probability is. I feel like Carl's gonna have like a 60% chance on some crazy thing that I'm only</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10553" target="_blank">02:55:53.840</a></span> | <span class="t">going to assign like a 20% chance to or 30% chance or something. And like, I think those, those kinds</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10558" target="_blank">02:55:58.800</a></span> | <span class="t">of perturbations are like one, how long a period is there of complementarity between AI capabilities</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10564" target="_blank">02:56:04.000</a></span> | <span class="t">and human capabilities, which will tend to soften takeoff to like how much diminishing returns are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10569" target="_blank">02:56:09.520</a></span> | <span class="t">there on software progress such that like, is it like broader takeoff involving scaling, like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10575" target="_blank">02:56:15.120</a></span> | <span class="t">electricity production and hardware production? Is that likely to happen during takeoff where I'm</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10579" target="_blank">02:56:19.360</a></span> | <span class="t">like more like 50, 50 or more, um, stuff like this. Yeah. Okay. So is it that you think the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10586" target="_blank">02:56:26.720</a></span> | <span class="t">ultimate constraints will be more hard or like the, uh, the basic case he's laid out is that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10591" target="_blank">02:56:31.600</a></span> | <span class="t">you can just have a sequence of things like, uh, flash attention or MOE, uh, and you can just keep</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10598" target="_blank">02:56:38.400</a></span> | <span class="t">stacking these kinds of things on. I'm very unsure if you can keep stacking them or like,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10603" target="_blank">02:56:43.200</a></span> | <span class="t">it's kind of a question of what's like the returns curve. And like, Carl has some inference from</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10606" target="_blank">02:56:46.480</a></span> | <span class="t">historical data or some way he'd extrapolate the trend. I am more like 50, 50 on whether the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10610" target="_blank">02:56:50.800</a></span> | <span class="t">software on the intelligence explosion is even possible. And then like a somewhat higher</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10615" target="_blank">02:56:55.040</a></span> | <span class="t">probability that it's slower than I think it might not be possible. Well, so the entire question is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10620" target="_blank">02:57:00.080</a></span> | <span class="t">like, if you double R and D effort, do you get enough additional improvement to further double</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10624" target="_blank">02:57:04.960</a></span> | <span class="t">the efficiency? And like, that's that question will itself be a function of your hardware base,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10629" target="_blank">02:57:09.840</a></span> | <span class="t">like how much hardware you have. And of course it's like at the amount of hardware we're going</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10632" target="_blank">02:57:12.720</a></span> | <span class="t">to have and the level of sophistication we have as the process begins, like, is it the case that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10636" target="_blank">02:57:16.480</a></span> | <span class="t">each doubling of actually the initials only depends on the hardware or like each level of hardware</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10641" target="_blank">02:57:21.680</a></span> | <span class="t">will have some place at this dynamic asymptotes. Um, so the question is just like, for how long</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10646" target="_blank">02:57:26.000</a></span> | <span class="t">is it the case that each doubling of R and D at least doubles the effective output of your,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10650" target="_blank">02:57:30.720</a></span> | <span class="t">you know, AI research population. And I think like, I have a higher probability on that. Like,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10656" target="_blank">02:57:36.240</a></span> | <span class="t">I think it's kind of close. If you look at the empirics, I think the empirics benefit a lot from</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10659" target="_blank">02:57:39.120</a></span> | <span class="t">like continuing hardware scale up so that like the effective R and D stock is like significantly</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10664" target="_blank">02:57:44.000</a></span> | <span class="t">smaller than it looks, if that makes sense. Uh, what, what are the empirics you're referring to?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10667" target="_blank">02:57:47.920</a></span> | <span class="t">Um, so there's kind of two sources of evidence. One is like looking across a bunch of industries</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10672" target="_blank">02:57:52.400</a></span> | <span class="t">of like, what is the general improvement with each doubling of like either R and D investment</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10676" target="_blank">02:57:56.080</a></span> | <span class="t">or experience where like, it is quite exceptional to have a field with not, anyway, it's pretty</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10681" target="_blank">02:58:01.520</a></span> | <span class="t">good to have a field where each time you double the R and D investment, you get a doubling of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10684" target="_blank">02:58:04.880</a></span> | <span class="t">efficiency. The second source of evidence is on like actual, like algorithmic improvement in ML,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10689" target="_blank">02:58:09.600</a></span> | <span class="t">which is obviously much, much scarcer. Um, and they're like, you can make a case that it's been</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10695" target="_blank">02:58:15.120</a></span> | <span class="t">like each doubling of R and D has given you like roughly a four X or something increase in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10698" target="_blank">02:58:18.800</a></span> | <span class="t">computational efficiency. But like, there's a question of how much that benefits. When I say</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10702" target="_blank">02:58:22.800</a></span> | <span class="t">the effect of R and D stock is smaller, I mean, like we scale up, like you're doing a new task,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10706" target="_blank">02:58:26.880</a></span> | <span class="t">like every couple of years we're doing a new task because you're operating a scale much larger than</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10709" target="_blank">02:58:29.760</a></span> | <span class="t">the previous scale. And so a lot of your effort is how to make use of the new scale. So if you're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10713" target="_blank">02:58:33.760</a></span> | <span class="t">not increasing your installed hardware base and are just flat at a level of hardware, I think you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10716" target="_blank">02:58:36.960</a></span> | <span class="t">get like much faster diminishing returns than people have gotten historically. I think Karl</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10720" target="_blank">02:58:40.480</a></span> | <span class="t">agrees in principle, this is true. And then once you make that adjustment, I think it's like very</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10724" target="_blank">02:58:44.480</a></span> | <span class="t">unclear where the empirics shake out. I think Karl has thought about these more than I am,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10727" target="_blank">02:58:47.360</a></span> | <span class="t">so I should maybe defer more, but anyway, I'm at like 50, 50 on that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10731" target="_blank">02:58:51.120</a></span> | <span class="t">Um, how have your timelines changed over the last 20 years?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10734" target="_blank">02:58:54.480</a></span> | <span class="t">Last 20 years?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10735" target="_blank">02:58:55.360</a></span> | <span class="t">Yeah. Um, how long have you been working on anything related to AI?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10739" target="_blank">02:58:59.520</a></span> | <span class="t">So I started thinking about this stuff in like 2010, um, or so. So I think my first,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10745" target="_blank">02:59:05.760</a></span> | <span class="t">my earliest timeline prediction will be in like 2011. Um, I think in 2011, my like rough</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10752" target="_blank">02:59:12.480</a></span> | <span class="t">picture was like, we will not have insane AI in the next 10 years. And then like I get increasingly</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10758" target="_blank">02:59:18.080</a></span> | <span class="t">uncertain after that, but like we converged to like, you know, 1% per year or something like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10762" target="_blank">02:59:22.240</a></span> | <span class="t">that. And then probably in 2016, my take was like, we won't have crazy AI in the next five years,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10766" target="_blank">02:59:26.720</a></span> | <span class="t">but then we converged to like one or 2% per year after that. Um, then in 2019,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10774" target="_blank">02:59:34.720</a></span> | <span class="t">I guess I made a round of forecasts, uh, where I gave like 30% or something to 25%</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10783" target="_blank">02:59:43.760</a></span> | <span class="t">to crazy AI by 2040 and like 10% by 2030 or something like that. So I think my 2030 probability</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10792" target="_blank">02:59:52.640</a></span> | <span class="t">has been kind of stable and my 2040 probability has been going up. And I would guess it's too</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10796" target="_blank">02:59:56.320</a></span> | <span class="t">sticky. I guess that 40% I gave at the beginning is just like from not having updated recently</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10800" target="_blank">03:00:00.960</a></span> | <span class="t">enough. And I maybe just need to sit down. I would guess that should be even higher. I think</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10804" target="_blank">03:00:04.960</a></span> | <span class="t">like 15% in 2030, I'm not feeling that bad about this. It's just like each passing year is like a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10808" target="_blank">03:00:08.720</a></span> | <span class="t">big update against 2030. Like we don't have that many years left. Um, and that's like roughly</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10814" target="_blank">03:00:14.480</a></span> | <span class="t">counterbalanced with AI going pretty well. Whereas for like the 2040 thing, like the passing years</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10818" target="_blank">03:00:18.640</a></span> | <span class="t">are not that big a deal. And like, as we see the, like things are basically working, that's like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10821" target="_blank">03:00:21.920</a></span> | <span class="t">cutting out a lot of the probability of not having AI by 2040. So yeah, my 2030 probability up a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10826" target="_blank">03:00:26.880</a></span> | <span class="t">little bit, like maybe twice as high as it used to be or like something like that. My 2040 probably</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10831" target="_blank">03:00:31.360</a></span> | <span class="t">like up more, much more significantly. Uh, how fast do you think, um, uh, we can keep building</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10838" target="_blank">03:00:38.160</a></span> | <span class="t">fabs to keep up with the demand? Yeah, I don't know much about any of the relevant areas. My</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10842" target="_blank">03:00:42.240</a></span> | <span class="t">like best guess is like, um, maybe my understanding is right now, like 5% or something of like the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10850" target="_blank">03:00:50.640</a></span> | <span class="t">next year's like total or like best process fabs will be making AI hardware of which like only a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10858" target="_blank">03:00:58.960</a></span> | <span class="t">small fraction will be going into very large training runs, like only a couple, maybe a couple</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10862" target="_blank">03:01:02.960</a></span> | <span class="t">of percent of total output. And then like that represents maybe like 1% of total possible output,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10867" target="_blank">03:01:07.200</a></span> | <span class="t">a couple of percent of like leading process, 1% of total or something. I don't know if that's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10871" target="_blank">03:01:11.280</a></span> | <span class="t">right, but I think that's like the rough ballpark we're in. I think things will be like pretty fast</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10874" target="_blank">03:01:14.800</a></span> | <span class="t">as you scale up for like the next order of magnitude or two from there, because you're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10878" target="_blank">03:01:18.720</a></span> | <span class="t">basically just shifting over other stuff. My sense is it would be like years of delay. There's like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10883" target="_blank">03:01:23.440</a></span> | <span class="t">multiple reasons that you expect years of delay for going past that. Maybe even at that, you start</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10888" target="_blank">03:01:28.080</a></span> | <span class="t">having, yeah, there's just a lot of problems. Like building new fabs is quite slow. Um, and I don't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10894" target="_blank">03:01:34.480</a></span> | <span class="t">think there's like, TSMC is not like planning on increases in total demand driven by AI, like kind</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10899" target="_blank">03:01:39.600</a></span> | <span class="t">of conspicuously not planning on it. Um, I don't think anyone else is really ramping up production</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10905" target="_blank">03:01:45.360</a></span> | <span class="t">in anticipation either. So I think, and then similarly, like just building data centers of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10909" target="_blank">03:01:49.040</a></span> | <span class="t">that size seems like very, very hard and also probably has multiple years of delay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10912" target="_blank">03:01:52.640</a></span> | <span class="t">What does your portfolio look like?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10914" target="_blank">03:01:54.320</a></span> | <span class="t">Um, I've tried to get rid of most of the AI stuff that's like plausibly implicated in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10919" target="_blank">03:01:59.120</a></span> | <span class="t">policy work or like, um, see the advocacy on the RSP stuff or my involvement with Anthropic.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10925" target="_blank">03:02:05.520</a></span> | <span class="t">Or what would it look like if you had no complex of interest?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10927" target="_blank">03:02:07.760</a></span> | <span class="t">And no inside information. Like I also still have a bunch of hardware investments,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10932" target="_blank">03:02:12.880</a></span> | <span class="t">which I need to think about, but like, I don't know, a lot of TSMC. I have a chunk of NVIDIA,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10939" target="_blank">03:02:19.120</a></span> | <span class="t">although I keep, I just keep betting against NVIDIA constantly since 2016 or something. I've</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10944" target="_blank">03:02:24.560</a></span> | <span class="t">been destroyed on that bet. Although AMD has also done fine. I just like, well, now the case now is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10949" target="_blank">03:02:29.520</a></span> | <span class="t">even easier, but it's similar to the case in the old days, just a very expensive company given the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10954" target="_blank">03:02:34.480</a></span> | <span class="t">total amount of R and D investment they've made. They have like whatever, a trillion dollar</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10957" target="_blank">03:02:37.280</a></span> | <span class="t">valuation or something. That's like very high. So the question is like, how expensive is it to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10963" target="_blank">03:02:43.920</a></span> | <span class="t">like make a TPU such that's like actually outcompetes a H100 or something. And I'm like,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10969" target="_blank">03:02:49.280</a></span> | <span class="t">wow, it's real level, high level of incompetence. If Google can't like catch up fast enough to like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10974" target="_blank">03:02:54.800</a></span> | <span class="t">make that trillion dollar valuation not justified. Whereas with TSMC it's much harder. They have a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10980" target="_blank">03:03:00.720</a></span> | <span class="t">harder remote you think? Yeah. I think it's, it's a lot harder, especially if you're in this regime</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10984" target="_blank">03:03:04.240</a></span> | <span class="t">where like you're trying to scale up. So like if you're unable to build fabs, I think it will take</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10988" target="_blank">03:03:08.000</a></span> | <span class="t">a very long time to build as many fabs as people want. Like the effect of that will be to like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10991" target="_blank">03:03:11.440</a></span> | <span class="t">bid up the price of existing fabs and existing semi-conditioned manufacturing equipment. And so</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=10995" target="_blank">03:03:15.360</a></span> | <span class="t">like just those hard assets will become like spectacularly valuable as well the existing like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=11000" target="_blank">03:03:20.320</a></span> | <span class="t">GPUs and like the actual, yeah. Yeah. I think it's just hard. That seems like the hardest asset to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=11007" target="_blank">03:03:27.680</a></span> | <span class="t">scale up quickly. So it's like the asset, if you have like a rapid run-up, it's the one that you'd</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=11010" target="_blank">03:03:30.880</a></span> | <span class="t">expect to most benefit. Whereas like NVIDIA stuff will ultimately be replaced by like, either it's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=11017" target="_blank">03:03:37.120</a></span> | <span class="t">better stuff made by humans or stuff made by, with AI systems. Like the gap will close even further</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=11021" target="_blank">03:03:41.040</a></span> | <span class="t">as you build AI systems. Right. Unless NVIDIA is using those systems. Yeah. The point is just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=11025" target="_blank">03:03:45.680</a></span> | <span class="t">like the future R&D will sow a door past R&D and there's like just not that much stickiness. There's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=11031" target="_blank">03:03:51.280</a></span> | <span class="t">less stickiness in the future than there has been in the past. Like, yeah. I don't know. So I don't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=11036" target="_blank">03:03:56.560</a></span> | <span class="t">want to, not commenting from any private information, just in my gut having caveat of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=11039" target="_blank">03:03:59.920</a></span> | <span class="t">this is like the single bet I've most lost. Okay. Not including NVIDIA in that portfolio.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=11044" target="_blank">03:04:04.080</a></span> | <span class="t">And final question. There's a lot of schemes out there for alignment. And I think just like a lot</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=11048" target="_blank">03:04:08.960</a></span> | <span class="t">of general takes and a lot of this stuff is over my head where I think I literally, it took me like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=11054" target="_blank">03:04:14.000</a></span> | <span class="t">weeks to understand the mechanistic anomaly stuff you work on without spending weeks. How do you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=11059" target="_blank">03:04:19.600</a></span> | <span class="t">detect bullshit? Like people have explained their schemes to me and I'm like, honestly, I don't know</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=11064" target="_blank">03:04:24.320</a></span> | <span class="t">if it makes sense or not. With you, I'm just like, I trust Paul enough that I think there's probably</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=11068" target="_blank">03:04:28.880</a></span> | <span class="t">something here if I try to understand this enough, but yeah. How do you detect bullshit?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=11073" target="_blank">03:04:33.440</a></span> | <span class="t">Yeah. So I think it depends on the kind of work. So for like the kind of stuff we're doing,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=11077" target="_blank">03:04:37.360</a></span> | <span class="t">my guess is like most people, there's just not really a way you're going to tell whether it's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=11081" target="_blank">03:04:41.200</a></span> | <span class="t">bullshit. So I think like it's important that we don't spend that much money on like the people</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=11085" target="_blank">03:04:45.200</a></span> | <span class="t">who want to hire us are probably going to dig in in depth. I don't think there's a way you can tell</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=11088" target="_blank">03:04:48.720</a></span> | <span class="t">whether it's bullshit without either spending like a lot of effort or leaning on deference.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=11095" target="_blank">03:04:55.520</a></span> | <span class="t">With empirical work, it's like interesting in that you do have some signals of the quality</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=11098" target="_blank">03:04:58.800</a></span> | <span class="t">of work where you can be like, I mean, is it, does it work in practice? Like does the story,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=11102" target="_blank">03:05:02.240</a></span> | <span class="t">I think the stories are just radically simpler. And so you probably can evaluate those stories</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=11105" target="_blank">03:05:05.840</a></span> | <span class="t">like on their face. And then you mostly come down to these questions about like,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=11109" target="_blank">03:05:09.040</a></span> | <span class="t">what are the key difficulties? Yeah. I tend to like be optimistic when people dismiss something</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=11113" target="_blank">03:05:13.200</a></span> | <span class="t">because like this doesn't deal with a key difficulty or this runs into the following</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=11116" target="_blank">03:05:16.080</a></span> | <span class="t">insuperable obstacle. I tend to be like a little bit more skeptical about those arguments and tend</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=11120" target="_blank">03:05:20.800</a></span> | <span class="t">to think like, yeah, something can be bullshit because it's not addressing a real problem.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=11124" target="_blank">03:05:24.960</a></span> | <span class="t">That's like, I think the easiest way, like, this is a problem someone's interested in. That's just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=11128" target="_blank">03:05:28.000</a></span> | <span class="t">like not actually an important problem. And there's no story about why it's going to become</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=11130" target="_blank">03:05:30.560</a></span> | <span class="t">an important problem, e.g. like it's not a problem now and won't get worse, or it is maybe a problem</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=11135" target="_blank">03:05:35.040</a></span> | <span class="t">now, but it's clearly getting better. That's like one way. And then conditioned on like passing that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=11141" target="_blank">03:05:41.120</a></span> | <span class="t">bar, like dealing with something that actually engages with like important parts of the argument</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=11145" target="_blank">03:05:45.440</a></span> | <span class="t">for concern and then like actually making sense empirically. So like, I think most work is anchored</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=11150" target="_blank">03:05:50.400</a></span> | <span class="t">by its source of feedback is like actually engaging with real models. So it's like,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=11153" target="_blank">03:05:53.680</a></span> | <span class="t">does it make sense to have engaged with real models? And does the story about how it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=11156" target="_blank">03:05:56.640</a></span> | <span class="t">like deals with key difficulties actually make sense? Um, I'm like pretty liberal past there.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=11164" target="_blank">03:06:04.000</a></span> | <span class="t">Um, I think it's really hard to like, e.g. people look at mechanistic interpretability and be like,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=11168" target="_blank">03:06:08.640</a></span> | <span class="t">well, this obviously can't succeed. And I'm like, I don't know. How can you tell it obviously can't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=11171" target="_blank">03:06:11.760</a></span> | <span class="t">succeed? Like, I think it's reasonable to take total investment in the field, like how fast</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=11175" target="_blank">03:06:15.840</a></span> | <span class="t">is it making progress? Like how does that pencil? I think like most things people work on though,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=11181" target="_blank">03:06:21.120</a></span> | <span class="t">actually pencil, like pretty fine. Like they look like they could be reasonable investments. Um,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=11185" target="_blank">03:06:25.360</a></span> | <span class="t">things are not like super out of whack. Okay, great. This is, I think a good place to close.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=11190" target="_blank">03:06:30.080</a></span> | <span class="t">Paul, thank you so much for your time. Yeah. Thanks for having me. It was good chatting.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=11192" target="_blank">03:06:32.720</a></span> | <span class="t">Yeah, absolutely. Hey everybody. I hope you enjoyed that episode. As always,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=11198" target="_blank">03:06:38.720</a></span> | <span class="t">the most helpful thing you can do is to share the podcast, send it to people you think might</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=11202" target="_blank">03:06:42.960</a></span> | <span class="t">enjoy it, put it in Twitter, your group chats, et cetera. Just splits the world.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9AAhTLa0dT0&t=11207" target="_blank">03:06:47.600</a></span> | <span class="t">Appreciate your listening. I'll see you next time. Cheers.</span></div></div></body></html>