<html><head><title>AI Agents Take the Wheel: Devin, SIMA, Figure 01 and The Future of Jobs</title>
<style>
    body {
        font-family: Arial, sans-serif;
        margin: 0;
        padding: 0;
        background-color: #f4f4f4;
        color: #333;
    }
    .container {
        width: 95%;  /* Increased width to use more space */
        margin: auto;
        overflow: auto;  /* Added to handle overflow by adding a scrollbar if necessary */
    }
    h2, h3 {
        color: #333;
        text-align: center;
    }
    a {
        color: #0000FF;  /* Traditional blue color for links */
        text-decoration: none;
    }
    a:hover {
        text-decoration: underline;
    }
    img {
        display: block;
        margin: auto;
        max-width: 100%;
    }
    .c {
        margin: 10px 0;
    }
    .s, .t {
        display: inline-block;
        margin-right: 5px;
    }
    .max-width {
        max-width: 800px;
        margin: auto;
        padding-left: 20px;
    }
    table {
        width: 100%;
        border-collapse: collapse;
    }
    th, td {
        border: 1px solid #ddd;
        padding: 8px;
        text-align: left;  /* Ensure text alignment is consistent */
    }
    tr:nth-child(even) {
        background-color: #f2f2f2;
    }
    tr:nth-child(odd) {
        background-color: #e6e6e6;
    }
</style>

    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-69VLBMTTP0"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-69VLBMTTP0');
    </script>
    </head><body><div class='container'><a href="index.html">back to index</a><h2>AI Agents Take the Wheel: Devin, SIMA, Figure 01 and The Future of Jobs</h2><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM"><img src="https://i.ytimg.com/vi/Dbog8Yw3kEM/maxresdefault.jpg" style="width:50%;"></a><div><br></div><div style="text-align: left;"><a href="./Dbog8Yw3kEM.html">Whisper Transcript</a> | <a href="./transcript_Dbog8Yw3kEM.html">Transcript Only Page</a></div><br><div style="max-width: 800px;"><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=0" target="_blank">00:00:00.000</a></span> | <span class="t">Three developments in the last 48 hours show how we are moving into an era in which AI models</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=6" target="_blank">00:00:06.240</a></span> | <span class="t">can walk the walk, not just talk the talk. Whether the developments quite meet the hype</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=11" target="_blank">00:00:11.920</a></span> | <span class="t">attached to them is another question. I've read and analysed in full the three relevant papers</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=17" target="_blank">00:00:17.360</a></span> | <span class="t">and associated posts to find out more. We'll first explore Devon, the AI system your boss</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=22" target="_blank">00:00:22.960</a></span> | <span class="t">told you not to worry about. Then Google DeepMind's SEMA, which spends most of its time</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=27" target="_blank">00:00:27.760</a></span> | <span class="t">playing video games. And then Figure One, the humanoid robot which likes to talk while doing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=33" target="_blank">00:00:33.120</a></span> | <span class="t">the dishes. But the TL;DW is this. These three systems are each a long way from human performance</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=40" target="_blank">00:00:40.880</a></span> | <span class="t">in their domains, but think of them more as containers or shells for the vision language</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=46" target="_blank">00:00:46.400</a></span> | <span class="t">models powering them. So when the GPT-4 that's behind most of them is swapped out for GPT-5 or</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=53" target="_blank">00:00:53.280</a></span> | <span class="t">Gemini 2, all these systems are going to see big and hard to predict upgrades overnight. And that's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=59" target="_blank">00:00:59.840</a></span> | <span class="t">a point that seems especially relevant on this, the one year anniversary of the release of GPT-4.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=67" target="_blank">00:01:07.040</a></span> | <span class="t">But let's start of course with Devon, billed as the first AI software engineer. Now Devon isn't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=73" target="_blank">00:01:13.440</a></span> | <span class="t">a model, it's a system that's likely based on GPT-4. It's equipped with a code editor,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=79" target="_blank">00:01:19.680</a></span> | <span class="t">shell and browser. So of course it can not just understand your prompt, but look up and read</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=86" target="_blank">00:01:26.000</a></span> | <span class="t">documentation. A bit like AutoGPT, it's designed to come up with plans first and then execute them,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=92" target="_blank">00:01:32.560</a></span> | <span class="t">but it does so much better than AutoGPT did. But before we get to the benchmark that everyone's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=98" target="_blank">00:01:38.000</a></span> | <span class="t">talking about, let me show you a 30 second demonstration of Devon in action. All I had</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=102" target="_blank">00:01:42.960</a></span> | <span class="t">to do was send this blog post and a message to Devon. From there, Devon actually does all the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=107" target="_blank">00:01:47.760</a></span> | <span class="t">work for me, starting with reading this blog post and figuring out how to run the code.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=112" target="_blank">00:01:52.320</a></span> | <span class="t">In a couple minutes, Devon's actually made a lot of progress. And if we jump to the middle here,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=120" target="_blank">00:02:00.320</a></span> | <span class="t">you can see that Devon's been able to find and fix some edge cases and bugs that the blog post</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=126" target="_blank">00:02:06.080</a></span> | <span class="t">did not cover for me. And if we jump to the end, we can see that Devon sends me the final result,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=132" target="_blank">00:02:12.480</a></span> | <span class="t">which I love. I also got two bonus images here and here. So let me know if you guys see anything</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=141" target="_blank">00:02:21.280</a></span> | <span class="t">hidden in these. It can also fine tune a model autonomously. And if you're not familiar,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=146" target="_blank">00:02:26.160</a></span> | <span class="t">think of that as refining a model rather than training it from scratch. That makes me wonder</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=151" target="_blank">00:02:31.520</a></span> | <span class="t">about a future where if a model can't succeed at a task, it fine tunes another model or itself</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=157" target="_blank">00:02:37.840</a></span> | <span class="t">until it can. Anyway, this is the benchmark that everyone's talking about, SWE Bench,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=163" target="_blank">00:02:43.280</a></span> | <span class="t">Software Engineering Bench. Devon got almost 14% and in this chart crushes Cloud 2 and GPT-4,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=170" target="_blank">00:02:50.080</a></span> | <span class="t">which got 1.7%. They say Devon was unassisted, whereas all other models were assisted,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=176" target="_blank">00:02:56.320</a></span> | <span class="t">meaning the model was told exactly which files need to be edited. Before we get too much further</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=180" target="_blank">00:03:00.880</a></span> | <span class="t">though, what the hell is this benchmark? Well, unlike many benchmarks, they drew from real world</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=186" target="_blank">00:03:06.080</a></span> | <span class="t">professional problems, 2,294 software engineering problems that people had and their corresponding</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=193" target="_blank">00:03:13.200</a></span> | <span class="t">solutions. Resolving these issues requires understanding and coordinating changes across</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=198" target="_blank">00:03:18.400</a></span> | <span class="t">multiple functions, classes, and files simultaneously. The code involved might</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=203" target="_blank">00:03:23.040</a></span> | <span class="t">require the model to process extremely long contexts and perform, they say, complex reasoning.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=209" target="_blank">00:03:29.520</a></span> | <span class="t">These aren't just fill in the blank or multiple choice questions. The model has to understand the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=214" target="_blank">00:03:34.400</a></span> | <span class="t">issue, read through the relevant parts of the code base, remove lines, and add lines. Fixing a bug</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=220" target="_blank">00:03:40.480</a></span> | <span class="t">might involve navigating a large repo, understanding the interplay between functions in different files,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=225" target="_blank">00:03:45.920</a></span> | <span class="t">or spotting a small error in convoluted code. On average, a model might need to edit almost</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=231" target="_blank">00:03:51.200</a></span> | <span class="t">two files, three functions, and about 33 lines of code. But one point to make clear is that Devon</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=236" target="_blank">00:03:56.880</a></span> | <span class="t">was only tested on a subset of this benchmark and the tasks in the benchmark were only a tiny subset</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=243" target="_blank">00:04:03.360</a></span> | <span class="t">of GitHub issues. And even all of those issues represent just a subset of the skills of software</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=248" target="_blank">00:04:08.960</a></span> | <span class="t">engineering. So when you see all caps videos saying this is AGI, you've got to put it in some context.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=254" target="_blank">00:04:14.800</a></span> | <span class="t">Here's just one example of what I mean. They selected only pull requests, which are like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=259" target="_blank">00:04:19.280</a></span> | <span class="t">proposed solutions, that are merged or accepted, that solve the issue, and that introduce new tests.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=266" target="_blank">00:04:26.000</a></span> | <span class="t">Would that not slightly bias the dataset toward problems that are easier to detect,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=270" target="_blank">00:04:30.640</a></span> | <span class="t">report, and fix? In other words, complex issues might not be adequately represented if they're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=275" target="_blank">00:04:35.680</a></span> | <span class="t">less likely to have straightforward solutions. And narrowing down the proposed solutions to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=280" target="_blank">00:04:40.720</a></span> | <span class="t">only those that introduce new tests could bias towards bugs or features that are easier to write</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=285" target="_blank">00:04:45.840</a></span> | <span class="t">tests for. That is to say that highly complex issues, where writing a clear test is difficult,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=291" target="_blank">00:04:51.440</a></span> | <span class="t">may be underrepresented. Now, having said all of that, I might shock you by saying I think that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=296" target="_blank">00:04:56.720</a></span> | <span class="t">there will be rapid improvement in the performance on this benchmark. When Devin is equipped with GPT-5,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=302" target="_blank">00:05:02.480</a></span> | <span class="t">I could see it easily exceeding 50%. Here are just a few reasons why. First, some of these problems</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=308" target="_blank">00:05:08.320</a></span> | <span class="t">contained images, and therefore the more multimodal these language models get, the better they'll get.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=313" target="_blank">00:05:13.920</a></span> | <span class="t">Second, and more importantly, a large context window is particularly crucial for this task.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=318" target="_blank">00:05:18.960</a></span> | <span class="t">When the benchmark came out, they said models are simply ineffective at localizing problematic</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=324" target="_blank">00:05:24.080</a></span> | <span class="t">code in a sea of tokens. They get distracted by additional context. I don't think that will be</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=329" target="_blank">00:05:29.120</a></span> | <span class="t">true for much longer as we've already seen with Gemini 1.5. Third reason, models, they say,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=334" target="_blank">00:05:34.320</a></span> | <span class="t">are often trained using standard code files and likely rarely see patch files. I would bet that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=340" target="_blank">00:05:40.240</a></span> | <span class="t">GPT-5 would have seen everything. Fourth, language models will be augmented, they predict, with</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=345" target="_blank">00:05:45.360</a></span> | <span class="t">program analysis and software engineering tools. And it's almost like they could see six months</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=350" target="_blank">00:05:50.000</a></span> | <span class="t">in the future because they said, "To this end, we are particularly excited about agent-based</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=354" target="_blank">00:05:54.480</a></span> | <span class="t">approaches like Devin for identifying relevant context from a code base." I could go on, but</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=359" target="_blank">00:05:59.280</a></span> | <span class="t">hopefully that background on the benchmark allows you to put the rest of what I'm going to say in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=363" target="_blank">00:06:03.840</a></span> | <span class="t">a bit more context. And yes, of course, I saw how Devin was able to complete a real job on Upwork.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=369" target="_blank">00:06:09.760</a></span> | <span class="t">Honestly, I could see these kinds of tasks going the way of copywriting tasks on Upwork. Here's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=374" target="_blank">00:06:14.720</a></span> | <span class="t">some more context though. We don't know the actual cost of running Devin for so long. It actually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=379" target="_blank">00:06:19.040</a></span> | <span class="t">takes quite a while for it to execute on its task. We're talking 15, 20, 30 minutes, even 60 minutes</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=385" target="_blank">00:06:25.040</a></span> | <span class="t">sometimes. As Bindu Reddy points out, it can get even more expensive than a human, although costs</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=390" target="_blank">00:06:30.240</a></span> | <span class="t">are, of course, falling. Devin, she says, will not be replacing any software engineer in the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=394" target="_blank">00:06:34.640</a></span> | <span class="t">near term. And noted deep learning author Francois Charlet predicted this. There will be more software</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=399" target="_blank">00:06:39.520</a></span> | <span class="t">engineers, the kind that write code, in five years than there are today. And newly unemployed Andre</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=404" target="_blank">00:06:44.800</a></span> | <span class="t">Karpathy says that software engineering is on track to change substantially with humans more</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=410" target="_blank">00:06:50.080</a></span> | <span class="t">supervising the automation, pitching in high level commands, ideas, or progression strategies</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=415" target="_blank">00:06:55.520</a></span> | <span class="t">in English. I would say with the way things are going, they could pitch it in any language and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=419" target="_blank">00:06:59.840</a></span> | <span class="t">the model will understand. Frankly, with vision models the way they are, you could practically</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=424" target="_blank">00:07:04.240</a></span> | <span class="t">mime your code idea and it would understand what to do. And while Devin likely relies on GPT-4,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=430" target="_blank">00:07:10.080</a></span> | <span class="t">other competitors are training their own frontier scale models. Indeed, the startup Magic, which</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=436" target="_blank">00:07:16.000</a></span> | <span class="t">aims to build a co-worker, not just a co-pilot for developers, is going a step further. They're not</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=441" target="_blank">00:07:21.760</a></span> | <span class="t">even using transformers. They say transformers aren't the final architecture. We have something</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=446" target="_blank">00:07:26.000</a></span> | <span class="t">with a multi-million token context window. Super curious, of course, how that performs on SWE bench.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=452" target="_blank">00:07:32.080</a></span> | <span class="t">But the thing I want to emphasize again comes from Bloomberg. Cognition AI admit that Devin</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=457" target="_blank">00:07:37.360</a></span> | <span class="t">is very dependent on the underlying models and use GPT-4 together with the reinforcement learning</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=463" target="_blank">00:07:43.040</a></span> | <span class="t">techniques. Obviously, that's pretty vague, but imagine when GPT-5 comes out. With scale,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=467" target="_blank">00:07:47.280</a></span> | <span class="t">you get so many things, not just better coding ability. If you remember, GPT-3 couldn't actually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=472" target="_blank">00:07:52.000</a></span> | <span class="t">reflect effectively, whereas GPT-4 could. If GPT-5 is twice or 10 times better at reflecting</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=478" target="_blank">00:07:58.800</a></span> | <span class="t">and debugging, that is going to dramatically change the performance of the Devin system</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=483" target="_blank">00:08:03.200</a></span> | <span class="t">overnight. Just delete the GPT-4 API and put in the GPT-5 API. And wait, Jeff Kloon,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=489" target="_blank">00:08:09.440</a></span> | <span class="t">who I was going to talk about later in this video, has just retweeted one of my own videos. I</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=495" target="_blank">00:08:15.120</a></span> | <span class="t">literally just saw this two seconds ago when it came up as a notification on my Twitter account.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=500" target="_blank">00:08:20.320</a></span> | <span class="t">This was not at all supposed to be part of this video, but I am very much honored by that. And</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=505" target="_blank">00:08:25.120</a></span> | <span class="t">actually, I'm going to be talking about Jeff Kloon later in this video. Chances are he's going to see</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=509" target="_blank">00:08:29.040</a></span> | <span class="t">this video, so this is getting very Inception-like. He was key to CIMA, which I'm going to talk about</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=513" target="_blank">00:08:33.920</a></span> | <span class="t">next. The simulation hypothesis just got 10% more likely. I'm going to recover from that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=519" target="_blank">00:08:39.600</a></span> | <span class="t">distraction and get back to this video, because there's one more thing to mention about Devin.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=523" target="_blank">00:08:43.920</a></span> | <span class="t">The reaction to that model has been unlike almost anything I've seen. People are genuinely in some</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=530" target="_blank">00:08:50.000</a></span> | <span class="t">distress about the implications for jobs. And while I've given the context of what the benchmark does</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=535" target="_blank">00:08:55.120</a></span> | <span class="t">mean and doesn't mean, I can't deny that the job landscape is incredibly unpredictable at the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=540" target="_blank">00:09:00.880</a></span> | <span class="t">moment. Indeed, I can't see it ever not being unpredictable. I actually still have a lot of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=545" target="_blank">00:09:05.520</a></span> | <span class="t">optimism about there still being a human economy in the future, but maybe that's a topic for another</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=550" target="_blank">00:09:10.800</a></span> | <span class="t">video. I just want to acknowledge that people are scared and these companies should start addressing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=556" target="_blank">00:09:16.160</a></span> | <span class="t">those fears. And I know many of you are getting ready to comment that we want all jobs to go,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=560" target="_blank">00:09:20.800</a></span> | <span class="t">but you might be, I guess, disappointed by the fact that Cognition AI are asking for people to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=567" target="_blank">00:09:27.360</a></span> | <span class="t">apply to join them. So obviously they don't anticipate Devin automating everything just yet.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=572" target="_blank">00:09:32.080</a></span> | <span class="t">But it's time now to talk about Google DeepMind's CIMA, which is all about scaling up agents that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=577" target="_blank">00:09:37.680</a></span> | <span class="t">you can instruct with natural language. Essentially a scalable, instructable,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=583" target="_blank">00:09:43.280</a></span> | <span class="t">commandable, multi-world agent. The goal of CIMA being to develop an instructable agent that can</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=589" target="_blank">00:09:49.200</a></span> | <span class="t">accomplish anything a human can do in any simulated 3D environment. Their agent uses a mouse and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=596" target="_blank">00:09:56.240</a></span> | <span class="t">keyboard and takes pixels as input. But if you think about it, that's almost everything you do</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=601" target="_blank">00:10:01.600</a></span> | <span class="t">on a computer. Yes, this paper is about playing games, but couldn't you apply this technique to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=606" target="_blank">00:10:06.000</a></span> | <span class="t">say video editing or say anything you can do on your phone. Now, I know I haven't even told you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=610" target="_blank">00:10:10.480</a></span> | <span class="t">what the CIMA system is, but I'm giving you an idea of the kind of repercussions, implications.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=615" target="_blank">00:10:15.440</a></span> | <span class="t">If these systems work with games, there's so much else they might soon work with.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=619" target="_blank">00:10:19.760</a></span> | <span class="t">This was a paper I didn't get a chance to talk about that came out about six weeks ago.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=623" target="_blank">00:10:23.680</a></span> | <span class="t">It showed that even current generation models could handle tasks on a phone,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=627" target="_blank">00:10:27.680</a></span> | <span class="t">like navigating on Google Maps, downloading apps on Google Play or somewhat topically with TikTok,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=633" target="_blank">00:10:33.920</a></span> | <span class="t">swiping a video about a pet cat in TikTok and clicking a like for that video.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=638" target="_blank">00:10:38.640</a></span> | <span class="t">No, the success rates weren't perfect, but if you look at the averages and this is for GPT-4</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=643" target="_blank">00:10:43.280</a></span> | <span class="t">Vision, they are pretty high, 91%, 82%, 82%. These numbers in the middle, by the way, on the left,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=649" target="_blank">00:10:49.040</a></span> | <span class="t">reflect the number of steps that GPT-4 Vision took and on the right, the number of steps that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=653" target="_blank">00:10:53.360</a></span> | <span class="t">a human took. And that's just GPT-4 Vision, not a model optimized for agency, which we know</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=658" target="_blank">00:10:58.960</a></span> | <span class="t">that OpenAI is working on. So before we even get to video games, you can imagine an internet where</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=664" target="_blank">00:11:04.480</a></span> | <span class="t">there are models that are downloading, liking, commenting, doing pull requests, and we wouldn't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=670" target="_blank">00:11:10.480</a></span> | <span class="t">even know that it's AI. It would be, as far as I can tell, undetectable. Anyway, I'm getting</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=674" target="_blank">00:11:14.880</a></span> | <span class="t">distracted. Back to the CIMA paper. What is CIMA? In a nutshell, they got a bunch of games, including</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=680" target="_blank">00:11:20.640</a></span> | <span class="t">commercial video games like Valheim, 12 million copies sold at least, and their own made up games</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=686" target="_blank">00:11:26.560</a></span> | <span class="t">that Google created. They then paid a bunch of humans to play those games and gathered the data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=692" target="_blank">00:11:32.000</a></span> | <span class="t">That's what you could see on the screen, the images and the keyboard and mouse inputs that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=696" target="_blank">00:11:36.800</a></span> | <span class="t">the humans performed. They gave all of that training data to some pre-trained models. And</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=701" target="_blank">00:11:41.520</a></span> | <span class="t">at this point, the paper gets quite vague. It doesn't mention parameters or the exact composition</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=706" target="_blank">00:11:46.480</a></span> | <span class="t">of these pre-trained models. But from this, we get the CIMA agent, which then plays these games,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=712" target="_blank">00:11:52.320</a></span> | <span class="t">or more precisely, tries 10 second tasks within these games. This gives you an idea of the range</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=718" target="_blank">00:11:58.320</a></span> | <span class="t">of tasks, everything from taming and hunting to destroying and headbutting. But I don't want to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=724" target="_blank">00:12:04.160</a></span> | <span class="t">bury the lead. The main takeaway is this. Training on more games saw positive transfer when CIMA</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=730" target="_blank">00:12:10.400</a></span> | <span class="t">played on a new game. And notice how CIMA in purple across all of these games outperforms</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=736" target="_blank">00:12:16.320</a></span> | <span class="t">an environment specialized agent. That's one trained for just one game. And there is another</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=742" target="_blank">00:12:22.000</a></span> | <span class="t">gem buried in this graph. I'm colorblind, but I'm pretty sure that's teal or lighter blue. That's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=747" target="_blank">00:12:27.200</a></span> | <span class="t">zero shot. What that represents is when the model was trained across all the other games, bar the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=752" target="_blank">00:12:32.960</a></span> | <span class="t">actual game it was about to be tested in. And so notice how in some games like Goat Simulator 3,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=758" target="_blank">00:12:38.880</a></span> | <span class="t">that outperformed a model that was specialized for just that one game. The transfer effect was</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=765" target="_blank">00:12:45.280</a></span> | <span class="t">so powerful, it outdid the specialized training. Indeed, CIMA's performance is approaching the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=770" target="_blank">00:12:50.960</a></span> | <span class="t">ballpark of human performance. Now, I know we've seen that already with Starcraft 2 and OpenAI</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=776" target="_blank">00:12:56.560</a></span> | <span class="t">beating Dota, but this would be a model generalizing to almost any video game. Yes,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=781" target="_blank">00:13:01.360</a></span> | <span class="t">even Red Dead Redemption 2, which was covered in an entirely separate paper out of Beijing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=786" target="_blank">00:13:06.320</a></span> | <span class="t">That paper, they say, was the first to enable language models to follow the main storyline</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=791" target="_blank">00:13:11.280</a></span> | <span class="t">and finish real missions in complex AAA games. This time we're talking about things like protecting a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=796" target="_blank">00:13:16.640</a></span> | <span class="t">character, buying supplies, equipping shotguns. Again, what was holding them back was the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=801" target="_blank">00:13:21.440</a></span> | <span class="t">underlying model, GPT-4V. As I've covered elsewhere on the channel, it lacks in spatial perception.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=807" target="_blank">00:13:27.040</a></span> | <span class="t">It's not super accurate with moving the cursor, for example. But visual understanding and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=811" target="_blank">00:13:31.680</a></span> | <span class="t">performance is getting better fast. Take the challenging benchmark MMMU. It's about answering</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=817" target="_blank">00:13:37.920</a></span> | <span class="t">difficult questions that have a visual component. The benchmark only came out recently, giving top</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=822" target="_blank">00:13:42.480</a></span> | <span class="t">performance to GPT-4V at 56.8%, but that's already been superseded. Take Clawed 3 Opus,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=828" target="_blank">00:13:48.960</a></span> | <span class="t">which gets 59.4%. Yes, there is still a gap with human expert performance, but that gap</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=834" target="_blank">00:13:54.640</a></span> | <span class="t">is narrowing, like we've seen across this video. Just like Devon was solving real-world software</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=839" target="_blank">00:13:59.520</a></span> | <span class="t">engineering challenges, CIMA and other models are solving real-world games. Walking the walk,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=845" target="_blank">00:14:05.440</a></span> | <span class="t">not just talking the talk. And again, we can expect better and better results the more games</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=850" target="_blank">00:14:10.640</a></span> | <span class="t">CIMA is trained on. As the paper says, in every case, CIMA significantly outperforms the environment</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=856" target="_blank">00:14:16.240</a></span> | <span class="t">specialized agent, thus demonstrating positive transfer across environments. And this is exactly</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=861" target="_blank">00:14:21.680</a></span> | <span class="t">what we see in robotics as well. The key take-home from that Google DeepMind paper was that our</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=867" target="_blank">00:14:27.120</a></span> | <span class="t">results suggest that co-training with data from other platforms imbues RT2X in robotics with</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=874" target="_blank">00:14:34.080</a></span> | <span class="t">additional skills that were not present in the original dataset, enabling it to perform novel</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=878" target="_blank">00:14:38.560</a></span> | <span class="t">tasks. These were tasks and skills developed by other robots that were then transferred to RT2,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=884" target="_blank">00:14:44.880</a></span> | <span class="t">just like CIMA getting better at one video game by training on others. But did you notice there</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=890" target="_blank">00:14:50.240</a></span> | <span class="t">that smooth segue I did to robotics? It's the final container that I want to quickly talk about.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=896" target="_blank">00:14:56.880</a></span> | <span class="t">Why do I call this humanoid robot a container? Because it contains GPT-4 vision. Yes, of course,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=903" target="_blank">00:15:03.280</a></span> | <span class="t">it's real-time speed and dexterity is very impressive, but that intelligence of recognizing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=909" target="_blank">00:15:09.200</a></span> | <span class="t">what's on the table and moving it appropriately comes from the underlying model GPT-4 vision.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=914" target="_blank">00:15:14.320</a></span> | <span class="t">So, of course, I have to make the same point that the underlying model could easily be upgraded to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=919" target="_blank">00:15:19.280</a></span> | <span class="t">GPT-5 when it comes out. This humanoid would have a much deeper understanding of its environment</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=924" target="_blank">00:15:24.960</a></span> | <span class="t">and you as you're talking to it. Figure 1 takes in 10 images per second and this is not teleoperation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=931" target="_blank">00:15:31.360</a></span> | <span class="t">This is an end-to-end neural network. In other words, there's no human behind the scenes controlling</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=936" target="_blank">00:15:36.400</a></span> | <span class="t">this robot. Figure don't release pricing, but the estimate is between $30,000 and $150,000 per robot.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=944" target="_blank">00:15:44.320</a></span> | <span class="t">Still too pricey for most companies and individuals, but the CEO has a striking vision.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=950" target="_blank">00:15:50.240</a></span> | <span class="t">He basically wants to completely automate manual labor. This is the roadmap to a positive future</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=956" target="_blank">00:15:56.960</a></span> | <span class="t">powered by AI. He wants to build the largest company on the planet and eliminate the need</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=962" target="_blank">00:16:02.560</a></span> | <span class="t">for unsafe and undesirable jobs. The obvious question is if it can do those jobs, can't it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=968" target="_blank">00:16:08.400</a></span> | <span class="t">also do the safe and desirable jobs? I know I'm back to the jobs point again, but all of these</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=973" target="_blank">00:16:13.680</a></span> | <span class="t">questions became a bit more relevant, let's say, in the last 48 hours. The figure CEO goes on to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=979" target="_blank">00:16:19.200</a></span> | <span class="t">predict that everywhere from factories to farmland, the cost of labor will decrease until it becomes</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=984" target="_blank">00:16:24.960</a></span> | <span class="t">equivalent to the price of renting a robot, facilitating a long-term holistic reduction in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=990" target="_blank">00:16:30.160</a></span> | <span class="t">costs. Over time, humans could leave the loop altogether as robots become capable of building</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=995" target="_blank">00:16:35.840</a></span> | <span class="t">other robots, driving prices down even more. Manual labor, he says, could become optional.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=1001" target="_blank">00:16:41.920</a></span> | <span class="t">And if that's not a big enough vision for the next two decades, he goes on that the plan is also</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=1006" target="_blank">00:16:46.800</a></span> | <span class="t">to use these robots to build new worlds on other planets. Again, though, we get the reassurance</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=1012" target="_blank">00:16:52.560</a></span> | <span class="t">that our focus is on providing resources for jobs that humans don't want to perform. He also excludes</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=1018" target="_blank">00:16:58.400</a></span> | <span class="t">military applications. I just feel like his company and the world has a bit less control</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=1023" target="_blank">00:17:03.680</a></span> | <span class="t">over how the technology is going to be used than he might think it does. Indeed, Jeff Klune of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=1028" target="_blank">00:17:08.560</a></span> | <span class="t">OpenAI, Google DeepMind, SEMA, and earlier on in this video, FAME, reposted this from Edward Harris.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=1036" target="_blank">00:17:16.400</a></span> | <span class="t">It was a report commissioned by the US government that he worked on, and the TLDR was that things</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=1042" target="_blank">00:17:22.160</a></span> | <span class="t">are worse than we thought and nobody's in control. I definitely feel we're noticeably closer to AGI</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=1048" target="_blank">00:17:28.080</a></span> | <span class="t">this week than we were last week. As Jeff Klune put out yesterday, so many pieces of the AGI puzzle</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=1054" target="_blank">00:17:34.000</a></span> | <span class="t">are coming together. And I would also agree that as of today, no one's really in control. And we're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=1059" target="_blank">00:17:39.920</a></span> | <span class="t">not alone with Jensen Huang, the CEO of NVIDIA, saying that AI will pass every human test in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=1066" target="_blank">00:17:46.320</a></span> | <span class="t">around five years time. That, by the way, is a timeline shared by Sam Altman. This is a quote</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=1072" target="_blank">00:17:52.000</a></span> | <span class="t">from a book that's coming out soon. He was asked about what AGI means for marketers. He said, "Oh,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=1077" target="_blank">00:17:57.280</a></span> | <span class="t">for that, it will mean that 95% of what marketers use agencies, strategists, and creative professionals</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=1082" target="_blank">00:18:02.880</a></span> | <span class="t">for today will easily, nearly instantly, and at almost no cost be handled by the AI. And the AI</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=1089" target="_blank">00:18:09.280</a></span> | <span class="t">will likely be able to test its creative outputs against real or synthetic customer focus groups</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=1094" target="_blank">00:18:14.880</a></span> | <span class="t">for predicting results and optimizing. Again, all free, instant, and nearly perfect. Images, videos,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=1100" target="_blank">00:18:20.160</a></span> | <span class="t">campaign ideas, no problem." But specifically on timelines, he said this. When asked about when AGI</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=1105" target="_blank">00:18:25.280</a></span> | <span class="t">will be a reality, he said, "Five years, give or take, maybe slightly longer, but no one knows</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=1110" target="_blank">00:18:30.400</a></span> | <span class="t">exactly when or what it will mean for society." And it's not like that timeline is even unrealistic</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=1116" target="_blank">00:18:36.320</a></span> | <span class="t">in terms of compute. Using these estimates from semi-analysis, I calculated that just between</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=1120" target="_blank">00:18:40.960</a></span> | <span class="t">quarter one of 2024 and the fourth quarter of 2025, there will be a 14x increase in compute.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=1127" target="_blank">00:18:47.040</a></span> | <span class="t">Then if you factor in algorithmic efficiency doubling about every nine months, the effective</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=1131" target="_blank">00:18:51.840</a></span> | <span class="t">compute at the end of next year will be almost a hundred times that of right now. So yes, the world</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=1138" target="_blank">00:18:58.240</a></span> | <span class="t">is changing and changing fast and the public really need to start paying attention. But no,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=1144" target="_blank">00:19:04.320</a></span> | <span class="t">Devin is not AGI, no matter how much you put it in all caps. Thank you so much for watching to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=1149" target="_blank">00:19:09.840</a></span> | <span class="t">the end. And of course, I'd love to see you over on AI Insiders on Patreon. I'd love to see you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Dbog8Yw3kEM&t=1154" target="_blank">00:19:14.880</a></span> | <span class="t">there, but regardless, thank you so much for watching and as always have a wonderful day.</span></div></div></body></html>