<html><head><title>[LLM Paper Club] Llama 3.1 Paper: The Llama Family of Models</title>
<style>
    body {
        font-family: Arial, sans-serif;
        margin: 0;
        padding: 0;
        background-color: #f4f4f4;
        color: #333;
    }
    .container {
        width: 95%;  /* Increased width to use more space */
        margin: auto;
        overflow: auto;  /* Added to handle overflow by adding a scrollbar if necessary */
    }
    h2, h3 {
        color: #333;
        text-align: center;
    }
    a {
        color: #0000FF;  /* Traditional blue color for links */
        text-decoration: none;
    }
    a:hover {
        text-decoration: underline;
    }
    img {
        display: block;
        margin: auto;
        max-width: 100%;
    }
    .c {
        margin: 10px 0;
    }
    .s, .t {
        display: inline-block;
        margin-right: 5px;
    }
    .max-width {
        max-width: 800px;
        margin: auto;
        padding-left: 20px;
    }
    table {
        width: 100%;
        border-collapse: collapse;
    }
    th, td {
        border: 1px solid #ddd;
        padding: 8px;
        text-align: left;  /* Ensure text alignment is consistent */
    }
    tr:nth-child(even) {
        background-color: #f2f2f2;
    }
    tr:nth-child(odd) {
        background-color: #e6e6e6;
    }
</style>

    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-69VLBMTTP0"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-69VLBMTTP0');
    </script>
    </head><body><div class='container'><a href="index.html">back to index</a><h2>[LLM Paper Club] Llama 3.1 Paper: The Llama Family of Models</h2><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U"><img src="https://i.ytimg.com/vi/TgLSYIBoX5U/maxresdefault.jpg" style="width:50%;"></a><div><br></div><div style="text-align: left;"><a href="./TgLSYIBoX5U.html">Whisper Transcript</a> | <a href="./transcript_TgLSYIBoX5U.html">Transcript Only Page</a></div><br><div style="max-width: 800px;"><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=0" target="_blank">00:00:00.000</a></span> | <span class="t">And I kicked off like a what do people want to work on section with I'm going to do a deep dive in the paper because I need to make slides on this and that very much overtook the hackathon.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=10" target="_blank">00:00:10.000</a></span> | <span class="t">We had like a solid crew of like 20-30 people that were just discussing the paper with me and slides didn't really get made.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=16" target="_blank">00:00:16.000</a></span> | <span class="t">But also I don't know it was weird hackathon project winner was just a deep dive into the paper, but we had an in-person paper club session that I led yesterday and a lot of people from there trying to join in so it should be vibes.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=30" target="_blank">00:00:30.000</a></span> | <span class="t">I am liking in person hybrid format, I might start running those we'll see how they go but it was good. Everyone had good discussions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=40" target="_blank">00:00:40.000</a></span> | <span class="t">Amazing, amazing. Yeah, I would be happy to join that. Once I get back to SF this Friday.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=47" target="_blank">00:00:47.000</a></span> | <span class="t">Oh, Friday. Exciting. Yeah. So, as you know, we also we interviewed Thomas who was one of the paper co authors, he did not give us the paper beforehand, which is annoying because after reading the paper I have so much better questions that we actually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=62" target="_blank">00:01:02.000</a></span> | <span class="t">end up asking in a podcast but whatever.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=66" target="_blank">00:01:06.000</a></span> | <span class="t">Yeah, yeah, I think that you know a bunch of us have read it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=69" target="_blank">00:01:09.000</a></span> | <span class="t">I feel like Vibhu you're probably best situated to, to take over the screen if you want, if you have, if you have stuff.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=77" target="_blank">00:01:17.000</a></span> | <span class="t">I have very basic stuff but yeah, I'll share. We also got someone at the hackathon that worked on a hackathon project that's paper to video, so someone's cooking up a video explainer of this it's like literally doing inference right now, we'll share</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=91" target="_blank">00:01:31.000</a></span> | <span class="t">that once it's ready. Yeah. Yeah, this is, I mean this is, I'm excited about it but also I'm wondering how to do this justice. I feel like we can post questions in here, and then, you know, people can just kind of discuss in the chat.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=110" target="_blank">00:01:50.000</a></span> | <span class="t">And yeah, I mean like we classically have a lot of side discussions in the zoom chat anyway so I'm not worried about that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=117" target="_blank">00:01:57.000</a></span> | <span class="t">I mean, yeah, well Vibhu, Vibhu go ahead you can get started. But like, what do what do people think what people want to talk about, you know, personally, I, I called this the synthetic data paper.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=131" target="_blank">00:02:11.000</a></span> | <span class="t">So I have a lot of interesting insights or these questions about the synthetic data stuff, but we can talk about everything like there's just so much in here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=140" target="_blank">00:02:20.000</a></span> | <span class="t">The format that worked well yesterday was like, we're not getting through 100 pages, I'll give the high level we'll go through the tweet overviews. And then let's just dig into whatever anyone found interesting and had like, you know, something that someone dove into</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=154" target="_blank">00:02:34.000</a></span> | <span class="t">so like part of it was they had a bunch of scaling laws for pre training they had scaling laws for how they picked 405 B and 15 trillion tokens. So whatever someone chose to dive deep into is what like I was like okay, well we'll dig into that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=168" target="_blank">00:02:48.000</a></span> | <span class="t">Also, other part of this I'm probably going to give like a longer one hour breakdown of like I'll go through the whole paper, have like an hour talk at some point so I started slides, they're very not ready these are like 20 minutes of slides just became discussions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=181" target="_blank">00:03:01.000</a></span> | <span class="t">But basically, I'll spend like two minutes on overview everyone knows llama.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=186" target="_blank">00:03:06.000</a></span> | <span class="t">Interesting stuff that so like they drop three to three 131 was a pretty big update the AP got a lot better than 70 be got a lot better. A lot of this is just for other talk, but, um, yeah, they drop some sizes the context with getting bigger.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=201" target="_blank">00:03:21.000</a></span> | <span class="t">Their scaling laws were just overtrain and pray, but no, they're actually pretty grounded and real scaling laws.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=210" target="_blank">00:03:30.000</a></span> | <span class="t">They're all dense models, after reading the paper their whole justification for this was like we want to see stuff that scales. It's the first actual research paper where they talk about everything hardware inference hardware failures what happened how they fixed it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=223" target="_blank">00:03:43.000</a></span> | <span class="t">So, real research paper, there's a lot on it it's like basically everything pre training post training, they're scaling laws how they ran experiments it's a great recipe on how to build it, that's what this talk would be later when I do it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=236" target="_blank">00:03:56.000</a></span> | <span class="t">It's really cooked models really good, it's solid open sources like GPT four level, they talk about how they bring up performance.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=255" target="_blank">00:04:15.000</a></span> | <span class="t">Also for anyone that finds any time to cut us off cut us off it's all vibes.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=260" target="_blank">00:04:20.000</a></span> | <span class="t">The jumps for the eight be basically from three to three one, it got better all around overview of the paper, there's a bunch of Twitter threads so instead of me making slides will go over like the main one shared a discord for everyone that hasn't seen also is my</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=277" target="_blank">00:04:37.000</a></span> | <span class="t">whole screen sharing. So is it just okay let me share my desktop. Okay, so for people that are new and not in discord.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=285" target="_blank">00:04:45.000</a></span> | <span class="t">I do have a very active running llama three section, I'll share the paper. So, if we go to this little like you have to find it so you got to go through the news and find the llama there's like 60 links that we've been posting of everything popular on Twitter</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=302" target="_blank">00:05:02.000</a></span> | <span class="t">will go through these at some point but paper overview is basically like they have multiple phases of training. I'm very not ready I do have other notes on this that all share it there so I started screenshotting stuff.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=318" target="_blank">00:05:18.000</a></span> | <span class="t">They have like three aspects to a good foundation model, basically data scale complexity. This is why they didn't go into an MOE they want training stability, basic two phase training there's like pre training post training.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=332" target="_blank">00:05:32.000</a></span> | <span class="t">They do a lot of scaling well work so in their pre trained data set, how they, how do they determine what the pre training mixes in the post training in the pre training, they start doing most of the training at like low context, then they continue pre</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=346" target="_blank">00:05:46.000</a></span> | <span class="t">training at long contrast.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=348" target="_blank">00:05:48.000</a></span> | <span class="t">A lot of what they said in their complexity section was like, we want to do basic stuff that will like scale up this is like the foundation for how we can like redefine scaling laws and train this stuff up so no crazy complex RL just, you know, SFT for chat</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=363" target="_blank">00:06:03.000</a></span> | <span class="t">tuning and then they do a lot of models for rejection sampling to do data set stuff, DPO.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=382" target="_blank">00:06:22.000</a></span> | <span class="t">They added their safety bullshit at the end. Other interesting stuff that didn't make it to Twitter was like, they had multimodal experiments, they did a lot of experiments, they did a lot of tests, they did a lot of experiments, they did a lot</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=403" target="_blank">00:06:43.000</a></span> | <span class="t">don't do it. They added their safety bullshit at the end. Other interesting stuff that didn't make</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=408" target="_blank">00:06:48.760</a></span> | <span class="t">it to Twitter was like they had multimodal experiments. They trained in adapters. They</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=413" target="_blank">00:06:53.720</a></span> | <span class="t">have a vision adapter, audio adapter stuff. There was cool sections on their pre-training mix. So</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=420" target="_blank">00:07:00.600</a></span> | <span class="t">basically they used a lot of like traditional filtering techniques. So they have like Roberta</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=426" target="_blank">00:07:06.520</a></span> | <span class="t">based filters for high quality. They have this for their synthetic data distribution. Like how</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=431" target="_blank">00:07:11.800</a></span> | <span class="t">do we extract out high quality data? Then they have a lot of traditional NLP for like PII text</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=436" target="_blank">00:07:16.680</a></span> | <span class="t">extraction. They had a whole section on like how they scrape the web and how they train their own</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=441" target="_blank">00:07:21.480</a></span> | <span class="t">parsing HTML. They compared it to what's out there and their stuff's better. There's a lot in this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=446" target="_blank">00:07:26.200</a></span> | <span class="t">paper. Datamix was a really interesting section as well. So they basically go into, here's basically</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=454" target="_blank">00:07:34.440</a></span> | <span class="t">what they did, deduplication, all this stuff that you would expect. Model-based filtering was pretty</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=459" target="_blank">00:07:39.880</a></span> | <span class="t">cool. They used a lot of like they trained classifiers on LAMA 2 outputs. On the synthetic</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=464" target="_blank">00:07:44.840</a></span> | <span class="t">data side, Eugene has a great tweet thread. We'll probably go through it at some point.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=468" target="_blank">00:07:48.520</a></span> | <span class="t">This was an interesting section that we haven't seen before. So when you have like a base model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=474" target="_blank">00:07:54.200</a></span> | <span class="t">that you're pre-training and you have like 15 trillion tokens, how do you determine what the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=478" target="_blank">00:07:58.440</a></span> | <span class="t">right mix of that is? So their finding was like half the tokens are general knowledge, 25% map</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=484" target="_blank">00:08:04.440</a></span> | <span class="t">and reasoning, 17% code, all this stuff. But they're like, this is the first research paper</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=489" target="_blank">00:08:09.720</a></span> | <span class="t">that actually breaks this stuff down. They actually did like scaling law experiments.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=493" target="_blank">00:08:13.640</a></span> | <span class="t">So they trained small models that were like a couple billion parameters. They started testing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=499" target="_blank">00:08:19.480</a></span> | <span class="t">different datamixes and then they train a large model to see what actually works on what's the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=503" target="_blank">00:08:23.720</a></span> | <span class="t">right datamix. And then they're like, here's the answer for this stuff. Model architecture was</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=509" target="_blank">00:08:29.640</a></span> | <span class="t">pretty similar. They like did a few little changes. They did some better attention masking,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=514" target="_blank">00:08:34.600</a></span> | <span class="t">group query attention, here's architecture. All this stuff is like on Twitter, so not as interesting.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=519" target="_blank">00:08:39.640</a></span> | <span class="t">From the podcast that Sean had, the vocab section is pretty interesting. They're like,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=524" target="_blank">00:08:44.600</a></span> | <span class="t">instead of messing with tokenizers, changing vocab is pretty big for small models. Check out</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=529" target="_blank">00:08:49.960</a></span> | <span class="t">the podcast or if it comes up in discussion, we'll discuss it. Scaling laws was another interesting</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=535" target="_blank">00:08:55.160</a></span> | <span class="t">one for the paper itself. Basically traditional like chinchilla scaling laws used to have this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=541" target="_blank">00:09:01.960</a></span> | <span class="t">whole like, they're predicting what's the optimal for your compute budget, like what's the optimal</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=547" target="_blank">00:09:07.160</a></span> | <span class="t">model parameters, all that stuff, how many tokens you train on. We thought that they were just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=552" target="_blank">00:09:12.360</a></span> | <span class="t">scaling and preying and trading like, you know, fixed cost training run for cheaper inference.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=557" target="_blank">00:09:17.880</a></span> | <span class="t">But this stuff is actually grounded. So they developed new scaling laws where TLDR of what</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=563" target="_blank">00:09:23.000</a></span> | <span class="t">they did is previously we used to do scaling laws where we're just predicting on next token</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=570" target="_blank">00:09:30.040</a></span> | <span class="t">prediction accuracy, right? So we're trying to predict on like perplexity and just how good is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=575" target="_blank">00:09:35.480</a></span> | <span class="t">next token prediction. Instead they do all this fancy math and they change the training objective</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=581" target="_blank">00:09:41.720</a></span> | <span class="t">to be like more representative of a reasoning benchmark. They use the ARC challenge where</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=586" target="_blank">00:09:46.440</a></span> | <span class="t">basically they have a reasoning benchmark and now instead of doing scaling laws to predict next token</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=592" target="_blank">00:09:52.120</a></span> | <span class="t">prediction, they've changed it so that they're doing scaling laws to predict optimal model stuff</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=597" target="_blank">00:09:57.240</a></span> | <span class="t">based on actual reasoning. And that's where they come up with this like, their scaling laws show</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=602" target="_blank">00:10:02.680</a></span> | <span class="t">that for a 402b model, you want to train on 16 and a half trillion tokens. Based on that, they did a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=608" target="_blank">00:10:08.520</a></span> | <span class="t">flagship 405b based on 15 trillion tokens. And then this is where they have their like infra</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=615" target="_blank">00:10:15.400</a></span> | <span class="t">optimal where they started to do the 8b, the 70b, they just reuse their 15 trillion tokens and just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=622" target="_blank">00:10:22.360</a></span> | <span class="t">overtrained and that works. The other really cool section, the sections that didn't make it on</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=627" target="_blank">00:10:27.720</a></span> | <span class="t">Twitter were like their training infrastructure. So they give out everything, right? They give out</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=633" target="_blank">00:10:33.160</a></span> | <span class="t">like the full pre-training stack of like, they have a section in here on how they do their pre-training.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=638" target="_blank">00:10:38.920</a></span> | <span class="t">So like, one is like the whole hardware configuration. So 16,000 H100 hours, what</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=646" target="_blank">00:10:46.040</a></span> | <span class="t">failures they hit, why they went for simplicity. This was a pretty interesting section. Like over</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=651" target="_blank">00:10:51.800</a></span> | <span class="t">their 54 day training, they had like 400 job interruptions, 419 unexpected interruptions,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=659" target="_blank">00:10:59.560</a></span> | <span class="t">and like 78% of these were like GPU hardware issues. And then they have a section on like,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=665" target="_blank">00:11:05.240</a></span> | <span class="t">if they did MOE, all this stuff compounds. So we just wanted something like simple,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=669" target="_blank">00:11:09.480</a></span> | <span class="t">scalable that we could deal with well. And like, this is stuff that you don't really see in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=674" target="_blank">00:11:14.280</a></span> | <span class="t">papers anymore, right? It goes further with like, what is the pre-training set? So like,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=679" target="_blank">00:11:19.560</a></span> | <span class="t">these formulas, we don't really see anymore, right? So it's like when they pre-trained it,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=684" target="_blank">00:11:24.920</a></span> | <span class="t">here's their like peak learning rate, here's their warmup, here's their decay, here's how</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=688" target="_blank">00:11:28.600</a></span> | <span class="t">many training steps, here's the bat size, little nuggets like this haven't really like come up on</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=693" target="_blank">00:11:33.560</a></span> | <span class="t">Twitter yet. But like, you know, at first, they have a bat size of 4 million tokens with a small</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=698" target="_blank">00:11:38.280</a></span> | <span class="t">sequence length. So like, the first bit of training is a sequence length of 4,000. Then</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=703" target="_blank">00:11:43.080</a></span> | <span class="t">they double it to like 8 million sequences at 8,000 for the next 252 million tokens. After</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=709" target="_blank">00:11:49.960</a></span> | <span class="t">they've trained on 200 million tokens, they double it again to like larger bat size for the next 3</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=714" target="_blank">00:11:54.920</a></span> | <span class="t">trillion tokens. And then they do most of the training at 8,000 token sequence length. So like,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=720" target="_blank">00:12:00.520</a></span> | <span class="t">little stuff like this, I feel like we still need to digest. There's reasons for why they did this,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=725" target="_blank">00:12:05.800</a></span> | <span class="t">but basically TL;DR, no other open source paper has like a formula like this. And then that's kind</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=731" target="_blank">00:12:11.880</a></span> | <span class="t">of what the next like 100 pages is. I feel like at that point, instead of finding what I found</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=737" target="_blank">00:12:17.720</a></span> | <span class="t">interesting, like, I found all this stuff really interesting. They talked about the batching,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=742" target="_blank">00:12:22.760</a></span> | <span class="t">GPU utilization, memory, like utilization, all that stuff. Like CUDA optimizations, their whole</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=750" target="_blank">00:12:30.600</a></span> | <span class="t">training recipe, what they released performance stuff. Instead, I feel like that's enough of a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=756" target="_blank">00:12:36.280</a></span> | <span class="t">high level overview of the paper. The more fun stuff is like, yeah, so how does it perform?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=761" target="_blank">00:12:41.800</a></span> | <span class="t">They're all better. Infra companies are pretty cheap. And this is also where like everyone else</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=766" target="_blank">00:12:46.440</a></span> | <span class="t">can hop into discussion. Eugene, Sean, other Eugene, hop in now. You know, Fireworks is somehow</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=773" target="_blank">00:12:53.480</a></span> | <span class="t">really undercutting inference price. The scale leaderboard is a held out leaderboard. It does</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=778" target="_blank">00:12:58.200</a></span> | <span class="t">pretty good here. What else? Grok has it. So some insider info for all the Infra companies,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=785" target="_blank">00:13:05.640</a></span> | <span class="t">they gave access to randomized weights that were the same size about six days before launch.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=792" target="_blank">00:13:12.040</a></span> | <span class="t">So six days ago, Infra companies started playing around with it. They started working out how</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=796" target="_blank">00:13:16.440</a></span> | <span class="t">they're going to do inference, what type of decoding they need. But they didn't have the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=799" target="_blank">00:13:19.720</a></span> | <span class="t">paper. They didn't have the actual weights. And then day of, they released weights. But like,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=803" target="_blank">00:13:23.960</a></span> | <span class="t">yeah, stuff like Grok is serving a thousand tokens per second. What other discussions that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=809" target="_blank">00:13:29.400</a></span> | <span class="t">we have here? Kyle did pretty good evals on performance. He started doing it on his own</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=817" target="_blank">00:13:37.000</a></span> | <span class="t">fine tuning stack. So he started fine tuning it, compared it to 4.0 mini. OpenAI within hours</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=823" target="_blank">00:13:43.880</a></span> | <span class="t">responded with like 4.0 mini fine tuning. But fine tuning the Lama 3.18b is kind of on par with</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=832" target="_blank">00:13:52.360</a></span> | <span class="t">4.0 mini. 4.0 mini fine tuning is kind of broken and free, but it gets worse.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=836" target="_blank">00:13:56.520</a></span> | <span class="t">What other fun stuff? There's a comparison of model pricing here that's being updated live.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=843" target="_blank">00:14:03.640</a></span> | <span class="t">Other tweets, George Hotz, Karpathy tweeted. VLLM supports it. Other more independent benchmarks</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=852" target="_blank">00:14:12.040</a></span> | <span class="t">coming in. Basically, it's good. The other interesting part was the licensing. So they</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=857" target="_blank">00:14:17.720</a></span> | <span class="t">changed up their Lama license to proper full open source everything. We have more infra providers,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=864" target="_blank">00:14:24.760</a></span> | <span class="t">NVIDIA stuff. But yeah, that's kind of where I feel like we should open it up. That's the quick</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=871" target="_blank">00:14:31.000</a></span> | <span class="t">15, 10 to 15 minute overview. Whatever people found interesting, like I know there was a lot</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=875" target="_blank">00:14:35.960</a></span> | <span class="t">of discussion about synthetic data gen. Sean and Eugene, you had good tweets about this. So I think</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=883" target="_blank">00:14:43.000</a></span> | <span class="t">this is where we open it up to whatever people found interesting. And then we dig into those</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=888" target="_blank">00:14:48.040</a></span> | <span class="t">topics because we're not getting through the rest of it. I'm going to open up chat and see what</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=893" target="_blank">00:14:53.400</a></span> | <span class="t">people are up to. But yeah, thoughts everyone. Hop in. Yeah, I wanted to jump in by the way.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=901" target="_blank">00:15:01.560</a></span> | <span class="t">One thing to warn about pricing is that you're going to see a lot of providers</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=910" target="_blank">00:15:10.120</a></span> | <span class="t">jumping in and everyone's just trying to get the piece of the pie. So like with some of the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=916" target="_blank">00:15:16.440</a></span> | <span class="t">previous model launches, you see people coming in at lower and lower price and then they'll</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=920" target="_blank">00:15:20.040</a></span> | <span class="t">increase later. But I wanted to jump in on the training side because I'm quite sure Mibu,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=925" target="_blank">00:15:25.800</a></span> | <span class="t">Eugene, and Ed will have lots to say on the data. So I think I'll start with that. I can't share</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=932" target="_blank">00:15:32.200</a></span> | <span class="t">the screen by the way. Do you want to take over or do you want me to scroll? I want to take over</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=938" target="_blank">00:15:38.120</a></span> | <span class="t">slightly because I want to jump through a few things there. So let me share my screen.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=945" target="_blank">00:15:45.960</a></span> | <span class="t">All right. So I didn't see too much talk about on this but for me, one of the big ones is actually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=959" target="_blank">00:15:59.880</a></span> | <span class="t">pipeline parallelism. Not sure how many people... Can you see my screen? Yes. Yeah. So if you're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=968" target="_blank">00:16:08.760</a></span> | <span class="t">looking at this and like what is this crazy freaking schedule that they are doing here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=973" target="_blank">00:16:13.560</a></span> | <span class="t">But TLDR, pipeline parallelism is generally the idea of scaling up your training across multiple</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=981" target="_blank">00:16:21.080</a></span> | <span class="t">GPUs and to build around optimizing that. That has its own benefits. It has also its own downsides.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=990" target="_blank">00:16:30.200</a></span> | <span class="t">And the major downside, the reason why people try to avoid pipeline parallelism at all costs</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=996" target="_blank">00:16:36.360</a></span> | <span class="t">and they use like DeepSpeed 3, for example, where the weights are sharded around all the other GPUs</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=1002" target="_blank">00:16:42.200</a></span> | <span class="t">is that if you look at pipeline parallelism or model parallelism, there's this problem called</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=1009" target="_blank">00:16:49.080</a></span> | <span class="t">the bubble. The bubble is basically as your data set goes through the different devices. So the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=1016" target="_blank">00:16:56.280</a></span> | <span class="t">forward pass and then the backwards pass, you have all this GPU time here where some of the GPUs are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=1022" target="_blank">00:17:02.280</a></span> | <span class="t">waiting for other GPUs and are doing nothing and basically you're wasting compute. And because</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=1027" target="_blank">00:17:07.960</a></span> | <span class="t">everyone wanted to avoid wasting compute, it went on to a search of the algorithm to figure out how</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=1036" target="_blank">00:17:16.440</a></span> | <span class="t">to do pipeline parallelism. And one major one is actually CLSG, coincidentally Singapore,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=1043" target="_blank">00:17:23.880</a></span> | <span class="t">where they created this crazy-ass algorithm to basically train without any wasted time. So you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=1050" target="_blank">00:17:30.760</a></span> | <span class="t">see the gray spots are with the wasted time, respectively. And Facebook is now embarking on</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=1056" target="_blank">00:17:36.440</a></span> | <span class="t">their own journey on this. And the reason why this is exciting even for smaller models is that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=1063" target="_blank">00:17:43.240</a></span> | <span class="t">this kind of algorithmic changes on the training is what's going to allow you to train bigger models</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=1070" target="_blank">00:17:50.520</a></span> | <span class="t">easier on lower-end GPUs. So this concept could apply to, let's say, training a 7TB model on 24GB</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=1078" target="_blank">00:17:58.680</a></span> | <span class="t">GPUs and things like that. And the reason why they probably need it for the 80GB is because</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=1084" target="_blank">00:18:04.040</a></span> | <span class="t">they're training 405B. And yeah, and a lot of people thought, like academia thought that this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=1091" target="_blank">00:18:11.240</a></span> | <span class="t">treated it as a dead end because of the bubble problem. And then Facebook was like, "You know</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=1097" target="_blank">00:18:17.720</a></span> | <span class="t">what? We are going to do that." And that, to me, is one of the more exciting things.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=1102" target="_blank">00:18:22.200</a></span> | <span class="t">The other one that I saw some people tweet out is about batch sizing being smaller,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=1107" target="_blank">00:18:27.800</a></span> | <span class="t">constraints on the batch size. I thought Google has pipeline parallelism in their</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=1112" target="_blank">00:18:32.440</a></span> | <span class="t">JAX, the distributed training repositories. They don't? Yeah, they do. They do. But the thing is,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=1119" target="_blank">00:18:39.000</a></span> | <span class="t">no offense to Google, no one really took, everyone just interpreted it as TPU has 2L VRAM.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=1125" target="_blank">00:18:45.480</a></span> | <span class="t">Kind of, kind of, kind of thing. And they had the basic pipeline parallel, but</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=1131" target="_blank">00:18:51.320</a></span> | <span class="t">we still suffered from the bubble problem. This weird scheduling, which I'm quite sure</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=1136" target="_blank">00:18:56.120</a></span> | <span class="t">people are going to start replicating it, is to reduce the bubble, the wastage.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=1140" target="_blank">00:19:00.760</a></span> | <span class="t">So I also saw lots of papers on this from maybe NVIDIA and Matej Zaharia from Berkeley or Stanford.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=1148" target="_blank">00:19:08.440</a></span> | <span class="t">Like they had lots of interleaved pipeline parallelism updates.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=1151" target="_blank">00:19:11.960</a></span> | <span class="t">Correct.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=1153" target="_blank">00:19:13.560</a></span> | <span class="t">So you're saying no one is using it? Just Facebook has used it more recently? I find that pretty...</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=1159" target="_blank">00:19:19.400</a></span> | <span class="t">Or at least no one published it within their training processes. Because this is the first</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=1165" target="_blank">00:19:25.320</a></span> | <span class="t">major model of this CL class size, right, that's saying, "Hey, we are doing pipeline parallelism."</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=1171" target="_blank">00:19:31.400</a></span> | <span class="t">Google models, so they have some, these pathways, distributed training architecture systems,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=1180" target="_blank">00:19:40.760</a></span> | <span class="t">and they publish in maybe OSDI, which is kind of the biggest distributed systems conference.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=1186" target="_blank">00:19:46.680</a></span> | <span class="t">So they publish these trainings and they can do all sorts of parallelism within their systems,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=1192" target="_blank">00:19:52.040</a></span> | <span class="t">and even a mixture of experts parallelism and stuff like that. So they do quite,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=1197" target="_blank">00:19:57.160</a></span> | <span class="t">quite heavy stuff. I'll look it up and post some papers if I find them in the messages. But yeah,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=1204" target="_blank">00:20:04.600</a></span> | <span class="t">my mental model was that people are actually doing this at scale.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=1210" target="_blank">00:20:10.760</a></span> | <span class="t">Thanks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=1211" target="_blank">00:20:11.240</a></span> | <span class="t">Yeah. So I'll draw the distinction between pipeline parallelism and techniques like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=1216" target="_blank">00:20:16.120</a></span> | <span class="t">DeepSpeedTree, which is essentially where the GPU has MVLink connectivity to other GPUs to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=1225" target="_blank">00:20:25.000</a></span> | <span class="t">actually read the model weights. Pipeline parallelism is really more of like, instead of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=1229" target="_blank">00:20:29.640</a></span> | <span class="t">going cross GPU to read the weights of the other models, or the other half of the model, you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=1236" target="_blank">00:20:36.040</a></span> | <span class="t">actually just focus on the half of the model that you're working on. And this has the trade-off,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=1244" target="_blank">00:20:44.200</a></span> | <span class="t">respectively, of saving VRAM and allowing you training larger model and larger batch size,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=1249" target="_blank">00:20:49.240</a></span> | <span class="t">but it means you have the bubble problem. And I think the focus is really more about the bubble</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=1254" target="_blank">00:20:54.680</a></span> | <span class="t">problem here, rather than anything else. And yeah, like I said, I do expect more people to replicate</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=1261" target="_blank">00:21:01.160</a></span> | <span class="t">this part. Yeah. So that's the part that I wanted to jump in on. The other major one I wanted to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=1267" target="_blank">00:21:07.400</a></span> | <span class="t">jump in on is just multilingual. I'm so happy that I've seen this. We try to avoid using machine</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=1274" target="_blank">00:21:14.760</a></span> | <span class="t">translated data to fine-tune the model. This is something that I think multiple people know that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=1280" target="_blank">00:21:20.760</a></span> | <span class="t">I've been shouting on the roof about saying, "Hey, can we stop using machine translated data for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=1285" target="_blank">00:21:25.160</a></span> | <span class="t">other languages?" And then assuming that's great, because when you speak to the other language,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=1290" target="_blank">00:21:30.600</a></span> | <span class="t">native speakers, they've been saying, "That sucks." And finally, someone is also, at least</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=1295" target="_blank">00:21:35.400</a></span> | <span class="t">on the bigger model side, is doing that as well. So particularly excited about that part. But yeah,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=1301" target="_blank">00:21:41.400</a></span> | <span class="t">I think I'll hand off to the whole data stream. The interesting little section there of translated</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=1306" target="_blank">00:21:46.680</a></span> | <span class="t">data is I've still seen it used where they have a Lama3 filter that extracts out what's the highest</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=1312" target="_blank">00:21:52.200</a></span> | <span class="t">quality data, what's the highest quality reasoning code data and whatnot. And in other work, they'll</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=1317" target="_blank">00:21:57.160</a></span> | <span class="t">still do... This is very traditional pre-training data set stuff where you need more data augmentation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=1322" target="_blank">00:22:02.760</a></span> | <span class="t">to get more high-quality data and translation. So one thing is you can train on multiple rounds of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=1328" target="_blank">00:22:08.760</a></span> | <span class="t">that. It's like more epochs on high-quality data. So you can just resample it. But then there was a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=1334" target="_blank">00:22:14.040</a></span> | <span class="t">paper that I'm forgetting that tested this. Do they want to only use a little bit? Do they want</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=1338" target="_blank">00:22:18.280</a></span> | <span class="t">to train on multiple rounds of pass-throughs of the same high-quality data? Or do they want to do</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=1343" target="_blank">00:22:23.080</a></span> | <span class="t">basic augmentation, like translate and translate back? And somehow translation to other languages</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=1348" target="_blank">00:22:28.520</a></span> | <span class="t">work better. That was the best option. Translating it to high-quality in another language as opposed</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=1354" target="_blank">00:22:34.120</a></span> | <span class="t">to translate and translate it back. So there's still some value, but interesting little piece.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=1359" target="_blank">00:22:39.560</a></span> | <span class="t">Yeah. So I think I want to hand off to the people who are going to tear all the data</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=1365" target="_blank">00:22:45.640</a></span> | <span class="t">parts into bits. Because I just wanted to jump in on trains. Because that's what I can uniquely offer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=1370" target="_blank">00:22:50.040</a></span> | <span class="t">>> Awesome. Appreciate that. I think Cameron has his hand up.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=1378" target="_blank">00:22:58.040</a></span> | <span class="t">>> Hey, did they make any claims around it being good for code generation?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=1385" target="_blank">00:23:05.240</a></span> | <span class="t">I'm interested in whether yes versus cloud. >> Yeah. This is a big contrast to Llama 2,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=1395" target="_blank">00:23:15.240</a></span> | <span class="t">where they were intentionally not training for code, and then they put out code Llama separately.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=1399" target="_blank">00:23:19.480</a></span> | <span class="t">Now they explicitly outline code as a separate modality, like separate from text.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=1405" target="_blank">00:23:25.000</a></span> | <span class="t">Vibhu, I don't know if you have a slide on this stuff. And then they also did synthetic</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=1410" target="_blank">00:23:30.120</a></span> | <span class="t">data for code as well. Yeah. They just -- they spent a lot more time on code this time around.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=1416" target="_blank">00:23:36.920</a></span> | <span class="t">>> Has anyone looked at it versus Cloud 3.5 Sonnet yet?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=1421" target="_blank">00:23:41.800</a></span> | <span class="t">>> We vibe checked it. We vibe checked it. >> They did what? Checked vibe?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=1428" target="_blank">00:23:48.760</a></span> | <span class="t">>> Yeah. So like, you know, it's not rigorous evals, but like we vibe checked it. And like,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=1435" target="_blank">00:23:55.160</a></span> | <span class="t">it does pretty good. So in the paper, they did explicitly mention as well, like, yeah,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=1440" target="_blank">00:24:00.040</a></span> | <span class="t">they used to have previous -- they used to have previous code Llama models, right? And part of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=1446" target="_blank">00:24:06.600</a></span> | <span class="t">their, like, second step of post-training was to add in this section on code. But they explicitly</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=1452" target="_blank">00:24:12.360</a></span> | <span class="t">no longer need to do that. And I'll pull up the section of the paper, basically. But they</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=1456" target="_blank">00:24:16.920</a></span> | <span class="t">mentioned that this is, like, natively trained in, in pre-training as well. But it's a good</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=1462" target="_blank">00:24:22.920</a></span> | <span class="t">code model. They also have a -- the -- >> There's a scale AI benchmark.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=1468" target="_blank">00:24:28.840</a></span> | <span class="t">>> Yeah. >> Jeremy, can you repeat?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=1472" target="_blank">00:24:32.040</a></span> | <span class="t">We can't hear you very well. >> Okay. Yeah. There's a scale AI</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=1475" target="_blank">00:24:35.720</a></span> | <span class="t">benchmark where Sonnet and 4.0 were compared against the new 4.0.5b model. And 4.5b was found</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=1485" target="_blank">00:24:45.080</a></span> | <span class="t">to be basically on par with GPT 4.0, which is worse than both Sonnet and GPT 4.0 turbo preview.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=1491" target="_blank">00:24:51.560</a></span> | <span class="t">There's a tweet thread and a comment that I'll just drop. But it outperforms Jem and I 1.5.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=1501" target="_blank">00:25:01.320</a></span> | <span class="t">The thing I like about the scale benchmarks is that they are pulled out. That is, like,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=1506" target="_blank">00:25:06.200</a></span> | <span class="t">none of the companies have access to them. And they're private. So, there's probably more</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=1511" target="_blank">00:25:11.560</a></span> | <span class="t">durability to the benchmarks. And they don't have as much of a conflict of interest. They</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=1515" target="_blank">00:25:15.960</a></span> | <span class="t">did co-watch with Lama. So, yeah. There may be a little bit of conflict of interest.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=1520" target="_blank">00:25:20.040</a></span> | <span class="t">>> Thank you. Thank you, Jeremy. >> So, overview, the scale --</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=1527" target="_blank">00:25:27.320</a></span> | <span class="t">>> Go ahead. >> Scale leaderboards aren't just coding. So,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=1532" target="_blank">00:25:32.360</a></span> | <span class="t">for people that don't know, it started out with the GSM 8K, where they tried to recreate it. And</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=1538" target="_blank">00:25:38.200</a></span> | <span class="t">they made a GSM 1K, which is meant to match the actual benchmark and just be a held out that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=1543" target="_blank">00:25:43.960</a></span> | <span class="t">they'll run models, they'll evaluate them. And then that turned into now they have held out</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=1548" target="_blank">00:25:48.520</a></span> | <span class="t">benchmarks that no one can see what the actual examples are of coding, instruction following,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=1553" target="_blank">00:25:53.720</a></span> | <span class="t">math, Spanish. There's a bunch of these. And, yeah, they're kind of, like, pretty good in the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=1558" target="_blank">00:25:58.360</a></span> | <span class="t">sense of, like, no one can directly train on them. There was a piece that said, like, when they put</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=1563" target="_blank">00:26:03.400</a></span> | <span class="t">out their first one, what's the delta between companies, like, models that do really well</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=1569" target="_blank">00:26:09.240</a></span> | <span class="t">on traditional, like, GSM 8K, but don't do well on 1K, where it's like they haven't seen it before.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=1575" target="_blank">00:26:15.000</a></span> | <span class="t">So, they basically tried to test who overfit to the benchmarks. And this is trying to solve that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=1580" target="_blank">00:26:20.840</a></span> | <span class="t">So, if we go through real quick, this is kind of where the 405B sits in coding. It's, like,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=1585" target="_blank">00:26:25.960</a></span> | <span class="t">a step right below QPT 4s and Sonnet. Sonnet's still slightly better. And then we can kind of go</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=1594" target="_blank">00:26:34.120</a></span> | <span class="t">through it. I think they're still testing the 405B, because I'm not seeing it through the rest</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=1599" target="_blank">00:26:39.160</a></span> | <span class="t">of them. But they're being updated in tweet threads and whatnot. And then Jeremy shared a link</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=1606" target="_blank">00:26:46.120</a></span> | <span class="t">to the Reddit that talks about this, where they're basically going through them. And then there's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=1611" target="_blank">00:26:51.560</a></span> | <span class="t">discussion here, if anyone's interested. But yeah. Someone was also talking in.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=1616" target="_blank">00:26:56.200</a></span> | <span class="t">>> Thanks very much. >> I have something to share. The</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=1622" target="_blank">00:27:02.680</a></span> | <span class="t">coding evaluation, it seems like they so there's I can't share my screen. But basically,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=1635" target="_blank">00:27:15.160</a></span> | <span class="t">human eval is kind of one second. Let me try and share it. Can you see? Yeah. So, human eval</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=1645" target="_blank">00:27:25.960</a></span> | <span class="t">is one of the benchmark data sets that people use to benchmark coding. And it's very simple.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=1652" target="_blank">00:27:32.680</a></span> | <span class="t">Like, they have 150 questions. And it's almost, like, autocomplete. Like, solve this simple</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=1657" target="_blank">00:27:37.480</a></span> | <span class="t">puzzle in Python or things like that. It's very, like, one, two lines. And you can see that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=1664" target="_blank">00:27:44.840</a></span> | <span class="t">let's see. So, the LLAMA405B is not state of the art. So, Cloud Sonnet beats it by a few</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=1672" target="_blank">00:27:52.920</a></span> | <span class="t">percentage points. It's close to the GPT and Sonnet models, but slightly worse. And I think</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=1680" target="_blank">00:28:00.680</a></span> | <span class="t">this kind of is similar to the vibe checks. My understanding was on the initial LLAMA,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=1686" target="_blank">00:28:06.600</a></span> | <span class="t">stuff that Meta didn't focus that much on reasoning or on code, because they're a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=1692" target="_blank">00:28:12.200</a></span> | <span class="t">social company. So, maybe reasoning is not as super important for them. But then they hacked</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=1697" target="_blank">00:28:17.960</a></span> | <span class="t">focused coding data collection session and shared a big code model. Which kind of wasn't that great.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=1707" target="_blank">00:28:27.640</a></span> | <span class="t">Maybe if you don't put the data in from the beginning, just trying to fine tune on code</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=1713" target="_blank">00:28:33.320</a></span> | <span class="t">by itself doesn't work that well. The other thing I wanted to share, can you see this other page?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=1722" target="_blank">00:28:42.200</a></span> | <span class="t">Now? Basically, it seems they spend quite a bit to make their coding much better in LLAMA3.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=1731" target="_blank">00:28:51.080</a></span> | <span class="t">And they actually train the code experts and then try to use that code experts to maybe,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=1740" target="_blank">00:29:00.280</a></span> | <span class="t">I guess, collect high quality human annotations and do some more post-training. And then they</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=1749" target="_blank">00:29:09.880</a></span> | <span class="t">also did some synthetic data generation to improve coding. So, I think they spent quite a bit to work</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=1758" target="_blank">00:29:18.280</a></span> | <span class="t">on reasoning and coding. I didn't read this section carefully, but yeah, they have a full</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=1761" target="_blank">00:29:21.800</a></span> | <span class="t">section on trying to get better code data to generate, to incorporate feedback and do analysis.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=1770" target="_blank">00:29:30.200</a></span> | <span class="t">They did quite a bit on coding. Yeah. >> Yeah. There's two sections there.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=1779" target="_blank">00:29:39.240</a></span> | <span class="t">One is the synthetic data gen with coding, and the other is the pre-trained mix of their code</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=1786" target="_blank">00:29:46.120</a></span> | <span class="t">and reasoning sample where they trained a second classifier. So, one of the takeaways there was</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=1793" target="_blank">00:29:53.160</a></span> | <span class="t">when you're doing pre-processing of 15 trillion tokens, you actually can't just run inference.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=1798" target="_blank">00:29:58.280</a></span> | <span class="t">Even Meta with all the GPUs they have, they couldn't afford to just throw LLAMA3 inference as</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=1805" target="_blank">00:30:05.320</a></span> | <span class="t">this whole 15 trillion token set. So, they trained a code and reasoning classifier on Distal-Roberta,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=1811" target="_blank">00:30:11.560</a></span> | <span class="t">which is a small original encoder-decoder transformer to try to annotate out their</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=1817" target="_blank">00:30:17.400</a></span> | <span class="t">web scrape data for quality and whatnot. So, they have it both there in the pre-training set and in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=1823" target="_blank">00:30:23.640</a></span> | <span class="t">the synthetic data gen. There's a really good quote tweet that went on about all this code gen.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=1830" target="_blank">00:30:30.440</a></span> | <span class="t">It's by Eugene. I will share screen and throw him on the stage if he wants to talk about it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=1837" target="_blank">00:30:37.400</a></span> | <span class="t">>> Yeah. Thank you. I'm currently commuting, but I'm finding a quiet space right now.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=1846" target="_blank">00:30:46.920</a></span> | <span class="t">All right. Great. Thank you, Vibhu. Yeah, I can talk to you, I think.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=1849" target="_blank">00:30:49.880</a></span> | <span class="t">Can you hear me fine? >> We can come to it in a few minutes.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=1852" target="_blank">00:30:52.920</a></span> | <span class="t">If you're commuting, we can come to it in a bit. >> No, I'll be commuting for a while. I'm walking</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=1858" target="_blank">00:30:58.040</a></span> | <span class="t">to the stadium right now, team event, but I'm finding a good space to sit. Okay. So, I think</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=1863" target="_blank">00:31:03.320</a></span> | <span class="t">what really stood out for me in this paper was that how much automation and augmentation was there,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=1869" target="_blank">00:31:09.240</a></span> | <span class="t">right? In the first one, you can see they actually use Lama2 to filter out bad data, right? And this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=1877" target="_blank">00:31:17.560</a></span> | <span class="t">is in the pre-training step. So, essentially, what they're saying is that, "Hey, we trust Lama2's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=1881" target="_blank">00:31:21.880</a></span> | <span class="t">judgment well enough to be able to do that." And if you scroll down, next slide.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=1886" target="_blank">00:31:26.840</a></span> | <span class="t">And then over here, you can see that they actually trust Lama3 to do tag intention. They actually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=1895" target="_blank">00:31:35.560</a></span> | <span class="t">tag the generated data or the responses based on intention, and they also classify things based on</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=1903" target="_blank">00:31:43.720</a></span> | <span class="t">difficulty, right? And the thing is, they actually adopt some kind of curriculum learning where they</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=1910" target="_blank">00:31:50.360</a></span> | <span class="t">start with a single shot prompt or rather a single turn prompt and response, and then after that,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=1916" target="_blank">00:31:56.520</a></span> | <span class="t">they move on to multi-turn. Next slide. And then after that, and this is a code expert that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=1925" target="_blank">00:32:05.640</a></span> | <span class="t">everyone's been talking about, right? So, what it means is that in order to get Lama good at code,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=1931" target="_blank">00:32:11.080</a></span> | <span class="t">as an intermediate step, they had to train a code model. And that sounds quite crazy, right? I mean,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=1939" target="_blank">00:32:19.320</a></span> | <span class="t">for me, I mean, sometimes training such large models just seems to take so much effort to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=1945" target="_blank">00:32:25.560</a></span> | <span class="t">curate the data, to set up the info and everything, but it seems completely essential in this case.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=1953" target="_blank">00:32:33.080</a></span> | <span class="t">They could not have done it without that. And Andrej Karpaty had a great tweet about this,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=1956" target="_blank">00:32:36.840</a></span> | <span class="t">whereby every model distillation and synthetic data generation is really now a stepping stone</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=1965" target="_blank">00:32:45.000</a></span> | <span class="t">for the next better model. Next, please. And then the same thing here is, okay, and of course,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=1972" target="_blank">00:32:52.760</a></span> | <span class="t">here, this is just an example of how much we trust the synthetic data, right? The model was prompted</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=1979" target="_blank">00:32:59.400</a></span> | <span class="t">to generate problems, then solve each problem, so I'm focusing only on the green highlights here,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=1984" target="_blank">00:33:04.440</a></span> | <span class="t">solve each problems, and then they give the model the errors, and then they ask the model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=1989" target="_blank">00:33:09.000</a></span> | <span class="t">to solve the errors, and then the model also generates the unit tests, which they then use</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=1993" target="_blank">00:33:13.240</a></span> | <span class="t">to evaluate the generations on the unit test itself. It's like, you see that the human is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=1999" target="_blank">00:33:19.160</a></span> | <span class="t">very minimally in the loop. And then if we move on, and you see this pattern everywhere, like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=2006" target="_blank">00:33:26.280</a></span> | <span class="t">multilingual, you didn't hear me talk about it. One thing that's interesting here is that they</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=2011" target="_blank">00:33:31.000</a></span> | <span class="t">generate, they use Lama to generate data for target capabilities, and then they back translate it into</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=2017" target="_blank">00:33:37.000</a></span> | <span class="t">doc strings and comments. So that's how they can teach the model to explain code. And then they</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=2023" target="_blank">00:33:43.000</a></span> | <span class="t">use those tweets and comments, those doc strings and comments to actually create code again. And</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=2027" target="_blank">00:33:47.800</a></span> | <span class="t">then we're going to go through the rest really quickly. It's like multilingual, the same pattern</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=2032" target="_blank">00:33:52.360</a></span> | <span class="t">here, math and reasoning, the next one, you see it's the same pattern, whereby the model actually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=2037" target="_blank">00:33:57.400</a></span> | <span class="t">augments the training data with the step-by-step. So one thing that's really interesting here,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=2042" target="_blank">00:34:02.040</a></span> | <span class="t">in the sense that they actually went the extra step, no pun intended, to actually train step-wise</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=2048" target="_blank">00:34:08.360</a></span> | <span class="t">reward models. That's kind of crazy, no? I mean, they wanted each step in the chain of thought to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=2054" target="_blank">00:34:14.440</a></span> | <span class="t">be so good that they actually took the extra effort to train step-wise reward models, which</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=2059" target="_blank">00:34:19.240</a></span> | <span class="t">they then combined with Monte Carlo Tree Search to improve the reasoning traces. And then you see</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=2065" target="_blank">00:34:25.880</a></span> | <span class="t">synthetic data for long context, it's the same pattern, Q&A. And then as you scroll down,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=2073" target="_blank">00:34:33.400</a></span> | <span class="t">you see synthetic data for image captioning and synthetic data for factuality. Like factuality,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=2079" target="_blank">00:34:39.800</a></span> | <span class="t">essentially all of it is just synthetic data, if you look at this. I think time will tell whether</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=2084" target="_blank">00:34:44.840</a></span> | <span class="t">this really works out well or not. I think we're still too early on the evals. And then you see</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=2089" target="_blank">00:34:49.160</a></span> | <span class="t">synthetic data for adversarial examples, synthetic data for the image encoder training, where they</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=2094" target="_blank">00:34:54.520</a></span> | <span class="t">use image captions, and then they augment as existing datasets with new instructions and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=2099" target="_blank">00:34:59.160</a></span> | <span class="t">responses. And what's really interesting here, the second last tweet, is that the human annotators</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=2105" target="_blank">00:35:05.960</a></span> | <span class="t">were actually augmented with model in the loop, right? And if you think about it, this slightly</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=2115" target="_blank">00:35:15.640</a></span> | <span class="t">represents a shift in how some folks are thinking about it, right? I mean, a lot of people is like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=2119" target="_blank">00:35:19.640</a></span> | <span class="t">thinking human in the loop, but no, now it's model in the loop, whereby you use the model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=2127" target="_blank">00:35:27.720</a></span> | <span class="t">to create an initial generation that the human then can edit, and it just makes it so easy for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=2132" target="_blank">00:35:32.760</a></span> | <span class="t">the human, right? And then the one big takeaway from all of this, and that's what I had from this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=2139" target="_blank">00:35:39.160</a></span> | <span class="t">paper, but the one big takeaway from all of this is that, can you imagine how much META had to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=2147" target="_blank">00:35:47.240</a></span> | <span class="t">educate and upskill their SDEs or their existing scientists to use this new technology to be</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=2153" target="_blank">00:35:53.480</a></span> | <span class="t">trusting of it, and the annotators to trust the new technology and to just work based on that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=2159" target="_blank">00:35:59.080</a></span> | <span class="t">So that was quite eye-opening for me, and I think it sort of suggests the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=2162" target="_blank">00:36:02.840</a></span> | <span class="t">long-term, here's where the puck is heading. And that's all I had. Thank you.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=2167" target="_blank">00:36:07.880</a></span> | <span class="t">Awesome. Thank you, Vips.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=2171" target="_blank">00:36:11.400</a></span> | <span class="t">Eugene coming in clutch with, I threw him on the spot, he's commuting and already had</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=2175" target="_blank">00:36:15.800</a></span> | <span class="t">slides and tweet thread. But yeah, what other topics have we got? I've got the chat.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=2182" target="_blank">00:36:22.760</a></span> | <span class="t">Did they mention using chain of verification prompting, Eugene?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=2189" target="_blank">00:36:29.800</a></span> | <span class="t">Do you mean chain of thought prompting or chain of verification where they try to verify the chain?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=2199" target="_blank">00:36:39.320</a></span> | <span class="t">The latter.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=2201" target="_blank">00:36:41.400</a></span> | <span class="t">Okay, I don't think they actually did that, but they did mention they had stepwise reward models</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=2208" target="_blank">00:36:48.040</a></span> | <span class="t">that actually checks every step in the chain of thought. But I don't recall</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=2213" target="_blank">00:36:53.720</a></span> | <span class="t">seeing chain of verification. Sorry.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=2215" target="_blank">00:36:55.800</a></span> | <span class="t">Okay, thank you.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=2217" target="_blank">00:36:57.320</a></span> | <span class="t">Welcome.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=2218" target="_blank">00:36:58.860</a></span> | <span class="t">Eugene, like early last year, there was tree of thought and some iterations with Monte Carlo</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=2227" target="_blank">00:37:07.240</a></span> | <span class="t">search and this tree of thought stuff. But at that point, LLMs weren't good enough to verify</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=2235" target="_blank">00:37:15.160</a></span> | <span class="t">or provide enough signal for this multi-step reasoning things to happen and things in the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=2240" target="_blank">00:37:20.040</a></span> | <span class="t">loop. Do you know, do you have some idea how they solved it or why they were able to make all this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=2245" target="_blank">00:37:25.400</a></span> | <span class="t">progress? Basically use all the tricks we were reading about maybe half a year, a year ago,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=2250" target="_blank">00:37:30.840</a></span> | <span class="t">but it seems they actually got them to work. So yeah, I wonder what made it work.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=2256" target="_blank">00:37:36.600</a></span> | <span class="t">Yeah, I don't know. I'm very interesting. I'm very curious about that as well. I wish there</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=2261" target="_blank">00:37:41.480</a></span> | <span class="t">was more papers showing how to use Monte Carlo tree search and actually get it to work and share</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=2267" target="_blank">00:37:47.880</a></span> | <span class="t">more details about it. I'm afraid I haven't seen too much of that in this current paper.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=2271" target="_blank">00:37:51.720</a></span> | <span class="t">Is it mostly for coding that they employed this or for other tasks as well? Because for coding,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=2278" target="_blank">00:37:58.440</a></span> | <span class="t">you could signal back some reward, but for other things, like I don't know how you evaluate things</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=2283" target="_blank">00:38:03.720</a></span> | <span class="t">and propagate information and validate the chains of that. Yeah, if I recall correctly,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=2290" target="_blank">00:38:10.360</a></span> | <span class="t">it was actually in the math and reasoning section. So whereby they actually use stepwise</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=2295" target="_blank">00:38:15.640</a></span> | <span class="t">reward models to evaluate each step, to score each step in the chain of thoughts,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=2299" target="_blank">00:38:19.480</a></span> | <span class="t">so that the final output gets better.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=2303" target="_blank">00:38:23.640</a></span> | <span class="t">Thank you. I'll look into it more. Yeah, it's the math. Lightman et al was the citation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=2317" target="_blank">00:38:37.400</a></span> | <span class="t">And I guess I'll wrap up with one final thing. I'm sorry, it's a bit noisy. I think</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=2322" target="_blank">00:38:42.200</a></span> | <span class="t">Switzer's Latent Space podcast with Thomas, he really goes really deep and he has a strong</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=2330" target="_blank">00:38:50.920</a></span> | <span class="t">opinion on synthetic data. I think listening to that podcast will give you a lot more insight</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=2336" target="_blank">00:38:56.120</a></span> | <span class="t">into how meta is really embracing synthetic data. So I found that podcast quite helpful.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=2344" target="_blank">00:39:04.680</a></span> | <span class="t">And this was the Karpathy tweet about synthetic data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=2349" target="_blank">00:39:09.960</a></span> | <span class="t">Also, yeah, great podcast. I think that's the one. Exactly, wait a minute,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=2360" target="_blank">00:39:20.680</a></span> | <span class="t">I think that one thing in the sense that everything is a step for the next one.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=2366" target="_blank">00:39:26.120</a></span> | <span class="t">No, not this one. It was actually a tweet about smaller models,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=2373" target="_blank">00:39:33.080</a></span> | <span class="t">about how the competition for smaller models is going backwards, but buried in there.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=2377" target="_blank">00:39:37.240</a></span> | <span class="t">If you scroll down a little bit more. Yeah, this one. Yeah, exactly. You can see the models have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=2385" target="_blank">00:39:45.320</a></span> | <span class="t">to first get larger before they get smaller, right? And the three-line paragraph. And then</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=2391" target="_blank">00:39:51.480</a></span> | <span class="t">it's a staircase of improvement where one model helping to generate training data for the next.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=2395" target="_blank">00:39:55.640</a></span> | <span class="t">It's almost like he had read this paper up front and he was alluding to that. I don't know.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=2401" target="_blank">00:40:01.320</a></span> | <span class="t">Yeah, it's pretty interesting to see. Also, this was a tweet that came out even before,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=2406" target="_blank">00:40:06.200</a></span> | <span class="t">but very much the small model distillation work, it's pretty huge. And that's, I think,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=2411" target="_blank">00:40:11.640</a></span> | <span class="t">the big part of the license play of this too, where they did actually finally change their</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=2417" target="_blank">00:40:17.000</a></span> | <span class="t">license to allow people to generate synthetic data, train on outputs of the 405B. I think the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=2423" target="_blank">00:40:23.480</a></span> | <span class="t">405B is a little overhyped for just using it for inference. When it comes to inference</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=2428" target="_blank">00:40:28.520</a></span> | <span class="t">generation and cost-effectiveness, make sure if experts are pretty efficient. They use less RAM</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=2436" target="_blank">00:40:36.520</a></span> | <span class="t">at inference time and they're more cost-effective for just the best quality. But then this is really</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=2443" target="_blank">00:40:43.400</a></span> | <span class="t">valuable for synthetic data gen, for filtering, stuff like that. And that's what I see more of it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=2449" target="_blank">00:40:49.080</a></span> | <span class="t">I know, Sean Swicks, you also had a pretty good write-up about this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=2456" target="_blank">00:40:56.920</a></span> | <span class="t">Sorry about that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=2458" target="_blank">00:40:58.920</a></span> | <span class="t">Or any other about how this is a synthetic data gen model or any other topics we want to dive</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=2465" target="_blank">00:41:05.480</a></span> | <span class="t">into. Also open to everyone else that's in the call too. If anyone had anything interesting that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=2470" target="_blank">00:41:10.600</a></span> | <span class="t">they want to dive into on the paper, pop in, share your thoughts.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=2473" target="_blank">00:41:13.480</a></span> | <span class="t">I think Sachin's hand has been raised up for quite some time.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=2477" target="_blank">00:41:17.480</a></span> | <span class="t">Yeah, Sachin, go ahead.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=2478" target="_blank">00:41:18.360</a></span> | <span class="t">Yeah, so this is for Eugene and Vibhu also. So we saw SONET actually take over some time back.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=2487" target="_blank">00:41:27.240</a></span> | <span class="t">And there's still some, what do you call, gap to cover. So does SONET have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=2491" target="_blank">00:41:31.240</a></span> | <span class="t">some other tricks in their back which is getting them that higher up?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=2495" target="_blank">00:41:35.240</a></span> | <span class="t">I know someone's working on a write-up about this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=2502" target="_blank">00:41:42.920</a></span> | <span class="t">No, no, no. I abandoned the idea. Yeah, so they never published anything about</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=2512" target="_blank">00:41:52.840</a></span> | <span class="t">what tricks they use. But the evidence strongly points to the fact that they use the steering</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=2517" target="_blank">00:41:57.240</a></span> | <span class="t">vectors that they had from the scaling monosemanticity paper. The main evidence is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=2524" target="_blank">00:42:04.760</a></span> | <span class="t">that they happened to do this monosemanticity research on SONET.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=2533" target="_blank">00:42:13.080</a></span> | <span class="t">What are you guys doing, you little freaks?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=2533" target="_blank">00:42:13.880</a></span> | <span class="t">SJ is constantly screwing up his mic. They did it on SONET and obviously they only shipped</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=2541" target="_blank">00:42:21.640</a></span> | <span class="t">3.5 SONET. That's like the smoking gun. If they actually had anything else, any other trick</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=2548" target="_blank">00:42:28.440</a></span> | <span class="t">that caused 3.5 SONET to be so good, they probably would have deployed it on Haiku and Opus as well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=2555" target="_blank">00:42:35.560</a></span> | <span class="t">The fact that they don't is proof positive that it's basically the monosemanticity stuff.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=2560" target="_blank">00:42:40.520</a></span> | <span class="t">Does that answer your question? Do I need to explain what that is?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=2563" target="_blank">00:42:43.240</a></span> | <span class="t">I have a hard time.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=2565" target="_blank">00:42:45.240</a></span> | <span class="t">No, it does.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=2565" target="_blank">00:42:45.740</a></span> | <span class="t">I think it's not. I think it's not control vectors.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=2570" target="_blank">00:42:50.920</a></span> | <span class="t">Yeah, why?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=2573" target="_blank">00:42:53.000</a></span> | <span class="t">They could be. They did say it's a larger model. If you look at the training data and the training</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=2578" target="_blank">00:42:58.520</a></span> | <span class="t">date for when Cloud 3 SONET came out to 3.5 SONET, it also has a year and a half of significant data</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=2585" target="_blank">00:43:05.320</a></span> | <span class="t">updates. I think that there was a lot of research that put out on high-quality synthetic data,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=2590" target="_blank">00:43:10.360</a></span> | <span class="t">the post-training mixture of it. SONET probably just had a decent bit of... There's a lot more</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=2597" target="_blank">00:43:17.320</a></span> | <span class="t">that they could squeeze out of it. Also, they did say it's bigger. A lot more research and good</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=2604" target="_blank">00:43:24.280</a></span> | <span class="t">quality synthetic data, the pre-training data mixture started to come out. It's bigger. I think</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=2610" target="_blank">00:43:30.920</a></span> | <span class="t">it was just a lot more post-training as well, because there was quite a bit of time...</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=2615" target="_blank">00:43:35.800</a></span> | <span class="t">In post-training, there's a... Sorry, Vibhu. In post-training, in SONET, you can see there's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=2621" target="_blank">00:43:41.080</a></span> | <span class="t">this pause, thinking pause tokens, where sometimes it generates a token and it does internal thinking</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=2627" target="_blank">00:43:47.240</a></span> | <span class="t">and then generates the answer. It seems like they used some recent tricks where people say, "Hey,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=2633" target="_blank">00:43:53.640</a></span> | <span class="t">you need to think step-by-step, but maybe not materialize directly in the answer, the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=2638" target="_blank">00:43:58.520</a></span> | <span class="t">step-by-step thinking." Sometimes when you run SONET generations, you can see there's some...</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=2645" target="_blank">00:44:05.160</a></span> | <span class="t">It stops in the middle and people saw that those are actually pause for thinking and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=2651" target="_blank">00:44:11.080</a></span> | <span class="t">side thoughts. It seems that really helps with reasoning tasks quite a bit. That's one additional</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=2658" target="_blank">00:44:18.840</a></span> | <span class="t">trick that they use. I agree that it's been one year of work, so they probably have lots of tricks</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=2666" target="_blank">00:44:26.200</a></span> | <span class="t">in there, not just one, two, three. Much like in the Lama paper, you'll see that it's hundreds and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=2672" target="_blank">00:44:32.120</a></span> | <span class="t">hundreds of people, still less than a thousand, but yeah, it's like a Manhattan project to build</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=2677" target="_blank">00:44:37.880</a></span> | <span class="t">one of these things. I actually counted the number of people. Lama 3 had 200 core contributors,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=2683" target="_blank">00:44:43.960</a></span> | <span class="t">which is good. It's pretty small. It's less than Gemini, which had 950.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=2689" target="_blank">00:44:49.080</a></span> | <span class="t">Sebastian says, "What does thinking mean?" Okay, here's where we get philosophical.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=2701" target="_blank">00:45:01.480</a></span> | <span class="t">My quick take on that is this used to be a thing with the original ChatGPT web UI stuff of why is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=2707" target="_blank">00:45:07.880</a></span> | <span class="t">it pausing at stuff. I think some of this is also just the way the API works. What's the inference</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=2714" target="_blank">00:45:14.120</a></span> | <span class="t">it's running on? How's the streaming? What's the API service like? Sometimes when there's blocks,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=2719" target="_blank">00:45:19.240</a></span> | <span class="t">it's not that something else is going on. It's just that there's a delayed stream of your API</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=2723" target="_blank">00:45:23.640</a></span> | <span class="t">response and sometimes people overanalyze that. Is it that it's thinking? Is it what's going on?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=2729" target="_blank">00:45:29.560</a></span> | <span class="t">Maybe, maybe not. I think for the Sonnet's case that some users have already used, I guess,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=2738" target="_blank">00:45:38.440</a></span> | <span class="t">prompt injection to trick it into instead of doing the XML thinking block and to use it to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=2743" target="_blank">00:45:43.640</a></span> | <span class="t">output it in a different format, then you literally get to see the thinking process.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=2748" target="_blank">00:45:48.120</a></span> | <span class="t">Yeah, so for what it's worth, I went to iClear and interviewed the pause token author. It's on</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=2758" target="_blank">00:45:58.040</a></span> | <span class="t">the iClear episode if people want to check it out. I do not think that Cloud specifically</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=2763" target="_blank">00:46:03.640</a></span> | <span class="t">implemented that version of thinking. I think it's much simpler. It is just chain of thought. It is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=2768" target="_blank">00:46:08.680</a></span> | <span class="t">just prompted XML chain of thought that is then subsequently post-processed and removed inside</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=2774" target="_blank">00:46:14.920</a></span> | <span class="t">of Cloud Artifacts. Yeah, but it's still a form of thinking. It's a form of chain of thought.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=2780" target="_blank">00:46:20.520</a></span> | <span class="t">It definitely improves the performance. Right. Sorry. Yeah, that's what I was aware of.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=2787" target="_blank">00:46:27.000</a></span> | <span class="t">I'm sorry. I missed what Eugene mentioned for an alternative to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=2790" target="_blank">00:46:30.680</a></span> | <span class="t">what you described as a chain of thought that is not presented to the user.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=2794" target="_blank">00:46:34.520</a></span> | <span class="t">Eugene? Yeah, so instead of creating a custom token, which is the pause token concept,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=2805" target="_blank">00:46:45.320</a></span> | <span class="t">they literally just got the model through prompting, got the model to reply with a thinking</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=2810" target="_blank">00:46:50.920</a></span> | <span class="t">XML block, which then you can trick it through prompt engineering to substitute the tokens</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=2815" target="_blank">00:46:55.400</a></span> | <span class="t">respectively. Then suddenly this technique becomes very blatant when you get to see it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=2820" target="_blank">00:47:00.840</a></span> | <span class="t">respectively because it's no longer hidden from the UI. Yeah, I think also on a separate line,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=2827" target="_blank">00:47:07.880</a></span> | <span class="t">because since a lot of people are looking to the eval and then they're like, "Hey, some of these</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=2831" target="_blank">00:47:11.800</a></span> | <span class="t">evals are doing worse than, let's say, 4.0," or things like that, the fact that it's already</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=2837" target="_blank">00:47:17.640</a></span> | <span class="t">closed itself means that if you're just a few weeks away until every single benchmark, you're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=2844" target="_blank">00:47:24.520</a></span> | <span class="t">going to see a point jump because someone fine-tuned a code-specific version of the L3 model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=2851" target="_blank">00:47:31.480</a></span> | <span class="t">or a medical reasoning-specific version of this model. It's going to take slower than normal</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=2859" target="_blank">00:47:39.400</a></span> | <span class="t">because I spoke to some people in the fine-tuning community. The biggest hurdle has been, "What do</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=2865" target="_blank">00:47:45.080</a></span> | <span class="t">you mean you need at least three nodes of H100 to start the process?" Yeah, the amount of VRAM</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=2871" target="_blank">00:47:51.960</a></span> | <span class="t">requirement is kind of huge. I suspect we are going to see more Loras first before we get</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=2876" target="_blank">00:47:56.680</a></span> | <span class="t">full fine-tunes. Also, the most random part, I know Meta did this for good reasons because</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=2884" target="_blank">00:48:04.280</a></span> | <span class="t">they basically did a lot of no-keyword filtering from the sources, but a lot of people in the AI</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=2890" target="_blank">00:48:10.760</a></span> | <span class="t">companion space, they were like, "No!" basically. Yeah, it makes sense. I'm going to look into that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=2900" target="_blank">00:48:20.120</a></span> | <span class="t">Thanks. Do we have more things on the paper? I mean, there's more to discuss. I feel like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=2911" target="_blank">00:48:31.560</a></span> | <span class="t">everyone's being too polite. There's a lot of new scaling laws they brought up. They had a whole</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=2918" target="_blank">00:48:38.280</a></span> | <span class="t">recipe for post-training, how they did it, how they did their SFT, how they did... They also</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=2924" target="_blank">00:48:44.040</a></span> | <span class="t">released both the base and the instruct models, how much of this was done by synthetic data, how</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=2931" target="_blank">00:48:51.000</a></span> | <span class="t">they train their image video adapters, all that stuff for multilingual stuff. They give out a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=2936" target="_blank">00:48:56.520</a></span> | <span class="t">whole recipe on how to do this. It's a long, long read, but for anyone that hasn't read a lot of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=2942" target="_blank">00:49:02.760</a></span> | <span class="t">papers, this is also probably a really good one that's very approachable, very readable,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=2947" target="_blank">00:49:07.640</a></span> | <span class="t">and not too crazy technical, one to at least understand what's going on. They go into some</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=2953" target="_blank">00:49:13.320</a></span> | <span class="t">of their evals on their multimodality, how their adapters work, how it performs, and they're like,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=2958" target="_blank">00:49:18.680</a></span> | <span class="t">"Yeah, it's pretty good." They added speech into speech understanding, how to train a speech</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=2964" target="_blank">00:49:24.760</a></span> | <span class="t">encoder, how many hours of recording they used, how they filtered it. They go through literally</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=2971" target="_blank">00:49:31.160</a></span> | <span class="t">all of this. This is probably where you could have an hour on this paper. That's every step</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=2976" target="_blank">00:49:36.920</a></span> | <span class="t">of it. But it's an interesting one where, yeah, they do go into all that data set,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=2981" target="_blank">00:49:41.640</a></span> | <span class="t">how they transcribed it, just little, little stuff too. In their speech understanding section,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=2987" target="_blank">00:49:47.240</a></span> | <span class="t">there's a section on, "Our ASR training data contains 230,000 hours of manually transcribed</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=2995" target="_blank">00:49:55.080</a></span> | <span class="t">screech recording that spans 34 languages." Just a little one line of, "We casually manually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=3003" target="_blank">00:50:03.000</a></span> | <span class="t">transcribed 230,000 hours of 34 languages of speech, and we're just training a little adapter</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=3009" target="_blank">00:50:09.800</a></span> | <span class="t">for this that we're not releasing." They put a lot of work into that. Then it goes even deeper</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=3015" target="_blank">00:50:15.240</a></span> | <span class="t">into, "How do you use this for pre-training? What about spoken dialogue? How do we fine-tune?"</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=3021" target="_blank">00:50:21.400</a></span> | <span class="t">What's the recipe for a speech adapter in an LLM? Yeah, we did a lot of pre-processing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=3027" target="_blank">00:50:27.160</a></span> | <span class="t">to the base data set of manually transcribe a lot of speech recording, have multi-languages,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=3032" target="_blank">00:50:32.520</a></span> | <span class="t">train it out. Here's the speech length segments that we want. Then we fine-tune this adapter for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=3039" target="_blank">00:50:39.400</a></span> | <span class="t">spoken dialect. How do we do that? Well, we synthetically generate responses for prompt.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=3044" target="_blank">00:50:44.760</a></span> | <span class="t">We ask for transcripts. We generate them. They generate 25,000 hours of speech synthesis through</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=3052" target="_blank">00:50:52.360</a></span> | <span class="t">voice box, which is a whole other series that Meta has put out around everything,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=3057" target="_blank">00:50:57.560</a></span> | <span class="t">how they do voice generation. They have a whole really good breakdown paper of that, how they use</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=3067" target="_blank">00:51:07.800</a></span> | <span class="t">that to generate model, to fine-tune, and generate synthetic data for this. There's a lot in here,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=3073" target="_blank">00:51:13.160</a></span> | <span class="t">if anyone's interested in. A lot of that doesn't make it to Twitter, but dig in, present it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=3079" target="_blank">00:51:19.640</a></span> | <span class="t">Architecture stayed the same. I thought the interesting parts were also just like,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=3090" target="_blank">00:51:30.840</a></span> | <span class="t">they want to keep it very foundational and see what works and what they can just scale up.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=3097" target="_blank">00:51:37.400</a></span> | <span class="t">The second aspect of that is it'll be fun to see when they start cooking with actual MOEs,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=3103" target="_blank">00:51:43.880</a></span> | <span class="t">how do we go outside the box. It's nice to have clarity on their scaling laws. I've definitely</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=3113" target="_blank">00:51:53.480</a></span> | <span class="t">presented too many times that they just scaled up and prayed, and they took an AP to 15 trillion,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=3118" target="_blank">00:51:58.120</a></span> | <span class="t">and they were very inefficient. Other papers, like 5.3 took a big shot at this. 5.3's whole</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=3124" target="_blank">00:52:04.680</a></span> | <span class="t">paper is about how we had Chinchilla scaling. Then we have this inference optimal Lama scaling,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=3131" target="_blank">00:52:11.640</a></span> | <span class="t">and then here's how you could do what we think is right. Now, Lama puts out a paper and they're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=3137" target="_blank">00:52:17.240</a></span> | <span class="t">like, "No, this is actually all based. Here's new scaling that's not just next token prediction.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=3141" target="_blank">00:52:21.960</a></span> | <span class="t">It's grounded on reasoning. Here's how scaling laws work. Here's how you can use it. Here's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=3146" target="_blank">00:52:26.680</a></span> | <span class="t">why we did it." It's going to make sense. The scaling part, I found it interesting and funny</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=3154" target="_blank">00:52:34.200</a></span> | <span class="t">that they were using ARK as a measurement for the scaling training. One of the realistic that I had</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=3161" target="_blank">00:52:41.480</a></span> | <span class="t">in my head, it was like, "So Facebook spent over $100 million at the ARK challenge to try to win</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=3166" target="_blank">00:52:46.760</a></span> | <span class="t">the million-dollar prize." I think it's a different ARK, right? If I'm not mistaken. It's not the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=3172" target="_blank">00:52:52.840</a></span> | <span class="t">same as the million-dollar. It's not the same data set. Yeah, but it's still in the line.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=3183" target="_blank">00:53:03.240</a></span> | <span class="t">Yeah, a lot of good stuff. In the five to seven minutes we have left, I wanted to give some time</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=3189" target="_blank">00:53:09.560</a></span> | <span class="t">to, I guess, Hassan. Hassan's actually built an app that's kind of cool with Lama3U.1. Maybe</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=3197" target="_blank">00:53:17.720</a></span> | <span class="t">there's something to learn about prompting it, building with it, anything surprising.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=3202" target="_blank">00:53:22.680</a></span> | <span class="t">Yeah, thanks, Sean. Hey, everybody. I just want to talk about this app that I built real quick.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=3210" target="_blank">00:53:30.760</a></span> | <span class="t">Definitely a lot less technical than we're talking right now. This is dropping all the way down to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=3215" target="_blank">00:53:35.960</a></span> | <span class="t">the half layer. I guess it is all about building, but I just built this little app. It uses a search</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=3224" target="_blank">00:53:44.600</a></span> | <span class="t">API to put in whatever topic you want to learn about, like quantization, and it can explain it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=3230" target="_blank">00:53:50.120</a></span> | <span class="t">to you at kind of any level you want. So, let's learn about quantization at an elementary level.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=3235" target="_blank">00:53:55.080</a></span> | <span class="t">So, it will basically use a search API, grab all these sources, and put it into context,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=3239" target="_blank">00:53:59.240</a></span> | <span class="t">because obviously Lama3.1, larger context, you can fit in a lot of stuff, which is great.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=3243" target="_blank">00:54:03.480</a></span> | <span class="t">And I've noticed that it's pretty good at kind of dumbing down concepts, but also</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=3248" target="_blank">00:54:08.600</a></span> | <span class="t">responding to the prompts a little bit better. And almost responding, like if I set a system</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=3255" target="_blank">00:54:15.400</a></span> | <span class="t">prompt that kind of details how it should behave over the next few messages, I found that it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=3261" target="_blank">00:54:21.080</a></span> | <span class="t">responds a little bit better. Like, for example, for this system prompt, I had, like, make sure</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=3266" target="_blank">00:54:26.600</a></span> | <span class="t">you make the overview really short, because when I was testing on just Lama3 and on other platforms,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=3273" target="_blank">00:54:33.160</a></span> | <span class="t">it was giving me a really, really long initial answer. And so, I want it to give a really short</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=3278" target="_blank">00:54:38.920</a></span> | <span class="t">overview, but at the same time, I want it to be detailed in the future. And I also want it to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=3281" target="_blank">00:54:41.960</a></span> | <span class="t">include quizzes at certain times. And so, I just found that it's a little bit -- it was a little</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=3286" target="_blank">00:54:46.440</a></span> | <span class="t">bit smoother at kind of -- at responding. So, yeah, here it's going to, you know, actually try</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=3292" target="_blank">00:54:52.440</a></span> | <span class="t">to give me a quiz and try to just be interactive and kind of teach me a subject at any level that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=3298" target="_blank">00:54:58.680</a></span> | <span class="t">I want. So, it's fully open source. LamaTutor.com, it's definitely open source. I misspelled this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=3309" target="_blank">00:55:09.400</a></span> | <span class="t">>> Did it give an example of quantization math?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=3312" target="_blank">00:55:12.600</a></span> | <span class="t">>> I don't actually know over here. I think it's talking about --</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=3318" target="_blank">00:55:18.760</a></span> | <span class="t">>> I just got into a debate on a call where someone was making an obvious error in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=3323" target="_blank">00:55:23.720</a></span> | <span class="t">quantization math and how much the memory before versus after. I can send this to them.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=3331" target="_blank">00:55:31.480</a></span> | <span class="t">>> I'm not sure if it'll -- I know it does formulas as well, yeah, so it'll put some -- I</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=3335" target="_blank">00:55:35.160</a></span> | <span class="t">should probably format these a little bit nicer. >> That's awesome, though.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=3338" target="_blank">00:55:38.760</a></span> | <span class="t">>> Yeah, thank you. It has -- yeah, I got about 4,000 visitors, and if anybody's curious about</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=3345" target="_blank">00:55:45.880</a></span> | <span class="t">cost as well, so about 6,400 requests. I had some errors because I was playing around with -- I was</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=3352" target="_blank">00:55:52.280</a></span> | <span class="t">hitting the context limit and a bunch of other stuff. And also, you know, using the together API.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=3357" target="_blank">00:55:57.160</a></span> | <span class="t">Very biased. I work over it together. But the cost for anybody curious, so we have about 12,000</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=3364" target="_blank">00:56:04.920</a></span> | <span class="t">average tokens per request. We have about 5,900 successful tokens. And so if you do the math,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=3370" target="_blank">00:56:10.200</a></span> | <span class="t">that's like 74 million tokens. And if I go over to our pricing, right now we're at 18 cents</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=3377" target="_blank">00:56:17.240</a></span> | <span class="t">per million tokens for 8b 3.1. So that comes out to about $12 from the 72 million tokens that I</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=3385" target="_blank">00:56:25.400</a></span> | <span class="t">used in the last 24 hours from these 4,000 people and 6,000 requests. So that's all I have.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=3392" target="_blank">00:56:32.680</a></span> | <span class="t">>> And so, wait. Wait. Can you show -- did you put a link in the chat? Or can you type --</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=3401" target="_blank">00:56:41.200</a></span> | <span class="t">>> No, I'll do that. Yes, I'll put in a link to the LamaTutor.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=3407" target="_blank">00:56:47.000</a></span> | <span class="t">>> Oh, LamaTutor, okay. >> HassanLamaTutor.com.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=3410" target="_blank">00:56:50.280</a></span> | <span class="t">>> Hassan, I have a question at a high level. Is this using some sort of, like,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=3422" target="_blank">00:57:02.440</a></span> | <span class="t">have you ever used the GPT's actions? Is it using a system similar to that?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=3425" target="_blank">00:57:05.960</a></span> | <span class="t">>> I actually haven't used actions. Can you tell me about that?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=3429" target="_blank">00:57:09.800</a></span> | <span class="t">>> So actions is where you input an API spec and the model itself can make the calls -- the model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=3437" target="_blank">00:57:17.640</a></span> | <span class="t">itself can decide to make the calls to that API, provided that API spec.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=3441" target="_blank">00:57:21.640</a></span> | <span class="t">>> Oh, so like function calling, basically. >> Yes.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=3445" target="_blank">00:57:25.960</a></span> | <span class="t">>> No, I'm not using -- yes, I'm not using it on this app. This was, like,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=3451" target="_blank">00:57:31.640</a></span> | <span class="t">the most simple example I could do, where I give it a system prompt, I do this API call for search,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=3456" target="_blank">00:57:36.920</a></span> | <span class="t">I parse all the sources, and I just drop everything. And I'm like, hey, build something</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=3461" target="_blank">00:57:41.000</a></span> | <span class="t">interactive. So this is kind of step one. There's obviously so much more I want to do. I want to try</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=3465" target="_blank">00:57:45.480</a></span> | <span class="t">to do generative UI, maybe, with the Versalia ISDK, where I show -- for the quiz example,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=3472" target="_blank">00:57:52.200</a></span> | <span class="t">I show an actual quiz component that renders. I can, like, generate a little, like, report out</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=3478" target="_blank">00:57:58.840</a></span> | <span class="t">of all the sources and have, like, read this, you know, like, you can read this to check it out, or</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=3484" target="_blank">00:58:04.360</a></span> | <span class="t">flashcards, or, like, I feel like there's a lot of directions to go with it, but I kind of just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=3488" target="_blank">00:58:08.040</a></span> | <span class="t">wanted to build something really, really quickly. I just built it over the weekend. We got early</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=3492" target="_blank">00:58:12.760</a></span> | <span class="t">access to 3.1, because we were a launch partner with Meta. So kind of just playing around with it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=3499" target="_blank">00:58:19.160</a></span> | <span class="t">and try to build something really quick over a weekend. >> Oh. Okay. I missed that detail. That's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=3503" target="_blank">00:58:23.880</a></span> | <span class="t">really cool. >> All right. Thanks. >> So you're doing the retrieval. >> I'm curious if you could</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=3509" target="_blank">00:58:29.320</a></span> | <span class="t">share what does it take to serve a 405B model all together? >> What does it take to serve 405B? So</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=3520" target="_blank">00:58:40.040</a></span> | <span class="t">we're serving -- what is it? FP8. It takes eight H100s per instance.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=3525" target="_blank">00:58:45.800</a></span> | <span class="t">Yeah. But we're looking into quantizing down to int4 and trying to serve on four H100s. But</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=3534" target="_blank">00:58:54.440</a></span> | <span class="t">in progress. >> The map is roughly 1 gig to 1 gig of VRAM, right? So at FP8, yeah, 1 to 1. And then</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=3545" target="_blank">00:59:05.720</a></span> | <span class="t">you could scale that out. There's pretty good resources on this. I feel like we've shared them</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=3548" target="_blank">00:59:08.760</a></span> | <span class="t">in Discord. And then someone asked about quantization stuff. Together put out pretty</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=3553" target="_blank">00:59:13.880</a></span> | <span class="t">good -- like you're now running quantized models in a good blog post about this. It's somewhere</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=3558" target="_blank">00:59:18.280</a></span> | <span class="t">in the Zoom chat, and we'll probably share it in Discord, too. Good resource on all that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=3562" target="_blank">00:59:22.600</a></span> | <span class="t">Also the paper has a section on inference, of course. So how do you run a 405B? What does</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=3570" target="_blank">00:59:30.120</a></span> | <span class="t">that look like? What's efficiency in that? They have a whole section on this. They have sections</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=3575" target="_blank">00:59:35.960</a></span> | <span class="t">on previous meta work of how do we have more token efficiency? So multi-token prediction of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=3581" target="_blank">00:59:41.480</a></span> | <span class="t">the pre-training task. How do we have other parts of what you might see? Meta's done a lot of work</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=3588" target="_blank">00:59:48.200</a></span> | <span class="t">on this. But overall, that's kind of a high-level overview and our thoughts on the paper. If anyone</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=3594" target="_blank">00:59:54.040</a></span> | <span class="t">else has questions, we can discuss them. Otherwise, next week -- we were supposed to do</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=3600" target="_blank">01:00:00.600</a></span> | <span class="t">Wizard LM and Orca 3, heavy synthetic data gen stuff this week, today. We pushed that to next</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=3607" target="_blank">01:00:07.400</a></span> | <span class="t">week. Sorry, this was not super prompted. Basically, less than 24 hours ago, we decided</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=3615" target="_blank">01:00:15.560</a></span> | <span class="t">let's switch this paper club. So we didn't have crazy slides. But next week, we'll have stuff for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=3620" target="_blank">01:00:20.040</a></span> | <span class="t">Orca 3 and Wizard LM. Same paper club, same time. And then at some point, I might do a deeper dive</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=3628" target="_blank">01:00:28.760</a></span> | <span class="t">into this, a proper one-hour breakdown of all this. If anyone's interested, I'll share somewhere.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=3633" target="_blank">01:00:33.960</a></span> | <span class="t">I'm curious about the quantization thing and whether -- if you have the choice of a larger --</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=3642" target="_blank">01:00:42.040</a></span> | <span class="t">sorry, more parameters, but worse quantization, how do you figure out the trade-off between that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=3648" target="_blank">01:00:48.200</a></span> | <span class="t">and running, say, the 70 billion model without quantization versus the 405 with quantization to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=3656" target="_blank">01:00:56.200</a></span> | <span class="t">make it down to the same size? >> People generally do benchmarks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=3660" target="_blank">01:01:00.520</a></span> | <span class="t">These are already happening right now. A lot of the communities are trying to figure this out.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=3668" target="_blank">01:01:08.920</a></span> | <span class="t">For anyone who wants to try 4-bit quantize, you can actually run it on 16</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=3677" target="_blank">01:01:17.240</a></span> | <span class="t">4090 GPUs if you're doing 4-bit quantize. I'm already seeing folks doing that. Whether that's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=3687" target="_blank">01:01:27.560</a></span> | <span class="t">a good idea, whether the model will get dumber or not is something we'll probably find out in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=3691" target="_blank">01:01:31.800</a></span> | <span class="t">the next few days. >> At a high level, though,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=3695" target="_blank">01:01:35.320</a></span> | <span class="t">the larger ones see less of a hit when quantizing than the small ones. r/locallama has a lot of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=3701" target="_blank">01:01:41.880</a></span> | <span class="t">comparisons and benchmarks of different quantizations. Basically, a lot of the prosumer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=3707" target="_blank">01:01:47.800</a></span> | <span class="t">rig is a dual 4090 or dual 3090 system. You've got about 48 gigs of VRAM. With 48 gigs of VRAM,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=3715" target="_blank">01:01:55.400</a></span> | <span class="t">you can run a 70B at 4-bit quant. A lot of people will spend $3,000 on a local rig. They can run</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=3725" target="_blank">01:02:05.080</a></span> | <span class="t">a 4-bit 70B, or they'll look at how does that compare to a 34B at higher precision, or a single</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=3731" target="_blank">01:02:11.560</a></span> | <span class="t">GPU where you're running an 8B. There's solid breakdowns of benchmarks of these. This is where</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=3738" target="_blank">01:02:18.280</a></span> | <span class="t">Reddit people are doing good work, as opposed to when you look at it from the infra provider side</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=3745" target="_blank">01:02:25.800</a></span> | <span class="t">of what's the benefits of quantizing. There's also efficiency in QLORA fine-tuning and quantizing and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=3752" target="_blank">01:02:32.520</a></span> | <span class="t">doing it. Benchmarks-wise, the LDR is bigger models take less of a hit, smaller models take</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=3758" target="_blank">01:02:38.760</a></span> | <span class="t">a bigger hit, and then speed inference. Alex, do you have thoughts? >> I have a question, actually.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=3766" target="_blank">01:02:46.360</a></span> | <span class="t">I don't usually have questions, but this time I have a question about effects of quantization.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=3770" target="_blank">01:02:50.520</a></span> | <span class="t">In your guys' experiences, what are the most visible effects of quantization? What comes</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=3780" target="_blank">01:03:00.040</a></span> | <span class="t">to mind when you see that the model is quantized, and how quickly do you realize, "Oh, this is the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=3786" target="_blank">01:03:06.760</a></span> | <span class="t">effects of quantization"? >> It's just dumber, that's all. >> Dumber in any specific areas? Is it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=3792" target="_blank">01:03:12.920</a></span> | <span class="t">dumber knowledge-wise, is it dumber logic-wise, or any specific areas? Which is overall dumber?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=3798" target="_blank">01:03:18.440</a></span> | <span class="t">>> One thing that I've seen a lot of community members do is that when you over-quantize</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=3805" target="_blank">01:03:25.800</a></span> | <span class="t">at longer context length, it starts going into repetition</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=3808" target="_blank">01:03:28.920</a></span> | <span class="t">rapidly. So that's like, "We have gone too far line." >> Yeah, in a lot of the one-bit</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=3820" target="_blank">01:03:40.120</a></span> | <span class="t">quants, as people ineffectively quantize stuff, it starts to just go into pure chaos. So it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=3826" target="_blank">01:03:46.280</a></span> | <span class="t">becomes stochastic random next-token prediction. The little trade-offs that you see at what type</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=3832" target="_blank">01:03:52.280</a></span> | <span class="t">of quantization you want to do, it starts to perform worse at chain of thought, at long context,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=3837" target="_blank">01:03:57.640</a></span> | <span class="t">at needle in the haystack. Some of those things start to degrade earlier on in quantization,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=3843" target="_blank">01:04:03.320</a></span> | <span class="t">as opposed to pure performance. And then, yeah, sometimes it's just dumber. It's just worse on</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=3848" target="_blank">01:04:08.200</a></span> | <span class="t">some of the trivia QA-type benchmarks, which is interesting because it's worse on reasoning</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=3855" target="_blank">01:04:15.560</a></span> | <span class="t">benchmarks, but decent on trivia. So trivia is where it's under internal knowledge, what does</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=3860" target="_blank">01:04:20.360</a></span> | <span class="t">it already know? It doesn't lose facts, but it loses reasoning, it loses verboseness of responses</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=3866" target="_blank">01:04:26.760</a></span> | <span class="t">and whatnot. So it degrades in that sense. But then you do have benefits of, yeah, it's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=3873" target="_blank">01:04:33.400</a></span> | <span class="t">significantly more efficient to run, right? Four-bit versus eight-bit, you can run in half</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=3877" target="_blank">01:04:37.640</a></span> | <span class="t">the hardware, you get speed-ups, you can fine-tune more efficiently. So there's trade-offs. Though</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=3883" target="_blank">01:04:43.080</a></span> | <span class="t">the one interesting thing I'll note there is if anyone saw the Apple LLMs at their WWDC stuff,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=3889" target="_blank">01:04:49.240</a></span> | <span class="t">they put out an Apple research blog on how they have all their local LoRa swaps, and they dropped</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=3895" target="_blank">01:04:55.800</a></span> | <span class="t">in a little paragraph where they're like, "We tested our models at a net of one or two-bit</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=3902" target="_blank">01:05:02.520</a></span> | <span class="t">quantization, and we saw no performance drop compared to full precision." So they're basically</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=3907" target="_blank">01:05:07.720</a></span> | <span class="t">like, "Yeah, we benchmarked it, we got lossless quantization, no details, no nothing." But</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=3914" target="_blank">01:05:14.520</a></span> | <span class="t">they seem to have stated they figured it out, which, you know, skeptical, but</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=3918" target="_blank">01:05:18.840</a></span> | <span class="t">they're running quantization for on-device. Yeah, but on specific tasks for them.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=3923" target="_blank">01:05:23.640</a></span> | <span class="t">It's also going to be very... Sorry. It's also going to be task-specific. We have seen</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=3930" target="_blank">01:05:30.440</a></span> | <span class="t">weird edge cases where when you quantize a model one step for certain tasks, it actually improves.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=3937" target="_blank">01:05:37.240</a></span> | <span class="t">We are degrading all the time. That's true, too.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=3942" target="_blank">01:05:42.760</a></span> | <span class="t">I'm writing an email now between cloud providers for 3.170B just to see if, like, you know,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=3949" target="_blank">01:05:49.320</a></span> | <span class="t">together's FB8 versus, I don't know, Fireworks or something like this has a difference, or versus</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=3956" target="_blank">01:05:56.760</a></span> | <span class="t">Glock. Have you seen an artificially analysis? Oh yeah, I think I saw something.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=3966" target="_blank">01:06:06.360</a></span> | <span class="t">These guys, they run pretty good. Yeah, but they don't do quality,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=3970" target="_blank">01:06:10.520</a></span> | <span class="t">they just do reported numbers, I think. But they do compare in front providers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=3977" target="_blank">01:06:17.160</a></span> | <span class="t">Oh, they're not doing their own benchmarks? I thought they have...</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=3979" target="_blank">01:06:19.800</a></span> | <span class="t">They're doing pricing and they're doing speed. I don't think they're doing quality.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=3983" target="_blank">01:06:23.560</a></span> | <span class="t">Yeah, they're not doing benchmarks. Yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=3985" target="_blank">01:06:25.880</a></span> | <span class="t">Glock is much more difficult to benchmark, to be honest.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=3989" target="_blank">01:06:29.320</a></span> | <span class="t">So, I'll add to Alex, like, what he was asking. I know credible reports of people where they're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4001" target="_blank">01:06:41.080</a></span> | <span class="t">saying between Glock and some other providers the quality is different in the sense everything else</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4008" target="_blank">01:06:48.280</a></span> | <span class="t">remaining the same, the inference engines are giving wrong answers. So, I'll just leave it at</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4012" target="_blank">01:06:52.920</a></span> | <span class="t">that. I mean, one thing I can tell you right now that I noticed that Glock temperatures zero</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4019" target="_blank">01:06:59.560</a></span> | <span class="t">returns different responses every request. So, I don't know if temperatures zero actually works</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4023" target="_blank">01:07:03.720</a></span> | <span class="t">there. Yeah, that has been... A lot of people have said that to the CEO also.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4036" target="_blank">01:07:16.200</a></span> | <span class="t">Wouldn't temperatures zero supposed to be the most deterministic instead of...</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4041" target="_blank">01:07:21.800</a></span> | <span class="t">Depends on the framework, to be honest. For opinion, I think temperature is zero.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4049" target="_blank">01:07:29.400</a></span> | <span class="t">Well, theoretically, it's supposed to be the most deterministic. I would expect, based on</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4055" target="_blank">01:07:35.240</a></span> | <span class="t">what temperature is supposed to do, that it would be the most deterministic.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4062" target="_blank">01:07:42.200</a></span> | <span class="t">Yeah, I guess... Oh, go ahead, Vibhu.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4066" target="_blank">01:07:46.200</a></span> | <span class="t">So, sometimes there's little reasons, like, when they're running inference, right? They might run</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4071" target="_blank">01:07:51.160</a></span> | <span class="t">it on different hardware. So, like, maybe there's a server in West Coast, East Coast that's different</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4077" target="_blank">01:07:57.160</a></span> | <span class="t">GPUs, different CUDA kernels, different drivers, and some of that affects how you do rounding,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4081" target="_blank">01:08:01.720</a></span> | <span class="t">how you do next, like, what... Yeah, basically, how is inference being done? So, you see slight</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4086" target="_blank">01:08:06.280</a></span> | <span class="t">variation. Then, across inference providers, this is their, like, secret sauce, right? Are they doing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4091" target="_blank">01:08:11.240</a></span> | <span class="t">self-speculative decoding? Are they doing speculative decoding? How are they doing it? So,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4095" target="_blank">01:08:15.240</a></span> | <span class="t">like, all these little things have differences, but there's also the reason of temperatures,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4100" target="_blank">01:08:20.360</a></span> | <span class="t">like, yeah, different hardware, different drivers, different all that. So, some of that answers it,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4105" target="_blank">01:08:25.240</a></span> | <span class="t">but I don't know, Eugene, maybe you have more to add. I was just going to say that for GPUs,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4111" target="_blank">01:08:31.080</a></span> | <span class="t">floating point just on what... I mean, for GPUs with floating points and you push it through so</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4115" target="_blank">01:08:35.720</a></span> | <span class="t">many calculations and so many matmuls, the floating points aren't just not going to be precise. So,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4121" target="_blank">01:08:41.880</a></span> | <span class="t">that's why even if temperature is zero, it's not going to be the same throughout for multiple</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4126" target="_blank">01:08:46.760</a></span> | <span class="t">requests. Yeah, even if it's, like, the same GPU on the same request, like, the order you do</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4134" target="_blank">01:08:54.120</a></span> | <span class="t">reduction on the matmuls, as Eugene mentioned, will affect the results because, like, floating</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4139" target="_blank">01:08:59.400</a></span> | <span class="t">point calculations is not deterministic. Like, you can try this in Python and add 0.1 and plus</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4145" target="_blank">01:09:05.720</a></span> | <span class="t">0.2, you might get 0.1999, not 0.2. So, like, the order you're doing the addition and multiplication</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4153" target="_blank">01:09:13.640</a></span> | <span class="t">can affect the results. And if you're doing, like, a thousand addition and multiplications,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4157" target="_blank">01:09:17.720</a></span> | <span class="t">it's difficult to get the same order every time. It's about that very small 0.0000001% noise</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4165" target="_blank">01:09:25.320</a></span> | <span class="t">that ends up cascading all the way. If you want true temperature equals to zero, the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4171" target="_blank">01:09:31.560</a></span> | <span class="t">non-reliable way is to run it on CPU because the CPU will do have the floating point precision</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4177" target="_blank">01:09:37.080</a></span> | <span class="t">reliability. But if you're running on CPU, you're going to take forever.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4181" target="_blank">01:09:41.880</a></span> | <span class="t">And to add to Eugene also, there are actually, like, five or six different class of floating</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4192" target="_blank">01:09:52.840</a></span> | <span class="t">point, what do you call, classes that there are in the CUDA. And I believe, like, people</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4197" target="_blank">01:09:57.560</a></span> | <span class="t">have to hand code certain, have to account for these, what do you call, differences.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4204" target="_blank">01:10:04.680</a></span> | <span class="t">And that's where they have to be actually shown the errors, saying that on some other</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4209" target="_blank">01:10:09.800</a></span> | <span class="t">platform we see this error and over here we see this answer. And now someone has to painfully</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4215" target="_blank">01:10:15.000</a></span> | <span class="t">go back and figure out a bug in their code. So, most of this is basically bugs in the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4220" target="_blank">01:10:20.120</a></span> | <span class="t">translation, not bugs in the hardware. That's what I was trying to say.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4223" target="_blank">01:10:23.400</a></span> | <span class="t">I'm definitely going to try that CPU approach. So, I'm trying to get a project approved and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4230" target="_blank">01:10:30.600</a></span> | <span class="t">not with the rationale being this type of inconsistency.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4245" target="_blank">01:10:45.240</a></span> | <span class="t">Also, like, depends on the engine. Like, XLAT12 is not deterministic at all compared to maybe,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4251" target="_blank">01:10:51.320</a></span> | <span class="t">I think, transformers is more deterministic. You can set the torch seed and the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4256" target="_blank">01:10:56.840</a></span> | <span class="t">inference seed. So, also the inference engine is very important.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4271" target="_blank">01:11:11.000</a></span> | <span class="t">Thank you.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4271" target="_blank">01:11:11.400</a></span> | <span class="t">Awesome. Well, thanks, everyone, for joining in on our last minute drop-in.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4278" target="_blank">01:11:18.760</a></span> | <span class="t">Can I share something really quick?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4280" target="_blank">01:11:20.280</a></span> | <span class="t">Yeah, yeah. Go ahead. I've got to drop, but this room will still stay open. I'm going to make</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4286" target="_blank">01:11:26.680</a></span> | <span class="t">someone else host. Feel free to keep discussing. Next week we have another one at 12, but I'm</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4292" target="_blank">01:11:32.680</a></span> | <span class="t">going to make Eugene host.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4294" target="_blank">01:11:34.600</a></span> | <span class="t">Oh, it's okay. I can do it next time.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4296" target="_blank">01:11:36.760</a></span> | <span class="t">No, no. Go ahead, go ahead, go ahead.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4298" target="_blank">01:11:38.920</a></span> | <span class="t">No, don't make me host. I'm at a baseball game.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4301" target="_blank">01:11:41.480</a></span> | <span class="t">No, the other Eugene.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4303" target="_blank">01:11:43.160</a></span> | <span class="t">So, it's quick. So, basically, I found like a LAMA 3.1, like a 405B, actually might do better</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4312" target="_blank">01:11:52.920</a></span> | <span class="t">in some domains, specific question, than like a CharGBT 4.0. Do you guys want to see a little bit?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4319" target="_blank">01:11:59.400</a></span> | <span class="t">Just really quick.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4320" target="_blank">01:12:00.200</a></span> | <span class="t">Sure. And it's no surprise, actually. I actually think that more and more people will find</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4327" target="_blank">01:12:07.560</a></span> | <span class="t">specific domains as time will happen.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4329" target="_blank">01:12:09.960</a></span> | <span class="t">That's great. So, let me share really quickly.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4333" target="_blank">01:12:13.720</a></span> | <span class="t">So, here's a little summary. So, basically, this is the specific question I was asking.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4340" target="_blank">01:12:20.280</a></span> | <span class="t">Here, you're an expert in mechanistic interval research. How do you use the rest of the stream?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4346" target="_blank">01:12:26.040</a></span> | <span class="t">Yeah. And so, here's my summary. Overall, I think, you know, 405B did a better job to explain.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4354" target="_blank">01:12:34.680</a></span> | <span class="t">And also, there are some important information like is missing in CharGBT 4.0 or not expressly</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4361" target="_blank">01:12:41.080</a></span> | <span class="t">explained. So, let me show you the answer from LAMA 3.0, 405B first.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4368" target="_blank">01:12:48.360</a></span> | <span class="t">I feel, I find it's really easy to follow for someone like me. Like, I'm not doing research</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4372" target="_blank">01:12:52.840</a></span> | <span class="t">in this field. And it also gives enough technical detail. So, if anyone wants to read a little bit.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4381" target="_blank">01:13:01.480</a></span> | <span class="t">Yeah. So, and I can move to the chat. What did the answer from CharGBT 4.0? Do you guys want to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4391" target="_blank">01:13:11.320</a></span> | <span class="t">see it? Yeah, yeah. Yeah, I'm done. You're done? Okay, cool. So, this one is from CharGBT 4.0.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4401" target="_blank">01:13:21.240</a></span> | <span class="t">I feel like CharGBT still kind of like answer things in a sort of generalized way.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4408" target="_blank">01:13:28.440</a></span> | <span class="t">Let me know if you want me to move, scroll down. Or if I'm scrolling down too fast.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4421" target="_blank">01:13:41.880</a></span> | <span class="t">I think Eugene, the other Eugene would chime in that actually a lot of these things</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4435" target="_blank">01:13:55.720</a></span> | <span class="t">are very dependent on the prompt. So, it won't surprise me if you tweak the prompt right,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4451" target="_blank">01:14:11.560</a></span> | <span class="t">the winner ends up flipping around. That's what I meant. Yes, just for the argument,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4457" target="_blank">01:14:17.480</a></span> | <span class="t">I didn't tweak the prompt just for LAMA 405B. So, I just said, hey, I have this one. I just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4463" target="_blank">01:14:23.560</a></span> | <span class="t">throw it out. But definitely, you know, more detailed study needs to be done. And let me show</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4468" target="_blank">01:14:28.680</a></span> | <span class="t">you CharGBT 4.0. It's better than 4.0, but I don't think, I still think LAMA 405B did a better job.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4479" target="_blank">01:14:39.640</a></span> | <span class="t">Just a second. So, I'm going to do the same thing, scrolling down. Let me know if I'm moving too</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4493" target="_blank">01:14:53.880</a></span> | <span class="t">fast. So, basically, I think I kind of feel, of course, need to do more detailed study. I feel</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4513" target="_blank">01:15:13.640</a></span> | <span class="t">like LAMA 405B may have been doing a much better job of organizing this knowledge, you know, how</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4521" target="_blank">01:15:21.960</a></span> | <span class="t">the way to handle how to answer questions, you know, how to organize the knowledge together.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4526" target="_blank">01:15:26.440</a></span> | <span class="t">I think that's pretty important.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4529" target="_blank">01:15:29.560</a></span> | <span class="t">So, I'll give my personal example that when I look at some healthcare related data,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4537" target="_blank">01:15:37.160</a></span> | <span class="t">and if I'm looking at through basically CharGBT 4.0, and then even when I use the similar prompt</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4547" target="_blank">01:15:47.160</a></span> | <span class="t">that I give through perplexity, I get different answers. But since I know the domain, I know that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4553" target="_blank">01:15:53.000</a></span> | <span class="t">sometimes like CharGBT is just bullshitting. And perplexity actually gets references, and it gives</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4558" target="_blank">01:15:58.840</a></span> | <span class="t">you a slightly better or more answer, which I can take and go back to the references and dig deeper.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4565" target="_blank">01:16:05.240</a></span> | <span class="t">So, you will definitely, once you know the domain better, you should not fall in for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4570" target="_blank">01:16:10.200</a></span> | <span class="t">the English is my take. The English may look all correct, but it might be nonsense at the end of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4574" target="_blank">01:16:14.440</a></span> | <span class="t">the day. Oh, I looked into a little bit about the rest of the stream. I can have pretty good</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4581" target="_blank">01:16:21.400</a></span> | <span class="t">confidence. It's not the bullshitting from 405B. Yeah. So, the things that really amazed me is like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4588" target="_blank">01:16:28.440</a></span> | <span class="t">how it explains. And it's me, like I said, hey, I'm just starting getting into like a lot of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4594" target="_blank">01:16:34.200</a></span> | <span class="t">technical things I haven't done before. It seems like it just really explained really well. I can</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4599" target="_blank">01:16:39.640</a></span> | <span class="t">just go down to, you know, do look into specific information and stuff like that. But definitely,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4605" target="_blank">01:16:45.400</a></span> | <span class="t">I see your point, like it's just one shot. But still, it seems pretty amazing because I didn't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4610" target="_blank">01:16:50.680</a></span> | <span class="t">try to twit the problem just for 405B. Yeah. Thank you. Yeah. So, that's what I want to share.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4616" target="_blank">01:16:56.200</a></span> | <span class="t">Yeah, definitely. We are going to see more and more of this. Like, I think what's interesting,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4622" target="_blank">01:17:02.680</a></span> | <span class="t">especially when you're having different foundation models, you're going to have very different</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4627" target="_blank">01:17:07.800</a></span> | <span class="t">default outputs. Because, yeah, we can probably steer all models, especially the bigger ones,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4633" target="_blank">01:17:13.080</a></span> | <span class="t">we prompt engineering to a certain desired effects or even like fine-tuning. But the default out of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4639" target="_blank">01:17:19.560</a></span> | <span class="t">the box would be what's interesting because that's what a lot of day-to-day users is what</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4645" target="_blank">01:17:25.560</a></span> | <span class="t">they will experience. So, like for me, for the longest period of time, I didn't care that GPT-4</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4651" target="_blank">01:17:31.960</a></span> | <span class="t">had a better eval score across the board than the cloud model. The cloud model just seems</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4658" target="_blank">01:17:38.840</a></span> | <span class="t">friendly and nicer to me and I like it better. And maybe that's what does matter sometime when</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4665" target="_blank">01:17:45.320</a></span> | <span class="t">they are all good enough to get the job done. Yes. So, I wish we have a better model where</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4671" target="_blank">01:17:51.880</a></span> | <span class="t">we don't need to twit the prompt, you know. In a way, it can reflect how well the model is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4678" target="_blank">01:17:58.760</a></span> | <span class="t">organized, its knowledge, you know. And so, if it's easy, just talk to it without</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4683" target="_blank">01:18:03.800</a></span> | <span class="t">twitting the prompt. Actually, it's, you know, in a much better advanced stage, I think.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4689" target="_blank">01:18:09.880</a></span> | <span class="t">But I think in the long run, that will be hard to achieve because if you just view each model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4696" target="_blank">01:18:16.520</a></span> | <span class="t">a bit like an individual, so you can call it Lama-kun, you can call it GPT-4-kun, etc. It's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4705" target="_blank">01:18:25.480</a></span> | <span class="t">just really a preference thing when it boils down to it. Because, as I said, well, I prefer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4712" target="_blank">01:18:32.440</a></span> | <span class="t">Claude because of the way he did the artwork. I know someone who prefers the other way.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4716" target="_blank">01:18:36.760</a></span> | <span class="t">And that's the challenge here, right? You can't possibly just train the model to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4723" target="_blank">01:18:43.000</a></span> | <span class="t">satisfy everyone in the world. There'll be that back and forth. And that's where all those, like,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4728" target="_blank">01:18:48.200</a></span> | <span class="t">more view-shot prompting will come in or fine-tunes will come in. And I think that is probably the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4734" target="_blank">01:18:54.200</a></span> | <span class="t">more exciting thing about Lama because we're going to see lots of fine-tunes.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4738" target="_blank">01:18:58.200</a></span> | <span class="t">Sorry, go ahead.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4744" target="_blank">01:19:04.200</a></span> | <span class="t">I think, because since we are well past the usual, and there's a lot of new faces here,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4751" target="_blank">01:19:11.160</a></span> | <span class="t">I'm just going to, like, recap and point it out. So, the Latentspace Discord, we host this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4760" target="_blank">01:19:20.520</a></span> | <span class="t">weekly papers talk, and this is why this session happened. This week is just a very special one</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4766" target="_blank">01:19:26.920</a></span> | <span class="t">because of the whole Lama 3 model came out. Prior to that, we were planning to do other papers,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4774" target="_blank">01:19:34.600</a></span> | <span class="t">and we'll probably go back to our usual schedule. So, if any of you, especially the new folks that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4780" target="_blank">01:19:40.280</a></span> | <span class="t">joined in because this got broadcast on a much larger audience, feel free to join us next week,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4787" target="_blank">01:19:47.080</a></span> | <span class="t">and we'll be talking other papers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4790" target="_blank">01:19:50.120</a></span> | <span class="t">Great. Thank you. Yes.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4791" target="_blank">01:19:51.480</a></span> | <span class="t">Thank you, everyone.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4794" target="_blank">01:19:54.520</a></span> | <span class="t">Thanks a lot.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4797" target="_blank">01:19:57.560</a></span> | <span class="t">All right. Have a great day, everyone.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4800" target="_blank">01:20:00.680</a></span> | <span class="t">Okay. I'll stay. It's got organized.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4827" target="_blank">01:20:27.240</a></span> | <span class="t">Okay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4828" target="_blank">01:20:28.700</a></span> | <span class="t">Okay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4830" target="_blank">01:20:30.160</a></span> | <span class="t">Okay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4831" target="_blank">01:20:31.620</a></span> | <span class="t">Okay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4833" target="_blank">01:20:33.080</a></span> | <span class="t">Okay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4834" target="_blank">01:20:34.540</a></span> | <span class="t">Okay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4836" target="_blank">01:20:36.000</a></span> | <span class="t">Okay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4837" target="_blank">01:20:37.460</a></span> | <span class="t">Okay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4838" target="_blank">01:20:38.920</a></span> | <span class="t">Okay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4840" target="_blank">01:20:40.380</a></span> | <span class="t">Okay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4840" target="_blank">01:20:40.880</a></span> | <span class="t">Okay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4842" target="_blank">01:20:42.880</a></span> | <span class="t">Okay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4844" target="_blank">01:20:44.880</a></span> | <span class="t">Okay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4846" target="_blank">01:20:46.880</a></span> | <span class="t">Okay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4848" target="_blank">01:20:48.880</a></span> | <span class="t">Okay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4850" target="_blank">01:20:50.880</a></span> | <span class="t">Okay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4852" target="_blank">01:20:52.880</a></span> | <span class="t">Okay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4854" target="_blank">01:20:54.880</a></span> | <span class="t">Okay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4856" target="_blank">01:20:56.880</a></span> | <span class="t">Okay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4858" target="_blank">01:20:58.880</a></span> | <span class="t">Okay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4860" target="_blank">01:21:00.880</a></span> | <span class="t">Okay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4862" target="_blank">01:21:02.880</a></span> | <span class="t">Okay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4864" target="_blank">01:21:04.880</a></span> | <span class="t">Okay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4866" target="_blank">01:21:06.880</a></span> | <span class="t">Okay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4868" target="_blank">01:21:08.880</a></span> | <span class="t">Okay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4869" target="_blank">01:21:09.380</a></span> | <span class="t">Okay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4871" target="_blank">01:21:11.380</a></span> | <span class="t">Okay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4873" target="_blank">01:21:13.380</a></span> | <span class="t">Okay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4875" target="_blank">01:21:15.380</a></span> | <span class="t">Okay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4877" target="_blank">01:21:17.380</a></span> | <span class="t">Okay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4879" target="_blank">01:21:19.380</a></span> | <span class="t">Okay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4881" target="_blank">01:21:21.380</a></span> | <span class="t">Okay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4883" target="_blank">01:21:23.380</a></span> | <span class="t">Okay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4885" target="_blank">01:21:25.380</a></span> | <span class="t">Okay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4887" target="_blank">01:21:27.380</a></span> | <span class="t">Okay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4889" target="_blank">01:21:29.380</a></span> | <span class="t">Okay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4891" target="_blank">01:21:31.380</a></span> | <span class="t">Okay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4893" target="_blank">01:21:33.380</a></span> | <span class="t">Okay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4895" target="_blank">01:21:35.380</a></span> | <span class="t">Okay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4897" target="_blank">01:21:37.380</a></span> | <span class="t">Okay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4897" target="_blank">01:21:37.880</a></span> | <span class="t">Okay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4899" target="_blank">01:21:39.880</a></span> | <span class="t">Okay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4901" target="_blank">01:21:41.880</a></span> | <span class="t">Okay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4903" target="_blank">01:21:43.880</a></span> | <span class="t">Okay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4905" target="_blank">01:21:45.880</a></span> | <span class="t">Okay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4907" target="_blank">01:21:47.880</a></span> | <span class="t">Okay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4909" target="_blank">01:21:49.880</a></span> | <span class="t">Okay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4911" target="_blank">01:21:51.880</a></span> | <span class="t">Okay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4913" target="_blank">01:21:53.880</a></span> | <span class="t">Okay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4915" target="_blank">01:21:55.880</a></span> | <span class="t">Okay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4917" target="_blank">01:21:57.880</a></span> | <span class="t">Okay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4919" target="_blank">01:21:59.880</a></span> | <span class="t">Okay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4921" target="_blank">01:22:01.880</a></span> | <span class="t">Okay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4923" target="_blank">01:22:03.880</a></span> | <span class="t">Okay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4925" target="_blank">01:22:05.880</a></span> | <span class="t">Okay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4926" target="_blank">01:22:06.380</a></span> | <span class="t">Okay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4928" target="_blank">01:22:08.380</a></span> | <span class="t">Okay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4930" target="_blank">01:22:10.380</a></span> | <span class="t">Okay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4932" target="_blank">01:22:12.380</a></span> | <span class="t">Okay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4934" target="_blank">01:22:14.380</a></span> | <span class="t">Okay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4936" target="_blank">01:22:16.380</a></span> | <span class="t">Okay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4938" target="_blank">01:22:18.380</a></span> | <span class="t">Okay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4940" target="_blank">01:22:20.380</a></span> | <span class="t">Okay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4942" target="_blank">01:22:22.380</a></span> | <span class="t">Okay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4944" target="_blank">01:22:24.380</a></span> | <span class="t">Okay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4946" target="_blank">01:22:26.380</a></span> | <span class="t">Okay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4948" target="_blank">01:22:28.380</a></span> | <span class="t">Okay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4950" target="_blank">01:22:30.380</a></span> | <span class="t">Okay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4952" target="_blank">01:22:32.380</a></span> | <span class="t">Okay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4954" target="_blank">01:22:34.380</a></span> | <span class="t">Okay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4954" target="_blank">01:22:34.880</a></span> | <span class="t">Okay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4956" target="_blank">01:22:36.880</a></span> | <span class="t">Okay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4958" target="_blank">01:22:38.880</a></span> | <span class="t">Okay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4960" target="_blank">01:22:40.880</a></span> | <span class="t">Okay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4962" target="_blank">01:22:42.880</a></span> | <span class="t">Okay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4964" target="_blank">01:22:44.880</a></span> | <span class="t">Okay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4966" target="_blank">01:22:46.880</a></span> | <span class="t">Okay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4968" target="_blank">01:22:48.880</a></span> | <span class="t">Okay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4970" target="_blank">01:22:50.880</a></span> | <span class="t">Okay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4972" target="_blank">01:22:52.880</a></span> | <span class="t">Okay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4974" target="_blank">01:22:54.880</a></span> | <span class="t">Okay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4976" target="_blank">01:22:56.880</a></span> | <span class="t">Okay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4978" target="_blank">01:22:58.880</a></span> | <span class="t">Okay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4980" target="_blank">01:23:00.880</a></span> | <span class="t">Okay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4983" target="_blank">01:23:03.880</a></span> | <span class="t">See you later, Eugene. Peace.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4985" target="_blank">01:23:05.880</a></span> | <span class="t">You</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4987" target="_blank">01:23:07.880</a></span> | <span class="t">You</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4989" target="_blank">01:23:09.880</a></span> | <span class="t">You</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4991" target="_blank">01:23:11.880</a></span> | <span class="t">You</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4993" target="_blank">01:23:13.880</a></span> | <span class="t">You</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4995" target="_blank">01:23:15.880</a></span> | <span class="t">You</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4997" target="_blank">01:23:17.880</a></span> | <span class="t">You</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=4999" target="_blank">01:23:19.880</a></span> | <span class="t">You</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=5001" target="_blank">01:23:21.880</a></span> | <span class="t">You</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=5003" target="_blank">01:23:23.880</a></span> | <span class="t">You</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=5005" target="_blank">01:23:25.880</a></span> | <span class="t">You</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=5007" target="_blank">01:23:27.880</a></span> | <span class="t">You</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=5009" target="_blank">01:23:29.880</a></span> | <span class="t">You</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=5011" target="_blank">01:23:31.880</a></span> | <span class="t">You</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=5013" target="_blank">01:23:33.880</a></span> | <span class="t">You</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=5015" target="_blank">01:23:35.880</a></span> | <span class="t">You</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=5017" target="_blank">01:23:37.880</a></span> | <span class="t">You</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=5019" target="_blank">01:23:39.880</a></span> | <span class="t">You</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=5021" target="_blank">01:23:41.880</a></span> | <span class="t">You</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=TgLSYIBoX5U&t=5023" target="_blank">01:23:43.880</a></span> | <span class="t">You</span></div></div></body></html>