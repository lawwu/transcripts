<html><head><title>CLIP - Paper explanation (training and inference)</title>
<style>
    body {
        font-family: Arial, sans-serif;
        margin: 0;
        padding: 0;
        background-color: #f4f4f4;
        color: #333;
    }
    .container {
        width: 95%;  /* Increased width to use more space */
        margin: auto;
        overflow: auto;  /* Added to handle overflow by adding a scrollbar if necessary */
    }
    h2, h3 {
        color: #333;
        text-align: center;
    }
    a {
        color: #0000FF;  /* Traditional blue color for links */
        text-decoration: none;
    }
    a:hover {
        text-decoration: underline;
    }
    img {
        display: block;
        margin: auto;
        max-width: 100%;
    }
    .c {
        margin: 10px 0;
    }
    .s, .t {
        display: inline-block;
        margin-right: 5px;
    }
    .max-width {
        max-width: 800px;
        margin: auto;
        padding-left: 20px;
    }
    table {
        width: 100%;
        border-collapse: collapse;
    }
    th, td {
        border: 1px solid #ddd;
        padding: 8px;
        text-align: left;  /* Ensure text alignment is consistent */
    }
    tr:nth-child(even) {
        background-color: #f2f2f2;
    }
    tr:nth-child(odd) {
        background-color: #e6e6e6;
    }
</style>

    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-69VLBMTTP0"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-69VLBMTTP0');
    </script>
    </head><body><div class='container'><a href="index.html">back to index</a><h2>CLIP - Paper explanation (training and inference)</h2><a href="https://www.youtube.com/watch?v=L3BTG8ETY_Y"><img src="https://i.ytimg.com/vi/L3BTG8ETY_Y/maxresdefault.jpg" style="width:50%;"></a><div><br></div><div style="text-align: left;"><a href="./L3BTG8ETY_Y.html">Whisper Transcript</a> | <a href="./transcript_L3BTG8ETY_Y.html">Transcript Only Page</a></div><br><div style="max-width: 800px;"><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L3BTG8ETY_Y&t=0" target="_blank">00:00:00.000</a></span> | <span class="t">Hello guys, welcome to this new video about Clip.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L3BTG8ETY_Y&t=4" target="_blank">00:00:04.320</a></span> | <span class="t">Clip is a model from OpenAI released 2021.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L3BTG8ETY_Y&t=8" target="_blank">00:00:08.560</a></span> | <span class="t">And it's got really popular even recently because of stable diffusion.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L3BTG8ETY_Y&t=13" target="_blank">00:00:13.280</a></span> | <span class="t">And it was quite revolutionary for the time, especially because it's used a novel way of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L3BTG8ETY_Y&t=18" target="_blank">00:00:18.000</a></span> | <span class="t">connecting text and images.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L3BTG8ETY_Y&t=19" target="_blank">00:00:19.560</a></span> | <span class="t">First of all, we will explore what is Clip and why what does it mean to connect text</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L3BTG8ETY_Y&t=24" target="_blank">00:00:24.800</a></span> | <span class="t">and images.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L3BTG8ETY_Y&t=25" target="_blank">00:00:25.920</a></span> | <span class="t">And secondly, actually before that, we will also explore why we needed Clip in the first</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L3BTG8ETY_Y&t=31" target="_blank">00:00:31.680</a></span> | <span class="t">place.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L3BTG8ETY_Y&t=32" target="_blank">00:00:32.680</a></span> | <span class="t">Okay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L3BTG8ETY_Y&t=33" target="_blank">00:00:33.680</a></span> | <span class="t">First of all, the task we are concerned about is image classification.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L3BTG8ETY_Y&t=37" target="_blank">00:00:37.120</a></span> | <span class="t">So we are in the domain of classification.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L3BTG8ETY_Y&t=39" target="_blank">00:00:39.660</a></span> | <span class="t">And before we had Clip, we had these convolutional neural networks that were trained to classify</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L3BTG8ETY_Y&t=45" target="_blank">00:00:45.720</a></span> | <span class="t">pictures, images into classes.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L3BTG8ETY_Y&t=48" target="_blank">00:00:48.880</a></span> | <span class="t">For example, let's see this picture from Google's website.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L3BTG8ETY_Y&t=53" target="_blank">00:00:53.880</a></span> | <span class="t">And we see that, for example, before, if we had pictures of cats or dogs, and we wanted</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L3BTG8ETY_Y&t=59" target="_blank">00:00:59.000</a></span> | <span class="t">to classify them into two classes, we had to create this convolutional neural network</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L3BTG8ETY_Y&t=65" target="_blank">00:01:05.800</a></span> | <span class="t">with a lot of convolutions, max pooling, and finally, a fully connected layer that would</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L3BTG8ETY_Y&t=71" target="_blank">00:01:11.680</a></span> | <span class="t">give a maximum score to the class that is most representative for the input image.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L3BTG8ETY_Y&t=75" target="_blank">00:01:15.760</a></span> | <span class="t">For example, the activation for the cat output would be the highest in this case, because</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L3BTG8ETY_Y&t=82" target="_blank">00:01:22.920</a></span> | <span class="t">we are giving a picture of the cat.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L3BTG8ETY_Y&t=84" target="_blank">00:01:24.740</a></span> | <span class="t">And if it was a dog, then the output for the dog would be the have the highest value.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L3BTG8ETY_Y&t=91" target="_blank">00:01:31.140</a></span> | <span class="t">This was working well, actually, the problem with this method with this way of proceeding</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L3BTG8ETY_Y&t=96" target="_blank">00:01:36.760</a></span> | <span class="t">is that we need a lot of pictures, we need a big data set, we need a lot of labels data</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L3BTG8ETY_Y&t=102" target="_blank">00:01:42.440</a></span> | <span class="t">set.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L3BTG8ETY_Y&t=103" target="_blank">00:01:43.440</a></span> | <span class="t">So we need a lot of pictures of cats, a lot of pictures of dogs.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L3BTG8ETY_Y&t=107" target="_blank">00:01:47.000</a></span> | <span class="t">And someone has to spend time to build this data set and to label them and to verify that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L3BTG8ETY_Y&t=111" target="_blank">00:01:51.800</a></span> | <span class="t">these labels are actually correct.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L3BTG8ETY_Y&t=114" target="_blank">00:01:54.480</a></span> | <span class="t">This is okay, if we have a small number of classes, and they are quite different from</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L3BTG8ETY_Y&t=119" target="_blank">00:01:59.880</a></span> | <span class="t">each other.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L3BTG8ETY_Y&t=120" target="_blank">00:02:00.880</a></span> | <span class="t">However, in some domains, it's not easy to build this data set.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L3BTG8ETY_Y&t=124" target="_blank">00:02:04.480</a></span> | <span class="t">And it's quite costly actually to build them.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L3BTG8ETY_Y&t=127" target="_blank">00:02:07.280</a></span> | <span class="t">I think of medical research in which the pictures have to be labeled by, for example, a doctor</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L3BTG8ETY_Y&t=133" target="_blank">00:02:13.520</a></span> | <span class="t">or anyway, someone who has knowledge in the domain.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L3BTG8ETY_Y&t=136" target="_blank">00:02:16.840</a></span> | <span class="t">So you cannot just ask a random person to classify cancer and non cancer images from</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L3BTG8ETY_Y&t=143" target="_blank">00:02:23.720</a></span> | <span class="t">medical devices.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L3BTG8ETY_Y&t=145" target="_blank">00:02:25.520</a></span> | <span class="t">So the problem was to build this data set was really expensive.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L3BTG8ETY_Y&t=149" target="_blank">00:02:29.760</a></span> | <span class="t">And plus, what they saw is that this data set could not generalize to other tasks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L3BTG8ETY_Y&t=155" target="_blank">00:02:35.520</a></span> | <span class="t">So for example, classifier that was trained upon dogs and cats could not generalize easily</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L3BTG8ETY_Y&t=162" target="_blank">00:02:42.500</a></span> | <span class="t">to other type of classes.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L3BTG8ETY_Y&t=166" target="_blank">00:02:46.400</a></span> | <span class="t">And it would perform really badly on other kind of classic classifications.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L3BTG8ETY_Y&t=172" target="_blank">00:02:52.680</a></span> | <span class="t">So let's explore how clip solves this problem.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L3BTG8ETY_Y&t=176" target="_blank">00:02:56.220</a></span> | <span class="t">So clip just like the name says, connecting images and pictures, sorry, images and text</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L3BTG8ETY_Y&t=183" target="_blank">00:03:03.080</a></span> | <span class="t">is a model from open AI.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L3BTG8ETY_Y&t=187" target="_blank">00:03:07.040</a></span> | <span class="t">And basically, it means contrastive learning images pre training.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L3BTG8ETY_Y&t=191" target="_blank">00:03:11.280</a></span> | <span class="t">And the way it works is written is shown here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L3BTG8ETY_Y&t=194" target="_blank">00:03:14.880</a></span> | <span class="t">So basically, clip is made of two encoders, one text encoder and one image encoder.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L3BTG8ETY_Y&t=203" target="_blank">00:03:23.240</a></span> | <span class="t">What do we feed to clip first of all, we give him a batch of text and the corresponding</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L3BTG8ETY_Y&t=207" target="_blank">00:03:27.920</a></span> | <span class="t">images, which means that the first item in this text batch is corresponding to the first</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L3BTG8ETY_Y&t=214" target="_blank">00:03:34.360</a></span> | <span class="t">image in this image back.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L3BTG8ETY_Y&t=217" target="_blank">00:03:37.620</a></span> | <span class="t">So pepper the Aussie pup is actually corresponding to this picture.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L3BTG8ETY_Y&t=221" target="_blank">00:03:41.640</a></span> | <span class="t">And where do we get all this picture?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L3BTG8ETY_Y&t=223" target="_blank">00:03:43.400</a></span> | <span class="t">The authors of clip got these pictures and this text from the internet, they created</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L3BTG8ETY_Y&t=228" target="_blank">00:03:48.000</a></span> | <span class="t">a data set of 400 million images collected from the internet that were supposedly well</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L3BTG8ETY_Y&t=236" target="_blank">00:03:56.840</a></span> | <span class="t">described by the users by the authors.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L3BTG8ETY_Y&t=240" target="_blank">00:04:00.280</a></span> | <span class="t">Usually when you find a picture on the internet, actually, you don't find just the picture,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L3BTG8ETY_Y&t=244" target="_blank">00:04:04.200</a></span> | <span class="t">you also find some description of the picture behind it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L3BTG8ETY_Y&t=247" target="_blank">00:04:07.240</a></span> | <span class="t">Especially on social networks, for example, people going on a trip in somewhere they will</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L3BTG8ETY_Y&t=251" target="_blank">00:04:11.400</a></span> | <span class="t">write something about the content of the picture.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L3BTG8ETY_Y&t=254" target="_blank">00:04:14.720</a></span> | <span class="t">And this, this is not just a single word.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L3BTG8ETY_Y&t=257" target="_blank">00:04:17.960</a></span> | <span class="t">So for example, here, we don't just write dog, we actually describe the picture.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L3BTG8ETY_Y&t=261" target="_blank">00:04:21.960</a></span> | <span class="t">So this is why they call it natural language supervision.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L3BTG8ETY_Y&t=266" target="_blank">00:04:26.320</a></span> | <span class="t">So the way it works is, they take the text in the batch of text, and they go pass it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L3BTG8ETY_Y&t=271" target="_blank">00:04:31.360</a></span> | <span class="t">through the text encoder, which gives us some features for this tech.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L3BTG8ETY_Y&t=276" target="_blank">00:04:36.200</a></span> | <span class="t">And these features are actually then multiplied by another matrix so that the dimension of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L3BTG8ETY_Y&t=280" target="_blank">00:04:40.160</a></span> | <span class="t">the features is a particular dimension.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L3BTG8ETY_Y&t=283" target="_blank">00:04:43.840</a></span> | <span class="t">And then they do the same with the images.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L3BTG8ETY_Y&t=286" target="_blank">00:04:46.560</a></span> | <span class="t">So they pass the images through the image encoder.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L3BTG8ETY_Y&t=289" target="_blank">00:04:49.640</a></span> | <span class="t">And then they multiply this feature by another matrix to make the images have the same dimension</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L3BTG8ETY_Y&t=296" target="_blank">00:04:56.960</a></span> | <span class="t">as the text features.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L3BTG8ETY_Y&t=299" target="_blank">00:04:59.240</a></span> | <span class="t">When then they build this dot product, this cosine similarity metric, we can see here,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L3BTG8ETY_Y&t=306" target="_blank">00:05:06.280</a></span> | <span class="t">in which they calculate the cosine similarity between each possible combination of text</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L3BTG8ETY_Y&t=311" target="_blank">00:05:11.520</a></span> | <span class="t">and image.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L3BTG8ETY_Y&t=312" target="_blank">00:05:12.520</a></span> | <span class="t">And what do we expect?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L3BTG8ETY_Y&t=313" target="_blank">00:05:13.520</a></span> | <span class="t">I mean, what do we expect, since we know that the ground truth is the fact that this picture</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L3BTG8ETY_Y&t=318" target="_blank">00:05:18.320</a></span> | <span class="t">matches with the first text, and the second text matches with the second picture, and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L3BTG8ETY_Y&t=323" target="_blank">00:05:23.240</a></span> | <span class="t">the third text matches with the third picture, we want all the items in the diagonal.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L3BTG8ETY_Y&t=329" target="_blank">00:05:29.480</a></span> | <span class="t">So the one we know match to each other, we have the most to be the most similar to have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L3BTG8ETY_Y&t=336" target="_blank">00:05:36.480</a></span> | <span class="t">the highest similarity, while we want the other pairs to have a lower similarity, even</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L3BTG8ETY_Y&t=343" target="_blank">00:05:43.600</a></span> | <span class="t">zero.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L3BTG8ETY_Y&t=345" target="_blank">00:05:45.000</a></span> | <span class="t">But we want these ones for on the diagonal to have the highest one.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L3BTG8ETY_Y&t=350" target="_blank">00:05:50.160</a></span> | <span class="t">And actually, this code is written also in the paper, which we can see here, let me check</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L3BTG8ETY_Y&t=357" target="_blank">00:05:57.200</a></span> | <span class="t">which page Yeah, here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L3BTG8ETY_Y&t=361" target="_blank">00:06:01.380</a></span> | <span class="t">So here we have a batch of images, we pass it through the image encoder to get some at</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L3BTG8ETY_Y&t=367" target="_blank">00:06:07.720</a></span> | <span class="t">the bed.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L3BTG8ETY_Y&t=368" target="_blank">00:06:08.760</a></span> | <span class="t">And then the embeddings from the image encoder of dimension di.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L3BTG8ETY_Y&t=374" target="_blank">00:06:14.520</a></span> | <span class="t">Then we do the same with the text, we have n text, and we pass it to the text encoder,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L3BTG8ETY_Y&t=379" target="_blank">00:06:19.600</a></span> | <span class="t">we will get some features from this text encoder of the dimension t dt.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L3BTG8ETY_Y&t=385" target="_blank">00:06:25.080</a></span> | <span class="t">Then we multiply the features from the image and the features from the text with the two</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L3BTG8ETY_Y&t=390" target="_blank">00:06:30.080</a></span> | <span class="t">matrices so that each of them will have a resulting feature size of d e.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L3BTG8ETY_Y&t=396" target="_blank">00:06:36.560</a></span> | <span class="t">We do the cosine similarities for each pair.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L3BTG8ETY_Y&t=399" target="_blank">00:06:39.840</a></span> | <span class="t">And we calculate the logics, then what we do, we calculate the loss, how, how should</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L3BTG8ETY_Y&t=408" target="_blank">00:06:48.040</a></span> | <span class="t">we calculate the loss?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L3BTG8ETY_Y&t=409" target="_blank">00:06:49.040</a></span> | <span class="t">Well, basically, what we expect is, is that by in the rows in this row, for example, we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L3BTG8ETY_Y&t=416" target="_blank">00:06:56.840</a></span> | <span class="t">expect the this item, so the position one to have the highest cosine similarity in this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L3BTG8ETY_Y&t=424" target="_blank">00:07:04.120</a></span> | <span class="t">row, we expect the second one to have the highest similarity.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L3BTG8ETY_Y&t=428" target="_blank">00:07:08.680</a></span> | <span class="t">And the third row, we expect the third one, and the same for the columns in the first</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L3BTG8ETY_Y&t=432" target="_blank">00:07:12.800</a></span> | <span class="t">column, we expect this one to have the highest second one, we have this one to have the highest</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L3BTG8ETY_Y&t=437" target="_blank">00:07:17.200</a></span> | <span class="t">and the third one, we have this item to have the highest cosine similarity.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L3BTG8ETY_Y&t=442" target="_blank">00:07:22.360</a></span> | <span class="t">And this explains the choice of the loss function here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L3BTG8ETY_Y&t=445" target="_blank">00:07:25.880</a></span> | <span class="t">So basically, we just generate a range between zero and n.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L3BTG8ETY_Y&t=450" target="_blank">00:07:30.720</a></span> | <span class="t">And then we this is our expected actually labeled.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L3BTG8ETY_Y&t=454" target="_blank">00:07:34.660</a></span> | <span class="t">So we want that particular row of that particular position in the row or in the column to have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L3BTG8ETY_Y&t=459" target="_blank">00:07:39.280</a></span> | <span class="t">the highest one.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L3BTG8ETY_Y&t=460" target="_blank">00:07:40.280</a></span> | <span class="t">And we compare this one with the logic generated on the first axis and on the second axis,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L3BTG8ETY_Y&t=466" target="_blank">00:07:46.880</a></span> | <span class="t">basically means on there by rows or by columns, then we sum the two losses and we divide by</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L3BTG8ETY_Y&t=472" target="_blank">00:07:52.040</a></span> | <span class="t">two.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L3BTG8ETY_Y&t=473" target="_blank">00:07:53.040</a></span> | <span class="t">So we do the average of the two loss.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L3BTG8ETY_Y&t=474" target="_blank">00:07:54.040</a></span> | <span class="t">And this is our loss function.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L3BTG8ETY_Y&t=476" target="_blank">00:07:56.880</a></span> | <span class="t">And this is how the training works for this contrastive training.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L3BTG8ETY_Y&t=483" target="_blank">00:08:03.600</a></span> | <span class="t">Then how do we do inference?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L3BTG8ETY_Y&t=487" target="_blank">00:08:07.800</a></span> | <span class="t">Inference is quite easy, and quite efficient, also, I have to say, first of all, because</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L3BTG8ETY_Y&t=493" target="_blank">00:08:13.320</a></span> | <span class="t">imagine we have a picture of a dog.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L3BTG8ETY_Y&t=495" target="_blank">00:08:15.840</a></span> | <span class="t">What we do, we don't need to calculate anything from the text encoder, which we can calculate</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L3BTG8ETY_Y&t=502" target="_blank">00:08:22.200</a></span> | <span class="t">only one.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L3BTG8ETY_Y&t=503" target="_blank">00:08:23.200</a></span> | <span class="t">So first of all, actually, what we do is, we create a prompt, so a photo of a something.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L3BTG8ETY_Y&t=509" target="_blank">00:08:29.240</a></span> | <span class="t">And what we do is, we create a list of classes that we expect to work with.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L3BTG8ETY_Y&t=515" target="_blank">00:08:35.880</a></span> | <span class="t">So in this case, we can work with plane cars, dogs, birds, etc.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L3BTG8ETY_Y&t=519" target="_blank">00:08:39.760</a></span> | <span class="t">So we pass all of these possible classes into this prompt generate the corresponding feature</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L3BTG8ETY_Y&t=526" target="_blank">00:08:46.240</a></span> | <span class="t">for the prompt.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L3BTG8ETY_Y&t=527" target="_blank">00:08:47.240</a></span> | <span class="t">So for example, we will have a picture of a plane and generate its features into t one,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L3BTG8ETY_Y&t=532" target="_blank">00:08:52.160</a></span> | <span class="t">then a picture of a car and we will have another feature and put it into t two, a picture of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L3BTG8ETY_Y&t=536" target="_blank">00:08:56.960</a></span> | <span class="t">a dog, and then put it into t three, we compute all these features, and we keep them aside,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L3BTG8ETY_Y&t=543" target="_blank">00:09:03.720</a></span> | <span class="t">we save them, we can reuse them even for the next classification.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L3BTG8ETY_Y&t=548" target="_blank">00:09:08.000</a></span> | <span class="t">We don't have to compute them every time we want to classify an image.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L3BTG8ETY_Y&t=551" target="_blank">00:09:11.800</a></span> | <span class="t">So we do this job only once.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L3BTG8ETY_Y&t=554" target="_blank">00:09:14.160</a></span> | <span class="t">And then what we do is we take the picture of the dog, we pass it through the image encoder,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L3BTG8ETY_Y&t=557" target="_blank">00:09:17.960</a></span> | <span class="t">we calculate its features, and then we multiply basically what we have computed before with</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L3BTG8ETY_Y&t=562" target="_blank">00:09:22.680</a></span> | <span class="t">the features of from of the image.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L3BTG8ETY_Y&t=566" target="_blank">00:09:26.120</a></span> | <span class="t">And the one with the highest value will be the chosen label will be the chosen text corresponding</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L3BTG8ETY_Y&t=572" target="_blank">00:09:32.520</a></span> | <span class="t">to this picture.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L3BTG8ETY_Y&t=574" target="_blank">00:09:34.400</a></span> | <span class="t">And this is how the inference works.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L3BTG8ETY_Y&t=576" target="_blank">00:09:36.140</a></span> | <span class="t">As we can see, it's quite efficient also, because we only have to compute the features</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L3BTG8ETY_Y&t=580" target="_blank">00:09:40.400</a></span> | <span class="t">of the image once and then of course, we have to multiply.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L3BTG8ETY_Y&t=586" target="_blank">00:09:46.960</a></span> | <span class="t">And okay, this in the website, we also can see that the clip authors were telling about</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L3BTG8ETY_Y&t=595" target="_blank">00:09:55.560</a></span> | <span class="t">the problems they had with the previous models, for example, image net was, you know, was</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L3BTG8ETY_Y&t=601" target="_blank">00:10:01.360</a></span> | <span class="t">built using millions of images, and they see required over 25,000 workers to annotate 14</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L3BTG8ETY_Y&t=609" target="_blank">00:10:09.040</a></span> | <span class="t">million images for 22,000 objects series.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L3BTG8ETY_Y&t=612" target="_blank">00:10:12.520</a></span> | <span class="t">So actually, clip is doing it nearly for free, if we could say, because actually, we are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L3BTG8ETY_Y&t=617" target="_blank">00:10:17.440</a></span> | <span class="t">learning from the internet, and there is a lot of resource available on the internet.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L3BTG8ETY_Y&t=621" target="_blank">00:10:21.360</a></span> | <span class="t">And this model actually will be used also by stable diffusion and all these generative</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L3BTG8ETY_Y&t=625" target="_blank">00:10:25.680</a></span> | <span class="t">systems that actually just download the stuff from the internet and train models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L3BTG8ETY_Y&t=630" target="_blank">00:10:30.920</a></span> | <span class="t">And the same is done for GPT and all the other language models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L3BTG8ETY_Y&t=636" target="_blank">00:10:36.840</a></span> | <span class="t">And here we can see some examples of of classification.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L3BTG8ETY_Y&t=642" target="_blank">00:10:42.600</a></span> | <span class="t">I didn't load all of them.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L3BTG8ETY_Y&t=645" target="_blank">00:10:45.080</a></span> | <span class="t">And clip is also very highly efficient compared to the other models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L3BTG8ETY_Y&t=648" target="_blank">00:10:48.880</a></span> | <span class="t">And the best aspect of clip is that it can work very well on zero shot.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L3BTG8ETY_Y&t=655" target="_blank">00:10:55.400</a></span> | <span class="t">So for example, for example, clip is able to classify, I don't know, action recognition,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L3BTG8ETY_Y&t=666" target="_blank">00:11:06.000</a></span> | <span class="t">even OCR.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L3BTG8ETY_Y&t=667" target="_blank">00:11:07.640</a></span> | <span class="t">But not all tasks is not efficient in every task, of course, for example, some tasks that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L3BTG8ETY_Y&t=673" target="_blank">00:11:13.200</a></span> | <span class="t">are even difficult for human as a zero shot task, of course, clip is not performing very</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L3BTG8ETY_Y&t=680" target="_blank">00:11:20.200</a></span> | <span class="t">well on them.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L3BTG8ETY_Y&t=681" target="_blank">00:11:21.760</a></span> | <span class="t">And some tasks that are totally unrelated to his training data are also he's not also</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L3BTG8ETY_Y&t=686" target="_blank">00:11:26.360</a></span> | <span class="t">performing very well on those tasks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L3BTG8ETY_Y&t=689" target="_blank">00:11:29.920</a></span> | <span class="t">For example, counting the objects in an image, etc.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L3BTG8ETY_Y&t=693" target="_blank">00:11:33.700</a></span> | <span class="t">And yeah, this is it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L3BTG8ETY_Y&t=697" target="_blank">00:11:37.480</a></span> | <span class="t">Another note I wanted to add is, is that how does they how do they extract features.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L3BTG8ETY_Y&t=705" target="_blank">00:11:45.400</a></span> | <span class="t">So we have one text encoder here and one image encoder as the image encoder, the authors</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L3BTG8ETY_Y&t=712" target="_blank">00:11:52.820</a></span> | <span class="t">use ResNet and the vision transformer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L3BTG8ETY_Y&t=716" target="_blank">00:11:56.720</a></span> | <span class="t">And for them, we just extract the features from the last year and that's it about the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L3BTG8ETY_Y&t=721" target="_blank">00:12:01.400</a></span> | <span class="t">text encoder.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L3BTG8ETY_Y&t=723" target="_blank">00:12:03.440</a></span> | <span class="t">What the authors do actually is they choose a transformer, but they only use the encoder</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L3BTG8ETY_Y&t=729" target="_blank">00:12:09.880</a></span> | <span class="t">part of the transformer, of course.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L3BTG8ETY_Y&t=732" target="_blank">00:12:12.080</a></span> | <span class="t">And what they do is they take the features corresponding to the end of text token from</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L3BTG8ETY_Y&t=740" target="_blank">00:12:20.260</a></span> | <span class="t">the last layer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L3BTG8ETY_Y&t=741" target="_blank">00:12:21.920</a></span> | <span class="t">So basically, it's written here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L3BTG8ETY_Y&t=744" target="_blank">00:12:24.640</a></span> | <span class="t">Actually, it was not very clear to me the way the authors wrote it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L3BTG8ETY_Y&t=750" target="_blank">00:12:30.080</a></span> | <span class="t">So the text sequence is bracketed with start of sentence and end of sentence tokens and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L3BTG8ETY_Y&t=753" target="_blank">00:12:33.840</a></span> | <span class="t">the activation of the highest layer of the transformer at the end of sentence token are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L3BTG8ETY_Y&t=758" target="_blank">00:12:38.720</a></span> | <span class="t">treated as the feature representation of the text.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L3BTG8ETY_Y&t=762" target="_blank">00:12:42.320</a></span> | <span class="t">This basically means that if we watch the attention paper, they take the features from</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L3BTG8ETY_Y&t=769" target="_blank">00:12:49.080</a></span> | <span class="t">here and corresponding to the end of sentence character, which in the code is done on this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L3BTG8ETY_Y&t=778" target="_blank">00:12:58.720</a></span> | <span class="t">You can see here, this is file model.py.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L3BTG8ETY_Y&t=782" target="_blank">00:13:02.320</a></span> | <span class="t">It's done here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L3BTG8ETY_Y&t=783" target="_blank">00:13:03.720</a></span> | <span class="t">So what they do is for they pass the text to the transformer, they do the normalization.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L3BTG8ETY_Y&t=792" target="_blank">00:13:12.760</a></span> | <span class="t">Then for each of the text, they check in the original text, where was the position of the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L3BTG8ETY_Y&t=798" target="_blank">00:13:18.920</a></span> | <span class="t">end of sentence token.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L3BTG8ETY_Y&t=801" target="_blank">00:13:21.560</a></span> | <span class="t">This is how they do it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L3BTG8ETY_Y&t=803" target="_blank">00:13:23.240</a></span> | <span class="t">And they get the features corresponding to that one.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L3BTG8ETY_Y&t=806" target="_blank">00:13:26.120</a></span> | <span class="t">And that's what they use to multiply with the W matrix to obtain the features and then</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L3BTG8ETY_Y&t=811" target="_blank">00:13:31.960</a></span> | <span class="t">do the cosine similarity.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L3BTG8ETY_Y&t=815" target="_blank">00:13:35.040</a></span> | <span class="t">I hope my explanation was clear.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L3BTG8ETY_Y&t=817" target="_blank">00:13:37.160</a></span> | <span class="t">I was not very concerned about actually the results, which you can read on the paper and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L3BTG8ETY_Y&t=822" target="_blank">00:13:42.280</a></span> | <span class="t">you can read also on the website, even the applications.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L3BTG8ETY_Y&t=826" target="_blank">00:13:46.280</a></span> | <span class="t">Actually what I wanted to show in this paper in this small video is that how do how does</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L3BTG8ETY_Y&t=834" target="_blank">00:13:54.120</a></span> | <span class="t">clip work and how do we train a model similar to this?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L3BTG8ETY_Y&t=838" target="_blank">00:13:58.120</a></span> | <span class="t">Thank you for listening and enjoy the rest of your day.</span></div></div></body></html>