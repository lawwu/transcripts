<html><head><title>Is Effective Altruism RISK OBSESSED?</title>
<style>
    body {
        font-family: Arial, sans-serif;
        margin: 0;
        padding: 0;
        background-color: #f4f4f4;
        color: #333;
    }
    .container {
        width: 95%;  /* Increased width to use more space */
        margin: auto;
        overflow: auto;  /* Added to handle overflow by adding a scrollbar if necessary */
    }
    h2, h3 {
        color: #333;
        text-align: center;
    }
    a {
        color: #0000FF;  /* Traditional blue color for links */
        text-decoration: none;
    }
    a:hover {
        text-decoration: underline;
    }
    img {
        display: block;
        margin: auto;
        max-width: 100%;
    }
    .c {
        margin: 10px 0;
    }
    .s, .t {
        display: inline-block;
        margin-right: 5px;
    }
    .max-width {
        max-width: 800px;
        margin: auto;
        padding-left: 20px;
    }
    table {
        width: 100%;
        border-collapse: collapse;
    }
    th, td {
        border: 1px solid #ddd;
        padding: 8px;
        text-align: left;  /* Ensure text alignment is consistent */
    }
    tr:nth-child(even) {
        background-color: #f2f2f2;
    }
    tr:nth-child(odd) {
        background-color: #e6e6e6;
    }
</style>

    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-69VLBMTTP0"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-69VLBMTTP0');
    </script>
    </head><body><div class='container'><a href="index.html">Back to Index</a><h2>Is Effective Altruism RISK OBSESSED?</h2><a href="https://www.youtube.com/watch?v=OvaHrV_63xE" target="_blank"><img src="https://i.ytimg.com/vi/OvaHrV_63xE/hq720_2.jpg?sqp=-oaymwEdCJUDENAFSFXyq4qpAw8IARUAAIhCcAHAAQbQAQE=&rs=AOn4CLBBAJ5hjimESCAAZFdB0GosO8HU_w" style="width:50%;"></a><div><br></div><h3>Transcript</h3><div class='max-width'><p>they're not epistemically modest enough when it comes to existential risk. These very particular hypotheses about AGI, and we've got to prevent this, and that's where I really differ from them. I think that if AGI is a risk, it's the worst set of procedures that will do you in, and you can't regulate those very well at all.</p><p>And putting everyone at your favorite tech company through this training about alignment, I'm not against doing that, but come on. If it's going to happen, it's like handling pandemic materials. It's the sloppiest people you've got to worry about, and they are not sitting in on your class on AGI and alignment.</p><p>I'm all for things to make nuclear weapons safer, but it's hard to know exactly what you do. There's not some special branch of EA long-termism that tells you what to do in Ukraine, and those people, if anything, tend to be kind of under-invested in historical and cultural forms of knowledge.</p><p>Plenty of people in the U.S. foreign policy establishment who think about all this stuff. It doesn't change the debate much.</p></div></div></body></html>